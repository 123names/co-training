{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chung-may yang1.txt', 'david g lloyd0.txt', 'david g lloyd1.txt', 'jeong hwan kim1.txt', 'chung-may yang0.txt', 'michael wagner0.txt', 'kevin m. ryan0.txt', 'michael wagner1.txt', 'lei wang0.txt', 'jeong hwan kim0.txt', 'lei wang1.txt', 'kevin m. ryan1.txt']\n",
      "['-0.232623', '-0.12317', '-0.178615', '-0.120828', '-0.0637316', '0.119655', '-0.136511', '-0.012849', '-0.125184', '0.0461908', '0.0581749', '-0.183963', '-0.0459688', '0.19452', '-0.0170126', '-0.142147', '0.066843', '0.0642291', '0.00959536', '-0.107407', '0.0097539', '0.0416746', '-0.103548', '0.0770354', '0.108264', '0.0566145', '-0.0668466', '0.163799', '0.0729433', '-0.000337214', '-0.161726', '0.046857', '0.0794689', '-0.0573545', '-0.035842', '-0.0549588', '0.0425291', '-0.0653112', '0.0527278', '0.0105899', '-0.15386', '-0.104491', '-0.0575352', '-0.113251', '-0.0697307', '0.0515379', '-0.0936607', '0.0598422', '-0.0820808', '-0.0636461', '0.0354209', '-0.0147456', '0.119361', '-0.0330736', '0.056727', '-0.165324', '-0.0327852', '0.0489133', '0.0677268', '-0.245867', '0.0293898', '-0.0616188', '-0.040249', '-0.205614', '0.0825651', '0.0415449', '0.122681', '-0.231099', '0.108181', '-0.0763333', '0.0119602', '-0.24921', '0.0784226', '-0.0935032', '0.0334085', '-0.0857513', '0.0657114', '0.111908', '0.117492', '0.168683', '0.0201762', '-0.0189834', '0.0308606', '-0.0884006', '-0.0247744', '0.00208677', '0.0574192', '0.104499', '0.00580749', '-0.182603', '0.00696503', '0.037431', '-0.0301263', '-0.128484', '-0.0433902', '0.0996642', '-0.118848', '0.00068486', '-0.0493116', '0.00573114']\n",
      "['-0.260863', '-0.0575147', '-0.20865', '-0.06824', '-0.0462675', '0.158533', '-0.103522', '0.0818297', '-0.054455', '0.0763776', '-0.112115', '-0.0312639', '-0.0535294', '0.148288', '-0.0483862', '-0.182657', '0.0290918', '0.113457', '0.0408922', '0.151185', '0.141287', '0.000903907', '0.0310395', '0.154702', '0.0948534', '-0.0197563', '0.0063923', '0.0528762', '0.112095', '-0.0673987', '-0.18505', '0.0861527', '0.0433998', '-0.0521172', '-0.0527875', '0.132237', '-0.119259', '-0.188731', '-0.119535', '0.0908325', '-0.0874132', '-0.0538344', '-0.0218321', '-0.0830512', '-0.151364', '-0.174384', '-0.096629', '-0.0126548', '-0.00266152', '-0.0609014', '0.0111415', '-0.0461712', '0.0617766', '-0.0220772', '0.134287', '-0.125483', '0.0642811', '-0.0330317', '-0.0505816', '-0.000657477', '0.0962274', '-0.0992277', '0.0278588', '-0.142329', '-0.0691681', '-0.0389713', '0.0137012', '-0.0543299', '-0.108635', '-0.0532416', '-0.0513788', '-0.0235441', '0.230458', '-0.0754578', '0.0485878', '-0.0157642', '0.0227683', '-0.19018', '0.0321877', '0.0531086', '-0.0426352', '-0.118388', '0.0774679', '-0.116677', '-0.0588731', '-0.0221933', '-0.06306', '-0.0914483', '0.0717639', '0.0366791', '-0.00220658', '-0.0251809', '-0.0671998', '-0.103334', '-0.148648', '-0.0564627', '-0.206351', '0.0359273', '-0.227927', '0.0661824']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# collect data\n",
    "fileDir = \"../Data/DataForClassification/\"\n",
    "fileList = os.listdir(fileDir)\n",
    "print(fileList)\n",
    "\n",
    "# # auto method that go through all the file in directory\n",
    "# for file in fileList:\n",
    "#     if not file.startswith('.'):\n",
    "#         if file.endswith(\".txt\"):\n",
    "#             file = file[:-4]\n",
    "\n",
    "# hard code to read the file one by one\n",
    "author0 = []\n",
    "author1 = []\n",
    "with open(fileDir+\"lei wang0.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        read_data = line.strip().split(\"\\t\")\n",
    "        author0.append(read_data[1].split(\" \"))\n",
    "\n",
    "with open(fileDir+\"lei wang1.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        read_data = line.strip().split(\"\\t\")\n",
    "        author1.append(read_data[1].split(\" \"))\n",
    "print(author0[0])\n",
    "print(author1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# size of each class\n",
    "print(len(author0))\n",
    "print(len(author1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# number of features (dimension)\n",
    "print(len(author0[0]))\n",
    "print(len(author1[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0           1           2           3           4          5  \\\n",
      "0  0.0641123  -0.0615801   -0.251977   -0.023063  -0.0188361   0.038366   \n",
      "1  -0.233405  -0.0512902   -0.219455   -0.023153   -0.084073  0.0945192   \n",
      "2  -0.202214   -0.126435  -0.0815735  -0.0469542  -0.0273222  0.0569356   \n",
      "3  -0.253184   0.0318314   -0.248105   -0.184714    0.166186  0.0543164   \n",
      "4  -0.153682  -0.0443485   -0.107922   -0.139944  -0.0898169   0.055224   \n",
      "\n",
      "            6           7           8            9  ...           91  \\\n",
      "0  -0.0937673  -0.0578285   -0.100574    0.0223806  ...   0.00321343   \n",
      "1  -0.0710282  -0.0337651  -0.0476832     0.108345  ...    0.0826303   \n",
      "2   -0.076542  -0.0407632   -0.105154  -0.00680006  ...    0.0907763   \n",
      "3   0.0603233   0.0190748  -0.0815832     0.092431  ...    0.0230457   \n",
      "4   -0.193431   -0.130026  -0.0899581    0.0777159  ...   -0.0151897   \n",
      "\n",
      "           92          93           94          95          96          97  \\\n",
      "0  -0.0127611   -0.106231   -0.0856751  -0.0034695  -0.0522007  -0.0735756   \n",
      "1  -0.0740323  -0.0491293    -0.132997  -0.0104761   -0.208466   0.0265355   \n",
      "2  -0.0930582   -0.171352    -0.185926    0.146031   -0.126847  -0.0301973   \n",
      "3   -0.228117   -0.241786    -0.119662  -0.0205572   -0.111634   -0.054321   \n",
      "4  -0.0695683    -0.12338  -0.00300068    0.110622  -0.0888987  -0.0173465   \n",
      "\n",
      "          98          99 label  \n",
      "0  -0.250922  -0.0389861     0  \n",
      "1  -0.147722  0.00835459     1  \n",
      "2  -0.257511   -0.131568     0  \n",
      "3   -0.26336   -0.016532     0  \n",
      "4  -0.113203   -0.129437     0  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# reconstract data so that we can feed it to svm\n",
    "import pandas as pd\n",
    "classOne = pd.DataFrame(author0)\n",
    "classOne[\"label\"] = 0\n",
    "#print(classOne[:2:])\n",
    "classTwo = pd.DataFrame(author1)\n",
    "classTwo[\"label\"] = 1\n",
    "#print(classTwo[:2:])\n",
    "# combine data from different class get all data\n",
    "combinedData = pd.concat([classOne, classTwo])\n",
    "combinedData = combinedData.sample(frac=1).reset_index(drop=True)\n",
    "print(combinedData[:5])\n",
    "# split data and label\n",
    "data = combinedData.drop('label', axis=1)\n",
    "label = combinedData['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "def k_fold_cv(data, label, classifier, dataname):\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    # create lists to collect statistic\n",
    "    tp = []\n",
    "    fp = []\n",
    "    tn = []\n",
    "    fn = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        label_train, test_true_label = label.iloc[train_index], label.iloc[test_index]\n",
    "        # fit data to svm\n",
    "        classifier.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = classifier.predict(data_test)\n",
    "        # find round confusion matrix\n",
    "        round_tn, round_fp, round_fn, round_tp = metrics.confusion_matrix(test_true_label, label_pred).ravel()\n",
    "        # add data data to array\n",
    "        tp.append(round_tp)\n",
    "        fp.append(round_fp)\n",
    "        fn.append(round_fn)\n",
    "        tn.append(round_tn)\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "\n",
    "    print(\"Dataset: {name}\\nTrue positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "          .format(name=dataname, tp=np.sum(tp), fp=np.sum(fp), fn=np.sum(fn), tn=np.sum(tn)))\n",
    "    ppv, npv, specificity, sensitivity, accuracy = calculate_important_value(np.sum(tp), np.sum(tn),\n",
    "                                                                             np.sum(fp), np.sum(fn), len(data))\n",
    "    return ppv, npv, specificity, sensitivity, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate ppv,npv,specificity,sensitivity, and accuracy\n",
    "def calculate_important_value(tp, tn, fp, fn, sample_length):\n",
    "    # 1. Positive predicted value (PPV) or precision aka hit rate = True positive/ )True positive + False positive)\n",
    "    ppv = (tp / (tp + fp))\n",
    "    # 2. Negative predicted value (NPV) = True negative / (True negative + False negative)\n",
    "    npv = (tn / (tn + fn))\n",
    "    # 3. Specificity = (1 - False positive)\n",
    "    specificity = (tn / (tn + fp))\n",
    "    # 4. Sensitivity = True positive\n",
    "    sensitivity = (tp / (tp + fn))\n",
    "    # 5. Accuracy = (True positive + True negative) / Total number of sample\n",
    "    accuracy = (tp + tn) / sample_length\n",
    "    print('PPV: ', ppv)\n",
    "    print('NPV: ', npv)\n",
    "    print('Specificity: ', specificity)\n",
    "    print('Sensitivity: ', sensitivity)\n",
    "    print('Accuracy: ', accuracy,)\n",
    "    return ppv, npv, specificity, sensitivity, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Dataset: Same name author\n",
      "True positive: 63, False positive: 0, False negative: 1, True negative: 53\n",
      "PPV:  1.0\n",
      "NPV:  0.9814814814814815\n",
      "Specificity:  1.0\n",
      "Sensitivity:  0.984375\n",
      "Accuracy:  0.9914529914529915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9814814814814815, 1.0, 0.984375, 0.9914529914529915)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # create linear SVM model\n",
    "# linear_svc = svm.SVC(kernel='linear')\n",
    "# print(linear_svc)\n",
    "\n",
    "# create rbf SVM model\n",
    "rbf_svc = svm.SVC(kernel='rbf', C=100)\n",
    "print(rbf_svc)\n",
    "\n",
    "# fit model and do 10-fold cv\n",
    "k_fold_cv(data, label, rbf_svc, \"Same name author\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
