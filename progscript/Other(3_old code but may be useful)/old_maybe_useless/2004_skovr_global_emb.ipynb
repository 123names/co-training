{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T17:52:06.918037Z",
     "start_time": "2018-12-19T17:52:06.862288Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import com_func\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "# parameters\n",
    "threshold = 30\n",
    "cutoff = 3\n",
    "\n",
    "pp_textual = [\"tf\",\"tf_idf\",\"lsa\"]\n",
    "\n",
    "Dataset = \"pubmed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T17:52:09.910571Z",
     "start_time": "2018-12-19T17:52:07.465516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  135796  labeled paper have text information\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load text information\n",
    "Dataset = \"pubmed\"\n",
    "raw_filepath = \"../../Data\"+\"/\"+Dataset+\"/id_textual_combined_labeled.txt\"\n",
    "all_text_content = []\n",
    "with open(raw_filepath, 'r', encoding = 'utf8') as f:\n",
    "    # items[0] is paper ID, items[1] is title, items[2] is abstract\n",
    "    for line in f:\n",
    "        items = line.split(\"\\t\")\n",
    "        # lower case all character\n",
    "        paperID = items[0]\n",
    "        title = items[1].lower()\n",
    "        keywords = items[2].lower()\n",
    "        mesh = items[3].lower()\n",
    "        abstract = items[4].lower()\n",
    "        # textual information can be defined as title+abstract\n",
    "        content = title+\" \"+keywords+\" \"+mesh+\" \"+abstract\n",
    "        paper_text_content = {\"paperID\": paperID, \"combine_textual\":content}\n",
    "        all_text_content.append(paper_text_content)\n",
    "print(\"Total \", len(all_text_content), \" labeled paper have text information\")\n",
    "# convert to dataframe so it's easy to process\n",
    "all_text_content = pd.DataFrame(all_text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T18:08:38.262498Z",
     "start_time": "2018-12-19T18:08:38.066852Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# read trained rec to rec textual graph\n",
    "def read_textual_embedding(Dataset = \"pubmed\", emb_type = \"off\"):\n",
    "    textual_emb = []\n",
    "    while True:\n",
    "        if emb_type == \"pv_dm\":\n",
    "            modelSaveDir = \"../../Data/\"+Dataset+\"/models/doc2v/textual_sample=140k/\"\n",
    "            model = gensim.models.Doc2Vec.load(modelSaveDir+\"pv_dm/Doc2Vec(dmm,d100,n5,w5,mc3,s0.001,t24)\")\n",
    "            allPaperTags = model.docvecs.offset2doctag\n",
    "            for pid in allPaperTags:\n",
    "                vectorRepresentation = model.docvecs[pid].tolist()\n",
    "                vectorRepresentation = [format(i, '.8f') for i in vectorRepresentation]\n",
    "                vectorRepresentation = ' '.join(vectorRepresentation)\n",
    "                textual_emb.append(pid+\" \"+vectorRepresentation)\n",
    "                \n",
    "            print(\"Total textual vector records:\",len(textual_emb))\n",
    "            print(textual_emb[:3])\n",
    "            break\n",
    "        elif emb_type == \"pv_dbow\":\n",
    "            modelSaveDir = \"../../Data/\"+Dataset+\"/models/doc2v/textual_sample=140k/\"\n",
    "            model = gensim.models.Doc2Vec.load(modelSaveDir+\"pv_dbow/Doc2Vec(dbow,d100,n5,mc3,s0.001,t24)\")\n",
    "            allPaperTags = model.docvecs.offset2doctag\n",
    "            for pid in allPaperTags:\n",
    "                vectorRepresentation = model.docvecs[pid].tolist()\n",
    "                vectorRepresentation = [format(i, '.8f') for i in vectorRepresentation]\n",
    "                vectorRepresentation = ' '.join(vectorRepresentation)\n",
    "                textual_emb.append(pid+\" \"+vectorRepresentation)\n",
    "                \n",
    "            print(\"Total textual vector records:\",len(textual_emb))\n",
    "            print(textual_emb[:3])\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return textual_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T17:52:40.789875Z",
     "start_time": "2018-12-19T17:52:40.714698Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read trained rec to rec node2vec citation graph\n",
    "def read_citation_embedding(Dataset = \"pubmed\", emb_type = \"off\"):\n",
    "    citation_emb = []\n",
    "    while True:\n",
    "        if emb_type == \"n2v\":\n",
    "            citation_emb_dir = \"../../Data/\"+Dataset+\"/vectors/\"+emb_type+\"/extracted_labeled_n2v.txt\"\n",
    "            with open(citation_emb_dir, 'r', encoding = 'utf8') as f:\n",
    "                for line in f:\n",
    "                    read_data = line.split(\" \")\n",
    "                    if(len(read_data)==101):\n",
    "                        paper_Vectors = read_data\n",
    "                        citation_emb.append(paper_Vectors)\n",
    "            f.close()\n",
    "            print(\"Total citation vector records:\",len(citation_emb))\n",
    "            print(citation_emb[:3])\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return citation_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T17:52:41.040500Z",
     "start_time": "2018-12-19T17:52:40.994203Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy(doc):\n",
    "    return doc\n",
    "def read_labeled_file(infile):\n",
    "    LabeledRecords_original = []\n",
    "    with open(infile, 'r', encoding = 'utf8') as f:\n",
    "        for line in f:\n",
    "            read_data = line.split(\"\\t\")\n",
    "            # get ride of bad formated lines\n",
    "            if(len(read_data)==13 or len(read_data)==12):\n",
    "                paper_detail = {\"paperID\": read_data[0], \"authorID\":read_data[1], \n",
    "                                \"co-author\": read_data[5], \"venue_id\": read_data[7]}\n",
    "                LabeledRecords_original.append(paper_detail)\n",
    "            else:\n",
    "                print(len(read_data))\n",
    "        f.close()\n",
    "    return pd.DataFrame(LabeledRecords_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T17:52:41.329584Z",
     "start_time": "2018-12-19T17:52:41.300843Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSA(cleaned_token, dim=100):\n",
    "    # Tf-idf Transformation\n",
    "    modelSaveDir = \"../../Data/\"+Dataset+\"/models/count/textual_sample=140k/\"\n",
    "    with open(modelSaveDir+'tf_idf_Vectorizer.pickle', \"rb\") as input_file:\n",
    "        model = pickle.load(input_file)\n",
    "    tfidfMatrix = model.transform(cleaned_token).toarray()\n",
    "    # tf-idf + svd\n",
    "    svd = TruncatedSVD(n_components=dim)\n",
    "    final_lsa_Matrix = svd.fit_transform(tfidfMatrix)\n",
    "    print(svd.explained_variance_ratio_.sum())\n",
    "    return final_lsa_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_embedding(all_embedding, pid):\n",
    "    extracted_emb = []\n",
    "    wanted_pid = pid.values.tolist()\n",
    "    # only if embedding exist\n",
    "    if len(all_embedding)>0:\n",
    "        for paper_embedding in all_embedding:\n",
    "            if paper_embedding[0] in wanted_pid:\n",
    "                extracted_emb.append(paper_embedding)\n",
    "    \n",
    "    extracted_emb = pd.DataFrame(extracted_emb)\n",
    "    # only if embedding exist\n",
    "    if len(all_embedding)>0:\n",
    "        # reorder embedding with pid and fill empty record with 0\n",
    "        extracted_emb = pd.merge(pid.to_frame(), extracted_emb, left_on='paperID', right_on=0, how='outer')\n",
    "        # fill missing value with 0\n",
    "        extracted_emb.fillna(0, inplace = True)\n",
    "        # remove index\n",
    "        extracted_emb.drop(['paperID', 0], axis=1, inplace=True)\n",
    "    return extracted_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T17:52:41.844585Z",
     "start_time": "2018-12-19T17:52:41.658803Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim\n",
    "# document relation wrt textual content\n",
    "# convert raw text to numerical feature vectors\n",
    "# bow(Bags of words) are used with uni-gram setting\n",
    "def get_textual_embedding(raw_textual_content, pretrained_emb, pid, emb_type=\"off\", stopword=True):\n",
    "    while True:\n",
    "        if emb_type == \"tf\":\n",
    "            cleaned_token, sample_size= com_func.clean_batch_of_raw(raw_textual_content, stopword=stopword)\n",
    "            average_sample_size = sum(sample_size)/len(sample_size)\n",
    "            print(\"Minimal sample size: \", min(sample_size))\n",
    "            print(\"maximal sample size: \", max(sample_size))\n",
    "            modelSaveDir = \"../../Data/\"+Dataset+\"/models/count/textual_sample=140k/\"\n",
    "            with open(modelSaveDir+'CountVectorizer.pickle', \"rb\") as input_file:\n",
    "                model = pickle.load(input_file)\n",
    "            tf_vector = model.transform(cleaned_token).toarray()\n",
    "            print(tf_vector.shape)\n",
    "            result_vector = normalize(tf_vector)\n",
    "            break\n",
    "        elif emb_type == \"tf_idf\":\n",
    "            cleaned_token, sample_size= com_func.clean_batch_of_raw(raw_textual_content, stopword=stopword)\n",
    "            average_sample_size = sum(sample_size)/len(sample_size)\n",
    "            print(\"Minimal sample size: \", min(sample_size))\n",
    "            print(\"maximal sample size: \", max(sample_size))\n",
    "            # using tf-idf\n",
    "            modelSaveDir = \"../../Data/\"+Dataset+\"/models/count/textual_sample=140k/\"\n",
    "            with open(modelSaveDir+'tf_idf_Vectorizer.pickle', \"rb\") as input_file:\n",
    "                model = pickle.load(input_file)\n",
    "            result_vector = model.transform(cleaned_token).toarray()\n",
    "            #print(len(tfidf_vectorizer.vocabulary_))\n",
    "            #print(tfidf_vectorizer.get_feature_names())\n",
    "            break\n",
    "        elif emb_type == \"lsa\":\n",
    "            cleaned_token, sample_size= com_func.clean_batch_of_raw(raw_textual_content, stopword=stopword)\n",
    "            average_sample_size = sum(sample_size)/len(sample_size)\n",
    "            print(\"Minimal sample size: \", min(sample_size))\n",
    "            print(\"maximal sample size: \", max(sample_size))\n",
    "            # use lsa\n",
    "            result_vector = LSA(cleaned_token, dim=100)\n",
    "            break\n",
    "        elif emb_type ==\"pv_dm\" or emb_type ==\"pv_dbow\":\n",
    "            result_vector = extract_embedding(pretrained_emb, pid)\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, return nothing\")\n",
    "            emb_type=\"off\"\n",
    "    return result_vector, average_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T17:52:42.554298Z",
     "start_time": "2018-12-19T17:52:42.374616Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "# cross validation\n",
    "def k_fold_cv(data, label, clf, k=10):\n",
    "    kf = KFold(n_splits=k, shuffle=False)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data[train_index], data[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        # fit data to clf\n",
    "        clf.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = clf.predict(data_test)\n",
    "        allTrueLabel.extend(label_test)\n",
    "        allPredLabel.extend(label_pred)\n",
    "\n",
    "    accuracy = accuracy_score(allTrueLabel, allPredLabel)\n",
    "    f1 = f1_score(allTrueLabel, allPredLabel,average='macro')\n",
    "    \n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel).ravel())\n",
    "    \n",
    "    # accumulate statistic for entire model f1\n",
    "    cnf_matrix = confusion_matrix(allTrueLabel, allPredLabel)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "#     print(cnf_matrix)\n",
    "#     print(\"TP: \",TP, \"TN: \",TN, \"FP: \",FP,\"FN: \",FN)\n",
    "\n",
    "    return accuracy, f1, TP.sum(), TN.sum(), FP.sum(), FN.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T17:52:43.136641Z",
     "start_time": "2018-12-19T17:52:43.073351Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_csv_df(savePath, filename, df):\n",
    "    if not os.path.exists(savePath):\n",
    "        os.makedirs(savePath)\n",
    "    # Give the filename you wish to save the file to\n",
    "    pathfile = os.path.normpath(os.path.join(savePath,filename))\n",
    "\n",
    "    # Use this function to search for any files which match your filename\n",
    "    files_present = os.path.isfile(pathfile) \n",
    "    # if no matching files, write to csv, if there are matching files, print statement\n",
    "    if not files_present:\n",
    "        df.to_csv(pathfile, encoding='utf-8',index=False)\n",
    "    else:\n",
    "        overwrite = input(\"WARNING: \" + pathfile + \" already exists! Do you want to overwrite <y/n>? \\n \")\n",
    "        if overwrite == 'y':\n",
    "            df.to_csv(pathfile, encoding='utf-8',index=False)\n",
    "        elif overwrite == 'n':\n",
    "            new_filename = input(\"Type new filename: \\n \")\n",
    "            write_csv_df(savePath,new_filename,df)\n",
    "        else:\n",
    "            print(\"Not a valid input. Data is NOT saved!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T18:07:59.259173Z",
     "start_time": "2018-12-19T18:07:40.167890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total textual vector records: 135796\n",
      "['8077 -0.42665145 -0.20274664 0.08016871 0.28375724 0.03493189 -0.22356583 -0.37297058 0.08550507 -0.84635490 -0.53577036 -0.18753140 -0.15832068 0.03342307 0.19853322 0.21486974 -0.88039148 0.07680665 -0.45549583 0.25181597 0.68849790 -0.52579153 -0.15735805 0.69318497 -0.31203189 0.26918790 -0.69177866 0.31827661 -1.24258828 -0.03450382 -0.43042749 0.15029581 0.36190116 -0.03027276 -0.47853798 0.48261651 0.27281243 -0.00015305 -0.02307266 0.28314903 0.43221837 -0.08020838 0.63495243 -0.51042092 1.03504837 0.15637830 0.16105181 -0.16248947 0.57620406 0.12860727 0.20960683 0.15471290 0.27213791 -0.38468286 0.67985624 -0.59635264 -0.00133450 0.07793075 0.17300151 0.07857662 0.66823900 -0.27214140 -0.08212417 -0.43762782 -0.68239814 -0.06299266 0.59357041 0.05746553 -0.02640015 -0.13266836 0.39245602 -0.12700117 -0.46807149 0.15950061 -0.13681552 -0.06565703 -0.13609785 0.44973734 0.06173952 -0.39990264 0.62084496 -0.76443452 -0.12911695 0.70948893 0.06835897 -0.13429186 0.10509528 0.22430976 0.16911224 -0.72276074 -0.11136439 -0.65887821 -0.63525999 0.10970883 0.19054700 0.41874287 -0.36001453 0.22330466 0.38500062 0.17834879 -0.06432433', '17755 -0.06311796 -0.38962537 -0.18472108 0.34644586 -0.67488199 -0.10343249 -0.13457124 -0.12827699 -0.30540439 -0.32146168 -0.50951487 -0.20759399 0.46517101 -0.36092335 -0.43507403 -0.33101714 0.12841816 0.41331699 -0.09575557 0.24425662 0.01455390 -0.27823880 -0.04362241 -0.18510345 0.17995608 -0.50266308 0.26229584 -0.54281205 -0.14098105 -0.23929028 -0.61563706 0.03981762 -0.35247871 -0.43138689 -0.21233805 0.67046493 0.13643932 -0.01213502 -0.15070374 0.34481177 0.16575441 -0.10752333 -0.02134823 -0.26811773 -0.25607637 0.23388921 0.04028615 0.40813410 -0.03527819 -0.37982923 -0.06540231 0.35722050 0.37580407 0.36824811 -0.81638902 -0.25204501 0.06212635 0.21550804 0.22777897 0.08421216 -0.05528188 0.20641613 0.27868226 -0.36849284 -0.21966398 0.22040363 0.26257515 0.11294510 0.36398467 0.04520021 -0.06702038 -0.38875407 -0.26087564 0.24085359 0.25449407 0.11364726 0.34672672 -0.09693519 -0.07045508 -0.29521909 0.06204965 0.56102353 0.22571076 -0.26162505 -0.05398407 0.24112512 0.25973603 -0.21445566 0.00555543 -0.28359157 -0.06269858 -0.40407878 0.18140721 0.40502623 0.25746351 -0.06679741 -0.05091966 0.41102654 0.28617632 0.12657307', '28220 -0.51832366 0.40383309 -0.41082394 -0.24403661 -0.33219358 0.51777220 -0.42321238 -0.00919083 -0.51330537 0.62211299 -0.69933939 -0.34431648 0.24824771 0.06701107 0.33997804 -0.77507716 0.25466543 -0.02661148 0.54447317 0.81636524 0.17327650 0.41548026 -0.20884198 -0.09302299 -0.62451750 -0.38741890 0.33105859 -0.48974726 -0.43435308 -0.06289585 0.16255441 0.60764533 -0.27378094 0.11446487 0.80298698 0.04217253 0.30793196 -0.32928082 0.47493178 -0.04808808 -0.54196548 0.26063412 -0.89067948 0.33889949 0.21707909 0.59092170 -0.47599769 -0.15430516 0.32269561 -0.54182684 1.47508061 -0.33730960 0.31492281 0.13887328 -0.43857372 0.20292005 -0.42910376 0.10601065 0.23672412 0.28420725 -0.31581396 0.84619784 0.12820376 0.03517140 -0.81506610 0.62881237 0.63470435 0.04508404 0.08354325 0.27415788 -0.38771114 0.15090024 -0.24748677 0.31503400 0.34970772 -0.07121788 0.00687338 -0.36666843 0.73019242 -0.38219351 0.22702719 -0.39933175 0.43949589 -0.11054336 0.11926067 -0.41524392 0.52608252 0.41004828 0.16637830 -0.07313053 0.09466083 -0.59853107 0.24492213 0.93115282 0.56094372 0.07755036 -0.36973521 0.25104213 0.35482913 0.04965527']\n",
      "Total citation vector records: 124922\n",
      "[['8077', '0.074837', '0.437304', '0.157833', '0.179944', '-0.0696371', '-0.0925071', '-0.37209', '0.16441', '0.257381', '0.482553', '0.420752', '0.294299', '0.48322', '0.310536', '0.451489', '-0.0321524', '-0.266308', '-0.507235', '0.302519', '-0.192578', '-0.196128', '-0.716089', '0.118927', '0.130549', '0.0538411', '-0.36721', '0.320577', '0.107628', '0.437685', '0.261019', '-0.134182', '0.467584', '-0.433934', '-0.337566', '-0.112999', '0.131627', '0.185436', '-0.0716854', '0.222004', '-0.296244', '0.0662622', '0.209887', '-0.177259', '-0.202866', '0.206727', '-0.0535898', '-0.0832955', '0.00406953', '-0.13292', '-0.0853675', '-0.241761', '-0.327425', '-0.46692', '0.0485383', '0.00806723', '0.0284221', '0.115838', '-0.255672', '-0.770949', '0.0873891', '0.00681434', '0.0626846', '-0.0590345', '0.299776', '-0.173271', '-0.00270774', '-0.498401', '-0.222046', '0.321921', '0.0837049', '-0.0501312', '-0.284909', '0.274566', '0.0670506', '0.0773459', '0.24957', '-0.0768505', '0.0357878', '-0.197779', '-0.110859', '-0.0586628', '-0.371421', '-0.331327', '-0.184969', '0.347994', '-0.535585', '0.136484', '0.606065', '-0.34836', '-0.153024', '0.264854', '-0.347494', '0.0979302', '0.352819', '0.116963', '-0.428671', '-0.203673', '0.340799', '-0.153595', '0.333619\\n'], ['17755', '0.117789', '0.0381872', '0.140725', '0.0353051', '0.0743335', '-0.0230412', '-0.142969', '0.133352', '0.0249408', '0.174816', '0.0710962', '-0.0186644', '0.131927', '-0.0813431', '0.00454495', '0.0411643', '-0.211366', '-0.334071', '0.122605', '0.0906733', '-0.0945511', '-0.204131', '0.0216074', '0.050275', '-0.0138835', '-0.00201036', '0.181787', '0.0625838', '0.163003', '-0.060977', '-0.099711', '0.199833', '-0.257413', '-0.20593', '-0.148003', '-0.0193572', '0.127712', '-0.00496556', '0.203692', '-0.0632423', '-0.085105', '0.111502', '0.0563165', '-0.150758', '0.130987', '-0.24935', '-0.0698974', '-0.159101', '-0.0325247', '0.112569', '-0.0933885', '0.0523473', '-0.311551', '-0.0534642', '-0.0335219', '0.0381494', '0.0325196', '0.0200638', '-0.25958', '0.116856', '-0.00533538', '0.015437', '-0.122961', '0.0405297', '-0.0402108', '-0.0648276', '-0.280718', '-0.0610803', '0.235437', '-0.154469', '0.040941', '0.0660014', '0.0144551', '0.0697055', '0.0861819', '0.22364', '-0.108656', '-0.159732', '0.0263292', '0.0976405', '0.0357826', '-0.0407278', '-0.109561', '-0.0477482', '0.0600652', '-0.244403', '0.0708506', '0.206281', '-0.0660206', '-0.246335', '0.0559538', '-0.250907', '-0.0278802', '0.138755', '-0.0880744', '-0.158979', '-0.0278477', '0.176379', '-0.0994503', '0.134535\\n'], ['28220', '-0.168945', '0.0421443', '0.23792', '0.0796514', '0.19611', '0.0638499', '-0.513983', '0.205836', '0.190542', '0.415064', '0.377228', '0.0176192', '0.152356', '-0.114991', '0.357162', '-0.296283', '0.0681007', '-0.204847', '0.135245', '-0.00781574', '-0.12612', '-0.143662', '-0.0130079', '0.185709', '-0.0763587', '0.0492441', '0.054612', '0.0511256', '0.134606', '0.117456', '-0.231842', '0.0450055', '-0.302675', '-0.0223345', '-0.055917', '-0.261424', '0.105746', '0.104476', '0.183511', '0.0450612', '-0.373329', '0.144302', '0.148158', '0.0699681', '0.270498', '0.0455624', '-0.120792', '-0.172808', '-0.161062', '-0.000496539', '-0.128889', '-0.0161444', '-0.246482', '-0.0448989', '-0.0789056', '-0.15212', '0.111224', '-0.161332', '-0.259847', '0.00823854', '0.0212978', '-0.0829648', '-0.224326', '0.337475', '0.153362', '0.0231983', '-0.138663', '-0.102745', '0.195753', '-0.16937', '-0.350263', '0.134394', '0.228506', '0.375576', '0.115358', '0.228747', '-0.235889', '-0.278699', '-0.151732', '-0.0599872', '0.130166', '-0.0182416', '-0.0320656', '-0.245937', '0.20861', '0.173579', '0.0255497', '0.0826704', '-0.169168', '-0.154122', '0.0454759', '-0.219318', '0.0486723', '0.349938', '0.118215', '-0.281961', '0.0711244', '0.166005', '0.0144367', '0.393137\\n']]\n"
     ]
    }
   ],
   "source": [
    "# read pretrained embeddings\n",
    "all_textual_embedding = read_textual_embedding(emb_type = \"pv_dbow\")\n",
    "all_citation_embedding = read_citation_embedding(emb_type = \"n2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T23:09:48.594329Z",
     "start_time": "2018-12-17T23:08:19.286906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For name:  j_read\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5159-1192': 57, '0000-0002-9029-5185': 39, '0000-0002-9697-0962': 31, '0000-0002-4739-9245': 3, '0000-0003-0605-5259': 3, '0000-0003-4316-7006': 1, '0000-0002-0784-0091': 1, '0000-0002-3888-6631': 1})\n",
      "['0000-0002-9697-0962', '0000-0002-9029-5185', '0000-0002-5159-1192']\n",
      "Total sample size after apply threshold:  127\n",
      "Minimal sample size:  6\n",
      "maximal sample size:  248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.0 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 331350)\n",
      "(127, 331350)\n",
      "1\n",
      "127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        31\n",
      "           1       1.00      0.95      0.97        39\n",
      "           2       0.93      1.00      0.97        57\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       127\n",
      "   macro avg       0.98      0.96      0.97       127\n",
      "weighted avg       0.97      0.97      0.97       127\n",
      "\n",
      "[29  0  2  0 37  2  0  0 57]\n",
      "svc Accuracy:  0.968503937007874\n",
      "svc F1:  0.9688175240360789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85        31\n",
      "           1       0.97      0.92      0.95        39\n",
      "           2       0.85      1.00      0.92        57\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       127\n",
      "   macro avg       0.94      0.89      0.91       127\n",
      "weighted avg       0.92      0.91      0.91       127\n",
      "\n",
      "[23  1  7  0 36  3  0  0 57]\n",
      "LR Accuracy:  0.9133858267716536\n",
      "LR F1:  0.906191703871387\n",
      "svc: TP:  123 TN:  250 FP:  4 FN:  4\n",
      "lr: TP:  116 TN:  243 FP:  11 FN:  11\n"
     ]
    }
   ],
   "source": [
    "# load the file\n",
    "import io\n",
    "import collections\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "fileDir = \"../../Data/\"+Dataset+\"/canopies_labeled/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "\n",
    "# entire model f1\n",
    "modelSVCf1, modelLRf1 = ([] for i in range(2))\n",
    "\n",
    "for emb in pp_textual:\n",
    "    # collect statistic to output\n",
    "    allname, num_class, per_class_count, average_textual_size = ([] for i in range(4))\n",
    "\n",
    "    all_svcLinear_accuracy, all_svcLinear_f1, all_LR_accuracy, all_LR_f1 = ([] for i in range(4))\n",
    "    \n",
    "    # collect overall tp, tn, fp, fn\n",
    "    svcTP=svcTN=svcFP=svcFN = 0\n",
    "    lrTP=lrTN=lrFP=lrFN = 0\n",
    "    # read all file in labeled group\n",
    "    for file in listfiles:\n",
    "        # group name\n",
    "        temp = file.split(\"_\")\n",
    "        name = temp[1]+\"_\"+temp[-1]\n",
    "        print(\"For name: \",name)\n",
    "        # read needed content in labeled file\n",
    "        labeled_data_part = read_labeled_file(fileDir+file)\n",
    "        print(\"total sample size before apply threshold: \",len(labeled_data_part))\n",
    "        # count number of paper each author write based on author ID\n",
    "        paperCounter = collections.Counter(labeled_data_part[\"authorID\"])\n",
    "        print(paperCounter)\n",
    "        # collect per class statistic\n",
    "        for k in list(paperCounter):\n",
    "            if paperCounter[k] < threshold:\n",
    "                del paperCounter[k]\n",
    "        temp =list(paperCounter.keys())\n",
    "        print(temp)\n",
    "        # remove samples that are smaller than threshold\n",
    "        labeled_data_part = labeled_data_part[labeled_data_part.authorID.isin(temp)]\n",
    "        print(\"Total sample size after apply threshold: \",len(labeled_data_part))\n",
    "        # if only have one class or no class pass the threshold, not applicable\n",
    "        if(len(paperCounter)==0) or (len(paperCounter)==1):\n",
    "            print(name, \" pass\")\n",
    "        else:\n",
    "            allname.append(name)\n",
    "            num_class.append(len(paperCounter))\n",
    "            per_class_count.append(paperCounter)\n",
    "            # convert author id to label\n",
    "            gather_label = []\n",
    "            for index, record in labeled_data_part.iterrows():\n",
    "                gather_label.append(temp.index(record[\"authorID\"]))\n",
    "            labeled_data_part[\"label\"] = gather_label\n",
    "            # merge title and abstract from all raw data to labeled dataset\n",
    "            labeled_data = pd.merge(left=labeled_data_part,right=all_text_content, how='left', left_on='paperID', right_on='paperID')\n",
    "            # shuffle the data\n",
    "            labeled_data = labeled_data.sample(frac=1).reset_index(drop=True)\n",
    "            # extract true label and pid\n",
    "            label = labeled_data[\"label\"]\n",
    "            pid = labeled_data[\"paperID\"]\n",
    "            # list of different data field\n",
    "            part_collection = []\n",
    "            # select feature wanted to fit to clustering/classification algorithm\n",
    "            # data part, textual information\n",
    "            data_part_textual, avg_textual_size = raw_text_to_vector(labeled_data['combine_textual'], emb_type=emb)\n",
    "            average_textual_size.append(avg_textual_size)\n",
    "            print(data_part_textual.shape)\n",
    "            part_collection.append(data_part_textual)\n",
    "            # merge different part of data data together by concatenate it all together\n",
    "            # remove empty emb (when emb set off)\n",
    "            part_collection = [part for part in part_collection if len(part)!=0]\n",
    "            print(len(part_collection))\n",
    "            if len(part_collection)>1:\n",
    "                combinedata = np.concatenate(part_collection,axis=1)\n",
    "            elif len(part_collection)==1:\n",
    "                if isinstance(part_collection[0], pd.DataFrame):\n",
    "                    combinedata = part_collection[0].values\n",
    "                else:\n",
    "                    combinedata = part_collection[0]\n",
    "            else:\n",
    "                print(\"No data available\")\n",
    "                break\n",
    "            print(len(combinedata))\n",
    "            # using converted feature vector to train classifier\n",
    "            # using SVM with linear kernal\n",
    "            clf = SVC(decision_function_shape='ovr', kernel='linear')\n",
    "            svcaccuracy, svcmarcof1, tp, tn, fp, fn = k_fold_cv(combinedata, label, clf, k=10)\n",
    "            svcTP+=tp\n",
    "            svcTN+=tn\n",
    "            svcFP+=fp\n",
    "            svcFN+=fn\n",
    "            print(\"svc Accuracy: \",svcaccuracy)\n",
    "            print(\"svc F1: \", svcmarcof1)\n",
    "            all_svcLinear_accuracy.append(svcaccuracy)\n",
    "            all_svcLinear_f1.append(svcmarcof1)\n",
    "            # using logistic regression\n",
    "            clf = LogisticRegression(multi_class='ovr')\n",
    "            LRaccuracy, LRmarcof1, tp, tn, fp, fn = k_fold_cv(combinedata, label, clf, k=10)\n",
    "            lrTP+=tp\n",
    "            lrTN+=tn\n",
    "            lrFP+=fp\n",
    "            lrFN+=fn\n",
    "            print(\"LR Accuracy: \",LRaccuracy)\n",
    "            print(\"LR F1: \", LRmarcof1)\n",
    "            all_LR_accuracy.append(LRaccuracy)\n",
    "            all_LR_f1.append(LRmarcof1)\n",
    "        break\n",
    "    # print f1 for entire model\n",
    "    print(\"svc: TP: \",svcTP, \"TN: \",svcTN, \"FP: \",svcFP,\"FN: \",svcFN)\n",
    "    print(\"lr: TP: \",lrTP, \"TN: \",lrTN, \"FP: \",lrFP,\"FN: \",lrFN)\n",
    "    svcF1 = 2*svcTP / (2*svcTP + svcFP + svcFN)\n",
    "    lrF1 = 2*lrTP / (2*lrTP + lrFP + lrFN)\n",
    "    modelSVCf1.append(svcF1)\n",
    "    modelLRf1.append(lrF1)\n",
    "    break\n",
    "#     # write evaluation result to excel\n",
    "#     output = pd.DataFrame({'Name Group':allname,\"Class number\":num_class,\"per_class_size\":per_class_count, \n",
    "#                            \"svc(linear) accuracy\":all_svcLinear_accuracy, \"svc(linear) macro f1\": all_svcLinear_f1, \n",
    "#                            \"logistic regression accuracy\":all_LR_accuracy, \"logistic regression macro f1\": all_LR_f1})\n",
    "\n",
    "#     savePath = \"../../result/\"+Dataset+\"/skovr/\"\n",
    "#     filename = \"textual=\"+emb+\"_threshold=\"+str(threshold)+\".csv\"\n",
    "#     write_csv_df(savePath, filename, output)\n",
    "#     print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T05:13:38.648417Z",
     "start_time": "2018-12-14T05:13:38.641968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tf', 'tf_idf', 'lsa']\n",
      "svc:  [0.9464991405128569, 0.9731343812578639, 0.9706356660582325]\n",
      "lr:  [0.9699976962200287, 0.9314359637774903, 0.9415017101135941]\n"
     ]
    }
   ],
   "source": [
    "print(pp_textual)\n",
    "print(\"svc: \", modelSVCf1)\n",
    "print(\"lr: \", modelLRf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T01:26:32.525744Z",
     "start_time": "2018-12-14T01:26:32.507072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n",
      "578\n",
      "0.9798807689357634\n",
      "0.9496564529342066\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "from statistics import mean \n",
    "cleaned_svcLinear_accuracy = [x for x in all_svcLinear_accuracy if isinstance(x, float)]\n",
    "cleaned_lr_accuracy = [x for x in all_LR_accuracy if isinstance(x, float)]\n",
    "print(len(cleaned_svcLinear_accuracy))\n",
    "print(len(cleaned_lr_accuracy))\n",
    "print(mean(cleaned_svcLinear_accuracy))\n",
    "print(mean(cleaned_lr_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T01:26:32.881233Z",
     "start_time": "2018-12-14T01:26:32.856794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n",
      "578\n",
      "0.9764067884953497\n",
      "0.9288583090243283\n"
     ]
    }
   ],
   "source": [
    "# f1\n",
    "from statistics import mean \n",
    "# remove string from result\n",
    "cleaned_svcLinear_f1 = [x for x in all_svcLinear_f1 if isinstance(x, float)]\n",
    "cleaned_lr_f1 = [x for x in all_LR_f1 if isinstance(x, float)]\n",
    "print(len(cleaned_svcLinear_f1))\n",
    "print(len(cleaned_lr_f1))\n",
    "print(mean(cleaned_svcLinear_f1))\n",
    "print(mean(cleaned_lr_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-29T21:26:31.930Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%who"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
