{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:28:53.163726Z",
     "start_time": "2018-12-02T02:28:52.682858Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import com_func\n",
    "\n",
    "Dataset = \"pubmed\"\n",
    "\n",
    "# parameters\n",
    "threshold = 10\n",
    "cutoff = 3\n",
    "\n",
    "coauthor_emb_type = \"off\"\n",
    "venue_emb_type = \"tf_idf\"\n",
    "year_emb_type = \"tf_idf\"\n",
    "pp_textual_emb_type = \"off\"\n",
    "citation_emb_type = \"off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:28:53.216420Z",
     "start_time": "2018-12-02T02:28:53.168215Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy(doc):\n",
    "    return doc\n",
    "def read_labeled_file(infile):\n",
    "    LabeledRecords_original = []\n",
    "    with open(infile, 'r', encoding = 'utf8') as f:\n",
    "        for line in f:\n",
    "            read_data = line.split(\"\\t\")\n",
    "            # get ride of bad formated lines\n",
    "            if(len(read_data)==13 or len(read_data)==12):\n",
    "                paper_detail = {\"paperID\": read_data[0], \"authorID\":read_data[1], \n",
    "                                \"co-author\": read_data[5], \"venue_id\": read_data[7],\n",
    "                                \"publish_year\": read_data[10]}\n",
    "                LabeledRecords_original.append(paper_detail)\n",
    "            else:\n",
    "                print(len(read_data))\n",
    "        f.close()\n",
    "    return pd.DataFrame(LabeledRecords_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:28:53.255460Z",
     "start_time": "2018-12-02T02:28:53.220473Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSA(cleaned_token, dim=100):\n",
    "    # Tf-idf Transformation\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True, tokenizer=dummy,\n",
    "                                               preprocessor=dummy, stop_words = None,min_df=cutoff)\n",
    "    tfidfMatrix = tfidf_vectorizer.fit_transform(cleaned_token).toarray()\n",
    "    if(tfidfMatrix.shape[1]<dim):\n",
    "        dim = tfidfMatrix.shape[1] -1\n",
    "    # tf-idf + svd\n",
    "    svd = TruncatedSVD(n_components=dim)\n",
    "    final_lsa_Matrix = svd.fit_transform(tfidfMatrix)\n",
    "    print(svd.explained_variance_ratio_.sum())\n",
    "    return final_lsa_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:28:53.322104Z",
     "start_time": "2018-12-02T02:28:53.259713Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# co-author relation to frequence count\n",
    "def co_author_to_vector(raw_co_author_data, emb_type=\"off\"):\n",
    "    while True:\n",
    "        if emb_type == \"tf\":\n",
    "            co_author_vectorizer = CountVectorizer()\n",
    "            print(co_author_vectorizer)\n",
    "            result_vector = co_author_vectorizer.fit_transform(raw_co_author_data).toarray()\n",
    "            #print(co_author_vectorizer.get_feature_names())\n",
    "            #print(len(co_author_vectorizer.vocabulary_))\n",
    "            break\n",
    "        elif emb_type == \"tf_idf\":\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
    "                                               stop_words = None)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(raw_co_author_data).toarray()\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:29:37.160190Z",
     "start_time": "2018-12-02T02:29:37.133736Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# venue relation with author\n",
    "def venue_to_vector(raw_venue_id, emb_type=\"off\"):\n",
    "    while True:\n",
    "        if emb_type == \"tf\":\n",
    "            venue_count_vectorizer = CountVectorizer()\n",
    "            print(venue_count_vectorizer)\n",
    "            result_vector = venue_count_vectorizer.fit_transform(raw_venue_id).toarray()\n",
    "            #print(len(venue_count_vectorizer.vocabulary_))\n",
    "            break\n",
    "        elif emb_type == \"tf_idf\":\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
    "                                               stop_words = None)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(raw_venue_id).toarray()\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:29:37.291532Z",
     "start_time": "2018-12-02T02:29:37.267355Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# author-year relation to emb\n",
    "def year_to_vector(raw_year, emb_type=\"off\"):\n",
    "    while True:\n",
    "        if emb_type == \"tf\":\n",
    "            count_vectorizer = CountVectorizer()\n",
    "            result_vector = count_vectorizer.fit_transform(raw_year).toarray()\n",
    "            #print(len(count_vectorizer.vocabulary_))\n",
    "            break\n",
    "        elif emb_type == \"tf_idf\":\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
    "                                               stop_words = None)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(raw_year).toarray()\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"tf\"\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:28:54.431531Z",
     "start_time": "2018-12-02T02:28:54.371665Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# document relation wrt textual content\n",
    "# convert raw text to numerical feature vectors\n",
    "# bow(Bags of words) are used with uni-gram setting\n",
    "def raw_text_to_vector(raw_textual_content, emb_type=\"off\", stopword=True):\n",
    "    cleaned_token, sample_size= com_func.clean_batch_of_raw(raw_textual_content, stopword=stopword)\n",
    "    average_sample_size = sum(sample_size)/len(sample_size)\n",
    "    print(\"Minimal sample size: \", min(sample_size))\n",
    "    print(\"maximal sample size: \", max(sample_size))\n",
    "    while True:\n",
    "        if emb_type == \"tf_idf\":\n",
    "            # using tf-idf\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True, tokenizer=dummy,\n",
    "                                               preprocessor=dummy, stop_words = None,min_df=cutoff)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(cleaned_token).toarray()\n",
    "            #print(len(tfidf_vectorizer.vocabulary_))\n",
    "            #print(tfidf_vectorizer.get_feature_names())\n",
    "            break\n",
    "        elif emb_type == \"tf\":\n",
    "            # Document-Term frequence Matrix\n",
    "            count_vectorizer = CountVectorizer(tokenizer=dummy,preprocessor=dummy, min_df=cutoff)\n",
    "            result_vector = count_vectorizer.fit_transform(cleaned_token).toarray()\n",
    "            break\n",
    "        elif emb_type == \"lsa\":\n",
    "            # use lsa\n",
    "            result_vector = LSA(cleaned_token, dim=100)\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return result_vector, average_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:28:54.843421Z",
     "start_time": "2018-12-02T02:28:54.793962Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "# cross validation\n",
    "def k_fold_cv(data, label, clf, k=10):\n",
    "    kf = KFold(n_splits=k, shuffle=False)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data[train_index], data[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        # fit data to clf\n",
    "        clf.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = clf.predict(data_test)\n",
    "        allTrueLabel.extend(label_test)\n",
    "        allPredLabel.extend(label_pred)\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "\n",
    "    accuracy = accuracy_score(allTrueLabel, allPredLabel)\n",
    "    f1 = f1_score(allTrueLabel, allPredLabel,average='macro')\n",
    "    \n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel).ravel())\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:38:01.171142Z",
     "start_time": "2018-12-02T02:32:55.564666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For name:  j_read\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5159-1192': 57, '0000-0002-9029-5185': 39, '0000-0002-9697-0962': 31, '0000-0002-4739-9245': 3, '0000-0003-0605-5259': 3, '0000-0003-4316-7006': 1, '0000-0002-0784-0091': 1, '0000-0002-3888-6631': 1})\n",
      "['0000-0002-9697-0962', '0000-0002-9029-5185', '0000-0002-5159-1192']\n",
      "Total sample size after apply threshold:  127\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 79)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 18)\n",
      "2\n",
      "(127, 97)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.26      0.35        31\n",
      "          1       0.65      0.67      0.66        39\n",
      "          2       0.61      0.77      0.68        57\n",
      "\n",
      "avg / total       0.60      0.61      0.59       127\n",
      "\n",
      "[ 8  5 18  3 26 10  4  9 44]\n",
      "MNB Accuracy:  0.6141732283464567\n",
      "MNB F1:  0.5627414925644821\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.42      0.46        31\n",
      "          1       0.90      0.67      0.76        39\n",
      "          2       0.66      0.84      0.74        57\n",
      "\n",
      "avg / total       0.70      0.69      0.68       127\n",
      "\n",
      "[13  1 17  5 26  8  7  2 48]\n",
      "svc Accuracy:  0.6850393700787402\n",
      "svc F1:  0.6558177117000646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.29      0.38        31\n",
      "          1       0.85      0.59      0.70        39\n",
      "          2       0.61      0.89      0.72        57\n",
      "\n",
      "avg / total       0.67      0.65      0.63       127\n",
      "\n",
      "[ 9  2 20  3 23 13  4  2 51]\n",
      "LR Accuracy:  0.6535433070866141\n",
      "LR F1:  0.6011175585643671\n",
      "For name:  f_esteves\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-3046-1313': 18, '0000-0002-5403-0091': 12, '0000-0003-0589-0746': 3, '0000-0003-3172-6253': 1})\n",
      "['0000-0002-5403-0091', '0000-0002-3046-1313']\n",
      "Total sample size after apply threshold:  30\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(30, 24)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(30, 15)\n",
      "2\n",
      "(30, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.42      0.53        12\n",
      "          1       0.70      0.89      0.78        18\n",
      "\n",
      "avg / total       0.70      0.70      0.68        30\n",
      "\n",
      "[ 5  7  2 16]\n",
      "MNB Accuracy:  0.7\n",
      "MNB F1:  0.6534017971758665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.58      0.64        12\n",
      "          1       0.75      0.83      0.79        18\n",
      "\n",
      "avg / total       0.73      0.73      0.73        30\n",
      "\n",
      "[ 7  5  3 15]\n",
      "svc Accuracy:  0.7333333333333333\n",
      "svc F1:  0.7129186602870814\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.42      0.53        12\n",
      "          1       0.70      0.89      0.78        18\n",
      "\n",
      "avg / total       0.70      0.70      0.68        30\n",
      "\n",
      "[ 5  7  2 16]\n",
      "LR Accuracy:  0.7\n",
      "LR F1:  0.6534017971758665\n",
      "For name:  c_miller\n",
      "total sample size before apply threshold:  252\n",
      "Counter({'0000-0003-4341-1283': 51, '0000-0002-3989-7973': 40, '0000-0002-3813-1706': 39, '0000-0003-2772-9531': 27, '0000-0001-6082-9273': 22, '0000-0002-2601-4422': 22, '0000-0002-9448-8144': 19, '0000-0001-8628-4902': 15, '0000-0002-2936-7717': 6, '0000-0003-3898-9734': 6, '0000-0002-5074-6914': 2, '0000-0003-4266-6700': 1, '0000-0002-9286-9787': 1, '0000-0002-0821-0892': 1})\n",
      "['0000-0003-4341-1283', '0000-0002-9448-8144', '0000-0003-2772-9531', '0000-0001-6082-9273', '0000-0002-3813-1706', '0000-0001-8628-4902', '0000-0002-3989-7973', '0000-0002-2601-4422']\n",
      "Total sample size after apply threshold:  235\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(235, 97)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(235, 29)\n",
      "2\n",
      "(235, 126)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.82      0.57        51\n",
      "          1       0.00      0.00      0.00        19\n",
      "          2       0.94      0.56      0.70        27\n",
      "          3       1.00      0.55      0.71        22\n",
      "          4       0.77      0.92      0.84        39\n",
      "          5       1.00      0.07      0.12        15\n",
      "          6       0.62      0.75      0.68        40\n",
      "          7       1.00      0.59      0.74        22\n",
      "\n",
      "avg / total       0.69      0.63      0.60       235\n",
      "\n",
      "[42  1  1  0  3  0  4  0 13  0  0  0  1  0  5  0  9  0 15  0  1  0  2  0\n",
      "  6  0  0 12  3  0  1  0  3  0  0  0 36  0  0  0 12  0  0  0  1  1  1  0\n",
      "  9  0  0  0  1  0 30  0  3  0  0  0  1  0  5 13]\n",
      "MNB Accuracy:  0.6340425531914894\n",
      "MNB F1:  0.5447511207642877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.88      0.61        51\n",
      "          1       0.62      0.26      0.37        19\n",
      "          2       0.95      0.67      0.78        27\n",
      "          3       1.00      0.77      0.87        22\n",
      "          4       1.00      0.92      0.96        39\n",
      "          5       0.83      0.33      0.48        15\n",
      "          6       0.86      0.80      0.83        40\n",
      "          7       1.00      0.73      0.84        22\n",
      "\n",
      "avg / total       0.81      0.74      0.74       235\n",
      "\n",
      "[45  3  1  0  0  1  1  0 13  5  0  0  0  0  1  0  8  0 18  0  0  0  1  0\n",
      "  5  0  0 17  0  0  0  0  3  0  0  0 36  0  0  0  9  0  0  0  0  5  1  0\n",
      "  8  0  0  0  0  0 32  0  5  0  0  0  0  0  1 16]\n",
      "svc Accuracy:  0.7404255319148936\n",
      "svc F1:  0.7183104257867252\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.86      0.59        51\n",
      "          1       0.50      0.05      0.10        19\n",
      "          2       0.90      0.67      0.77        27\n",
      "          3       0.94      0.68      0.79        22\n",
      "          4       0.97      0.90      0.93        39\n",
      "          5       1.00      0.20      0.33        15\n",
      "          6       0.72      0.78      0.75        40\n",
      "          7       1.00      0.73      0.84        22\n",
      "\n",
      "avg / total       0.77      0.69      0.68       235\n",
      "\n",
      "[44  1  2  1  1  0  2  0 13  1  0  0  0  0  5  0  8  0 18  0  0  0  1  0\n",
      "  7  0  0 15  0  0  0  0  4  0  0  0 35  0  0  0 11  0  0  0  0  3  1  0\n",
      "  9  0  0  0  0  0 31  0  3  0  0  0  0  0  3 16]\n",
      "LR Accuracy:  0.6936170212765957\n",
      "LR F1:  0.6366369718194487\n",
      "For name:  r_jha\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0002-2891-8353': 6, '0000-0003-0332-2542': 3, '0000-0003-1877-1973': 1, '0000-0002-7755-7443': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  a_lowe\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0002-4691-8162': 69, '0000-0001-6650-7486': 22, '0000-0002-0558-3597': 10, '0000-0003-1139-2516': 1})\n",
      "['0000-0002-0558-3597', '0000-0002-4691-8162', '0000-0001-6650-7486']\n",
      "Total sample size after apply threshold:  101\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 55)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 16)\n",
      "2\n",
      "(101, 71)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.74      0.99      0.84        69\n",
      "          2       0.62      0.23      0.33        22\n",
      "\n",
      "avg / total       0.64      0.72      0.65       101\n",
      "\n",
      "[ 0  8  2  0 68  1  1 16  5]\n",
      "MNB Accuracy:  0.7227722772277227\n",
      "MNB F1:  0.39268461007591443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.81      1.00      0.90        69\n",
      "          2       0.93      0.59      0.72        22\n",
      "\n",
      "avg / total       0.76      0.81      0.77       101\n",
      "\n",
      "[ 0  9  1  0 69  0  2  7 13]\n",
      "svc Accuracy:  0.8118811881188119\n",
      "svc F1:  0.5394420394420395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.73      1.00      0.84        69\n",
      "          2       1.00      0.27      0.43        22\n",
      "\n",
      "avg / total       0.71      0.74      0.67       101\n",
      "\n",
      "[ 0 10  0  0 69  0  0 16  6]\n",
      "LR Accuracy:  0.7425742574257426\n",
      "LR F1:  0.4233449477351916\n",
      "For name:  a_vega\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-8207-9925': 10, '0000-0002-2178-2780': 8, '0000-0002-8148-5702': 1, '0000-0003-1082-0961': 1})\n",
      "['0000-0002-8207-9925']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  k_smith\n",
      "total sample size before apply threshold:  338\n",
      "Counter({'0000-0002-6736-4779': 133, '0000-0001-8088-566X': 75, '0000-0002-1323-627X': 29, '0000-0002-8914-6457': 23, '0000-0001-6828-7480': 19, '0000-0001-8150-5702': 15, '0000-0003-2793-3460': 14, '0000-0002-4530-6914': 13, '0000-0003-2802-4939': 8, '0000-0002-0932-1412': 4, '0000-0002-2424-6254': 1, '0000-0001-6957-5361': 1, '0000-0002-7807-2472': 1, '0000-0002-0346-2820': 1, '0000-0003-2060-9369': 1})\n",
      "['0000-0001-8150-5702', '0000-0002-1323-627X', '0000-0002-4530-6914', '0000-0002-6736-4779', '0000-0003-2793-3460', '0000-0002-8914-6457', '0000-0001-8088-566X', '0000-0001-6828-7480']\n",
      "Total sample size after apply threshold:  321\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(321, 155)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(321, 40)\n",
      "2\n",
      "(321, 195)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        15\n",
      "          1       0.69      0.76      0.72        29\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.84      0.95      0.89       133\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       1.00      0.26      0.41        23\n",
      "          6       0.54      0.92      0.68        75\n",
      "          7       1.00      0.16      0.27        19\n",
      "\n",
      "avg / total       0.67      0.71      0.64       321\n",
      "\n",
      "[  0   4   0   1   0   0  10   0   0  22   0   3   0   0   4   0   0   1\n",
      "   0   4   0   0   8   0   0   3   0 127   0   0   3   0   0   0   0   2\n",
      "   0   0  12   0   0   1   0   5   0   6  11   0   0   1   0   5   0   0\n",
      "  69   0   0   0   0   5   0   0  11   3]\n",
      "MNB Accuracy:  0.7071651090342679\n",
      "MNB F1:  0.372357859678231\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        15\n",
      "          1       0.57      0.79      0.67        29\n",
      "          2       0.67      0.15      0.25        13\n",
      "          3       0.97      0.92      0.95       133\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       1.00      0.48      0.65        23\n",
      "          6       0.59      0.95      0.72        75\n",
      "          7       1.00      0.74      0.85        19\n",
      "\n",
      "avg / total       0.79      0.78      0.75       321\n",
      "\n",
      "[  5   2   0   0   0   0   8   0   0  23   0   0   0   0   6   0   0   4\n",
      "   2   1   0   0   6   0   0   4   0 123   0   0   6   0   0   1   0   1\n",
      "   0   0  12   0   0   5   0   0   0  11   7   0   0   1   1   2   0   0\n",
      "  71   0   0   0   0   0   0   0   5  14]\n",
      "svc Accuracy:  0.7757009345794392\n",
      "svc F1:  0.5728567475941426\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.12        15\n",
      "          1       0.66      0.66      0.66        29\n",
      "          2       1.00      0.15      0.27        13\n",
      "          3       0.82      0.96      0.89       133\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       1.00      0.26      0.41        23\n",
      "          6       0.56      0.88      0.68        75\n",
      "          7       1.00      0.47      0.64        19\n",
      "\n",
      "avg / total       0.75      0.72      0.67       321\n",
      "\n",
      "[  1   4   0   0   0   0  10   0   0  19   0   6   0   0   4   0   0   2\n",
      "   2   3   0   0   6   0   0   2   0 128   0   0   3   0   0   0   0   2\n",
      "   0   0  12   0   0   2   0   5   0   6  10   0   0   0   0   9   0   0\n",
      "  66   0   0   0   0   3   0   0   7   9]\n",
      "LR Accuracy:  0.719626168224299\n",
      "LR F1:  0.45915503742353914\n",
      "For name:  j_gordon\n",
      "total sample size before apply threshold:  19\n",
      "Counter({'0000-0002-0061-2168': 12, '0000-0001-9494-0586': 4, '0000-0001-7811-9245': 2, '0000-0002-5911-4219': 1})\n",
      "['0000-0002-0061-2168']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  s_liao\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0003-4129-0879': 46, '0000-0002-4312-5351': 43, '0000-0003-0943-0667': 10, '0000-0002-3122-8249': 2, '0000-0002-2372-9502': 1, '0000-0002-8872-2117': 1, '0000-0002-7339-2768': 1})\n",
      "['0000-0003-0943-0667', '0000-0003-4129-0879', '0000-0002-4312-5351']\n",
      "Total sample size after apply threshold:  99\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(99, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(99, 16)\n",
      "2\n",
      "(99, 64)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.69      0.78      0.73        46\n",
      "          2       0.74      0.81      0.78        43\n",
      "\n",
      "avg / total       0.65      0.72      0.68        99\n",
      "\n",
      "[ 0  8  2  0 36 10  0  8 35]\n",
      "MNB Accuracy:  0.7171717171717171\n",
      "MNB F1:  0.5041572184429327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.65      0.87      0.74        46\n",
      "          2       0.89      0.72      0.79        43\n",
      "\n",
      "avg / total       0.68      0.72      0.69        99\n",
      "\n",
      "[ 0 10  0  2 40  4  0 12 31]\n",
      "svc Accuracy:  0.7171717171717171\n",
      "svc F1:  0.5118708452041786\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.64      0.83      0.72        46\n",
      "          2       0.78      0.72      0.75        43\n",
      "\n",
      "avg / total       0.64      0.70      0.66        99\n",
      "\n",
      "[ 0  9  1  0 38  8  0 12 31]\n",
      "LR Accuracy:  0.696969696969697\n",
      "LR F1:  0.49026582520558426\n",
      "For name:  j_qian\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-8793-9330': 6, '0000-0001-6145-045X': 6, '0000-0003-3162-2913': 1, '0000-0002-9522-6445': 1, '0000-0002-1325-6975': 1, '0000-0002-5438-0833': 1, '0000-0001-5043-020X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_bernardi\n",
      "total sample size before apply threshold:  91\n",
      "Counter({'0000-0001-5672-0881': 38, '0000-0002-7429-3075': 30, '0000-0002-1050-3096': 17, '0000-0001-6130-8533': 6})\n",
      "['0000-0002-7429-3075', '0000-0001-5672-0881', '0000-0002-1050-3096']\n",
      "Total sample size after apply threshold:  85\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 63)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 25)\n",
      "2\n",
      "(85, 88)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.77      0.73        30\n",
      "          1       0.65      0.79      0.71        38\n",
      "          2       1.00      0.35      0.52        17\n",
      "\n",
      "avg / total       0.74      0.69      0.68        85\n",
      "\n",
      "[23  7  0  8 30  0  2  9  6]\n",
      "MNB Accuracy:  0.6941176470588235\n",
      "MNB F1:  0.6553945249597425\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70        30\n",
      "          1       0.62      0.74      0.67        38\n",
      "          2       0.80      0.47      0.59        17\n",
      "\n",
      "avg / total       0.69      0.67      0.67        85\n",
      "\n",
      "[21  9  0  8 28  2  1  8  8]\n",
      "svc Accuracy:  0.6705882352941176\n",
      "svc F1:  0.6557637959244386\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.77      0.73        30\n",
      "          1       0.59      0.79      0.67        38\n",
      "          2       1.00      0.06      0.11        17\n",
      "\n",
      "avg / total       0.71      0.64      0.58        85\n",
      "\n",
      "[23  7  0  8 30  0  2 14  1]\n",
      "LR Accuracy:  0.6352941176470588\n",
      "LR F1:  0.505142381546876\n",
      "For name:  t_hill\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0003-4159-9104': 7, '0000-0001-6996-9475': 3, '0000-0002-4125-7895': 2, '0000-0003-2980-4099': 2, '0000-0002-7995-9315': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_schindler\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-9991-9513': 26, '0000-0002-7054-5431': 13, '0000-0003-1028-3115': 6, '0000-0003-1378-0053': 5, '0000-0002-1755-4304': 1})\n",
      "['0000-0002-7054-5431', '0000-0002-9991-9513']\n",
      "Total sample size after apply threshold:  39\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 17)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 18)\n",
      "2\n",
      "(39, 35)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.96      1.00      0.98        26\n",
      "\n",
      "avg / total       0.98      0.97      0.97        39\n",
      "\n",
      "[12  1  0 26]\n",
      "MNB Accuracy:  0.9743589743589743\n",
      "MNB F1:  0.9705660377358492\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.96      1.00      0.98        26\n",
      "\n",
      "avg / total       0.98      0.97      0.97        39\n",
      "\n",
      "[12  1  0 26]\n",
      "svc Accuracy:  0.9743589743589743\n",
      "svc F1:  0.9705660377358492\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.96      1.00      0.98        26\n",
      "\n",
      "avg / total       0.98      0.97      0.97        39\n",
      "\n",
      "[12  1  0 26]\n",
      "LR Accuracy:  0.9743589743589743\n",
      "LR F1:  0.9705660377358492\n",
      "For name:  j_williams\n",
      "total sample size before apply threshold:  625\n",
      "Counter({'0000-0001-5188-7957': 141, '0000-0002-6063-7615': 82, '0000-0001-6665-6596': 79, '0000-0002-4688-3000': 66, '0000-0001-7152-765X': 51, '0000-0001-8251-4176': 28, '0000-0003-1235-5186': 26, '0000-0002-8883-7838': 25, '0000-0001-8331-3181': 20, '0000-0001-8377-5175': 15, '0000-0002-8861-0596': 14, '0000-0002-3804-2594': 14, '0000-0003-3815-0891': 14, '0000-0002-4497-4961': 10, '0000-0002-9801-9580': 9, '0000-0003-4400-5180': 5, '0000-0002-3500-914X': 5, '0000-0002-0195-6771': 4, '0000-0001-6105-0296': 3, '0000-0002-4681-3360': 3, '0000-0003-0161-0532': 3, '0000-0002-6511-1284': 3, '0000-0002-0195-5509': 2, '0000-0003-0500-1961': 2, '0000-0002-5355-3210': 1})\n",
      "['0000-0003-1235-5186', '0000-0002-8861-0596', '0000-0001-7152-765X', '0000-0001-6665-6596', '0000-0002-4497-4961', '0000-0002-6063-7615', '0000-0001-5188-7957', '0000-0002-3804-2594', '0000-0002-8883-7838', '0000-0001-8251-4176', '0000-0003-3815-0891', '0000-0001-8331-3181', '0000-0002-4688-3000', '0000-0001-8377-5175']\n",
      "Total sample size after apply threshold:  585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(585, 240)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(585, 35)\n",
      "2\n",
      "(585, 275)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.12      0.20        26\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.65      0.59      0.62        51\n",
      "          3       0.58      0.81      0.68        79\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.83      0.82      0.82        82\n",
      "          6       0.50      0.95      0.66       141\n",
      "          7       0.00      0.00      0.00        14\n",
      "          8       0.00      0.00      0.00        25\n",
      "          9       1.00      0.07      0.13        28\n",
      "         10       0.00      0.00      0.00        14\n",
      "         11       1.00      0.30      0.46        20\n",
      "         12       0.74      0.77      0.76        66\n",
      "         13       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.57      0.61      0.54       585\n",
      "\n",
      "[  3   0   2   8   0   2   8   0   0   0   0   0   3   0   0   0   4   5\n",
      "   0   0   3   0   0   0   0   0   2   0   0   0  30   4   0   0  15   0\n",
      "   0   0   0   0   2   0   0   0   0  64   0   0  13   0   0   0   0   0\n",
      "   2   0   0   0   1   1   0   0   6   0   0   0   0   0   2   0   0   0\n",
      "   1   1   0  67  13   0   0   0   0   0   0   0   0   0   0   5   0   2\n",
      " 134   0   0   0   0   0   0   0   0   0   2   2   0   0  10   0   0   0\n",
      "   0   0   0   0   0   0   0   2   0   3  19   0   0   0   0   0   1   0\n",
      "   0   0   2   3   0   2  18   0   0   2   0   0   1   0   0   0   2   3\n",
      "   0   2   3   0   0   0   0   0   4   0   1   0   2   6   0   0   4   0\n",
      "   0   0   0   6   1   0   0   0   0   3   0   3   9   0   0   0   0   0\n",
      "  51   0   0   0   0   3   0   0  12   0   0   0   0   0   0   0]\n",
      "MNB Accuracy:  0.6102564102564103\n",
      "MNB F1:  0.3089415259553962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.46      0.62        26\n",
      "          1       0.14      0.07      0.10        14\n",
      "          2       0.52      0.67      0.59        51\n",
      "          3       0.80      0.82      0.81        79\n",
      "          4       1.00      0.30      0.46        10\n",
      "          5       0.92      0.82      0.86        82\n",
      "          6       0.56      0.96      0.70       141\n",
      "          7       1.00      0.21      0.35        14\n",
      "          8       0.78      0.28      0.41        25\n",
      "          9       0.94      0.54      0.68        28\n",
      "         10       1.00      0.07      0.13        14\n",
      "         11       1.00      0.60      0.75        20\n",
      "         12       0.96      0.76      0.85        66\n",
      "         13       1.00      0.47      0.64        15\n",
      "\n",
      "avg / total       0.77      0.70      0.69       585\n",
      "\n",
      "[ 12   0   4   2   0   0   8   0   0   0   0   0   0   0   0   1   5   3\n",
      "   0   0   5   0   0   0   0   0   0   0   0   0  34   3   0   0  14   0\n",
      "   0   0   0   0   0   0   0   1   3  65   0   0  10   0   0   0   0   0\n",
      "   0   0   0   0   3   0   3   0   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  67  15   0   0   0   0   0   0   0   0   0   1   3   0   2\n",
      " 135   0   0   0   0   0   0   0   0   0   4   1   0   0   6   3   0   0\n",
      "   0   0   0   0   0   0   1   0   0   2  14   0   7   0   0   0   1   0\n",
      "   0   2   0   0   0   0  10   0   0  15   0   0   1   0   0   1   4   2\n",
      "   0   0   6   0   0   0   1   0   0   0   1   1   2   1   0   0   3   0\n",
      "   0   0   0  12   0   0   0   0   2   1   0   2   9   0   2   0   0   0\n",
      "  50   0   0   1   2   0   0   0   4   0   0   1   0   0   0   7]\n",
      "svc Accuracy:  0.7042735042735043\n",
      "svc F1:  0.5680134184808495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.35      0.50        26\n",
      "          1       0.33      0.07      0.12        14\n",
      "          2       0.54      0.69      0.60        51\n",
      "          3       0.62      0.82      0.71        79\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.78      0.84      0.81        82\n",
      "          6       0.55      0.94      0.70       141\n",
      "          7       0.00      0.00      0.00        14\n",
      "          8       0.00      0.00      0.00        25\n",
      "          9       1.00      0.18      0.30        28\n",
      "         10       0.50      0.07      0.12        14\n",
      "         11       0.92      0.55      0.69        20\n",
      "         12       0.98      0.74      0.84        66\n",
      "         13       1.00      0.33      0.50        15\n",
      "\n",
      "avg / total       0.65      0.65      0.60       585\n",
      "\n",
      "[  9   0   4   4   0   2   7   0   0   0   0   0   0   0   0   1   6   5\n",
      "   0   0   2   0   0   0   0   0   0   0   0   0  35   4   0   1  11   0\n",
      "   0   0   0   0   0   0   0   1   3  65   0   2   8   0   0   0   0   0\n",
      "   0   0   0   0   2   2   0   1   5   0   0   0   0   0   0   0   0   0\n",
      "   1   0   0  69  12   0   0   0   0   0   0   0   0   0   1   4   0   2\n",
      " 133   0   0   0   1   0   0   0   0   0   3   2   0   0   9   0   0   0\n",
      "   0   0   0   0   0   0   2   2   0   3  17   0   0   0   0   0   1   0\n",
      "   0   0   3   3   0   2  15   0   0   5   0   0   0   0   0   0   2   3\n",
      "   0   4   3   0   0   0   1   1   0   0   1   1   1   4   0   0   2   0\n",
      "   0   0   0  11   0   0   0   0   2   3   0   3   9   0   0   0   0   0\n",
      "  49   0   0   0   0   3   0   0   7   0   0   0   0   0   0   5]\n",
      "LR Accuracy:  0.6547008547008547\n",
      "LR F1:  0.42121542936446016\n",
      "For name:  s_jacobson\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-9042-8750': 20, '0000-0002-3955-5746': 4, '0000-0002-4952-9007': 3, '0000-0001-9937-419X': 1})\n",
      "['0000-0002-9042-8750']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  e_andrade\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-1941-580X': 7, '0000-0001-7080-7035': 5, '0000-0003-2016-8305': 4, '0000-0002-5030-1675': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_santos\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0002-5365-4863': 18, '0000-0003-3765-5863': 14, '0000-0001-9072-5010': 3, '0000-0001-9947-6022': 2, '0000-0002-7694-306X': 2, '0000-0003-4171-5806': 1, '0000-0002-9744-0410': 1, '0000-0002-5325-3090': 1, '0000-0003-4620-0174': 1, '0000-0002-5738-4995': 1, '0000-0001-6892-0354': 1})\n",
      "['0000-0003-3765-5863', '0000-0002-5365-4863']\n",
      "Total sample size after apply threshold:  32\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 13)\n",
      "2\n",
      "(32, 35)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.43      0.57        14\n",
      "          1       0.68      0.94      0.79        18\n",
      "\n",
      "avg / total       0.76      0.72      0.69        32\n",
      "\n",
      "[ 6  8  1 17]\n",
      "MNB Accuracy:  0.71875\n",
      "MNB F1:  0.6810631229235881\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.71      0.74        14\n",
      "          1       0.79      0.83      0.81        18\n",
      "\n",
      "avg / total       0.78      0.78      0.78        32\n",
      "\n",
      "[10  4  3 15]\n",
      "svc Accuracy:  0.78125\n",
      "svc F1:  0.7757757757757758\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.64      0.72        14\n",
      "          1       0.76      0.89      0.82        18\n",
      "\n",
      "avg / total       0.79      0.78      0.78        32\n",
      "\n",
      "[ 9  5  2 16]\n",
      "LR Accuracy:  0.78125\n",
      "LR F1:  0.7702564102564102\n",
      "For name:  k_kim\n",
      "total sample size before apply threshold:  1111\n",
      "Counter({'0000-0002-6929-5359': 211, '0000-0001-9498-284X': 154, '0000-0002-5878-8895': 139, '0000-0002-1864-3392': 92, '0000-0002-7045-8004': 57, '0000-0001-7896-6751': 57, '0000-0002-7991-9428': 55, '0000-0002-4010-1063': 45, '0000-0002-2186-3484': 28, '0000-0002-4899-1929': 25, '0000-0003-0487-4242': 24, '0000-0002-3642-1486': 22, '0000-0001-9965-3535': 17, '0000-0002-4168-757X': 17, '0000-0001-6525-3744': 14, '0000-0002-3897-0278': 14, '0000-0002-1181-5112': 12, '0000-0003-1447-9385': 11, '0000-0002-7305-8786': 11, '0000-0002-2655-7806': 10, '0000-0003-3466-5353': 9, '0000-0002-7359-663X': 8, '0000-0003-4600-8668': 6, '0000-0002-1382-7088': 5, '0000-0002-9505-4882': 5, '0000-0003-3667-9900': 4, '0000-0001-9714-6038': 4, '0000-0002-4760-0228': 3, '0000-0003-4188-7915': 3, '0000-0001-9454-0427': 3, '0000-0002-0333-6808': 3, '0000-0003-2134-4964': 3, '0000-0002-6658-047X': 3, '0000-0003-1273-379X': 3, '0000-0002-7047-3183': 3, '0000-0002-1814-9546': 3, '0000-0003-4812-6297': 2, '0000-0001-6597-578X': 2, '0000-0002-5285-9138': 2, '0000-0002-6796-7844': 2, '0000-0002-1130-8698': 2, '0000-0001-8518-8150': 2, '0000-0002-7103-924X': 2, '0000-0002-5407-0202': 1, '0000-0001-6220-8411': 1, '0000-0002-7440-6703': 1, '0000-0002-1603-7559': 1, '0000-0003-0257-1707': 1, '0000-0001-8532-6517': 1, '0000-0001-6626-316X': 1, '0000-0002-3246-9861': 1, '0000-0002-7207-4389': 1, '0000-0001-9682-9654': 1, '0000-0002-0196-3832': 1, '0000-0001-8063-6081': 1, '0000-0003-2037-3333': 1, '0000-0001-8872-6751': 1})\n",
      "['0000-0003-1447-9385', '0000-0001-6525-3744', '0000-0001-9498-284X', '0000-0002-3642-1486', '0000-0001-9965-3535', '0000-0002-7305-8786', '0000-0002-4899-1929', '0000-0002-6929-5359', '0000-0002-7045-8004', '0000-0002-2186-3484', '0000-0002-5878-8895', '0000-0002-4010-1063', '0000-0003-0487-4242', '0000-0001-7896-6751', '0000-0002-3897-0278', '0000-0002-7991-9428', '0000-0002-1864-3392', '0000-0002-4168-757X', '0000-0002-2655-7806', '0000-0002-1181-5112']\n",
      "Total sample size after apply threshold:  1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(1015, 331)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(1015, 22)\n",
      "2\n",
      "(1015, 353)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.53      0.77      0.63       154\n",
      "          3       0.00      0.00      0.00        22\n",
      "          4       1.00      0.29      0.45        17\n",
      "          5       0.00      0.00      0.00        11\n",
      "          6       0.00      0.00      0.00        25\n",
      "          7       0.43      0.98      0.60       211\n",
      "          8       0.91      0.51      0.65        57\n",
      "          9       0.64      0.25      0.36        28\n",
      "         10       0.79      0.77      0.78       139\n",
      "         11       1.00      0.11      0.20        45\n",
      "         12       0.75      0.12      0.21        24\n",
      "         13       0.95      0.32      0.47        57\n",
      "         14       0.00      0.00      0.00        14\n",
      "         15       0.73      0.40      0.52        55\n",
      "         16       0.84      0.70      0.76        92\n",
      "         17       0.00      0.00      0.00        17\n",
      "         18       0.00      0.00      0.00        10\n",
      "         19       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.60      0.58      0.52      1015\n",
      "\n",
      "[  0   0   2   0   0   0   0   5   0   4   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   3   0   0   0   0   9   0   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   0 119   0   0   0   0  23   0   0  11   0   0   1\n",
      "   0   0   0   0   0   0   0   0   7   0   0   0   0   5   0   0   0   0\n",
      "   1   0   0   0   9   0   0   0   0   0   4   0   5   0   0   8   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  11\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0\n",
      "   0  17   3   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0\n",
      "   0   0   0 206   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "   6   0   0   0   0  21  29   0   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   3   0   0   0   0  14   0   7   4   0   0   0   0   0   0   0\n",
      "   0   0   0   0  17   0   0   0   0  15   0   0 107   0   0   0   0   0\n",
      "   0   0   0   0   0   0   5   0   0   0   0  33   0   0   2   5   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0   0   0   0\n",
      "   3   0   0   0   1   0   0   0   0   0  15   0   0   0   0  21   0   0\n",
      "   3   0   0  18   0   0   0   0   0   0   0   0   2   0   0   0   0   3\n",
      "   0   0   1   0   0   0   0   8   0   0   0   0   0   0  14   0   0   0\n",
      "   0  19   0   0   0   0   0   0   0  22   0   0   0   0   0   0  11   0\n",
      "   0   0   0  14   0   0   3   0   0   0   0   0  64   0   0   0   0   0\n",
      "   2   0   0   0   0  14   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   0   0   8   0   0   0   0   0   0   0   0   1   0\n",
      "   0   0   0   0   4   0   0   0   0   8   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "MNB Accuracy:  0.5763546798029556\n",
      "MNB F1:  0.28224191668865045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       0.39      0.86      0.54       154\n",
      "          3       0.36      0.18      0.24        22\n",
      "          4       1.00      0.82      0.90        17\n",
      "          5       0.43      0.27      0.33        11\n",
      "          6       0.64      0.28      0.39        25\n",
      "          7       0.94      0.90      0.92       211\n",
      "          8       0.92      0.61      0.74        57\n",
      "          9       0.80      0.71      0.75        28\n",
      "         10       0.80      0.74      0.77       139\n",
      "         11       1.00      0.58      0.73        45\n",
      "         12       0.42      0.46      0.44        24\n",
      "         13       0.86      0.56      0.68        57\n",
      "         14       0.00      0.00      0.00        14\n",
      "         15       0.65      0.56      0.60        55\n",
      "         16       0.83      0.77      0.80        92\n",
      "         17       1.00      0.12      0.21        17\n",
      "         18       0.71      0.50      0.59        10\n",
      "         19       1.00      0.17      0.29        12\n",
      "\n",
      "avg / total       0.74      0.68      0.68      1015\n",
      "\n",
      "[  0   0   5   0   0   0   0   0   0   5   0   0   1   0   0   0   0   0\n",
      "   0   0   0   6   2   0   0   0   0   0   0   0   4   0   2   0   0   0\n",
      "   0   0   0   0   0   0 132   0   0   0   1   0   0   0  12   0   3   3\n",
      "   0   3   0   0   0   0   0   0   6   4   0   0   0   0   0   0   1   0\n",
      "   1   0   0   0  10   0   0   0   0   0   3   0  14   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   8\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13   0   0   0\n",
      "   7   0   3   0   1   0   1   0   0   0   0   0   0   0   0   0  14   0\n",
      "   0   4   0 190   0   0   0   0   2   0   0   0   1   0   0   0   0   0\n",
      "  17   0   0   0   3   0  35   0   2   0   0   0   0   0   0   0   0   0\n",
      "   0   0   7   0   0   0   0   0   0  20   0   0   1   0   0   0   0   0\n",
      "   0   0   0   0  34   0   0   0   0   0   0   0 103   0   0   1   0   1\n",
      "   0   0   0   0   0   0  17   0   0   0   0   0   0   0   2  26   0   0\n",
      "   0   0   0   0   0   0   0   0   5   2   0   0   0   3   0   0   0   0\n",
      "  11   0   0   0   2   0   1   0   0   0  21   0   0   0   0   0   0   0\n",
      "   2   0   1  32   0   1   0   0   0   0   0   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  12   0   0   0   0   0   0  21   0   0   0\n",
      "   0   0   0   0   1   0   0   1   1  31   0   0   0   0   0   0  14   5\n",
      "   0   0   0   0   0   0   0   0   1   0   0   0  71   0   1   0   0   0\n",
      "  12   0   0   0   0   2   0   0   1   0   0   0   0   0   0   2   0   0\n",
      "   0   0   2   0   0   0   0   0   0   0   0   0   1   0   0   0   2   0\n",
      "   5   0   0   0   9   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "   0   0   0   2]\n",
      "svc Accuracy:  0.683743842364532\n",
      "svc F1:  0.5261076931230263\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.07      0.13        14\n",
      "          2       0.49      0.80      0.61       154\n",
      "          3       0.00      0.00      0.00        22\n",
      "          4       1.00      0.82      0.90        17\n",
      "          5       0.00      0.00      0.00        11\n",
      "          6       0.71      0.20      0.31        25\n",
      "          7       0.66      0.94      0.78       211\n",
      "          8       0.92      0.58      0.71        57\n",
      "          9       0.75      0.54      0.63        28\n",
      "         10       0.70      0.81      0.75       139\n",
      "         11       1.00      0.62      0.77        45\n",
      "         12       0.36      0.38      0.37        24\n",
      "         13       0.83      0.53      0.65        57\n",
      "         14       0.00      0.00      0.00        14\n",
      "         15       0.66      0.49      0.56        55\n",
      "         16       0.81      0.70      0.75        92\n",
      "         17       1.00      0.12      0.21        17\n",
      "         18       0.75      0.30      0.43        10\n",
      "         19       1.00      0.17      0.29        12\n",
      "\n",
      "avg / total       0.67      0.66      0.63      1015\n",
      "\n",
      "[  0   0   2   0   0   0   0   3   0   5   0   0   1   0   0   0   0   0\n",
      "   0   0   0   1   1   0   0   0   0   3   0   0   7   0   2   0   0   0\n",
      "   0   0   0   0   0   0 123   0   0   0   0   9   0   0  15   0   3   3\n",
      "   0   1   0   0   0   0   0   0   8   0   0   0   0   2   0   0   2   0\n",
      "   1   0   0   0   9   0   0   0   0   0   2   0  14   0   0   1   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  11\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8   0   0   0\n",
      "   5   6   3   0   1   0   2   0   0   0   0   0   0   0   0   0   8   0\n",
      "   0   1   0 199   0   0   2   0   0   0   0   0   1   0   0   0   0   0\n",
      "   9   0   0   0   2   9  33   0   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0   4   0   0   0   0   4   0  15   4   0   1   0   0   0   0   0\n",
      "   0   0   0   0  16   0   0   0   0   7   0   0 113   0   0   1   0   2\n",
      "   0   0   0   0   0   0   6   0   0   0   0   7   0   0   3  28   1   0\n",
      "   0   0   0   0   0   0   0   0   5   0   0   0   0   6   0   0   0   0\n",
      "   9   0   0   0   3   0   1   0   0   0  17   0   0   0   0   6   0   0\n",
      "   3   0   0  30   0   1   0   0   0   0   0   0   1   0   0   0   0   2\n",
      "   0   0   1   0   0   0   0  10   0   0   0   0   0   0  15   0   0   0\n",
      "   0  10   0   0   2   0   1   0   0  27   0   0   0   0   0   0  14   4\n",
      "   0   0   0   5   0   0   4   0   1   0   0   0  64   0   0   0   0   0\n",
      "   7   0   0   0   0   7   0   0   1   0   0   0   0   0   0   2   0   0\n",
      "   0   0   2   0   0   0   0   1   0   0   0   0   2   0   0   0   2   0\n",
      "   3   0   0   0   4   0   0   0   0   3   0   0   0   0   1   2   0   0\n",
      "   0   0   0   2]\n",
      "LR Accuracy:  0.6581280788177339\n",
      "LR F1:  0.4416651881256759\n",
      "For name:  d_ricci\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0003-0015-6374': 26, '0000-0003-2853-4816': 12, '0000-0001-9678-904X': 1, '0000-0002-9790-0552': 1})\n",
      "['0000-0003-0015-6374', '0000-0003-2853-4816']\n",
      "Total sample size after apply threshold:  38\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 12)\n",
      "2\n",
      "(38, 32)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.92      0.81        26\n",
      "          1       0.60      0.25      0.35        12\n",
      "\n",
      "avg / total       0.69      0.71      0.67        38\n",
      "\n",
      "[24  2  9  3]\n",
      "MNB Accuracy:  0.7105263157894737\n",
      "MNB F1:  0.5832502492522433\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.88      0.84        26\n",
      "          1       0.67      0.50      0.57        12\n",
      "\n",
      "avg / total       0.75      0.76      0.75        38\n",
      "\n",
      "[23  3  6  6]\n",
      "svc Accuracy:  0.7631578947368421\n",
      "svc F1:  0.7038961038961039\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.96      0.82        26\n",
      "          1       0.67      0.17      0.27        12\n",
      "\n",
      "avg / total       0.70      0.71      0.65        38\n",
      "\n",
      "[25  1 10  2]\n",
      "LR Accuracy:  0.7105263157894737\n",
      "LR F1:  0.5431693989071038\n",
      "For name:  s_cameron\n",
      "total sample size before apply threshold:  66\n",
      "Counter({'0000-0002-6694-4130': 41, '0000-0002-3050-7262': 16, '0000-0001-9570-135X': 7, '0000-0001-5680-2641': 2})\n",
      "['0000-0002-6694-4130', '0000-0002-3050-7262']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 24)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 11)\n",
      "2\n",
      "(57, 35)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.88      0.91        41\n",
      "          1       0.74      0.88      0.80        16\n",
      "\n",
      "avg / total       0.89      0.88      0.88        57\n",
      "\n",
      "[36  5  2 14]\n",
      "MNB Accuracy:  0.8771929824561403\n",
      "MNB F1:  0.8556962025316456\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        41\n",
      "          1       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.98      0.98      0.98        57\n",
      "\n",
      "[41  0  1 15]\n",
      "svc Accuracy:  0.9824561403508771\n",
      "svc F1:  0.9778468713563933\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        41\n",
      "          1       1.00      0.50      0.67        16\n",
      "\n",
      "avg / total       0.88      0.86      0.84        57\n",
      "\n",
      "[41  0  8  8]\n",
      "LR Accuracy:  0.8596491228070176\n",
      "LR F1:  0.7888888888888889\n",
      "For name:  t_wright\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-5071-9978': 19, '0000-0002-5813-9991': 6, '0000-0001-8338-5935': 5, '0000-0001-7836-6705': 1})\n",
      "['0000-0001-5071-9978']\n",
      "Total sample size after apply threshold:  19\n",
      "For name:  r_cunha\n",
      "total sample size before apply threshold:  209\n",
      "Counter({'0000-0003-2550-6422': 151, '0000-0002-0203-3143': 24, '0000-0002-0849-3247': 12, '0000-0002-6622-7043': 12, '0000-0003-2228-5492': 8, '0000-0002-2382-7479': 2})\n",
      "['0000-0002-0849-3247', '0000-0002-6622-7043', '0000-0003-2550-6422', '0000-0002-0203-3143']\n",
      "Total sample size after apply threshold:  199\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(199, 92)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(199, 22)\n",
      "2\n",
      "(199, 114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.77      0.99      0.87       151\n",
      "          3       0.33      0.04      0.07        24\n",
      "\n",
      "avg / total       0.68      0.76      0.68       199\n",
      "\n",
      "[  1   0  11   0   0   0  11   1   0   0 150   1   0   0  23   1]\n",
      "MNB Accuracy:  0.7638190954773869\n",
      "MNB F1:  0.27374306276040383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.58      0.67        12\n",
      "          1       1.00      0.33      0.50        12\n",
      "          2       0.83      0.99      0.90       151\n",
      "          3       0.67      0.17      0.27        24\n",
      "\n",
      "avg / total       0.82      0.82      0.79       199\n",
      "\n",
      "[  7   0   5   0   0   4   7   1   1   0 149   1   1   0  19   4]\n",
      "svc Accuracy:  0.8241206030150754\n",
      "svc F1:  0.5834088620342396\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        12\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.78      1.00      0.88       151\n",
      "          3       0.50      0.04      0.08        24\n",
      "\n",
      "avg / total       0.71      0.78      0.70       199\n",
      "\n",
      "[  3   0   9   0   0   0  11   1   0   0 151   0   0   0  23   1]\n",
      "LR Accuracy:  0.7788944723618091\n",
      "LR F1:  0.3380713489409142\n",
      "For name:  s_fuchs\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0002-1338-2699': 18, '0000-0001-9191-7970': 11, '0000-0002-0644-2876': 2, '0000-0001-7261-9214': 1})\n",
      "['0000-0001-9191-7970', '0000-0002-1338-2699']\n",
      "Total sample size after apply threshold:  29\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 18)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 12)\n",
      "2\n",
      "(29, 30)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.55      0.57        11\n",
      "          1       0.74      0.78      0.76        18\n",
      "\n",
      "avg / total       0.68      0.69      0.69        29\n",
      "\n",
      "[ 6  5  4 14]\n",
      "MNB Accuracy:  0.6896551724137931\n",
      "MNB F1:  0.664092664092664\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.89      0.86      0.85        29\n",
      "\n",
      "[ 7  4  0 18]\n",
      "svc Accuracy:  0.8620689655172413\n",
      "svc F1:  0.8388888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       0.75      1.00      0.86        18\n",
      "\n",
      "avg / total       0.84      0.79      0.77        29\n",
      "\n",
      "[ 5  6  0 18]\n",
      "LR Accuracy:  0.7931034482758621\n",
      "LR F1:  0.7410714285714286\n",
      "For name:  m_nawaz\n",
      "total sample size before apply threshold:  9\n",
      "Counter({'0000-0002-0792-8296': 4, '0000-0001-9016-9229': 3, '0000-0003-4249-4259': 1, '0000-0003-3387-484X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  k_harris\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0001-8486-1219': 15, '0000-0002-5930-6456': 10, '0000-0003-1769-2587': 8, '0000-0002-1199-2856': 7, '0000-0003-2162-9652': 3, '0000-0003-0302-2523': 2, '0000-0001-5190-4219': 1, '0000-0003-2806-1262': 1})\n",
      "['0000-0002-5930-6456', '0000-0001-8486-1219']\n",
      "Total sample size after apply threshold:  25\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 16)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 11)\n",
      "2\n",
      "(25, 27)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90        10\n",
      "          1       0.93      0.93      0.93        15\n",
      "\n",
      "avg / total       0.92      0.92      0.92        25\n",
      "\n",
      "[ 9  1  1 14]\n",
      "MNB Accuracy:  0.92\n",
      "MNB F1:  0.9166666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90        10\n",
      "          1       0.93      0.93      0.93        15\n",
      "\n",
      "avg / total       0.92      0.92      0.92        25\n",
      "\n",
      "[ 9  1  1 14]\n",
      "svc Accuracy:  0.92\n",
      "svc F1:  0.9166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.80      0.84        10\n",
      "          1       0.88      0.93      0.90        15\n",
      "\n",
      "avg / total       0.88      0.88      0.88        25\n",
      "\n",
      "[ 8  2  1 14]\n",
      "LR Accuracy:  0.88\n",
      "LR F1:  0.8726655348047538\n",
      "For name:  r_daniel\n",
      "total sample size before apply threshold:  173\n",
      "Counter({'0000-0002-8646-7925': 123, '0000-0002-6483-5897': 37, '0000-0001-8835-8047': 8, '0000-0002-1753-6683': 5})\n",
      "['0000-0002-8646-7925', '0000-0002-6483-5897']\n",
      "Total sample size after apply threshold:  160\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(160, 46)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(160, 21)\n",
      "2\n",
      "(160, 67)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       123\n",
      "          1       1.00      0.81      0.90        37\n",
      "\n",
      "avg / total       0.96      0.96      0.95       160\n",
      "\n",
      "[123   0   7  30]\n",
      "MNB Accuracy:  0.95625\n",
      "MNB F1:  0.933927201934989\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       123\n",
      "          1       1.00      0.81      0.90        37\n",
      "\n",
      "avg / total       0.96      0.96      0.95       160\n",
      "\n",
      "[123   0   7  30]\n",
      "svc Accuracy:  0.95625\n",
      "svc F1:  0.933927201934989\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       123\n",
      "          1       1.00      0.70      0.83        37\n",
      "\n",
      "avg / total       0.94      0.93      0.93       160\n",
      "\n",
      "[123   0  11  26]\n",
      "LR Accuracy:  0.93125\n",
      "LR F1:  0.891297634488296\n",
      "For name:  k_xu\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0002-2788-194X': 19, '0000-0003-2036-3469': 14, '0000-0002-3985-739X': 3, '0000-0001-7851-2629': 1})\n",
      "['0000-0003-2036-3469', '0000-0002-2788-194X']\n",
      "Total sample size after apply threshold:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 11)\n",
      "2\n",
      "(33, 31)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.71      0.77        14\n",
      "          1       0.81      0.89      0.85        19\n",
      "\n",
      "avg / total       0.82      0.82      0.82        33\n",
      "\n",
      "[10  4  2 17]\n",
      "MNB Accuracy:  0.8181818181818182\n",
      "MNB F1:  0.8096153846153846\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.71      0.77        14\n",
      "          1       0.81      0.89      0.85        19\n",
      "\n",
      "avg / total       0.82      0.82      0.82        33\n",
      "\n",
      "[10  4  2 17]\n",
      "svc Accuracy:  0.8181818181818182\n",
      "svc F1:  0.8096153846153846\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.71      0.77        14\n",
      "          1       0.81      0.89      0.85        19\n",
      "\n",
      "avg / total       0.82      0.82      0.82        33\n",
      "\n",
      "[10  4  2 17]\n",
      "LR Accuracy:  0.8181818181818182\n",
      "LR F1:  0.8096153846153846\n",
      "For name:  s_antunes\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-6686-9919': 35, '0000-0002-5512-9093': 12, '0000-0003-3218-3924': 4, '0000-0002-2264-3774': 3})\n",
      "['0000-0002-5512-9093', '0000-0002-6686-9919']\n",
      "Total sample size after apply threshold:  47\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 26)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 10)\n",
      "2\n",
      "(47, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.33      0.44        12\n",
      "          1       0.80      0.94      0.87        35\n",
      "\n",
      "avg / total       0.77      0.79      0.76        47\n",
      "\n",
      "[ 4  8  2 33]\n",
      "MNB Accuracy:  0.7872340425531915\n",
      "MNB F1:  0.6564327485380117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.33      0.44        12\n",
      "          1       0.80      0.94      0.87        35\n",
      "\n",
      "avg / total       0.77      0.79      0.76        47\n",
      "\n",
      "[ 4  8  2 33]\n",
      "svc Accuracy:  0.7872340425531915\n",
      "svc F1:  0.6564327485380117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.73      0.94      0.83        35\n",
      "\n",
      "avg / total       0.55      0.70      0.61        47\n",
      "\n",
      "[ 0 12  2 33]\n",
      "LR Accuracy:  0.7021276595744681\n",
      "LR F1:  0.41250000000000003\n",
      "For name:  k_cho\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0002-7751-0469': 55, '0000-0001-6586-983X': 47, '0000-0002-5782-6028': 15, '0000-0003-2555-5048': 6, '0000-0003-3818-9403': 1, '0000-0003-1154-4065': 1, '0000-0003-2926-3958': 1})\n",
      "['0000-0001-6586-983X', '0000-0002-7751-0469', '0000-0002-5782-6028']\n",
      "Total sample size after apply threshold:  117\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 52)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 19)\n",
      "2\n",
      "(117, 71)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.94      0.82        47\n",
      "          1       0.87      0.87      0.87        55\n",
      "          2       1.00      0.13      0.24        15\n",
      "\n",
      "avg / total       0.83      0.80      0.77       117\n",
      "\n",
      "[44  3  0  7 48  0  9  4  2]\n",
      "MNB Accuracy:  0.8034188034188035\n",
      "MNB F1:  0.6434837656387958\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.89      0.92        47\n",
      "          1       0.84      0.98      0.91        55\n",
      "          2       1.00      0.60      0.75        15\n",
      "\n",
      "avg / total       0.91      0.90      0.89       117\n",
      "\n",
      "[42  5  0  1 54  0  1  5  9]\n",
      "svc Accuracy:  0.8974358974358975\n",
      "svc F1:  0.860213316095669\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.85      0.86        47\n",
      "          1       0.78      0.96      0.86        55\n",
      "          2       1.00      0.20      0.33        15\n",
      "\n",
      "avg / total       0.84      0.82      0.79       117\n",
      "\n",
      "[40  7  0  2 53  0  4  8  3]\n",
      "LR Accuracy:  0.8205128205128205\n",
      "LR F1:  0.6851123349943178\n",
      "For name:  j_sanderson\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-7023-8442': 24, '0000-0003-3326-9842': 3, '0000-0002-1206-8833': 2, '0000-0003-1000-2897': 1, '0000-0002-4726-4885': 1})\n",
      "['0000-0001-7023-8442']\n",
      "Total sample size after apply threshold:  24\n",
      "For name:  s_uddin\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0003-4698-2225': 13, '0000-0003-1886-6710': 8, '0000-0003-0091-6919': 8, '0000-0001-6045-6059': 8, '0000-0002-7285-4262': 2})\n",
      "['0000-0003-4698-2225']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  a_batista\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-6652-3988': 14, '0000-0003-1904-0531': 9, '0000-0003-1593-0174': 8, '0000-0002-5672-8266': 6, '0000-0001-7366-1254': 5, '0000-0002-7788-1753': 3, '0000-0002-9617-8094': 2, '0000-0002-2287-4265': 1})\n",
      "['0000-0001-6652-3988']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  h_pereira\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0003-1043-1675': 16, '0000-0002-5393-4443': 16, '0000-0002-1369-2099': 10, '0000-0003-4373-7005': 9, '0000-0002-7933-6097': 6, '0000-0002-0104-8714': 6, '0000-0002-1423-3038': 4, '0000-0001-9448-682X': 2, '0000-0002-3561-4980': 1})\n",
      "['0000-0003-1043-1675', '0000-0002-5393-4443', '0000-0002-1369-2099']\n",
      "Total sample size after apply threshold:  42\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 16)\n",
      "2\n",
      "(42, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.56      0.58        16\n",
      "          1       0.65      0.81      0.72        16\n",
      "          2       0.86      0.60      0.71        10\n",
      "\n",
      "avg / total       0.68      0.67      0.66        42\n",
      "\n",
      "[ 9  6  1  3 13  0  3  1  6]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.6695832454845737\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.69      0.65        16\n",
      "          1       0.75      0.75      0.75        16\n",
      "          2       0.88      0.70      0.78        10\n",
      "\n",
      "avg / total       0.73      0.71      0.72        42\n",
      "\n",
      "[11  4  1  4 12  0  3  0  7]\n",
      "svc Accuracy:  0.7142857142857143\n",
      "svc F1:  0.7249455337690631\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.69      0.65        16\n",
      "          1       0.71      0.75      0.73        16\n",
      "          2       0.86      0.60      0.71        10\n",
      "\n",
      "avg / total       0.71      0.69      0.69        42\n",
      "\n",
      "[11  4  1  4 12  0  3  1  6]\n",
      "LR Accuracy:  0.6904761904761905\n",
      "LR F1:  0.6934046345811051\n",
      "For name:  a_patel\n",
      "total sample size before apply threshold:  262\n",
      "Counter({'0000-0003-1984-1400': 61, '0000-0001-7621-6463': 32, '0000-0002-6570-8582': 27, '0000-0003-1751-0421': 25, '0000-0002-3840-2473': 20, '0000-0002-5549-9166': 19, '0000-0001-7214-5901': 18, '0000-0003-0075-3304': 13, '0000-0003-3874-3216': 11, '0000-0002-7129-7548': 10, '0000-0002-4914-5062': 9, '0000-0002-3632-4977': 8, '0000-0001-8915-8995': 3, '0000-0003-3423-5134': 2, '0000-0002-2344-4179': 1, '0000-0001-7857-8724': 1, '0000-0003-4213-7454': 1, '0000-0002-9245-731X': 1})\n",
      "['0000-0002-6570-8582', '0000-0003-1751-0421', '0000-0002-5549-9166', '0000-0002-7129-7548', '0000-0003-3874-3216', '0000-0002-3840-2473', '0000-0001-7214-5901', '0000-0003-0075-3304', '0000-0003-1984-1400', '0000-0001-7621-6463']\n",
      "Total sample size after apply threshold:  236\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(236, 131)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(236, 24)\n",
      "2\n",
      "(236, 155)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        27\n",
      "          1       0.60      0.36      0.45        25\n",
      "          2       0.55      0.63      0.59        19\n",
      "          3       1.00      0.50      0.67        10\n",
      "          4       1.00      0.09      0.17        11\n",
      "          5       1.00      0.20      0.33        20\n",
      "          6       0.57      0.72      0.63        18\n",
      "          7       0.00      0.00      0.00        13\n",
      "          8       0.52      0.90      0.66        61\n",
      "          9       0.30      0.56      0.39        32\n",
      "\n",
      "avg / total       0.50      0.50      0.43       236\n",
      "\n",
      "[ 0  2  3  0  0  0  1  0 15  6  0  9  1  0  0  0  6  0  3  6  0  1 12  0\n",
      "  0  0  0  0  1  5  0  0  0  5  0  0  0  0  3  2  0  0  0  0  1  0  0  0\n",
      "  0 10  0  1  2  0  0  4  2  0  5  6  0  2  2  0  0  0 13  0  0  1  0  0\n",
      "  2  0  0  0  1  0  9  1  1  0  0  0  0  0  0  0 55  5  0  0  0  0  0  0\n",
      "  0  0 14 18]\n",
      "MNB Accuracy:  0.4957627118644068\n",
      "MNB F1:  0.38901338120243434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.30      0.42        27\n",
      "          1       0.59      0.64      0.62        25\n",
      "          2       0.64      0.84      0.73        19\n",
      "          3       1.00      0.90      0.95        10\n",
      "          4       0.80      0.36      0.50        11\n",
      "          5       1.00      0.70      0.82        20\n",
      "          6       1.00      0.50      0.67        18\n",
      "          7       1.00      0.15      0.27        13\n",
      "          8       0.58      0.80      0.67        61\n",
      "          9       0.41      0.62      0.49        32\n",
      "\n",
      "avg / total       0.70      0.62      0.61       236\n",
      "\n",
      "[ 8  3  3  0  0  0  0  0  9  4  1 16  1  0  0  0  0  0  3  4  0  0 16  0\n",
      "  0  0  0  0  1  2  0  0  0  9  0  0  0  0  1  0  0  0  0  0  4  0  0  0\n",
      "  0  7  0  2  0  0  1 14  0  0  2  1  0  5  3  0  0  0  9  0  0  1  0  1\n",
      "  2  0  0  0  0  2  8  0  2  0  0  0  0  0  0  0 49 10  0  0  0  0  0  0\n",
      "  0  0 12 20]\n",
      "svc Accuracy:  0.6228813559322034\n",
      "svc F1:  0.6133001177593117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.11      0.18        27\n",
      "          1       0.64      0.36      0.46        25\n",
      "          2       0.55      0.63      0.59        19\n",
      "          3       1.00      0.70      0.82        10\n",
      "          4       1.00      0.36      0.53        11\n",
      "          5       1.00      0.30      0.46        20\n",
      "          6       0.59      0.72      0.65        18\n",
      "          7       0.00      0.00      0.00        13\n",
      "          8       0.56      0.89      0.68        61\n",
      "          9       0.37      0.66      0.47        32\n",
      "\n",
      "avg / total       0.57      0.55      0.51       236\n",
      "\n",
      "[ 3  1  4  0  0  0  1  0 14  4  0  9  1  0  0  0  6  0  3  6  2  0 12  0\n",
      "  0  0  0  0  1  4  0  0  0  7  0  0  0  0  1  2  0  0  0  0  4  0  0  0\n",
      "  0  7  0  1  1  0  0  6  2  0  5  5  0  2  2  0  0  0 13  0  0  1  1  1\n",
      "  2  0  0  0  0  0  8  1  1  0  0  0  0  0  0  0 54  6  0  0  0  0  0  0\n",
      "  0  0 11 21]\n",
      "LR Accuracy:  0.5466101694915254\n",
      "LR F1:  0.4847230526225811\n",
      "For name:  r_graham\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0002-8686-4867': 41, '0000-0002-5530-8120': 9, '0000-0003-3082-8784': 1, '0000-0003-0103-2971': 1})\n",
      "['0000-0002-8686-4867']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  a_nilsson\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0001-5885-7101': 29, '0000-0002-5609-4988': 5, '0000-0002-1217-2163': 4, '0000-0002-9476-4516': 2, '0000-0001-5774-7189': 1, '0000-0003-1968-8696': 1})\n",
      "['0000-0001-5885-7101']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  m_soto\n",
      "total sample size before apply threshold:  97\n",
      "Counter({'0000-0002-4541-8182': 40, '0000-0003-2045-7238': 30, '0000-0002-4843-556X': 14, '0000-0002-2140-2012': 13})\n",
      "['0000-0002-4541-8182', '0000-0002-2140-2012', '0000-0002-4843-556X', '0000-0003-2045-7238']\n",
      "Total sample size after apply threshold:  97\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(97, 40)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(97, 24)\n",
      "2\n",
      "(97, 64)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.93      0.79        40\n",
      "          1       1.00      0.69      0.82        13\n",
      "          2       0.75      0.43      0.55        14\n",
      "          3       0.92      0.80      0.86        30\n",
      "\n",
      "avg / total       0.81      0.78      0.78        97\n",
      "\n",
      "[37  0  2  1  4  9  0  0  7  0  6  1  6  0  0 24]\n",
      "MNB Accuracy:  0.7835051546391752\n",
      "MNB F1:  0.7520033158331031\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.93      0.80        40\n",
      "          1       1.00      0.85      0.92        13\n",
      "          2       0.82      0.64      0.72        14\n",
      "          3       0.96      0.73      0.83        30\n",
      "\n",
      "avg / total       0.84      0.81      0.82        97\n",
      "\n",
      "[37  0  2  1  2 11  0  0  5  0  9  0  8  0  0 22]\n",
      "svc Accuracy:  0.8144329896907216\n",
      "svc F1:  0.8178007929997266\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.95      0.78        40\n",
      "          1       1.00      0.77      0.87        13\n",
      "          2       0.86      0.43      0.57        14\n",
      "          3       0.95      0.70      0.81        30\n",
      "\n",
      "avg / total       0.82      0.77      0.77        97\n",
      "\n",
      "[38  0  1  1  3 10  0  0  8  0  6  0  9  0  0 21]\n",
      "LR Accuracy:  0.7731958762886598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR F1:  0.7560490751484541\n",
      "For name:  g_guidi\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0002-3061-9870': 15, '0000-0003-3199-6624': 11, '0000-0001-9535-9152': 5, '0000-0002-1393-326X': 4, '0000-0002-8857-0096': 2})\n",
      "['0000-0003-3199-6624', '0000-0002-3061-9870']\n",
      "Total sample size after apply threshold:  26\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 15)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 14)\n",
      "2\n",
      "(26, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.27      0.37        11\n",
      "          1       0.62      0.87      0.72        15\n",
      "\n",
      "avg / total       0.61      0.62      0.58        26\n",
      "\n",
      "[ 3  8  2 13]\n",
      "MNB Accuracy:  0.6153846153846154\n",
      "MNB F1:  0.548611111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.91      0.80        11\n",
      "          1       0.92      0.73      0.81        15\n",
      "\n",
      "avg / total       0.83      0.81      0.81        26\n",
      "\n",
      "[10  1  4 11]\n",
      "svc Accuracy:  0.8076923076923077\n",
      "svc F1:  0.8074074074074074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.55      0.63        11\n",
      "          1       0.72      0.87      0.79        15\n",
      "\n",
      "avg / total       0.73      0.73      0.72        26\n",
      "\n",
      "[ 6  5  2 13]\n",
      "LR Accuracy:  0.7307692307692307\n",
      "LR F1:  0.7097288676236044\n",
      "For name:  e_andersson\n",
      "total sample size before apply threshold:  138\n",
      "Counter({'0000-0002-7864-1014': 36, '0000-0003-0088-8719': 33, '0000-0002-2854-0354': 29, '0000-0003-3095-465X': 26, '0000-0001-5856-6806': 10, '0000-0002-8608-625X': 2, '0000-0001-8453-2079': 1, '0000-0003-3398-0132': 1})\n",
      "['0000-0001-5856-6806', '0000-0003-3095-465X', '0000-0002-2854-0354', '0000-0003-0088-8719', '0000-0002-7864-1014']\n",
      "Total sample size after apply threshold:  134\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 64)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 27)\n",
      "2\n",
      "(134, 91)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.90      0.35      0.50        26\n",
      "          2       0.57      0.41      0.48        29\n",
      "          3       0.55      0.91      0.68        33\n",
      "          4       0.65      0.78      0.71        36\n",
      "\n",
      "avg / total       0.68      0.63      0.61       134\n",
      "\n",
      "[ 5  0  1  4  0  0  9  4  4  9  0  1 12 12  4  0  0  1 30  2  0  0  3  5\n",
      " 28]\n",
      "MNB Accuracy:  0.6268656716417911\n",
      "MNB F1:  0.6074691215957039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       0.73      0.73      0.73        26\n",
      "          2       0.71      0.52      0.60        29\n",
      "          3       0.60      0.82      0.69        33\n",
      "          4       0.91      0.81      0.85        36\n",
      "\n",
      "avg / total       0.76      0.75      0.75       134\n",
      "\n",
      "[10  0  0  0  0  0 19  2  3  2  0  2 15 11  1  0  2  4 27  0  0  3  0  4\n",
      " 29]\n",
      "svc Accuracy:  0.746268656716418\n",
      "svc F1:  0.7752036199095023\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.67      0.46      0.55        26\n",
      "          2       0.57      0.41      0.48        29\n",
      "          3       0.59      0.88      0.71        33\n",
      "          4       0.71      0.75      0.73        36\n",
      "\n",
      "avg / total       0.66      0.66      0.65       134\n",
      "\n",
      "[ 8  1  1  0  0  0 12  4  3  7  0  2 12 12  3  0  1  2 29  1  0  2  2  5\n",
      " 27]\n",
      "LR Accuracy:  0.6567164179104478\n",
      "LR F1:  0.6702780474487792\n",
      "For name:  s_reid\n",
      "total sample size before apply threshold:  132\n",
      "Counter({'0000-0001-9916-7414': 43, '0000-0002-6103-4429': 42, '0000-0001-7779-4820': 34, '0000-0002-8068-6529': 12, '0000-0001-9415-5246': 1})\n",
      "['0000-0001-7779-4820', '0000-0001-9916-7414', '0000-0002-8068-6529', '0000-0002-6103-4429']\n",
      "Total sample size after apply threshold:  131\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(131, 59)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(131, 18)\n",
      "2\n",
      "(131, 77)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.47      0.58        34\n",
      "          1       0.63      0.93      0.75        43\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       0.68      0.76      0.72        42\n",
      "\n",
      "avg / total       0.62      0.67      0.63       131\n",
      "\n",
      "[16 10  0  8  2 40  0  1  1  5  0  6  2  8  0 32]\n",
      "MNB Accuracy:  0.6717557251908397\n",
      "MNB F1:  0.5139090716364406\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.85      0.75        34\n",
      "          1       0.97      0.91      0.94        43\n",
      "          2       0.50      0.08      0.14        12\n",
      "          3       0.78      0.86      0.82        42\n",
      "\n",
      "avg / total       0.79      0.80      0.78       131\n",
      "\n",
      "[29  0  0  5  2 39  1  1  6  1  1  4  6  0  0 36]\n",
      "svc Accuracy:  0.8015267175572519\n",
      "svc F1:  0.6635111876075731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.68      0.67        34\n",
      "          1       0.93      0.88      0.90        43\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       0.67      0.88      0.76        42\n",
      "\n",
      "avg / total       0.69      0.75      0.71       131\n",
      "\n",
      "[23  1  0 10  4 38  0  1  4  1  0  7  4  1  0 37]\n",
      "LR Accuracy:  0.7480916030534351\n",
      "LR F1:  0.5835787923416789\n",
      "For name:  a_maleki\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0001-5490-3350': 15, '0000-0001-8261-8717': 5, '0000-0003-3203-7492': 4, '0000-0001-7888-1985': 1})\n",
      "['0000-0001-5490-3350']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  j_moon\n",
      "total sample size before apply threshold:  203\n",
      "Counter({'0000-0001-8071-1491': 96, '0000-0001-6327-0575': 23, '0000-0001-7776-6889': 19, '0000-0002-9182-5475': 17, '0000-0001-9760-297X': 13, '0000-0002-9274-4554': 12, '0000-0002-8625-6562': 8, '0000-0003-1282-4528': 7, '0000-0003-1569-3068': 2, '0000-0003-1428-414X': 2, '0000-0002-7049-892X': 1, '0000-0001-8246-931X': 1, '0000-0003-4742-8744': 1, '0000-0002-4630-3301': 1})\n",
      "['0000-0001-7776-6889', '0000-0002-9274-4554', '0000-0001-8071-1491', '0000-0001-9760-297X', '0000-0002-9182-5475', '0000-0001-6327-0575']\n",
      "Total sample size after apply threshold:  180\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(180, 102)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(180, 12)\n",
      "2\n",
      "(180, 114)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.47      0.55        19\n",
      "          1       0.33      0.08      0.13        12\n",
      "          2       0.78      0.99      0.87        96\n",
      "          3       0.50      0.08      0.13        13\n",
      "          4       0.76      0.76      0.76        17\n",
      "          5       0.59      0.57      0.58        23\n",
      "\n",
      "avg / total       0.69      0.73      0.69       180\n",
      "\n",
      "[ 9  2  6  0  0  2  4  1  5  0  0  2  0  0 95  0  0  1  0  0  6  1  3  3\n",
      "  1  0  2  0 13  1  0  0  8  1  1 13]\n",
      "MNB Accuracy:  0.7333333333333333\n",
      "MNB F1:  0.504360750879909\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.53      0.61        19\n",
      "          1       0.62      0.42      0.50        12\n",
      "          2       0.82      0.98      0.90        96\n",
      "          3       0.60      0.23      0.33        13\n",
      "          4       1.00      0.76      0.87        17\n",
      "          5       0.62      0.70      0.65        23\n",
      "\n",
      "avg / total       0.77      0.78      0.76       180\n",
      "\n",
      "[10  2  4  0  0  3  3  5  3  0  0  1  0  1 94  0  0  1  0  0  6  3  0  4\n",
      "  0  0  2  1 13  1  1  0  5  1  0 16]\n",
      "svc Accuracy:  0.7833333333333333\n",
      "svc F1:  0.6423933209647495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.47      0.55        19\n",
      "          1       0.50      0.17      0.25        12\n",
      "          2       0.75      0.99      0.86        96\n",
      "          3       0.60      0.23      0.33        13\n",
      "          4       0.86      0.71      0.77        17\n",
      "          5       0.71      0.52      0.60        23\n",
      "\n",
      "avg / total       0.72      0.74      0.70       180\n",
      "\n",
      "[ 9  2  6  0  0  2  4  2  5  0  0  1  0  0 95  0  0  1  0  0  8  3  1  1\n",
      "  1  0  3  1 12  0  0  0  9  1  1 12]\n",
      "LR Accuracy:  0.7388888888888889\n",
      "LR F1:  0.559806213838472\n",
      "For name:  t_abe\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0003-3496-1953': 19, '0000-0002-4185-5254': 17, '0000-0001-5298-082X': 12, '0000-0003-1251-7448': 2})\n",
      "['0000-0002-4185-5254', '0000-0001-5298-082X', '0000-0003-3496-1953']\n",
      "Total sample size after apply threshold:  48\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 12)\n",
      "2\n",
      "(48, 42)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.76      0.76        17\n",
      "          1       0.89      0.67      0.76        12\n",
      "          2       0.73      0.84      0.78        19\n",
      "\n",
      "avg / total       0.78      0.77      0.77        48\n",
      "\n",
      "[13  0  4  2  8  2  2  1 16]\n",
      "MNB Accuracy:  0.7708333333333334\n",
      "MNB F1:  0.769032816378584\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.82      0.80        17\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.80      0.84      0.82        19\n",
      "\n",
      "avg / total       0.84      0.83      0.84        48\n",
      "\n",
      "[14  0  3  1 10  1  3  0 16]\n",
      "svc Accuracy:  0.8333333333333334\n",
      "svc F1:  0.8432012432012431\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.76      0.79        17\n",
      "          1       1.00      0.67      0.80        12\n",
      "          2       0.71      0.89      0.79        19\n",
      "\n",
      "avg / total       0.82      0.79      0.79        48\n",
      "\n",
      "[13  0  4  1  8  3  2  0 17]\n",
      "LR Accuracy:  0.7916666666666666\n",
      "LR F1:  0.7928588207657975\n",
      "For name:  x_fu\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-6928-4396': 8, '0000-0001-9295-6314': 6, '0000-0002-8012-4753': 1, '0000-0002-4305-6624': 1})\n",
      "[]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  f_ortega\n",
      "total sample size before apply threshold:  368\n",
      "Counter({'0000-0003-2001-1121': 205, '0000-0003-2111-769X': 86, '0000-0002-4730-9270': 38, '0000-0002-3172-2095': 22, '0000-0002-7431-354X': 9, '0000-0001-7850-2105': 7, '0000-0003-0231-2051': 1})\n",
      "['0000-0002-3172-2095', '0000-0003-2001-1121', '0000-0002-4730-9270', '0000-0003-2111-769X']\n",
      "Total sample size after apply threshold:  351\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(351, 135)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(351, 17)\n",
      "2\n",
      "(351, 152)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.14      0.23        22\n",
      "          1       0.72      0.92      0.81       205\n",
      "          2       0.88      0.55      0.68        38\n",
      "          3       0.67      0.48      0.56        86\n",
      "\n",
      "avg / total       0.73      0.72      0.69       351\n",
      "\n",
      "[  3  13   3   3   0 188   0  17   1  16  21   0   0  45   0  41]\n",
      "MNB Accuracy:  0.7207977207977208\n",
      "MNB F1:  0.567787725288786\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.55      0.69        22\n",
      "          1       0.83      0.93      0.88       205\n",
      "          2       1.00      0.89      0.94        38\n",
      "          3       0.77      0.67      0.72        86\n",
      "\n",
      "avg / total       0.84      0.84      0.83       351\n",
      "\n",
      "[ 12   8   0   2   0 190   0  15   1   3  34   0   0  28   0  58]\n",
      "svc Accuracy:  0.8376068376068376\n",
      "svc F1:  0.8065579153587569\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        22\n",
      "          1       0.73      0.96      0.83       205\n",
      "          2       1.00      0.50      0.67        38\n",
      "          3       0.83      0.62      0.71        86\n",
      "\n",
      "avg / total       0.74      0.76      0.73       351\n",
      "\n",
      "[  0  20   0   2   0 196   0   9   1  18  19   0   0  33   0  53]\n",
      "LR Accuracy:  0.7635327635327636\n",
      "LR F1:  0.5509604519774011\n",
      "For name:  r_morris\n",
      "total sample size before apply threshold:  409\n",
      "Counter({'0000-0001-7240-4563': 107, '0000-0001-7809-0315': 73, '0000-0001-8661-1520': 59, '0000-0002-7574-9388': 51, '0000-0003-3080-2613': 44, '0000-0002-5018-1239': 21, '0000-0001-7431-6401': 20, '0000-0001-7450-5923': 14, '0000-0001-5511-3457': 10, '0000-0003-4764-3639': 7, '0000-0001-7443-7406': 2, '0000-0002-9193-3417': 1})\n",
      "['0000-0003-3080-2613', '0000-0002-5018-1239', '0000-0001-7809-0315', '0000-0001-5511-3457', '0000-0001-7240-4563', '0000-0001-7431-6401', '0000-0002-7574-9388', '0000-0001-8661-1520', '0000-0001-7450-5923']\n",
      "Total sample size after apply threshold:  399\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(399, 179)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(399, 22)\n",
      "2\n",
      "(399, 201)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.25      0.37        44\n",
      "          1       0.00      0.00      0.00        21\n",
      "          2       0.48      0.82      0.61        73\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.56      0.90      0.69       107\n",
      "          5       0.00      0.00      0.00        20\n",
      "          6       0.61      0.39      0.48        51\n",
      "          7       0.66      0.59      0.62        59\n",
      "          8       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.49      0.56      0.49       399\n",
      "\n",
      "[11  0  9  0 18  1  2  3  0  0  0  7  0 12  0  1  1  0  1  0 60  0  5  0\n",
      "  5  2  0  0  0  4  0  6  0  0  0  0  0  0  7  0 96  1  1  2  0  2  0  2\n",
      "  0 13  0  1  2  0  0  0 22  0  7  0 20  2  0  1  0  7  0 14  0  2 35  0\n",
      "  0  0  6  0  1  0  1  6  0]\n",
      "MNB Accuracy:  0.556390977443609\n",
      "MNB F1:  0.3079312145523329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.64      0.72        44\n",
      "          1       0.89      0.38      0.53        21\n",
      "          2       0.68      0.77      0.72        73\n",
      "          3       1.00      0.20      0.33        10\n",
      "          4       0.62      0.97      0.76       107\n",
      "          5       0.70      0.35      0.47        20\n",
      "          6       0.73      0.47      0.57        51\n",
      "          7       0.71      0.68      0.70        59\n",
      "          8       1.00      0.36      0.53        14\n",
      "\n",
      "avg / total       0.72      0.69      0.67       399\n",
      "\n",
      "[ 28   0   1   0   9   1   0   5   0   0   8   1   0  12   0   0   0   0\n",
      "   2   0  56   0   3   0   9   3   0   2   0   0   2   6   0   0   0   0\n",
      "   0   0   1   0 104   1   0   1   0   0   1   0   0   9   7   0   3   0\n",
      "   0   0  21   0   5   0  24   1   0   2   0   2   0  14   1   0  40   0\n",
      "   0   0   0   0   6   0   0   3   5]\n",
      "svc Accuracy:  0.6867167919799498\n",
      "svc F1:  0.5915136519580307\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.36      0.50        44\n",
      "          1       0.75      0.14      0.24        21\n",
      "          2       0.60      0.73      0.66        73\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.53      0.97      0.69       107\n",
      "          5       0.50      0.10      0.17        20\n",
      "          6       0.75      0.47      0.58        51\n",
      "          7       0.67      0.63      0.65        59\n",
      "          8       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.60      0.60      0.55       399\n",
      "\n",
      "[ 16   0   4   0  19   1   0   4   0   0   3   3   0  15   0   0   0   0\n",
      "   1   0  53   0  10   0   7   2   0   0   0   3   0   7   0   0   0   0\n",
      "   0   0   1   0 104   0   0   2   0   1   1   0   0  13   2   0   3   0\n",
      "   0   0  17   0   9   0  24   1   0   2   0   2   0  16   1   1  37   0\n",
      "   0   0   5   0   3   0   0   6   0]\n",
      "LR Accuracy:  0.5989974937343359\n",
      "LR F1:  0.38655071852540523\n",
      "For name:  w_fang\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0002-8431-8256': 31, '0000-0002-9580-3716': 6, '0000-0002-2449-3749': 3, '0000-0002-9724-898X': 3})\n",
      "['0000-0002-8431-8256']\n",
      "Total sample size after apply threshold:  31\n",
      "For name:  m_amaral\n",
      "total sample size before apply threshold:  134\n",
      "Counter({'0000-0002-0828-8630': 101, '0000-0002-3209-3366': 21, '0000-0003-4966-2614': 6, '0000-0002-4301-2760': 4, '0000-0001-5607-6475': 1, '0000-0001-9686-1312': 1})\n",
      "['0000-0002-0828-8630', '0000-0002-3209-3366']\n",
      "Total sample size after apply threshold:  122\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(122, 77)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(122, 21)\n",
      "2\n",
      "(122, 98)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90       101\n",
      "          1       0.33      0.05      0.08        21\n",
      "\n",
      "avg / total       0.75      0.82      0.76       122\n",
      "\n",
      "[99  2 20  1]\n",
      "MNB Accuracy:  0.819672131147541\n",
      "MNB F1:  0.4916666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.92       101\n",
      "          1       0.67      0.48      0.56        21\n",
      "\n",
      "avg / total       0.86      0.87      0.86       122\n",
      "\n",
      "[96  5 11 10]\n",
      "svc Accuracy:  0.8688524590163934\n",
      "svc F1:  0.7393162393162394\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       101\n",
      "          1       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.69      0.83      0.75       122\n",
      "\n",
      "[101   0  21   0]\n",
      "LR Accuracy:  0.8278688524590164\n",
      "LR F1:  0.45291479820627806\n",
      "For name:  h_song\n",
      "total sample size before apply threshold:  210\n",
      "Counter({'0000-0001-5684-4059': 88, '0000-0001-5553-2539': 30, '0000-0002-3134-782X': 29, '0000-0003-3845-8079': 20, '0000-0002-7844-2293': 14, '0000-0001-5486-2560': 8, '0000-0002-8720-6436': 6, '0000-0002-2721-3626': 2, '0000-0002-3563-9504': 2, '0000-0003-2197-1562': 2, '0000-0002-9849-8091': 2, '0000-0002-2164-8813': 2, '0000-0001-6000-1572': 1, '0000-0001-5747-8847': 1, '0000-0002-2791-1723': 1, '0000-0002-4204-6459': 1, '0000-0003-2631-9223': 1})\n",
      "['0000-0002-3134-782X', '0000-0002-7844-2293', '0000-0001-5684-4059', '0000-0001-5553-2539', '0000-0003-3845-8079']\n",
      "Total sample size after apply threshold:  181\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(181, 75)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(181, 24)\n",
      "2\n",
      "(181, 99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.97      0.82        29\n",
      "          1       1.00      0.14      0.25        14\n",
      "          2       0.72      0.94      0.81        88\n",
      "          3       0.73      0.37      0.49        30\n",
      "          4       0.89      0.40      0.55        20\n",
      "\n",
      "avg / total       0.76      0.73      0.69       181\n",
      "\n",
      "[28  0  1  0  0  2  2  9  1  0  2  0 83  2  1  5  0 14 11  0  2  0  9  1\n",
      "  8]\n",
      "MNB Accuracy:  0.7292817679558011\n",
      "MNB F1:  0.5855735857561416\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        29\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       0.73      0.94      0.82        88\n",
      "          3       0.65      0.37      0.47        30\n",
      "          4       0.92      0.55      0.69        20\n",
      "\n",
      "avg / total       0.80      0.79      0.77       181\n",
      "\n",
      "[28  0  1  0  0  0 10  2  2  0  0  0 83  4  1  0  0 19 11  0  0  0  9  0\n",
      " 11]\n",
      "svc Accuracy:  0.7900552486187845\n",
      "svc F1:  0.7586313516570022\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        29\n",
      "          1       1.00      0.07      0.13        14\n",
      "          2       0.65      0.97      0.78        88\n",
      "          3       0.67      0.27      0.38        30\n",
      "          4       1.00      0.45      0.62        20\n",
      "\n",
      "avg / total       0.77      0.72      0.68       181\n",
      "\n",
      "[28  0  1  0  0  0  1 12  1  0  0  0 85  3  0  0  0 22  8  0  0  0 11  0\n",
      "  9]\n",
      "LR Accuracy:  0.7237569060773481\n",
      "LR F1:  0.5787374435143124\n",
      "For name:  h_dai\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0003-1395-7904': 2, '0000-0002-1516-7255': 2, '0000-0003-3807-4585': 1, '0000-0001-6165-4196': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  y_nakajima\n",
      "total sample size before apply threshold:  12\n",
      "Counter({'0000-0001-6558-5378': 8, '0000-0001-9759-3487': 2, '0000-0002-7153-6238': 1, '0000-0002-7357-2910': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_warner\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0003-3988-4408': 56, '0000-0003-0604-0110': 6, '0000-0003-1809-102X': 3, '0000-0001-8397-6030': 3})\n",
      "['0000-0003-3988-4408']\n",
      "Total sample size after apply threshold:  56\n",
      "For name:  s_saha\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0001-9433-8894': 24, '0000-0001-6610-4820': 23, '0000-0002-0087-8652': 14, '0000-0001-8780-9117': 12, '0000-0001-6631-0464': 8, '0000-0003-3029-7995': 5, '0000-0003-1060-9402': 5, '0000-0003-1534-7130': 4, '0000-0002-5791-8635': 3, '0000-0002-8312-6711': 3, '0000-0003-1742-2974': 2, '0000-0003-2366-8620': 2, '0000-0002-7184-6906': 2, '0000-0002-7487-9885': 1, '0000-0001-6844-2516': 1, '0000-0002-6655-4001': 1, '0000-0001-9742-3306': 1})\n",
      "['0000-0002-0087-8652', '0000-0001-8780-9117', '0000-0001-9433-8894', '0000-0001-6610-4820']\n",
      "Total sample size after apply threshold:  73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 43)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 12)\n",
      "2\n",
      "(73, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.21      0.29        14\n",
      "          1       0.57      0.33      0.42        12\n",
      "          2       0.66      0.79      0.72        24\n",
      "          3       0.57      0.74      0.64        23\n",
      "\n",
      "avg / total       0.57      0.59      0.56        73\n",
      "\n",
      "[ 3  2  3  6  3  4  2  3  1  0 19  4  0  1  5 17]\n",
      "MNB Accuracy:  0.589041095890411\n",
      "MNB F1:  0.5163143708327422\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.71      0.67        14\n",
      "          1       0.86      0.50      0.63        12\n",
      "          2       0.72      0.88      0.79        24\n",
      "          3       0.81      0.74      0.77        23\n",
      "\n",
      "avg / total       0.75      0.74      0.74        73\n",
      "\n",
      "[10  0  3  1  4  6  1  1  1  0 21  2  1  1  4 17]\n",
      "svc Accuracy:  0.7397260273972602\n",
      "svc F1:  0.7158564292377598\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.50      0.54        14\n",
      "          1       0.67      0.33      0.44        12\n",
      "          2       0.68      0.88      0.76        24\n",
      "          3       0.67      0.70      0.68        23\n",
      "\n",
      "avg / total       0.65      0.66      0.64        73\n",
      "\n",
      "[ 7  1  3  3  4  4  2  2  0  0 21  3  1  1  5 16]\n",
      "LR Accuracy:  0.6575342465753424\n",
      "LR F1:  0.6068483525930334\n",
      "For name:  j_fernandez\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0003-2222-3355': 7, '0000-0002-4190-7341': 5, '0000-0003-2969-8150': 5, '0000-0003-4756-6645': 5, '0000-0002-8533-1858': 1, '0000-0003-4427-3935': 1, '0000-0002-7315-2326': 1, '0000-0002-7629-6106': 1, '0000-0001-5894-9866': 1, '0000-0002-9528-6173': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_pan\n",
      "total sample size before apply threshold:  146\n",
      "Counter({'0000-0002-5188-7030': 128, '0000-0001-5535-2714': 10, '0000-0001-5697-6086': 6, '0000-0003-1485-3154': 1, '0000-0003-3350-8719': 1})\n",
      "['0000-0001-5535-2714', '0000-0002-5188-7030']\n",
      "Total sample size after apply threshold:  138\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(138, 45)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(138, 20)\n",
      "2\n",
      "(138, 65)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.93      1.00      0.96       128\n",
      "\n",
      "avg / total       0.86      0.93      0.89       138\n",
      "\n",
      "[  0  10   0 128]\n",
      "MNB Accuracy:  0.927536231884058\n",
      "MNB F1:  0.48120300751879697\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.93      0.98      0.95       128\n",
      "\n",
      "avg / total       0.86      0.91      0.89       138\n",
      "\n",
      "[  0  10   2 126]\n",
      "svc Accuracy:  0.9130434782608695\n",
      "svc F1:  0.47727272727272724\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.93      1.00      0.96       128\n",
      "\n",
      "avg / total       0.86      0.93      0.89       138\n",
      "\n",
      "[  0  10   0 128]\n",
      "LR Accuracy:  0.927536231884058\n",
      "LR F1:  0.48120300751879697\n",
      "For name:  a_simon\n",
      "total sample size before apply threshold:  117\n",
      "Counter({'0000-0002-6141-7921': 60, '0000-0002-0151-0120': 19, '0000-0002-6509-4541': 14, '0000-0001-6023-6427': 14, '0000-0002-1879-5628': 5, '0000-0002-3286-5776': 4, '0000-0003-4641-6186': 1})\n",
      "['0000-0002-6141-7921', '0000-0002-6509-4541', '0000-0002-0151-0120', '0000-0001-6023-6427']\n",
      "Total sample size after apply threshold:  107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 76)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 17)\n",
      "2\n",
      "(107, 93)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.93      0.76        60\n",
      "          1       0.50      0.07      0.12        14\n",
      "          2       0.65      0.58      0.61        19\n",
      "          3       1.00      0.07      0.13        14\n",
      "\n",
      "avg / total       0.67      0.64      0.57       107\n",
      "\n",
      "[56  1  3  0 10  1  3  0  8  0 11  0 13  0  0  1]\n",
      "MNB Accuracy:  0.6448598130841121\n",
      "MNB F1:  0.40783730158730164\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.93      0.79        60\n",
      "          1       0.50      0.14      0.22        14\n",
      "          2       0.75      0.47      0.58        19\n",
      "          3       1.00      0.64      0.78        14\n",
      "\n",
      "avg / total       0.71      0.71      0.68       107\n",
      "\n",
      "[56  2  2  0 11  2  1  0 10  0  9  0  5  0  0  9]\n",
      "svc Accuracy:  0.7102803738317757\n",
      "svc F1:  0.593552118382729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.97      0.76        60\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.70      0.37      0.48        19\n",
      "          3       1.00      0.29      0.44        14\n",
      "\n",
      "avg / total       0.60      0.64      0.57       107\n",
      "\n",
      "[58  0  2  0 13  0  1  0 12  0  7  0 10  0  0  4]\n",
      "LR Accuracy:  0.6448598130841121\n",
      "LR F1:  0.42134324994365563\n",
      "For name:  r_freitas\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0003-4900-3897': 48, '0000-0001-8605-2925': 6, '0000-0002-0123-7232': 6, '0000-0002-4448-6458': 5, '0000-0001-5811-5255': 5, '0000-0002-1645-4125': 2, '0000-0001-8836-1422': 1})\n",
      "['0000-0003-4900-3897']\n",
      "Total sample size after apply threshold:  48\n",
      "For name:  c_yun\n",
      "total sample size before apply threshold:  284\n",
      "Counter({'0000-0002-9466-4531': 149, '0000-0002-0041-2887': 98, '0000-0003-2204-8067': 36, '0000-0002-6747-4628': 1})\n",
      "['0000-0002-9466-4531', '0000-0002-0041-2887', '0000-0003-2204-8067']\n",
      "Total sample size after apply threshold:  283\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(283, 133)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(283, 20)\n",
      "2\n",
      "(283, 153)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.85      0.79       149\n",
      "          1       0.69      0.76      0.72        98\n",
      "          2       0.75      0.08      0.15        36\n",
      "\n",
      "avg / total       0.72      0.72      0.68       283\n",
      "\n",
      "[126  22   1  24  74   0  21  12   3]\n",
      "MNB Accuracy:  0.7173144876325088\n",
      "MNB F1:  0.5519822006472491\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.88      0.78       149\n",
      "          1       0.74      0.61      0.67        98\n",
      "          2       0.86      0.33      0.48        36\n",
      "\n",
      "avg / total       0.73      0.72      0.70       283\n",
      "\n",
      "[131  16   2  38  60   0  19   5  12]\n",
      "svc Accuracy:  0.7173144876325088\n",
      "svc F1:  0.6426130442230438\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.87      0.77       149\n",
      "          1       0.69      0.65      0.67        98\n",
      "          2       1.00      0.06      0.11        36\n",
      "\n",
      "avg / total       0.73      0.69      0.65       283\n",
      "\n",
      "[129  20   0  34  64   0  25   9   2]\n",
      "LR Accuracy:  0.6890459363957597\n",
      "LR F1:  0.5136662869908002\n",
      "For name:  j_huang\n",
      "total sample size before apply threshold:  443\n",
      "Counter({'0000-0001-8011-2317': 69, '0000-0001-9207-8953': 68, '0000-0001-5495-3577': 68, '0000-0002-2742-5557': 32, '0000-0001-8993-2506': 25, '0000-0002-7027-3042': 22, '0000-0003-3282-8892': 21, '0000-0003-0996-9451': 18, '0000-0002-7163-5156': 17, '0000-0002-4452-4557': 15, '0000-0001-7281-663X': 14, '0000-0002-4569-0629': 12, '0000-0002-5761-2177': 12, '0000-0002-9570-4101': 10, '0000-0001-9069-5739': 8, '0000-0001-9639-2907': 6, '0000-0002-0901-9635': 5, '0000-0003-4435-7274': 4, '0000-0002-4051-4482': 4, '0000-0002-5153-506X': 3, '0000-0001-7288-9724': 2, '0000-0003-1776-9863': 1, '0000-0003-2314-7104': 1, '0000-0002-7531-4691': 1, '0000-0001-8111-0583': 1, '0000-0001-6589-4963': 1, '0000-0002-6135-1256': 1, '0000-0002-5736-6148': 1, '0000-0002-4189-3779': 1})\n",
      "['0000-0003-3282-8892', '0000-0001-9207-8953', '0000-0001-8011-2317', '0000-0002-7163-5156', '0000-0001-7281-663X', '0000-0001-8993-2506', '0000-0002-9570-4101', '0000-0002-2742-5557', '0000-0002-4569-0629', '0000-0002-4452-4557', '0000-0002-7027-3042', '0000-0003-0996-9451', '0000-0002-5761-2177', '0000-0001-5495-3577']\n",
      "Total sample size after apply threshold:  403\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(403, 187)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(403, 21)\n",
      "2\n",
      "(403, 208)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        21\n",
      "          1       0.34      0.88      0.49        68\n",
      "          2       0.45      0.65      0.53        69\n",
      "          3       0.00      0.00      0.00        17\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       0.67      0.08      0.14        25\n",
      "          6       0.00      0.00      0.00        10\n",
      "          7       0.80      0.38      0.51        32\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.00      0.00      0.00        15\n",
      "         10       0.80      0.18      0.30        22\n",
      "         11       0.00      0.00      0.00        18\n",
      "         12       0.00      0.00      0.00        12\n",
      "         13       0.56      0.84      0.67        68\n",
      "\n",
      "avg / total       0.38      0.45      0.35       403\n",
      "\n",
      "[ 0 10  6  0  0  0  0  0  0  0  0  0  0  5  0 60  4  0  0  0  0  0  0  0\n",
      "  0  0  0  4  0 15 45  0  0  0  0  1  0  0  0  0  0  8  0 10  1  0  0  0\n",
      "  0  0  0  0  0  0  0  6  0 10  4  0  0  0  0  0  0  0  0  0  0  0  0 10\n",
      "  5  0  0  2  0  0  0  0  1  0  0  7  0  5  4  0  0  0  0  0  0  0  0  0\n",
      "  0  1  0 11  8  0  0  0  0 12  0  0  0  0  0  1  0  6  4  0  0  0  0  1\n",
      "  0  0  0  0  0  1  0  8  3  0  0  0  0  1  0  0  0  0  0  3  0  8  3  0\n",
      "  0  1  0  0  0  0  4  0  0  6  0 10  5  0  0  0  0  0  0  0  0  0  0  3\n",
      "  0 11  1  0  0  0  0  0  0  0  0  0  0  0  0  4  7  0  0  0  0  0  0  0\n",
      "  0  0  0 57]\n",
      "MNB Accuracy:  0.4466501240694789\n",
      "MNB F1:  0.18862351636192162\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.38        21\n",
      "          1       0.86      0.84      0.85        68\n",
      "          2       0.36      0.88      0.51        69\n",
      "          3       0.67      0.24      0.35        17\n",
      "          4       0.92      0.86      0.89        14\n",
      "          5       0.83      0.60      0.70        25\n",
      "          6       0.83      0.50      0.62        10\n",
      "          7       0.81      0.53      0.64        32\n",
      "          8       0.33      0.08      0.13        12\n",
      "          9       0.75      0.40      0.52        15\n",
      "         10       0.58      0.50      0.54        22\n",
      "         11       0.75      0.17      0.27        18\n",
      "         12       0.75      0.75      0.75        12\n",
      "         13       0.91      0.72      0.80        68\n",
      "\n",
      "avg / total       0.74      0.63      0.63       403\n",
      "\n",
      "[ 5  0 16  0  0  0  0  0  0  0  0  0  0  0  0 57  9  0  0  0  1  0  0  0\n",
      "  1  0  0  0  0  2 61  0  0  0  0  2  0  2  0  0  0  2  0  0 10  4  0  0\n",
      "  0  0  0  0  1  0  0  2  0  0  1  0 12  1  0  0  0  0  0  0  0  0  0  0\n",
      "  5  0  1 15  0  0  0  0  4  0  0  0  0  2  3  0  0  0  5  0  0  0  0  0\n",
      "  0  0  0  2 11  0  0  0  0 17  2  0  0  0  0  0  0  1  9  0  0  0  0  1\n",
      "  1  0  0  0  0  0  0  0  8  0  0  0  0  1  0  6  0  0  0  0  0  1  4  1\n",
      "  0  2  0  0  0  0 11  0  3  0  0  0 14  0  0  0  0  0  0  0  0  3  0  1\n",
      "  0  0  1  0  0  0  0  0  0  0  2  0  9  0  0  1 16  1  0  0  0  0  0  0\n",
      "  0  1  0 49]\n",
      "svc Accuracy:  0.6327543424317618\n",
      "svc F1:  0.5691923003605368\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.17        21\n",
      "          1       0.62      0.84      0.71        68\n",
      "          2       0.38      0.75      0.51        69\n",
      "          3       0.67      0.12      0.20        17\n",
      "          4       1.00      0.71      0.83        14\n",
      "          5       0.83      0.40      0.54        25\n",
      "          6       1.00      0.10      0.18        10\n",
      "          7       0.86      0.59      0.70        32\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.67      0.27      0.38        15\n",
      "         10       0.65      0.50      0.56        22\n",
      "         11       0.00      0.00      0.00        18\n",
      "         12       0.89      0.67      0.76        12\n",
      "         13       0.62      0.84      0.71        68\n",
      "\n",
      "avg / total       0.62      0.58      0.54       403\n",
      "\n",
      "[ 2  4 10  0  0  0  0  0  0  0  0  0  0  5  0 57  8  0  0  0  0  0  0  0\n",
      "  0  0  0  3  0  6 52  0  0  0  0  1  0  2  0  0  0  8  0  2  7  2  0  0\n",
      "  0  0  0  0  0  0  0  6  0  0  4  0 10  0  0  0  0  0  0  0  0  0  0  1\n",
      "  5  0  0 10  0  0  0  0  5  0  0  4  0  3  5  0  0  0  1  0  0  0  0  0\n",
      "  0  1  0  3  8  0  0  0  0 19  1  0  0  0  0  1  0  3  7  0  0  0  0  1\n",
      "  0  0  0  0  0  1  0  3  5  0  0  0  0  1  0  4  0  0  0  2  0  3  3  1\n",
      "  0  2  0  0  0  0 11  0  1  1  0  6  9  0  0  0  0  0  0  0  0  0  0  3\n",
      "  0  0  3  0  0  0  0  0  0  0  1  0  8  0  0  1 10  0  0  0  0  0  0  0\n",
      "  0  0  0 57]\n",
      "LR Accuracy:  0.5781637717121588\n",
      "LR F1:  0.4480418273574613\n",
      "For name:  p_santos\n",
      "total sample size before apply threshold:  92\n",
      "Counter({'0000-0003-3234-4265': 24, '0000-0002-2225-455X': 17, '0000-0003-3548-700X': 16, '0000-0001-9669-9837': 9, '0000-0002-8723-4373': 8, '0000-0002-2362-5527': 4, '0000-0002-3363-0098': 3, '0000-0003-3045-4591': 3, '0000-0001-7907-5133': 2, '0000-0002-4188-7766': 1, '0000-0002-0257-592X': 1, '0000-0003-2505-8420': 1, '0000-0002-2537-5904': 1, '0000-0003-1179-3096': 1, '0000-0001-9785-0180': 1})\n",
      "['0000-0003-3548-700X', '0000-0003-3234-4265', '0000-0002-2225-455X']\n",
      "Total sample size after apply threshold:  57\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 43)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 19)\n",
      "2\n",
      "(57, 62)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.56      0.58        16\n",
      "          1       0.53      0.67      0.59        24\n",
      "          2       0.58      0.41      0.48        17\n",
      "\n",
      "avg / total       0.57      0.56      0.56        57\n",
      "\n",
      "[ 9  7  0  3 16  5  3  7  7]\n",
      "MNB Accuracy:  0.5614035087719298\n",
      "MNB F1:  0.5519987915241901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.56      0.56        16\n",
      "          1       0.55      0.67      0.60        24\n",
      "          2       0.67      0.47      0.55        17\n",
      "\n",
      "avg / total       0.59      0.58      0.58        57\n",
      "\n",
      "[ 9  7  0  4 16  4  3  6  8]\n",
      "svc Accuracy:  0.5789473684210527\n",
      "svc F1:  0.5726659076122316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.56      0.58        16\n",
      "          1       0.53      0.67      0.59        24\n",
      "          2       0.58      0.41      0.48        17\n",
      "\n",
      "avg / total       0.57      0.56      0.56        57\n",
      "\n",
      "[ 9  7  0  3 16  5  3  7  7]\n",
      "LR Accuracy:  0.5614035087719298\n",
      "LR F1:  0.5519987915241901\n",
      "For name:  n_young\n",
      "total sample size before apply threshold:  182\n",
      "Counter({'0000-0002-1739-3299': 72, '0000-0001-8756-229X': 66, '0000-0002-3323-2815': 30, '0000-0002-3263-4847': 8, '0000-0002-9323-9437': 6})\n",
      "['0000-0001-8756-229X', '0000-0002-3323-2815', '0000-0002-1739-3299']\n",
      "Total sample size after apply threshold:  168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(168, 76)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(168, 22)\n",
      "2\n",
      "(168, 98)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.91      0.77        66\n",
      "          1       0.62      0.17      0.26        30\n",
      "          2       0.89      0.88      0.88        72\n",
      "\n",
      "avg / total       0.76      0.76      0.73       168\n",
      "\n",
      "[60  3  3 20  5  5  9  0 63]\n",
      "MNB Accuracy:  0.7619047619047619\n",
      "MNB F1:  0.63949010808094\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.88      0.78        66\n",
      "          1       0.53      0.27      0.36        30\n",
      "          2       0.93      0.90      0.92        72\n",
      "\n",
      "avg / total       0.77      0.78      0.76       168\n",
      "\n",
      "[58  6  2 19  8  3  6  1 65]\n",
      "svc Accuracy:  0.7797619047619048\n",
      "svc F1:  0.6831906677449734\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.86      0.77        66\n",
      "          1       0.70      0.23      0.35        30\n",
      "          2       0.86      0.90      0.88        72\n",
      "\n",
      "avg / total       0.76      0.77      0.74       168\n",
      "\n",
      "[57  3  6 18  7  5  7  0 65]\n",
      "LR Accuracy:  0.7678571428571429\n",
      "LR F1:  0.6662162162162162\n",
      "For name:  d_ross\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-8272-1877': 8, '0000-0002-8659-3833': 7, '0000-0001-7426-9561': 7, '0000-0002-5480-9978': 2, '0000-0001-6353-6951': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  q_wang\n",
      "total sample size before apply threshold:  348\n",
      "Counter({'0000-0002-2149-384X': 85, '0000-0001-7929-7692': 54, '0000-0001-9409-0251': 31, '0000-0002-7982-7275': 22, '0000-0001-5988-1293': 18, '0000-0002-5125-3724': 16, '0000-0002-6514-3470': 15, '0000-0002-1355-1616': 12, '0000-0001-7309-9580': 12, '0000-0002-2359-3262': 11, '0000-0002-0645-6514': 8, '0000-0002-9808-5035': 7, '0000-0002-4036-1818': 7, '0000-0001-7692-6721': 7, '0000-0001-8566-1120': 6, '0000-0002-6010-2178': 6, '0000-0002-9706-2421': 5, '0000-0003-2645-5807': 5, '0000-0002-6411-984X': 4, '0000-0003-3525-3422': 4, '0000-0002-8460-6821': 3, '0000-0003-3514-455X': 3, '0000-0002-0757-5208': 2, '0000-0001-7952-7101': 1, '0000-0001-5483-0243': 1, '0000-0002-6858-2778': 1, '0000-0003-3484-4810': 1, '0000-0003-3715-9106': 1})\n",
      "['0000-0002-2149-384X', '0000-0002-7982-7275', '0000-0002-2359-3262', '0000-0002-1355-1616', '0000-0001-5988-1293', '0000-0001-7309-9580', '0000-0001-9409-0251', '0000-0002-5125-3724', '0000-0001-7929-7692', '0000-0002-6514-3470']\n",
      "Total sample size after apply threshold:  276\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(276, 123)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(276, 20)\n",
      "2\n",
      "(276, 143)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.91      0.63        85\n",
      "          1       0.50      0.14      0.21        22\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.33      0.06      0.10        18\n",
      "          5       0.00      0.00      0.00        12\n",
      "          6       0.82      0.58      0.68        31\n",
      "          7       0.00      0.00      0.00        16\n",
      "          8       0.47      0.76      0.58        54\n",
      "          9       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.40      0.51      0.41       276\n",
      "\n",
      "[77  1  0  0  1  0  2  0  4  0 13  3  0  0  0  0  0  0  6  0  4  0  0  0\n",
      "  0  0  0  0  7  0  8  0  0  0  0  0  0  0  4  0 14  1  0  0  1  0  0  0\n",
      "  2  0  8  1  0  0  0  0  0  0  3  0 11  0  0  0  0  0 18  0  2  0  6  0\n",
      "  0  0  1  0  0  0  9  0 13  0  0  0  0  0  0  0 41  0  4  0  0  0  0  0\n",
      "  2  0  9  0]\n",
      "MNB Accuracy:  0.5072463768115942\n",
      "MNB F1:  0.22040742321976986\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.86      0.68        85\n",
      "          1       0.55      0.50      0.52        22\n",
      "          2       0.33      0.09      0.14        11\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       0.56      0.28      0.37        18\n",
      "          5       0.37      0.58      0.45        12\n",
      "          6       0.87      0.65      0.74        31\n",
      "          7       0.40      0.25      0.31        16\n",
      "          8       0.80      0.76      0.78        54\n",
      "          9       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.60      0.61      0.58       276\n",
      "\n",
      "[73  4  0  0  3  2  1  2  0  0  7 11  0  0  0  3  0  1  0  0  6  0  1  0\n",
      "  0  1  0  1  1  1  4  0  0  6  0  1  0  0  1  0  9  3  0  0  5  1  0  0\n",
      "  0  0  3  1  0  0  0  7  0  0  1  0  7  1  1  0  0  0 20  0  0  2  7  0\n",
      "  0  0  1  1  0  4  3  0  9  0  0  0  0  1  0  1 41  2  5  0  1  0  0  2\n",
      "  2  1  4  0]\n",
      "svc Accuracy:  0.6086956521739131\n",
      "svc F1:  0.46637718037568004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.92      0.64        85\n",
      "          1       0.50      0.18      0.27        22\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.17      0.29        12\n",
      "          4       0.00      0.00      0.00        18\n",
      "          5       0.00      0.00      0.00        12\n",
      "          6       0.88      0.68      0.76        31\n",
      "          7       1.00      0.12      0.22        16\n",
      "          8       0.54      0.70      0.61        54\n",
      "          9       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.50      0.53      0.45       276\n",
      "\n",
      "[78  1  0  0  3  0  1  0  2  0 13  4  0  0  0  2  0  0  3  0  4  0  0  0\n",
      "  0  0  0  0  6  1  6  0  0  2  0  1  0  0  3  0 14  2  0  0  0  1  0  0\n",
      "  1  0  9  1  0  0  0  0  0  0  2  0  9  0  0  0  0  0 21  0  1  0  6  0\n",
      "  0  0  0  0  0  2  7  1 14  0  0  0  0  0  0  0 38  2  4  0  0  0  0  2\n",
      "  2  0  7  0]\n",
      "LR Accuracy:  0.5253623188405797\n",
      "LR F1:  0.2795770863219543\n",
      "For name:  c_cardoso\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-6239-6651': 15, '0000-0003-3645-5368': 12, '0000-0001-7273-0676': 10, '0000-0002-9339-8075': 8, '0000-0003-3323-4447': 4, '0000-0002-7527-3973': 2, '0000-0003-1914-9553': 1})\n",
      "['0000-0001-6239-6651', '0000-0001-7273-0676', '0000-0003-3645-5368']\n",
      "Total sample size after apply threshold:  37\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 12)\n",
      "2\n",
      "(37, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.93      0.80        15\n",
      "          1       1.00      0.60      0.75        10\n",
      "          2       0.82      0.75      0.78        12\n",
      "\n",
      "avg / total       0.82      0.78      0.78        37\n",
      "\n",
      "[14  0  1  3  6  1  3  0  9]\n",
      "MNB Accuracy:  0.7837837837837838\n",
      "MNB F1:  0.7775362318840578\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      1.00      0.79        15\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.86      0.78      0.78        37\n",
      "\n",
      "[15  0  0  3  7  0  5  0  7]\n",
      "svc Accuracy:  0.7837837837837838\n",
      "svc F1:  0.7832817337461301\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.93      0.76        15\n",
      "          1       1.00      0.60      0.75        10\n",
      "          2       0.78      0.58      0.67        12\n",
      "\n",
      "avg / total       0.78      0.73      0.73        37\n",
      "\n",
      "[14  0  1  3  6  1  5  0  7]\n",
      "LR Accuracy:  0.7297297297297297\n",
      "LR F1:  0.7244744744744743\n",
      "For name:  j_matthews\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0002-9815-8636': 46, '0000-0001-6184-1813': 7, '0000-0002-5993-7610': 5, '0000-0002-1832-4420': 4, '0000-0002-7282-8929': 1, '0000-0002-6888-9438': 1, '0000-0002-3968-8282': 1})\n",
      "['0000-0002-9815-8636']\n",
      "Total sample size after apply threshold:  46\n",
      "For name:  g_lee\n",
      "total sample size before apply threshold:  202\n",
      "Counter({'0000-0001-6910-9133': 102, '0000-0002-8441-0802': 27, '0000-0001-7895-5112': 18, '0000-0002-3028-867X': 15, '0000-0001-6250-8852': 13, '0000-0002-7619-8979': 5, '0000-0002-4521-8957': 4, '0000-0003-0932-4418': 4, '0000-0003-4122-7976': 3, '0000-0002-4676-4554': 3, '0000-0002-3488-8963': 2, '0000-0002-8705-9210': 2, '0000-0002-8492-650X': 1, '0000-0002-8206-1151': 1, '0000-0002-2587-2775': 1, '0000-0002-6412-9482': 1})\n",
      "['0000-0001-6250-8852', '0000-0001-6910-9133', '0000-0002-3028-867X', '0000-0002-8441-0802', '0000-0001-7895-5112']\n",
      "Total sample size after apply threshold:  175\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 65)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 16)\n",
      "2\n",
      "(175, 81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.14        13\n",
      "          1       0.74      1.00      0.85       102\n",
      "          2       1.00      0.07      0.12        15\n",
      "          3       0.75      0.78      0.76        27\n",
      "          4       0.86      0.33      0.48        18\n",
      "\n",
      "avg / total       0.79      0.75      0.68       175\n",
      "\n",
      "[  1  11   0   1   0   0 102   0   0   0   0   9   1   4   1   0   6   0\n",
      "  21   0   0  10   0   2   6]\n",
      "MNB Accuracy:  0.7485714285714286\n",
      "MNB F1:  0.47229870129870133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.56        13\n",
      "          1       0.81      1.00      0.89       102\n",
      "          2       0.80      0.53      0.64        15\n",
      "          3       0.86      0.70      0.78        27\n",
      "          4       0.75      0.50      0.60        18\n",
      "\n",
      "avg / total       0.83      0.82      0.80       175\n",
      "\n",
      "[  5   7   0   1   0   0 102   0   0   0   0   3   8   1   3   0   8   0\n",
      "  19   0   0   6   2   1   9]\n",
      "svc Accuracy:  0.8171428571428572\n",
      "svc F1:  0.6931605203484903\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       0.70      1.00      0.83       102\n",
      "          2       1.00      0.13      0.24        15\n",
      "          3       0.81      0.63      0.71        27\n",
      "          4       0.80      0.22      0.35        18\n",
      "\n",
      "avg / total       0.78      0.73      0.67       175\n",
      "\n",
      "[  2  10   0   1   0   0 102   0   0   0   0  11   2   1   1   0  10   0\n",
      "  17   0   0  12   0   2   4]\n",
      "LR Accuracy:  0.7257142857142858\n",
      "LR F1:  0.47680622715553395\n",
      "For name:  m_salem\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-4955-0479': 12, '0000-0003-3214-3711': 9, '0000-0002-3961-7935': 3, '0000-0002-4189-857X': 1})\n",
      "['0000-0003-4955-0479']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  h_lai\n",
      "total sample size before apply threshold:  165\n",
      "Counter({'0000-0002-7958-2183': 146, '0000-0003-4334-0243': 10, '0000-0003-1834-4154': 6, '0000-0003-2521-0509': 2, '0000-0001-6044-8470': 1})\n",
      "['0000-0002-7958-2183', '0000-0003-4334-0243']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(156, 79)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(156, 25)\n",
      "2\n",
      "(156, 104)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       146\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.88      0.94      0.90       156\n",
      "\n",
      "[146   0  10   0]\n",
      "MNB Accuracy:  0.9358974358974359\n",
      "MNB F1:  0.48344370860927155\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       146\n",
      "          1       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.95      0.95      0.93       156\n",
      "\n",
      "[146   0   8   2]\n",
      "svc Accuracy:  0.9487179487179487\n",
      "svc F1:  0.6533333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       146\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.88      0.94      0.90       156\n",
      "\n",
      "[146   0  10   0]\n",
      "LR Accuracy:  0.9358974358974359\n",
      "LR F1:  0.48344370860927155\n",
      "For name:  r_harris\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0002-4377-5063': 26, '0000-0002-7943-5650': 8, '0000-0002-2636-1520': 6, '0000-0003-1787-7784': 3, '0000-0002-9247-0768': 3, '0000-0003-0954-1981': 2, '0000-0003-3322-1371': 2})\n",
      "['0000-0002-4377-5063']\n",
      "Total sample size after apply threshold:  26\n",
      "For name:  c_vaughan\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0003-4314-7689': 73, '0000-0003-3988-8222': 7, '0000-0001-8714-4442': 2, '0000-0001-9147-8648': 1})\n",
      "['0000-0003-4314-7689']\n",
      "Total sample size after apply threshold:  73\n",
      "For name:  e_thompson\n",
      "total sample size before apply threshold:  181\n",
      "Counter({'0000-0002-9723-4924': 163, '0000-0001-8633-2417': 9, '0000-0002-6434-9290': 4, '0000-0003-3506-0401': 2, '0000-0002-5615-2893': 2, '0000-0002-7115-0001': 1})\n",
      "['0000-0002-9723-4924']\n",
      "Total sample size after apply threshold:  163\n",
      "For name:  r_gomes\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-7155-0059': 15, '0000-0002-9197-8279': 10, '0000-0003-0278-4876': 10, '0000-0002-7242-6540': 6, '0000-0002-9012-3287': 6, '0000-0002-5984-0712': 4, '0000-0002-6375-7014': 1})\n",
      "['0000-0001-7155-0059', '0000-0002-9197-8279', '0000-0003-0278-4876']\n",
      "Total sample size after apply threshold:  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 11)\n",
      "2\n",
      "(35, 32)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.87      0.81        15\n",
      "          1       1.00      0.50      0.67        10\n",
      "          2       0.77      1.00      0.87        10\n",
      "\n",
      "avg / total       0.83      0.80      0.79        35\n",
      "\n",
      "[13  0  2  4  5  1  0  0 10]\n",
      "MNB Accuracy:  0.8\n",
      "MNB F1:  0.7829106280193235\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.93      0.82        15\n",
      "          1       0.83      0.50      0.62        10\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.84      0.83      0.82        35\n",
      "\n",
      "[14  1  0  5  5  0  0  0 10]\n",
      "svc Accuracy:  0.8285714285714286\n",
      "svc F1:  0.8161764705882352\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.93      0.82        15\n",
      "          1       0.83      0.50      0.62        10\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.84      0.83      0.82        35\n",
      "\n",
      "[14  1  0  5  5  0  0  0 10]\n",
      "LR Accuracy:  0.8285714285714286\n",
      "LR F1:  0.8161764705882352\n",
      "For name:  r_bennett\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-7526-3425': 74, '0000-0002-7227-4831': 11, '0000-0002-5780-8786': 3, '0000-0002-3746-367X': 3, '0000-0002-5210-1386': 1, '0000-0002-1200-2068': 1})\n",
      "['0000-0002-7526-3425', '0000-0002-7227-4831']\n",
      "Total sample size after apply threshold:  85\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 49)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 28)\n",
      "2\n",
      "(85, 77)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        74\n",
      "          1       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.91      0.89      0.86        85\n",
      "\n",
      "[74  0  9  2]\n",
      "MNB Accuracy:  0.8941176470588236\n",
      "MNB F1:  0.6251837334639883\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        74\n",
      "          1       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.97      0.96      0.96        85\n",
      "\n",
      "[74  0  3  8]\n",
      "svc Accuracy:  0.9647058823529412\n",
      "svc F1:  0.9111188567445103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        74\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.76      0.87      0.81        85\n",
      "\n",
      "[74  0 11  0]\n",
      "LR Accuracy:  0.8705882352941177\n",
      "LR F1:  0.46540880503144655\n",
      "For name:  m_collins\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-7656-4975': 20, '0000-0003-3785-6008': 14, '0000-0003-3969-5797': 9, '0000-0002-2312-3172': 6, '0000-0003-2536-4508': 6, '0000-0003-1641-848X': 2})\n",
      "['0000-0002-7656-4975', '0000-0003-3785-6008']\n",
      "Total sample size after apply threshold:  34\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 10)\n",
      "2\n",
      "(34, 31)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80        20\n",
      "          1       0.71      0.71      0.71        14\n",
      "\n",
      "avg / total       0.76      0.76      0.76        34\n",
      "\n",
      "[16  4  4 10]\n",
      "MNB Accuracy:  0.7647058823529411\n",
      "MNB F1:  0.7571428571428572\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        20\n",
      "          1       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97        34\n",
      "\n",
      "[20  0  1 13]\n",
      "svc Accuracy:  0.9705882352941176\n",
      "svc F1:  0.969286359530262\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.95      0.86        20\n",
      "          1       0.90      0.64      0.75        14\n",
      "\n",
      "avg / total       0.84      0.82      0.82        34\n",
      "\n",
      "[19  1  5  9]\n",
      "LR Accuracy:  0.8235294117647058\n",
      "LR F1:  0.8068181818181818\n",
      "For name:  m_cowley\n",
      "total sample size before apply threshold:  132\n",
      "Counter({'0000-0001-7811-134X': 57, '0000-0002-9519-5714': 49, '0000-0003-0664-2891': 17, '0000-0001-8564-4224': 9})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000-0003-0664-2891', '0000-0002-9519-5714', '0000-0001-7811-134X']\n",
      "Total sample size after apply threshold:  123\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(123, 73)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(123, 15)\n",
      "2\n",
      "(123, 88)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.30        17\n",
      "          1       0.67      0.76      0.71        49\n",
      "          2       0.72      0.82      0.77        57\n",
      "\n",
      "avg / total       0.74      0.71      0.68       123\n",
      "\n",
      "[ 3  8  6  0 37 12  0 10 47]\n",
      "MNB Accuracy:  0.7073170731707317\n",
      "MNB F1:  0.5940100882723833\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.53      0.64        17\n",
      "          1       0.69      0.86      0.76        49\n",
      "          2       0.90      0.81      0.85        57\n",
      "\n",
      "avg / total       0.81      0.79      0.79       123\n",
      "\n",
      "[ 9  8  0  2 42  5  0 11 46]\n",
      "svc Accuracy:  0.7886178861788617\n",
      "svc F1:  0.7527817861151194\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        17\n",
      "          1       0.65      0.73      0.69        49\n",
      "          2       0.73      0.81      0.77        57\n",
      "\n",
      "avg / total       0.74      0.71      0.69       123\n",
      "\n",
      "[ 5  8  4  0 36 13  0 11 46]\n",
      "LR Accuracy:  0.7073170731707317\n",
      "LR F1:  0.6378399378399379\n",
      "For name:  p_teixeira\n",
      "total sample size before apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "Counter({'0000-0002-7258-7977': 60, '0000-0002-6296-5137': 55, '0000-0001-7202-0527': 48, '0000-0003-2315-2261': 26, '0000-0003-2735-6608': 22, '0000-0002-7596-9735': 1, '0000-0002-1593-8064': 1})\n",
      "['0000-0001-7202-0527', '0000-0002-7258-7977', '0000-0003-2315-2261', '0000-0003-2735-6608', '0000-0002-6296-5137']\n",
      "Total sample size after apply threshold:  211\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(211, 84)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(211, 15)\n",
      "2\n",
      "(211, 99)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.67      0.74        48\n",
      "          1       0.62      0.95      0.75        60\n",
      "          2       0.94      0.62      0.74        26\n",
      "          3       1.00      0.18      0.31        22\n",
      "          4       0.78      0.84      0.81        55\n",
      "\n",
      "avg / total       0.79      0.73      0.71       211\n",
      "\n",
      "[32 13  0  0  3  2 57  0  0  1  1  6 16  0  3  2 10  0  4  6  2  6  1  0\n",
      " 46]\n",
      "MNB Accuracy:  0.7345971563981043\n",
      "MNB F1:  0.6689056163943261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.90      0.81        48\n",
      "          1       1.00      0.92      0.96        60\n",
      "          2       0.96      0.85      0.90        26\n",
      "          3       0.62      0.36      0.46        22\n",
      "          4       0.76      0.85      0.80        55\n",
      "\n",
      "avg / total       0.83      0.83      0.82       211\n",
      "\n",
      "[43  0  0  1  4  4 55  0  0  1  1  0 22  1  2  6  0  0  8  8  4  0  1  3\n",
      " 47]\n",
      "svc Accuracy:  0.8293838862559242\n",
      "svc F1:  0.7852726676165093\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.79      0.78        48\n",
      "          1       0.92      0.90      0.91        60\n",
      "          2       1.00      0.77      0.87        26\n",
      "          3       0.75      0.41      0.53        22\n",
      "          4       0.70      0.89      0.78        55\n",
      "\n",
      "avg / total       0.82      0.81      0.80       211\n",
      "\n",
      "[38  2  0  1  7  3 54  0  0  3  1  1 20  1  3  3  2  0  9  8  5  0  0  1\n",
      " 49]\n",
      "LR Accuracy:  0.8056872037914692\n",
      "LR F1:  0.7732100422777807\n",
      "For name:  c_cox\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0002-4927-979X': 24, '0000-0003-0625-328X': 21, '0000-0003-1074-3839': 2, '0000-0002-4486-0681': 1})\n",
      "['0000-0003-0625-328X', '0000-0002-4927-979X']\n",
      "Total sample size after apply threshold:  45\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 14)\n",
      "2\n",
      "(45, 42)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.67      0.67        21\n",
      "          1       0.71      0.71      0.71        24\n",
      "\n",
      "avg / total       0.69      0.69      0.69        45\n",
      "\n",
      "[14  7  7 17]\n",
      "MNB Accuracy:  0.6888888888888889\n",
      "MNB F1:  0.6875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.81      0.83        21\n",
      "          1       0.84      0.88      0.86        24\n",
      "\n",
      "avg / total       0.84      0.84      0.84        45\n",
      "\n",
      "[17  4  3 21]\n",
      "svc Accuracy:  0.8444444444444444\n",
      "svc F1:  0.843205574912892\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.62      0.63        21\n",
      "          1       0.68      0.71      0.69        24\n",
      "\n",
      "avg / total       0.67      0.67      0.67        45\n",
      "\n",
      "[13  8  7 17]\n",
      "LR Accuracy:  0.6666666666666666\n",
      "LR F1:  0.6640119462419114\n",
      "For name:  s_hsu\n",
      "total sample size before apply threshold:  204\n",
      "Counter({'0000-0003-3399-055X': 124, '0000-0002-7231-0185': 65, '0000-0002-8214-1696': 12, '0000-0002-8830-5305': 1, '0000-0002-6666-4665': 1, '0000-0002-7232-9839': 1})\n",
      "['0000-0002-8214-1696', '0000-0002-7231-0185', '0000-0003-3399-055X']\n",
      "Total sample size after apply threshold:  201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(201, 81)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(201, 17)\n",
      "2\n",
      "(201, 98)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.76      0.72      0.74        65\n",
      "          2       0.83      0.93      0.87       124\n",
      "\n",
      "avg / total       0.76      0.81      0.78       201\n",
      "\n",
      "[  0   6   6   0  47  18   0   9 115]\n",
      "MNB Accuracy:  0.8059701492537313\n",
      "MNB F1:  0.538227398381286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.42      0.50        12\n",
      "          1       0.98      0.72      0.83        65\n",
      "          2       0.85      0.99      0.91       124\n",
      "\n",
      "avg / total       0.88      0.87      0.86       201\n",
      "\n",
      "[  5   1   6   2  47  16   1   0 123]\n",
      "svc Accuracy:  0.8706467661691543\n",
      "svc F1:  0.7487855161145288\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.25      0.38        12\n",
      "          1       0.95      0.63      0.76        65\n",
      "          2       0.81      1.00      0.89       124\n",
      "\n",
      "avg / total       0.85      0.84      0.82       201\n",
      "\n",
      "[  3   2   7   1  41  23   0   0 124]\n",
      "LR Accuracy:  0.835820895522388\n",
      "LR F1:  0.6754485300648371\n",
      "For name:  f_williams\n",
      "total sample size before apply threshold:  149\n",
      "Counter({'0000-0002-2998-2744': 84, '0000-0002-6194-2734': 33, '0000-0002-3046-9235': 29, '0000-0003-4144-1411': 2, '0000-0001-7507-4870': 1})\n",
      "['0000-0002-2998-2744', '0000-0002-6194-2734', '0000-0002-3046-9235']\n",
      "Total sample size after apply threshold:  146\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(146, 77)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 20)\n",
      "2\n",
      "(146, 97)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.99      0.88        84\n",
      "          1       0.85      0.67      0.75        33\n",
      "          2       0.87      0.45      0.59        29\n",
      "\n",
      "avg / total       0.82      0.81      0.79       146\n",
      "\n",
      "[83  0  1 10 22  1 12  4 13]\n",
      "MNB Accuracy:  0.8082191780821918\n",
      "MNB F1:  0.738326227026792\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.98      0.89        84\n",
      "          1       1.00      0.82      0.90        33\n",
      "          2       0.84      0.55      0.67        29\n",
      "\n",
      "avg / total       0.87      0.86      0.85       146\n",
      "\n",
      "[82  0  2  5 27  1 13  0 16]\n",
      "svc Accuracy:  0.8561643835616438\n",
      "svc F1:  0.8193236714975844\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.99      0.84        84\n",
      "          1       1.00      0.64      0.78        33\n",
      "          2       0.92      0.38      0.54        29\n",
      "\n",
      "avg / total       0.83      0.79      0.77       146\n",
      "\n",
      "[83  0  1 12 21  0 18  0 11]\n",
      "LR Accuracy:  0.7876712328767124\n",
      "LR F1:  0.7190009125133553\n",
      "For name:  d_parsons\n",
      "total sample size before apply threshold:  30\n",
      "Counter({'0000-0002-3956-6031': 26, '0000-0002-1393-8431': 2, '0000-0002-9121-7859': 1, '0000-0002-5142-4466': 1})\n",
      "['0000-0002-3956-6031']\n",
      "Total sample size after apply threshold:  26\n",
      "For name:  a_choudhury\n",
      "total sample size before apply threshold:  56\n",
      "Counter({'0000-0002-3561-6580': 28, '0000-0001-5496-7346': 24, '0000-0002-7042-8139': 3, '0000-0002-8990-879X': 1})\n",
      "['0000-0001-5496-7346', '0000-0002-3561-6580']\n",
      "Total sample size after apply threshold:  52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 17)\n",
      "2\n",
      "(52, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.75      0.75        24\n",
      "          1       0.79      0.79      0.79        28\n",
      "\n",
      "avg / total       0.77      0.77      0.77        52\n",
      "\n",
      "[18  6  6 22]\n",
      "MNB Accuracy:  0.7692307692307693\n",
      "MNB F1:  0.7678571428571428\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        24\n",
      "          1       0.82      1.00      0.90        28\n",
      "\n",
      "avg / total       0.90      0.88      0.88        52\n",
      "\n",
      "[18  6  0 28]\n",
      "svc Accuracy:  0.8846153846153846\n",
      "svc F1:  0.880184331797235\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.71      0.79        24\n",
      "          1       0.79      0.93      0.85        28\n",
      "\n",
      "avg / total       0.84      0.83      0.82        52\n",
      "\n",
      "[17  7  2 26]\n",
      "LR Accuracy:  0.8269230769230769\n",
      "LR F1:  0.8215783454060236\n",
      "For name:  c_richter\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0002-5658-6173': 4, '0000-0002-6591-1118': 4, '0000-0001-6017-1520': 2, '0000-0002-6839-7994': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_hossain\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0003-1408-2273': 26, '0000-0002-1878-8145': 17, '0000-0003-3967-2544': 10, '0000-0003-3399-581X': 9, '0000-0003-3303-5755': 7, '0000-0003-1271-1515': 7, '0000-0003-4733-0018': 6, '0000-0002-9953-586X': 5, '0000-0001-8019-843X': 4, '0000-0001-7996-9233': 3, '0000-0002-1917-8701': 1, '0000-0002-0984-984X': 1, '0000-0002-7673-8410': 1, '0000-0002-0977-4593': 1, '0000-0003-2970-2324': 1, '0000-0001-6753-4216': 1, '0000-0002-3929-6211': 1, '0000-0002-6621-8737': 1})\n",
      "['0000-0003-3967-2544', '0000-0003-1408-2273', '0000-0002-1878-8145']\n",
      "Total sample size after apply threshold:  53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 12)\n",
      "2\n",
      "(53, 47)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.10      0.17        10\n",
      "          1       0.59      0.88      0.71        26\n",
      "          2       0.50      0.35      0.41        17\n",
      "\n",
      "avg / total       0.54      0.57      0.51        53\n",
      "\n",
      "[ 1  6  3  0 23  3  1 10  6]\n",
      "MNB Accuracy:  0.5660377358490566\n",
      "MNB F1:  0.42938402593575004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.20      0.31        10\n",
      "          1       0.63      1.00      0.78        26\n",
      "          2       0.67      0.35      0.46        17\n",
      "\n",
      "avg / total       0.65      0.64      0.59        53\n",
      "\n",
      "[ 2  5  3  0 26  0  1 10  6]\n",
      "svc Accuracy:  0.6415094339622641\n",
      "svc F1:  0.515116724071948\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.57      0.88      0.70        26\n",
      "          2       0.50      0.35      0.41        17\n",
      "\n",
      "avg / total       0.44      0.55      0.47        53\n",
      "\n",
      "[ 0  7  3  0 23  3  1 10  6]\n",
      "LR Accuracy:  0.5471698113207547\n",
      "LR F1:  0.37025426680599094\n",
      "For name:  v_alves\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-8430-4380': 13, '0000-0002-6182-1748': 5, '0000-0003-1819-7051': 4, '0000-0002-1485-6032': 2})\n",
      "['0000-0002-8430-4380']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  j_becker\n",
      "total sample size before apply threshold:  177\n",
      "Counter({'0000-0003-4425-4726': 122, '0000-0002-6845-6122': 45, '0000-0003-4564-3192': 4, '0000-0001-5668-1544': 3, '0000-0002-5041-5488': 2, '0000-0002-7733-4522': 1})\n",
      "['0000-0002-6845-6122', '0000-0003-4425-4726']\n",
      "Total sample size after apply threshold:  167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(167, 95)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(167, 15)\n",
      "2\n",
      "(167, 110)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.40      0.54        45\n",
      "          1       0.81      0.97      0.88       122\n",
      "\n",
      "avg / total       0.81      0.81      0.79       167\n",
      "\n",
      "[ 18  27   4 118]\n",
      "MNB Accuracy:  0.8143712574850299\n",
      "MNB F1:  0.7106042819609817\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.47      0.63        45\n",
      "          1       0.83      0.99      0.91       122\n",
      "\n",
      "avg / total       0.87      0.85      0.83       167\n",
      "\n",
      "[ 21  24   1 121]\n",
      "svc Accuracy:  0.8502994011976048\n",
      "svc F1:  0.7666163564201465\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.27      0.41        45\n",
      "          1       0.78      0.98      0.87       122\n",
      "\n",
      "avg / total       0.80      0.79      0.75       167\n",
      "\n",
      "[ 12  33   2 120]\n",
      "LR Accuracy:  0.7904191616766467\n",
      "LR F1:  0.6397534668721109\n",
      "For name:  m_soares\n",
      "total sample size before apply threshold:  247\n",
      "Counter({'0000-0001-9701-836X': 75, '0000-0002-9314-4833': 68, '0000-0001-6071-0272': 44, '0000-0003-1579-8513': 32, '0000-0002-5213-2377': 10, '0000-0001-8860-0470': 7, '0000-0003-4227-4141': 4, '0000-0002-7181-1906': 3, '0000-0002-4614-8209': 2, '0000-0002-8059-7067': 1, '0000-0002-9013-2570': 1})\n",
      "['0000-0002-5213-2377', '0000-0001-6071-0272', '0000-0003-1579-8513', '0000-0002-9314-4833', '0000-0001-9701-836X']\n",
      "Total sample size after apply threshold:  229\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(229, 120)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(229, 30)\n",
      "2\n",
      "(229, 150)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.67      0.66      0.67        44\n",
      "          2       0.66      0.59      0.62        32\n",
      "          3       0.58      0.53      0.55        68\n",
      "          4       0.67      0.85      0.75        75\n",
      "\n",
      "avg / total       0.61      0.65      0.63       229\n",
      "\n",
      "[ 0  1  0  4  5  0 29  2  8  5  0  4 19  7  2  0  7  6 36 19  0  2  2  7\n",
      " 64]\n",
      "MNB Accuracy:  0.6462882096069869\n",
      "MNB F1:  0.519280963331108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.20      0.31        10\n",
      "          1       0.78      0.64      0.70        44\n",
      "          2       0.81      0.66      0.72        32\n",
      "          3       0.59      0.88      0.71        68\n",
      "          4       0.94      0.79      0.86        75\n",
      "\n",
      "avg / total       0.77      0.74      0.74       229\n",
      "\n",
      "[ 2  1  0  5  2  0 28  1 14  1  0  1 21 10  0  0  5  2 60  1  1  1  2 12\n",
      " 59]\n",
      "svc Accuracy:  0.74235807860262\n",
      "svc F1:  0.6593923748185079\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.74      0.59      0.66        44\n",
      "          2       0.70      0.50      0.58        32\n",
      "          3       0.54      0.68      0.60        68\n",
      "          4       0.69      0.79      0.74        75\n",
      "\n",
      "avg / total       0.63      0.64      0.63       229\n",
      "\n",
      "[ 0  1  0  4  5  0 26  3 11  4  0  3 16 12  1  0  4  2 46 16  1  1  2 12\n",
      " 59]\n",
      "LR Accuracy:  0.6419213973799127\n",
      "LR F1:  0.5157706438923862\n",
      "For name:  j_yi\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0001-5299-9897': 18, '0000-0002-9296-8443': 9, '0000-0002-1025-865X': 1, '0000-0003-1718-6326': 1})\n",
      "['0000-0001-5299-9897']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  s_khan\n",
      "total sample size before apply threshold:  193\n",
      "Counter({'0000-0001-5147-145X': 61, '0000-0001-5654-2835': 42, '0000-0003-4185-8882': 29, '0000-0002-6792-3577': 7, '0000-0003-0910-4095': 7, '0000-0002-0310-0424': 6, '0000-0002-0763-2583': 6, '0000-0002-9564-5092': 5, '0000-0003-0273-1248': 5, '0000-0002-2689-8563': 4, '0000-0002-0948-5003': 4, '0000-0003-0772-6122': 4, '0000-0002-3845-541X': 3, '0000-0001-6732-768X': 2, '0000-0002-9643-6858': 2, '0000-0002-1894-7839': 1, '0000-0002-1589-6634': 1, '0000-0001-9377-6382': 1, '0000-0002-6307-2023': 1, '0000-0002-0823-4042': 1, '0000-0001-8678-2872': 1})\n",
      "['0000-0003-4185-8882', '0000-0001-5147-145X', '0000-0001-5654-2835']\n",
      "Total sample size after apply threshold:  132\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(132, 62)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(132, 13)\n",
      "2\n",
      "(132, 75)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        29\n",
      "          1       0.76      0.95      0.85        61\n",
      "          2       0.82      0.74      0.78        42\n",
      "\n",
      "avg / total       0.83      0.81      0.81       132\n",
      "\n",
      "[18  7  4  0 58  3  0 11 31]\n",
      "MNB Accuracy:  0.8106060606060606\n",
      "MNB F1:  0.795890925091888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.59      0.67        29\n",
      "          1       0.89      0.90      0.89        61\n",
      "          2       0.83      0.95      0.89        42\n",
      "\n",
      "avg / total       0.84      0.85      0.84       132\n",
      "\n",
      "[17  7  5  3 55  3  2  0 40]\n",
      "svc Accuracy:  0.8484848484848485\n",
      "svc F1:  0.8166214995483289\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        29\n",
      "          1       0.84      0.93      0.88        61\n",
      "          2       0.80      0.88      0.84        42\n",
      "\n",
      "avg / total       0.86      0.85      0.84       132\n",
      "\n",
      "[18  6  5  0 57  4  0  5 37]\n",
      "LR Accuracy:  0.8484848484848485\n",
      "LR F1:  0.8301958226500532\n",
      "For name:  a_rao\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-2676-2762': 36, '0000-0003-0320-2962': 20, '0000-0002-2550-6097': 11, '0000-0001-6440-1274': 8, '0000-0003-2319-6539': 5, '0000-0002-2474-5010': 5, '0000-0003-4480-3190': 3, '0000-0003-4879-1123': 2, '0000-0002-7983-0773': 1, '0000-0002-0220-7131': 1, '0000-0002-6531-8728': 1})\n",
      "['0000-0002-2550-6097', '0000-0003-0320-2962', '0000-0002-2676-2762']\n",
      "Total sample size after apply threshold:  67\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 41)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 21)\n",
      "2\n",
      "(67, 62)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.09      0.15        11\n",
      "          1       0.67      0.90      0.77        20\n",
      "          2       0.89      0.94      0.92        36\n",
      "\n",
      "avg / total       0.76      0.79      0.75        67\n",
      "\n",
      "[ 1  7  3  1 18  1  0  2 34]\n",
      "MNB Accuracy:  0.7910447761194029\n",
      "MNB F1:  0.6129075065245279\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.18      0.24        11\n",
      "          1       0.73      0.80      0.76        20\n",
      "          2       0.87      0.94      0.91        36\n",
      "\n",
      "avg / total       0.74      0.78      0.75        67\n",
      "\n",
      "[ 2  5  4  3 16  1  1  1 34]\n",
      "svc Accuracy:  0.7761194029850746\n",
      "svc F1:  0.6346218487394958\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.74      0.70      0.72        20\n",
      "          2       0.74      0.97      0.84        36\n",
      "\n",
      "avg / total       0.62      0.73      0.67        67\n",
      "\n",
      "[ 0  4  7  1 14  5  0  1 35]\n",
      "LR Accuracy:  0.7313432835820896\n",
      "LR F1:  0.5204407373082072\n",
      "For name:  d_cameron\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0002-5439-6544': 29, '0000-0001-6274-2913': 17, '0000-0001-7520-7741': 2, '0000-0003-2567-0564': 1})\n",
      "['0000-0002-5439-6544', '0000-0001-6274-2913']\n",
      "Total sample size after apply threshold:  46\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 24)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 16)\n",
      "2\n",
      "(46, 40)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93        29\n",
      "          1       0.93      0.82      0.87        17\n",
      "\n",
      "avg / total       0.91      0.91      0.91        46\n",
      "\n",
      "[28  1  3 14]\n",
      "MNB Accuracy:  0.9130434782608695\n",
      "MNB F1:  0.9041666666666666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        29\n",
      "          1       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.94      0.93      0.93        46\n",
      "\n",
      "[29  0  3 14]\n",
      "svc Accuracy:  0.9347826086956522\n",
      "svc F1:  0.9270227392913801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        29\n",
      "          1       1.00      0.65      0.79        17\n",
      "\n",
      "avg / total       0.89      0.87      0.86        46\n",
      "\n",
      "[29  0  6 11]\n",
      "LR Accuracy:  0.8695652173913043\n",
      "LR F1:  0.8459821428571429\n",
      "For name:  c_morgan\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0003-3131-9906': 15, '0000-0003-0931-5474': 11, '0000-0002-7511-0488': 11, '0000-0002-0118-1056': 3, '0000-0002-1508-2614': 2, '0000-0002-8191-3738': 1})\n",
      "['0000-0003-3131-9906', '0000-0003-0931-5474', '0000-0002-7511-0488']\n",
      "Total sample size after apply threshold:  37\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 12)\n",
      "2\n",
      "(37, 43)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.67      0.61        15\n",
      "          1       0.75      0.55      0.63        11\n",
      "          2       0.73      0.73      0.73        11\n",
      "\n",
      "avg / total       0.66      0.65      0.65        37\n",
      "\n",
      "[10  2  3  5  6  0  3  0  8]\n",
      "MNB Accuracy:  0.6486486486486487\n",
      "MNB F1:  0.6549707602339181\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.67      0.61        15\n",
      "          1       0.62      0.45      0.53        11\n",
      "          2       0.73      0.73      0.73        11\n",
      "\n",
      "avg / total       0.63      0.62      0.62        37\n",
      "\n",
      "[10  2  3  6  5  0  2  1  8]\n",
      "svc Accuracy:  0.6216216216216216\n",
      "svc F1:  0.6198830409356725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.67      0.59        15\n",
      "          1       0.71      0.45      0.56        11\n",
      "          2       0.73      0.73      0.73        11\n",
      "\n",
      "avg / total       0.64      0.62      0.62        37\n",
      "\n",
      "[10  2  3  6  5  0  3  0  8]\n",
      "LR Accuracy:  0.6216216216216216\n",
      "LR F1:  0.6236878589819767\n",
      "For name:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_cui\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0001-6394-4808': 11, '0000-0003-3358-8958': 10, '0000-0002-9870-748X': 9, '0000-0002-6343-1014': 9, '0000-0002-8627-8534': 1})\n",
      "['0000-0001-6394-4808', '0000-0003-3358-8958']\n",
      "Total sample size after apply threshold:  21\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 15)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 7)\n",
      "2\n",
      "(21, 22)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.91      0.87        11\n",
      "          1       0.89      0.80      0.84        10\n",
      "\n",
      "avg / total       0.86      0.86      0.86        21\n",
      "\n",
      "[10  1  2  8]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.8558352402745996\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.91      0.87        11\n",
      "          1       0.89      0.80      0.84        10\n",
      "\n",
      "avg / total       0.86      0.86      0.86        21\n",
      "\n",
      "[10  1  2  8]\n",
      "svc Accuracy:  0.8571428571428571\n",
      "svc F1:  0.8558352402745996\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82        11\n",
      "          1       0.80      0.80      0.80        10\n",
      "\n",
      "avg / total       0.81      0.81      0.81        21\n",
      "\n",
      "[9 2 2 8]\n",
      "LR Accuracy:  0.8095238095238095\n",
      "LR F1:  0.8090909090909092\n",
      "For name:  p_zhang\n",
      "total sample size before apply threshold:  137\n",
      "Counter({'0000-0002-1765-5965': 26, '0000-0003-3603-0175': 25, '0000-0003-2228-3569': 20, '0000-0002-2774-5534': 17, '0000-0002-5409-7480': 16, '0000-0001-5574-0899': 8, '0000-0002-6218-1885': 6, '0000-0002-1806-4200': 5, '0000-0001-9539-1136': 5, '0000-0003-0606-6855': 3, '0000-0001-6953-800X': 3, '0000-0002-8462-0340': 1, '0000-0001-7331-6020': 1, '0000-0003-3344-4823': 1})\n",
      "['0000-0002-5409-7480', '0000-0002-2774-5534', '0000-0003-3603-0175', '0000-0003-2228-3569', '0000-0002-1765-5965']\n",
      "Total sample size after apply threshold:  104\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(104, 40)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(104, 16)\n",
      "2\n",
      "(104, 56)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.56      0.58        16\n",
      "          1       0.53      0.53      0.53        17\n",
      "          2       0.64      0.64      0.64        25\n",
      "          3       0.54      0.65      0.59        20\n",
      "          4       0.78      0.69      0.73        26\n",
      "\n",
      "avg / total       0.63      0.62      0.63       104\n",
      "\n",
      "[ 9  3  0  4  0  1  9  2  2  3  2  1 16  4  2  2  1  4 13  0  1  3  3  1\n",
      " 18]\n",
      "MNB Accuracy:  0.625\n",
      "MNB F1:  0.6151319788912633\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.56      0.60        16\n",
      "          1       0.45      0.59      0.51        17\n",
      "          2       0.63      0.68      0.65        25\n",
      "          3       0.50      0.50      0.50        20\n",
      "          4       0.81      0.65      0.72        26\n",
      "\n",
      "avg / total       0.62      0.61      0.61       104\n",
      "\n",
      "[ 9  3  0  4  0  1 10  2  2  2  1  1 17  4  2  3  1  6 10  0  0  7  2  0\n",
      " 17]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "svc Accuracy:  0.6057692307692307\n",
      "svc F1:  0.5980141843971631\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.56      0.56        16\n",
      "          1       0.53      0.53      0.53        17\n",
      "          2       0.75      0.72      0.73        25\n",
      "          3       0.63      0.60      0.62        20\n",
      "          4       0.75      0.81      0.78        26\n",
      "\n",
      "avg / total       0.66      0.66      0.66       104\n",
      "\n",
      "[ 9  3  0  3  1  1  9  2  2  3  1  1 18  2  3  4  1  3 12  0  1  3  1  0\n",
      " 21]\n",
      "LR Accuracy:  0.6634615384615384\n",
      "LR F1:  0.6439536070838592\n",
      "For name:  j_fernandes\n",
      "total sample size before apply threshold:  208\n",
      "Counter({'0000-0002-2550-1640': 63, '0000-0003-1556-1698': 38, '0000-0001-5512-4092': 33, '0000-0002-8565-2942': 27, '0000-0002-6726-5324': 22, '0000-0002-9089-273X': 6, '0000-0001-8205-5870': 4, '0000-0001-6387-2939': 3, '0000-0002-4505-4809': 3, '0000-0001-6616-3513': 3, '0000-0003-0337-7084': 3, '0000-0003-1519-8032': 2, '0000-0003-0934-9244': 1})\n",
      "['0000-0002-2550-1640', '0000-0003-1556-1698', '0000-0002-8565-2942', '0000-0001-5512-4092', '0000-0002-6726-5324']\n",
      "Total sample size after apply threshold:  183\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(183, 93)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(183, 16)\n",
      "2\n",
      "(183, 109)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.89      0.73        63\n",
      "          1       0.55      0.29      0.38        38\n",
      "          2       0.71      0.56      0.63        27\n",
      "          3       0.57      0.85      0.68        33\n",
      "          4       0.67      0.09      0.16        22\n",
      "\n",
      "avg / total       0.62      0.61      0.57       183\n",
      "\n",
      "[56  2  0  4  1 19 11  2  6  0  4  2 15  6  0  4  1  0 28  0  7  4  4  5\n",
      "  2]\n",
      "MNB Accuracy:  0.6120218579234973\n",
      "MNB F1:  0.5158526635773458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.95      0.77        63\n",
      "          1       0.66      0.50      0.57        38\n",
      "          2       0.90      0.67      0.77        27\n",
      "          3       1.00      0.91      0.95        33\n",
      "          4       0.75      0.41      0.53        22\n",
      "\n",
      "avg / total       0.76      0.74      0.73       183\n",
      "\n",
      "[60  2  0  0  1 16 19  2  0  1  5  3 18  0  1  2  1  0 30  0  9  4  0  0\n",
      "  9]\n",
      "svc Accuracy:  0.7431693989071039\n",
      "svc F1:  0.717821578277384\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.95      0.70        63\n",
      "          1       0.46      0.34      0.39        38\n",
      "          2       0.81      0.48      0.60        27\n",
      "          3       1.00      0.82      0.90        33\n",
      "          4       0.50      0.09      0.15        22\n",
      "\n",
      "avg / total       0.65      0.63      0.59       183\n",
      "\n",
      "[60  2  0  0  1 23 13  2  0  0  6  7 13  0  1  4  2  0 27  0 15  4  1  0\n",
      "  2]\n",
      "LR Accuracy:  0.6284153005464481\n",
      "LR F1:  0.5508382193082315\n",
      "For name:  a_jain\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0001-7808-6180': 15, '0000-0003-0250-3608': 11, '0000-0001-5320-0880': 9, '0000-0003-2235-5139': 7, '0000-0003-4032-1442': 6, '0000-0002-3281-9729': 5, '0000-0003-2827-6263': 4, '0000-0001-9415-0883': 4, '0000-0001-5658-367X': 3, '0000-0002-2457-8144': 1, '0000-0002-8481-7119': 1, '0000-0002-3950-2601': 1})\n",
      "['0000-0003-0250-3608', '0000-0001-7808-6180']\n",
      "Total sample size after apply threshold:  26\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 18)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 11)\n",
      "2\n",
      "(26, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.73      0.76        11\n",
      "          1       0.81      0.87      0.84        15\n",
      "\n",
      "avg / total       0.81      0.81      0.81        26\n",
      "\n",
      "[ 8  3  2 13]\n",
      "MNB Accuracy:  0.8076923076923077\n",
      "MNB F1:  0.8003072196620584\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.83      1.00      0.91        15\n",
      "\n",
      "avg / total       0.90      0.88      0.88        26\n",
      "\n",
      "[ 8  3  0 15]\n",
      "svc Accuracy:  0.8846153846153846\n",
      "svc F1:  0.8755980861244019\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.64      0.74        11\n",
      "          1       0.78      0.93      0.85        15\n",
      "\n",
      "avg / total       0.82      0.81      0.80        26\n",
      "\n",
      "[ 7  4  1 14]\n",
      "LR Accuracy:  0.8076923076923077\n",
      "LR F1: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.7926634768740032\n",
      "For name:  d_zhang\n",
      "total sample size before apply threshold:  94\n",
      "Counter({'0000-0002-4175-5982': 17, '0000-0002-7665-2182': 12, '0000-0003-0779-6438': 11, '0000-0003-4280-0068': 8, '0000-0001-9295-4992': 7, '0000-0001-9508-8209': 7, '0000-0001-6930-5994': 6, '0000-0001-9478-5344': 6, '0000-0001-5809-0027': 5, '0000-0002-4149-4938': 4, '0000-0002-1581-2357': 4, '0000-0001-5956-4618': 2, '0000-0001-7063-7742': 2, '0000-0002-2541-837X': 1, '0000-0001-6259-7082': 1, '0000-0002-4515-2070': 1})\n",
      "['0000-0002-4175-5982', '0000-0002-7665-2182', '0000-0003-0779-6438']\n",
      "Total sample size after apply threshold:  40\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 26)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 12)\n",
      "2\n",
      "(40, 38)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.76      0.70        17\n",
      "          1       0.67      0.67      0.67        12\n",
      "          2       0.62      0.45      0.53        11\n",
      "\n",
      "avg / total       0.65      0.65      0.64        40\n",
      "\n",
      "[13  3  1  2  8  2  5  1  5]\n",
      "MNB Accuracy:  0.65\n",
      "MNB F1:  0.6318950529476846\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.82      0.74        17\n",
      "          1       0.73      0.67      0.70        12\n",
      "          2       0.62      0.45      0.53        11\n",
      "\n",
      "avg / total       0.67      0.68      0.67        40\n",
      "\n",
      "[14  2  1  2  8  2  5  1  5]\n",
      "svc Accuracy:  0.675\n",
      "svc F1:  0.6529366895499619\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.76      0.68        17\n",
      "          1       0.64      0.58      0.61        12\n",
      "          2       0.62      0.45      0.53        11\n",
      "\n",
      "avg / total       0.63      0.62      0.62        40\n",
      "\n",
      "[13  3  1  3  7  2  5  1  5]\n",
      "LR Accuracy:  0.625\n",
      "LR F1:  0.6064073226544622\n",
      "For name:  b_huang\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-9082-2216': 16, '0000-0002-1981-5838': 12, '0000-0002-1246-7447': 9, '0000-0001-6189-814X': 5, '0000-0001-5009-3928': 3, '0000-0003-2838-6315': 3})\n",
      "['0000-0001-9082-2216', '0000-0002-1981-5838']\n",
      "Total sample size after apply threshold:  28\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 18)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 8)\n",
      "2\n",
      "(28, 26)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.94      0.86        16\n",
      "          1       0.89      0.67      0.76        12\n",
      "\n",
      "avg / total       0.83      0.82      0.82        28\n",
      "\n",
      "[15  1  4  8]\n",
      "MNB Accuracy:  0.8214285714285714\n",
      "MNB F1:  0.8095238095238095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.81      0.79        16\n",
      "          1       0.73      0.67      0.70        12\n",
      "\n",
      "avg / total       0.75      0.75      0.75        28\n",
      "\n",
      "[13  3  4  8]\n",
      "svc Accuracy:  0.75\n",
      "svc F1:  0.7417654808959158\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.88      0.82        16\n",
      "          1       0.80      0.67      0.73        12\n",
      "\n",
      "avg / total       0.79      0.79      0.78        28\n",
      "\n",
      "[14  2  4  8]\n",
      "LR Accuracy:  0.7857142857142857\n",
      "LR F1:  0.7754010695187166\n",
      "For name:  m_chong"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0001-9324-5901': 20, '0000-0002-9586-6303': 20, '0000-0003-0587-2505': 1, '0000-0002-5507-1987': 1, '0000-0002-7324-1660': 1})\n",
      "['0000-0001-9324-5901', '0000-0002-9586-6303']\n",
      "Total sample size after apply threshold:  40\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 27)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 9)\n",
      "2\n",
      "(40, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.60      0.57        20\n",
      "          1       0.56      0.50      0.53        20\n",
      "\n",
      "avg / total       0.55      0.55      0.55        40\n",
      "\n",
      "[12  8 10 10]\n",
      "MNB Accuracy:  0.55\n",
      "MNB F1:  0.5488721804511277\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.55      0.61        20\n",
      "          1       0.62      0.75      0.68        20\n",
      "\n",
      "avg / total       0.66      0.65      0.65        40\n",
      "\n",
      "[11  9  5 15]\n",
      "svc Accuracy:  0.65\n",
      "svc F1:  0.6464646464646464\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.55      0.55        20\n",
      "          1       0.55      0.55      0.55        20\n",
      "\n",
      "avg / total       0.55      0.55      0.55        40\n",
      "\n",
      "[11  9  9 11]\n",
      "LR Accuracy:  0.55\n",
      "LR F1:  0.55\n",
      "For name:  m_cerqueira\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-8342-2967': 12, '0000-0002-2430-7758': 12, '0000-0001-6614-3942': 11, '0000-0002-3505-6982': 4, '0000-0001-7237-5053': 2})\n",
      "['0000-0002-8342-2967', '0000-0002-2430-7758', '0000-0001-6614-3942']\n",
      "Total sample size after apply threshold:  35\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 10)\n",
      "2\n",
      "(35, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.75      0.75        12\n",
      "          1       0.64      0.58      0.61        12\n",
      "          2       0.67      0.73      0.70        11\n",
      "\n",
      "avg / total       0.68      0.69      0.68        35\n",
      "\n",
      "[9 2 1 2 7 3 1 2 8]\n",
      "MNB Accuracy:  0.6857142857142857\n",
      "MNB F1:  0.6847826086956522\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.83      0.87        12\n",
      "          1       0.64      0.75      0.69        12\n",
      "          2       0.70      0.64      0.67        11\n",
      "\n",
      "avg / total       0.75      0.74      0.75        35\n",
      "\n",
      "[10  1  1  1  9  2  0  4  7]\n",
      "svc Accuracy:  0.7428571428571429\n",
      "svc F1:  0.7428465254552211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.83      0.87        12\n",
      "          1       0.64      0.75      0.69        12\n",
      "          2       0.70      0.64      0.67        11\n",
      "\n",
      "avg / total       0.75      0.74      0.75        35\n",
      "\n",
      "[10  2  0  0  9  3  1  3  7]\n",
      "LR Accuracy:  0.7428571428571429\n",
      "LR F1:  0.7428465254552211\n",
      "For name:  p_yang\n",
      "total sample size before apply threshold:  227\n",
      "Counter({'0000-0001-6330-6048': 102, '0000-0003-3473-4611': 46, '0000-0003-1098-3138': 17, '0000-0002-4004-2518': 17, '0000-0002-0463-1024': 14, '0000-0002-2334-5664': 10, '0000-0002-4635-1215': 6, '0000-0001-7554-5281': 5, '0000-0001-9227-3919': 4, '0000-0002-6610-1758': 3, '0000-0001-5247-1953': 1, '0000-0003-1840-6204': 1, '0000-0001-8472-0205': 1})"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['0000-0001-6330-6048', '0000-0003-3473-4611', '0000-0002-0463-1024', '0000-0003-1098-3138', '0000-0002-4004-2518', '0000-0002-2334-5664']\n",
      "Total sample size after apply threshold:  206\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(206, 113)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(206, 24)\n",
      "2\n",
      "(206, 137)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.92      0.70       102\n",
      "          1       0.83      0.54      0.66        46\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.67      0.24      0.35        17\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.52      0.60      0.52       206\n",
      "\n",
      "[94  4  0  2  2  0 21 25  0  0  0  0 14  0  0  0  0  0 13  0  0  4  0  0\n",
      " 15  1  0  0  0  1  9  0  0  0  1  0]\n",
      "MNB Accuracy:  0.5970873786407767\n",
      "MNB F1:  0.2845355601853433\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.93      0.77       102\n",
      "          1       0.91      0.65      0.76        46\n",
      "          2       1.00      0.50      0.67        14\n",
      "          3       0.80      0.47      0.59        17\n",
      "          4       0.14      0.06      0.08        17\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.67      0.68      0.65       206\n",
      "\n",
      "[95  3  0  1  3  0 16 30  0  0  0  0  7  0  7  0  0  0  8  0  0  8  0  1\n",
      " 14  0  0  0  1  2  6  0  0  1  3  0]\n",
      "svc Accuracy:  0.6844660194174758\n",
      "svc F1:  0.47803588262278884\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.93      0.71       102\n",
      "          1       0.83      0.52      0.64        46\n",
      "          2       1.00      0.07      0.13        14\n",
      "          3       0.80      0.24      0.36        17\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.60      0.60      0.53       206\n",
      "\n",
      "[95  4  0  1  2  0 22 24  0  0  0  0 13  0  1  0  0  0 13  0  0  4  0  0\n",
      " 14  1  0  0  0  2  9  0  0  0  1  0]\n",
      "LR Accuracy:  0.6019417475728155\n",
      "LR F1:  0.30765415347504893\n",
      "For name:  j_marques\n",
      "total sample size before apply threshold:  183\n",
      "Counter({'0000-0001-8865-8189': 30, '0000-0001-8157-8864': 28, '0000-0002-3800-7756': 27, '0000-0001-8910-4735': 18, '0000-0002-3457-3320': 14, '0000-0002-8124-3156': 12, '0000-0001-9436-1613': 11, '0000-0002-7234-9477': 8, '0000-0002-3724-5664': 8, '0000-0002-7333-9158': 6, '0000-0002-1014-0483': 5, '0000-0003-2199-9362': 4, '0000-0002-8740-642X': 4, '0000-0003-3429-0774': 2, '0000-0002-1644-7195': 2, '0000-0002-2523-6365': 1, '0000-0003-0972-1149': 1, '0000-0002-2354-433X': 1, '0000-0001-9834-1361': 1})\n",
      "['0000-0002-3457-3320', '0000-0002-8124-3156', '0000-0002-3800-7756', '0000-0001-8910-4735', '0000-0001-8865-8189', '0000-0001-9436-1613', '0000-0001-8157-8864']\n",
      "Total sample size after apply threshold:  140\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 62)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 19)\n",
      "2\n",
      "(140, 81)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.21      0.32        14\n",
      "          1       0.60      0.25      0.35        12\n",
      "          2       0.70      0.96      0.81        27\n",
      "          3       0.44      0.22      0.30        18\n",
      "          4       0.56      0.77      0.65        30\n",
      "          5       1.00      0.18      0.31        11\n",
      "          6       0.46      0.68      0.55        28\n",
      "\n",
      "avg / total       0.60      0.57      0.53       140\n",
      "\n",
      "[ 3  1  2  0  6  0  2  0  3  1  0  2  0  6  0  0 26  1  0  0  0  0  0  5\n",
      "  4  3  0  6  2  0  2  1 23  0  2  0  0  0  0  3  2  6  0  1  1  3  4  0\n",
      " 19]\n",
      "MNB Accuracy:  0.5714285714285714\n",
      "MNB F1:  0.46911874510974627\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.36      0.42        14\n",
      "          1       0.90      0.75      0.82        12\n",
      "          2       0.96      0.96      0.96        27\n",
      "          3       0.42      0.56      0.48        18\n",
      "          4       0.83      0.80      0.81        30\n",
      "          5       1.00      0.45      0.62        11\n",
      "          6       0.54      0.68      0.60        28\n",
      "\n",
      "avg / total       0.73      0.70      0.70       140\n",
      "\n",
      "[ 5  0  0  3  1  0  5  0  9  0  0  0  0  3  0  0 26  1  0  0  0  1  0  1\n",
      " 10  2  0  4  2  0  0  3 24  0  1  1  0  0  2  0  5  3  1  1  0  5  2  0\n",
      " 19]\n",
      "svc Accuracy:  0.7\n",
      "svc F1:  0.6736765498872036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.29      0.40        14\n",
      "          1       0.90      0.75      0.82        12\n",
      "          2       0.86      0.93      0.89        27\n",
      "          3       0.42      0.44      0.43        18\n",
      "          4       0.64      0.83      0.72        30\n",
      "          5       0.60      0.27      0.37        11\n",
      "          6       0.56      0.64      0.60        28\n",
      "\n",
      "avg / total       0.66      0.66      0.64       140\n",
      "\n",
      "[ 4  0  1  3  5  1  0  0  9  0  0  0  0  3  0  0 25  2  0  0  0  0  0  2\n",
      "  8  4  0  4  2  0  1  1 25  0  1  0  0  0  2  0  3  6  0  1  0  3  5  1\n",
      " 18]\n",
      "LR Accuracy:  0.6571428571428571\n",
      "LR F1:  0.6061584392329734\n",
      "For name:  n_ali\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0001-8121-0939': 6, '0000-0003-2063-2745': 3, '0000-0003-1245-4299': 2, '0000-0002-8292-0091': 1, '0000-0003-0858-7849': 1, '0000-0003-2924-6429': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_ng\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0002-9210-5349': 53, '0000-0001-6352-8417': 41, '0000-0002-4055-8151': 13, '0000-0001-6519-1942': 1, '0000-0003-2397-840X': 1})\n",
      "['0000-0001-6352-8417', '0000-0002-9210-5349', '0000-0002-4055-8151']\n",
      "Total sample size after apply threshold:  107\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 16)\n",
      "2\n",
      "(107, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.76      0.84        41\n",
      "          1       0.70      0.96      0.81        53\n",
      "          2       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.71      0.77      0.72       107\n",
      "\n",
      "[31 10  0  1 51  1  1 12  0]\n",
      "MNB Accuracy:  0.7663551401869159\n",
      "MNB F1:  0.5491205491205492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        41\n",
      "          1       0.90      0.89      0.90        53\n",
      "          2       0.60      0.23      0.33        13\n",
      "\n",
      "avg / total       0.83      0.85      0.83       107\n",
      "\n",
      "[41  0  0  4 47  2  5  5  3]\n",
      "svc Accuracy:  0.8504672897196262\n",
      "svc F1:  0.7098901098901099\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.88      0.84        41\n",
      "          1       0.77      0.89      0.82        53\n",
      "          2       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.69      0.78      0.73       107\n",
      "\n",
      "[36  5  0  5 47  1  4  9  0]\n",
      "LR Accuracy:  0.7757009345794392\n",
      "LR F1:  0.5539235686114511\n",
      "For name:  m_viana\n",
      "total sample size before apply threshold:  139\n",
      "Counter({'0000-0002-0464-4845': 34, '0000-0003-4356-8109': 31, '0000-0002-4073-3802': 29, '0000-0001-9665-2115': 26, '0000-0001-9288-2108': 13, '0000-0002-3074-767X': 5, '0000-0002-5657-5570': 1})\n",
      "['0000-0001-9665-2115', '0000-0003-4356-8109', '0000-0002-4073-3802', '0000-0001-9288-2108', '0000-0002-0464-4845']\n",
      "Total sample size after apply threshold:  133\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 76)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 15)\n",
      "2\n",
      "(133, 91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.77      0.85        26\n",
      "          1       0.67      0.65      0.66        31\n",
      "          2       0.71      0.86      0.78        29\n",
      "          3       1.00      0.15      0.27        13\n",
      "          4       0.64      0.85      0.73        34\n",
      "\n",
      "avg / total       0.76      0.72      0.70       133\n",
      "\n",
      "[20  3  0  0  3  1 20  5  0  5  0  1 25  0  3  0  3  3  2  5  0  3  2  0\n",
      " 29]\n",
      "MNB Accuracy:  0.7218045112781954\n",
      "MNB F1:  0.6577790833123613\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        26\n",
      "          1       0.79      0.71      0.75        31\n",
      "          2       0.89      0.86      0.88        29\n",
      "          3       0.40      0.15      0.22        13\n",
      "          4       0.55      0.82      0.66        34\n",
      "\n",
      "avg / total       0.75      0.74      0.73       133\n",
      "\n",
      "[21  0  0  0  5  0 22  1  1  7  0  1 25  0  3  0  2  1  2  8  0  3  1  2\n",
      " 28]\n",
      "svc Accuracy:  0.7368421052631579\n",
      "svc F1:  0.679523693446226\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        26\n",
      "          1       0.70      0.74      0.72        31\n",
      "          2       0.83      0.86      0.85        29\n",
      "          3       0.33      0.08      0.12        13\n",
      "          4       0.58      0.82      0.68        34\n",
      "\n",
      "avg / total       0.72      0.72      0.70       133\n",
      "\n",
      "[19  3  0  0  4  0 23  2  1  5  0  1 25  0  3  0  2  2  1  8  0  4  1  1\n",
      " 28]\n",
      "LR Accuracy:  0.7218045112781954\n",
      "LR F1:  0.6437157801662763\n",
      "For name:  t_inoue\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0002-2728-0060': 52, '0000-0003-3289-4478': 9, '0000-0002-7710-1526': 8, '0000-0003-0582-0908': 1})\n",
      "['0000-0002-2728-0060']\n",
      "Total sample size after apply threshold:  52\n",
      "For name:  b_meyer\n",
      "total sample size before apply threshold:  92\n",
      "Counter({'0000-0002-0388-9568': 60, '0000-0003-1100-0260': 25, '0000-0002-2549-1825': 3, '0000-0002-7903-5710': 2, '0000-0001-9321-1277': 1, '0000-0002-6530-4588': 1})\n",
      "['0000-0002-0388-9568', '0000-0003-1100-0260']\n",
      "Total sample size after apply threshold:  85\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 58)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 15)\n",
      "2\n",
      "(85, 73)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.93      0.85        60\n",
      "          1       0.71      0.40      0.51        25\n",
      "\n",
      "avg / total       0.77      0.78      0.75        85\n",
      "\n",
      "[56  4 15 10]\n",
      "MNB Accuracy:  0.7764705882352941\n",
      "MNB F1:  0.6838911724407908\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.97      0.88        60\n",
      "          1       0.85      0.44      0.58        25\n",
      "\n",
      "avg / total       0.82      0.81      0.79        85\n",
      "\n",
      "[58  2 14 11]\n",
      "svc Accuracy:  0.8117647058823529\n",
      "svc F1:  0.7288676236044658\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.97      0.85        60\n",
      "          1       0.75      0.24      0.36        25\n",
      "\n",
      "avg / total       0.75      0.75      0.70        85\n",
      "\n",
      "[58  2 19  6]\n",
      "LR Accuracy:  0.7529411764705882\n",
      "LR F1:  0.6051758460517584\n",
      "For name:  c_liao\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-1324-9644': 11, '0000-0001-5168-6493': 11, '0000-0001-9777-3701': 6, '0000-0003-3459-1913': 6, '0000-0003-4156-0912': 1})\n",
      "['0000-0002-1324-9644', '0000-0001-5168-6493']\n",
      "Total sample size after apply threshold:  22\n",
      "(0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 9)\n",
      "2\n",
      "(22, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.55      0.52        11\n",
      "          1       0.50      0.45      0.48        11\n",
      "\n",
      "avg / total       0.50      0.50      0.50        22\n",
      "\n",
      "[6 5 6 5]\n",
      "MNB Accuracy:  0.5\n",
      "MNB F1:  0.4989648033126294\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.55      0.52        11\n",
      "          1       0.50      0.45      0.48        11\n",
      "\n",
      "avg / total       0.50      0.50      0.50        22\n",
      "\n",
      "[6 5 6 5]\n",
      "svc Accuracy:  0.5\n",
      "svc F1:  0.4989648033126294\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.55      0.55        11\n",
      "          1       0.55      0.55      0.55        11\n",
      "\n",
      "avg / total       0.55      0.55      0.55        22\n",
      "\n",
      "[6 5 5 6]\n",
      "LR Accuracy:  0.5454545454545454\n",
      "LR F1:  0.5454545454545454\n",
      "For name:  k_wheeler\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0003-3728-8928': 18, '0000-0001-6752-7542': 6, '0000-0002-6806-4233': 2, '0000-0003-2056-9977': 2})\n",
      "['0000-0003-3728-8928']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  m_rizzo\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0002-9549-8504': 68, '0000-0002-3856-5010': 53, '0000-0001-5924-8615': 18, '0000-0002-1023-4260': 9, '0000-0003-4343-8937': 4})\n",
      "['0000-0002-9549-8504', '0000-0001-5924-8615', '0000-0002-3856-5010']\n",
      "Total sample size after apply threshold:  139\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 67)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 12)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2\n",
      "(139, 79)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92        68\n",
      "          1       1.00      0.06      0.11        18\n",
      "          2       0.78      0.89      0.83        53\n",
      "\n",
      "avg / total       0.85      0.83      0.78       139\n",
      "\n",
      "[67  0  1  5  1 12  6  0 47]\n",
      "MNB Accuracy:  0.8273381294964028\n",
      "MNB F1:  0.6183099280508216\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.90        68\n",
      "          1       0.36      0.22      0.28        18\n",
      "          2       0.88      0.83      0.85        53\n",
      "\n",
      "avg / total       0.80      0.82      0.80       139\n",
      "\n",
      "[66  2  0  8  4  6  4  5 44]\n",
      "svc Accuracy:  0.8201438848920863\n",
      "svc F1:  0.6781135300151493\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        68\n",
      "          1       0.50      0.06      0.10        18\n",
      "          2       0.82      0.89      0.85        53\n",
      "\n",
      "avg / total       0.79      0.83      0.79       139\n",
      "\n",
      "[68  0  0  7  1 10  5  1 47]\n",
      "LR Accuracy:  0.8345323741007195\n",
      "LR F1:  0.6244881244881245\n",
      "For name:  y_shi\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0001-6933-4971': 17, '0000-0003-4530-2056': 10, '0000-0003-2943-5465': 7, '0000-0001-6029-6526': 5, '0000-0001-7421-3306': 5, '0000-0001-7713-0813': 4, '0000-0003-4273-8663': 3, '0000-0001-9406-7967': 3, '0000-0003-1804-6990': 3, '0000-0002-6715-7681': 2, '0000-0002-7887-3050': 2, '0000-0001-7256-3628': 2, '0000-0001-6085-7880': 1, '0000-0003-0965-5751': 1, '0000-0001-7502-9201': 1, '0000-0002-3284-4449': 1})\n",
      "['0000-0001-6933-4971', '0000-0003-4530-2056']\n",
      "Total sample size after apply threshold:  27\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 16)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 5)\n",
      "2\n",
      "(27, 21)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.76      0.81        17\n",
      "          1       0.67      0.80      0.73        10\n",
      "\n",
      "avg / total       0.79      0.78      0.78        27\n",
      "\n",
      "[13  4  2  8]\n",
      "MNB Accuracy:  0.7777777777777778\n",
      "MNB F1:  0.7698863636363635\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.88      0.77        17\n",
      "          1       0.60      0.30      0.40        10\n",
      "\n",
      "avg / total       0.65      0.67      0.63        27\n",
      "\n",
      "[15  2  7  3]\n",
      "svc Accuracy:  0.6666666666666666\n",
      "svc F1:  0.5846153846153846\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.82      0.72        17\n",
      "          1       0.40      0.20      0.27        10\n",
      "\n",
      "avg / total       0.55      0.59      0.55        27\n",
      "\n",
      "[14  3  8  2]\n",
      "LR Accuracy:  0.5925925925925926\n",
      "LR F1:  0.49230769230769234\n",
      "For name:  c_luo\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0003-0524-5886': 36, '0000-0002-6453-7435': 18, '0000-0003-2193-3670': 15, '0000-0002-3477-5969': 5, '0000-0001-5876-5266': 1, '0000-0002-0879-3127': 1, '0000-0003-1152-0557': 1, '0000-0001-8806-1139': 1})\n",
      "['0000-0003-0524-5886', '0000-0002-6453-7435', '0000-0003-2193-3670']\n",
      "Total sample size after apply threshold:  69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 40)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 10)\n",
      "2\n",
      "(69, 50)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.94      0.86        36\n",
      "          1       0.55      0.61      0.58        18\n",
      "          2       0.50      0.20      0.29        15\n",
      "\n",
      "avg / total       0.66      0.70      0.66        69\n",
      "\n",
      "[34  1  1  5 11  2  4  8  3]\n",
      "MNB Accuracy:  0.6956521739130435\n",
      "MNB F1:  0.5751403826020749\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.86      0.84        36\n",
      "          1       0.82      0.78      0.80        18\n",
      "          2       0.43      0.40      0.41        15\n",
      "\n",
      "avg / total       0.73      0.74      0.74        69\n",
      "\n",
      "[31  1  4  0 14  4  7  2  6]\n",
      "svc Accuracy:  0.7391304347826086\n",
      "svc F1:  0.6838769804287045\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.94      0.85        36\n",
      "          1       0.59      0.56      0.57        18\n",
      "          2       0.62      0.33      0.43        15\n",
      "\n",
      "avg / total       0.69      0.71      0.69        69\n",
      "\n",
      "[34  2  0  5 10  3  5  5  5]\n",
      "LR Accuracy:  0.7101449275362319\n",
      "LR F1:  0.6187370600414078\n",
      "For name:  j_arthur\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-4796-0207': 24, '0000-0002-9185-6108': 11, '0000-0003-4540-4511': 6, '0000-0003-0344-4478': 1})\n",
      "['0000-0002-4796-0207', '0000-0002-9185-6108']\n",
      "Total sample size after apply threshold:  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 11)\n",
      "2\n",
      "(35, 30)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        24\n",
      "          1       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.92      0.91      0.91        35\n",
      "\n",
      "[24  0  3  8]\n",
      "MNB Accuracy:  0.9142857142857143\n",
      "MNB F1:  0.8916408668730651\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        24\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.90      0.89      0.88        35\n",
      "\n",
      "[24  0  4  7]\n",
      "svc Accuracy:  0.8857142857142857\n",
      "svc F1:  0.8504273504273504\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        24\n",
      "          1       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.86      0.83      0.81        35\n",
      "\n",
      "[24  0  6  5]\n",
      "LR Accuracy:  0.8285714285714286\n",
      "LR F1:  0.7569444444444444\n",
      "For name:  m_ansari\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0001-6365-7104': 9, '0000-0002-8718-3078': 8, '0000-0001-7678-4639': 7, '0000-0003-2790-8353': 5, '0000-0002-9106-0978': 3, '0000-0002-0112-238X': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  g_anderson\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0001-5087-7837': 65, '0000-0001-7545-9893': 35, '0000-0002-5768-6360': 1, '0000-0001-6544-8007': 1, '0000-0003-2046-3152': 1})\n",
      "['0000-0001-7545-9893', '0000-0001-5087-7837']\n",
      "Total sample size after apply threshold:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 58)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 18)\n",
      "2\n",
      "(100, 76)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.86      0.80        35\n",
      "          1       0.92      0.85      0.88        65\n",
      "\n",
      "avg / total       0.86      0.85      0.85       100\n",
      "\n",
      "[30  5 10 55]\n",
      "MNB Accuracy:  0.85\n",
      "MNB F1:  0.8399999999999999\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.74      0.79        35\n",
      "          1       0.87      0.92      0.90        65\n",
      "\n",
      "avg / total       0.86      0.86      0.86       100\n",
      "\n",
      "[26  9  5 60]\n",
      "svc Accuracy:  0.86\n",
      "svc F1:  0.8417005879692447\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.60      0.71        35\n",
      "          1       0.82      0.95      0.88        65\n",
      "\n",
      "avg / total       0.84      0.83      0.82       100\n",
      "\n",
      "[21 14  3 62]\n",
      "LR Accuracy:  0.83\n",
      "LR F1:  0.795648515446568\n",
      "For name:  m_hidalgo\n",
      "total sample size before apply threshold:  279\n",
      "Counter({'0000-0002-3765-3318': 238, '0000-0002-4450-3772': 31, '0000-0001-9862-6578': 5, '0000-0002-3494-9658': 3, '0000-0003-0684-0740': 2})\n",
      "['0000-0002-3765-3318', '0000-0002-4450-3772']\n",
      "Total sample size after apply threshold:  269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(269, 105)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(269, 17)\n",
      "2\n",
      "(269, 122)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       238\n",
      "          1       0.83      0.16      0.27        31\n",
      "\n",
      "avg / total       0.89      0.90      0.87       269\n",
      "\n",
      "[237   1  26   5]\n",
      "MNB Accuracy:  0.8996282527881041\n",
      "MNB F1:  0.608189027350704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       238\n",
      "          1       1.00      0.58      0.73        31\n",
      "\n",
      "avg / total       0.95      0.95      0.95       269\n",
      "\n",
      "[238   0  13  18]\n",
      "svc Accuracy:  0.9516728624535316\n",
      "svc F1:  0.854054505237678\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       238\n",
      "          1       1.00      0.10      0.18        31\n",
      "\n",
      "avg / total       0.91      0.90      0.86       269\n",
      "\n",
      "[238   0  28   3]\n",
      "LR Accuracy:  0.895910780669145\n",
      "LR F1:  0.5604575163398693\n",
      "For name:  k_jacobsen\n",
      "total sample size before apply threshold:  113\n",
      "Counter({'0000-0002-4198-6246': 93, '0000-0002-1121-2979': 17, '0000-0002-3450-0850': 2, '0000-0003-0135-0988': 1})\n",
      "['0000-0002-4198-6246', '0000-0002-1121-2979']\n",
      "Total sample size after apply threshold:  110\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(110, 68)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(110, 16)\n",
      "2\n",
      "(110, 84)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95        93\n",
      "          1       0.82      0.53      0.64        17\n",
      "\n",
      "avg / total       0.90      0.91      0.90       110\n",
      "\n",
      "[91  2  8  9]\n",
      "MNB Accuracy:  0.9090909090909091\n",
      "MNB F1:  0.7953869047619048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        93\n",
      "          1       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.97      0.96      0.96       110\n",
      "\n",
      "[93  0  4 13]\n",
      "svc Accuracy:  0.9636363636363636\n",
      "svc F1:  0.9228070175438596\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        93\n",
      "          1       1.00      0.41      0.58        17\n",
      "\n",
      "avg / total       0.92      0.91      0.89       110\n",
      "\n",
      "[93  0 10  7]\n",
      "LR Accuracy:  0.9090909090909091\n",
      "LR F1:  0.7661564625850341\n",
      "For name:  s_kelly\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0003-4002-048X': 31, '0000-0001-8583-5362': 26, '0000-0002-8245-0181': 20, '0000-0003-3533-5268': 12, '0000-0002-0375-1040': 11, '0000-0002-3078-8404': 2})\n",
      "['0000-0002-8245-0181', '0000-0001-8583-5362', '0000-0003-3533-5268', '0000-0002-0375-1040', '0000-0003-4002-048X']\n",
      "Total sample size after apply threshold:  100\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 70)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 18)\n",
      "2\n",
      "(100, 88)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.85      0.61        20\n",
      "          1       0.64      0.62      0.63        26\n",
      "          2       1.00      0.42      0.59        12\n",
      "          3       1.00      0.45      0.62        11\n",
      "          4       0.66      0.61      0.63        31\n",
      "\n",
      "avg / total       0.69      0.62      0.62       100\n",
      "\n",
      "[17  1  0  0  2  4 16  0  0  6  5  0  5  0  2  5  1  0  5  0  5  7  0  0\n",
      " 19]\n",
      "MNB Accuracy:  0.62\n",
      "MNB F1:  0.616232492997199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.80      0.60        20\n",
      "          1       0.61      0.54      0.57        26\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       0.83      0.45      0.59        11\n",
      "          4       0.69      0.65      0.67        31\n",
      "\n",
      "avg / total       0.68      0.64      0.64       100\n",
      "\n",
      "[16  1  0  1  2  5 14  0  0  7  3  0  9  0  0  5  1  0  5  0  4  7  0  0\n",
      " 20]\n",
      "svc Accuracy:  0.64\n",
      "svc F1:  0.6574493948522806\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.70      0.61        20\n",
      "          1       0.64      0.62      0.63        26\n",
      "          2       0.64      0.58      0.61        12\n",
      "          3       1.00      0.45      0.62        11\n",
      "          4       0.61      0.65      0.62        31\n",
      "\n",
      "avg / total       0.65      0.62      0.62       100\n",
      "\n",
      "[14  1  2  0  3  2 16  1  0  7  2  0  7  0  3  4  1  1  5  0  4  7  0  0\n",
      " 20]\n",
      "LR Accuracy:  0.62\n",
      "LR F1:  0.6189684569479966\n",
      "For name:  s_james\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0001-9369-3288': 29, '0000-0003-0651-9842': 13, '0000-0001-7955-0491': 8, '0000-0001-6758-5726': 7, '0000-0003-1150-0628': 1, '0000-0002-8128-2139': 1})\n",
      "['0000-0003-0651-9842', '0000-0001-9369-3288']\n",
      "Total sample size after apply threshold:  42\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 16)\n",
      "2\n",
      "(42, 44)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.97      1.00      0.98        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        42\n",
      "\n",
      "[12  1  0 29]\n",
      "MNB Accuracy:  0.9761904761904762\n",
      "MNB F1:  0.9715254237288136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.94      1.00      0.97        29\n",
      "\n",
      "avg / total       0.96      0.95      0.95        42\n",
      "\n",
      "[11  2  0 29]\n",
      "svc Accuracy:  0.9523809523809523\n",
      "svc F1:  0.9416666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.94      1.00      0.97        29\n",
      "\n",
      "avg / total       0.96      0.95      0.95        42\n",
      "\n",
      "[11  2  0 29]\n",
      "LR Accuracy:  0.9523809523809523\n",
      "LR F1:  0.9416666666666667\n",
      "For name:  p_persson\n",
      "total sample size before apply threshold:  80\n",
      "Counter({'0000-0001-9172-3068': 39, '0000-0001-7600-3230': 26, '0000-0001-9140-6724': 8, '0000-0003-4468-032X': 7})\n",
      "['0000-0001-7600-3230', '0000-0001-9172-3068']\n",
      "Total sample size after apply threshold:  65\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 16)\n",
      "2\n",
      "(65, 35)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.62      0.67        26\n",
      "          1       0.77      0.85      0.80        39\n",
      "\n",
      "avg / total       0.75      0.75      0.75        65\n",
      "\n",
      "[16 10  6 33]\n",
      "MNB Accuracy:  0.7538461538461538\n",
      "MNB F1:  0.7357723577235773\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.81      0.78        26\n",
      "          1       0.86      0.82      0.84        39\n",
      "\n",
      "avg / total       0.82      0.82      0.82        65\n",
      "\n",
      "[21  5  7 32]\n",
      "svc Accuracy:  0.8153846153846154\n",
      "svc F1:  0.8099415204678363\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.65      0.69        26\n",
      "          1       0.79      0.85      0.81        39\n",
      "\n",
      "avg / total       0.77      0.77      0.77        65\n",
      "\n",
      "[17  9  6 33]\n",
      "LR Accuracy:  0.7692307692307693\n",
      "LR F1:  0.7543461829176115\n",
      "For name:  y_tanaka\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-0674-660X': 12, '0000-0002-6190-4586': 5, '0000-0001-9598-5583': 2, '0000-0002-5163-7752': 1})\n",
      "['0000-0002-0674-660X']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  c_gao\n",
      "total sample size before apply threshold:  189\n",
      "Counter({'0000-0001-5084-7208': 144, '0000-0003-3429-3473': 17, '0000-0001-7386-692X': 13, '0000-0002-1445-7939': 11, '0000-0003-2792-5022': 2, '0000-0003-2736-3920': 1, '0000-0002-5456-451X': 1})\n",
      "['0000-0003-3429-3473', '0000-0002-1445-7939', '0000-0001-7386-692X', '0000-0001-5084-7208']\n",
      "Total sample size after apply threshold:  185\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(185, 64)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(185, 16)\n",
      "2\n",
      "(185, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.35      0.50        17\n",
      "          1       1.00      0.18      0.31        11\n",
      "          2       1.00      0.08      0.14        13\n",
      "          3       0.82      1.00      0.90       144\n",
      "\n",
      "avg / total       0.85      0.83      0.78       185\n",
      "\n",
      "[  6   0   0  11   1   2   0   8   0   0   1  12   0   0   0 144]\n",
      "MNB Accuracy:  0.827027027027027\n",
      "MNB F1:  0.46334269179096765\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.36      0.24      0.29        17\n",
      "          1       1.00      0.45      0.62        11\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       0.85      0.95      0.90       144\n",
      "\n",
      "avg / total       0.83      0.83      0.82       185\n",
      "\n",
      "[  4   0   0  13   0   5   0   6   0   0   8   5   7   0   0 137]\n",
      "svc Accuracy:  0.8324324324324325\n",
      "svc F1:  0.6427449258391882\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.12      0.21        17\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.79      1.00      0.88       144\n",
      "\n",
      "avg / total       0.70      0.79      0.70       185\n",
      "\n",
      "[  2   0   0  15   0   0   0  11   0   0   0  13   0   0   0 144]\n",
      "LR Accuracy:  0.7891891891891892\n",
      "LR F1:  0.2728150651859005\n",
      "For name:  w_jung\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0002-8697-9584': 17, '0000-0002-6853-2885': 8, '0000-0001-5266-3795': 4, '0000-0001-9590-3859': 2, '0000-0002-1615-750X': 2})\n",
      "['0000-0002-8697-9584']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  s_lewis\n",
      "total sample size before apply threshold:  306\n",
      "Counter({'0000-0003-1861-4652': 112, '0000-0002-8343-612X': 69, '0000-0002-2049-1586': 35, '0000-0003-1210-2314': 27, '0000-0003-4555-4907': 20, '0000-0001-9537-5822': 19, '0000-0002-6929-6626': 15, '0000-0001-7262-3168': 7, '0000-0003-4557-4123': 1, '0000-0002-5250-7415': 1})\n",
      "['0000-0003-4555-4907', '0000-0001-9537-5822', '0000-0002-2049-1586', '0000-0002-8343-612X', '0000-0003-1861-4652', '0000-0002-6929-6626', '0000-0003-1210-2314']\n",
      "Total sample size after apply threshold:  297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(297, 123)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(297, 30)\n",
      "2\n",
      "(297, 153)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.20      0.32        20\n",
      "          1       1.00      0.11      0.19        19\n",
      "          2       0.88      0.66      0.75        35\n",
      "          3       0.69      0.74      0.71        69\n",
      "          4       0.61      0.94      0.74       112\n",
      "          5       1.00      0.40      0.57        15\n",
      "          6       0.92      0.41      0.56        27\n",
      "\n",
      "avg / total       0.75      0.68      0.65       297\n",
      "\n",
      "[  4   0   2   3  11   0   0   0   2   0   6  11   0   0   1   0  23   4\n",
      "   7   0   0   0   0   1  51  17   0   0   0   0   0   6 105   0   1   0\n",
      "   0   0   1   8   6   0   0   0   0   3  13   0  11]\n",
      "MNB Accuracy:  0.6801346801346801\n",
      "MNB F1:  0.5504041456668697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.40      0.52        20\n",
      "          1       0.87      0.68      0.76        19\n",
      "          2       0.96      0.77      0.86        35\n",
      "          3       0.70      0.72      0.71        69\n",
      "          4       0.74      0.94      0.83       112\n",
      "          5       1.00      0.80      0.89        15\n",
      "          6       0.89      0.59      0.71        27\n",
      "\n",
      "avg / total       0.79      0.78      0.77       297\n",
      "\n",
      "[  8   0   1   3   8   0   0   0  13   0   6   0   0   0   2   0  27   1\n",
      "   5   0   0   1   2   0  50  16   0   0   0   0   0   5 105   0   2   0\n",
      "   0   0   1   2  12   0   0   0   0   5   6   0  16]\n",
      "svc Accuracy:  0.7777777777777778\n",
      "svc F1:  0.7541478770832691\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.25      0.37        20\n",
      "          1       1.00      0.11      0.19        19\n",
      "          2       0.96      0.63      0.76        35\n",
      "          3       0.76      0.74      0.75        69\n",
      "          4       0.61      0.96      0.75       112\n",
      "          5       1.00      0.60      0.75        15\n",
      "          6       0.87      0.48      0.62        27\n",
      "\n",
      "avg / total       0.76      0.70      0.68       297\n",
      "\n",
      "[  5   0   1   3  11   0   0   0   2   0   4  13   0   0   2   0  22   2\n",
      "   9   0   0   0   0   0  51  18   0   0   0   0   0   3 107   0   2   0\n",
      "   0   0   1   5   9   0   0   0   0   3  11   0  13]\n",
      "LR Accuracy:  0.7037037037037037\n",
      "LR F1:  0.5981095168287286\n",
      "For name:  w_han\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0001-9702-0523': 18, '0000-0001-8678-7147': 9, '0000-0003-2252-9311': 3, '0000-0002-4544-2908': 3, '0000-0002-7567-1883': 1})\n",
      "['0000-0001-9702-0523']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  m_shah\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0003-0299-8903': 10, '0000-0001-6126-7102': 2, '0000-0001-6599-7233': 2, '0000-0003-2191-7611': 1, '0000-0002-4354-9760': 1, '0000-0002-9740-8429': 1})\n",
      "['0000-0003-0299-8903']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  c_arango\n",
      "total sample size before apply threshold:  185\n",
      "Counter({'0000-0003-3382-4754': 177, '0000-0003-1098-830X': 6, '0000-0001-5920-5340': 1, '0000-0002-2970-4074': 1})\n",
      "['0000-0003-3382-4754']\n",
      "Total sample size after apply threshold:  177\n",
      "For name:  r_young\n",
      "total sample size before apply threshold:  361\n",
      "Counter({'0000-0002-6806-6503': 117, '0000-0001-8001-2914': 87, '0000-0002-6380-6314': 70, '0000-0001-7003-3017': 38, '0000-0001-6073-9489': 24, '0000-0002-1062-5691': 10, '0000-0002-5719-2205': 9, '0000-0001-7485-0604': 6})\n",
      "['0000-0001-8001-2914', '0000-0002-6806-6503', '0000-0001-7003-3017', '0000-0002-1062-5691', '0000-0001-6073-9489', '0000-0002-6380-6314']\n",
      "Total sample size after apply threshold:  346\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(346, 146)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(346, 38)\n",
      "2\n",
      "(346, 184)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.77      0.81        87\n",
      "          1       0.61      0.91      0.73       117\n",
      "          2       0.76      0.58      0.66        38\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.17      0.29        24\n",
      "          5       0.85      0.71      0.78        70\n",
      "\n",
      "avg / total       0.74      0.72      0.70       346\n",
      "\n",
      "[ 67  13   4   0   0   3   5 107   1   0   0   4   1  15  22   0   0   0\n",
      "   2   7   1   0   0   0   1  17   0   0   4   2   3  16   1   0   0  50]\n",
      "MNB Accuracy:  0.7225433526011561\n",
      "MNB F1:  0.5429550216776272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.84      0.85        87\n",
      "          1       0.69      0.94      0.79       117\n",
      "          2       0.81      0.58      0.68        38\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.58      0.74        24\n",
      "          5       0.93      0.76      0.83        70\n",
      "\n",
      "avg / total       0.80      0.79      0.78       346\n",
      "\n",
      "[ 73   9   2   2   0   1   3 110   1   0   0   3   2  13  22   1   0   0\n",
      "   4   5   1   0   0   0   0  10   0   0  14   0   3  13   1   0   0  53]\n",
      "svc Accuracy:  0.7861271676300579\n",
      "svc F1:  0.6485786479157833\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.77      0.81        87\n",
      "          1       0.61      0.91      0.74       117\n",
      "          2       0.80      0.53      0.63        38\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.42      0.59        24\n",
      "          5       0.88      0.74      0.81        70\n",
      "\n",
      "avg / total       0.76      0.74      0.73       346\n",
      "\n",
      "[ 67  16   3   0   0   1   4 107   1   0   0   5   2  16  20   0   0   0\n",
      "   3   7   0   0   0   0   0  13   0   0  10   1   2  15   1   0   0  52]\n",
      "LR Accuracy:  0.7398843930635838\n",
      "LR F1:  0.5961456467584213\n",
      "For name:  r_coleman\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0003-4136-5914': 15, '0000-0002-5194-8550': 13, '0000-0001-7118-524X': 3, '0000-0002-9731-7498': 3})\n",
      "['0000-0003-4136-5914', '0000-0002-5194-8550']\n",
      "Total sample size after apply threshold:  28\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 13)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 12)\n",
      "2\n",
      "(28, 25)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.80      0.83        15\n",
      "          1       0.79      0.85      0.81        13\n",
      "\n",
      "avg / total       0.82      0.82      0.82        28\n",
      "\n",
      "[12  3  2 11]\n",
      "MNB Accuracy:  0.8214285714285714\n",
      "MNB F1:  0.8212005108556832\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        15\n",
      "          1       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        28\n",
      "\n",
      "[15  0  2 11]\n",
      "svc Accuracy:  0.9285714285714286\n",
      "svc F1:  0.9270833333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        15\n",
      "          1       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.91      0.89      0.89        28\n",
      "\n",
      "[15  0  3 10]\n",
      "LR Accuracy:  0.8928571428571429\n",
      "LR F1:  0.8893280632411067\n",
      "For name:  b_kang\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0001-5902-0549': 10, '0000-0001-6946-2279': 5, '0000-0003-2637-4695': 2, '0000-0003-0901-4903': 1, '0000-0002-4299-2170': 1, '0000-0002-1690-7753': 1})\n",
      "['0000-0001-5902-0549']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  s_carter\n",
      "total sample size before apply threshold:  205\n",
      "Counter({'0000-0002-3585-9400': 124, '0000-0003-2617-8694': 44, '0000-0002-9080-519X': 15, '0000-0002-4670-0884': 12, '0000-0002-9817-0029': 5, '0000-0002-3619-8640': 2, '0000-0002-8169-4483': 2, '0000-0002-2907-9651': 1})\n",
      "['0000-0002-3585-9400', '0000-0002-4670-0884', '0000-0003-2617-8694', '0000-0002-9080-519X']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  195\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(195, 86)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(195, 29)\n",
      "2\n",
      "(195, 115)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       124\n",
      "          1       1.00      0.33      0.50        12\n",
      "          2       0.62      0.68      0.65        44\n",
      "          3       0.67      0.13      0.22        15\n",
      "\n",
      "avg / total       0.79      0.79      0.77       195\n",
      "\n",
      "[119   0   5   0   2   4   5   1  14   0  30   0   5   0   8   2]\n",
      "MNB Accuracy:  0.7948717948717948\n",
      "MNB F1:  0.568977821695213\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       124\n",
      "          1       1.00      0.58      0.74        12\n",
      "          2       0.84      0.70      0.77        44\n",
      "          3       1.00      0.33      0.50        15\n",
      "\n",
      "avg / total       0.87      0.86      0.84       195\n",
      "\n",
      "[124   0   0   0   3   7   2   0  13   0  31   0   6   0   4   5]\n",
      "svc Accuracy:  0.8564102564102564\n",
      "svc F1:  0.7301981806367772\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.99      0.87       124\n",
      "          1       1.00      0.17      0.29        12\n",
      "          2       0.72      0.52      0.61        44\n",
      "          3       1.00      0.07      0.12        15\n",
      "\n",
      "avg / total       0.79      0.76      0.71       195\n",
      "\n",
      "[123   0   1   0   8   2   2   0  21   0  23   0   8   0   6   1]\n",
      "LR Accuracy:  0.764102564102564\n",
      "LR F1:  0.47054365667690345\n",
      "For name:  c_thomas\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0003-2822-1334': 56, '0000-0001-5855-1196': 15, '0000-0003-0316-6391': 15, '0000-0001-8704-3262': 8, '0000-0003-3091-5757': 2, '0000-0002-0351-0466': 2, '0000-0001-6662-6362': 2, '0000-0001-5706-3940': 1, '0000-0001-6536-4591': 1})\n",
      "['0000-0001-5855-1196', '0000-0003-2822-1334', '0000-0003-0316-6391']\n",
      "Total sample size after apply threshold:  86\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 22)\n",
      "2\n",
      "(86, 59)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.33      0.48        15\n",
      "          1       0.73      0.98      0.84        56\n",
      "          2       1.00      0.33      0.50        15\n",
      "\n",
      "avg / total       0.80      0.76      0.72        86\n",
      "\n",
      "[ 5 10  0  1 55  0  0 10  5]\n",
      "MNB Accuracy:  0.7558139534883721\n",
      "MNB F1:  0.605295044226342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.60      0.69        15\n",
      "          1       0.81      1.00      0.90        56\n",
      "          2       1.00      0.40      0.57        15\n",
      "\n",
      "avg / total       0.85      0.83      0.80        86\n",
      "\n",
      "[ 9  6  0  0 56  0  2  7  6]\n",
      "svc Accuracy:  0.8255813953488372\n",
      "svc F1:  0.719912087912088\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        15\n",
      "          1       0.68      1.00      0.81        56\n",
      "          2       1.00      0.07      0.12        15\n",
      "\n",
      "avg / total       0.79      0.70      0.61        86\n",
      "\n",
      "[ 3 12  0  0 56  0  0 14  1]\n",
      "LR Accuracy:  0.6976744186046512\n",
      "LR F1:  0.42330917874396135\n",
      "For name:  m_gutierrez\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0003-3199-0337': 30, '0000-0003-0964-6222': 2})\n",
      "['0000-0003-3199-0337']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  s_moon\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0001-6248-9049': 30, '0000-0002-7513-4404': 20, '0000-0001-7282-2888': 16, '0000-0002-3803-6354': 16, '0000-0002-2249-7500': 1, '0000-0002-4662-7859': 1, '0000-0002-4989-0150': 1})\n",
      "['0000-0001-6248-9049', '0000-0001-7282-2888', '0000-0002-3803-6354', '0000-0002-7513-4404']\n",
      "Total sample size after apply threshold:  82\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 49)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 16)\n",
      "2\n",
      "(82, 65)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.90      0.78        30\n",
      "          1       1.00      0.38      0.55        16\n",
      "          2       0.67      0.50      0.57        16\n",
      "          3       0.56      0.70      0.62        20\n",
      "\n",
      "avg / total       0.72      0.67      0.66        82\n",
      "\n",
      "[27  0  0  3  2  6  2  6  6  0  8  2  4  0  2 14]\n",
      "MNB Accuracy:  0.6707317073170732\n",
      "MNB F1:  0.6304285086893783\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.83      0.72        30\n",
      "          1       0.69      0.56      0.62        16\n",
      "          2       0.69      0.56      0.62        16\n",
      "          3       1.00      0.85      0.92        20\n",
      "\n",
      "avg / total       0.75      0.73      0.73        82\n",
      "\n",
      "[25  3  2  0  7  9  0  0  7  0  9  0  0  1  2 17]\n",
      "svc Accuracy:  0.7317073170731707\n",
      "svc F1:  0.7212339776057917\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.90      0.75        30\n",
      "          1       0.70      0.44      0.54        16\n",
      "          2       0.80      0.50      0.62        16\n",
      "          3       0.70      0.70      0.70        20\n",
      "\n",
      "avg / total       0.70      0.68      0.67        82\n",
      "\n",
      "[27  2  0  1  6  7  0  3  6  0  8  2  3  1  2 14]\n",
      "LR Accuracy:  0.6829268292682927\n",
      "LR F1:  0.6509615384615384\n",
      "For name:  r_pereira\n",
      "total sample size before apply threshold:  202\n",
      "Counter({'0000-0001-6857-5968': 74, '0000-0003-3704-2848': 39, '0000-0002-3889-798X': 29, '0000-0002-8076-4822': 14, '0000-0002-7514-6130': 14, '0000-0003-1800-1450': 8, '0000-0001-7279-5728': 6, '0000-0003-2767-8535': 5, '0000-0003-1146-7506': 3, '0000-0003-1553-9693': 3, '0000-0001-8500-7364': 2, '0000-0002-3834-3709': 2, '0000-0002-5618-7690': 1, '0000-0002-9841-4775': 1, '0000-0002-2176-016X': 1})\n",
      "['0000-0002-8076-4822', '0000-0002-7514-6130', '0000-0002-3889-798X', '0000-0001-6857-5968', '0000-0003-3704-2848']\n",
      "Total sample size after apply threshold:  170\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(170, 80)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(170, 14)\n",
      "2\n",
      "(170, 94)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.44        14\n",
      "          1       1.00      0.07      0.13        14\n",
      "          2       0.83      0.52      0.64        29\n",
      "          3       0.55      0.96      0.70        74\n",
      "          4       0.63      0.31      0.41        39\n",
      "\n",
      "avg / total       0.69      0.61      0.56       170\n",
      "\n",
      "[ 4  0  0 10  0  0  1  0 10  3  0  0 15 12  2  0  0  1 71  2  0  0  2 25\n",
      " 12]\n",
      "MNB Accuracy:  0.6058823529411764\n",
      "MNB F1:  0.4665678101192364\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.57      0.70        14\n",
      "          1       0.89      0.57      0.70        14\n",
      "          2       0.70      0.55      0.62        29\n",
      "          3       0.77      0.85      0.81        74\n",
      "          4       0.51      0.62      0.56        39\n",
      "\n",
      "avg / total       0.72      0.70      0.70       170\n",
      "\n",
      "[ 8  0  0  3  3  0  8  0  1  5  0  0 16  6  7  1  0  2 63  8  0  1  5  9\n",
      " 24]\n",
      "svc Accuracy:  0.7\n",
      "svc F1:  0.6745041611573462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.44        14\n",
      "          1       1.00      0.14      0.25        14\n",
      "          2       0.79      0.52      0.62        29\n",
      "          3       0.58      0.97      0.72        74\n",
      "          4       0.60      0.31      0.41        39\n",
      "\n",
      "avg / total       0.69      0.62      0.57       170\n",
      "\n",
      "[ 4  0  0 10  0  0  2  1  8  3  0  0 15 10  4  0  0  1 72  1  0  0  2 25\n",
      " 12]\n",
      "LR Accuracy:  0.6176470588235294\n",
      "LR F1:  0.4899684391827311\n",
      "For name:  a_nielsen\n",
      "total sample size before apply threshold:  132\n",
      "Counter({'0000-0003-4372-9961': 70, '0000-0001-6616-0187': 27, '0000-0003-4464-8549': 17, '0000-0002-6469-4473': 7, '0000-0002-4837-9449': 3, '0000-0001-9842-5303': 2, '0000-0002-4741-7992': 2, '0000-0002-8955-9374': 2, '0000-0003-2199-2857': 1, '0000-0002-7130-6432': 1})\n",
      "['0000-0001-6616-0187', '0000-0003-4372-9961', '0000-0003-4464-8549']\n",
      "Total sample size after apply threshold:  114\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 71)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 24)\n",
      "2\n",
      "(114, 95)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.48      0.55        27\n",
      "          1       0.78      0.90      0.83        70\n",
      "          2       0.92      0.71      0.80        17\n",
      "\n",
      "avg / total       0.77      0.77      0.76       114\n",
      "\n",
      "[13 14  0  6 63  1  1  4 12]\n",
      "MNB Accuracy:  0.7719298245614035\n",
      "MNB F1:  0.7292095251514725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.52      0.62        27\n",
      "          1       0.77      0.93      0.84        70\n",
      "          2       0.92      0.65      0.76        17\n",
      "\n",
      "avg / total       0.80      0.79      0.78       114\n",
      "\n",
      "[14 13  0  4 65  1  0  6 11]\n",
      "svc Accuracy:  0.7894736842105263\n",
      "svc F1:  0.7416662520110796\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.30      0.41        27\n",
      "          1       0.72      0.96      0.82        70\n",
      "          2       1.00      0.53      0.69        17\n",
      "\n",
      "avg / total       0.75      0.74      0.71       114\n",
      "\n",
      "[ 8 19  0  3 67  0  1  7  9]\n",
      "LR Accuracy:  0.7368421052631579\n",
      "LR F1:  0.6415499973782183\n",
      "For name:  j_conde\n",
      "total sample size before apply threshold:  84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'0000-0001-8422-6792': 35, '0000-0002-2187-479X': 29, '0000-0002-5677-3024': 19, '0000-0001-8739-6893': 1})\n",
      "['0000-0001-8422-6792', '0000-0002-5677-3024', '0000-0002-2187-479X']\n",
      "Total sample size after apply threshold:  83\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(83, 47)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(83, 12)\n",
      "2\n",
      "(83, 59)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.71      0.69        35\n",
      "          1       0.60      0.47      0.53        19\n",
      "          2       0.71      0.76      0.73        29\n",
      "\n",
      "avg / total       0.67      0.67      0.67        83\n",
      "\n",
      "[25  4  6  7  9  3  5  2 22]\n",
      "MNB Accuracy:  0.6746987951807228\n",
      "MNB F1:  0.6523965141612201\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.80      0.73        35\n",
      "          1       0.75      0.63      0.69        19\n",
      "          2       0.80      0.69      0.74        29\n",
      "\n",
      "avg / total       0.73      0.72      0.72        83\n",
      "\n",
      "[28  3  4  6 12  1  8  1 20]\n",
      "svc Accuracy:  0.7228915662650602\n",
      "svc F1:  0.7179092512425846\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.71      0.65        35\n",
      "          1       0.73      0.42      0.53        19\n",
      "          2       0.63      0.66      0.64        29\n",
      "\n",
      "avg / total       0.64      0.63      0.62        83\n",
      "\n",
      "[25  2  8  8  8  3  9  1 19]\n",
      "LR Accuracy:  0.6265060240963856\n",
      "LR F1:  0.6089172597647173\n",
      "For name:  k_wright\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0003-0040-9247': 18, '0000-0002-9020-1572': 15, '0000-0003-3865-9743': 12, '0000-0002-0387-3048': 7, '0000-0001-6202-1737': 6, '0000-0003-0700-6010': 1})\n",
      "['0000-0003-0040-9247', '0000-0002-9020-1572', '0000-0003-3865-9743']\n",
      "Total sample size after apply threshold:  45\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 36)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 19)\n",
      "2\n",
      "(45, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.67      0.67        18\n",
      "          1       0.53      0.67      0.59        15\n",
      "          2       0.62      0.42      0.50        12\n",
      "\n",
      "avg / total       0.61      0.60      0.60        45\n",
      "\n",
      "[12  5  1  3 10  2  3  4  5]\n",
      "MNB Accuracy:  0.6\n",
      "MNB F1:  0.5849673202614379\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.67      0.67        18\n",
      "          1       0.59      0.67      0.62        15\n",
      "          2       0.70      0.58      0.64        12\n",
      "\n",
      "avg / total       0.65      0.64      0.64        45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[12  5  1  3 10  2  3  2  7]\n",
      "svc Accuracy:  0.6444444444444445\n",
      "svc F1:  0.6426767676767676\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.67      0.63        18\n",
      "          1       0.47      0.53      0.50        15\n",
      "          2       0.62      0.42      0.50        12\n",
      "\n",
      "avg / total       0.56      0.56      0.55        45\n",
      "\n",
      "[12  5  1  5  8  2  3  4  5]\n",
      "LR Accuracy:  0.5555555555555556\n",
      "LR F1:  0.543859649122807\n",
      "For name:  m_parker\n",
      "total sample size before apply threshold:  280\n",
      "Counter({'0000-0002-3101-1138': 232, '0000-0002-7172-5231': 13, '0000-0003-1007-4612': 11, '0000-0002-3772-3742': 10, '0000-0002-1052-9296': 6, '0000-0002-3170-3505': 4, '0000-0002-1597-4858': 3, '0000-0001-9845-9108': 1})\n",
      "['0000-0002-3101-1138', '0000-0003-1007-4612', '0000-0002-7172-5231', '0000-0002-3772-3742']\n",
      "Total sample size after apply threshold:  266\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(266, 100)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(266, 31)\n",
      "2\n",
      "(266, 131)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93       232\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.08      0.14        13\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.81      0.88      0.82       266\n",
      "\n",
      "[232   0   0   0  11   0   0   0  12   0   1   0  10   0   0   0]\n",
      "MNB Accuracy:  0.8759398496240601\n",
      "MNB F1:  0.26911468812877265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       232\n",
      "          1       0.67      0.18      0.29        11\n",
      "          2       1.00      0.46      0.63        13\n",
      "          3       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.92      0.92      0.91       266\n",
      "\n",
      "[231   1   0   0   9   2   0   0   7   0   6   0   4   0   0   6]\n",
      "svc Accuracy:  0.9210526315789473\n",
      "svc F1:  0.6559537430532854\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       232\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.15      0.27        13\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.82      0.88      0.83       266\n",
      "\n",
      "[232   0   0   0  11   0   0   0  11   0   2   0  10   0   0   0]\n",
      "LR Accuracy:  0.8796992481203008\n",
      "LR F1:  0.30053763440860215\n",
      "For name:  h_huang\n",
      "total sample size before apply threshold:  224\n",
      "Counter({'0000-0002-3386-0934': 87, '0000-0002-3382-305X': 24, '0000-0001-7640-7702': 18, '0000-0003-2657-3635': 16, '0000-0003-1461-5762': 16, '0000-0001-5497-0158': 14, '0000-0002-3778-4457': 9, '0000-0002-5647-7049': 6, '0000-0002-0919-4644': 5, '0000-0003-1743-7850': 5, '0000-0002-4564-7604': 5, '0000-0002-9665-2489': 4, '0000-0002-0534-2718': 4, '0000-0002-5948-317X': 3, '0000-0002-4104-9471': 2, '0000-0001-8346-1571': 1, '0000-0002-2650-3736': 1, '0000-0001-8237-0168': 1, '0000-0002-1188-9760': 1, '0000-0001-6455-676X': 1, '0000-0003-4184-3744': 1})\n",
      "['0000-0001-7640-7702', '0000-0002-3382-305X', '0000-0001-5497-0158', '0000-0003-2657-3635', '0000-0002-3386-0934', '0000-0003-1461-5762']\n",
      "Total sample size after apply threshold:  175\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 80)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 19)\n",
      "2\n",
      "(175, 99)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.33      0.48        18\n",
      "          1       0.44      0.29      0.35        24\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.09      0.06      0.07        16\n",
      "          4       0.59      0.94      0.73        87\n",
      "          5       0.33      0.06      0.11        16\n",
      "\n",
      "avg / total       0.48      0.55      0.48       175\n",
      "\n",
      "[ 6  3  0  1  8  0  1  7  0  1 15  0  0  2  0  3  9  0  0  2  0  1 11  2\n",
      "  0  2  0  3 82  0  0  0  0  2 13  1]\n",
      "MNB Accuracy:  0.5542857142857143\n",
      "MNB F1:  0.2897043534762833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.33      0.48        18\n",
      "          1       0.38      0.50      0.43        24\n",
      "          2       1.00      0.50      0.67        14\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.66      0.86      0.75        87\n",
      "          5       0.12      0.06      0.08        16\n",
      "\n",
      "avg / total       0.56      0.58      0.54       175\n",
      "\n",
      "[ 6  5  0  1  6  0  0 12  0  1 11  0  1  1  7  1  4  0  0  4  0  0  8  4\n",
      "  0  7  0  2 75  3  0  3  0  2 10  1]\n",
      "svc Accuracy:  0.5771428571428572\n",
      "svc F1:  0.4008066808813078\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.28      0.42        18\n",
      "          1       0.42      0.33      0.37        24\n",
      "          2       1.00      0.36      0.53        14\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.59      0.93      0.72        87\n",
      "          5       0.50      0.06      0.11        16\n",
      "\n",
      "avg / total       0.56      0.57      0.51       175\n",
      "\n",
      "[ 5  3  0  1  9  0  1  8  0  1 14  0  0  0  5  1  8  0  0  4  0  0 12  0\n",
      "  0  4  0  1 81  1  0  0  0  2 13  1]\n",
      "LR Accuracy:  0.5714285714285714\n",
      "LR F1:  0.35823347937026023\n",
      "For name:  j_terry\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-6829-5736': 35, '0000-0001-5464-8679': 20, '0000-0003-4255-5509': 1, '0000-0002-6314-1412': 1})\n",
      "['0000-0001-5464-8679', '0000-0002-6829-5736']\n",
      "Total sample size after apply threshold:  55\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 41)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 14)\n",
      "2\n",
      "(55, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.70      0.76        20\n",
      "          1       0.84      0.91      0.88        35\n",
      "\n",
      "avg / total       0.84      0.84      0.83        55\n",
      "\n",
      "[14  6  3 32]\n",
      "MNB Accuracy:  0.8363636363636363\n",
      "MNB F1:  0.81673454276194\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.80      0.84        20\n",
      "          1       0.89      0.94      0.92        35\n",
      "\n",
      "avg / total       0.89      0.89      0.89        55\n",
      "\n",
      "[16  4  2 33]\n",
      "svc Accuracy:  0.8909090909090909\n",
      "svc F1:  0.8793859649122808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.50      0.62        20\n",
      "          1       0.77      0.94      0.85        35\n",
      "\n",
      "avg / total       0.79      0.78      0.77        55\n",
      "\n",
      "[10 10  2 33]\n",
      "LR Accuracy:  0.7818181818181819\n",
      "LR F1:  0.7355769230769231\n",
      "For name:  y_xu\n",
      "total sample size before apply threshold:  137\n",
      "Counter({'0000-0002-2195-1695': 47, '0000-0002-6689-7768': 19, '0000-0002-6406-7832': 17, '0000-0001-6643-3173': 9, '0000-0002-0763-9953': 8, '0000-0002-4479-6157': 8, '0000-0001-7429-4724': 5, '0000-0002-5578-4960': 4, '0000-0002-1887-0632': 4, '0000-0002-9834-3006': 3, '0000-0002-9945-3514': 3, '0000-0001-8488-0399': 2, '0000-0001-9106-0049': 1, '0000-0003-4549-6110': 1, '0000-0002-2341-7971': 1, '0000-0003-4420-6353': 1, '0000-0002-7963-6890': 1, '0000-0002-7962-6668': 1, '0000-0003-1355-0055': 1, '0000-0002-1563-8811': 1})\n",
      "['0000-0002-6406-7832', '0000-0002-2195-1695', '0000-0002-6689-7768']\n",
      "Total sample size after apply threshold:  83\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(83, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(83, 14)\n",
      "2\n",
      "(83, 51)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.12      0.19        17\n",
      "          1       0.65      0.94      0.77        47\n",
      "          2       0.73      0.42      0.53        19\n",
      "\n",
      "avg / total       0.64      0.65      0.59        83\n",
      "\n",
      "[ 2 14  1  1 44  2  1 10  8]\n",
      "MNB Accuracy:  0.6506024096385542\n",
      "MNB F1:  0.49634230503795723\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.29      0.40        17\n",
      "          1       0.69      0.89      0.78        47\n",
      "          2       0.64      0.47      0.55        19\n",
      "\n",
      "avg / total       0.67      0.67      0.65        83\n",
      "\n",
      "[ 5 10  2  2 42  3  1  9  9]\n",
      "svc Accuracy:  0.6746987951807228\n",
      "svc F1:  0.5744107744107744\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.12      0.20        17\n",
      "          1       0.62      0.94      0.75        47\n",
      "          2       0.67      0.32      0.43        19\n",
      "\n",
      "avg / total       0.64      0.63      0.56        83\n",
      "\n",
      "[ 2 14  1  1 44  2  0 13  6]\n",
      "LR Accuracy:  0.6265060240963856\n",
      "LR F1:  0.45811138014527847\n",
      "For name:  a_melo\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-6455-7834': 26, '0000-0002-9153-0773': 11, '0000-0002-4606-7791': 7, '0000-0001-5682-2116': 4})\n",
      "['0000-0001-6455-7834', '0000-0002-9153-0773']\n",
      "Total sample size after apply threshold:  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 12)\n",
      "2\n",
      "(37, 32)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.96      0.85        26\n",
      "          1       0.75      0.27      0.40        11\n",
      "\n",
      "avg / total       0.76      0.76      0.71        37\n",
      "\n",
      "[25  1  8  3]\n",
      "MNB Accuracy:  0.7567567567567568\n",
      "MNB F1:  0.6237288135593221\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.92      0.81        26\n",
      "          1       0.50      0.18      0.27        11\n",
      "\n",
      "avg / total       0.66      0.70      0.65        37\n",
      "\n",
      "[24  2  9  2]\n",
      "svc Accuracy:  0.7027027027027027\n",
      "svc F1:  0.5401129943502825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.92      0.81        26\n",
      "          1       0.50      0.18      0.27        11\n",
      "\n",
      "avg / total       0.66      0.70      0.65        37\n",
      "\n",
      "[24  2  9  2]\n",
      "LR Accuracy:  0.7027027027027027\n",
      "LR F1:  0.5401129943502825\n",
      "For name:  r_doyle\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0001-6229-4700': 5, '0000-0001-5001-1945': 4, '0000-0003-1019-6783': 1, '0000-0002-4704-7178': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_bernardo\n",
      "total sample size before apply threshold:  250\n",
      "Counter({'0000-0001-8748-6717': 216, '0000-0002-9204-7230': 22, '0000-0002-5823-6636': 11, '0000-0003-2661-5380': 1})\n",
      "['0000-0002-9204-7230', '0000-0001-8748-6717', '0000-0002-5823-6636']\n",
      "Total sample size after apply threshold:  249\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(249, 99)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(249, 29)\n",
      "2\n",
      "(249, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.18      0.30        22\n",
      "          1       0.88      1.00      0.93       216\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.84      0.88      0.84       249\n",
      "\n",
      "[  4  18   0   1 215   0   0  11   0]\n",
      "MNB Accuracy:  0.8795180722891566\n",
      "MNB F1:  0.4103596349973162\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.32      0.47        22\n",
      "          1       0.91      1.00      0.95       216\n",
      "          2       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.92      0.92      0.90       249\n",
      "\n",
      "[  7  15   0   1 215   0   0   5   6]\n",
      "svc Accuracy:  0.9156626506024096\n",
      "svc F1:  0.7086619422343956\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.05      0.09        22\n",
      "          1       0.87      1.00      0.93       216\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.84      0.87      0.82       249\n",
      "\n",
      "[  1  21   0   0 216   0   0  11   0]\n",
      "LR Accuracy:  0.8714859437751004\n",
      "LR F1:  0.33933033483258374\n",
      "For name:  j_soares\n",
      "total sample size before apply threshold:  49"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counter({'0000-0001-6558-4973': 17, '0000-0002-2775-131X': 8, '0000-0002-7105-2815': 6, '0000-0003-3464-6208': 5, '0000-0002-7241-8719': 5, '0000-0001-8496-156X': 3, '0000-0003-3908-0741': 2, '0000-0001-5277-4575': 2, '0000-0001-6534-1824': 1})\n",
      "['0000-0001-6558-4973']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  j_richard\n",
      "total sample size before apply threshold:  179\n",
      "Counter({'0000-0002-0440-2387': 110, '0000-0003-1503-3035': 57, '0000-0001-5750-0418': 10, '0000-0003-2514-8282': 2})\n",
      "['0000-0002-0440-2387', '0000-0003-1503-3035', '0000-0001-5750-0418']\n",
      "Total sample size after apply threshold:  177\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(177, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(177, 20)\n",
      "2\n",
      "(177, 76)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91       110\n",
      "          1       0.88      0.74      0.80        57\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.81      0.85      0.82       177\n",
      "\n",
      "[109   1   0  15  42   0   5   5   0]\n",
      "MNB Accuracy:  0.8531073446327684\n",
      "MNB F1:  0.5707112970711297\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.91      0.93       110\n",
      "          1       0.79      0.91      0.85        57\n",
      "          2       0.86      0.60      0.71        10\n",
      "\n",
      "avg / total       0.90      0.89      0.89       177\n",
      "\n",
      "[100  10   0   4  52   1   0   4   6]\n",
      "svc Accuracy:  0.8926553672316384\n",
      "svc F1:  0.8286634158260219\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       110\n",
      "          1       0.85      0.77      0.81        57\n",
      "          2       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.87      0.86      0.85       177\n",
      "\n",
      "[107   3   0  13  44   0   3   5   2]\n",
      "LR Accuracy:  0.864406779661017\n",
      "LR F1:  0.6863759061656451\n",
      "For name:  p_robinson\n",
      "total sample size before apply threshold:  275\n",
      "Counter({'0000-0002-7878-0313': 133, '0000-0002-0736-9199': 119, '0000-0002-3156-3418': 19, '0000-0002-0577-3147': 4})\n",
      "['0000-0002-0736-9199', '0000-0002-7878-0313', '0000-0002-3156-3418']\n",
      "Total sample size after apply threshold:  271\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(271, 143)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(271, 32)\n",
      "2\n",
      "(271, 175)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.87      0.77       119\n",
      "          1       0.78      0.71      0.74       133\n",
      "          2       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.69      0.73      0.70       271\n",
      "\n",
      "[104  15   0  39  94   0   8  11   0]\n",
      "MNB Accuracy:  0.7306273062730627\n",
      "MNB F1:  0.5044844581076465\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.82      0.76       119\n",
      "          1       0.75      0.74      0.75       133\n",
      "          2       0.33      0.05      0.09        19\n",
      "\n",
      "avg / total       0.71      0.73      0.71       271\n",
      "\n",
      "[98 21  0 33 98  2  7 11  1]\n",
      "svc Accuracy:  0.7269372693726938\n",
      "svc F1:  0.532934051198317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.73      0.72       119\n",
      "          1       0.70      0.77      0.74       133\n",
      "          2       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.65      0.70      0.68       271\n",
      "\n",
      "[ 87  32   0  30 103   0   7  12   0]\n",
      "LR Accuracy:  0.7011070110701108\n",
      "LR F1:  0.48392122281011174\n",
      "For name:  c_zou\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0003-2484-7292': 22, '0000-0001-8569-3747': 8, '0000-0003-4305-5055': 1, '0000-0002-9712-4282': 1})\n",
      "['0000-0003-2484-7292']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  s_rana\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-8039-1149': 30, '0000-0001-9197-8378': 9, '0000-0003-0628-7076': 2, '0000-0002-6604-997X': 1})\n",
      "['0000-0002-8039-1149']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  a_nunes\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0003-2760-3277': 18, '0000-0001-9102-3600': 11, '0000-0001-8893-9247': 9, '0000-0001-8844-8333': 5, '0000-0002-3296-0183': 5, '0000-0002-0595-5821': 4, '0000-0002-5001-3534': 2, '0000-0002-4789-0253': 2, '0000-0003-4440-0391': 2, '0000-0001-6847-5764': 2, '0000-0001-8665-4459': 1})\n",
      "['0000-0001-9102-3600', '0000-0003-2760-3277']\n",
      "Total sample size after apply threshold:  29\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 16)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 11)\n",
      "2\n",
      "(29, 27)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.86      1.00      0.92        18\n",
      "\n",
      "avg / total       0.91      0.90      0.89        29\n",
      "\n",
      "[ 8  3  0 18]\n",
      "MNB Accuracy:  0.896551724137931\n",
      "MNB F1:  0.8825910931174089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82        11\n",
      "          1       0.89      0.89      0.89        18\n",
      "\n",
      "avg / total       0.86      0.86      0.86        29\n",
      "\n",
      "[ 9  2  2 16]\n",
      "svc Accuracy:  0.8620689655172413\n",
      "svc F1:  0.8535353535353536\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.86      1.00      0.92        18\n",
      "\n",
      "avg / total       0.91      0.90      0.89        29\n",
      "\n",
      "[ 8  3  0 18]\n",
      "LR Accuracy:  0.896551724137931\n",
      "LR F1:  0.8825910931174089\n",
      "For name:  s_jeong\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0001-6178-8338': 33, '0000-0002-1958-8436': 21, '0000-0002-6376-7001': 13, '0000-0002-6480-7685': 7, '0000-0002-9084-5183': 6, '0000-0001-8995-3497': 5, '0000-0002-8370-3566': 1, '0000-0002-4004-3510': 1, '0000-0001-9175-9642': 1, '0000-0001-9197-1184': 1, '0000-0002-9868-621X': 1, '0000-0002-3309-0693': 1, '0000-0001-9575-0354': 1, '0000-0001-9588-1928': 1})\n",
      "['0000-0002-6376-7001', '0000-0002-1958-8436', '0000-0001-6178-8338']\n",
      "Total sample size after apply threshold:  67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 15)\n",
      "2\n",
      "(67, 54)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.23      0.35        13\n",
      "          1       0.92      0.57      0.71        21\n",
      "          2       0.66      1.00      0.80        33\n",
      "\n",
      "avg / total       0.76      0.72      0.68        67\n",
      "\n",
      "[ 3  1  9  1 12  8  0  0 33]\n",
      "MNB Accuracy:  0.7164179104477612\n",
      "MNB F1:  0.6180014174344436\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.46      0.60        13\n",
      "          1       0.87      0.62      0.72        21\n",
      "          2       0.69      0.94      0.79        33\n",
      "\n",
      "avg / total       0.78      0.75      0.73        67\n",
      "\n",
      "[ 6  0  7  1 13  7  0  2 31]\n",
      "svc Accuracy:  0.746268656716418\n",
      "svc F1:  0.7056980056980057\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.23      0.35        13\n",
      "          1       0.86      0.57      0.69        21\n",
      "          2       0.65      0.97      0.78        33\n",
      "\n",
      "avg / total       0.74      0.70      0.67        67\n",
      "\n",
      "[ 3  1  9  1 12  8  0  1 32]\n",
      "LR Accuracy:  0.7014925373134329\n",
      "LR F1:  0.6063810890209742\n",
      "For name:  b_olsen\n",
      "total sample size before apply threshold:  213\n",
      "Counter({'0000-0002-4646-691X': 167, '0000-0002-7272-7140': 35, '0000-0001-9758-3641': 6, '0000-0001-5608-2779': 3, '0000-0002-6551-6812': 2})\n",
      "['0000-0002-7272-7140', '0000-0002-4646-691X']\n",
      "Total sample size after apply threshold:  202\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(202, 76)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(202, 23)\n",
      "2\n",
      "(202, 99)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.54      0.67        35\n",
      "          1       0.91      0.98      0.95       167\n",
      "\n",
      "avg / total       0.90      0.91      0.90       202\n",
      "\n",
      "[ 19  16   3 164]\n",
      "MNB Accuracy:  0.905940594059406\n",
      "MNB F1:  0.8059558117195005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        35\n",
      "          1       0.94      1.00      0.97       167\n",
      "\n",
      "avg / total       0.95      0.95      0.95       202\n",
      "\n",
      "[ 25  10   0 167]\n",
      "svc Accuracy:  0.9504950495049505\n",
      "svc F1:  0.9021317829457365\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.34      0.51        35\n",
      "          1       0.88      1.00      0.94       167\n",
      "\n",
      "avg / total       0.90      0.89      0.86       202\n",
      "\n",
      "[ 12  23   0 167]\n",
      "LR Accuracy:  0.8861386138613861\n",
      "LR F1:  0.7231062637821086\n",
      "For name:  m_reilly\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0001-8029-0084': 17, '0000-0002-5526-8245': 1, '0000-0001-8746-3224': 1, '0000-0003-2506-3190': 1})\n",
      "['0000-0001-8029-0084']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  d_nguyen\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-4997-555X': 8, '0000-0002-3283-3504': 7, '0000-0001-6420-7308': 3, '0000-0002-6811-5897': 2, '0000-0001-6432-4467': 2, '0000-0002-1694-0617': 1, '0000-0001-7720-3592': 1, '0000-0002-9680-5772': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_santos\n",
      "total sample size before apply threshold:  184\n",
      "Counter({'0000-0003-3737-8296': 33, '0000-0002-1577-1663': 29, '0000-0001-5071-443X': 20, '0000-0002-3085-5128': 16, '0000-0001-7720-6806': 13, '0000-0002-7394-7604': 13, '0000-0002-4830-0470': 11, '0000-0001-6182-1708': 8, '0000-0002-7604-5753': 7, '0000-0001-5240-6799': 6, '0000-0003-0126-7420': 6, '0000-0002-8368-8618': 4, '0000-0001-8183-9649': 4, '0000-0001-6071-8100': 4, '0000-0002-0070-5735': 2, '0000-0003-4395-8078': 2, '0000-0001-7922-5357': 1, '0000-0002-9133-2187': 1, '0000-0002-7861-4366': 1, '0000-0002-5431-4756': 1, '0000-0001-6328-8097': 1, '0000-0001-5845-5698': 1})\n",
      "['0000-0003-3737-8296', '0000-0002-4830-0470', '0000-0001-7720-6806', '0000-0001-5071-443X', '0000-0002-1577-1663', '0000-0002-3085-5128', '0000-0002-7394-7604']\n",
      "Total sample size after apply threshold:  135\n",
      "(0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(135, 87)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(135, 29)\n",
      "2\n",
      "(135, 116)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.94      0.58        33\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.23      0.38        13\n",
      "          3       0.62      0.25      0.36        20\n",
      "          4       0.55      0.72      0.63        29\n",
      "          5       0.71      0.31      0.43        16\n",
      "          6       0.80      0.31      0.44        13\n",
      "\n",
      "avg / total       0.57      0.51      0.46       135\n",
      "\n",
      "[31  0  0  0  1  0  1  4  0  0  0  7  0  0 10  0  3  0  0  0  0  9  0  0\n",
      "  5  6  0  0  3  0  0  3 21  2  0  8  0  0  0  3  5  0  9  0  0  0  0  0\n",
      "  4]\n",
      "MNB Accuracy:  0.5111111111111111\n",
      "MNB F1:  0.4025249763230277\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.94      0.66        33\n",
      "          1       0.67      0.18      0.29        11\n",
      "          2       1.00      0.46      0.63        13\n",
      "          3       0.73      0.40      0.52        20\n",
      "          4       0.62      0.79      0.70        29\n",
      "          5       0.67      0.38      0.48        16\n",
      "          6       0.88      0.54      0.67        13\n",
      "\n",
      "avg / total       0.68      0.61      0.59       135\n",
      "\n",
      "[31  0  0  0  1  0  1  3  2  0  0  5  1  0  7  0  6  0  0  0  0  7  0  0\n",
      "  8  5  0  0  0  1  0  3 23  2  0  7  0  0  0  3  6  0  6  0  0  0  0  0\n",
      "  7]\n",
      "svc Accuracy:  0.6148148148148148\n",
      "svc F1:  0.5623761567231773\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.94      0.63        33\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.23      0.38        13\n",
      "          3       0.62      0.25      0.36        20\n",
      "          4       0.56      0.86      0.68        29\n",
      "          5       0.83      0.31      0.45        16\n",
      "          6       0.86      0.46      0.60        13\n",
      "\n",
      "avg / total       0.60      0.56      0.50       135\n",
      "\n",
      "[31  0  0  0  1  0  1  3  0  0  0  8  0  0 10  0  3  0  0  0  0  9  0  0\n",
      "  5  6  0  0  0  0  0  3 25  1  0  6  0  0  0  5  5  0  7  0  0  0  0  0\n",
      "  6]\n",
      "LR Accuracy:  0.5555555555555556\n",
      "LR F1:  0.4412323733752306\n",
      "For name:  f_ferreira\n",
      "total sample size before apply threshold:  224\n",
      "Counter({'0000-0003-0989-2335': 125, '0000-0002-7571-1830': 18, '0000-0002-9160-7355': 18, '0000-0001-5765-576X': 16, '0000-0003-1516-1221': 15, '0000-0003-3326-1250': 12, '0000-0001-9616-295X': 5, '0000-0001-8714-2615': 5, '0000-0001-5177-6237': 4, '0000-0002-8857-2438': 3, '0000-0001-5815-2136': 2, '0000-0001-8818-6521': 1})\n",
      "['0000-0003-0989-2335', '0000-0003-1516-1221', '0000-0002-7571-1830', '0000-0003-3326-1250', '0000-0001-5765-576X', '0000-0002-9160-7355']\n",
      "Total sample size after apply threshold:  204\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(204, 97)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(204, 21)\n",
      "2\n",
      "(204, 118)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      1.00      0.81       125\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       1.00      0.28      0.43        18\n",
      "          3       1.00      0.17      0.29        12\n",
      "          4       0.67      0.62      0.65        16\n",
      "          5       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.62      0.70      0.60       204\n",
      "\n",
      "[125   0   0   0   0   0  12   0   0   0   3   0  11   0   5   0   2   0\n",
      "  10   0   0   2   0   0   6   0   0   0  10   0  18   0   0   0   0   0]\n",
      "MNB Accuracy:  0.696078431372549\n",
      "MNB F1:  0.36333173871492025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.98      0.87       125\n",
      "          1       1.00      0.40      0.57        15\n",
      "          2       1.00      0.72      0.84        18\n",
      "          3       0.67      0.17      0.27        12\n",
      "          4       0.67      0.75      0.71        16\n",
      "          5       1.00      0.28      0.43        18\n",
      "\n",
      "avg / total       0.82      0.79      0.76       204\n",
      "\n",
      "[123   0   0   1   1   0   6   6   0   0   3   0   3   0  13   0   2   0\n",
      "  10   0   0   2   0   0   4   0   0   0  12   0  13   0   0   0   0   5]\n",
      "svc Accuracy:  0.7892156862745098\n",
      "svc F1:  0.613944510041669\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      1.00      0.81       125\n",
      "          1       1.00      0.07      0.12        15\n",
      "          2       1.00      0.50      0.67        18\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.67      0.50      0.57        16\n",
      "          5       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.63      0.70      0.61       204\n",
      "\n",
      "[125   0   0   0   0   0  11   1   0   0   3   0   8   0   9   0   1   0\n",
      "  12   0   0   0   0   0   8   0   0   0   8   0  18   0   0   0   0   0]\n",
      "LR Accuracy:  0.7009803921568627\n",
      "LR F1:  0.3629045809420402\n",
      "For name:  y_ng\n",
      "total sample size before apply threshold:  19\n",
      "Counter({'0000-0003-4598-1829': 11, '0000-0001-9142-2126': 4, '0000-0002-7140-1616': 2, '0000-0002-4590-3364': 1, '0000-0002-7213-5030': 1})\n",
      "['0000-0003-4598-1829']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  j_madsen\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0001-7625-9498': 28, '0000-0003-1664-7645': 24, '0000-0003-1411-9080': 8, '0000-0003-3246-0215': 8, '0000-0002-6874-2970': 1})\n",
      "['0000-0001-7625-9498', '0000-0003-1664-7645']\n",
      "Total sample size after apply threshold:  52\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 15)\n",
      "2\n",
      "(52, 52)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.86      0.81        28\n",
      "          1       0.81      0.71      0.76        24\n",
      "\n",
      "avg / total       0.79      0.79      0.79        52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[24  4  7 17]\n",
      "MNB Accuracy:  0.7884615384615384\n",
      "MNB F1:  0.784557438794727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.79      0.81        28\n",
      "          1       0.77      0.83      0.80        24\n",
      "\n",
      "avg / total       0.81      0.81      0.81        52\n",
      "\n",
      "[22  6  4 20]\n",
      "svc Accuracy:  0.8076923076923077\n",
      "svc F1:  0.8074074074074074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.75      0.76        28\n",
      "          1       0.72      0.75      0.73        24\n",
      "\n",
      "avg / total       0.75      0.75      0.75        52\n",
      "\n",
      "[21  7  6 18]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.7491651205936921\n",
      "For name:  d_collins\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-6754-9290': 8, '0000-0002-6248-9644': 7, '0000-0002-3283-0733': 6, '0000-0003-2274-0889': 5, '0000-0003-2484-1640': 2, '0000-0002-8432-7021': 1, '0000-0001-8891-1893': 1, '0000-0002-7981-3586': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  l_davies\n",
      "total sample size before apply threshold:  96\n",
      "Counter({'0000-0001-8801-3559': 62, '0000-0002-0451-8670': 19, '0000-0002-4876-6270': 11, '0000-0002-2986-705X': 4})\n",
      "['0000-0001-8801-3559', '0000-0002-4876-6270', '0000-0002-0451-8670']\n",
      "Total sample size after apply threshold:  92\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(92, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(92, 25)\n",
      "2\n",
      "(92, 81)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.97      0.89        62\n",
      "          1       1.00      0.18      0.31        11\n",
      "          2       0.82      0.74      0.78        19\n",
      "\n",
      "avg / total       0.84      0.83      0.80        92\n",
      "\n",
      "[60  0  2  8  2  1  5  0 14]\n",
      "MNB Accuracy:  0.8260869565217391\n",
      "MNB F1:  0.6581196581196581\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92        62\n",
      "          1       0.67      0.36      0.47        11\n",
      "          2       1.00      0.79      0.88        19\n",
      "\n",
      "avg / total       0.87      0.87      0.86        92\n",
      "\n",
      "[61  1  0  7  4  0  3  1 15]\n",
      "svc Accuracy:  0.8695652173913043\n",
      "svc F1:  0.7567448031844316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        62\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.53      0.69        19\n",
      "\n",
      "avg / total       0.72      0.78      0.72        92\n",
      "\n",
      "[62  0  0 11  0  0  9  0 10]\n",
      "LR Accuracy:  0.782608695652174\n",
      "LR F1:  0.5169220945083014\n",
      "For name:  m_mora\n",
      "total sample size before apply threshold:  131\n",
      "Counter({'0000-0002-5765-2320': 104, '0000-0002-8393-0216': 22, '0000-0002-2979-3601': 4, '0000-0003-0627-6764': 1})\n",
      "['0000-0002-8393-0216', '0000-0002-5765-2320']\n",
      "Total sample size after apply threshold:  126\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(126, 60)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(126, 27)\n",
      "2\n",
      "(126, 87)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.59      0.68        22\n",
      "          1       0.92      0.97      0.94       104\n",
      "\n",
      "avg / total       0.90      0.90      0.90       126\n",
      "\n",
      "[ 13   9   3 101]\n",
      "MNB Accuracy:  0.9047619047619048\n",
      "MNB F1:  0.8140678799803247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.82      0.88        22\n",
      "          1       0.96      0.99      0.98       104\n",
      "\n",
      "avg / total       0.96      0.96      0.96       126\n",
      "\n",
      "[ 18   4   1 103]\n",
      "svc Accuracy:  0.9603174603174603\n",
      "svc F1:  0.9271760490116749\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        22\n",
      "          1       0.89      1.00      0.94       104\n",
      "\n",
      "avg / total       0.91      0.90      0.88       126\n",
      "\n",
      "[  9  13   0 104]\n",
      "LR Accuracy:  0.8968253968253969\n",
      "LR F1:  0.760910815939279\n",
      "For name:  a_fontana\n",
      "total sample size before apply threshold:  203\n",
      "Counter({'0000-0002-6660-5315': 65, '0000-0002-5453-461X': 59, '0000-0002-5391-7520': 44, '0000-0002-8481-1219': 16, '0000-0002-4791-8746': 14, '0000-0003-3820-2823': 3, '0000-0003-1556-2770': 2})\n",
      "['0000-0002-5391-7520', '0000-0002-5453-461X', '0000-0002-4791-8746', '0000-0002-6660-5315', '0000-0002-8481-1219']\n",
      "Total sample size after apply threshold:  198\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(198, 114)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(198, 25)\n",
      "2\n",
      "(198, 139)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.55      0.54        44\n",
      "          1       0.65      0.58      0.61        59\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.64      0.94      0.76        65\n",
      "          4       1.00      0.38      0.55        16\n",
      "\n",
      "avg / total       0.60      0.63      0.60       198\n",
      "\n",
      "[24  8  0 12  0 12 34  0 13  0  2  8  0  4  0  4  0  0 61  0  3  2  0  5\n",
      "  6]\n",
      "MNB Accuracy:  0.6313131313131313\n",
      "MNB F1:  0.49197860015275746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.61      0.63        44\n",
      "          1       0.63      0.58      0.60        59\n",
      "          2       1.00      0.43      0.60        14\n",
      "          3       0.71      0.92      0.80        65\n",
      "          4       0.91      0.62      0.74        16\n",
      "\n",
      "avg / total       0.71      0.69      0.68       198\n",
      "\n",
      "[27  9  0  8  0 12 34  0 12  1  0  6  6  2  0  3  2  0 60  0  0  3  0  3\n",
      " 10]\n",
      "svc Accuracy:  0.6919191919191919\n",
      "svc F1:  0.6740835257978703\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.59      0.58        44\n",
      "          1       0.67      0.59      0.63        59\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.63      0.92      0.75        65\n",
      "          4       1.00      0.38      0.55        16\n",
      "\n",
      "avg / total       0.62      0.64      0.61       198\n",
      "\n",
      "[26  6  0 12  0 11 35  0 13  0  2  8  0  4  0  3  2  0 60  0  3  1  0  6\n",
      "  6]\n",
      "LR Accuracy:  0.6414141414141414\n",
      "LR F1:  0.5020709678013049\n",
      "For name:  r_chen\n",
      "total sample size before apply threshold:  367\n",
      "Counter({'0000-0002-8371-8629': 179, '0000-0001-6344-1442': 34, '0000-0003-0291-006X': 32, '0000-0001-6892-0602': 32, '0000-0003-3987-033X': 24, '0000-0002-7505-5415': 21, '0000-0003-1455-5093': 20, '0000-0001-9186-6747': 11, '0000-0002-5340-248X': 4, '0000-0002-8237-6612': 3, '0000-0001-6968-4955': 2, '0000-0003-1919-3335': 1, '0000-0003-4581-8204': 1, '0000-0001-8395-4392': 1, '0000-0001-9750-6670': 1, '0000-0003-1298-9381': 1})\n",
      "['0000-0003-0291-006X', '0000-0001-9186-6747', '0000-0001-6892-0602', '0000-0002-8371-8629', '0000-0003-1455-5093', '0000-0003-3987-033X', '0000-0002-7505-5415', '0000-0001-6344-1442']\n",
      "Total sample size after apply threshold:  353\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(353, 158)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(353, 24)\n",
      "2\n",
      "(353, 182)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.22      0.36        32\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.71      0.31      0.43        32\n",
      "          3       0.55      0.99      0.71       179\n",
      "          4       0.00      0.00      0.00        20\n",
      "          5       0.00      0.00      0.00        24\n",
      "          6       0.00      0.00      0.00        21\n",
      "          7       0.56      0.15      0.23        34\n",
      "\n",
      "avg / total       0.49      0.56      0.45       353\n",
      "\n",
      "[  7   0   0  25   0   0   0   0   0   0   0  11   0   0   0   0   0   0\n",
      "  10  20   0   0   0   2   0   0   1 177   0   0   0   1   0   0   0  20\n",
      "   0   0   0   0   0   0   0  23   0   0   0   1   0   0   0  21   0   0\n",
      "   0   0   0   0   3  26   0   0   0   5]\n",
      "MNB Accuracy:  0.5637393767705382\n",
      "MNB F1:  0.2164367987591776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.50      0.62        32\n",
      "          1       1.00      0.64      0.78        11\n",
      "          2       0.48      0.31      0.38        32\n",
      "          3       0.67      0.96      0.79       179\n",
      "          4       1.00      0.50      0.67        20\n",
      "          5       1.00      0.29      0.45        24\n",
      "          6       0.67      0.19      0.30        21\n",
      "          7       0.77      0.59      0.67        34\n",
      "\n",
      "avg / total       0.72      0.69      0.66       353\n",
      "\n",
      "[ 16   0   3  13   0   0   0   0   1   7   1   2   0   0   0   0   1   0\n",
      "  10  19   0   0   0   2   1   0   3 171   0   0   1   3   0   0   1   9\n",
      "  10   0   0   0   0   0   0  15   0   7   1   1   0   0   1  16   0   0\n",
      "   4   0   1   0   2  11   0   0   0  20]\n",
      "svc Accuracy:  0.6940509915014165\n",
      "svc F1:  0.5797462891419489\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.48        32\n",
      "          1       1.00      0.18      0.31        11\n",
      "          2       0.71      0.31      0.43        32\n",
      "          3       0.57      0.98      0.72       179\n",
      "          4       1.00      0.15      0.26        20\n",
      "          5       1.00      0.08      0.15        24\n",
      "          6       0.00      0.00      0.00        21\n",
      "          7       0.77      0.29      0.43        34\n",
      "\n",
      "avg / total       0.68      0.60      0.52       353\n",
      "\n",
      "[ 10   0   0  22   0   0   0   0   0   2   0   9   0   0   0   0   0   0\n",
      "  10  21   0   0   0   1   0   0   2 176   0   0   0   1   0   0   0  17\n",
      "   3   0   0   0   0   0   0  20   0   2   1   1   0   0   0  21   0   0\n",
      "   0   0   0   0   2  22   0   0   0  10]\n",
      "LR Accuracy:  0.603399433427762\n",
      "LR F1:  0.3477132042923091\n",
      "For name:  s_krause\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0002-5259-4651': 43, '0000-0003-1943-2703': 11, '0000-0002-8532-4244': 11, '0000-0002-7062-8472': 5})\n",
      "['0000-0003-1943-2703', '0000-0002-5259-4651', '0000-0002-8532-4244']\n",
      "Total sample size after apply threshold:  65\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 38)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 17)\n",
      "2\n",
      "(65, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.18      0.25        11\n",
      "          1       0.81      0.98      0.88        43\n",
      "          2       0.75      0.55      0.63        11\n",
      "\n",
      "avg / total       0.73      0.77      0.73        65\n",
      "\n",
      "[ 2  7  2  1 42  0  2  3  6]\n",
      "MNB Accuracy:  0.7692307692307693\n",
      "MNB F1:  0.5885964912280702\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.45      0.59        11\n",
      "          1       0.84      0.98      0.90        43\n",
      "          2       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.87      0.86      0.85        65\n",
      "\n",
      "[ 5  6  0  1 42  0  0  2  9]\n",
      "svc Accuracy:  0.8615384615384616\n",
      "svc F1:  0.7971537001897534\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.74      1.00      0.85        43\n",
      "          2       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.66      0.75      0.68        65\n",
      "\n",
      "[ 0 11  0  0 43  0  1  4  6]\n",
      "LR Accuracy:  0.7538461538461538\n",
      "LR F1:  0.5191225004853427\n",
      "For name:  t_smith\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  603\n",
      "Counter({'0000-0002-3650-9381': 154, '0000-0003-1673-2954': 113, '0000-0002-2120-2766': 85, '0000-0002-6279-9685': 84, '0000-0003-3528-6793': 65, '0000-0003-4453-9713': 32, '0000-0002-5197-5030': 26, '0000-0002-3945-630X': 10, '0000-0001-7894-6814': 9, '0000-0002-5750-0706': 6, '0000-0002-5495-8906': 4, '0000-0003-3762-6253': 4, '0000-0002-0479-4261': 3, '0000-0003-2389-461X': 2, '0000-0001-6272-8871': 2, '0000-0001-7683-2653': 1, '0000-0002-2104-2264': 1, '0000-0001-9068-4642': 1, '0000-0002-1881-2766': 1})\n",
      "['0000-0002-3945-630X', '0000-0003-4453-9713', '0000-0003-3528-6793', '0000-0002-6279-9685', '0000-0003-1673-2954', '0000-0002-3650-9381', '0000-0002-2120-2766', '0000-0002-5197-5030']\n",
      "Total sample size after apply threshold:  569\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(569, 207)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(569, 34)\n",
      "2\n",
      "(569, 241)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.12      0.22        32\n",
      "          2       0.72      0.52      0.61        65\n",
      "          3       0.77      0.49      0.60        84\n",
      "          4       0.58      0.90      0.71       113\n",
      "          5       0.64      0.85      0.73       154\n",
      "          6       0.88      0.88      0.88        85\n",
      "          7       0.00      0.00      0.00        26\n",
      "\n",
      "avg / total       0.67      0.68      0.64       569\n",
      "\n",
      "[  0   0   2   0   4   3   1   0   0   4   4   0  16   8   0   0   0   0\n",
      "  34   8   7  15   1   0   0   0   6  41  15  21   1   0   0   0   0   0\n",
      " 102  11   0   0   0   0   0   3  17 131   3   0   0   0   0   1   1   8\n",
      "  75   0   0   0   1   0  13   8   4   0]\n",
      "MNB Accuracy:  0.680140597539543\n",
      "MNB F1:  0.46854956422348265\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       1.00      0.41      0.58        32\n",
      "          2       0.72      0.58      0.64        65\n",
      "          3       0.78      0.60      0.68        84\n",
      "          4       0.65      0.96      0.77       113\n",
      "          5       0.73      0.85      0.78       154\n",
      "          6       0.91      0.88      0.90        85\n",
      "          7       0.83      0.19      0.31        26\n",
      "\n",
      "avg / total       0.77      0.75      0.73       569\n",
      "\n",
      "[  4   0   0   0   3   3   0   0   0  13   2   0  10   7   0   0   0   0\n",
      "  38   9   8   9   1   0   0   0   9  50  11  13   1   0   0   0   0   2\n",
      " 108   3   0   0   0   0   3   2  17 131   1   0   0   0   0   1   0   8\n",
      "  75   1   0   0   1   0  10   6   4   5]\n",
      "svc Accuracy:  0.7451669595782073\n",
      "svc F1:  0.654439140432461\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        10\n",
      "          1       1.00      0.22      0.36        32\n",
      "          2       0.75      0.55      0.64        65\n",
      "          3       0.75      0.55      0.63        84\n",
      "          4       0.60      0.90      0.72       113\n",
      "          5       0.66      0.85      0.75       154\n",
      "          6       0.92      0.89      0.90        85\n",
      "          7       1.00      0.04      0.07        26\n",
      "\n",
      "avg / total       0.75      0.70      0.67       569\n",
      "\n",
      "[  1   0   0   1   4   4   0   0   0   7   2   0  15   8   0   0   0   0\n",
      "  36  11   7  10   1   0   0   0   6  46  13  18   1   0   0   0   0   0\n",
      " 102  11   0   0   0   0   3   2  17 131   1   0   0   0   0   1   0   8\n",
      "  76   0   0   0   1   0  13   7   4   1]\n",
      "LR Accuracy:  0.70298769771529\n",
      "LR F1:  0.5320035031794756\n",
      "For name:  a_biswas\n",
      "total sample size before apply threshold:  10\n",
      "Counter({'0000-0003-2010-9524': 3, '0000-0002-5828-7230': 3, '0000-0002-0393-6280': 2, '0000-0002-7446-4639': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_day\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-9520-3465': 5, '0000-0003-1686-4885': 2, '0000-0001-8681-9831': 2, '0000-0001-6274-9197': 2, '0000-0001-6803-5865': 1, '0000-0003-4324-3486': 1, '0000-0003-1035-2117': 1, '0000-0003-4277-4816': 1, '0000-0003-3133-943X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_truong\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0003-4946-8969': 7, '0000-0002-1720-1744': 4, '0000-0003-3200-1297': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_pan\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0003-3154-6690': 34, '0000-0002-8247-2110': 12, '0000-0002-1189-4199': 11, '0000-0003-2082-4077': 10, '0000-0001-6451-4666': 10, '0000-0002-7581-1831': 9, '0000-0003-2620-7272': 6, '0000-0001-6565-3836': 5, '0000-0003-0794-527X': 4})\n",
      "['0000-0003-2082-4077', '0000-0001-6451-4666', '0000-0002-1189-4199', '0000-0002-8247-2110', '0000-0003-3154-6690']\n",
      "Total sample size after apply threshold:  77\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 45)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 17)\n",
      "2\n",
      "(77, 62)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.40      0.44        10\n",
      "          1       0.71      0.50      0.59        10\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.83      0.42      0.56        12\n",
      "          4       0.57      0.94      0.71        34\n",
      "\n",
      "avg / total       0.54      0.60      0.53        77\n",
      "\n",
      "[ 4  0  0  0  6  2  5  0  1  2  1  0  0  0 10  1  0  0  5  6  0  2  0  0\n",
      " 32]\n",
      "MNB Accuracy:  0.5974025974025974\n",
      "MNB F1:  0.4598692810457516\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.60      0.60      0.60        10\n",
      "          2       0.50      0.18      0.27        11\n",
      "          3       0.62      0.42      0.50        12\n",
      "          4       0.64      0.88      0.74        34\n",
      "\n",
      "avg / total       0.66      0.66      0.64        77\n",
      "\n",
      "[ 8  0  0  0  2  0  6  0  2  2  0  0  2  1  8  0  1  1  5  5  0  3  1  0\n",
      " 30]\n",
      "svc Accuracy:  0.6623376623376623\n",
      "svc F1:  0.5992592592592592\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.62      0.50      0.56        10\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.25      0.40        12\n",
      "          4       0.50      0.91      0.65        34\n",
      "\n",
      "avg / total       0.59      0.56      0.49        77\n",
      "\n",
      "[ 4  0  0  0  6  0  5  0  0  5  0  0  0  0 11  0  0  0  3  9  0  3  0  0\n",
      " 31]\n",
      "LR Accuracy:  0.5584415584415584\n",
      "LR F1:  0.4345634920634921\n",
      "For name:  a_andrade\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-9569-6503': 18, '0000-0002-5689-6606': 13, '0000-0003-4902-8728': 10, '0000-0002-8107-7338': 9, '0000-0002-3540-6858': 1, '0000-0001-7128-3472': 1})\n",
      "['0000-0002-5689-6606', '0000-0003-4902-8728', '0000-0001-9569-6503']\n",
      "Total sample size after apply threshold:  41\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 13)\n",
      "2\n",
      "(41, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.69      0.67        13\n",
      "          1       0.67      0.60      0.63        10\n",
      "          2       0.78      0.78      0.78        18\n",
      "\n",
      "avg / total       0.71      0.71      0.71        41\n",
      "\n",
      "[ 9  1  3  3  6  1  2  2 14]\n",
      "MNB Accuracy:  0.7073170731707317\n",
      "MNB F1:  0.6920077972709552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.69      0.67        13\n",
      "          1       0.67      0.60      0.63        10\n",
      "          2       0.78      0.78      0.78        18\n",
      "\n",
      "avg / total       0.71      0.71      0.71        41\n",
      "\n",
      "[ 9  1  3  3  6  1  2  2 14]\n",
      "svc Accuracy:  0.7073170731707317\n",
      "svc F1:  0.6920077972709552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.62      0.64        13\n",
      "          1       0.67      0.40      0.50        10\n",
      "          2       0.61      0.78      0.68        18\n",
      "\n",
      "avg / total       0.64      0.63      0.62        41\n",
      "\n",
      "[ 8  0  5  2  4  4  2  2 14]\n",
      "LR Accuracy:  0.6341463414634146\n",
      "LR F1:  0.6076422764227644\n",
      "For name:  t_oliveira\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-2654-0879': 17, '0000-0003-0843-7541': 11, '0000-0003-0509-0562': 9, '0000-0001-7040-7189': 1, '0000-0003-3947-1881': 1, '0000-0002-9200-3625': 1, '0000-0001-6055-058X': 1})\n",
      "['0000-0003-0843-7541', '0000-0002-2654-0879']\n",
      "Total sample size after apply threshold:  28\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 8)\n",
      "2\n",
      "(28, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.55      0.67        11\n",
      "          1       0.76      0.94      0.84        17\n",
      "\n",
      "avg / total       0.80      0.79      0.77        28\n",
      "\n",
      "[ 6  5  1 16]\n",
      "MNB Accuracy:  0.7857142857142857\n",
      "MNB F1:  0.7543859649122806\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.36      0.47        11\n",
      "          1       0.68      0.88      0.77        17\n",
      "\n",
      "avg / total       0.68      0.68      0.65        28\n",
      "\n",
      "[ 4  7  2 15]\n",
      "svc Accuracy:  0.6785714285714286\n",
      "svc F1:  0.6199095022624435\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.55      0.63        11\n",
      "          1       0.75      0.88      0.81        17\n",
      "\n",
      "avg / total       0.75      0.75      0.74        28\n",
      "\n",
      "[ 6  5  2 15]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.7211948790896159\n",
      "For name:  n_romano\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0003-2765-4912': 7, '0000-0002-9541-8885': 2, '0000-0002-6105-1827': 1, '0000-0001-7276-6994': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_hara\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0003-2668-6218': 15, '0000-0003-0450-6829': 6, '0000-0002-6565-0720': 1, '0000-0002-0235-238X': 1})\n",
      "['0000-0003-2668-6218']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  t_wong\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-1045-2698': 9, '0000-0002-5752-7917': 2, '0000-0001-9234-4529': 1, '0000-0001-6187-8851': 1, '0000-0001-8611-4911': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_ross\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-2302-8415': 17, '0000-0001-7305-3451': 3, '0000-0002-3094-3769': 2, '0000-0003-3512-9579': 1, '0000-0001-5676-4489': 1, '0000-0001-5523-2376': 1})\n",
      "['0000-0002-2302-8415']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  d_richardson\n",
      "total sample size before apply threshold:  456\n",
      "Counter({'0000-0003-0960-6415': 231, '0000-0002-7751-1058': 167, '0000-0002-3992-8610': 22, '0000-0003-0247-9118': 17, '0000-0002-3189-2190': 12, '0000-0002-0054-6850': 7})\n",
      "['0000-0002-3189-2190', '0000-0003-0960-6415', '0000-0002-7751-1058', '0000-0002-3992-8610', '0000-0003-0247-9118']\n",
      "Total sample size after apply threshold:  449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(449, 101)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(449, 27)\n",
      "2\n",
      "(449, 128)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.88      0.95      0.91       231\n",
      "          2       0.86      0.95      0.90       167\n",
      "          3       1.00      0.73      0.84        22\n",
      "          4       1.00      0.12      0.21        17\n",
      "\n",
      "avg / total       0.86      0.88      0.86       449\n",
      "\n",
      "[  0   9   3   0   0   0 219  12   0   0   0   9 158   0   0   0   4   2\n",
      "  16   0   0   7   8   0   2]\n",
      "MNB Accuracy:  0.8797327394209354\n",
      "MNB F1:  0.5739787464485848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.08      0.13        12\n",
      "          1       0.88      1.00      0.94       231\n",
      "          2       0.99      0.94      0.97       167\n",
      "          3       1.00      0.86      0.93        22\n",
      "          4       0.89      0.47      0.62        17\n",
      "\n",
      "avg / total       0.92      0.92      0.91       449\n",
      "\n",
      "[  1  11   0   0   0   1 230   0   0   0   0   9 157   0   1   0   3   0\n",
      "  19   0   1   7   1   0   8]\n",
      "svc Accuracy:  0.9242761692650334\n",
      "svc F1:  0.715712921390533\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.84      1.00      0.91       231\n",
      "          2       1.00      0.93      0.96       167\n",
      "          3       1.00      0.68      0.81        22\n",
      "          4       1.00      0.18      0.30        17\n",
      "\n",
      "avg / total       0.89      0.90      0.88       449\n",
      "\n",
      "[  0  12   0   0   0   0 231   0   0   0   0  12 155   0   0   0   7   0\n",
      "  15   0   0  14   0   0   3]\n",
      "LR Accuracy:  0.8997772828507795\n",
      "LR F1:  0.596957266723153\n",
      "For name:  j_moraes\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0002-5766-6802': 13, '0000-0002-8563-6432': 7, '0000-0002-4490-8307': 4, '0000-0002-3067-5194': 2})\n",
      "['0000-0002-5766-6802']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  e_moreno\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0002-2309-4826': 26, '0000-0001-5040-452X': 21, '0000-0001-9490-7030': 14, '0000-0002-8434-2483': 8, '0000-0003-0491-7951': 5, '0000-0002-2301-4558': 4, '0000-0002-7197-5679': 3, '0000-0001-8520-8086': 1, '0000-0002-2733-0267': 1})\n",
      "['0000-0002-2309-4826', '0000-0001-9490-7030', '0000-0001-5040-452X']\n",
      "Total sample size after apply threshold:  61\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 17)\n",
      "2\n",
      "(61, 61)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.85      0.72        26\n",
      "          1       0.67      0.57      0.62        14\n",
      "          2       0.57      0.38      0.46        21\n",
      "\n",
      "avg / total       0.62      0.62      0.61        61\n",
      "\n",
      "[22  1  3  3  8  3 10  3  8]\n",
      "MNB Accuracy:  0.6229508196721312\n",
      "MNB F1:  0.5979463159791029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.69      0.65        26\n",
      "          1       0.83      0.71      0.77        14\n",
      "          2       0.55      0.52      0.54        21\n",
      "\n",
      "avg / total       0.65      0.64      0.64        61\n",
      "\n",
      "[18  1  7  2 10  2  9  1 11]\n",
      "svc Accuracy:  0.639344262295082\n",
      "svc F1:  0.6534538632099607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.85      0.72        26\n",
      "          1       0.88      0.50      0.64        14\n",
      "          2       0.50      0.43      0.46        21\n",
      "\n",
      "avg / total       0.64      0.62      0.61        61\n",
      "\n",
      "[22  0  4  2  7  5 11  1  9]\n",
      "LR Accuracy:  0.6229508196721312\n",
      "LR F1:  0.6064045244373112\n",
      "For name:  r_little\n",
      "total sample size before apply threshold:  4\n",
      "Counter({'0000-0002-4000-946X': 2, '0000-0002-7732-157X': 1, '0000-0003-1870-3241': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_kobayashi\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-4008-454X': 85, '0000-0002-0237-3623': 22, '0000-0002-2738-373X': 10, '0000-0002-7650-1763': 10, '0000-0002-0903-6259': 6, '0000-0002-9202-7643': 5, '0000-0001-7297-8524': 5, '0000-0002-6952-8669': 4, '0000-0003-0963-2525': 2, '0000-0003-4264-5117': 1})\n",
      "['0000-0002-4008-454X', '0000-0002-2738-373X', '0000-0002-0237-3623', '0000-0002-7650-1763']\n",
      "Total sample size after apply threshold:  127\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 30)\n",
      "2\n",
      "(127, 86)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.93      0.85        85\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.56      0.68      0.61        22\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.62      0.74      0.68       127\n",
      "\n",
      "[79  0  6  0  7  0  3  0  7  0 15  0  7  0  3  0]\n",
      "MNB Accuracy:  0.7401574803149606\n",
      "MNB F1:  0.3665747380033094\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.90        85\n",
      "          1       1.00      0.60      0.75        10\n",
      "          2       1.00      0.91      0.95        22\n",
      "          3       0.20      0.10      0.13        10\n",
      "\n",
      "avg / total       0.83      0.85      0.83       127\n",
      "\n",
      "[81  0  0  4  4  6  0  0  2  0 20  0  9  0  0  1]\n",
      "svc Accuracy:  0.8503937007874016\n",
      "svc F1:  0.6826854775059193\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        85\n",
      "          1       1.00      0.20      0.33        10\n",
      "          2       1.00      0.64      0.78        22\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.76      0.80      0.74       127\n",
      "\n",
      "[85  0  0  0  8  2  0  0  8  0 14  0 10  0  0  0]\n",
      "LR Accuracy:  0.7952755905511811\n",
      "LR F1:  0.49461451247165533\n",
      "For name:  a_lin\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0003-4236-7233': 27, '0000-0001-6310-9765': 10, '0000-0001-9783-1270': 5, '0000-0003-0072-612X': 3, '0000-0001-8545-2222': 1})\n",
      "['0000-0003-4236-7233', '0000-0001-6310-9765']\n",
      "Total sample size after apply threshold:  37\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 18)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 11)\n",
      "2\n",
      "(37, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.93      0.85        27\n",
      "          1       0.60      0.30      0.40        10\n",
      "\n",
      "avg / total       0.73      0.76      0.73        37\n",
      "\n",
      "[25  2  7  3]\n",
      "MNB Accuracy:  0.7567567567567568\n",
      "MNB F1:  0.623728813559322\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.96      0.88        27\n",
      "          1       0.80      0.40      0.53        10\n",
      "\n",
      "avg / total       0.81      0.81      0.79        37\n",
      "\n",
      "[26  1  6  4]\n",
      "svc Accuracy:  0.8108108108108109\n",
      "svc F1:  0.7073446327683616\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.84        27\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.53      0.73      0.62        37\n",
      "\n",
      "[27  0 10  0]\n",
      "LR Accuracy:  0.7297297297297297\n",
      "LR F1:  0.42187499999999994\n",
      "For name:  a_miranda\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0001-6998-5686': 48, '0000-0001-5807-5820': 11, '0000-0003-3957-6288': 4, '0000-0003-4964-2197': 2, '0000-0002-9066-6935': 2, '0000-0003-4872-0632': 2, '0000-0002-7297-9639': 1})\n",
      "['0000-0001-5807-5820', '0000-0001-6998-5686']\n",
      "Total sample size after apply threshold:  59\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 27)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 14)\n",
      "2\n",
      "(59, 41)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.55      0.60        11\n",
      "          1       0.90      0.94      0.92        48\n",
      "\n",
      "avg / total       0.86      0.86      0.86        59\n",
      "\n",
      "[ 6  5  3 45]\n",
      "MNB Accuracy:  0.864406779661017\n",
      "MNB F1:  0.7591836734693878\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.64      0.74        11\n",
      "          1       0.92      0.98      0.95        48\n",
      "\n",
      "avg / total       0.91      0.92      0.91        59\n",
      "\n",
      "[ 7  4  1 47]\n",
      "svc Accuracy:  0.9152542372881356\n",
      "svc F1:  0.8431685273790537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17        11\n",
      "          1       0.83      1.00      0.91        48\n",
      "\n",
      "avg / total       0.86      0.83      0.77        59\n",
      "\n",
      "[ 1 10  0 48]\n",
      "LR Accuracy:  0.8305084745762712\n",
      "LR F1:  0.5361635220125787\n",
      "For name:  h_vogel\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0001-9821-7731': 5, '0000-0002-9902-8120': 4, '0000-0003-2404-9485': 4, '0000-0003-0072-4239': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_campos\n",
      "total sample size before apply threshold:  148\n",
      "Counter({'0000-0001-7738-9892': 107, '0000-0003-3217-9001': 12, '0000-0003-4313-7069': 8, '0000-0003-1012-6240': 6, '0000-0002-0883-0610': 5, '0000-0002-5233-3769': 5, '0000-0003-4683-0176': 3, '0000-0002-9516-6526': 2})\n",
      "['0000-0001-7738-9892', '0000-0003-3217-9001']\n",
      "Total sample size after apply threshold:  119\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(119, 67)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(119, 20)\n",
      "2\n",
      "(119, 87)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       107\n",
      "          1       1.00      0.42      0.59        12\n",
      "\n",
      "avg / total       0.94      0.94      0.93       119\n",
      "\n",
      "[107   0   7   5]\n",
      "MNB Accuracy:  0.9411764705882353\n",
      "MNB F1:  0.7782805429864253\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99       107\n",
      "          1       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.98      0.97      0.97       119\n",
      "\n",
      "[107   0   3   9]\n",
      "svc Accuracy:  0.9747899159663865\n",
      "svc F1:  0.9216589861751152\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.96       107\n",
      "          1       1.00      0.17      0.29        12\n",
      "\n",
      "avg / total       0.92      0.92      0.89       119\n",
      "\n",
      "[107   0  10   2]\n",
      "LR Accuracy:  0.9159663865546218\n",
      "LR F1:  0.6205357142857143\n",
      "For name:  d_stewart\n",
      "total sample size before apply threshold:  294\n",
      "Counter({'0000-0002-8157-7746': 210, '0000-0001-7360-8592': 77, '0000-0002-6764-4842': 3, '0000-0002-8499-7105': 1, '0000-0002-4087-5544': 1, '0000-0001-5144-1234': 1, '0000-0002-3690-9844': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000-0001-7360-8592', '0000-0002-8157-7746']\n",
      "Total sample size after apply threshold:  287\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(287, 124)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(287, 26)\n",
      "2\n",
      "(287, 150)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.79      0.77        77\n",
      "          1       0.92      0.90      0.91       210\n",
      "\n",
      "avg / total       0.88      0.87      0.88       287\n",
      "\n",
      "[ 61  16  20 190]\n",
      "MNB Accuracy:  0.8745644599303136\n",
      "MNB F1:  0.8428067185978578\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.78      0.86        77\n",
      "          1       0.92      0.99      0.96       210\n",
      "\n",
      "avg / total       0.94      0.93      0.93       287\n",
      "\n",
      "[ 60  17   2 208]\n",
      "svc Accuracy:  0.9337979094076655\n",
      "svc F1:  0.9098155957992227\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        77\n",
      "          1       0.88      1.00      0.94       210\n",
      "\n",
      "avg / total       0.91      0.90      0.89       287\n",
      "\n",
      "[ 48  29   0 210]\n",
      "LR Accuracy:  0.8989547038327527\n",
      "LR F1:  0.851706013363029\n",
      "For name:  j_abrantes\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-8391-7134': 42, '0000-0003-1902-9017': 11, '0000-0003-4585-9831': 4})\n",
      "['0000-0003-1902-9017', '0000-0002-8391-7134']\n",
      "Total sample size after apply threshold:  53\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 33)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 11)\n",
      "2\n",
      "(53, 44)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.36      0.50        11\n",
      "          1       0.85      0.98      0.91        42\n",
      "\n",
      "avg / total       0.84      0.85      0.83        53\n",
      "\n",
      "[ 4  7  1 41]\n",
      "MNB Accuracy:  0.8490566037735849\n",
      "MNB F1:  0.7055555555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.91      1.00      0.95        42\n",
      "\n",
      "avg / total       0.93      0.92      0.92        53\n",
      "\n",
      "[ 7  4  0 42]\n",
      "svc Accuracy:  0.9245283018867925\n",
      "svc F1:  0.8661616161616161\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.79      1.00      0.88        42\n",
      "\n",
      "avg / total       0.63      0.79      0.70        53\n",
      "\n",
      "[ 0 11  0 42]\n",
      "LR Accuracy:  0.7924528301886793\n",
      "LR F1:  0.4421052631578948\n",
      "For name:  j_arroyo\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0002-1971-1721': 65, '0000-0003-4749-2519': 18, '0000-0002-5992-5011': 10, '0000-0002-5674-6739': 10, '0000-0001-7658-8750': 6})\n",
      "['0000-0003-4749-2519', '0000-0002-5992-5011', '0000-0002-5674-6739', '0000-0002-1971-1721']\n",
      "Total sample size after apply threshold:  103\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 60)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 23)\n",
      "2\n",
      "(103, 83)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.50      0.56        18\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.72      0.95      0.82        65\n",
      "\n",
      "avg / total       0.57      0.69      0.62       103\n",
      "\n",
      "[ 9  0  1  8  1  0  1  8  1  1  0  8  3  0  0 62]\n",
      "MNB Accuracy:  0.6893203883495146\n",
      "MNB F1:  0.34592301324503316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.67      0.71        18\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.20      0.10      0.13        10\n",
      "          3       0.77      0.91      0.83        65\n",
      "\n",
      "avg / total       0.63      0.70      0.66       103\n",
      "\n",
      "[12  0  1  5  1  0  1  8  1  3  1  5  2  2  2 59]\n",
      "svc Accuracy:  0.6990291262135923\n",
      "svc F1:  0.41755040044186686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.22      0.36        18\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.67      1.00      0.80        65\n",
      "\n",
      "avg / total       0.60      0.67      0.57       103\n",
      "\n",
      "[ 4  0  0 14  0  0  1  9  0  1  0  9  0  0  0 65]\n",
      "LR Accuracy:  0.6699029126213593\n",
      "LR F1:  0.29152637485970817\n",
      "For name:  a_giuliani\n",
      "total sample size before apply threshold:  196\n",
      "Counter({'0000-0002-4640-804X': 155, '0000-0003-1710-4933': 36, '0000-0002-4315-1699': 4, '0000-0002-6823-2807': 1})\n",
      "['0000-0003-1710-4933', '0000-0002-4640-804X']\n",
      "Total sample size after apply threshold:  191\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 112)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 30)\n",
      "2\n",
      "(191, 142)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.36      0.50        36\n",
      "          1       0.87      0.98      0.92       155\n",
      "\n",
      "avg / total       0.86      0.86      0.84       191\n",
      "\n",
      "[ 13  23   3 152]\n",
      "MNB Accuracy:  0.8638743455497382\n",
      "MNB F1:  0.7106060606060606\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        36\n",
      "          1       0.92      1.00      0.96       155\n",
      "\n",
      "avg / total       0.94      0.93      0.93       191\n",
      "\n",
      "[ 23  13   0 155]\n",
      "svc Accuracy:  0.9319371727748691\n",
      "svc F1:  0.8697066694652883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.24        36\n",
      "          1       0.83      1.00      0.91       155\n",
      "\n",
      "avg / total       0.86      0.84      0.78       191\n",
      "\n",
      "[  5  31   0 155]\n",
      "LR Accuracy:  0.837696335078534\n",
      "LR F1:  0.5764966740576497\n",
      "For name:  f_campos\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0001-8376-0977': 14, '0000-0002-5948-472X': 12, '0000-0002-1132-3257': 10, '0000-0001-8332-5043': 9, '0000-0001-9826-751X': 2, '0000-0001-5828-2862': 2})\n",
      "['0000-0001-8376-0977', '0000-0002-5948-472X', '0000-0002-1132-3257']\n",
      "Total sample size after apply threshold:  36\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 13)\n",
      "2\n",
      "(36, 35)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.64      0.55        14\n",
      "          1       0.60      0.50      0.55        12\n",
      "          2       0.57      0.40      0.47        10\n",
      "\n",
      "avg / total       0.54      0.53      0.52        36\n",
      "\n",
      "[9 3 2 5 6 1 5 1 4]\n",
      "MNB Accuracy:  0.5277777777777778\n",
      "MNB F1:  0.5204991087344029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.71      0.63        14\n",
      "          1       0.64      0.58      0.61        12\n",
      "          2       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.71      0.67      0.67        36\n",
      "\n",
      "[10  4  0  5  7  0  3  0  7]\n",
      "svc Accuracy:  0.6666666666666666\n",
      "svc F1:  0.6857416879795396\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.64      0.55        14\n",
      "          1       0.50      0.42      0.45        12\n",
      "          2       0.57      0.40      0.47        10\n",
      "\n",
      "avg / total       0.51      0.50      0.49        36\n",
      "\n",
      "[9 4 1 5 5 2 5 1 4]\n",
      "LR Accuracy:  0.5\n",
      "LR F1:  0.4901960784313726\n",
      "For name:  a_mitchell\n",
      "total sample size before apply threshold:  436\n",
      "Counter({'0000-0001-6014-598X': 188, '0000-0002-0868-4000': 98, '0000-0002-2463-2956': 65, '0000-0001-8996-1067': 24, '0000-0001-8655-7966': 23, '0000-0002-9946-183X': 20, '0000-0003-1062-0716': 6, '0000-0001-5022-5898': 4, '0000-0003-2001-1738': 4, '0000-0003-0969-1680': 3, '0000-0003-3352-3046': 1})\n",
      "['0000-0002-9946-183X', '0000-0001-6014-598X', '0000-0001-8655-7966', '0000-0002-2463-2956', '0000-0002-0868-4000', '0000-0001-8996-1067']\n",
      "Total sample size after apply threshold:  418\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(418, 178)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(418, 22)\n",
      "2\n",
      "(418, 200)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        20\n",
      "          1       0.65      0.94      0.77       188\n",
      "          2       0.75      0.26      0.39        23\n",
      "          3       0.95      0.54      0.69        65\n",
      "          4       0.75      0.70      0.73        98\n",
      "          5       1.00      0.29      0.45        24\n",
      "\n",
      "avg / total       0.71      0.70      0.67       418\n",
      "\n",
      "[  0  19   0   0   1   0   0 177   0   1  10   0   0  11   6   0   6   0\n",
      "   0  27   0  35   3   0   0  27   2   0  69   0   0  13   0   1   3   7]\n",
      "MNB Accuracy:  0.7033492822966507\n",
      "MNB F1:  0.5029222904884544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.45      0.56        20\n",
      "          1       0.76      0.99      0.86       188\n",
      "          2       0.90      0.78      0.84        23\n",
      "          3       0.94      0.68      0.79        65\n",
      "          4       0.97      0.76      0.85        98\n",
      "          5       0.94      0.67      0.78        24\n",
      "\n",
      "avg / total       0.85      0.83      0.82       418\n",
      "\n",
      "[  9   9   0   2   0   0   1 186   0   0   0   1   0   5  18   0   0   0\n",
      "   1  19   0  44   1   0   1  21   2   0  74   0   0   6   0   1   1  16]\n",
      "svc Accuracy:  0.8301435406698564\n",
      "svc F1:  0.7789381604507418\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.26        20\n",
      "          1       0.65      0.99      0.79       188\n",
      "          2       0.86      0.52      0.65        23\n",
      "          3       0.97      0.55      0.71        65\n",
      "          4       0.94      0.64      0.76        98\n",
      "          5       1.00      0.42      0.59        24\n",
      "\n",
      "avg / total       0.82      0.74      0.72       418\n",
      "\n",
      "[  3  17   0   0   0   0   0 187   0   0   1   0   0  10  12   0   1   0\n",
      "   0  28   0  36   1   0   0  33   2   0  63   0   0  12   0   1   1  10]\n",
      "LR Accuracy:  0.7440191387559809\n",
      "LR F1:  0.6257734409356431\n",
      "For name:  c_murray\n",
      "total sample size before apply threshold:  112\n",
      "Counter({'0000-0002-0951-5700': 41, '0000-0001-6736-1546': 28, '0000-0002-2398-3914': 23, '0000-0002-5499-6857': 15, '0000-0003-4471-0509': 4, '0000-0002-4713-8475': 1})\n",
      "['0000-0001-6736-1546', '0000-0002-2398-3914', '0000-0002-5499-6857', '0000-0002-0951-5700']\n",
      "Total sample size after apply threshold:  107\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 16)\n",
      "2\n",
      "(107, 72)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.32      0.40        28\n",
      "          1       0.75      0.91      0.82        23\n",
      "          2       0.50      0.20      0.29        15\n",
      "          3       0.62      0.85      0.72        41\n",
      "\n",
      "avg / total       0.61      0.64      0.60       107\n",
      "\n",
      "[ 9  4  2 13  2 21  0  0  3  1  3  8  3  2  1 35]\n",
      "MNB Accuracy:  0.6355140186915887\n",
      "MNB F1:  0.5577232955037685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.71      0.61        28\n",
      "          1       0.95      0.87      0.91        23\n",
      "          2       0.60      0.40      0.48        15\n",
      "          3       0.82      0.76      0.78        41\n",
      "\n",
      "avg / total       0.74      0.72      0.72       107\n",
      "\n",
      "[20  1  2  5  3 20  0  0  7  0  6  2  8  0  2 31]\n",
      "svc Accuracy:  0.719626168224299\n",
      "svc F1:  0.6949904104334484\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.39      0.42        28\n",
      "          1       0.86      0.83      0.84        23\n",
      "          2       0.56      0.33      0.42        15\n",
      "          3       0.65      0.83      0.73        41\n",
      "\n",
      "avg / total       0.63      0.64      0.63       107\n",
      "\n",
      "[11  2  2 13  3 19  1  0  4  1  5  5  6  0  1 34]\n",
      "LR Accuracy:  0.6448598130841121\n",
      "LR F1:  0.6038427074717397\n",
      "For name:  m_grant\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-1380-2104': 28, '0000-0002-7838-8725': 9, '0000-0003-1003-4071': 1, '0000-0002-0377-2036': 1})\n",
      "['0000-0002-1380-2104']\n",
      "Total sample size after apply threshold:  28\n",
      "For name:  d_scott\n",
      "total sample size before apply threshold:  145\n",
      "Counter({'0000-0001-5226-1972': 65, '0000-0002-6726-2078': 64, '0000-0002-6878-9840': 10, '0000-0003-2230-0090': 2, '0000-0003-4918-2610': 2, '0000-0001-8560-0248': 1, '0000-0002-2592-1522': 1})\n",
      "['0000-0002-6726-2078', '0000-0001-5226-1972', '0000-0002-6878-9840']\n",
      "Total sample size after apply threshold:  139\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 68)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 20)\n",
      "2\n",
      "(139, 88)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.81      0.82        64\n",
      "          1       0.81      0.92      0.86        65\n",
      "          2       0.50      0.10      0.17        10\n",
      "\n",
      "avg / total       0.80      0.81      0.79       139\n",
      "\n",
      "[52 11  1  5 60  0  6  3  1]\n",
      "MNB Accuracy:  0.8129496402877698\n",
      "MNB F1:  0.6162912189933093\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.78      0.84        64\n",
      "          1       0.82      0.94      0.88        65\n",
      "          2       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.87      0.86      0.86       139\n",
      "\n",
      "[50 13  1  4 61  0  1  0  9]\n",
      "svc Accuracy:  0.8633093525179856\n",
      "svc F1:  0.8726779920601334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.81      0.81        64\n",
      "          1       0.82      0.89      0.85        65\n",
      "          2       0.67      0.20      0.31        10\n",
      "\n",
      "avg / total       0.80      0.81      0.79       139\n",
      "\n",
      "[52 11  1  7 58  0  6  2  2]\n",
      "LR Accuracy:  0.8057553956834532\n",
      "LR F1:  0.6556116781834976\n",
      "For name:  s_mohan\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0002-5305-9685': 43, '0000-0002-4797-9565': 4, '0000-0001-5628-2631': 2, '0000-0001-8980-0730': 1})\n",
      "['0000-0002-5305-9685']\n",
      "Total sample size after apply threshold:  43\n",
      "For name:  n_wong\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0003-3788-8114': 13, '0000-0002-7003-6020': 9, '0000-0003-4393-7541': 1, '0000-0002-5932-1015': 1})\n",
      "['0000-0003-3788-8114']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  k_anderson\n",
      "total sample size before apply threshold:  171\n",
      "Counter({'0000-0003-1657-2161': 78, '0000-0002-9324-9598': 44, '0000-0001-9843-404X': 22, '0000-0001-5613-5893': 14, '0000-0002-3289-2598': 6, '0000-0003-3927-8117': 4, '0000-0002-1472-3352': 2, '0000-0002-5458-6735': 1})\n",
      "['0000-0001-9843-404X', '0000-0002-9324-9598', '0000-0001-5613-5893', '0000-0003-1657-2161']\n",
      "Total sample size after apply threshold:  158\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(158, 80)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(158, 17)\n",
      "2\n",
      "(158, 97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.45      0.61        22\n",
      "          1       0.56      0.50      0.53        44\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.61      0.83      0.70        78\n",
      "\n",
      "avg / total       0.58      0.61      0.58       158\n",
      "\n",
      "[10  1  0 11  1 22  0 21  0  4  0 10  0 12  1 65]\n",
      "MNB Accuracy:  0.6139240506329114\n",
      "MNB F1:  0.45972094767275495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.59      0.67        22\n",
      "          1       0.54      0.59      0.57        44\n",
      "          2       0.67      0.14      0.24        14\n",
      "          3       0.69      0.79      0.74        78\n",
      "\n",
      "avg / total       0.66      0.65      0.64       158\n",
      "\n",
      "[13  2  0  7  3 26  0 15  1  5  2  6  0 15  1 62]\n",
      "svc Accuracy:  0.6518987341772152\n",
      "svc F1:  0.5513183534283279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.32      0.45        22\n",
      "          1       0.61      0.45      0.52        44\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.59      0.87      0.70        78\n",
      "\n",
      "avg / total       0.57      0.60      0.55       158\n",
      "\n",
      "[ 7  1  0 14  1 20  0 23  0  3  0 11  1  9  0 68]\n",
      "LR Accuracy:  0.6012658227848101\n",
      "LR F1:  0.41803108763534436\n",
      "For name:  m_king\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-2587-9117': 26, '0000-0001-6030-5154': 13, '0000-0001-9895-7297': 9, '0000-0001-5611-9498': 7, '0000-0002-9558-8622': 2, '0000-0001-7993-8808': 1})\n",
      "['0000-0001-6030-5154', '0000-0002-2587-9117']\n",
      "Total sample size after apply threshold:  39\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 13)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 15)\n",
      "2\n",
      "(39, 28)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.77      0.83        13\n",
      "          1       0.89      0.96      0.93        26\n",
      "\n",
      "avg / total       0.90      0.90      0.90        39\n",
      "\n",
      "[10  3  1 25]\n",
      "MNB Accuracy:  0.8974358974358975\n",
      "MNB F1:  0.8796296296296295\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.96      0.98        26\n",
      "\n",
      "avg / total       0.98      0.97      0.97        39\n",
      "\n",
      "[13  0  1 25]\n",
      "svc Accuracy:  0.9743589743589743\n",
      "svc F1:  0.971677559912854\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.69      0.78        13\n",
      "          1       0.86      0.96      0.91        26\n",
      "\n",
      "avg / total       0.87      0.87      0.87        39\n",
      "\n",
      "[ 9  4  1 25]\n",
      "LR Accuracy:  0.8717948717948718\n",
      "LR F1:  0.8458498023715415\n",
      "For name:  a_srivastava\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0002-2031-4643': 14, '0000-0002-0211-7814': 13, '0000-0001-9866-8145': 6, '0000-0001-7042-4317': 5, '0000-0001-8340-856X': 3, '0000-0001-9871-5781': 3, '0000-0001-5345-6405': 2, '0000-0002-7046-405X': 1, '0000-0002-4590-7947': 1, '0000-0002-5295-7176': 1})\n",
      "['0000-0002-2031-4643', '0000-0002-0211-7814']\n",
      "Total sample size after apply threshold:  27\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 10)\n",
      "2\n",
      "(27, 30)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.64      0.67        14\n",
      "          1       0.64      0.69      0.67        13\n",
      "\n",
      "avg / total       0.67      0.67      0.67        27\n",
      "\n",
      "[9 5 4 9]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.71      0.69        14\n",
      "          1       0.67      0.62      0.64        13\n",
      "\n",
      "avg / total       0.67      0.67      0.67        27\n",
      "\n",
      "[10  4  5  8]\n",
      "svc Accuracy:  0.6666666666666666\n",
      "svc F1:  0.6648275862068965\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.64      0.67        14\n",
      "          1       0.64      0.69      0.67        13\n",
      "\n",
      "avg / total       0.67      0.67      0.67        27\n",
      "\n",
      "[9 5 4 9]\n",
      "LR Accuracy:  0.6666666666666666\n",
      "LR F1:  0.6666666666666666\n",
      "For name:  m_scholz\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0001-8440-6785': 31, '0000-0002-4300-3020': 9, '0000-0001-9887-9831': 2})\n",
      "['0000-0001-8440-6785']\n",
      "Total sample size after apply threshold:  31\n",
      "For name:  y_ju\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0002-5120-6960': 14, '0000-0001-8325-1494': 9, '0000-0003-0103-1207': 3, '0000-0002-5514-4189': 1})\n",
      "['0000-0002-5120-6960']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  d_stanley\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0001-9806-5694': 4, '0000-0001-5992-8901': 1, '0000-0001-8948-8409': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_nogueira\n",
      "total sample size before apply threshold:  303\n",
      "Counter({'0000-0003-2950-3632': 279, '0000-0002-0853-5304': 16, '0000-0001-8464-0045': 4, '0000-0002-9152-754X': 4})\n",
      "['0000-0002-0853-5304', '0000-0003-2950-3632']\n",
      "Total sample size after apply threshold:  295\n",
      "(0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 104)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 16)\n",
      "2\n",
      "(295, 120)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.06      0.11        16\n",
      "          1       0.95      1.00      0.97       279\n",
      "\n",
      "avg / total       0.92      0.95      0.93       295\n",
      "\n",
      "[  1  15   1 278]\n",
      "MNB Accuracy:  0.9457627118644067\n",
      "MNB F1:  0.5415695415695416\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.06      0.11        16\n",
      "          1       0.95      1.00      0.97       279\n",
      "\n",
      "avg / total       0.92      0.95      0.93       295\n",
      "\n",
      "[  1  15   1 278]\n",
      "svc Accuracy:  0.9457627118644067\n",
      "svc F1:  0.5415695415695416\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.95      1.00      0.97       279\n",
      "\n",
      "avg / total       0.89      0.95      0.92       295\n",
      "\n",
      "[  0  16   0 279]\n",
      "LR Accuracy:  0.9457627118644067\n",
      "LR F1:  0.48606271777003485\n",
      "For name:  j_cooper\n",
      "total sample size before apply threshold:  147\n",
      "Counter({'0000-0003-1339-4750': 85, '0000-0001-6009-3542': 24, '0000-0001-8163-2306': 19, '0000-0002-9014-4395': 14, '0000-0002-8626-7827': 4, '0000-0002-4932-1740': 1})\n",
      "['0000-0002-9014-4395', '0000-0001-6009-3542', '0000-0001-8163-2306', '0000-0003-1339-4750']\n",
      "Total sample size after apply threshold:  142\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 72)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 24)\n",
      "2\n",
      "(142, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.14      0.24        14\n",
      "          1       0.87      0.54      0.67        24\n",
      "          2       0.67      0.32      0.43        19\n",
      "          3       0.72      0.98      0.83        85\n",
      "\n",
      "avg / total       0.73      0.73      0.69       142\n",
      "\n",
      "[ 2  1  1 10  1 13  0 10  0  1  6 12  0  0  2 83]\n",
      "MNB Accuracy:  0.7323943661971831\n",
      "MNB F1:  0.5401330532212886\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.64      0.75        14\n",
      "          1       0.81      0.71      0.76        24\n",
      "          2       0.83      0.53      0.65        19\n",
      "          3       0.84      0.98      0.90        85\n",
      "\n",
      "avg / total       0.84      0.84      0.83       142\n",
      "\n",
      "[ 9  1  0  4  1 17  0  6  0  3 10  6  0  0  2 83]\n",
      "svc Accuracy:  0.8380281690140845\n",
      "svc F1:  0.7632226897304035\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25        14\n",
      "          1       0.93      0.54      0.68        24\n",
      "          2       1.00      0.05      0.10        19\n",
      "          3       0.68      1.00      0.81        85\n",
      "\n",
      "avg / total       0.80      0.71      0.64       142\n",
      "\n",
      "[ 2  0  0 12  0 13  0 11  0  1  1 17  0  0  0 85]\n",
      "LR Accuracy:  0.7112676056338029\n",
      "LR F1:  0.46093358395989975\n",
      "For name:  k_lau\n",
      "total sample size before apply threshold:  121\n",
      "Counter({'0000-0003-2125-6841': 81, '0000-0003-3676-9228': 18, '0000-0001-8438-0319': 17, '0000-0002-7713-1928': 4, '0000-0003-2197-5539': 1})\n",
      "['0000-0001-8438-0319', '0000-0003-2125-6841', '0000-0003-3676-9228']\n",
      "Total sample size after apply threshold:  116\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(116, 36)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(116, 13)\n",
      "2\n",
      "(116, 49)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        17\n",
      "          1       0.80      0.99      0.88        81\n",
      "          2       0.70      0.39      0.50        18\n",
      "\n",
      "avg / total       0.81      0.80      0.77       116\n",
      "\n",
      "[ 6  9  2  0 80  1  0 11  7]\n",
      "MNB Accuracy:  0.8017241379310345\n",
      "MNB F1:  0.6352390103290896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.65      0.76        17\n",
      "          1       0.92      0.96      0.94        81\n",
      "          2       0.58      0.61      0.59        18\n",
      "\n",
      "avg / total       0.86      0.86      0.86       116\n",
      "\n",
      "[11  1  5  0 78  3  1  6 11]\n",
      "svc Accuracy:  0.8620689655172413\n",
      "svc F1:  0.7643247734647818\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        17\n",
      "          1       0.77      1.00      0.87        81\n",
      "          2       0.83      0.28      0.42        18\n",
      "\n",
      "avg / total       0.81      0.78      0.74       116\n",
      "\n",
      "[ 5 11  1  0 81  0  0 13  5]\n",
      "LR Accuracy:  0.7844827586206896\n",
      "LR F1:  0.5807266210492018\n",
      "For name:  s_hussein\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0002-7946-0717': 18, '0000-0002-6305-508X': 9, '0000-0003-3657-7410': 4, '0000-0002-5394-4385': 1, '0000-0002-0139-1483': 1})\n",
      "['0000-0002-7946-0717']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  z_luo\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-3074-046X': 15, '0000-0002-2719-1025': 5, '0000-0002-8129-333X': 3, '0000-0003-0164-4492': 2})\n",
      "['0000-0002-3074-046X']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  c_pimentel\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0002-5158-6414': 16, '0000-0002-1106-8962': 3, '0000-0002-8364-8990': 2, '0000-0002-4932-0174': 1})\n",
      "['0000-0002-5158-6414']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  s_ito\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0003-1776-4608': 22, '0000-0001-9310-1852': 18, '0000-0003-1108-1371': 14, '0000-0002-0268-013X': 4, '0000-0002-3635-2580': 1})\n",
      "['0000-0001-9310-1852', '0000-0003-1108-1371', '0000-0003-1776-4608']\n",
      "Total sample size after apply threshold:  54"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 24)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 13)\n",
      "2\n",
      "(54, 37)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.72      0.79        18\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       0.74      0.91      0.82        22\n",
      "\n",
      "avg / total       0.85      0.83      0.83        54\n",
      "\n",
      "[13  0  5  0 12  2  2  0 20]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.8424274138559852\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.89      0.86        18\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       0.83      0.86      0.84        22\n",
      "\n",
      "avg / total       0.88      0.87      0.87        54\n",
      "\n",
      "[16  0  2  0 12  2  3  0 19]\n",
      "svc Accuracy:  0.8703703703703703\n",
      "svc F1:  0.8774620774620775\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.78      0.80        18\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       0.76      0.86      0.81        22\n",
      "\n",
      "avg / total       0.84      0.83      0.84        54\n",
      "\n",
      "[14  0  4  0 12  2  3  0 19]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.8438625204582652\n",
      "For name:  f_zhang\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0001-6035-4829': 27, '0000-0001-7434-7339': 23, '0000-0002-0480-7501': 11, '0000-0001-9542-6634': 10, '0000-0003-1298-9795': 9, '0000-0002-1371-266X': 7, '0000-0002-1957-0543': 5, '0000-0002-2822-2049': 4, '0000-0002-9309-9577': 2, '0000-0003-1709-7788': 2, '0000-0001-7550-9483': 1, '0000-0002-8438-7155': 1, '0000-0003-2829-0735': 1})\n",
      "['0000-0001-7434-7339', '0000-0002-0480-7501', '0000-0001-6035-4829', '0000-0001-9542-6634']\n",
      "Total sample size after apply threshold:  71\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 52)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 10)\n",
      "2\n",
      "(71, 62)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.52      0.56        23\n",
      "          1       0.50      0.55      0.52        11\n",
      "          2       0.51      0.67      0.58        27\n",
      "          3       0.75      0.30      0.43        10\n",
      "\n",
      "avg / total       0.57      0.55      0.54        71\n",
      "\n",
      "[12  3  8  0  0  6  4  1  7  2 18  0  1  1  5  3]\n",
      "MNB Accuracy:  0.5492957746478874\n",
      "MNB F1:  0.5222738137950637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.57      0.60        23\n",
      "          1       0.88      0.64      0.74        11\n",
      "          2       0.51      0.67      0.58        27\n",
      "          3       0.62      0.50      0.56        10\n",
      "\n",
      "avg / total       0.63      0.61      0.61        71\n",
      "\n",
      "[13  0 10  0  0  7  3  1  6  1 18  2  1  0  4  5]\n",
      "svc Accuracy:  0.6056338028169014\n",
      "svc F1:  0.6194234962249334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.48      0.54        23\n",
      "          1       0.55      0.55      0.55        11\n",
      "          2       0.49      0.70      0.58        27\n",
      "          3       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.61      0.55      0.54        71\n",
      "\n",
      "[11  3  9  0  0  6  5  0  6  2 19  0  1  0  6  3]\n",
      "LR Accuracy:  0.5492957746478874\n",
      "LR F1:  0.5298339871510603\n",
      "For name:  s_chapman\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0003-3347-6024': 23, '0000-0003-0053-1584': 23, '0000-0002-4314-9193': 15, '0000-0003-0778-084X': 7, '0000-0003-2342-3383': 3})\n",
      "['0000-0003-3347-6024', '0000-0003-0053-1584', '0000-0002-4314-9193']\n",
      "Total sample size after apply threshold:  61\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 13)\n",
      "2\n",
      "(61, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.52      0.55        23\n",
      "          1       0.56      0.78      0.65        23\n",
      "          2       0.88      0.47      0.61        15\n",
      "\n",
      "avg / total       0.64      0.61      0.60        61\n",
      "\n",
      "[12 10  1  5 18  0  4  4  7]\n",
      "MNB Accuracy:  0.6065573770491803\n",
      "MNB F1:  0.6028985507246377\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70        23\n",
      "          1       0.72      0.78      0.75        23\n",
      "          2       1.00      0.87      0.93        15\n",
      "\n",
      "avg / total       0.78      0.77      0.77        61\n",
      "\n",
      "[16  7  0  5 18  0  2  0 13]\n",
      "svc Accuracy:  0.7704918032786885\n",
      "svc F1:  0.791407867494824\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.52      0.53        23\n",
      "          1       0.64      0.78      0.71        23\n",
      "          2       0.91      0.67      0.77        15\n",
      "\n",
      "avg / total       0.67      0.66      0.66        61\n",
      "\n",
      "[12 10  1  5 18  0  5  0 10]\n",
      "LR Accuracy:  0.6557377049180327\n",
      "LR F1:  0.669482151835093\n",
      "For name:  j_rosa\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0003-0857-3746': 15, '0000-0001-7770-5381': 7, '0000-0002-7154-2494': 4, '0000-0001-7947-2681': 2, '0000-0002-0015-6254': 1})\n",
      "['0000-0003-0857-3746']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  y_yin\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0003-0218-3042': 127, '0000-0003-1077-810X': 8, '0000-0003-3514-5712': 5, '0000-0003-0963-2672': 5, '0000-0003-0965-4951': 4, '0000-0002-8685-4378': 2, '0000-0001-5821-7497': 1})\n",
      "['0000-0003-0218-3042']\n",
      "Total sample size after apply threshold:  127\n",
      "For name:  p_tavares\n",
      "total sample size before apply threshold:  53\n",
      "Counter({'0000-0002-7398-2661': 29, '0000-0001-7589-1299': 13, '0000-0002-2287-2446': 8, '0000-0001-7832-4134': 3})\n",
      "['0000-0001-7589-1299', '0000-0002-7398-2661']\n",
      "Total sample size after apply threshold:  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 19)\n",
      "2\n",
      "(42, 40)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.77      0.71        13\n",
      "          1       0.89      0.83      0.86        29\n",
      "\n",
      "avg / total       0.82      0.81      0.81        42\n",
      "\n",
      "[10  3  5 24]\n",
      "MNB Accuracy:  0.8095238095238095\n",
      "MNB F1:  0.7857142857142857\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.62      0.70        13\n",
      "          1       0.84      0.93      0.89        29\n",
      "\n",
      "avg / total       0.83      0.83      0.83        42\n",
      "\n",
      "[ 8  5  2 27]\n",
      "svc Accuracy:  0.8333333333333334\n",
      "svc F1:  0.7904490377761939\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        13\n",
      "          1       0.83      1.00      0.91        29\n",
      "\n",
      "avg / total       0.88      0.86      0.84        42\n",
      "\n",
      "[ 7  6  0 29]\n",
      "LR Accuracy:  0.8571428571428571\n",
      "LR F1:  0.8031250000000001\n",
      "For name:  a_palma\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0003-2099-1297': 34, '0000-0002-8530-4913': 13, '0000-0002-5971-3676': 8, '0000-0003-0420-1785': 3, '0000-0002-1682-7032': 2, '0000-0002-7263-4868': 1})\n",
      "['0000-0002-8530-4913', '0000-0003-2099-1297']\n",
      "Total sample size after apply threshold:  47\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 12)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 12)\n",
      "2\n",
      "(47, 24)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        13\n",
      "          1       0.92      1.00      0.96        34\n",
      "\n",
      "avg / total       0.94      0.94      0.93        47\n",
      "\n",
      "[10  3  0 34]\n",
      "MNB Accuracy:  0.9361702127659575\n",
      "MNB F1:  0.913655848132272\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.77      0.80        13\n",
      "          1       0.91      0.94      0.93        34\n",
      "\n",
      "avg / total       0.89      0.89      0.89        47\n",
      "\n",
      "[10  3  2 32]\n",
      "svc Accuracy:  0.8936170212765957\n",
      "svc F1:  0.863768115942029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.87      1.00      0.93        34\n",
      "\n",
      "avg / total       0.91      0.89      0.88        47\n",
      "\n",
      "[ 8  5  0 34]\n",
      "LR Accuracy:  0.8936170212765957\n",
      "LR F1:  0.8467058056099153\n",
      "For name:  e_shaw\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0003-1424-7568': 9, '0000-0002-5653-0145': 4, '0000-0002-4148-3526': 2, '0000-0002-4334-1900': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_cameron\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0001-5788-8790': 17, '0000-0002-2277-7035': 9, '0000-0001-9464-8796': 1, '0000-0002-2508-7718': 1})\n",
      "['0000-0001-5788-8790']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  a_reid\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-0523-926X': 18, '0000-0003-1752-3302': 18, '0000-0003-4713-2951': 6, '0000-0002-2500-2980': 2})\n",
      "['0000-0002-0523-926X', '0000-0003-1752-3302']\n",
      "Total sample size after apply threshold:  36\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 10)\n",
      "2\n",
      "(36, 41)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.26      0.28      0.27        18\n",
      "          1       0.24      0.22      0.23        18\n",
      "\n",
      "avg / total       0.25      0.25      0.25        36\n",
      "\n",
      "[ 5 13 14  4]\n",
      "MNB Accuracy:  0.25\n",
      "MNB F1:  0.2494208494208494\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.23      0.17      0.19        18\n",
      "          1       0.35      0.44      0.39        18\n",
      "\n",
      "avg / total       0.29      0.31      0.29        36\n",
      "\n",
      "[ 3 15 10  8]\n",
      "svc Accuracy:  0.3055555555555556\n",
      "svc F1:  0.29189614476789927\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.28      0.28      0.28        18\n",
      "          1       0.28      0.28      0.28        18\n",
      "\n",
      "avg / total       0.28      0.28      0.28        36\n",
      "\n",
      "[ 5 13 13  5]\n",
      "LR Accuracy:  0.2777777777777778\n",
      "LR F1:  0.2777777777777778\n",
      "For name:  d_gil\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0003-3179-1987': 23, '0000-0002-2770-4767': 16, '0000-0003-4241-1302': 16, '0000-0001-8910-2780': 4, '0000-0003-0791-8298': 1})\n",
      "['0000-0002-2770-4767', '0000-0003-3179-1987', '0000-0003-4241-1302']\n",
      "Total sample size after apply threshold:  55\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 36)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 13)\n",
      "2\n",
      "(55, 49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.25      0.32        16\n",
      "          1       0.64      0.78      0.71        23\n",
      "          2       0.61      0.69      0.65        16\n",
      "\n",
      "avg / total       0.58      0.60      0.58        55\n",
      "\n",
      "[ 4  7  5  3 18  2  2  3 11]\n",
      "MNB Accuracy:  0.6\n",
      "MNB F1:  0.5576470588235294\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.19      0.23        16\n",
      "          1       0.53      0.70      0.60        23\n",
      "          2       0.60      0.56      0.58        16\n",
      "\n",
      "avg / total       0.48      0.51      0.49        55\n",
      "\n",
      "[ 3  9  4  5 16  2  2  5  9]\n",
      "svc Accuracy:  0.509090909090909\n",
      "svc F1:  0.4717293256550712\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      0.12      0.17        16\n",
      "          1       0.59      0.74      0.65        23\n",
      "          2       0.53      0.62      0.57        16\n",
      "\n",
      "avg / total       0.48      0.53      0.49        55\n",
      "\n",
      "[ 2  8  6  3 17  3  2  4 10]\n",
      "LR Accuracy:  0.5272727272727272\n",
      "LR F1:  0.466395922917662\n",
      "For name:  s_morgan\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0003-4069-3801': 38, '0000-0001-5091-3148': 28, '0000-0002-5340-0652': 7, '0000-0001-9528-8323': 4, '0000-0002-1734-4710': 2, '0000-0002-7529-0028': 2, '0000-0001-7601-3551': 1, '0000-0001-7610-4496': 1})\n",
      "['0000-0003-4069-3801', '0000-0001-5091-3148']\n",
      "Total sample size after apply threshold:  66\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 33)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 24)\n",
      "2\n",
      "(66, 57)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.74      0.80        38\n",
      "          1       0.71      0.86      0.77        28\n",
      "\n",
      "avg / total       0.80      0.79      0.79        66\n",
      "\n",
      "[28 10  4 24]\n",
      "MNB Accuracy:  0.7878787878787878\n",
      "MNB F1:  0.7870967741935484\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.87      0.81        38\n",
      "          1       0.78      0.64      0.71        28\n",
      "\n",
      "avg / total       0.77      0.77      0.77        66\n",
      "\n",
      "[33  5 10 18]\n",
      "svc Accuracy:  0.7727272727272727\n",
      "svc F1:  0.7603485838779956\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79        38\n",
      "          1       0.74      0.61      0.67        28\n",
      "\n",
      "avg / total       0.74      0.74      0.74        66\n",
      "\n",
      "[32  6 11 17]\n",
      "LR Accuracy:  0.7424242424242424\n",
      "LR F1:  0.728395061728395\n",
      "For name:  p_ross\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0001-7105-7117': 14, '0000-0002-5051-5382': 10, '0000-0001-7984-6452': 2, '0000-0001-7645-7523': 1})\n",
      "['0000-0002-5051-5382', '0000-0001-7105-7117']\n",
      "Total sample size after apply threshold:  24\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 17)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 12)\n",
      "2\n",
      "(24, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.50      0.56        10\n",
      "          1       0.69      0.79      0.73        14\n",
      "\n",
      "avg / total       0.66      0.67      0.66        24\n",
      "\n",
      "[ 5  5  3 11]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.6444444444444445\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.50      0.56        10\n",
      "          1       0.69      0.79      0.73        14\n",
      "\n",
      "avg / total       0.66      0.67      0.66        24\n",
      "\n",
      "[ 5  5  3 11]\n",
      "svc Accuracy:  0.6666666666666666\n",
      "svc F1:  0.6444444444444445\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.40      0.47        10\n",
      "          1       0.65      0.79      0.71        14\n",
      "\n",
      "avg / total       0.62      0.62      0.61        24\n",
      "\n",
      "[ 4  6  3 11]\n",
      "LR Accuracy:  0.625\n",
      "LR F1:  0.5901328273244781\n",
      "For name:  l_simon\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0003-4321-8539': 7, '0000-0003-4870-1052': 4, '0000-0002-5010-4778': 2, '0000-0002-0148-4217': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  k_thomas\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0003-3436-2184': 23, '0000-0003-3355-9583': 23, '0000-0001-8152-9974': 6, '0000-0003-2980-2384': 5, '0000-0001-8836-4631': 3})\n",
      "['0000-0003-3436-2184', '0000-0003-3355-9583']\n",
      "Total sample size after apply threshold:  46\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 20)\n",
      "2\n",
      "(46, 50)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.91      0.84        23\n",
      "          1       0.89      0.74      0.81        23\n",
      "\n",
      "avg / total       0.84      0.83      0.82        46\n",
      "\n",
      "[21  2  6 17]\n",
      "MNB Accuracy:  0.8260869565217391\n",
      "MNB F1:  0.8247619047619048\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.87      0.87        23\n",
      "          1       0.87      0.87      0.87        23\n",
      "\n",
      "avg / total       0.87      0.87      0.87        46\n",
      "\n",
      "[20  3  3 20]\n",
      "svc Accuracy:  0.8695652173913043\n",
      "svc F1:  0.8695652173913043\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.89        23\n",
      "          1       0.91      0.87      0.89        23\n",
      "\n",
      "avg / total       0.89      0.89      0.89        46\n",
      "\n",
      "[21  2  3 20]\n",
      "LR Accuracy:  0.8913043478260869\n",
      "LR F1:  0.8912529550827424\n",
      "For name:  l_torres\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0002-0194-7875': 56, '0000-0002-4598-1899': 7, '0000-0002-2512-1074': 1, '0000-0001-9945-7331': 1})\n",
      "['0000-0002-0194-7875']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  56\n",
      "For name:  p_ding\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-3535-6053': 8, '0000-0003-2559-4696': 8, '0000-0002-2613-2496': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  g_morris\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0003-1731-8405': 50, '0000-0003-2588-6349': 23, '0000-0002-1097-4453': 19, '0000-0001-9893-6648': 16, '0000-0002-3067-3359': 15, '0000-0003-2892-8428': 5})\n",
      "['0000-0001-9893-6648', '0000-0003-2588-6349', '0000-0002-1097-4453', '0000-0002-3067-3359', '0000-0003-1731-8405']\n",
      "Total sample size after apply threshold:  123\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(123, 81)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(123, 23)\n",
      "2\n",
      "(123, 104)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.12      0.22        16\n",
      "          1       0.50      0.74      0.60        23\n",
      "          2       0.45      0.26      0.33        19\n",
      "          3       0.08      0.07      0.07        15\n",
      "          4       0.70      0.90      0.79        50\n",
      "\n",
      "avg / total       0.59      0.57      0.52       123\n",
      "\n",
      "[ 2  5  3  2  4  0 17  1  1  4  0  4  5  6  4  0  5  2  1  7  0  3  0  2\n",
      " 45]\n",
      "MNB Accuracy:  0.5691056910569106\n",
      "MNB F1:  0.4031189083820662\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.25      0.33        16\n",
      "          1       0.72      0.78      0.75        23\n",
      "          2       0.54      0.37      0.44        19\n",
      "          3       0.06      0.07      0.06        15\n",
      "          4       0.69      0.84      0.76        50\n",
      "\n",
      "avg / total       0.57      0.59      0.57       123\n",
      "\n",
      "[ 4  2  0  3  7  0 18  0  3  2  1  1  7  6  4  1  2  5  1  6  2  2  1  3\n",
      " 42]\n",
      "svc Accuracy:  0.5853658536585366\n",
      "svc F1:  0.4684212438244696\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.12      0.18        16\n",
      "          1       0.65      0.48      0.55        23\n",
      "          2       0.62      0.26      0.37        19\n",
      "          3       0.09      0.07      0.08        15\n",
      "          4       0.57      0.92      0.70        50\n",
      "\n",
      "avg / total       0.50      0.53      0.48       123\n",
      "\n",
      "[ 2  3  1  2  8  1 11  0  0 11  1  1  5  6  6  1  1  2  1 10  1  1  0  2\n",
      " 46]\n",
      "LR Accuracy:  0.5284552845528455\n",
      "LR F1:  0.37628034108950137\n",
      "For name:  s_andrews\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0003-4295-2686': 46, '0000-0002-2103-7748': 6, '0000-0002-3851-2197': 3, '0000-0003-0878-1182': 2, '0000-0002-5499-5125': 1, '0000-0003-2174-6728': 1, '0000-0003-4997-3906': 1})\n",
      "['0000-0003-4295-2686']\n",
      "Total sample size after apply threshold:  46\n",
      "For name:  b_yan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  129\n",
      "Counter({'0000-0001-8802-9606': 93, '0000-0003-4268-4757': 21, '0000-0003-3509-0686': 10, '0000-0001-7235-5554': 4, '0000-0003-2258-2817': 1})\n",
      "['0000-0003-4268-4757', '0000-0001-8802-9606', '0000-0003-3509-0686']\n",
      "Total sample size after apply threshold:  124\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(124, 50)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(124, 12)\n",
      "2\n",
      "(124, 62)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.29      0.43        21\n",
      "          1       0.79      0.99      0.88        93\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.73      0.79      0.73       124\n",
      "\n",
      "[ 6 15  0  1 92  0  0 10  0]\n",
      "MNB Accuracy:  0.7903225806451613\n",
      "MNB F1:  0.43492063492063493\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        21\n",
      "          1       0.90      1.00      0.95        93\n",
      "          2       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.93      0.92      0.91       124\n",
      "\n",
      "[15  6  0  0 93  0  0  4  6]\n",
      "svc Accuracy:  0.9193548387096774\n",
      "svc F1:  0.8441043083900226\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.17        21\n",
      "          1       0.77      1.00      0.87        93\n",
      "          2       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.83      0.77      0.70       124\n",
      "\n",
      "[ 2 19  0  0 93  0  0  9  1]\n",
      "LR Accuracy:  0.7741935483870968\n",
      "LR F1:  0.4082967012670386\n",
      "For name:  r_hu\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0001-6709-031X': 93, '0000-0001-7412-8451': 27, '0000-0001-6893-529X': 4, '0000-0001-5549-3082': 2, '0000-0002-7126-4076': 1, '0000-0001-5921-6891': 1})\n",
      "['0000-0001-6709-031X', '0000-0001-7412-8451']\n",
      "Total sample size after apply threshold:  120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(120, 55)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(120, 18)\n",
      "2\n",
      "(120, 73)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        93\n",
      "          1       0.70      0.70      0.70        27\n",
      "\n",
      "avg / total       0.87      0.87      0.87       120\n",
      "\n",
      "[85  8  8 19]\n",
      "MNB Accuracy:  0.8666666666666667\n",
      "MNB F1:  0.8088410991636799\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        93\n",
      "          1       1.00      0.59      0.74        27\n",
      "\n",
      "avg / total       0.92      0.91      0.90       120\n",
      "\n",
      "[93  0 11 16]\n",
      "svc Accuracy:  0.9083333333333333\n",
      "svc F1:  0.8441742415299256\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        93\n",
      "          1       1.00      0.44      0.62        27\n",
      "\n",
      "avg / total       0.89      0.88      0.86       120\n",
      "\n",
      "[93  0 15 12]\n",
      "LR Accuracy:  0.875\n",
      "LR F1:  0.7703788748564868\n",
      "For name:  j_braun\n",
      "total sample size before apply threshold:  72\n",
      "Counter({'0000-0002-8886-078X': 37, '0000-0002-4504-6235': 25, '0000-0002-8309-6401': 5, '0000-0002-2491-5788': 5})\n",
      "['0000-0002-8886-078X', '0000-0002-4504-6235']\n",
      "Total sample size after apply threshold:  62\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 22)\n",
      "2\n",
      "(62, 52)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.81      0.81        37\n",
      "          1       0.72      0.72      0.72        25\n",
      "\n",
      "avg / total       0.77      0.77      0.77        62\n",
      "\n",
      "[30  7  7 18]\n",
      "MNB Accuracy:  0.7741935483870968\n",
      "MNB F1:  0.7654054054054054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.89      0.82        37\n",
      "          1       0.79      0.60      0.68        25\n",
      "\n",
      "avg / total       0.78      0.77      0.77        62\n",
      "\n",
      "[33  4 10 15]\n",
      "svc Accuracy:  0.7741935483870968\n",
      "svc F1:  0.7534090909090909\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.97      0.86        37\n",
      "          1       0.93      0.56      0.70        25\n",
      "\n",
      "avg / total       0.83      0.81      0.79        62\n",
      "\n",
      "[36  1 11 14]\n",
      "LR Accuracy:  0.8064516129032258\n",
      "LR F1:  0.7785714285714286\n",
      "For name:  c_he\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0002-4868-331X': 20, '0000-0002-1918-5186': 13, '0000-0002-0663-275X': 7, '0000-0001-7869-7627': 5, '0000-0001-5426-769X': 2, '0000-0001-9867-9629': 1, '0000-0001-5842-9617': 1})\n",
      "['0000-0002-4868-331X', '0000-0002-1918-5186']\n",
      "Total sample size after apply threshold:  33\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 10)\n",
      "2\n",
      "(33, 38)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.90      0.78        20\n",
      "          1       0.71      0.38      0.50        13\n",
      "\n",
      "avg / total       0.70      0.70      0.67        33\n",
      "\n",
      "[18  2  8  5]\n",
      "MNB Accuracy:  0.696969696969697\n",
      "MNB F1:  0.6413043478260869\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.90      0.78        20\n",
      "          1       0.71      0.38      0.50        13\n",
      "\n",
      "avg / total       0.70      0.70      0.67        33\n",
      "\n",
      "[18  2  8  5]\n",
      "svc Accuracy:  0.696969696969697\n",
      "svc F1:  0.6413043478260869\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.90      0.78        20\n",
      "          1       0.71      0.38      0.50        13\n",
      "\n",
      "avg / total       0.70      0.70      0.67        33\n",
      "\n",
      "[18  2  8  5]\n",
      "LR Accuracy:  0.696969696969697\n",
      "LR F1:  0.6413043478260869\n",
      "For name:  w_lu\n",
      "total sample size before apply threshold:  138\n",
      "Counter({'0000-0003-4731-1976': 38, '0000-0001-6722-1527': 33, '0000-0001-5358-305X': 30, '0000-0001-7421-347X': 13, '0000-0002-1405-4806': 6, '0000-0001-9798-8964': 4, '0000-0003-4334-5722': 3, '0000-0002-6570-3044': 3, '0000-0002-5243-5554': 2, '0000-0001-5508-342X': 2, '0000-0002-1398-9933': 1, '0000-0001-6214-4024': 1, '0000-0002-5101-9778': 1, '0000-0002-4528-2246': 1})\n",
      "['0000-0001-5358-305X', '0000-0003-4731-1976', '0000-0001-7421-347X', '0000-0001-6722-1527']\n",
      "Total sample size after apply threshold:  114\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 27)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 15)\n",
      "2\n",
      "(114, 42)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.93      0.82        30\n",
      "          1       0.85      0.61      0.71        38\n",
      "          2       0.91      0.77      0.83        13\n",
      "          3       0.68      0.79      0.73        33\n",
      "\n",
      "avg / total       0.78      0.76      0.76       114\n",
      "\n",
      "[28  1  0  1  4 23  1 10  2  0 10  1  4  3  0 26]\n",
      "MNB Accuracy:  0.7631578947368421\n",
      "MNB F1:  0.7742373547468824\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        30\n",
      "          1       0.82      0.71      0.76        38\n",
      "          2       1.00      0.92      0.96        13\n",
      "          3       0.69      0.73      0.71        33\n",
      "\n",
      "avg / total       0.82      0.82      0.81       114\n",
      "\n",
      "[30  0  0  0  0 27  0 11  0  1 12  0  4  5  0 24]\n",
      "svc Accuracy:  0.8157894736842105\n",
      "svc F1:  0.8409864333057167\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.93      0.84        30\n",
      "          1       0.78      0.66      0.71        38\n",
      "          2       1.00      0.77      0.87        13\n",
      "          3       0.66      0.70      0.68        33\n",
      "\n",
      "avg / total       0.76      0.75      0.75       114\n",
      "\n",
      "[28  1  0  1  3 25  0 10  2  0 10  1  4  6  0 23]\n",
      "LR Accuracy:  0.7543859649122807\n",
      "LR F1:  0.7740356038586752\n",
      "For name:  r_radhakrishnan\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0003-0088-4777': 35, '0000-0002-8220-655X': 14, '0000-0001-6616-8525': 7, '0000-0001-7170-699X': 5, '0000-0002-3560-1020': 1})\n",
      "['0000-0003-0088-4777', '0000-0002-8220-655X']\n",
      "Total sample size after apply threshold:  49\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 9)\n",
      "2\n",
      "(49, 44)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.91      0.82        35\n",
      "          1       0.50      0.21      0.30        14\n",
      "\n",
      "avg / total       0.67      0.71      0.67        49\n",
      "\n",
      "[32  3 11  3]\n",
      "MNB Accuracy:  0.7142857142857143\n",
      "MNB F1:  0.5602564102564103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90        35\n",
      "          1       1.00      0.43      0.60        14\n",
      "\n",
      "avg / total       0.87      0.84      0.81        49\n",
      "\n",
      "[35  0  8  6]\n",
      "svc Accuracy:  0.8367346938775511\n",
      "svc F1:  0.7487179487179487"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        35\n",
      "          1       1.00      0.14      0.25        14\n",
      "\n",
      "avg / total       0.82      0.76      0.68        49\n",
      "\n",
      "[35  0 12  2]\n",
      "LR Accuracy:  0.7551020408163265\n",
      "LR F1:  0.5518292682926829\n",
      "For name:  k_saito\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0003-4663-1134': 26, '0000-0002-2151-6204': 16, '0000-0002-5726-8775': 11, '0000-0003-2557-1726': 7, '0000-0001-6310-5342': 1})\n",
      "['0000-0002-2151-6204', '0000-0003-4663-1134', '0000-0002-5726-8775']\n",
      "Total sample size after apply threshold:  53\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 34)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 20)\n",
      "2\n",
      "(53, 54)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.31      0.32        16\n",
      "          1       0.58      0.73      0.64        26\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.38      0.45      0.41        53\n",
      "\n",
      "[ 5  8  3  5 19  2  5  6  0]\n",
      "MNB Accuracy:  0.4528301886792453\n",
      "MNB F1:  0.32221614725715325\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.28      0.31      0.29        16\n",
      "          1       0.55      0.65      0.60        26\n",
      "          2       0.25      0.09      0.13        11\n",
      "\n",
      "avg / total       0.40      0.43      0.41        53\n",
      "\n",
      "[ 5  9  2  8 17  1  5  5  1]\n",
      "svc Accuracy:  0.4339622641509434\n",
      "svc F1:  0.34131406948744414\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      0.25      0.27        16\n",
      "          1       0.57      0.77      0.66        26\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.37      0.45      0.40        53\n",
      "\n",
      "[ 4  9  3  5 20  1  5  6  0]\n",
      "LR Accuracy:  0.4528301886792453\n",
      "LR F1:  0.30746812386156647\n",
      "For name:  y_wang\n",
      "total sample size before apply threshold:  1689\n",
      "Counter({'0000-0001-8592-0698': 121, '0000-0003-0852-0767': 117, '0000-0002-6227-6112': 69, '0000-0001-5803-5343': 60, '0000-0002-1211-2822': 57, '0000-0002-3063-3066': 55, '0000-0003-2067-382X': 54, '0000-0003-0773-1212': 42, '0000-0002-6574-6706': 40, '0000-0001-9574-2194': 37, '0000-0001-5764-6740': 35, '0000-0001-6046-2934': 31, '0000-0001-8043-5757': 31, '0000-0003-2533-865X': 31, '0000-0001-8619-0455': 30, '0000-0003-0764-2279': 30, '0000-0002-9893-8296': 29, '0000-0001-7076-8312': 29, '0000-0001-5291-9826': 28, '0000-0002-0921-0122': 27, '0000-0003-3557-5085': 26, '0000-0002-0474-4790': 25, '0000-0003-2540-2199': 24, '0000-0003-0513-9039': 22, '0000-0003-3011-1919': 18, '0000-0002-1241-6252': 17, '0000-0002-5845-5150': 17, '0000-0001-9753-5535': 16, '0000-0003-0961-1716': 16, '0000-0001-6321-9542': 15, '0000-0002-0768-1676': 15, '0000-0002-7851-1623': 14, '0000-0003-1360-8931': 14, '0000-0001-7042-9804': 14, '0000-0002-5985-5244': 13, '0000-0001-5716-3183': 13, '0000-0002-7243-441X': 13, '0000-0002-0363-926X': 13, '0000-0001-6790-1311': 12, '0000-0003-0266-0224': 12, '0000-0001-8440-9388': 12, '0000-0002-2110-623X': 11, '0000-0002-2626-478X': 11, '0000-0001-8021-5180': 11, '0000-0001-8697-9165': 11, '0000-0002-1786-5970': 11, '0000-0003-0144-1388': 11, '0000-0002-3002-8069': 10, '0000-0002-6822-4778': 9, '0000-0002-9659-977X': 9, '0000-0002-8601-8302': 9, '0000-0001-9032-9990': 9, '0000-0002-1851-3483': 9, '0000-0002-1255-0937': 9, '0000-0002-7209-585X': 9, '0000-0002-5111-1443': 9, '0000-0002-6295-6492': 8, '0000-0002-4847-6273': 8, '0000-0002-0002-2467': 8, '0000-0002-7389-5066': 8, '0000-0003-2561-1855': 7, '0000-0003-1286-2401': 7, '0000-0002-2900-5126': 7, '0000-0003-3594-2658': 7, '0000-0003-4816-9182': 6, '0000-0001-5580-7766': 6, '0000-0002-0582-0855': 6, '0000-0002-3034-7377': 6, '0000-0002-2188-383X': 6, '0000-0003-1567-3358': 6, '0000-0001-5020-2020': 6, '0000-0001-9997-7636': 5, '0000-0002-6401-7464': 5, '0000-0003-3620-8455': 5, '0000-0002-2532-4832': 5, '0000-0002-3823-2136': 5, '0000-0002-5300-7121': 4, '0000-0002-7986-4500': 4, '0000-0003-3430-2210': 4, '0000-0002-3769-0020': 4, '0000-0001-8925-5277': 4, '0000-0001-6232-0382': 4, '0000-0003-2763-1008': 3, '0000-0001-5231-6283': 3, '0000-0003-3222-0211': 3, '0000-0002-5590-5881': 3, '0000-0002-3729-2743': 3, '0000-0002-1769-1966': 3, '0000-0003-1786-5767': 3, '0000-0003-0708-1950': 2, '0000-0002-1609-2523': 2, '0000-0001-8518-6745': 2, '0000-0001-5495-5839': 2, '0000-0003-1681-9566': 2, '0000-0001-9474-6396': 2, '0000-0001-6108-5157': 2, '0000-0001-5500-1228': 2, '0000-0002-8648-2172': 2, '0000-0002-3184-4201': 2, '0000-0003-3432-0603': 2, '0000-0002-8937-3000': 2, '0000-0002-0676-5886': 2, '0000-0003-1154-820X': 2, '0000-0002-5223-4074': 2, '0000-0001-6264-650X': 2, '0000-0002-6066-2634': 2, '0000-0003-1404-8526': 2, '0000-0003-3928-6926': 2, '0000-0002-5399-2803': 2, '0000-0002-1288-8997': 2, '0000-0001-6085-5615': 2, '0000-0002-3656-4284': 2, '0000-0002-5187-3755': 2, '0000-0002-9628-1382': 2, '0000-0002-2244-1742': 2, '0000-0003-1009-2087': 1, '0000-0001-6823-1225': 1, '0000-0002-5692-3117': 1, '0000-0001-6981-7797': 1, '0000-0001-7956-3102': 1, '0000-0002-2657-7057': 1, '0000-0002-2665-0365': 1, '0000-0002-4336-0474': 1, '0000-0002-7629-4178': 1, '0000-0001-5918-7525': 1, '0000-0002-0891-1517': 1, '0000-0002-9684-1730': 1, '0000-0002-2932-6042': 1, '0000-0001-8538-5998': 1, '0000-0002-4506-4230': 1, '0000-0003-3120-827X': 1, '0000-0002-9640-0871': 1, '0000-0003-3511-0288': 1, '0000-0001-9156-0377': 1, '0000-0002-7281-1908': 1, '0000-0003-2540-5824': 1, '0000-0002-9365-1851': 1, '0000-0002-2333-157X': 1})\n",
      "['0000-0002-0474-4790', '0000-0001-6790-1311', '0000-0002-2110-623X', '0000-0001-5291-9826', '0000-0002-7851-1623', '0000-0002-1241-6252', '0000-0001-5764-6740', '0000-0001-6046-2934', '0000-0002-0921-0122', '0000-0003-0266-0224', '0000-0002-5985-5244', '0000-0003-1360-8931', '0000-0002-9893-8296', '0000-0002-2626-478X', '0000-0001-8021-5180', '0000-0002-5845-5150', '0000-0003-2540-2199', '0000-0001-8619-0455', '0000-0001-6321-9542', '0000-0003-0513-9039', '0000-0002-1211-2822', '0000-0001-8697-9165', '0000-0002-3063-3066', '0000-0001-5716-3183', '0000-0001-8043-5757', '0000-0002-3002-8069', '0000-0001-7076-8312', '0000-0001-9753-5535', '0000-0003-0961-1716', '0000-0001-8592-0698', '0000-0003-0852-0767', '0000-0002-1786-5970', '0000-0003-0764-2279', '0000-0001-5803-5343', '0000-0002-7243-441X', '0000-0003-2067-382X', '0000-0001-7042-9804', '0000-0002-0768-1676', '0000-0002-0363-926X', '0000-0001-9574-2194', '0000-0003-3557-5085', '0000-0002-6574-6706', '0000-0003-0773-1212', '0000-0003-2533-865X', '0000-0003-3011-1919', '0000-0002-6227-6112', '0000-0003-0144-1388', '0000-0001-8440-9388']\n",
      "Total sample size after apply threshold:  1370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(1370, 492)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(1370, 28)\n",
      "2\n",
      "(1370, 520)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.40      0.45        25\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.00      0.00      0.00        28\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       0.00      0.00      0.00        17\n",
      "          6       0.87      0.37      0.52        35\n",
      "          7       0.30      0.10      0.15        31\n",
      "          8       0.60      0.11      0.19        27\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       0.00      0.00      0.00        13\n",
      "         11       0.00      0.00      0.00        14\n",
      "         12       0.17      0.07      0.10        29\n",
      "         13       0.00      0.00      0.00        11\n",
      "         14       0.00      0.00      0.00        11\n",
      "         15       0.00      0.00      0.00        17\n",
      "         16       0.00      0.00      0.00        24\n",
      "         17       0.07      0.03      0.04        30\n",
      "         18       0.00      0.00      0.00        15\n",
      "         19       1.00      0.05      0.09        22\n",
      "         20       0.56      0.26      0.36        57\n",
      "         21       0.00      0.00      0.00        11\n",
      "         22       0.56      0.18      0.27        55\n",
      "         23       0.00      0.00      0.00        13\n",
      "         24       0.00      0.00      0.00        31\n",
      "         25       0.00      0.00      0.00        10\n",
      "         26       1.00      0.07      0.13        29\n",
      "         27       0.00      0.00      0.00        16\n",
      "         28       0.00      0.00      0.00        16\n",
      "         29       0.19      0.75      0.30       121\n",
      "         30       0.21      0.74      0.32       117\n",
      "         31       0.00      0.00      0.00        11\n",
      "         32       0.29      0.27      0.28        30\n",
      "         33       0.40      0.52      0.45        60\n",
      "         34       0.00      0.00      0.00        13\n",
      "         35       0.62      0.37      0.47        54\n",
      "         36       0.00      0.00      0.00        14\n",
      "         37       0.00      0.00      0.00        15\n",
      "         38       0.00      0.00      0.00        13\n",
      "         39       0.93      0.68      0.78        37\n",
      "         40       0.22      0.15      0.18        26\n",
      "         41       0.00      0.00      0.00        40\n",
      "         42       1.00      0.14      0.25        42\n",
      "         43       0.00      0.00      0.00        31\n",
      "         44       0.67      0.11      0.19        18\n",
      "         45       0.25      0.51      0.33        69\n",
      "         46       0.00      0.00      0.00        11\n",
      "         47       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.30      0.27      0.21      1370\n",
      "\n",
      "[10  0  0 ...  3  0  0]\n",
      "MNB Accuracy:  0.2686131386861314\n",
      "MNB F1:  0.12186759940838543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.60      0.53        25\n",
      "          1       1.00      0.08      0.15        12\n",
      "          2       0.45      0.45      0.45        11\n",
      "          3       0.58      0.25      0.35        28\n",
      "          4       0.60      0.43      0.50        14\n",
      "          5       0.88      0.41      0.56        17\n",
      "          6       0.94      0.46      0.62        35\n",
      "          7       0.33      0.35      0.34        31\n",
      "          8       0.71      0.63      0.67        27\n",
      "          9       0.50      0.17      0.25        12\n",
      "         10       1.00      0.54      0.70        13\n",
      "         11       0.30      0.21      0.25        14\n",
      "         12       0.65      0.45      0.53        29\n",
      "         13       0.00      0.00      0.00        11\n",
      "         14       1.00      0.18      0.31        11\n",
      "         15       0.21      0.18      0.19        17\n",
      "         16       0.33      0.33      0.33        24\n",
      "         17       0.24      0.23      0.24        30\n",
      "         18       0.58      0.47      0.52        15\n",
      "         19       0.82      0.41      0.55        22\n",
      "         20       0.63      0.39      0.48        57\n",
      "         21       0.29      0.18      0.22        11\n",
      "         22       0.37      0.35      0.36        55\n",
      "         23       0.62      0.38      0.48        13\n",
      "         24       0.12      0.06      0.09        31\n",
      "         25       0.33      0.20      0.25        10\n",
      "         26       0.91      0.34      0.50        29\n",
      "         27       0.33      0.06      0.11        16\n",
      "         28       0.50      0.06      0.11        16\n",
      "         29       0.27      0.69      0.39       121\n",
      "         30       0.48      0.64      0.55       117\n",
      "         31       0.42      0.45      0.43        11\n",
      "         32       0.29      0.47      0.36        30\n",
      "         33       0.48      0.68      0.56        60\n",
      "         34       0.00      0.00      0.00        13\n",
      "         35       0.66      0.46      0.54        54\n",
      "         36       0.25      0.14      0.18        14\n",
      "         37       0.80      0.27      0.40        15\n",
      "         38       0.00      0.00      0.00        13\n",
      "         39       0.88      0.76      0.81        37\n",
      "         40       0.26      0.38      0.31        26\n",
      "         41       0.35      0.15      0.21        40\n",
      "         42       0.88      0.52      0.66        42\n",
      "         43       0.58      0.35      0.44        31\n",
      "         44       0.82      0.50      0.62        18\n",
      "         45       0.31      0.62      0.42        69\n",
      "         46       1.00      0.18      0.31        11\n",
      "         47       0.50      0.08      0.14        12\n",
      "\n",
      "avg / total       0.50      0.43      0.42      1370\n",
      "\n",
      "[15  0  1 ...  6  0  1]\n",
      "svc Accuracy:  0.4313868613138686\n",
      "svc F1:  0.3742112817826901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.60      0.58        25\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.25      0.40        28\n",
      "          4       0.57      0.29      0.38        14\n",
      "          5       0.75      0.18      0.29        17\n",
      "          6       0.83      0.43      0.57        35\n",
      "          7       0.37      0.32      0.34        31\n",
      "          8       0.58      0.52      0.55        27\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       1.00      0.31      0.47        13\n",
      "         11       0.50      0.43      0.46        14\n",
      "         12       0.59      0.45      0.51        29\n",
      "         13       0.00      0.00      0.00        11\n",
      "         14       0.00      0.00      0.00        11\n",
      "         15       0.00      0.00      0.00        17\n",
      "         16       0.30      0.12      0.18        24\n",
      "         17       0.23      0.23      0.23        30\n",
      "         18       0.42      0.33      0.37        15\n",
      "         19       0.82      0.41      0.55        22\n",
      "         20       0.49      0.35      0.41        57\n",
      "         21       0.00      0.00      0.00        11\n",
      "         22       0.42      0.27      0.33        55\n",
      "         23       0.40      0.15      0.22        13\n",
      "         24       0.10      0.03      0.05        31\n",
      "         25       0.00      0.00      0.00        10\n",
      "         26       1.00      0.24      0.39        29\n",
      "         27       0.00      0.00      0.00        16\n",
      "         28       0.00      0.00      0.00        16\n",
      "         29       0.25      0.66      0.36       121\n",
      "         30       0.38      0.68      0.49       117\n",
      "         31       0.33      0.27      0.30        11\n",
      "         32       0.30      0.57      0.40        30\n",
      "         33       0.35      0.62      0.45        60\n",
      "         34       0.00      0.00      0.00        13\n",
      "         35       0.56      0.43      0.48        54\n",
      "         36       0.00      0.00      0.00        14\n",
      "         37       0.57      0.27      0.36        15\n",
      "         38       0.00      0.00      0.00        13\n",
      "         39       0.88      0.78      0.83        37\n",
      "         40       0.29      0.42      0.34        26\n",
      "         41       0.30      0.07      0.12        40\n",
      "         42       0.87      0.31      0.46        42\n",
      "         43       0.50      0.16      0.24        31\n",
      "         44       0.55      0.33      0.41        18\n",
      "         45       0.25      0.62      0.35        69\n",
      "         46       0.00      0.00      0.00        11\n",
      "         47       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.41      0.38      0.34      1370\n",
      "\n",
      "[15  0  0 ...  7  0  0]\n",
      "LR Accuracy:  0.37518248175182484\n",
      "LR F1:  0.2680108283248223\n",
      "For name:  j_gao\n",
      "total sample size before apply threshold:  222\n",
      "Counter({'0000-0003-3215-7013': 44, '0000-0001-9341-1287': 36, '0000-0001-9778-4312': 26, '0000-0002-6200-4141': 24, '0000-0001-9803-0256': 20, '0000-0001-5732-9905': 14, '0000-0002-4545-1126': 12, '0000-0002-9943-4786': 12, '0000-0002-5739-1781': 11, '0000-0002-3952-208X': 8, '0000-0003-2059-0290': 7, '0000-0002-9959-5600': 2, '0000-0001-6659-5770': 1, '0000-0002-1181-4531': 1, '0000-0003-1160-6553': 1, '0000-0003-2668-6672': 1, '0000-0003-4024-4694': 1, '0000-0002-5977-0021': 1})\n",
      "['0000-0002-6200-4141', '0000-0001-5732-9905', '0000-0001-9341-1287', '0000-0003-3215-7013', '0000-0001-9778-4312', '0000-0002-5739-1781', '0000-0002-4545-1126', '0000-0002-9943-4786', '0000-0001-9803-0256']\n",
      "Total sample size after apply threshold:  199\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(199, 80)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(199, 16)\n",
      "2\n",
      "(199, 96)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.21      0.29        24\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.31      0.44      0.37        36\n",
      "          3       0.30      0.61      0.40        44\n",
      "          4       0.39      0.58      0.47        26\n",
      "          5       0.00      0.00      0.00        11\n",
      "          6       0.00      0.00      0.00        12\n",
      "          7       1.00      0.17      0.29        12\n",
      "          8       1.00      0.30      0.46        20\n",
      "\n",
      "avg / total       0.40      0.36      0.32       199\n",
      "\n",
      "[ 5  0  4 11  4  0  0  0  0  0  0  6  7  1  0  0  0  0  2  0 16 14  4  0\n",
      "  0  0  0  1  1 11 27  4  0  0  0  0  0  0  4  7 15  0  0  0  0  0  0  4\n",
      "  4  3  0  0  0  0  0  0  3  9  0  0  0  0  0  0  0  3  3  4  0  0  2  0\n",
      "  2  0  0  9  3  0  0  0  6]\n",
      "MNB Accuracy:  0.35678391959798994\n",
      "MNB F1:  0.2531040540295104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.50      0.52        24\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.30      0.39      0.34        36\n",
      "          3       0.33      0.57      0.42        44\n",
      "          4       0.85      0.65      0.74        26\n",
      "          5       1.00      0.18      0.31        11\n",
      "          6       0.29      0.17      0.21        12\n",
      "          7       1.00      0.58      0.74        12\n",
      "          8       1.00      0.55      0.71        20\n",
      "\n",
      "avg / total       0.54      0.45      0.46       199\n",
      "\n",
      "[12  0  6  6  0  0  0  0  0  0  0  6  6  2  0  0  0  0  4  2 14 16  0  0\n",
      "  0  0  0  2  2 10 25  1  0  4  0  0  0  4  0  4 17  0  1  0  0  0  0  4\n",
      "  5  0  2  0  0  0  1  0  2  7  0  0  2  0  0  1  0  2  2  0  0  0  7  0\n",
      "  2  0  2  5  0  0  0  0 11]\n",
      "svc Accuracy:  0.45226130653266333\n",
      "svc F1:  0.4426375327353314\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.42      0.51        24\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.36      0.50      0.42        36\n",
      "          3       0.34      0.59      0.43        44\n",
      "          4       0.46      0.62      0.52        26\n",
      "          5       1.00      0.18      0.31        11\n",
      "          6       0.00      0.00      0.00        12\n",
      "          7       1.00      0.33      0.50        12\n",
      "          8       1.00      0.50      0.67        20\n",
      "\n",
      "avg / total       0.50      0.43      0.42       199\n",
      "\n",
      "[10  0  4  9  1  0  0  0  0  0  0  7  6  1  0  0  0  0  2  0 18 12  4  0\n",
      "  0  0  0  1  0  9 26  4  0  4  0  0  0  1  3  5 16  0  1  0  0  0  0  4\n",
      "  2  3  2  0  0  0  0  0  3  9  0  0  0  0  0  0  0  2  2  4  0  0  4  0\n",
      "  2  0  0  6  2  0  0  0 10]\n",
      "LR Accuracy:  0.4321608040201005\n",
      "LR F1:  0.37334737426582293\n",
      "For name:  d_fernandes\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0003-0599-3200': 20, '0000-0002-5056-5734': 9, '0000-0001-5263-2737': 5, '0000-0001-6155-6246': 4, '0000-0002-2208-6349': 1, '0000-0003-3466-9450': 1})\n",
      "['0000-0003-0599-3200']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  c_silva\n",
      "total sample size before apply threshold:  148\n",
      "Counter({'0000-0003-4521-6377': 23, '0000-0001-6348-0505': 16, '0000-0001-6252-8693': 13, '0000-0002-7870-8848': 9, '0000-0002-9310-2457': 9, '0000-0002-1015-5095': 8, '0000-0002-0495-3955': 8, '0000-0002-2357-3405': 7, '0000-0003-1413-8038': 7, '0000-0002-1399-6674': 4, '0000-0002-1439-9214': 3, '0000-0002-9413-4573': 3, '0000-0003-0104-8412': 3, '0000-0003-4331-3755': 3, '0000-0002-5831-2993': 3, '0000-0001-7590-9639': 2, '0000-0002-1196-306X': 2, '0000-0002-1549-6833': 2, '0000-0002-7103-9100': 2, '0000-0002-7092-1169': 2, '0000-0001-6827-8939': 2, '0000-0002-7238-546X': 2, '0000-0002-1771-1517': 2, '0000-0003-1731-7883': 2, '0000-0003-4327-5744': 1, '0000-0002-5656-0061': 1, '0000-0001-6475-6622': 1, '0000-0003-2701-179X': 1, '0000-0001-8172-5860': 1, '0000-0001-9777-8406': 1, '0000-0002-4327-6272': 1, '0000-0002-5077-5176': 1, '0000-0002-7477-1495': 1, '0000-0003-2506-1435': 1, '0000-0002-9148-5458': 1})\n",
      "['0000-0001-6348-0505', '0000-0003-4521-6377', '0000-0001-6252-8693']\n",
      "Total sample size after apply threshold:  52\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 27)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 15)\n",
      "2\n",
      "(52, 42)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        16\n",
      "          1       0.68      0.74      0.71        23\n",
      "          2       0.62      0.38      0.48        13\n",
      "\n",
      "avg / total       0.72      0.73      0.71        52\n",
      "\n",
      "[16  0  0  3 17  3  0  8  5]\n",
      "MNB Accuracy:  0.7307692307692307\n",
      "MNB F1:  0.6996031746031747\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       0.78      0.91      0.84        23\n",
      "          2       0.78      0.54      0.64        13\n",
      "\n",
      "avg / total       0.85      0.85      0.84        52\n",
      "\n",
      "[16  0  0  0 21  2  0  6  7]\n",
      "svc Accuracy:  0.8461538461538461\n",
      "svc F1:  0.8254545454545453\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.67      0.96      0.79        23\n",
      "          2       0.80      0.31      0.44        13\n",
      "\n",
      "avg / total       0.80      0.77      0.75        52\n",
      "\n",
      "[14  2  0  0 22  1  0  9  4]\n",
      "LR Accuracy:  0.7692307692307693\n",
      "LR F1:  0.7211640211640211\n",
      "For name:  t_fitzgerald\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-3855-1591': 31, '0000-0002-2370-8496': 21, '0000-0001-9898-1166': 1, '0000-0002-1532-517X': 1})\n",
      "['0000-0002-3855-1591', '0000-0002-2370-8496']\n",
      "Total sample size after apply threshold:  52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 10)\n",
      "2\n",
      "(52, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.97      0.88        31\n",
      "          1       0.93      0.67      0.78        21\n",
      "\n",
      "avg / total       0.86      0.85      0.84        52\n",
      "\n",
      "[30  1  7 14]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.8300653594771241\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.94      0.83        31\n",
      "          1       0.85      0.52      0.65        21\n",
      "\n",
      "avg / total       0.79      0.77      0.76        52\n",
      "\n",
      "[29  2 10 11]\n",
      "svc Accuracy:  0.7692307692307693\n",
      "svc F1:  0.7378151260504202\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.97      0.86        31\n",
      "          1       0.92      0.57      0.71        21\n",
      "\n",
      "avg / total       0.83      0.81      0.80        52\n",
      "\n",
      "[30  1  9 12]\n",
      "LR Accuracy:  0.8076923076923077\n",
      "LR F1:  0.7815126050420169\n",
      "For name:  j_mitchell\n",
      "total sample size before apply threshold:  143\n",
      "Counter({'0000-0002-0379-6097': 57, '0000-0002-8445-0935': 32, '0000-0002-7147-4604': 16, '0000-0002-2361-9805': 14, '0000-0003-4956-1530': 11, '0000-0002-2520-8428': 6, '0000-0001-6785-9352': 3, '0000-0002-0710-5580': 3, '0000-0002-8624-5070': 1})\n",
      "['0000-0002-0379-6097', '0000-0002-8445-0935', '0000-0002-7147-4604', '0000-0003-4956-1530', '0000-0002-2361-9805']\n",
      "Total sample size after apply threshold:  130\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 77)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 16)\n",
      "2\n",
      "(130, 93)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.98      0.75        57\n",
      "          1       0.69      0.56      0.62        32\n",
      "          2       0.50      0.12      0.20        16\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.71      0.36      0.48        14\n",
      "\n",
      "avg / total       0.57      0.62      0.56       130\n",
      "\n",
      "[56  0  0  0  1 12 18  1  0  1 10  4  2  0  0  8  2  1  0  0  7  2  0  0\n",
      "  5]\n",
      "MNB Accuracy:  0.6230769230769231\n",
      "MNB F1:  0.40870935960591137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.95      0.79        57\n",
      "          1       0.56      0.56      0.56        32\n",
      "          2       0.57      0.25      0.35        16\n",
      "          3       0.50      0.18      0.27        11\n",
      "          4       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.65      0.65      0.62       130\n",
      "\n",
      "[54  3  0  0  0 12 18  2  0  0  5  6  4  1  0  5  3  1  2  0  4  2  0  1\n",
      "  7]\n",
      "svc Accuracy:  0.6538461538461539\n",
      "svc F1:  0.5263961176346134\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      1.00      0.75        57\n",
      "          1       0.68      0.53      0.60        32\n",
      "          2       1.00      0.12      0.22        16\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.66      0.64      0.57       130\n",
      "\n",
      "[57  0  0  0  0 15 17  0  0  0 10  4  2  0  0  9  2  0  0  0  5  2  0  0\n",
      "  7]\n",
      "LR Accuracy:  0.6384615384615384\n",
      "LR F1:  0.4460956312349501\n",
      "For name:  a_gomes\n",
      "total sample size before apply threshold:  244\n",
      "Counter({'0000-0002-9819-3036': 44, '0000-0002-0567-064X': 42, '0000-0002-5940-9893': 32, '0000-0001-7883-2446': 20, '0000-0002-8221-6985': 19, '0000-0003-1052-8004': 18, '0000-0002-3348-0448': 16, '0000-0001-9598-1275': 13, '0000-0002-4989-6026': 7, '0000-0003-3976-238X': 6, '0000-0002-6390-9866': 6, '0000-0001-9565-8814': 5, '0000-0003-1998-0291': 5, '0000-0002-1707-9208': 3, '0000-0001-8702-4360': 2, '0000-0002-9793-4816': 1, '0000-0003-0010-2608': 1, '0000-0002-3498-7734': 1, '0000-0001-5466-0272': 1, '0000-0002-3332-834X': 1, '0000-0002-3201-0081': 1})\n",
      "['0000-0002-9819-3036', '0000-0002-5940-9893', '0000-0003-1052-8004', '0000-0002-8221-6985', '0000-0001-9598-1275', '0000-0001-7883-2446', '0000-0002-3348-0448', '0000-0002-0567-064X']\n",
      "Total sample size after apply threshold:  204\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(204, 104)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(204, 23)\n",
      "2\n",
      "(204, 127)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.68      0.57        44\n",
      "          1       0.53      1.00      0.70        32\n",
      "          2       0.57      0.22      0.32        18\n",
      "          3       0.75      0.47      0.58        19\n",
      "          4       0.00      0.00      0.00        13\n",
      "          5       1.00      0.15      0.26        20\n",
      "          6       0.00      0.00      0.00        16\n",
      "          7       0.41      0.57      0.48        42\n",
      "\n",
      "avg / total       0.49      0.50      0.44       204\n",
      "\n",
      "[30  2  2  0  0  0  0 10  0 32  0  0  0  0  0  0  5  2  4  0  0  0  1  6\n",
      "  3  5  0  9  0  0  0  2  3  5  0  0  0  0  0  5  4  5  0  1  0  3  0  7\n",
      "  7  2  1  1  0  0  0  5  9  7  0  1  0  0  1 24]\n",
      "MNB Accuracy:  0.5\n",
      "MNB F1:  0.3629803745752255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.61      0.60        44\n",
      "          1       1.00      1.00      1.00        32\n",
      "          2       0.58      0.39      0.47        18\n",
      "          3       0.58      0.58      0.58        19\n",
      "          4       1.00      0.69      0.82        13\n",
      "          5       0.78      0.35      0.48        20\n",
      "          6       0.33      0.19      0.24        16\n",
      "          7       0.44      0.71      0.55        42\n",
      "\n",
      "avg / total       0.65      0.62      0.61       204\n",
      "\n",
      "[27  0  3  1  0  0  1 12  0 32  0  0  0  0  0  0  4  0  7  0  0  1  2  4\n",
      "  1  0  0 11  0  1  1  5  0  0  0  0  9  0  0  4  3  0  0  1  0  7  1  8\n",
      "  3  0  1  4  0  0  3  5  8  0  1  2  0  0  1 30]\n",
      "svc Accuracy:  0.6176470588235294\n",
      "svc F1:  0.5915011274267172\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.68      0.60        44\n",
      "          1       1.00      1.00      1.00        32\n",
      "          2       0.58      0.39      0.47        18\n",
      "          3       0.83      0.53      0.65        19\n",
      "          4       1.00      0.54      0.70        13\n",
      "          5       0.86      0.30      0.44        20\n",
      "          6       0.00      0.00      0.00        16\n",
      "          7       0.40      0.74      0.52        42\n",
      "\n",
      "avg / total       0.63      0.60      0.58       204\n",
      "\n",
      "[30  0  3  0  0  0  0 11  0 32  0  0  0  0  0  0  7  0  7  0  0  0  0  4\n",
      "  2  0  0 10  0  0  0  7  1  0  0  0  7  0  0  5  2  0  0  1  0  6  0 11\n",
      "  5  0  2  0  0  1  0  8  9  0  0  1  0  0  1 31]\n",
      "LR Accuracy:  0.6029411764705882\n",
      "LR F1:  0.5471601005993796\n",
      "For name:  t_weber\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0002-0494-0484': 29, '0000-0001-8994-1285': 13, '0000-0002-8260-5120': 12, '0000-0003-2931-8963': 10, '0000-0001-8320-361X': 7})\n",
      "['0000-0002-0494-0484', '0000-0001-8994-1285', '0000-0003-2931-8963', '0000-0002-8260-5120']\n",
      "Total sample size after apply threshold:  64\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(64, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(64, 15)\n",
      "2\n",
      "(64, 63)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.79      0.81        29\n",
      "          1       0.62      0.62      0.62        13\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.55      1.00      0.71        12\n",
      "\n",
      "avg / total       0.60      0.67      0.62        64\n",
      "\n",
      "[23  4  0  2  2  8  1  2  3  1  0  6  0  0  0 12]\n",
      "MNB Accuracy:  0.671875\n",
      "MNB F1:  0.5320711280463603\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.72      0.74        29\n",
      "          1       0.50      0.38      0.43        13\n",
      "          2       0.75      0.30      0.43        10\n",
      "          3       0.55      1.00      0.71        12\n",
      "\n",
      "avg / total       0.66      0.64      0.62        64\n",
      "\n",
      "[21  4  0  4  5  5  1  2  2  1  3  4  0  0  0 12]\n",
      "svc Accuracy:  0.640625\n",
      "svc F1:  0.5765196238678538\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.86      0.77        29\n",
      "          1       0.71      0.38      0.50        13\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.52      0.92      0.67        12\n",
      "\n",
      "avg / total       0.56      0.64      0.58        64\n",
      "\n",
      "[25  2  0  2  6  5  0  2  4  0  0  6  1  0  0 11]\n",
      "LR Accuracy:  0.640625\n",
      "LR F1:  0.483974358974359\n",
      "For name:  j_shim\n",
      "total sample size before apply threshold:  188\n",
      "Counter({'0000-0002-5361-2903': 91, '0000-0003-0167-7307': 36, '0000-0003-1881-8436': 30, '0000-0003-4088-2557': 12, '0000-0002-3974-1290': 6, '0000-0003-4577-1952': 6, '0000-0001-5485-160X': 3, '0000-0003-0101-3076': 2, '0000-0001-9367-2233': 1, '0000-0002-1909-5412': 1})\n",
      "['0000-0003-4088-2557', '0000-0002-5361-2903', '0000-0003-0167-7307', '0000-0003-1881-8436']\n",
      "Total sample size after apply threshold:  169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 75)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 15)\n",
      "2\n",
      "(169, 90)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.67      0.96      0.79        91\n",
      "          2       0.76      0.53      0.62        36\n",
      "          3       0.93      0.43      0.59        30\n",
      "\n",
      "avg / total       0.69      0.70      0.66       169\n",
      "\n",
      "[ 0 12  0  0  0 87  4  0  0 16 19  1  0 15  2 13]\n",
      "MNB Accuracy:  0.7041420118343196\n",
      "MNB F1:  0.5002975568308259\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.33      0.47        12\n",
      "          1       0.88      0.89      0.89        91\n",
      "          2       0.61      0.92      0.73        36\n",
      "          3       1.00      0.60      0.75        30\n",
      "\n",
      "avg / total       0.84      0.80      0.80       169\n",
      "\n",
      "[ 4  4  4  0  0 81 10  0  0  3 33  0  1  4  7 18]\n",
      "svc Accuracy:  0.8047337278106509\n",
      "svc F1:  0.7097918675666988\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.67      0.96      0.79        91\n",
      "          2       0.80      0.56      0.66        36\n",
      "          3       1.00      0.47      0.64        30\n",
      "\n",
      "avg / total       0.71      0.72      0.68       169\n",
      "\n",
      "[ 0 12  0  0  0 87  4  0  0 16 20  0  0 15  1 14]\n",
      "LR Accuracy:  0.7159763313609467\n",
      "LR F1:  0.5198579145059377\n",
      "For name:  k_kang\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0003-2622-9017': 53, '0000-0003-0446-469X': 22, '0000-0002-0457-842X': 12, '0000-0002-8790-9350': 11, '0000-0002-4465-0617': 9, '0000-0001-6374-8356': 8, '0000-0003-3290-1017': 3, '0000-0002-6529-4543': 3, '0000-0002-8428-8288': 3, '0000-0003-1230-3626': 2, '0000-0003-0611-9320': 1, '0000-0001-9135-1890': 1})\n",
      "['0000-0002-0457-842X', '0000-0002-8790-9350', '0000-0003-2622-9017', '0000-0003-0446-469X']\n",
      "Total sample size after apply threshold:  98\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 67)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 15)\n",
      "2\n",
      "(98, 82)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.42      0.56        12\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       0.72      1.00      0.83        53\n",
      "          3       1.00      0.77      0.87        22\n",
      "\n",
      "avg / total       0.83      0.78      0.73        98\n",
      "\n",
      "[ 5  0  7  0  1  1  9  0  0  0 53  0  0  0  5 17]\n",
      "MNB Accuracy:  0.7755102040816326\n",
      "MNB F1:  0.6071656908271081\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       0.83      0.98      0.90        53\n",
      "          3       0.94      0.77      0.85        22\n",
      "\n",
      "avg / total       0.89      0.88      0.88        98\n",
      "\n",
      "[ 9  0  3  0  0  8  3  0  0  0 52  1  0  0  5 17]\n",
      "svc Accuracy:  0.8775510204081632\n",
      "svc F1:  0.8614499611096708\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.42      0.56        12\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       0.71      1.00      0.83        53\n",
      "          3       1.00      0.73      0.84        22\n",
      "\n",
      "avg / total       0.82      0.77      0.72        98\n",
      "\n",
      "[ 5  0  7  0  1  1  9  0  0  0 53  0  0  0  6 16]\n",
      "LR Accuracy:  0.7653061224489796\n",
      "LR F1:  0.5981131213450293\n",
      "For name:  i_ferreira\n",
      "total sample size before apply threshold:  344\n",
      "Counter({'0000-0003-4910-4882': 166, '0000-0003-1434-0607': 90, '0000-0001-8424-1431': 44, '0000-0001-6552-4479': 19, '0000-0002-8838-0364': 13, '0000-0002-4934-917X': 7, '0000-0002-3164-8227': 3, '0000-0002-5368-9505': 2})\n",
      "['0000-0003-1434-0607', '0000-0001-6552-4479', '0000-0003-4910-4882', '0000-0002-8838-0364', '0000-0001-8424-1431']\n",
      "Total sample size after apply threshold:  332\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(332, 123)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(332, 23)\n",
      "2\n",
      "(332, 146)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.69      0.75        90\n",
      "          1       1.00      0.11      0.19        19\n",
      "          2       0.67      0.97      0.80       166\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.62      0.23      0.33        44\n",
      "\n",
      "avg / total       0.70      0.71      0.66       332\n",
      "\n",
      "[ 62   0  25   0   3   5   2  10   0   2   4   0 161   0   1   2   0  11\n",
      "   0   0   2   0  32   0  10]\n",
      "MNB Accuracy:  0.7078313253012049\n",
      "MNB F1:  0.41407728074394745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.87      0.74        90\n",
      "          1       1.00      0.16      0.27        19\n",
      "          2       0.78      0.88      0.83       166\n",
      "          3       1.00      0.31      0.47        13\n",
      "          4       0.47      0.18      0.26        44\n",
      "\n",
      "avg / total       0.72      0.72      0.68       332\n",
      "\n",
      "[ 78   0  11   0   1  11   3   3   0   2  14   0 146   0   6   7   0   2\n",
      "   4   0  12   0  24   0   8]\n",
      "svc Accuracy:  0.7198795180722891\n",
      "svc F1:  0.5142010202275663\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.78      0.71        90\n",
      "          1       0.00      0.00      0.00        19\n",
      "          2       0.70      0.87      0.78       166\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.47      0.18      0.26        44\n",
      "\n",
      "avg / total       0.59      0.67      0.62       332\n",
      "\n",
      "[ 70   0  19   0   1  11   0   8   0   0  13   0 145   0   8   5   0   8\n",
      "   0   0   9   0  27   0   8]\n",
      "LR Accuracy:  0.6716867469879518\n",
      "LR F1:  0.34936913635986283\n",
      "For name:  y_jia\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0002-2784-1905': 24, '0000-0003-3852-7302': 10, '0000-0002-8852-7557': 3, '0000-0001-9657-0806': 3, '0000-0001-7978-9312': 3, '0000-0001-9395-2139': 2, '0000-0003-4972-1004': 1})\n",
      "['0000-0003-3852-7302', '0000-0002-2784-1905']\n",
      "Total sample size after apply threshold:  34\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 15)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 8)\n",
      "2\n",
      "(34, 23)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70        10\n",
      "          1       0.88      0.88      0.88        24\n",
      "\n",
      "avg / total       0.82      0.82      0.82        34\n",
      "\n",
      "[ 7  3  3 21]\n",
      "MNB Accuracy:  0.8235294117647058\n",
      "MNB F1:  0.7875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.60      0.63        10\n",
      "          1       0.84      0.88      0.86        24\n",
      "\n",
      "avg / total       0.79      0.79      0.79        34\n",
      "\n",
      "[ 6  4  3 21]\n",
      "svc Accuracy:  0.7941176470588235\n",
      "svc F1:  0.7443609022556391\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.10      0.17        10\n",
      "          1       0.72      0.96      0.82        24\n",
      "\n",
      "avg / total       0.65      0.71      0.63        34\n",
      "\n",
      "[ 1  9  1 23]\n",
      "LR Accuracy:  0.7058823529411765\n",
      "LR F1:  0.49404761904761907\n",
      "For name:  p_gaspar\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0003-4217-5717': 87, '0000-0001-5967-0584': 3, '0000-0002-4832-8537': 2, '0000-0003-3388-1724': 1})\n",
      "['0000-0003-4217-5717']\n",
      "Total sample size after apply threshold:  87\n",
      "For name:  r_o'connor\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0003-4426-2507': 36, '0000-0002-4643-9794': 27, '0000-0002-6869-7954': 13, '0000-0002-3916-3101': 6})\n",
      "['0000-0002-6869-7954', '0000-0003-4426-2507', '0000-0002-4643-9794']\n",
      "Total sample size after apply threshold:  76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(76, 50)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(76, 18)\n",
      "2\n",
      "(76, 68)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       0.69      0.92      0.79        36\n",
      "          2       0.77      0.74      0.75        27\n",
      "\n",
      "avg / total       0.77      0.72      0.69        76\n",
      "\n",
      "[ 2  8  3  0 33  3  0  7 20]\n",
      "MNB Accuracy:  0.7236842105263158\n",
      "MNB F1:  0.602365977837676\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       0.69      0.94      0.80        36\n",
      "          2       0.81      0.63      0.71        27\n",
      "\n",
      "avg / total       0.79      0.75      0.74        76\n",
      "\n",
      "[ 6  5  2  0 34  2  0 10 17]\n",
      "svc Accuracy:  0.75\n",
      "svc F1:  0.7133040935672516\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.14        13\n",
      "          1       0.62      0.92      0.74        36\n",
      "          2       0.73      0.59      0.65        27\n",
      "\n",
      "avg / total       0.72      0.66      0.61        76\n",
      "\n",
      "[ 1  9  3  0 33  3  0 11 16]\n",
      "LR Accuracy:  0.6578947368421053\n",
      "LR F1:  0.5124971336849345\n",
      "For name:  k_larsen\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0003-2172-7519': 35, '0000-0002-3918-6645': 6, '0000-0002-1421-6182': 4, '0000-0002-6473-7285': 1, '0000-0003-1182-7727': 1})\n",
      "['0000-0003-2172-7519']\n",
      "Total sample size after apply threshold:  35\n",
      "For name:  s_das\n",
      "total sample size before apply threshold:  197\n",
      "Counter({'0000-0002-1659-2499': 50, '0000-0002-2424-2851': 21, '0000-0002-8394-5303': 17, '0000-0002-5353-0422': 15, '0000-0002-0539-5174': 14, '0000-0003-1185-9366': 13, '0000-0002-2384-3903': 9, '0000-0001-6256-5646': 9, '0000-0002-7066-2128': 6, '0000-0002-8097-6542': 6, '0000-0002-4217-9972': 5, '0000-0001-6470-7302': 4, '0000-0002-5974-7649': 4, '0000-0001-9380-2907': 3, '0000-0002-8628-5128': 2, '0000-0003-0467-0872': 2, '0000-0002-4852-1396': 2, '0000-0003-0745-469X': 2, '0000-0002-9302-7645': 2, '0000-0002-3428-1862': 1, '0000-0001-5339-7708': 1, '0000-0002-0994-8960': 1, '0000-0003-2889-8644': 1, '0000-0003-2161-4784': 1, '0000-0002-0285-8970': 1, '0000-0002-4464-3417': 1, '0000-0002-7336-9568': 1, '0000-0002-3010-6469': 1, '0000-0001-7329-8264': 1, '0000-0002-9896-3520': 1})\n",
      "['0000-0002-0539-5174', '0000-0002-5353-0422', '0000-0002-2424-2851', '0000-0003-1185-9366', '0000-0002-8394-5303', '0000-0002-1659-2499']\n",
      "Total sample size after apply threshold:  130\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 78)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 28)\n",
      "2\n",
      "(130, 106)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       1.00      0.13      0.24        15\n",
      "          2       0.58      0.71      0.64        21\n",
      "          3       0.54      0.54      0.54        13\n",
      "          4       0.71      0.59      0.65        17\n",
      "          5       0.56      0.82      0.67        50\n",
      "\n",
      "avg / total       0.57      0.58      0.52       130\n",
      "\n",
      "[ 0  0  2  1  0 11  0  2  2  0  1 10  0  0 15  1  0  5  0  0  1  7  3  2\n",
      "  0  0  0  3 10  4  2  0  6  1  0 41]\n",
      "MNB Accuracy:  0.5769230769230769\n",
      "MNB F1:  0.45398024757304506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.57      0.27      0.36        15\n",
      "          2       0.72      0.62      0.67        21\n",
      "          3       0.56      0.69      0.62        13\n",
      "          4       0.83      0.59      0.69        17\n",
      "          5       0.59      0.78      0.67        50\n",
      "\n",
      "avg / total       0.58      0.58      0.56       130\n",
      "\n",
      "[ 0  0  2  1  0 11  0  4  1  1  0  9  1  1 13  1  1  4  1  0  1  9  1  1\n",
      "  2  0  0  3 10  2  7  2  1  1  0 39]\n",
      "svc Accuracy:  0.5769230769230769\n",
      "svc F1:  0.5021769418321141\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.72      0.62      0.67        21\n",
      "          3       0.53      0.69      0.60        13\n",
      "          4       0.90      0.53      0.67        17\n",
      "          5       0.56      0.94      0.70        50\n",
      "\n",
      "avg / total       0.50      0.60      0.52       130\n",
      "\n",
      "[ 0  0  2  1  0 11  0  0  1  1  0 13  0  0 13  1  0  7  0  0  1  9  1  2\n",
      "  0  0  0  4  9  4  1  0  1  1  0 47]\n",
      "LR Accuracy:  0.6\n",
      "LR F1:  0.4391376451077944\n",
      "For name:  f_rodriguez\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0003-4044-8734': 3, '0000-0003-1213-0999': 2, '0000-0003-4053-099X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  w_peng\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0001-5093-7115': 14, '0000-0002-4506-0942': 13, '0000-0001-9747-2466': 8, '0000-0003-4917-6851': 3})\n",
      "['0000-0002-4506-0942', '0000-0001-5093-7115']\n",
      "Total sample size after apply threshold:  27\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 10)\n",
      "2\n",
      "(27, 33)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.85      0.73        13\n",
      "          1       0.80      0.57      0.67        14\n",
      "\n",
      "avg / total       0.73      0.70      0.70        27\n",
      "\n",
      "[11  2  6  8]\n",
      "MNB Accuracy:  0.7037037037037037\n",
      "MNB F1:  0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.85      0.79        13\n",
      "          1       0.83      0.71      0.77        14\n",
      "\n",
      "avg / total       0.79      0.78      0.78        27\n",
      "\n",
      "[11  2  4 10]\n",
      "svc Accuracy:  0.7777777777777778\n",
      "svc F1:  0.7774725274725274\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.85      0.79        13\n",
      "          1       0.83      0.71      0.77        14\n",
      "\n",
      "avg / total       0.79      0.78      0.78        27\n",
      "\n",
      "[11  2  4 10]\n",
      "LR Accuracy:  0.7777777777777778\n",
      "LR F1:  0.7774725274725274\n",
      "For name:  c_torres\n",
      "total sample size before apply threshold:  300\n",
      "Counter({'0000-0003-3709-1690': 237, '0000-0001-8573-0990': 20, '0000-0001-6303-4417': 16, '0000-0001-6786-8769': 15, '0000-0003-3991-0573': 9, '0000-0001-6322-5862': 2, '0000-0002-7908-6884': 1})\n",
      "['0000-0001-8573-0990', '0000-0001-6786-8769', '0000-0003-3709-1690', '0000-0001-6303-4417']\n",
      "Total sample size after apply threshold:  288\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(288, 92)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(288, 21)\n",
      "2\n",
      "(288, 113)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.30      0.44        20\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.85      1.00      0.92       237\n",
      "          3       1.00      0.06      0.12        16\n",
      "\n",
      "avg / total       0.81      0.85      0.79       288\n",
      "\n",
      "[  6   0  14   0   0   0  15   0   0   0 237   0   1   0  14   1]\n",
      "MNB Accuracy:  0.8472222222222222\n",
      "MNB F1:  0.3697298390665099\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        20\n",
      "          1       1.00      0.27      0.42        15\n",
      "          2       0.91      1.00      0.95       237\n",
      "          3       0.83      0.31      0.45        16\n",
      "\n",
      "avg / total       0.92      0.92      0.90       288\n",
      "\n",
      "[ 19   0   1   0   0   4  11   0   0   0 236   1   0   0  11   5]\n",
      "svc Accuracy:  0.9166666666666666\n",
      "svc F1:  0.7003924909272957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        20\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.84      1.00      0.91       237\n",
      "          3       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.76      0.84      0.78       288\n",
      "\n",
      "[  6   0  14   0   0   0  15   0   0   0 237   0   0   0  16   0]\n",
      "LR Accuracy:  0.84375\n",
      "LR F1:  0.3437083148065807\n",
      "For name:  s_rossi\n",
      "total sample size before apply threshold:  199\n",
      "Counter({'0000-0003-3257-8248': 86, '0000-0002-9963-8121': 34, '0000-0002-9919-0494': 25, '0000-0002-8854-7072': 14, '0000-0003-0346-8410': 13, '0000-0002-3278-8993': 10, '0000-0002-2694-9535': 8, '0000-0001-5134-8398': 5, '0000-0001-7048-7158': 1, '0000-0001-8853-0775': 1, '0000-0001-9511-3857': 1, '0000-0001-7479-5756': 1})\n",
      "['0000-0002-8854-7072', '0000-0002-9919-0494', '0000-0003-0346-8410', '0000-0002-9963-8121', '0000-0002-3278-8993', '0000-0003-3257-8248']\n",
      "Total sample size after apply threshold:  182\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(182, 90)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(182, 19)\n",
      "2\n",
      "(182, 109)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       1.00      0.52      0.68        25\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.87      0.59      0.70        34\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.58      0.99      0.73        86\n",
      "\n",
      "avg / total       0.57      0.65      0.57       182\n",
      "\n",
      "[ 0  0  0  1  0 13  0 13  0  0  0 12  0  0  0  1  0 12  0  0  0 20  0 14\n",
      "  0  0  0  0  0 10  0  0  0  1  0 85]\n",
      "MNB Accuracy:  0.6483516483516484\n",
      "MNB F1:  0.3531205888283928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.21      0.30        14\n",
      "          1       1.00      0.80      0.89        25\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.87      0.59      0.70        34\n",
      "          4       0.67      0.20      0.31        10\n",
      "          5       0.64      0.94      0.76        86\n",
      "\n",
      "avg / total       0.68      0.69      0.65       182\n",
      "\n",
      "[ 3  0  1  1  0  9  0 20  0  0  0  5  0  0  0  1  0 12  0  0  0 20  0 14\n",
      "  1  0  1  0  2  6  2  0  1  1  1 81]\n",
      "svc Accuracy:  0.6923076923076923\n",
      "svc F1:  0.49314982713796646\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       1.00      0.64      0.78        25\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.87      0.59      0.70        34\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.60      0.99      0.75        86\n",
      "\n",
      "avg / total       0.58      0.66      0.59       182\n",
      "\n",
      "[ 0  0  1  1  0 12  0 16  0  0  0  9  0  0  0  1  0 12  0  0  0 20  0 14\n",
      "  0  0  1  0  0  9  0  0  0  1  0 85]\n",
      "LR Accuracy:  0.6648351648351648\n",
      "LR F1:  0.37185681154284306\n",
      "For name:  s_alavi\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0003-4328-4747': 23, '0000-0003-4009-4921': 14, '0000-0003-1130-3165': 1})\n",
      "['0000-0003-4328-4747', '0000-0003-4009-4921']\n",
      "Total sample size after apply threshold:  37\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 9)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 8)\n",
      "2\n",
      "(37, 17)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        23\n",
      "          1       0.82      1.00      0.90        14\n",
      "\n",
      "avg / total       0.93      0.92      0.92        37\n",
      "\n",
      "[20  3  0 14]\n",
      "MNB Accuracy:  0.918918918918919\n",
      "MNB F1:  0.9167291822955739\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        23\n",
      "          1       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97        37\n",
      "\n",
      "[23  0  1 13]\n",
      "svc Accuracy:  0.972972972972973\n",
      "svc F1:  0.9708431836091411\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        23\n",
      "          1       0.93      0.93      0.93        14\n",
      "\n",
      "avg / total       0.95      0.95      0.95        37\n",
      "\n",
      "[22  1  1 13]\n",
      "LR Accuracy:  0.9459459459459459\n",
      "LR F1:  0.9425465838509317\n",
      "For name:  r_marques\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-6949-0947': 11, '0000-0002-4749-7523': 11, '0000-0002-3125-3911': 8, '0000-0001-6239-5456': 3, '0000-0002-9416-1299': 2, '0000-0001-8261-4409': 1, '0000-0001-6925-041X': 1, '0000-0002-9197-9845': 1, '0000-0002-0672-9260': 1, '0000-0001-8622-9786': 1, '0000-0003-0314-3675': 1})\n",
      "['0000-0002-6949-0947', '0000-0002-4749-7523']\n",
      "Total sample size after apply threshold:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 8)\n",
      "2\n",
      "(22, 28)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73        11\n",
      "          1       0.73      0.73      0.73        11\n",
      "\n",
      "avg / total       0.73      0.73      0.73        22\n",
      "\n",
      "[8 3 3 8]\n",
      "MNB Accuracy:  0.7272727272727273\n",
      "MNB F1:  0.7272727272727273\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73        11\n",
      "          1       0.73      0.73      0.73        11\n",
      "\n",
      "avg / total       0.73      0.73      0.73        22\n",
      "\n",
      "[8 3 3 8]\n",
      "svc Accuracy:  0.7272727272727273\n",
      "svc F1:  0.7272727272727273\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73        11\n",
      "          1       0.73      0.73      0.73        11\n",
      "\n",
      "avg / total       0.73      0.73      0.73        22\n",
      "\n",
      "[8 3 3 8]\n",
      "LR Accuracy:  0.7272727272727273\n",
      "LR F1:  0.7272727272727273\n",
      "For name:  m_wheeler\n",
      "total sample size before apply threshold:  163\n",
      "Counter({'0000-0002-7480-7267': 112, '0000-0001-5589-357X': 47, '0000-0002-0319-1987': 3, '0000-0002-7404-7069': 1})\n",
      "['0000-0002-7480-7267', '0000-0001-5589-357X']\n",
      "Total sample size after apply threshold:  159\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(159, 59)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(159, 26)\n",
      "2\n",
      "(159, 85)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.96      0.89       112\n",
      "          1       0.83      0.53      0.65        47\n",
      "\n",
      "avg / total       0.83      0.83      0.82       159\n",
      "\n",
      "[107   5  22  25]\n",
      "MNB Accuracy:  0.8301886792452831\n",
      "MNB F1:  0.7686587271649512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.91       112\n",
      "          1       0.93      0.55      0.69        47\n",
      "\n",
      "avg / total       0.87      0.86      0.84       159\n",
      "\n",
      "[110   2  21  26]\n",
      "svc Accuracy:  0.8553459119496856\n",
      "svc F1:  0.7993415637860083\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.99      0.88       112\n",
      "          1       0.95      0.38      0.55        47\n",
      "\n",
      "avg / total       0.84      0.81      0.78       159\n",
      "\n",
      "[111   1  29  18]\n",
      "LR Accuracy:  0.8113207547169812\n",
      "LR F1:  0.7132034632034632\n",
      "For name:  l_rasmussen\n",
      "total sample size before apply threshold:  249\n",
      "Counter({'0000-0002-7480-3004': 214, '0000-0002-4497-8049': 24, '0000-0001-6613-2469': 5, '0000-0001-5962-6647': 4, '0000-0001-5795-4794': 1, '0000-0002-7301-3182': 1})\n",
      "['0000-0002-4497-8049', '0000-0002-7480-3004']\n",
      "Total sample size after apply threshold:  238\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(238, 88)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(238, 22)\n",
      "2\n",
      "(238, 110)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.08      0.14        24\n",
      "          1       0.91      0.99      0.95       214\n",
      "\n",
      "avg / total       0.87      0.90      0.87       238\n",
      "\n",
      "[  2  22   2 212]\n",
      "MNB Accuracy:  0.8991596638655462\n",
      "MNB F1:  0.5446428571428572\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.55        24\n",
      "          1       0.93      1.00      0.97       214\n",
      "\n",
      "avg / total       0.94      0.94      0.92       238\n",
      "\n",
      "[  9  15   0 214]\n",
      "svc Accuracy:  0.9369747899159664\n",
      "svc F1:  0.7557972501539092\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29        24\n",
      "          1       0.91      1.00      0.96       214\n",
      "\n",
      "avg / total       0.92      0.92      0.89       238\n",
      "\n",
      "[  4  20   0 214]\n",
      "LR Accuracy:  0.9159663865546218\n",
      "LR F1:  0.6205357142857143\n",
      "For name:  m_saad\n",
      "total sample size before apply threshold:  4\n",
      "Counter({'0000-0003-0458-5942': 1, '0000-0002-8071-2328': 1, '0000-0002-5655-8674': 1, '0000-0003-1291-366X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_carr\n",
      "total sample size before apply threshold:  271\n",
      "Counter({'0000-0002-4398-8237': 179, '0000-0002-6445-2992': 42, '0000-0002-5028-2160': 40, '0000-0002-2729-0920': 6, '0000-0002-9164-4156': 2, '0000-0002-2324-8944': 1, '0000-0002-1080-1472': 1})\n",
      "['0000-0002-6445-2992', '0000-0002-5028-2160', '0000-0002-4398-8237']\n",
      "Total sample size after apply threshold:  261\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(261, 107)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(261, 22)\n",
      "2\n",
      "(261, 129)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.81      0.84        42\n",
      "          1       0.90      0.45      0.60        40\n",
      "          2       0.87      0.98      0.92       179\n",
      "\n",
      "avg / total       0.88      0.87      0.86       261\n",
      "\n",
      "[ 34   0   8   4  18  18   1   2 176]\n",
      "MNB Accuracy:  0.8735632183908046\n",
      "MNB F1:  0.7877968957584006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        42\n",
      "          1       0.94      0.75      0.83        40\n",
      "          2       0.93      0.99      0.96       179\n",
      "\n",
      "avg / total       0.94      0.94      0.94       261\n",
      "\n",
      "[ 38   0   4   0  30  10   0   2 177]\n",
      "svc Accuracy:  0.9386973180076629\n",
      "svc F1:  0.9133633633633634\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        42\n",
      "          1       1.00      0.40      0.57        40\n",
      "          2       0.84      1.00      0.91       179\n",
      "\n",
      "avg / total       0.89      0.87      0.85       261\n",
      "\n",
      "[ 31   0  11   0  16  24   0   0 179]\n",
      "LR Accuracy:  0.8659003831417624\n",
      "LR F1:  0.7772283719162315\n",
      "For name:  j_fraser\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0002-5080-2859': 38, '0000-0002-6505-1883': 36, '0000-0002-5980-3989': 9, '0000-0003-0111-9137': 6, '0000-0002-8020-2985': 6, '0000-0001-9697-3795': 3, '0000-0003-4941-1997': 3})\n",
      "['0000-0002-6505-1883', '0000-0002-5080-2859']\n",
      "Total sample size after apply threshold:  74\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(74, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(74, 14)\n",
      "2\n",
      "(74, 58)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.86      0.83        36\n",
      "          1       0.86      0.79      0.82        38\n",
      "\n",
      "avg / total       0.83      0.82      0.82        74\n",
      "\n",
      "[31  5  8 30]\n",
      "MNB Accuracy:  0.8243243243243243\n",
      "MNB F1:  0.8242922374429225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.78      0.78        36\n",
      "          1       0.79      0.79      0.79        38\n",
      "\n",
      "avg / total       0.78      0.78      0.78        74\n",
      "\n",
      "[28  8  8 30]\n",
      "svc Accuracy:  0.7837837837837838\n",
      "svc F1:  0.7836257309941521\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.78      0.78        36\n",
      "          1       0.79      0.79      0.79        38\n",
      "\n",
      "avg / total       0.78      0.78      0.78        74\n",
      "\n",
      "[28  8  8 30]\n",
      "LR Accuracy:  0.7837837837837838\n",
      "LR F1:  0.7836257309941521\n",
      "For name:  s_woo\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-3692-7169': 22, '0000-0001-8788-2875': 1, '0000-0001-6765-4322': 1, '0000-0001-6902-0315': 1})\n",
      "['0000-0003-3692-7169']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  s_bartlett\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0001-9755-2490': 80, '0000-0003-4387-670X': 18, '0000-0002-7044-4454': 3, '0000-0003-0699-2250': 3})\n",
      "['0000-0003-4387-670X', '0000-0001-9755-2490']\n",
      "Total sample size after apply threshold:  98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 55)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 21)\n",
      "2\n",
      "(98, 76)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.78      0.82        18\n",
      "          1       0.95      0.97      0.96        80\n",
      "\n",
      "avg / total       0.94      0.94      0.94        98\n",
      "\n",
      "[14  4  2 78]\n",
      "MNB Accuracy:  0.9387755102040817\n",
      "MNB F1:  0.8932461873638344\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        18\n",
      "          1       0.96      1.00      0.98        80\n",
      "\n",
      "avg / total       0.97      0.97      0.97        98\n",
      "\n",
      "[15  3  0 80]\n",
      "svc Accuracy:  0.9693877551020408\n",
      "svc F1:  0.9453430005577245\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.72      0.84        18\n",
      "          1       0.94      1.00      0.97        80\n",
      "\n",
      "avg / total       0.95      0.95      0.95        98\n",
      "\n",
      "[13  5  0 80]\n",
      "LR Accuracy:  0.9489795918367347\n",
      "LR F1:  0.9042033235581622\n",
      "For name:  m_lucas\n",
      "total sample size before apply threshold:  75\n",
      "Counter({'0000-0002-3252-0145': 25, '0000-0002-3625-9714': 19, '0000-0001-8672-9940': 15, '0000-0002-5463-0505': 14, '0000-0002-1646-4139': 2})\n",
      "['0000-0002-5463-0505', '0000-0001-8672-9940', '0000-0002-3625-9714', '0000-0002-3252-0145']\n",
      "Total sample size after apply threshold:  73\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 42)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 18)\n",
      "2\n",
      "(73, 60)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.79      0.81        14\n",
      "          1       0.67      0.27      0.38        15\n",
      "          2       0.58      0.74      0.65        19\n",
      "          3       0.53      0.64      0.58        25\n",
      "\n",
      "avg / total       0.63      0.62      0.60        73\n",
      "\n",
      "[11  0  1  2  0  4  3  8  0  1 14  4  2  1  6 16]\n",
      "MNB Accuracy:  0.6164383561643836\n",
      "MNB F1:  0.607187042070763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.71      0.80        14\n",
      "          1       0.82      0.60      0.69        15\n",
      "          2       0.88      0.79      0.83        19\n",
      "          3       0.59      0.80      0.68        25\n",
      "\n",
      "avg / total       0.77      0.74      0.74        73\n",
      "\n",
      "[10  0  0  4  0  9  0  6  0  0 15  4  1  2  2 20]\n",
      "svc Accuracy:  0.7397260273972602\n",
      "svc F1:  0.7509017818339851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.64      0.75        14\n",
      "          1       0.86      0.40      0.55        15\n",
      "          2       0.88      0.74      0.80        19\n",
      "          3       0.53      0.84      0.65        25\n",
      "\n",
      "avg / total       0.76      0.68      0.69        73\n",
      "\n",
      "[ 9  0  0  5  0  6  0  9  0  0 14  5  1  1  2 21]\n",
      "LR Accuracy:  0.684931506849315\n",
      "LR F1:  0.6854020979020978\n",
      "For name:  w_lee\n",
      "total sample size before apply threshold:  590\n",
      "Counter({'0000-0003-3171-7672': 108, '0000-0001-5833-989X': 100, '0000-0003-3231-9764': 82, '0000-0002-1082-7592': 62, '0000-0003-3267-4811': 40, '0000-0001-7805-869X': 36, '0000-0003-2883-0391': 21, '0000-0002-0607-038X': 21, '0000-0002-5461-6770': 16, '0000-0002-3912-6095': 11, '0000-0001-6757-885X': 11, '0000-0001-6408-7668': 10, '0000-0002-9873-1033': 9, '0000-0001-7801-083X': 8, '0000-0001-8430-4797': 7, '0000-0002-2572-7287': 5, '0000-0002-6766-8481': 5, '0000-0001-8706-6026': 4, '0000-0002-0036-2859': 4, '0000-0002-9624-0505': 3, '0000-0002-3413-4029': 3, '0000-0003-1817-8395': 3, '0000-0003-1744-8525': 3, '0000-0001-8052-2420': 2, '0000-0003-0853-8561': 2, '0000-0001-7285-4054': 2, '0000-0001-9645-8179': 2, '0000-0002-4383-756X': 2, '0000-0003-1911-3454': 2, '0000-0003-4333-5444': 1, '0000-0002-7324-5792': 1, '0000-0002-2152-7210': 1, '0000-0003-4040-1100': 1, '0000-0003-0133-9076': 1, '0000-0002-7696-5517': 1})\n",
      "['0000-0001-7805-869X', '0000-0002-3912-6095', '0000-0003-2883-0391', '0000-0001-6408-7668', '0000-0003-3267-4811', '0000-0003-3171-7672', '0000-0003-3231-9764', '0000-0001-5833-989X', '0000-0002-0607-038X', '0000-0002-1082-7592', '0000-0001-6757-885X', '0000-0002-5461-6770']\n",
      "Total sample size after apply threshold:  518\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(518, 227)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(518, 26)\n",
      "2\n",
      "(518, 253)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        36\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.24      0.38        21\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.62      0.20      0.30        40\n",
      "          5       0.43      0.71      0.53       108\n",
      "          6       0.73      0.65      0.68        82\n",
      "          7       0.58      0.93      0.72       100\n",
      "          8       1.00      0.05      0.09        21\n",
      "          9       0.48      0.66      0.56        62\n",
      "         10       0.00      0.00      0.00        11\n",
      "         11       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.50      0.54      0.47       518\n",
      "\n",
      "[ 0  0  0  0  0 23  2  7  0  4  0  0  0  0  0  0  2  4  1  3  0  1  0  0\n",
      "  0  0  5  0  0 10  3  2  0  1  0  0  0  0  0  0  0  3  1  0  0  6  0  0\n",
      "  0  0  0  0  8  9  3 16  0  4  0  0  1  0  0  0  1 77  5 14  0 10  0  0\n",
      "  0  0  0  0  2 10 53 10  0  7  0  0  0  0  0  0  0  6  1 93  0  0  0  0\n",
      "  0  0  0  0  0 10  0  6  1  4  0  0  0  0  0  0  0 18  3  0  0 41  0  0\n",
      "  0  0  0  0  0  3  0  7  0  1  0  0  0  0  0  0  0  7  1  2  0  6  0  0]\n",
      "MNB Accuracy:  0.5366795366795367\n",
      "MNB F1:  0.272434350214815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.33      0.47        36\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.80      0.38      0.52        21\n",
      "          3       0.17      0.10      0.12        10\n",
      "          4       0.37      0.35      0.36        40\n",
      "          5       0.45      0.90      0.60       108\n",
      "          6       0.91      0.60      0.72        82\n",
      "          7       0.98      0.95      0.96       100\n",
      "          8       0.92      0.52      0.67        21\n",
      "          9       0.74      0.63      0.68        62\n",
      "         10       0.00      0.00      0.00        11\n",
      "         11       1.00      0.56      0.72        16\n",
      "\n",
      "avg / total       0.70      0.65      0.64       518\n",
      "\n",
      "[12  0  0  0  3 18  1  0  0  2  0  0  0  0  0  0  7  4  0  0  0  0  0  0\n",
      "  0  0  8  1  0 11  0  0  0  1  0  0  0  0  0  1  0  6  0  0  0  3  0  0\n",
      "  2  6  0  1 14 15  1  1  0  0  0  0  0  0  1  0  4 97  3  0  1  2  0  0\n",
      "  1  0  1  1  7 21 49  0  0  2  0  0  0  0  0  0  1  3  0 95  0  1  0  0\n",
      "  0  0  0  0  2  8  0  0 11  0  0  0  0  0  0  2  0 21  0  0  0 39  0  0\n",
      "  0  2  0  0  0  7  0  0  0  2  0  0  0  0  0  0  0  5  0  1  0  1  0  9]\n",
      "svc Accuracy:  0.6467181467181468\n",
      "svc F1:  0.4849533196022875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.11        36\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.48      0.65        21\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.41      0.33      0.36        40\n",
      "          5       0.48      0.82      0.61       108\n",
      "          6       0.78      0.68      0.73        82\n",
      "          7       0.85      0.93      0.89       100\n",
      "          8       0.88      0.33      0.48        21\n",
      "          9       0.47      0.66      0.55        62\n",
      "         10       0.00      0.00      0.00        11\n",
      "         11       1.00      0.38      0.55        16\n",
      "\n",
      "avg / total       0.65      0.61      0.58       518\n",
      "\n",
      "[ 2  0  0  0  4 20  2  1  0  7  0  0  0  0  0  0  6  4  0  0  0  1  0  0\n",
      "  0  0 10  0  0  7  3  0  0  1  0  0  0  0  0  0  0  3  1  0  0  6  0  0\n",
      "  0  3  0  1 13 11  4  3  0  5  0  0  0  0  0  0  2 89  2  3  1 11  0  0\n",
      "  0  0  0  0  4 14 56  4  0  4  0  0  0  0  0  0  1  5  0 93  0  1  0  0\n",
      "  0  0  0  0  1  9  0  2  7  2  0  0  0  0  0  1  0 16  4  0  0 41  0  0\n",
      "  0  0  0  0  1  5  0  2  0  3  0  0  0  0  0  0  0  2  0  2  0  6  0  6]\n",
      "LR Accuracy:  0.611969111969112\n",
      "LR F1:  0.4089092447957931\n",
      "For name:  j_cheng\n",
      "total sample size before apply threshold:  66\n",
      "Counter({'0000-0003-1786-6188': 19, '0000-0001-8285-3207': 16, '0000-0001-5318-5668': 8, '0000-0002-7004-5138': 6, '0000-0003-3928-1770': 6, '0000-0002-1881-012X': 5, '0000-0002-4364-9657': 3, '0000-0002-1722-2617': 1, '0000-0002-5434-1201': 1, '0000-0001-6065-2682': 1})\n",
      "['0000-0003-1786-6188', '0000-0001-8285-3207']\n",
      "Total sample size after apply threshold:  35\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 13)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 9)\n",
      "2\n",
      "(35, 22)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.89      0.87        19\n",
      "          1       0.87      0.81      0.84        16\n",
      "\n",
      "avg / total       0.86      0.86      0.86        35\n",
      "\n",
      "[17  2  3 13]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.8552522746071134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.79      0.83        19\n",
      "          1       0.78      0.88      0.82        16\n",
      "\n",
      "avg / total       0.83      0.83      0.83        35\n",
      "\n",
      "[15  4  2 14]\n",
      "svc Accuracy:  0.8285714285714286\n",
      "svc F1:  0.8284313725490196\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.84      0.84        19\n",
      "          1       0.81      0.81      0.81        16\n",
      "\n",
      "avg / total       0.83      0.83      0.83        35\n",
      "\n",
      "[16  3  3 13]\n",
      "LR Accuracy:  0.8285714285714286\n",
      "LR F1:  0.8273026315789473\n",
      "For name:  g_lewis\n",
      "total sample size before apply threshold:  367\n",
      "Counter({'0000-0001-5205-8245': 343, '0000-0002-2548-8423': 12, '0000-0003-3081-9319': 7, '0000-0003-4112-5048': 5})\n",
      "['0000-0002-2548-8423', '0000-0001-5205-8245']\n",
      "Total sample size after apply threshold:  355\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(355, 103)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(355, 28)\n",
      "2\n",
      "(355, 131)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.97      1.00      0.98       343\n",
      "\n",
      "avg / total       0.93      0.97      0.95       355\n",
      "\n",
      "[  0  12   0 343]\n",
      "MNB Accuracy:  0.9661971830985916\n",
      "MNB F1:  0.49140401146131807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.98      1.00      0.99       343\n",
      "\n",
      "avg / total       0.98      0.98      0.98       355\n",
      "\n",
      "[  6   6   0 343]\n",
      "svc Accuracy:  0.9830985915492958\n",
      "svc F1:  0.8289980732177264\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.97      1.00      0.98       343\n",
      "\n",
      "avg / total       0.93      0.97      0.95       355\n",
      "\n",
      "[  0  12   0 343]\n",
      "LR Accuracy:  0.9661971830985916\n",
      "LR F1:  0.49140401146131807\n",
      "For name:  j_albert\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0002-3420-7371': 40, '0000-0001-6538-9801': 19, '0000-0001-5330-1892': 13, '0000-0002-8256-2650': 6})\n",
      "['0000-0002-3420-7371', '0000-0001-6538-9801', '0000-0001-5330-1892']\n",
      "Total sample size after apply threshold:  72\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 14)\n",
      "2\n",
      "(72, 58)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.93      0.78        40\n",
      "          1       0.80      0.21      0.33        19\n",
      "          2       0.67      0.62      0.64        13\n",
      "\n",
      "avg / total       0.71      0.68      0.64        72\n",
      "\n",
      "[37  1  2 13  4  2  5  0  8]\n",
      "MNB Accuracy:  0.6805555555555556\n",
      "MNB F1:  0.584093567251462\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.88      0.78        40\n",
      "          1       0.64      0.37      0.47        19\n",
      "          2       0.82      0.69      0.75        13\n",
      "\n",
      "avg / total       0.70      0.71      0.69        72\n",
      "\n",
      "[35  4  1 11  7  1  4  0  9]\n",
      "svc Accuracy:  0.7083333333333334\n",
      "svc F1:  0.6648148148148149\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.95      0.75        40\n",
      "          1       0.75      0.16      0.26        19\n",
      "          2       0.86      0.46      0.60        13\n",
      "\n",
      "avg / total       0.70      0.65      0.60        72\n",
      "\n",
      "[38  1  1 16  3  0  7  0  6]\n",
      "LR Accuracy:  0.6527777777777778\n",
      "LR F1:  0.5377816042473813\n",
      "For name:  k_goh\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-2839-8722': 22, '0000-0002-3623-4891': 5, '0000-0003-0599-9696': 5, '0000-0001-5499-5187': 4, '0000-0002-2367-8303': 3, '0000-0001-5416-9627': 2, '0000-0002-8265-3421': 1})\n",
      "['0000-0002-2839-8722']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  n_harris\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-1320-282X': 5, '0000-0003-1256-3006': 4, '0000-0002-3443-3643': 2, '0000-0002-1965-6750': 2, '0000-0001-9664-2769': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_hill\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0002-4424-239X': 118, '0000-0002-6474-0214': 12, '0000-0003-3010-8998': 7, '0000-0002-5909-692X': 5, '0000-0002-2995-2596': 4, '0000-0001-8055-860X': 3, '0000-0001-6742-3620': 2, '0000-0002-3305-6954': 1})\n",
      "['0000-0002-4424-239X', '0000-0002-6474-0214']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 130\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 33)\n",
      "2\n",
      "(130, 77)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       118\n",
      "          1       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.82      0.91      0.86       130\n",
      "\n",
      "[118   0  12   0]\n",
      "MNB Accuracy:  0.9076923076923077\n",
      "MNB F1:  0.47580645161290325\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       118\n",
      "          1       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98       130\n",
      "\n",
      "[118   0   2  10]\n",
      "svc Accuracy:  0.9846153846153847\n",
      "svc F1:  0.9503437738731856\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       118\n",
      "          1       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.82      0.91      0.86       130\n",
      "\n",
      "[118   0  12   0]\n",
      "LR Accuracy:  0.9076923076923077\n",
      "LR F1:  0.47580645161290325\n",
      "For name:  p_pathak\n",
      "total sample size before apply threshold:  9\n",
      "Counter({'0000-0003-0118-3235': 4, '0000-0002-1157-5550': 3, '0000-0002-9771-6624': 1, '0000-0003-2152-3938': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_zeng\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0002-8246-2000': 42, '0000-0002-0260-1059': 21, '0000-0002-9909-7732': 6, '0000-0002-9150-214X': 6, '0000-0003-0293-7692': 4, '0000-0002-7657-6714': 3})\n",
      "['0000-0002-0260-1059', '0000-0002-8246-2000']\n",
      "Total sample size after apply threshold:  63\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 14)\n",
      "2\n",
      "(63, 37)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.86      0.82        21\n",
      "          1       0.93      0.88      0.90        42\n",
      "\n",
      "avg / total       0.88      0.87      0.87        63\n",
      "\n",
      "[18  3  5 37]\n",
      "MNB Accuracy:  0.873015873015873\n",
      "MNB F1:  0.8603104212860311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.90      0.93        21\n",
      "          1       0.95      0.98      0.96        42\n",
      "\n",
      "avg / total       0.95      0.95      0.95        63\n",
      "\n",
      "[19  2  1 41]\n",
      "svc Accuracy:  0.9523809523809523\n",
      "svc F1:  0.9457675753228121\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.81      0.85        21\n",
      "          1       0.91      0.95      0.93        42\n",
      "\n",
      "avg / total       0.90      0.90      0.90        63\n",
      "\n",
      "[17  4  2 40]\n",
      "LR Accuracy:  0.9047619047619048\n",
      "LR F1:  0.8901162790697674\n",
      "For name:  h_liu\n",
      "total sample size before apply threshold:  439\n",
      "Counter({'0000-0001-6715-6366': 100, '0000-0002-0253-647X': 45, '0000-0002-1006-6666': 39, '0000-0001-7639-0904': 39, '0000-0002-7233-1509': 31, '0000-0001-9366-6204': 26, '0000-0002-4723-845X': 18, '0000-0003-3326-2640': 17, '0000-0002-3745-7202': 13, '0000-0003-4837-5373': 11, '0000-0003-3103-6949': 10, '0000-0002-4548-2002': 9, '0000-0003-0266-9472': 9, '0000-0001-7984-6305': 8, '0000-0002-7645-0855': 8, '0000-0003-2394-5421': 7, '0000-0001-5451-6828': 6, '0000-0002-1852-4537': 5, '0000-0003-2183-9609': 3, '0000-0003-1837-1435': 3, '0000-0002-2781-2637': 3, '0000-0001-8959-0315': 3, '0000-0003-1313-4000': 3, '0000-0003-1724-4418': 2, '0000-0003-0345-6647': 2, '0000-0001-8519-3240': 2, '0000-0002-3292-9303': 2, '0000-0003-1679-6560': 2, '0000-0003-4341-672X': 2, '0000-0001-8806-6204': 1, '0000-0003-3125-4399': 1, '0000-0002-5450-5958': 1, '0000-0003-0658-4425': 1, '0000-0002-6370-0704': 1, '0000-0001-6604-5509': 1, '0000-0002-6009-8797': 1, '0000-0003-4566-2107': 1, '0000-0003-3055-5528': 1, '0000-0002-5437-4695': 1, '0000-0003-3607-7176': 1})\n",
      "['0000-0003-4837-5373', '0000-0002-1006-6666', '0000-0003-3326-2640', '0000-0002-3745-7202', '0000-0001-6715-6366', '0000-0001-9366-6204', '0000-0002-0253-647X', '0000-0002-4723-845X', '0000-0001-7639-0904', '0000-0003-3103-6949', '0000-0002-7233-1509']\n",
      "Total sample size after apply threshold:  349\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(349, 175)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(349, 25)\n",
      "2\n",
      "(349, 200)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.37      0.26      0.30        39\n",
      "          2       1.00      0.18      0.30        17\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.51      0.90      0.65       100\n",
      "          5       0.48      0.50      0.49        26\n",
      "          6       0.51      0.84      0.64        45\n",
      "          7       0.00      0.00      0.00        18\n",
      "          8       0.78      0.46      0.58        39\n",
      "          9       0.00      0.00      0.00        10\n",
      "         10       0.88      0.45      0.60        31\n",
      "\n",
      "avg / total       0.50      0.53      0.47       349\n",
      "\n",
      "[ 0  2  0  0  7  1  0  0  0  0  1  0 10  0  0 20  3  2  1  2  0  1  0  0\n",
      "  3  0  6  0  8  0  0  0  0  0  1  0  0 10  1  1  0  0  0  0  0  4  0  0\n",
      " 90  2  4  0  0  0  0  0  0  0  0  7 13  4  0  2  0  0  0  0  0  0  7  0\n",
      " 38  0  0  0  0  0  6  0  0  5  1  6  0  0  0  0  0  2  0  0 11  2  6  0\n",
      " 18  0  0  1  2  0  0  1  2  3  0  1  0  0  0  0  0  0 13  2  2  0  0  0\n",
      " 14]\n",
      "MNB Accuracy:  0.5329512893982808\n",
      "MNB F1:  0.3234964672433863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.38      0.31      0.34        39\n",
      "          2       0.90      0.53      0.67        17\n",
      "          3       1.00      0.15      0.27        13\n",
      "          4       0.58      0.89      0.70       100\n",
      "          5       0.88      0.58      0.70        26\n",
      "          6       0.71      0.78      0.74        45\n",
      "          7       0.58      0.39      0.47        18\n",
      "          8       0.62      0.64      0.63        39\n",
      "          9       0.00      0.00      0.00        10\n",
      "         10       0.79      0.61      0.69        31\n",
      "\n",
      "avg / total       0.62      0.61      0.59       349\n",
      "\n",
      "[ 0  3  0  0  3  0  0  1  0  3  1  0 12  0  0 18  0  1  3  3  0  2  0  0\n",
      "  9  0  2  0  5  0  1  0  0  1  0  0  2  9  0  0  0  0  0  1  0  4  0  0\n",
      " 89  2  3  0  1  0  1  0  2  0  0  5 15  1  0  3  0  0  0  0  1  0  6  0\n",
      " 35  1  2  0  0  1  5  0  0  2  0  1  7  2  0  0  0  4  0  0 10  0  0  0\n",
      " 25  0  0  4  2  0  0  0  0  2  0  2  0  0  1  0  0  0  9  0  1  0  1  0\n",
      " 19]\n",
      "svc Accuracy:  0.6103151862464183\n",
      "svc F1:  0.473432839477244\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.37      0.26      0.30        39\n",
      "          2       0.86      0.35      0.50        17\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.52      0.96      0.67       100\n",
      "          5       0.89      0.62      0.73        26\n",
      "          6       0.69      0.78      0.73        45\n",
      "          7       0.25      0.06      0.09        18\n",
      "          8       0.56      0.49      0.52        39\n",
      "          9       0.00      0.00      0.00        10\n",
      "         10       0.73      0.52      0.60        31\n",
      "\n",
      "avg / total       0.53      0.57      0.52       349\n",
      "\n",
      "[ 0  3  0  0  7  0  0  0  0  0  1  0 10  0  0 22  0  1  3  3  0  0  0  0\n",
      "  6  0  3  0  6  0  2  0  0  0  1  0  0 12  0  0  0  0  0  0  0  2  0  0\n",
      " 96  0  1  0  0  0  1  0  0  0  0  4 16  2  0  4  0  0  0  0  1  0  8  0\n",
      " 35  0  1  0  0  0  7  0  0  5  0  2  1  2  0  1  0  2  0  0 13  1  1  0\n",
      " 19  0  3  0  2  0  0  3  1  2  0  2  0  0  0  0  0  0 13  0  1  0  1  0\n",
      " 16]\n",
      "LR Accuracy:  0.5702005730659025\n",
      "LR F1:  0.3769117263016909\n",
      "For name:  s_bae\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0003-0551-7618': 19, '0000-0002-3019-0584': 17, '0000-0002-4995-6543': 17, '0000-0002-8993-8884': 9, '0000-0003-0098-8816': 8, '0000-0003-1926-5466': 6, '0000-0001-7603-7676': 6, '0000-0003-0637-4110': 1})\n",
      "['0000-0003-0551-7618', '0000-0002-3019-0584', '0000-0002-4995-6543']\n",
      "Total sample size after apply threshold:  53\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 6)\n",
      "2\n",
      "(53, 38)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.84      0.73        19\n",
      "          1       0.83      0.59      0.69        17\n",
      "          2       0.81      0.76      0.79        17\n",
      "\n",
      "avg / total       0.76      0.74      0.73        53\n",
      "\n",
      "[16  2  1  5 10  2  4  0 13]\n",
      "MNB Accuracy:  0.7358490566037735\n",
      "MNB F1:  0.7349355625217694\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.89      0.89        19\n",
      "          1       0.92      0.65      0.76        17\n",
      "          2       0.68      0.88      0.77        17\n",
      "\n",
      "avg / total       0.83      0.81      0.81        53\n",
      "\n",
      "[17  0  2  1 11  5  1  1 15]\n",
      "svc Accuracy:  0.8113207547169812\n",
      "svc F1:  0.8075294336637349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.89      0.83        19\n",
      "          1       0.85      0.65      0.73        17\n",
      "          2       0.72      0.76      0.74        17\n",
      "\n",
      "avg / total       0.78      0.77      0.77        53\n",
      "\n",
      "[17  1  1  2 11  4  3  1 13]\n",
      "LR Accuracy:  0.7735849056603774\n",
      "LR F1:  0.7684862562911343\n",
      "For name:  s_fernandes\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0003-1128-833X': 20, '0000-0002-1295-5010': 6, '0000-0002-9035-793X': 5, '0000-0002-7871-6717': 5, '0000-0002-0790-303X': 2})\n",
      "['0000-0003-1128-833X']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  a_miller\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0002-7056-8502': 33, '0000-0001-8474-5090': 28, '0000-0002-7293-764X': 22, '0000-0002-0553-8470': 15, '0000-0001-9735-6609': 5, '0000-0001-8527-1595': 1, '0000-0002-1761-4143': 1, '0000-0002-3099-1648': 1, '0000-0002-0941-1717': 1, '0000-0001-9739-8462': 1, '0000-0003-0924-8443': 1})\n",
      "['0000-0001-8474-5090', '0000-0002-0553-8470', '0000-0002-7056-8502', '0000-0002-7293-764X']\n",
      "Total sample size after apply threshold:  98\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 62)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 14)\n",
      "2\n",
      "(98, 76)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.29      0.33        28\n",
      "          1       1.00      0.13      0.24        15\n",
      "          2       0.51      0.88      0.64        33\n",
      "          3       0.56      0.45      0.50        22\n",
      "\n",
      "avg / total       0.56      0.50      0.46        98\n",
      "\n",
      "[ 8  0 14  6  6  2  7  0  2  0 29  2  5  0  7 10]\n",
      "MNB Accuracy:  0.5\n",
      "MNB F1:  0.4265672935841003\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.93      0.65        28\n",
      "          1       0.75      0.20      0.32        15\n",
      "          2       0.96      0.76      0.85        33\n",
      "          3       0.88      0.64      0.74        22\n",
      "\n",
      "avg / total       0.78      0.69      0.68        98\n",
      "\n",
      "[26  1  0  1 12  3  0  0  7  0 25  1  7  0  1 14]\n",
      "svc Accuracy:  0.6938775510204082\n",
      "svc F1:  0.6375223015165031\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.64      0.53        28\n",
      "          1       1.00      0.20      0.33        15\n",
      "          2       0.73      0.82      0.77        33\n",
      "          3       0.67      0.55      0.60        22\n",
      "\n",
      "avg / total       0.68      0.61      0.60        98\n",
      "\n",
      "[18  0  5  5  9  3  3  0  5  0 27  1  8  0  2 12]\n",
      "LR Accuracy:  0.6122448979591837\n",
      "LR F1:  0.5585434173669468\n",
      "For name:  a_eklund\n",
      "total sample size before apply threshold:  118\n",
      "Counter({'0000-0002-2031-722X': 73, '0000-0003-0861-1001': 40, '0000-0003-1271-1814': 4, '0000-0002-2162-7537': 1})\n",
      "['0000-0003-0861-1001', '0000-0002-2031-722X']\n",
      "Total sample size after apply threshold:  113\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(113, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(113, 17)\n",
      "2\n",
      "(113, 73)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.45      0.56        40\n",
      "          1       0.75      0.92      0.83        73\n",
      "\n",
      "avg / total       0.75      0.75      0.73       113\n",
      "\n",
      "[18 22  6 67]\n",
      "MNB Accuracy:  0.7522123893805309\n",
      "MNB F1:  0.6948302469135803\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.57      0.66        40\n",
      "          1       0.80      0.90      0.85        73\n",
      "\n",
      "avg / total       0.79      0.79      0.78       113\n",
      "\n",
      "[23 17  7 66]\n",
      "svc Accuracy:  0.7876106194690266\n",
      "svc F1:  0.7516483516483516\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.40      0.52        40\n",
      "          1       0.74      0.93      0.82        73\n",
      "\n",
      "avg / total       0.75      0.74      0.72       113\n",
      "\n",
      "[16 24  5 68]\n",
      "LR Accuracy:  0.7433628318584071\n",
      "LR F1:  0.6744162940884253\n",
      "For name:  r_moore\n",
      "total sample size before apply threshold:  221\n",
      "Counter({'0000-0002-0776-5861': 75, '0000-0001-7221-6693': 51, '0000-0003-1072-2755': 45, '0000-0003-2027-2428': 44, '0000-0003-4196-1804': 6})\n",
      "['0000-0003-2027-2428', '0000-0003-1072-2755', '0000-0001-7221-6693', '0000-0002-0776-5861']\n",
      "Total sample size after apply threshold:  215\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(215, 120)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(215, 37)\n",
      "2\n",
      "(215, 157)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.39      0.51        44\n",
      "          1       0.76      0.36      0.48        45\n",
      "          2       0.73      0.78      0.75        51\n",
      "          3       0.54      0.84      0.66        75\n",
      "\n",
      "avg / total       0.67      0.63      0.61       215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  1  5 21  2 16  3 24  1  2 40  8  3  2  7 63]\n",
      "MNB Accuracy:  0.6325581395348837\n",
      "MNB F1:  0.6016785041055175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.61      0.73        44\n",
      "          1       0.58      0.42      0.49        45\n",
      "          2       0.89      0.78      0.83        51\n",
      "          3       0.60      0.85      0.70        75\n",
      "\n",
      "avg / total       0.72      0.70      0.69       215\n",
      "\n",
      "[27  4  1 12  1 19  1 24  1  3 40  7  1  7  3 64]\n",
      "svc Accuracy:  0.6976744186046512\n",
      "svc F1:  0.6883848133848134\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.45      0.57        44\n",
      "          1       0.61      0.38      0.47        45\n",
      "          2       0.83      0.75      0.78        51\n",
      "          3       0.57      0.88      0.69        75\n",
      "\n",
      "avg / total       0.68      0.66      0.64       215\n",
      "\n",
      "[20  4  3 17  2 17  2 24  1  4 38  8  3  3  3 66]\n",
      "LR Accuracy:  0.6558139534883721\n",
      "LR F1:  0.6288559982076359\n",
      "For name:  m_thomsen\n",
      "total sample size before apply threshold:  98\n",
      "Counter({'0000-0002-2469-6458': 37, '0000-0003-2453-5141': 32, '0000-0001-6805-7247': 17, '0000-0003-3081-9220': 7, '0000-0003-3814-1709': 3, '0000-0003-1208-5497': 2})\n",
      "['0000-0003-2453-5141', '0000-0002-2469-6458', '0000-0001-6805-7247']\n",
      "Total sample size after apply threshold:  86\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 43)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 18)\n",
      "2\n",
      "(86, 61)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.88      0.79        32\n",
      "          1       0.79      0.70      0.74        37\n",
      "          2       0.71      0.59      0.65        17\n",
      "\n",
      "avg / total       0.75      0.74      0.74        86\n",
      "\n",
      "[28  3  1  8 26  3  3  4 10]\n",
      "MNB Accuracy:  0.7441860465116279\n",
      "MNB F1:  0.7255836091819735\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        32\n",
      "          1       0.81      0.95      0.88        37\n",
      "          2       0.86      0.71      0.77        17\n",
      "\n",
      "avg / total       0.89      0.88      0.88        86\n",
      "\n",
      "[29  3  0  0 35  2  0  5 12]\n",
      "svc Accuracy:  0.8837209302325582\n",
      "svc F1:  0.8666710735060814\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.78      0.82        32\n",
      "          1       0.72      0.89      0.80        37\n",
      "          2       0.91      0.59      0.71        17\n",
      "\n",
      "avg / total       0.81      0.79      0.79        86\n",
      "\n",
      "[25  7  0  3 33  1  1  6 10]\n",
      "LR Accuracy:  0.7906976744186046\n",
      "LR F1:  0.7763795227749406\n",
      "For name:  l_ng\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0003-1905-3586': 37, '0000-0002-6973-9466': 3, '0000-0001-7500-9403': 1, '0000-0001-5988-008X': 1, '0000-0003-3135-244X': 1, '0000-0002-7189-1272': 1})\n",
      "['0000-0003-1905-3586']\n",
      "Total sample size after apply threshold:  37\n",
      "For name:  a_phillips\n",
      "total sample size before apply threshold:  170\n",
      "Counter({'0000-0002-5461-0598': 98, '0000-0001-6367-9784': 24, '0000-0001-5599-6499': 24, '0000-0003-4883-0022': 9, '0000-0003-4225-0158': 7, '0000-0003-4473-5108': 4, '0000-0001-6618-0145': 3, '0000-0001-6335-9430': 1})\n",
      "['0000-0001-6367-9784', '0000-0001-5599-6499', '0000-0002-5461-0598']\n",
      "Total sample size after apply threshold:  146\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(146, 58)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(146, 15)\n",
      "2\n",
      "(146, 73)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.50      0.62        24\n",
      "          1       0.82      0.75      0.78        24\n",
      "          2       0.85      0.95      0.90        98\n",
      "\n",
      "avg / total       0.84      0.84      0.83       146\n",
      "\n",
      "[12  2 10  0 18  6  3  2 93]\n",
      "MNB Accuracy:  0.8424657534246576\n",
      "MNB F1:  0.7655146785581568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.67      0.74        24\n",
      "          1       1.00      0.75      0.86        24\n",
      "          2       0.88      0.98      0.93        98\n",
      "\n",
      "avg / total       0.89      0.89      0.89       146\n",
      "\n",
      "[16  0  8  1 18  5  2  0 96]\n",
      "svc Accuracy:  0.8904109589041096\n",
      "svc F1:  0.8429550451795144\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.55        24\n",
      "          1       1.00      0.71      0.83        24\n",
      "          2       0.82      1.00      0.90        98\n",
      "\n",
      "avg / total       0.88      0.85      0.83       146\n",
      "\n",
      "[ 9  0 15  0 17  7  0  0 98]\n",
      "LR Accuracy:  0.8493150684931506\n",
      "LR F1:  0.7579351356482705\n",
      "For name:  y_ye\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0002-7517-1715': 75, '0000-0002-2029-4558': 8, '0000-0003-3962-8463': 1, '0000-0002-9172-6514': 1})\n",
      "['0000-0002-7517-1715']\n",
      "Total sample size after apply threshold:  75\n",
      "For name:  m_guerreiro\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0002-1948-1516': 23, '0000-0002-5133-8779': 6, '0000-0002-2863-887X': 6, '0000-0001-6774-9348': 1})\n",
      "['0000-0002-1948-1516']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  g_alves\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0002-4213-0714': 40, '0000-0003-0630-2870': 12, '0000-0003-3945-9962': 7, '0000-0003-4985-5555': 1})\n",
      "['0000-0003-0630-2870', '0000-0002-4213-0714']\n",
      "Total sample size after apply threshold:  52\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 10)\n",
      "2\n",
      "(52, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83        12\n",
      "          1       0.95      0.95      0.95        40\n",
      "\n",
      "avg / total       0.92      0.92      0.92        52\n",
      "\n",
      "[10  2  2 38]\n",
      "MNB Accuracy:  0.9230769230769231\n",
      "MNB F1:  0.8916666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83        12\n",
      "          1       0.95      0.95      0.95        40\n",
      "\n",
      "avg / total       0.92      0.92      0.92        52\n",
      "\n",
      "[10  2  2 38]\n",
      "svc Accuracy:  0.9230769230769231\n",
      "svc F1:  0.8916666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.33      0.47        12\n",
      "          1       0.83      0.97      0.90        40\n",
      "\n",
      "avg / total       0.82      0.83      0.80        52\n",
      "\n",
      "[ 4  8  1 39]\n",
      "LR Accuracy:  0.8269230769230769\n",
      "LR F1:  0.6835699797160244\n",
      "For name:  m_mohammed\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0003-3423-0085': 2, '0000-0002-1795-579X': 2, '0000-0002-9695-396X': 1, '0000-0002-7103-0165': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_mohammadi\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0003-1311-9636': 42, '0000-0003-0650-6654': 13, '0000-0003-3450-6424': 1, '0000-0003-1658-9756': 1, '0000-0002-6656-025X': 1, '0000-0002-9209-3034': 1})\n",
      "['0000-0003-0650-6654', '0000-0003-1311-9636']\n",
      "Total sample size after apply threshold:  55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 11)\n",
      "2\n",
      "(55, 43)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.15      0.24        13\n",
      "          1       0.78      0.95      0.86        42\n",
      "\n",
      "avg / total       0.72      0.76      0.71        55\n",
      "\n",
      "[ 2 11  2 40]\n",
      "MNB Accuracy:  0.7636363636363637\n",
      "MNB F1:  0.5477545857052498\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.38      0.53        13\n",
      "          1       0.84      0.98      0.90        42\n",
      "\n",
      "avg / total       0.84      0.84      0.81        55\n",
      "\n",
      "[ 5  8  1 41]\n",
      "svc Accuracy:  0.8363636363636363\n",
      "svc F1:  0.7137073452862928\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       0.79      1.00      0.88        42\n",
      "\n",
      "avg / total       0.84      0.80      0.74        55\n",
      "\n",
      "[ 2 11  0 42]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.5754385964912281\n",
      "For name:  c_chao\n",
      "total sample size before apply threshold:  155\n",
      "Counter({'0000-0003-2892-7986': 86, '0000-0002-2804-7447': 34, '0000-0001-6499-5789': 19, '0000-0002-8789-7732': 7, '0000-0001-7769-9305': 7, '0000-0003-1215-8588': 1, '0000-0003-4108-2658': 1})\n",
      "['0000-0002-2804-7447', '0000-0003-2892-7986', '0000-0001-6499-5789']\n",
      "Total sample size after apply threshold:  139\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 77)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 17)\n",
      "2\n",
      "(139, 94)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.68      0.70        34\n",
      "          1       0.83      1.00      0.91        86\n",
      "          2       0.25      0.05      0.09        19\n",
      "\n",
      "avg / total       0.73      0.79      0.75       139\n",
      "\n",
      "[23  8  3  0 86  0  9  9  1]\n",
      "MNB Accuracy:  0.7913669064748201\n",
      "MNB F1:  0.5646597095872458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.74      0.75        34\n",
      "          1       0.83      1.00      0.91        86\n",
      "          2       0.67      0.11      0.18        19\n",
      "\n",
      "avg / total       0.79      0.81      0.77       139\n",
      "\n",
      "[25  8  1  0 86  0  8  9  2]\n",
      "svc Accuracy:  0.8129496402877698\n",
      "svc F1:  0.61271324952917\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.62      0.66        34\n",
      "          1       0.81      1.00      0.90        86\n",
      "          2       0.33      0.05      0.09        19\n",
      "\n",
      "avg / total       0.72      0.78      0.73       139\n",
      "\n",
      "[21 11  2  0 86  0  9  9  1]\n",
      "LR Accuracy:  0.7769784172661871\n",
      "LR F1:  0.5476641414141414\n",
      "For name:  s_teixeira\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0003-0419-2348': 12, '0000-0001-5845-058X': 11, '0000-0002-2462-8535': 3, '0000-0002-9473-0113': 3, '0000-0002-7464-3944': 3, '0000-0002-6603-7936': 3, '0000-0003-3664-2577': 1})\n",
      "['0000-0003-0419-2348', '0000-0001-5845-058X']\n",
      "Total sample size after apply threshold:  23\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 10)\n",
      "2\n",
      "(23, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.58      0.58        12\n",
      "          1       0.55      0.55      0.55        11\n",
      "\n",
      "avg / total       0.57      0.57      0.57        23\n",
      "\n",
      "[7 5 5 6]\n",
      "MNB Accuracy:  0.5652173913043478\n",
      "MNB F1:  0.5643939393939394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.58      0.58        12\n",
      "          1       0.55      0.55      0.55        11\n",
      "\n",
      "avg / total       0.57      0.57      0.57        23\n",
      "\n",
      "[7 5 5 6]\n",
      "svc Accuracy:  0.5652173913043478\n",
      "svc F1:  0.5643939393939394\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.67      0.64        12\n",
      "          1       0.60      0.55      0.57        11\n",
      "\n",
      "avg / total       0.61      0.61      0.61        23\n",
      "\n",
      "[8 4 5 6]\n",
      "LR Accuracy:  0.6086956521739131\n",
      "LR F1:  0.6057142857142856\n",
      "For name:  l_almeida\n",
      "total sample size before apply threshold:  133\n",
      "Counter({'0000-0002-4861-8649': 57, '0000-0002-7769-4712': 43, '0000-0003-1370-961X': 12, '0000-0003-0370-214X': 8, '0000-0002-0651-7014': 5, '0000-0001-9346-7520': 4, '0000-0002-1324-0068': 1, '0000-0002-9544-3028': 1, '0000-0003-4711-4454': 1, '0000-0002-0921-887X': 1})\n",
      "['0000-0003-1370-961X', '0000-0002-4861-8649', '0000-0002-7769-4712']\n",
      "Total sample size after apply threshold:  112\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(112, 55)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(112, 23)\n",
      "2\n",
      "(112, 78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.33      0.47        12\n",
      "          1       0.74      0.95      0.83        57\n",
      "          2       0.85      0.67      0.75        43\n",
      "\n",
      "avg / total       0.79      0.78      0.76       112\n",
      "\n",
      "[ 4  5  3  1 54  2  0 14 29]\n",
      "MNB Accuracy:  0.7767857142857143\n",
      "MNB F1:  0.6848680731033672\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.17      0.25        12\n",
      "          1       0.77      0.88      0.82        57\n",
      "          2       0.79      0.79      0.79        43\n",
      "\n",
      "avg / total       0.75      0.77      0.75       112\n",
      "\n",
      "[ 2  7  3  1 50  6  1  8 34]\n",
      "svc Accuracy:  0.7678571428571429\n",
      "svc F1:  0.6201232685220486\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29        12\n",
      "          1       0.75      0.95      0.84        57\n",
      "          2       0.84      0.74      0.79        43\n",
      "\n",
      "avg / total       0.81      0.79      0.76       112\n",
      "\n",
      "[ 2  7  3  0 54  3  0 11 32]\n",
      "LR Accuracy:  0.7857142857142857\n",
      "LR F1:  0.6376823482766635\n",
      "For name:  y_tseng\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-8461-6181': 45, '0000-0002-2354-5906': 9, '0000-0001-6917-893X': 2, '0000-0002-3803-7410': 2, '0000-0002-1814-5553': 2, '0000-0002-3511-7191': 1})\n",
      "['0000-0002-8461-6181']\n",
      "Total sample size after apply threshold:  45\n",
      "For name:  a_ferro\n",
      "total sample size before apply threshold:  125\n",
      "Counter({'0000-0002-5486-9145': 91, '0000-0003-2399-3626': 11, '0000-0001-6042-4591': 10, '0000-0003-4470-079X': 7, '0000-0001-8403-9823': 4, '0000-0002-9431-5788': 2})\n",
      "['0000-0001-6042-4591', '0000-0002-5486-9145', '0000-0003-2399-3626']\n",
      "Total sample size after apply threshold:  112\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(112, 53)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(112, 18)\n",
      "2\n",
      "(112, 71)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.40      0.53        10\n",
      "          1       0.84      0.99      0.91        91\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.75      0.84      0.79       112\n",
      "\n",
      "[ 4  6  0  1 90  0  0 11  0]\n",
      "MNB Accuracy:  0.8392857142857143\n",
      "MNB F1:  0.4808080808080808\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.50      0.62        10\n",
      "          1       0.87      0.99      0.92        91\n",
      "          2       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.88      0.87      0.84       112\n",
      "\n",
      "[ 5  5  0  1 90  0  0  9  2]\n",
      "svc Accuracy:  0.8660714285714286\n",
      "svc F1:  0.6185897435897435\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.81      1.00      0.90        91\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.66      0.81      0.73       112\n",
      "\n",
      "[ 0 10  0  0 91  0  0 11  0]\n",
      "LR Accuracy:  0.8125\n",
      "LR F1:  0.2988505747126437\n",
      "For name:  d_he\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0003-3253-654X': 17, '0000-0003-2212-1973': 4, '0000-0002-9947-6177': 3, '0000-0002-2446-7436': 2, '0000-0002-4001-826X': 2, '0000-0002-3360-9352': 1})\n",
      "['0000-0003-3253-654X']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  k_ko\n",
      "total sample size before apply threshold:  168\n",
      "Counter({'0000-0002-0978-1937': 153, '0000-0003-3649-4594': 11, '0000-0002-6412-1026': 2, '0000-0002-0192-0269': 1, '0000-0002-0515-5904': 1})\n",
      "['0000-0003-3649-4594', '0000-0002-0978-1937']\n",
      "Total sample size after apply threshold:  164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(164, 45)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(164, 17)\n",
      "2\n",
      "(164, 62)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.36      0.50        11\n",
      "          1       0.96      0.99      0.97       153\n",
      "\n",
      "avg / total       0.95      0.95      0.94       164\n",
      "\n",
      "[  4   7   1 152]\n",
      "MNB Accuracy:  0.9512195121951219\n",
      "MNB F1:  0.7371794871794872\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.82      0.86        11\n",
      "          1       0.99      0.99      0.99       153\n",
      "\n",
      "avg / total       0.98      0.98      0.98       164\n",
      "\n",
      "[  9   2   1 152]\n",
      "svc Accuracy:  0.9817073170731707\n",
      "svc F1:  0.9236854350860866\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        11\n",
      "          1       0.95      1.00      0.97       153\n",
      "\n",
      "avg / total       0.95      0.95      0.94       164\n",
      "\n",
      "[  3   8   0 153]\n",
      "LR Accuracy:  0.9512195121951219\n",
      "LR F1:  0.7015468607825296\n",
      "For name:  t_mori\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0003-3918-0873': 92, '0000-0002-0370-1924': 10, '0000-0001-5340-3282': 1, '0000-0001-7096-4161': 1})\n",
      "['0000-0002-0370-1924', '0000-0003-3918-0873']\n",
      "Total sample size after apply threshold:  102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(102, 24)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(102, 15)\n",
      "2\n",
      "(102, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.30      0.43        10\n",
      "          1       0.93      0.99      0.96        92\n",
      "\n",
      "avg / total       0.91      0.92      0.91       102\n",
      "\n",
      "[ 3  7  1 91]\n",
      "MNB Accuracy:  0.9215686274509803\n",
      "MNB F1:  0.6932330827067669\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.95      1.00      0.97        92\n",
      "\n",
      "avg / total       0.95      0.95      0.94       102\n",
      "\n",
      "[ 5  5  0 92]\n",
      "svc Accuracy:  0.9509803921568627\n",
      "svc F1:  0.82010582010582\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.90      1.00      0.95        92\n",
      "\n",
      "avg / total       0.81      0.90      0.86       102\n",
      "\n",
      "[ 0 10  0 92]\n",
      "LR Accuracy:  0.9019607843137255\n",
      "LR F1:  0.4742268041237114\n",
      "For name:  p_lima\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-1252-2565': 8, '0000-0002-9739-0783': 8, '0000-0002-4323-3918': 4, '0000-0003-2081-571X': 2, '0000-0002-8962-8050': 1, '0000-0003-2937-9520': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_ferguson\n",
      "total sample size before apply threshold:  217\n",
      "Counter({'0000-0001-5045-819X': 174, '0000-0001-9302-5992': 35, '0000-0001-6448-8701': 4, '0000-0003-0612-6512': 3, '0000-0002-7400-7892': 1})\n",
      "['0000-0001-5045-819X', '0000-0001-9302-5992']\n",
      "Total sample size after apply threshold:  209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(209, 110)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(209, 34)\n",
      "2\n",
      "(209, 144)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       174\n",
      "          1       0.82      0.40      0.54        35\n",
      "\n",
      "avg / total       0.88      0.89      0.87       209\n",
      "\n",
      "[171   3  21  14]\n",
      "MNB Accuracy:  0.8851674641148325\n",
      "MNB F1:  0.7364438839848675\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       174\n",
      "          1       0.83      0.57      0.68        35\n",
      "\n",
      "avg / total       0.90      0.91      0.90       209\n",
      "\n",
      "[170   4  15  20]\n",
      "svc Accuracy:  0.9090909090909091\n",
      "svc F1:  0.8125206553042821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.94       174\n",
      "          1       0.93      0.37      0.53        35\n",
      "\n",
      "avg / total       0.89      0.89      0.87       209\n",
      "\n",
      "[173   1  22  13]\n",
      "LR Accuracy:  0.8899521531100478\n",
      "LR F1:  0.734140810795863\n",
      "For name:  h_moreira\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-1487-0539': 13, '0000-0002-5481-0688': 10, '0000-0002-4674-5417': 3, '0000-0002-4556-5027': 1, '0000-0002-5588-374X': 1})\n",
      "['0000-0002-1487-0539', '0000-0002-5481-0688']\n",
      "Total sample size after apply threshold:  23\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 17)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 7)\n",
      "2\n",
      "(23, 24)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.62      0.62        13\n",
      "          1       0.50      0.50      0.50        10\n",
      "\n",
      "avg / total       0.57      0.57      0.57        23\n",
      "\n",
      "[8 5 5 5]\n",
      "MNB Accuracy:  0.5652173913043478\n",
      "MNB F1:  0.5576923076923077\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.54      0.67        13\n",
      "          1       0.60      0.90      0.72        10\n",
      "\n",
      "avg / total       0.76      0.70      0.69        23\n",
      "\n",
      "[7 6 1 9]\n",
      "svc Accuracy:  0.6956521739130435\n",
      "svc F1:  0.6933333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.62      0.62        13\n",
      "          1       0.50      0.50      0.50        10\n",
      "\n",
      "avg / total       0.57      0.57      0.57        23\n",
      "\n",
      "[8 5 5 5]\n",
      "LR Accuracy:  0.5652173913043478\n",
      "LR F1:  0.5576923076923077\n",
      "For name:  s_yi\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0002-6656-6205': 29, '0000-0001-6333-4399': 19, '0000-0003-2689-8595': 11, '0000-0003-2804-7161': 3, '0000-0003-4932-8237': 3, '0000-0002-9190-5643': 2})\n",
      "['0000-0002-6656-6205', '0000-0003-2689-8595', '0000-0001-6333-4399']\n",
      "Total sample size after apply threshold:  59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 41)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 14)\n",
      "2\n",
      "(59, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.79      0.69        29\n",
      "          1       0.50      0.09      0.15        11\n",
      "          2       0.47      0.47      0.47        19\n",
      "\n",
      "avg / total       0.54      0.56      0.52        59\n",
      "\n",
      "[23  0  6  6  1  4  9  1  9]\n",
      "MNB Accuracy:  0.559322033898305\n",
      "MNB F1:  0.43803250951719136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.86      0.76        29\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       0.75      0.63      0.69        19\n",
      "\n",
      "avg / total       0.76      0.73      0.72        59\n",
      "\n",
      "[25  0  4  5  6  0  7  0 12]\n",
      "svc Accuracy:  0.7288135593220338\n",
      "svc F1:  0.7163907987437398\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.83      0.69        29\n",
      "          1       1.00      0.18      0.31        11\n",
      "          2       0.56      0.47      0.51        19\n",
      "\n",
      "avg / total       0.66      0.59      0.56        59\n",
      "\n",
      "[24  0  5  7  2  2 10  0  9]\n",
      "LR Accuracy:  0.5932203389830508\n",
      "LR F1:  0.5025641025641026\n",
      "For name:  q_liu\n",
      "total sample size before apply threshold:  264\n",
      "Counter({'0000-0001-8477-6452': 62, '0000-0001-8525-7961': 62, '0000-0002-1179-290X': 47, '0000-0002-8402-029X': 26, '0000-0001-5286-4423': 24, '0000-0003-3533-7140': 18, '0000-0003-4114-5540': 8, '0000-0002-3616-351X': 6, '0000-0002-2199-2999': 2, '0000-0003-1508-7172': 2, '0000-0003-0769-4642': 1, '0000-0001-9746-2938': 1, '0000-0002-6286-941X': 1, '0000-0002-7574-3752': 1, '0000-0002-4678-3333': 1, '0000-0002-8398-1021': 1, '0000-0002-7285-5425': 1})\n",
      "['0000-0002-1179-290X', '0000-0003-3533-7140', '0000-0001-8477-6452', '0000-0001-5286-4423', '0000-0002-8402-029X', '0000-0001-8525-7961']\n",
      "Total sample size after apply threshold:  239\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(239, 104)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(239, 20)\n",
      "2\n",
      "(239, 124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.64      0.62        47\n",
      "          1       0.55      0.33      0.41        18\n",
      "          2       0.64      0.60      0.62        62\n",
      "          3       0.80      0.33      0.47        24\n",
      "          4       0.42      0.31      0.36        26\n",
      "          5       0.54      0.81      0.65        62\n",
      "\n",
      "avg / total       0.59      0.58      0.57       239\n",
      "\n",
      "[30  0  9  0  2  6  2  6  2  1  4  3  7  0 37  1  2 15  4  2  4  8  1  5\n",
      "  1  2  2  0  8 13  5  1  4  0  2 50]\n",
      "MNB Accuracy:  0.5815899581589958\n",
      "MNB F1:  0.5218257017192108\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.68      0.74        47\n",
      "          1       0.53      0.44      0.48        18\n",
      "          2       0.65      0.89      0.75        62\n",
      "          3       0.82      0.58      0.68        24\n",
      "          4       0.62      0.62      0.62        26\n",
      "          5       0.79      0.73      0.76        62\n",
      "\n",
      "avg / total       0.72      0.71      0.71       239\n",
      "\n",
      "[32  2 10  0  0  3  1  8  3  2  4  0  5  0 55  0  0  2  0  3  6 14  0  1\n",
      "  1  2  1  0 16  6  0  0 10  1  6 45]\n",
      "svc Accuracy:  0.7112970711297071\n",
      "svc F1:  0.6719913027915526\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.62      0.67        47\n",
      "          1       0.58      0.39      0.47        18\n",
      "          2       0.56      0.73      0.63        62\n",
      "          3       0.82      0.38      0.51        24\n",
      "          4       0.59      0.50      0.54        26\n",
      "          5       0.63      0.74      0.68        62\n",
      "\n",
      "avg / total       0.64      0.62      0.62       239\n",
      "\n",
      "[29  0 13  0  1  4  2  7  2  2  3  2  7  0 45  0  0 10  1  2  9  9  0  3\n",
      "  0  2  3  0 13  8  1  1  9  0  5 46]\n",
      "LR Accuracy:  0.6234309623430963\n",
      "LR F1:  0.5833563041896376\n",
      "For name:  m_ibrahim\n",
      "total sample size before apply threshold:  146\n",
      "Counter({'0000-0002-5756-5198': 20, '0000-0002-9698-0837': 19, '0000-0001-6509-2979': 17, '0000-0003-4614-7182': 15, '0000-0003-0257-860X': 14, '0000-0001-6019-5055': 9, '0000-0001-8657-3368': 9, '0000-0002-0116-597X': 6, '0000-0003-1412-2132': 6, '0000-0002-2603-8280': 5, '0000-0002-7762-1580': 5, '0000-0003-0623-5225': 4, '0000-0003-0468-617X': 3, '0000-0002-8854-8198': 3, '0000-0002-7925-4585': 2, '0000-0002-0021-5971': 2, '0000-0002-9288-2359': 2, '0000-0002-5121-7256': 1, '0000-0001-8433-7409': 1, '0000-0003-3407-4983': 1, '0000-0002-3425-600X': 1, '0000-0002-2953-2305': 1})\n",
      "['0000-0001-6509-2979', '0000-0003-4614-7182', '0000-0003-0257-860X', '0000-0002-9698-0837', '0000-0002-5756-5198']\n",
      "Total sample size after apply threshold:  85\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 40)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 14)\n",
      "2\n",
      "(85, 54)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.88      0.73        17\n",
      "          1       0.58      0.73      0.65        15\n",
      "          2       0.86      0.43      0.57        14\n",
      "          3       0.56      0.74      0.64        19\n",
      "          4       0.90      0.45      0.60        20\n",
      "\n",
      "avg / total       0.71      0.65      0.64        85\n",
      "\n",
      "[15  1  0  1  0  1 11  0  3  0  2  2  6  4  0  2  1  1 14  1  4  4  0  3\n",
      "  9]\n",
      "MNB Accuracy:  0.6470588235294118\n",
      "MNB F1:  0.6373116696789581\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.88      0.91        17\n",
      "          1       0.59      0.67      0.62        15\n",
      "          2       0.40      0.43      0.41        14\n",
      "          3       1.00      0.68      0.81        19\n",
      "          4       0.71      0.85      0.77        20\n",
      "\n",
      "avg / total       0.75      0.72      0.72        85\n",
      "\n",
      "[15  1  0  0  1  0 10  5  0  0  1  4  6  0  3  0  2  1 13  3  0  0  3  0\n",
      " 17]\n",
      "svc Accuracy:  0.7176470588235294\n",
      "svc F1:  0.7066222570532915\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.88      0.81        17\n",
      "          1       0.60      0.60      0.60        15\n",
      "          2       0.67      0.43      0.52        14\n",
      "          3       0.76      0.68      0.72        19\n",
      "          4       0.71      0.85      0.77        20\n",
      "\n",
      "avg / total       0.70      0.71      0.70        85\n",
      "\n",
      "[15  1  0  1  0  0  9  2  1  3  2  3  6  1  2  2  1  1 13  2  1  1  0  1\n",
      " 17]\n",
      "LR Accuracy:  0.7058823529411765\n",
      "LR F1:  0.6854998872390177\n",
      "For name:  s_collins\n",
      "total sample size before apply threshold:  163\n",
      "Counter({'0000-0002-0193-2892': 43, '0000-0002-4276-5840': 38, '0000-0002-0648-7433': 24, '0000-0003-0204-5109': 15, '0000-0001-9989-8794': 13, '0000-0002-5245-6611': 10, '0000-0003-1571-7410': 9, '0000-0002-3110-1037': 7, '0000-0001-5503-7386': 2, '0000-0003-4721-0040': 2})\n",
      "['0000-0002-0193-2892', '0000-0002-4276-5840', '0000-0002-5245-6611', '0000-0003-0204-5109', '0000-0002-0648-7433', '0000-0001-9989-8794']\n",
      "Total sample size after apply threshold:  143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(143, 69)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(143, 22)\n",
      "2\n",
      "(143, 91)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.79      0.63        43\n",
      "          1       0.55      0.58      0.56        38\n",
      "          2       0.50      0.10      0.17        10\n",
      "          3       0.00      0.00      0.00        15\n",
      "          4       0.59      0.83      0.69        24\n",
      "          5       1.00      0.15      0.27        13\n",
      "\n",
      "avg / total       0.53      0.55      0.49       143\n",
      "\n",
      "[34  8  0  0  1  0 15 22  0  0  1  0  4  0  1  0  5  0  5  7  0  0  3  0\n",
      "  1  2  1  0 20  0  6  1  0  0  4  2]\n",
      "MNB Accuracy:  0.5524475524475524\n",
      "MNB F1:  0.38612011657988665\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.74      0.79        43\n",
      "          1       0.57      0.68      0.62        38\n",
      "          2       0.29      0.40      0.33        10\n",
      "          3       1.00      0.47      0.64        15\n",
      "          4       0.78      0.75      0.77        24\n",
      "          5       0.33      0.38      0.36        13\n",
      "\n",
      "avg / total       0.69      0.64      0.65       143\n",
      "\n",
      "[32  8  1  0  0  2  6 26  2  0  1  3  0  0  4  0  2  4  0  7  0  7  0  1\n",
      "  0  3  3  0 18  0  0  2  4  0  2  5]\n",
      "svc Accuracy:  0.6433566433566433\n",
      "svc F1:  0.5836613915810134\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.70      0.62        43\n",
      "          1       0.58      0.68      0.63        38\n",
      "          2       0.67      0.40      0.50        10\n",
      "          3       1.00      0.33      0.50        15\n",
      "          4       0.72      0.88      0.79        24\n",
      "          5       0.40      0.15      0.22        13\n",
      "\n",
      "avg / total       0.63      0.62      0.60       143\n",
      "\n",
      "[30 10  0  0  1  2 10 26  0  0  1  1  4  0  4  0  2  0  3  6  0  5  1  0\n",
      "  0  2  1  0 21  0  6  1  1  0  3  2]\n",
      "LR Accuracy:  0.6153846153846154\n",
      "LR F1:  0.5443635127512145\n",
      "For name:  d_franco\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0002-5669-7164': 58, '0000-0002-0093-7042': 40, '0000-0003-3849-4272': 8, '0000-0001-5604-2531': 6, '0000-0002-8653-0488': 2, '0000-0002-2050-7883': 1})\n",
      "['0000-0002-0093-7042', '0000-0002-5669-7164']\n",
      "Total sample size after apply threshold:  98\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 42)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 21)\n",
      "2\n",
      "(98, 63)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.85      0.79        40\n",
      "          1       0.88      0.79      0.84        58\n",
      "\n",
      "avg / total       0.83      0.82      0.82        98\n",
      "\n",
      "[34  6 12 46]\n",
      "MNB Accuracy:  0.8163265306122449\n",
      "MNB F1:  0.8135306553911205\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.80      0.85        40\n",
      "          1       0.87      0.95      0.91        58\n",
      "\n",
      "avg / total       0.89      0.89      0.89        98\n",
      "\n",
      "[32  8  3 55]\n",
      "svc Accuracy:  0.8877551020408163\n",
      "svc F1:  0.8812121212121211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.78      0.83        40\n",
      "          1       0.86      0.93      0.89        58\n",
      "\n",
      "avg / total       0.87      0.87      0.87        98\n",
      "\n",
      "[31  9  4 54]\n",
      "LR Accuracy:  0.8673469387755102\n",
      "LR F1:  0.8596143250688705\n",
      "For name:  h_brown\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-8578-5510': 17, '0000-0002-0067-991X': 9, '0000-0003-4870-8369': 8, '0000-0001-7418-5536': 6, '0000-0001-6227-5147': 3, '0000-0001-9404-9515': 3, '0000-0003-2292-7766': 2})\n",
      "['0000-0001-8578-5510']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  s_martins\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0002-9396-5957': 18, '0000-0002-3720-2920': 15, '0000-0001-7217-6273': 15, '0000-0003-0237-6370': 12, '0000-0002-1812-8913': 8, '0000-0002-1874-0192': 7, '0000-0002-7733-4485': 5, '0000-0003-2122-0670': 3, '0000-0002-3526-3199': 1})\n",
      "['0000-0002-3720-2920', '0000-0003-0237-6370', '0000-0001-7217-6273', '0000-0002-9396-5957']\n",
      "Total sample size after apply threshold:  60\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 14)\n",
      "2\n",
      "(60, 51)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.20      0.27        15\n",
      "          1       0.57      0.33      0.42        12\n",
      "          2       0.57      0.53      0.55        15\n",
      "          3       0.53      0.94      0.68        18\n",
      "\n",
      "avg / total       0.52      0.53      0.49        60\n",
      "\n",
      "[ 3  2  3  7  2  4  2  4  2  1  8  4  0  0  1 17]\n",
      "MNB Accuracy:  0.5333333333333333\n",
      "MNB F1:  0.4813760105593136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.53      0.59        15\n",
      "          1       0.67      0.50      0.57        12\n",
      "          2       0.69      0.60      0.64        15\n",
      "          3       0.58      0.83      0.68        18\n",
      "\n",
      "avg / total       0.65      0.63      0.63        60\n",
      "\n",
      "[ 8  1  2  4  1  6  1  4  2  1  9  3  1  1  1 15]\n",
      "svc Accuracy:  0.6333333333333333\n",
      "svc F1:  0.6221741221741222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.40      0.50        15\n",
      "          1       0.57      0.33      0.42        12\n",
      "          2       0.59      0.67      0.62        15\n",
      "          3       0.63      0.94      0.76        18\n",
      "\n",
      "avg / total       0.62      0.62      0.59        60\n",
      "\n",
      "[ 6  2  3  4  1  4  3  4  2  1 10  2  0  0  1 17]\n",
      "LR Accuracy:  0.6166666666666667\n",
      "LR F1:  0.5754020467836257\n",
      "For name:  m_ruiz\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0003-4174-6688': 40, '0000-0002-2734-2196': 32, '0000-0002-1530-9508': 9, '0000-0002-1337-0110': 5, '0000-0001-8617-667X': 4, '0000-0001-7492-9873': 3, '0000-0003-4419-1649': 3, '0000-0002-2926-702X': 3, '0000-0003-1437-5578': 2, '0000-0002-4670-9037': 2, '0000-0002-4917-1252': 2, '0000-0002-1286-6624': 2, '0000-0002-6799-1537': 1, '0000-0002-1116-206X': 1, '0000-0003-0118-668X': 1, '0000-0002-8527-4734': 1})\n",
      "['0000-0003-4174-6688', '0000-0002-2734-2196']\n",
      "Total sample size after apply threshold:  72\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 16)\n",
      "2\n",
      "(72, 51)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82        40\n",
      "          1       0.78      0.78      0.78        32\n",
      "\n",
      "avg / total       0.81      0.81      0.81        72\n",
      "\n",
      "[33  7  7 25]\n",
      "MNB Accuracy:  0.8055555555555556\n",
      "MNB F1:  0.803125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        40\n",
      "          1       0.80      1.00      0.89        32\n",
      "\n",
      "avg / total       0.91      0.89      0.89        72\n",
      "\n",
      "[32  8  0 32]\n",
      "svc Accuracy:  0.8888888888888888\n",
      "svc F1:  0.888888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.82      0.80        40\n",
      "          1       0.77      0.72      0.74        32\n",
      "\n",
      "avg / total       0.78      0.78      0.78        72\n",
      "\n",
      "[33  7  9 23]\n",
      "LR Accuracy:  0.7777777777777778\n",
      "LR F1:  0.7734067663257277\n",
      "For name:  a_levy\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0003-4770-1886': 13, '0000-0002-6709-4190': 6, '0000-0002-5856-8294': 3, '0000-0002-1521-658X': 1})\n",
      "['0000-0003-4770-1886']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  j_murray\n",
      "total sample size before apply threshold:  213\n",
      "Counter({'0000-0002-2282-3839': 78, '0000-0002-8897-0161': 32, '0000-0002-8992-7317': 23, '0000-0002-6928-2347': 23, '0000-0001-9314-2283': 18, '0000-0001-8224-679X': 13, '0000-0003-1941-9090': 11, '0000-0002-8577-7964': 8, '0000-0003-2994-4155': 3, '0000-0002-8741-4964': 1, '0000-0003-4390-1039': 1, '0000-0001-9721-992X': 1, '0000-0003-3000-9199': 1})\n",
      "['0000-0002-2282-3839', '0000-0001-9314-2283', '0000-0002-8992-7317', '0000-0003-1941-9090', '0000-0002-8897-0161', '0000-0001-8224-679X', '0000-0002-6928-2347']\n",
      "Total sample size after apply threshold:  198\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(198, 114)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(198, 28)\n",
      "2\n",
      "(198, 142)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.92      0.60        78\n",
      "          1       0.44      0.22      0.30        18\n",
      "          2       0.71      0.22      0.33        23\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.45      0.28      0.35        32\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.37      0.45      0.36       198\n",
      "\n",
      "[72  2  0  0  4  0  0 10  4  1  0  3  0  0 14  1  5  0  3  0  0 10  0  0\n",
      "  0  1  0  0 22  1  0  0  9  0  0 13  0  0  0  0  0  0 21  1  1  0  0  0\n",
      "  0]\n",
      "MNB Accuracy:  0.45454545454545453\n",
      "MNB F1:  0.2251119251119251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.85      0.63        78\n",
      "          1       0.32      0.33      0.32        18\n",
      "          2       0.54      0.30      0.39        23\n",
      "          3       1.00      0.55      0.71        11\n",
      "          4       0.53      0.31      0.39        32\n",
      "          5       1.00      0.23      0.38        13\n",
      "          6       0.29      0.09      0.13        23\n",
      "\n",
      "avg / total       0.53      0.51      0.47       198\n",
      "\n",
      "[66  1  1  0  7  0  3  9  6  3  0  0  0  0 13  3  7  0  0  0  0  5  0  0\n",
      "  6  0  0  0 15  4  1  0 10  0  2  9  1  0  0  0  3  0 14  4  1  0  2  0\n",
      "  2]\n",
      "svc Accuracy:  0.5050505050505051\n",
      "svc F1:  0.42159495851446316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.92      0.62        78\n",
      "          1       0.40      0.33      0.36        18\n",
      "          2       0.75      0.26      0.39        23\n",
      "          3       1.00      0.18      0.31        11\n",
      "          4       0.61      0.34      0.44        32\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       0.50      0.04      0.08        23\n",
      "\n",
      "avg / total       0.52      0.49      0.42       198\n",
      "\n",
      "[72  2  0  0  3  0  1  9  6  1  0  2  0  0 13  4  6  0  0  0  0  8  0  0\n",
      "  2  1  0  0 21  0  0  0 11  0  0 13  0  0  0  0  0  0 17  3  1  0  1  0\n",
      "  1]\n",
      "LR Accuracy:  0.494949494949495\n",
      "LR F1:  0.31454315269983474\n",
      "For name:  y_hou\n",
      "total sample size before apply threshold:  162\n",
      "Counter({'0000-0001-6546-2597': 97, '0000-0002-3995-7219': 29, '0000-0002-0420-0726': 14, '0000-0002-8114-166X': 12, '0000-0002-7360-5751': 5, '0000-0002-4978-9829': 4, '0000-0003-3195-7430': 1})\n",
      "['0000-0002-3995-7219', '0000-0002-8114-166X', '0000-0001-6546-2597', '0000-0002-0420-0726']\n",
      "Total sample size after apply threshold:  152\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(152, 59)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(152, 24)\n",
      "2\n",
      "(152, 83)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.69      0.67        29\n",
      "          1       0.71      0.83      0.77        12\n",
      "          2       0.84      0.90      0.87        97\n",
      "          3       0.67      0.14      0.24        14\n",
      "\n",
      "avg / total       0.77      0.78      0.76       152\n",
      "\n",
      "[20  0  9  0  1 10  1  0  6  3 87  1  4  1  7  2]\n",
      "MNB Accuracy:  0.7828947368421053\n",
      "MNB F1:  0.6342157988338849\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.76      0.85        29\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       0.86      0.97      0.91        97\n",
      "          3       0.78      0.50      0.61        14\n",
      "\n",
      "avg / total       0.88      0.88      0.88       152\n",
      "\n",
      "[22  0  7  0  0 11  1  0  1  0 94  2  0  0  7  7]\n",
      "svc Accuracy:  0.881578947368421\n",
      "svc F1:  0.8309981491703737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.52      0.68        29\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       0.77      0.99      0.87        97\n",
      "          3       0.50      0.07      0.12        14\n",
      "\n",
      "avg / total       0.81      0.81      0.77       152\n",
      "\n",
      "[15  0 14  0  0 11  1  0  0  0 96  1  0  0 13  1]\n",
      "LR Accuracy:  0.8092105263157895\n",
      "LR F1:  0.6580295503729008\n",
      "For name:  m_sahin\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-7044-2953': 41, '0000-0002-3490-6009': 3, '0000-0001-6502-2209': 2, '0000-0001-7677-8423': 2})\n",
      "['0000-0001-7044-2953']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  c_feng\n",
      "total sample size before apply threshold:  88\n",
      "Counter({'0000-0002-1854-356X': 30, '0000-0002-2130-8851': 26, '0000-0003-3267-0968': 12, '0000-0002-7031-4211': 12, '0000-0002-3278-9451': 7, '0000-0003-1085-4395': 1})\n",
      "['0000-0002-1854-356X', '0000-0002-2130-8851', '0000-0003-3267-0968', '0000-0002-7031-4211']\n",
      "Total sample size after apply threshold:  80\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(80, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(80, 11)\n",
      "2\n",
      "(80, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.83      0.74        30\n",
      "          1       0.68      0.81      0.74        26\n",
      "          2       0.80      0.33      0.47        12\n",
      "          3       0.83      0.42      0.56        12\n",
      "\n",
      "avg / total       0.71      0.69      0.67        80\n",
      "\n",
      "[25  5  0  0  5 21  0  0  5  2  4  1  3  3  1  5]\n",
      "MNB Accuracy:  0.6875\n",
      "MNB F1:  0.6245700034399724\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.97      0.81        30\n",
      "          1       0.83      0.73      0.78        26\n",
      "          2       0.67      0.33      0.44        12\n",
      "          3       0.78      0.58      0.67        12\n",
      "\n",
      "avg / total       0.74      0.74      0.72        80\n",
      "\n",
      "[29  1  0  0  4 19  1  2  7  1  4  0  2  2  1  7]\n",
      "svc Accuracy:  0.7375\n",
      "svc F1:  0.6730442176870748\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.93      0.76        30\n",
      "          1       0.71      0.65      0.68        26\n",
      "          2       0.67      0.33      0.44        12\n",
      "          3       0.83      0.42      0.56        12\n",
      "\n",
      "avg / total       0.69      0.68      0.65        80\n",
      "\n",
      "[28  2  0  0  8 17  1  0  5  2  4  1  3  3  1  5]\n",
      "LR Accuracy:  0.675\n",
      "LR F1:  0.6091891891891892\n",
      "For name:  j_coutinho\n",
      "total sample size before apply threshold:  129\n",
      "Counter({'0000-0002-3841-743X': 105, '0000-0002-6303-9549': 13, '0000-0002-1562-0099': 8, '0000-0003-0280-366X': 3})\n",
      "['0000-0002-6303-9549', '0000-0002-3841-743X']\n",
      "Total sample size after apply threshold:  118\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(118, 51)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(118, 12)\n",
      "2\n",
      "(118, 63)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.15      0.24        13\n",
      "          1       0.90      0.98      0.94       105\n",
      "\n",
      "avg / total       0.86      0.89      0.86       118\n",
      "\n",
      "[  2  11   2 103]\n",
      "MNB Accuracy:  0.8898305084745762\n",
      "MNB F1:  0.5879666935267258\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.92      1.00      0.96       105\n",
      "\n",
      "avg / total       0.93      0.92      0.91       118\n",
      "\n",
      "[  4   9   0 105]\n",
      "svc Accuracy:  0.923728813559322\n",
      "svc F1:  0.7147461724415793\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       0.91      1.00      0.95       105\n",
      "\n",
      "avg / total       0.92      0.91      0.87       118\n",
      "\n",
      "[  2  11   0 105]\n",
      "LR Accuracy:  0.9067796610169492\n",
      "LR F1:  0.6084464555052791\n",
      "For name:  s_huber\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-4125-159X': 26, '0000-0003-3558-351X': 12, '0000-0002-8271-7835': 3, '0000-0002-5842-5859': 2, '0000-0001-6303-5188': 1})\n",
      "['0000-0003-3558-351X', '0000-0002-4125-159X']\n",
      "Total sample size after apply threshold:  38\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 9)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 11)\n",
      "2\n",
      "(38, 20)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        12\n",
      "          1       0.93      1.00      0.96        26\n",
      "\n",
      "avg / total       0.95      0.95      0.95        38\n",
      "\n",
      "[10  2  0 26]\n",
      "MNB Accuracy:  0.9473684210526315\n",
      "MNB F1:  0.936026936026936\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.96      1.00      0.98        26\n",
      "\n",
      "avg / total       0.97      0.97      0.97        38\n",
      "\n",
      "[11  1  0 26]\n",
      "svc Accuracy:  0.9736842105263158\n",
      "svc F1:  0.9688269073010665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       0.90      1.00      0.95        26\n",
      "\n",
      "avg / total       0.93      0.92      0.92        38\n",
      "\n",
      "[ 9  3  0 26]\n",
      "LR Accuracy:  0.9210526315789473\n",
      "LR F1:  0.9012987012987013\n",
      "For name:  a_rocha\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0003-3218-7001': 26, '0000-0001-9710-9835': 21, '0000-0003-2165-5519': 12, '0000-0002-4094-7982': 3, '0000-0002-5637-1041': 3, '0000-0001-6528-9034': 3, '0000-0003-4940-6522': 2, '0000-0003-0298-8246': 2, '0000-0001-8679-2886': 1})\n",
      "['0000-0001-9710-9835', '0000-0003-2165-5519', '0000-0003-3218-7001']\n",
      "Total sample size after apply threshold:  59\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 25)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 20)\n",
      "2\n",
      "(59, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.95      0.87        21\n",
      "          1       0.89      0.67      0.76        12\n",
      "          2       0.88      0.85      0.86        26\n",
      "\n",
      "avg / total       0.85      0.85      0.84        59\n",
      "\n",
      "[20  0  1  2  8  2  3  1 22]\n",
      "MNB Accuracy:  0.847457627118644\n",
      "MNB F1:  0.8314050257784272\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.98        21\n",
      "          1       0.90      0.75      0.82        12\n",
      "          2       0.86      0.96      0.91        26\n",
      "\n",
      "avg / total       0.92      0.92      0.91        59\n",
      "\n",
      "[20  0  1  0  9  3  0  1 25]\n",
      "svc Accuracy:  0.9152542372881356\n",
      "svc F1:  0.9009608277900961\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.90      0.93        21\n",
      "          1       1.00      0.58      0.74        12\n",
      "          2       0.78      0.96      0.86        26\n",
      "\n",
      "avg / total       0.89      0.86      0.86        59\n",
      "\n",
      "[19  0  2  0  7  5  1  0 25]\n",
      "LR Accuracy:  0.864406779661017\n",
      "LR F1:  0.8419134463576942\n",
      "For name:  a_white\n",
      "total sample size before apply threshold:  386\n",
      "Counter({'0000-0002-9668-4632': 108, '0000-0003-1802-9891': 87, '0000-0002-7686-2884': 85, '0000-0001-9639-5200': 41, '0000-0002-5442-6985': 16, '0000-0002-9859-0947': 13, '0000-0002-1539-0158': 9, '0000-0001-5530-742X': 9, '0000-0001-7499-7390': 4, '0000-0002-3904-2019': 4, '0000-0002-7771-3899': 3, '0000-0002-9708-2406': 2, '0000-0002-2783-895X': 2, '0000-0002-7268-5163': 1, '0000-0002-4837-7128': 1, '0000-0002-7106-6440': 1})\n",
      "['0000-0002-7686-2884', '0000-0002-5442-6985', '0000-0002-9668-4632', '0000-0002-9859-0947', '0000-0001-9639-5200', '0000-0003-1802-9891']\n",
      "Total sample size after apply threshold:  350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(350, 165)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(350, 31)\n",
      "2\n",
      "(350, 196)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.52      0.64        85\n",
      "          1       0.00      0.00      0.00        16\n",
      "          2       0.64      0.90      0.75       108\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.88      0.56      0.69        41\n",
      "          5       0.57      0.78      0.66        87\n",
      "\n",
      "avg / total       0.64      0.66      0.63       350\n",
      "\n",
      "[44  0 23  0  0 18  1  0  6  0  0  9  4  0 97  0  1  6  3  0  4  0  0  6\n",
      "  0  0  6  0 23 12  1  0 16  0  2 68]\n",
      "MNB Accuracy:  0.6628571428571428\n",
      "MNB F1:  0.4550993907517536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.78      0.77        85\n",
      "          1       1.00      0.38      0.55        16\n",
      "          2       0.84      0.75      0.79       108\n",
      "          3       0.67      0.15      0.25        13\n",
      "          4       0.94      0.80      0.87        41\n",
      "          5       0.62      0.87      0.72        87\n",
      "\n",
      "avg / total       0.78      0.75      0.75       350\n",
      "\n",
      "[66  0  6  0  0 13  2  6  0  0  0  8 13  0 81  1  0 13  2  0  3  2  0  6\n",
      "  1  0  0  0 33  7  3  0  6  0  2 76]\n",
      "svc Accuracy:  0.7542857142857143\n",
      "svc F1:  0.658207438236598\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.68      0.73        85\n",
      "          1       1.00      0.12      0.22        16\n",
      "          2       0.69      0.87      0.77       108\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.96      0.56      0.71        41\n",
      "          5       0.59      0.78      0.67        87\n",
      "\n",
      "avg / total       0.71      0.70      0.68       350\n",
      "\n",
      "[58  0 13  0  0 14  1  2  4  0  0  9  7  0 94  0  0  7  3  0  4  0  0  6\n",
      "  1  0  6  0 23 11  3  0 15  0  1 68]\n",
      "LR Accuracy:  0.7\n",
      "LR F1:  0.5179751458526275\n",
      "For name:  j_scott\n",
      "total sample size before apply threshold:  342\n",
      "Counter({'0000-0002-7203-8601': 155, '0000-0002-0744-0688': 60, '0000-0003-0765-9054': 44, '0000-0002-9116-948X': 36, '0000-0002-7513-6768': 21, '0000-0002-9916-6523': 8, '0000-0001-7782-3601': 7, '0000-0002-5073-0832': 6, '0000-0003-2368-8218': 1, '0000-0003-2971-7673': 1, '0000-0002-5616-2688': 1, '0000-0002-4900-0891': 1, '0000-0001-8408-5176': 1})\n",
      "['0000-0002-7203-8601', '0000-0003-0765-9054', '0000-0002-0744-0688', '0000-0002-9116-948X', '0000-0002-7513-6768']\n",
      "Total sample size after apply threshold:  316\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(316, 130)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(316, 29)\n",
      "2\n",
      "(316, 159)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.90      0.75       155\n",
      "          1       0.67      0.41      0.51        44\n",
      "          2       0.47      0.52      0.49        60\n",
      "          3       1.00      0.17      0.29        36\n",
      "          4       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.61      0.61      0.56       316\n",
      "\n",
      "[139   4  12   0   0  18  18   8   0   0  28   1  31   0   0  18   3   9\n",
      "   6   0  14   1   6   0   0]\n",
      "MNB Accuracy:  0.6139240506329114\n",
      "MNB F1:  0.40642637185117875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.96      0.77       155\n",
      "          1       0.97      0.70      0.82        44\n",
      "          2       0.81      0.48      0.60        60\n",
      "          3       0.92      0.31      0.46        36\n",
      "          4       1.00      0.19      0.32        21\n",
      "\n",
      "avg / total       0.77      0.71      0.68       316\n",
      "\n",
      "[149   0   5   1   0  12  31   1   0   0  30   1  29   0   0  24   0   1\n",
      "  11   0  17   0   0   0   4]\n",
      "svc Accuracy:  0.7088607594936709\n",
      "svc F1:  0.5936630626954985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.94      0.75       155\n",
      "          1       0.83      0.45      0.59        44\n",
      "          2       0.64      0.50      0.56        60\n",
      "          3       0.80      0.22      0.35        36\n",
      "          4       1.00      0.10      0.17        21\n",
      "\n",
      "avg / total       0.70      0.65      0.61       316\n",
      "\n",
      "[145   2   8   0   0  19  20   4   1   0  30   0  30   0   0  24   1   3\n",
      "   8   0  15   1   2   1   2]\n",
      "LR Accuracy:  0.6487341772151899\n",
      "LR F1:  0.4836289537032406\n",
      "For name:  s_hosseini\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0001-6222-792X': 8, '0000-0002-5881-6796': 8, '0000-0002-5468-1281': 6, '0000-0002-0211-6248': 1, '0000-0002-0907-9427': 1, '0000-0001-7521-7907': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_vieira\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0002-7366-6765': 60, '0000-0003-4232-9413': 5, '0000-0001-7388-6904': 2, '0000-0001-6288-2086': 1})\n",
      "['0000-0002-7366-6765']\n",
      "Total sample size after apply threshold:  60\n",
      "For name:  j_kang\n",
      "total sample size before apply threshold:  200\n",
      "Counter({'0000-0002-6350-3997': 57, '0000-0001-7311-6053': 42, '0000-0001-8995-5636': 25, '0000-0002-9181-6819': 15, '0000-0002-1412-6179': 11, '0000-0003-4788-0028': 11, '0000-0002-5262-2712': 9, '0000-0002-8467-2503': 8, '0000-0002-9425-847X': 6, '0000-0002-8660-7940': 4, '0000-0003-1610-6742': 3, '0000-0002-1841-5357': 3, '0000-0001-8894-2630': 3, '0000-0001-5013-2683': 1, '0000-0003-4200-1020': 1, '0000-0002-2603-9718': 1})\n",
      "['0000-0002-1412-6179', '0000-0002-6350-3997', '0000-0002-9181-6819', '0000-0001-7311-6053', '0000-0001-8995-5636', '0000-0003-4788-0028']\n",
      "Total sample size after apply threshold:  161\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(161, 90)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(161, 22)\n",
      "2\n",
      "(161, 112)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.73      0.84      0.78        57\n",
      "          2       0.67      0.27      0.38        15\n",
      "          3       0.55      0.86      0.67        42\n",
      "          4       0.74      0.68      0.71        25\n",
      "          5       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.58      0.65      0.60       161\n",
      "\n",
      "[ 0  4  0  7  0  0  0 48  2  5  2  0  0  7  4  4  0  0  0  2  0 36  4  0\n",
      "  0  2  0  6 17  0  0  3  0  8  0  0]\n",
      "MNB Accuracy:  0.6521739130434783\n",
      "MNB F1:  0.42274003097173823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.45      0.56        11\n",
      "          1       0.77      0.89      0.83        57\n",
      "          2       0.60      0.40      0.48        15\n",
      "          3       0.70      0.90      0.79        42\n",
      "          4       1.00      0.72      0.84        25\n",
      "          5       0.83      0.45      0.59        11\n",
      "\n",
      "avg / total       0.77      0.76      0.75       161\n",
      "\n",
      "[ 5  2  1  2  0  1  0 51  3  3  0  0  0  5  6  4  0  0  0  4  0 38  0  0\n",
      "  0  3  0  4 18  0  2  1  0  3  0  5]\n",
      "svc Accuracy:  0.7639751552795031\n",
      "svc F1:  0.6803225185580629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.71      0.95      0.81        57\n",
      "          2       0.80      0.27      0.40        15\n",
      "          3       0.61      0.86      0.71        42\n",
      "          4       1.00      0.68      0.81        25\n",
      "          5       1.00      0.36      0.53        11\n",
      "\n",
      "avg / total       0.71      0.71      0.67       161\n",
      "\n",
      "[ 0  5  0  6  0  0  0 54  1  2  0  0  0  7  4  4  0  0  0  6  0 36  0  0\n",
      "  0  3  0  5 17  0  0  1  0  6  0  4]\n",
      "LR Accuracy:  0.7142857142857143\n",
      "LR F1:  0.5446264175289709\n",
      "For name:  j_jensen\n",
      "total sample size before apply threshold:  388\n",
      "Counter({'0000-0002-4733-1224': 124, '0000-0002-7464-7435': 99, '0000-0003-0657-4032': 43, '0000-0001-6841-1808': 30, '0000-0002-1465-1010': 21, '0000-0003-3291-8468': 18, '0000-0002-2369-8291': 17, '0000-0003-4036-0521': 17, '0000-0001-6228-2988': 12, '0000-0002-7954-8073': 3, '0000-0001-9962-6166': 3, '0000-0003-1873-4531': 1})\n",
      "['0000-0003-0657-4032', '0000-0002-1465-1010', '0000-0002-2369-8291', '0000-0001-6841-1808', '0000-0001-6228-2988', '0000-0002-4733-1224', '0000-0003-4036-0521', '0000-0003-3291-8468', '0000-0002-7464-7435']\n",
      "Total sample size after apply threshold:  381\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(381, 158)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(381, 26)\n",
      "2\n",
      "(381, 184)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.33      0.46        43\n",
      "          1       1.00      0.38      0.55        21\n",
      "          2       1.00      0.18      0.30        17\n",
      "          3       1.00      0.03      0.06        30\n",
      "          4       0.00      0.00      0.00        12\n",
      "          5       0.59      0.98      0.74       124\n",
      "          6       0.00      0.00      0.00        17\n",
      "          7       1.00      0.06      0.11        18\n",
      "          8       0.55      0.81      0.65        99\n",
      "\n",
      "avg / total       0.65      0.60      0.52       381\n",
      "\n",
      "[ 14   0   0   0   0  16   0   0  13   0   8   0   0   0   5   0   0   8\n",
      "   0   0   3   0   0   6   0   0   8   1   0   0   1   0  16   0   0  12\n",
      "   0   0   0   0   0   8   0   0   4   0   0   0   0   0 121   0   0   3\n",
      "   0   0   0   0   0   7   0   0  10   0   0   0   0   0   9   0   1   8\n",
      "   3   0   0   0   0  16   0   0  80]\n",
      "MNB Accuracy:  0.5984251968503937\n",
      "MNB F1:  0.31904288009324766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.49      0.60        43\n",
      "          1       0.56      0.48      0.51        21\n",
      "          2       1.00      0.65      0.79        17\n",
      "          3       0.92      0.37      0.52        30\n",
      "          4       1.00      0.33      0.50        12\n",
      "          5       0.94      0.85      0.89       124\n",
      "          6       0.71      0.29      0.42        17\n",
      "          7       1.00      0.78      0.88        18\n",
      "          8       0.49      0.88      0.63        99\n",
      "\n",
      "avg / total       0.78      0.70      0.70       381\n",
      "\n",
      "[ 21   0   0   1   0   0   0   0  21   0  10   0   0   0   0   0   0  11\n",
      "   0   0  11   0   0   0   0   0   6   2   2   0  11   0   1   0   0  14\n",
      "   0   1   0   0   4   0   0   0   7   1   0   0   0   0 105   0   0  18\n",
      "   0   1   0   0   0   1   5   0  10   1   0   0   0   0   1   0  14   2\n",
      "   2   4   0   0   0   4   2   0  87]\n",
      "svc Accuracy:  0.7034120734908137\n",
      "svc F1:  0.6373965300236487\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.47      0.58        43\n",
      "          1       0.60      0.43      0.50        21\n",
      "          2       1.00      0.29      0.45        17\n",
      "          3       1.00      0.27      0.42        30\n",
      "          4       1.00      0.08      0.15        12\n",
      "          5       0.78      0.90      0.83       124\n",
      "          6       1.00      0.29      0.45        17\n",
      "          7       1.00      0.28      0.43        18\n",
      "          8       0.49      0.87      0.63        99\n",
      "\n",
      "avg / total       0.75      0.66      0.63       381\n",
      "\n",
      "[ 20   0   0   0   0   5   0   0  18   0   9   0   0   0   2   0   0  10\n",
      "   1   0   5   0   0   2   0   0   9   1   2   0   8   0   4   0   0  15\n",
      "   0   0   0   0   1   3   0   0   8   0   1   0   0   0 111   0   0  12\n",
      "   0   1   0   0   0   2   5   0   9   1   0   0   0   0   5   0   5   7\n",
      "   3   2   0   0   0   8   0   0  86]\n",
      "LR Accuracy:  0.6561679790026247\n",
      "LR F1:  0.49590061603791585\n",
      "For name:  k_lai\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-8135-6030': 36, '0000-0001-9296-0882': 5, '0000-0002-0037-792X': 4, '0000-0002-3365-3927': 2, '0000-0002-4069-054X': 2, '0000-0001-8203-4252': 1, '0000-0001-7734-0941': 1, '0000-0003-1478-4996': 1})\n",
      "['0000-0001-8135-6030']\n",
      "Total sample size after apply threshold:  36\n",
      "For name:  j_gonzalez\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0001-5569-0705': 13, '0000-0003-3063-1770': 10, '0000-0002-3448-7393': 6, '0000-0002-9926-3323': 4, '0000-0002-0381-6393': 3, '0000-0002-0389-5263': 2, '0000-0003-3415-5943': 1})\n",
      "['0000-0003-3063-1770', '0000-0001-5569-0705']\n",
      "Total sample size after apply threshold:  23\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 16)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 17)\n",
      "2\n",
      "(23, 33)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.65      1.00      0.79        13\n",
      "\n",
      "avg / total       0.80      0.70      0.65        23\n",
      "\n",
      "[ 3  7  0 13]\n",
      "MNB Accuracy:  0.6956521739130435\n",
      "MNB F1:  0.6247086247086248\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.30      0.33        10\n",
      "          1       0.53      0.62      0.57        13\n",
      "\n",
      "avg / total       0.46      0.48      0.47        23\n",
      "\n",
      "[3 7 5 8]\n",
      "svc Accuracy:  0.4782608695652174\n",
      "svc F1:  0.4523809523809524\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.30      0.33        10\n",
      "          1       0.53      0.62      0.57        13\n",
      "\n",
      "avg / total       0.46      0.48      0.47        23\n",
      "\n",
      "[3 7 5 8]\n",
      "LR Accuracy:  0.4782608695652174\n",
      "LR F1:  0.4523809523809524\n",
      "For name:  m_zakaria\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-3694-3460': 10, '0000-0003-2525-0092': 8, '0000-0002-2698-615X': 5, '0000-0003-2456-6415': 1})\n",
      "['0000-0002-3694-3460']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  c_campos\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0003-1734-6924': 31, '0000-0002-7616-8518': 10, '0000-0003-1809-8272': 3, '0000-0002-2070-8618': 1, '0000-0002-4978-5449': 1, '0000-0001-6054-4243': 1, '0000-0001-8592-5384': 1})\n",
      "['0000-0002-7616-8518', '0000-0003-1734-6924']\n",
      "Total sample size after apply threshold:  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 27)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 7)\n",
      "2\n",
      "(41, 34)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.40      0.50        10\n",
      "          1       0.83      0.94      0.88        31\n",
      "\n",
      "avg / total       0.79      0.80      0.79        41\n",
      "\n",
      "[ 4  6  2 29]\n",
      "MNB Accuracy:  0.8048780487804879\n",
      "MNB F1:  0.6893939393939394\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.40      0.47        10\n",
      "          1       0.82      0.90      0.86        31\n",
      "\n",
      "avg / total       0.76      0.78      0.77        41\n",
      "\n",
      "[ 4  6  3 28]\n",
      "svc Accuracy:  0.7804878048780488\n",
      "svc F1:  0.6660633484162897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      0.10      0.14        10\n",
      "          1       0.76      0.90      0.82        31\n",
      "\n",
      "avg / total       0.63      0.71      0.66        41\n",
      "\n",
      "[ 1  9  3 28]\n",
      "LR Accuracy:  0.7073170731707317\n",
      "LR F1:  0.48319327731092443\n",
      "For name:  a_gad\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-1098-9129': 17, '0000-0001-9741-2105': 10, '0000-0002-5298-5206': 1, '0000-0002-0762-0953': 1})\n",
      "['0000-0001-9741-2105', '0000-0002-1098-9129']\n",
      "Total sample size after apply threshold:  27\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 10)\n",
      "2\n",
      "(27, 33)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70        10\n",
      "          1       0.82      0.82      0.82        17\n",
      "\n",
      "avg / total       0.78      0.78      0.78        27\n",
      "\n",
      "[ 7  3  3 14]\n",
      "MNB Accuracy:  0.7777777777777778\n",
      "MNB F1:  0.7617647058823529\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.80      0.76        10\n",
      "          1       0.88      0.82      0.85        17\n",
      "\n",
      "avg / total       0.82      0.81      0.82        27\n",
      "\n",
      "[ 8  2  3 14]\n",
      "svc Accuracy:  0.8148148148148148\n",
      "svc F1:  0.8051948051948052\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.30      0.37        10\n",
      "          1       0.67      0.82      0.74        17\n",
      "\n",
      "avg / total       0.60      0.63      0.60        27\n",
      "\n",
      "[ 3  7  3 14]\n",
      "LR Accuracy:  0.6296296296296297\n",
      "LR F1:  0.5559210526315789\n",
      "For name:  y_zhao\n",
      "total sample size before apply threshold:  338\n",
      "Counter({'0000-0003-1215-2565': 48, '0000-0002-7916-8687': 47, '0000-0001-6783-5182': 20, '0000-0002-9408-9979': 20, '0000-0002-6541-0612': 18, '0000-0002-5455-2586': 17, '0000-0002-2903-4218': 16, '0000-0003-0302-3470': 16, '0000-0002-6184-2530': 15, '0000-0003-1035-2272': 15, '0000-0002-6923-1099': 13, '0000-0002-1442-992X': 12, '0000-0001-6747-1665': 12, '0000-0003-3618-1379': 11, '0000-0002-9231-8360': 11, '0000-0003-1384-6024': 9, '0000-0002-0278-7543': 7, '0000-0001-8541-893X': 5, '0000-0001-8986-9164': 4, '0000-0002-2944-1315': 4, '0000-0001-8970-9398': 3, '0000-0001-8925-9462': 2, '0000-0003-1254-6732': 2, '0000-0002-5866-5932': 2, '0000-0001-8808-9481': 2, '0000-0003-1815-1408': 1, '0000-0002-4148-2603': 1, '0000-0003-1490-0416': 1, '0000-0002-7761-0072': 1, '0000-0002-6806-1593': 1, '0000-0003-4188-5725': 1, '0000-0003-2289-5709': 1})\n",
      "['0000-0002-1442-992X', '0000-0002-6541-0612', '0000-0003-3618-1379', '0000-0001-6783-5182', '0000-0002-6184-2530', '0000-0001-6747-1665', '0000-0002-2903-4218', '0000-0002-5455-2586', '0000-0002-9231-8360', '0000-0002-6923-1099', '0000-0003-1035-2272', '0000-0003-1215-2565', '0000-0002-7916-8687', '0000-0003-0302-3470', '0000-0002-9408-9979']\n",
      "Total sample size after apply threshold:  291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(291, 100)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(291, 18)\n",
      "2\n",
      "(291, 118)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.60      0.17      0.26        18\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.46      0.60      0.52        20\n",
      "          4       0.31      0.33      0.32        15\n",
      "          5       1.00      0.17      0.29        12\n",
      "          6       0.00      0.00      0.00        16\n",
      "          7       0.00      0.00      0.00        17\n",
      "          8       0.00      0.00      0.00        11\n",
      "          9       0.00      0.00      0.00        13\n",
      "         10       0.14      0.07      0.09        15\n",
      "         11       0.33      0.88      0.47        48\n",
      "         12       0.43      0.81      0.56        47\n",
      "         13       0.33      0.06      0.11        16\n",
      "         14       1.00      0.30      0.46        20\n",
      "\n",
      "avg / total       0.34      0.38      0.29       291\n",
      "\n",
      "[ 0  0  0  2  0  0  0  0  0  0  0  6  4  0  0  0  3  0  1  2  0  0  0  0\n",
      "  0  1  6  5  0  0  0  1  0  0  0  0  0  0  0  0  0  7  3  0  0  0  0  0\n",
      " 12  0  0  0  1  0  0  0  2  4  1  0  0  0  0  2  5  0  1  0  0  0  0  3\n",
      "  4  0  0  0  0  0  0  2  2  0  0  0  0  0  5  3  0  0  0  0  0  2  1  0\n",
      "  0  0  0  0  0 13  0  0  0  0  0  0  3  2  0  0  0  0  0  0  5  6  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  3  7  1  0  0  0  0  0  1  1  0  0  0  0\n",
      "  0  0  2  9  0  0  0  0  0  0  1  0  0  0  1  0  1 10  2  0  0  0  0  0\n",
      "  0  2  0  0  0  0  0  0 42  4  0  0  1  1  0  0  0  0  0  0  0  1  0  6\n",
      " 38  0  0  0  0  0  2  0  0  0  2  0  0  0  6  5  1  0  0  0  0  1  0  0\n",
      "  0  1  0  0  2  9  1  0  6]\n",
      "MNB Accuracy:  0.37800687285223367\n",
      "MNB F1:  0.20546760916454962\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.25      0.22        12\n",
      "          1       0.55      0.33      0.41        18\n",
      "          2       0.36      0.36      0.36        11\n",
      "          3       0.83      0.75      0.79        20\n",
      "          4       0.55      0.40      0.46        15\n",
      "          5       0.38      0.25      0.30        12\n",
      "          6       0.42      0.31      0.36        16\n",
      "          7       0.42      0.29      0.34        17\n",
      "          8       0.14      0.27      0.19        11\n",
      "          9       0.17      0.08      0.11        13\n",
      "         10       0.45      0.33      0.38        15\n",
      "         11       0.62      0.75      0.68        48\n",
      "         12       0.48      0.68      0.57        47\n",
      "         13       0.36      0.31      0.33        16\n",
      "         14       0.35      0.30      0.32        20\n",
      "\n",
      "avg / total       0.46      0.46      0.45       291\n",
      "\n",
      "[ 3  0  0  0  2  0  1  0  2  0  0  0  3  1  0  0  6  0  1  0  1  0  0  1\n",
      "  0  1  1  5  0  2  0  0  4  0  0  3  0  0  2  0  0  0  2  0  0  0  1  0\n",
      " 15  0  0  0  1  0  0  0  0  2  1  0  1  0  0  1  6  0  1  0  0  0  0  2\n",
      "  3  0  1  0  0  4  0  0  3  0  0  1  0  0  0  2  0  2  0  0  0  0  1  0\n",
      "  5  0  0  0  1  8  0  1  0  1  0  0  1  0  0  0  5  1  0  0  0  1  5  3\n",
      "  2  0  0  0  0  0  0  0  3  0  3  3  0  0  0  2  0  1  0  0  0  0  1  1\n",
      "  1  0  0  7  0  0  0  1  0  0  0  0  2  0  2  0  5  3  1  0  1  1  0  0\n",
      "  0  2  0  2  0  3  0  1 36  3  0  0  1  2  0  0  0  0  1  0  2  5  0  4\n",
      " 32  0  0  3  0  0  0  0  1  0  3  0  0  0  1  1  5  2  1  1  2  0  0  0\n",
      "  0  2  3  0  0  0  4  1  6]\n",
      "svc Accuracy:  0.4639175257731959\n",
      "svc F1:  0.38888582953387857\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.50      0.28      0.36        18\n",
      "          2       0.50      0.18      0.27        11\n",
      "          3       0.64      0.80      0.71        20\n",
      "          4       0.39      0.47      0.42        15\n",
      "          5       1.00      0.25      0.40        12\n",
      "          6       0.25      0.12      0.17        16\n",
      "          7       0.14      0.06      0.08        17\n",
      "          8       0.00      0.00      0.00        11\n",
      "          9       0.00      0.00      0.00        13\n",
      "         10       0.42      0.33      0.37        15\n",
      "         11       0.44      0.81      0.57        48\n",
      "         12       0.47      0.79      0.59        47\n",
      "         13       0.23      0.19      0.21        16\n",
      "         14       0.70      0.35      0.47        20\n",
      "\n",
      "avg / total       0.41      0.44      0.39       291\n",
      "\n",
      "[ 0  0  0  1  2  0  1  0  1  0  0  3  3  1  0  0  5  0  1  2  0  0  0  1\n",
      "  0  1  3  4  1  0  0  2  2  0  0  0  0  0  1  0  0  4  2  0  0  0  0  0\n",
      " 16  0  0  0  1  0  0  0  0  2  1  0  0  0  0  1  7  0  1  0  0  0  0  2\n",
      "  4  0  0  0  0  1  0  1  3  0  0  1  0  0  3  2  0  1  0  0  0  1  1  0\n",
      "  2  0  0  0  1 10  0  1  0  0  0  0  1  2  0  0  1  1  0  0  1  3  6  2\n",
      "  2  1  0  0  0  0  0  0  0  0  3  4  1  0  0  1  0  0  0  1  0  0  0  1\n",
      "  0  0  1  9  0  0  0  1  0  0  0  0  2  0  1  0  5  6  0  0  0  1  0  0\n",
      "  0  2  0  2  0  0  0  0 39  4  0  0  1  1  0  0  0  0  0  0  0  3  0  5\n",
      " 37  0  0  0  0  0  3  0  0  0  3  0  0  0  4  3  3  0  0  0  1  1  0  0\n",
      "  0  2  0  0  2  3  4  0  7]\n",
      "LR Accuracy:  0.436426116838488\n",
      "LR F1:  0.3079084039792627\n",
      "For name:  s_hussain\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-7894-2485': 18, '0000-0002-3298-6260': 11, '0000-0002-9765-0565': 9, '0000-0001-8564-9113': 5, '0000-0001-6835-7207': 2, '0000-0001-6687-7591': 2, '0000-0001-8537-7322': 1, '0000-0002-0529-7451': 1, '0000-0002-7164-3076': 1, '0000-0003-1342-143X': 1, '0000-0001-8475-9791': 1})\n",
      "['0000-0002-3298-6260', '0000-0001-7894-2485']\n",
      "Total sample size after apply threshold:  29\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 16)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 10)\n",
      "2\n",
      "(29, 26)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        11\n",
      "          1       0.94      0.94      0.94        18\n",
      "\n",
      "avg / total       0.93      0.93      0.93        29\n",
      "\n",
      "[10  1  1 17]\n",
      "MNB Accuracy:  0.9310344827586207\n",
      "MNB F1:  0.9267676767676767\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        11\n",
      "          1       0.94      0.94      0.94        18\n",
      "\n",
      "avg / total       0.93      0.93      0.93        29\n",
      "\n",
      "[10  1  1 17]\n",
      "svc Accuracy:  0.9310344827586207\n",
      "svc F1:  0.9267676767676767\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.82      0.86        11\n",
      "          1       0.89      0.94      0.92        18\n",
      "\n",
      "avg / total       0.90      0.90      0.90        29\n",
      "\n",
      "[ 9  2  1 17]\n",
      "LR Accuracy:  0.896551724137931\n",
      "LR F1:  0.888030888030888\n",
      "For name:  k_scott\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-7263-6778': 11, '0000-0001-7952-0348': 3, '0000-0002-7066-887X': 1, '0000-0003-0345-5417': 1})\n",
      "['0000-0001-7263-6778']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  a_martinez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  180\n",
      "Counter({'0000-0003-1643-6506': 64, '0000-0002-2707-8110': 56, '0000-0002-4804-6687': 20, '0000-0003-4882-4044': 17, '0000-0003-0710-2336': 10, '0000-0002-4395-0511': 7, '0000-0001-5448-0140': 4, '0000-0001-9076-6197': 2})\n",
      "['0000-0003-0710-2336', '0000-0003-4882-4044', '0000-0003-1643-6506', '0000-0002-2707-8110', '0000-0002-4804-6687']\n",
      "Total sample size after apply threshold:  167\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(167, 88)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(167, 22)\n",
      "2\n",
      "(167, 110)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.57      0.24      0.33        17\n",
      "          2       0.54      0.83      0.65        64\n",
      "          3       0.60      0.57      0.59        56\n",
      "          4       0.75      0.15      0.25        20\n",
      "\n",
      "avg / total       0.62      0.58      0.55       167\n",
      "\n",
      "[ 5  0  3  2  0  0  4  9  4  0  0  1 53 10  0  0  1 22 32  1  0  1 11  5\n",
      "  3]\n",
      "MNB Accuracy:  0.5808383233532934\n",
      "MNB F1:  0.4982953901914146\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.71      0.29      0.42        17\n",
      "          2       0.63      0.86      0.73        64\n",
      "          3       0.73      0.68      0.70        56\n",
      "          4       1.00      0.65      0.79        20\n",
      "\n",
      "avg / total       0.74      0.71      0.71       167\n",
      "\n",
      "[ 8  0  0  2  0  0  5 11  1  0  0  0 55  9  0  0  1 17 38  0  0  1  4  2\n",
      " 13]\n",
      "svc Accuracy:  0.7125748502994012\n",
      "svc F1:  0.7051229736660201\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.57      0.24      0.33        17\n",
      "          2       0.57      0.80      0.66        64\n",
      "          3       0.64      0.66      0.65        56\n",
      "          4       1.00      0.20      0.33        20\n",
      "\n",
      "avg / total       0.67      0.62      0.60       167\n",
      "\n",
      "[ 8  0  0  2  0  0  4 10  3  0  0  1 51 12  0  0  1 18 37  0  0  1 11  4\n",
      "  4]\n",
      "LR Accuracy:  0.6227544910179641\n",
      "LR F1:  0.5734032049821525\n",
      "For name:  r_luz\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-3999-4298': 9, '0000-0002-1021-5772': 6, '0000-0003-0045-6959': 3, '0000-0003-3051-5710': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  p_tran\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0003-3283-1450': 6, '0000-0003-2405-2086': 5, '0000-0003-1735-6903': 2, '0000-0002-7319-872X': 2, '0000-0003-3438-5829': 1, '0000-0001-9788-3433': 1, '0000-0003-4619-4376': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  e_romero\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0001-9087-2790': 20, '0000-0003-1430-8412': 1, '0000-0003-1858-1264': 1, '0000-0003-3115-7572': 1})\n",
      "['0000-0001-9087-2790']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  j_stevens\n",
      "total sample size before apply threshold:  161\n",
      "Counter({'0000-0002-6348-9347': 75, '0000-0002-9867-7209': 41, '0000-0002-1013-8447': 13, '0000-0003-2375-1360': 11, '0000-0003-1601-9008': 9, '0000-0003-4674-0314': 4, '0000-0003-0182-3829': 4, '0000-0002-4661-3481': 3, '0000-0002-2234-1960': 1})\n",
      "['0000-0003-2375-1360', '0000-0002-1013-8447', '0000-0002-9867-7209', '0000-0002-6348-9347']\n",
      "Total sample size after apply threshold:  140\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 74)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 18)\n",
      "2\n",
      "(140, 92)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.08      0.14        13\n",
      "          2       0.72      0.68      0.70        41\n",
      "          3       0.68      0.91      0.78        75\n",
      "\n",
      "avg / total       0.67      0.69      0.63       140\n",
      "\n",
      "[ 0  0  2  9  0  1  2 10  0  0 28 13  0  0  7 68]\n",
      "MNB Accuracy:  0.6928571428571428\n",
      "MNB F1:  0.405\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       1.00      0.69      0.82        13\n",
      "          2       0.96      0.66      0.78        41\n",
      "          3       0.74      1.00      0.85        75\n",
      "\n",
      "avg / total       0.85      0.81      0.79       140\n",
      "\n",
      "[ 2  0  1  8  0  9  0  4  0  0 27 14  0  0  0 75]\n",
      "svc Accuracy:  0.8071428571428572\n",
      "svc F1:  0.6901888871997568\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.08      0.14        13\n",
      "          2       0.85      0.56      0.68        41\n",
      "          3       0.65      0.97      0.78        75\n",
      "\n",
      "avg / total       0.69      0.69      0.63       140\n",
      "\n",
      "[ 0  0  2  9  0  1  0 12  0  0 23 18  0  0  2 73]\n",
      "LR Accuracy:  0.6928571428571428\n",
      "LR F1:  0.40001909854851037\n",
      "For name:  l_you\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0001-7304-0474': 12, '0000-0003-3058-2884': 12, '0000-0003-1162-0064': 7, '0000-0002-4741-0715': 1})\n",
      "['0000-0001-7304-0474', '0000-0003-3058-2884']\n",
      "Total sample size after apply threshold:  24\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 7)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 6)\n",
      "2\n",
      "(24, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.67      0.67        12\n",
      "          1       0.67      0.67      0.67        12\n",
      "\n",
      "avg / total       0.67      0.67      0.67        24\n",
      "\n",
      "[8 4 4 8]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.6666666666666666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.58      0.61        12\n",
      "          1       0.62      0.67      0.64        12\n",
      "\n",
      "avg / total       0.63      0.62      0.62        24\n",
      "\n",
      "[7 5 4 8]\n",
      "svc Accuracy:  0.625\n",
      "svc F1:  0.6243478260869566\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.67      0.67        12\n",
      "          1       0.67      0.67      0.67        12\n",
      "\n",
      "avg / total       0.67      0.67      0.67        24\n",
      "\n",
      "[8 4 4 8]\n",
      "LR Accuracy:  0.6666666666666666\n",
      "LR F1:  0.6666666666666666\n",
      "For name:  p_stevenson\n",
      "total sample size before apply threshold:  122\n",
      "Counter({'0000-0002-3520-5060': 86, '0000-0001-6780-6859': 33, '0000-0002-3232-5155': 2, '0000-0002-6616-0328': 1})\n",
      "['0000-0002-3520-5060', '0000-0001-6780-6859']\n",
      "Total sample size after apply threshold:  119\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(119, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(119, 19)\n",
      "2\n",
      "(119, 49)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        86\n",
      "          1       0.92      1.00      0.96        33\n",
      "\n",
      "avg / total       0.98      0.97      0.98       119\n",
      "\n",
      "[83  3  0 33]\n",
      "MNB Accuracy:  0.9747899159663865\n",
      "MNB F1:  0.9693851299202471\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        86\n",
      "          1       1.00      0.85      0.92        33\n",
      "\n",
      "avg / total       0.96      0.96      0.96       119\n",
      "\n",
      "[86  0  5 28]\n",
      "svc Accuracy:  0.957983193277311\n",
      "svc F1:  0.9448920996573122\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        86\n",
      "          1       1.00      0.82      0.90        33\n",
      "\n",
      "avg / total       0.95      0.95      0.95       119\n",
      "\n",
      "[86  0  6 27]\n",
      "LR Accuracy:  0.9495798319327731\n",
      "LR F1:  0.9331460674157304\n",
      "For name:  t_kang\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0001-5939-6247': 16, '0000-0002-4589-9772': 8, '0000-0002-8444-9889': 1, '0000-0001-6570-2570': 1})\n",
      "['0000-0001-5939-6247']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  s_mohanty\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0001-6601-944X': 43, '0000-0001-9822-427X': 12, '0000-0002-2142-5572': 9, '0000-0003-4464-8434': 2, '0000-0002-1378-3775': 1})\n",
      "['0000-0001-9822-427X', '0000-0001-6601-944X']\n",
      "Total sample size after apply threshold:  55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 14)\n",
      "2\n",
      "(55, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.58      0.61        12\n",
      "          1       0.89      0.91      0.90        43\n",
      "\n",
      "avg / total       0.83      0.84      0.83        55\n",
      "\n",
      "[ 7  5  4 39]\n",
      "MNB Accuracy:  0.8363636363636363\n",
      "MNB F1:  0.7526236881559221\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.67      0.73        12\n",
      "          1       0.91      0.95      0.93        43\n",
      "\n",
      "avg / total       0.89      0.89      0.89        55\n",
      "\n",
      "[ 8  4  2 41]\n",
      "svc Accuracy:  0.8909090909090909\n",
      "svc F1:  0.8295454545454546\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        12\n",
      "          1       0.83      1.00      0.91        43\n",
      "\n",
      "avg / total       0.86      0.84      0.80        55\n",
      "\n",
      "[ 3  9  0 43]\n",
      "LR Accuracy:  0.8363636363636363\n",
      "LR F1:  0.6526315789473685\n",
      "For name:  m_amorim\n",
      "total sample size before apply threshold:  95\n",
      "Counter({'0000-0001-8137-3295': 55, '0000-0002-4159-4023': 20, '0000-0002-4129-6659': 13, '0000-0002-3831-9602': 4, '0000-0002-6872-6671': 1, '0000-0002-0901-0614': 1, '0000-0003-1516-8407': 1})\n",
      "['0000-0002-4159-4023', '0000-0002-4129-6659', '0000-0001-8137-3295']\n",
      "Total sample size after apply threshold:  88\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 46)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 17)\n",
      "2\n",
      "(88, 63)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.35      0.48        20\n",
      "          1       1.00      0.31      0.47        13\n",
      "          2       0.73      1.00      0.85        55\n",
      "\n",
      "avg / total       0.78      0.75      0.71        88\n",
      "\n",
      "[ 7  0 13  2  4  7  0  0 55]\n",
      "MNB Accuracy:  0.75\n",
      "MNB F1:  0.5998335673792062\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.45      0.60        20\n",
      "          1       1.00      0.54      0.70        13\n",
      "          2       0.76      0.98      0.86        55\n",
      "\n",
      "avg / total       0.83      0.80      0.78        88\n",
      "\n",
      "[ 9  0 11  0  7  6  1  0 54]\n",
      "svc Accuracy:  0.7954545454545454\n",
      "svc F1:  0.719047619047619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.30      0.44        20\n",
      "          1       1.00      0.08      0.14        13\n",
      "          2       0.69      1.00      0.81        55\n",
      "\n",
      "avg / total       0.77      0.70      0.63        88\n",
      "\n",
      "[ 6  0 14  1  1 11  0  0 55]\n",
      "LR Accuracy:  0.7045454545454546\n",
      "LR F1:  0.4673721340388007\n",
      "For name:  y_kamiya\n",
      "total sample size before apply threshold:  161\n",
      "Counter({'0000-0003-4415-520X': 113, '0000-0001-9790-9867': 42, '0000-0001-8716-2536': 5, '0000-0002-0758-0234': 1})\n",
      "['0000-0003-4415-520X', '0000-0001-9790-9867']\n",
      "Total sample size after apply threshold:  155\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(155, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(155, 19)\n",
      "2\n",
      "(155, 67)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.96      0.89       113\n",
      "          1       0.79      0.45      0.58        42\n",
      "\n",
      "avg / total       0.82      0.82      0.80       155\n",
      "\n",
      "[108   5  23  19]\n",
      "MNB Accuracy:  0.8193548387096774\n",
      "MNB F1:  0.73050173869846\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.91       113\n",
      "          1       0.96      0.52      0.68        42\n",
      "\n",
      "avg / total       0.88      0.86      0.85       155\n",
      "\n",
      "[112   1  20  22]\n",
      "svc Accuracy:  0.864516129032258\n",
      "svc F1:  0.7956043956043957\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.99      0.88       113\n",
      "          1       0.92      0.29      0.44        42\n",
      "\n",
      "avg / total       0.83      0.80      0.76       155\n",
      "\n",
      "[112   1  30  12]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.6573975044563279\n",
      "For name:  w_he\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0003-3254-1242': 20, '0000-0003-3137-8420': 16, '0000-0003-0161-3274': 7, '0000-0003-1236-3047': 5})\n",
      "['0000-0003-3254-1242', '0000-0003-3137-8420']\n",
      "Total sample size after apply threshold:  36\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 9)\n",
      "2\n",
      "(36, 31)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.85      0.79        20\n",
      "          1       0.77      0.62      0.69        16\n",
      "\n",
      "avg / total       0.75      0.75      0.75        36\n",
      "\n",
      "[17  3  6 10]\n",
      "MNB Accuracy:  0.75\n",
      "MNB F1:  0.7401764234161989\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        20\n",
      "          1       1.00      0.56      0.72        16\n",
      "\n",
      "avg / total       0.86      0.81      0.79        36\n",
      "\n",
      "[20  0  7  9]\n",
      "svc Accuracy:  0.8055555555555556\n",
      "svc F1:  0.7855319148936171\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.95      0.81        20\n",
      "          1       0.89      0.50      0.64        16\n",
      "\n",
      "avg / total       0.79      0.75      0.73        36\n",
      "\n",
      "[19  1  8  8]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.7242553191489363\n",
      "For name:  t_kato\n",
      "total sample size before apply threshold:  249\n",
      "Counter({'0000-0001-7856-3952': 218, '0000-0002-0827-0051': 18, '0000-0003-1061-5888': 3, '0000-0002-9312-6272': 3, '0000-0002-1469-0685': 2, '0000-0002-7095-5676': 1, '0000-0003-3757-3243': 1, '0000-0003-4063-0042': 1, '0000-0003-4473-1131': 1, '0000-0002-6009-7962': 1})\n",
      "['0000-0002-0827-0051', '0000-0001-7856-3952']\n",
      "Total sample size after apply threshold:  236\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(236, 88)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(236, 27)\n",
      "2\n",
      "(236, 115)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.33      0.46        18\n",
      "          1       0.95      0.99      0.97       218\n",
      "\n",
      "avg / total       0.93      0.94      0.93       236\n",
      "\n",
      "[  6  12   2 216]\n",
      "MNB Accuracy:  0.940677966101695\n",
      "MNB F1:  0.7150741635046567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        18\n",
      "          1       0.96      1.00      0.98       218\n",
      "\n",
      "avg / total       0.96      0.96      0.96       236\n",
      "\n",
      "[  9   9   0 218]\n",
      "svc Accuracy:  0.961864406779661\n",
      "svc F1:  0.8232209737827716\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        18\n",
      "          1       0.92      1.00      0.96       218\n",
      "\n",
      "avg / total       0.85      0.92      0.89       236\n",
      "\n",
      "[  0  18   0 218]\n",
      "LR Accuracy:  0.923728813559322\n",
      "LR F1:  0.4801762114537445\n",
      "For name:  a_ward\n",
      "total sample size before apply threshold:  164\n",
      "Counter({'0000-0001-7945-7975': 92, '0000-0003-4102-8694': 40, '0000-0002-7000-2453': 10, '0000-0001-6948-4814': 9, '0000-0002-6376-0061': 6, '0000-0003-0038-9426': 4, '0000-0002-9774-8677': 2, '0000-0003-1321-3358': 1})\n",
      "['0000-0001-7945-7975', '0000-0002-7000-2453', '0000-0003-4102-8694']\n",
      "Total sample size after apply threshold:  142\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 80)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 25)\n",
      "2\n",
      "(142, 105)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.90      0.86        92\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.72      0.72      0.73        40\n",
      "\n",
      "avg / total       0.73      0.79      0.76       142\n",
      "\n",
      "[83  0  9  8  0  2 11  0 29]\n",
      "MNB Accuracy:  0.7887323943661971\n",
      "MNB F1:  0.5268900343642612\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.97      0.89        92\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.91      0.75      0.82        40\n",
      "\n",
      "avg / total       0.79      0.84      0.81       142\n",
      "\n",
      "[89  0  3 10  0  0  9  1 30]\n",
      "svc Accuracy:  0.8380281690140845\n",
      "svc F1:  0.5706392694063926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.97      0.85        92\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.88      0.53      0.66        40\n",
      "\n",
      "avg / total       0.74      0.77      0.73       142\n",
      "\n",
      "[89  0  3 10  0  0 19  0 21]\n",
      "LR Accuracy:  0.7746478873239436\n",
      "LR F1:  0.5012896825396825\n",
      "For name:  j_chen\n",
      "total sample size before apply threshold:  1139\n",
      "Counter({'0000-0001-5077-4483': 92, '0000-0002-5756-3336': 87, '0000-0001-7858-8236': 73, '0000-0002-1752-4201': 61, '0000-0002-9220-8436': 55, '0000-0001-5859-3070': 51, '0000-0003-2996-5781': 49, '0000-0001-8807-3607': 43, '0000-0001-6527-4801': 41, '0000-0001-6879-5936': 35, '0000-0002-7253-2722': 33, '0000-0001-7336-8808': 31, '0000-0001-8634-1145': 29, '0000-0001-6491-6577': 28, '0000-0002-0662-782X': 19, '0000-0001-7381-0918': 18, '0000-0002-4429-283X': 17, '0000-0001-5168-7074': 16, '0000-0002-1591-9744': 14, '0000-0002-7409-7859': 14, '0000-0002-8021-7458': 13, '0000-0002-7530-4215': 12, '0000-0002-4114-3046': 12, '0000-0001-9970-4582': 12, '0000-0002-7000-1469': 11, '0000-0002-3850-4875': 11, '0000-0001-5648-9202': 11, '0000-0002-1038-4162': 11, '0000-0002-3671-553X': 10, '0000-0002-3329-6384': 9, '0000-0001-6661-1734': 9, '0000-0003-0326-8304': 9, '0000-0001-9202-404X': 8, '0000-0001-6321-0505': 8, '0000-0002-5323-1801': 8, '0000-0001-7942-0187': 8, '0000-0003-0339-5880': 8, '0000-0002-0708-6498': 8, '0000-0003-4599-3600': 8, '0000-0002-1071-2234': 7, '0000-0003-3158-9471': 7, '0000-0001-8446-1821': 6, '0000-0002-5684-6692': 6, '0000-0003-1403-1708': 6, '0000-0001-5637-1829': 6, '0000-0001-5507-235X': 6, '0000-0002-6497-4141': 6, '0000-0001-6109-8433': 6, '0000-0002-4801-5397': 5, '0000-0002-6664-2597': 5, '0000-0003-3987-4816': 5, '0000-0002-2424-3969': 4, '0000-0002-7107-2867': 4, '0000-0002-2454-0058': 4, '0000-0003-4188-6189': 3, '0000-0002-9964-293X': 3, '0000-0002-2926-1090': 3, '0000-0001-7547-6423': 3, '0000-0001-5205-923X': 3, '0000-0002-3124-5452': 3, '0000-0002-5042-6179': 3, '0000-0002-0963-3520': 2, '0000-0002-6981-3363': 2, '0000-0002-5258-9035': 2, '0000-0002-2481-8814': 2, '0000-0002-6989-9048': 2, '0000-0003-0447-7466': 2, '0000-0001-8714-2543': 2, '0000-0003-3767-9486': 2, '0000-0003-0320-8707': 2, '0000-0002-3764-1149': 2, '0000-0001-9100-4784': 1, '0000-0002-7226-1678': 1, '0000-0002-4923-5076': 1, '0000-0002-2315-6070': 1, '0000-0002-4833-6756': 1, '0000-0001-6234-1001': 1, '0000-0003-2844-6947': 1, '0000-0002-2745-442X': 1, '0000-0001-6075-4806': 1, '0000-0002-6387-6814': 1, '0000-0002-5433-5178': 1, '0000-0003-4612-3279': 1, '0000-0001-7299-0355': 1, '0000-0001-7962-0840': 1, '0000-0003-4693-5234': 1, '0000-0002-1758-4634': 1, '0000-0001-7360-2238': 1, '0000-0001-5636-985X': 1, '0000-0002-9320-6774': 1, '0000-0002-7808-2670': 1, '0000-0001-5302-2463': 1, '0000-0002-0934-8519': 1, '0000-0002-0024-4561': 1})\n",
      "['0000-0001-7336-8808', '0000-0001-7858-8236', '0000-0002-7253-2722', '0000-0002-9220-8436', '0000-0001-6491-6577', '0000-0002-1591-9744', '0000-0002-4429-283X', '0000-0001-5077-4483', '0000-0002-7000-1469', '0000-0002-5756-3336', '0000-0001-5168-7074', '0000-0003-2996-5781', '0000-0002-7530-4215', '0000-0002-3671-553X', '0000-0002-4114-3046', '0000-0001-8807-3607', '0000-0001-7381-0918', '0000-0002-0662-782X', '0000-0002-1752-4201', '0000-0001-6527-4801', '0000-0001-9970-4582', '0000-0002-3850-4875', '0000-0001-5648-9202', '0000-0002-1038-4162', '0000-0002-7409-7859', '0000-0002-8021-7458', '0000-0001-5859-3070', '0000-0001-6879-5936', '0000-0001-8634-1145']\n",
      "Total sample size after apply threshold:  909\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(909, 327)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(909, 27)\n",
      "2\n",
      "(909, 354)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.16      0.26        31\n",
      "          1       0.41      0.79      0.54        73\n",
      "          2       0.00      0.00      0.00        33\n",
      "          3       0.40      0.29      0.34        55\n",
      "          4       0.77      0.61      0.68        28\n",
      "          5       0.00      0.00      0.00        14\n",
      "          6       0.00      0.00      0.00        17\n",
      "          7       0.28      0.73      0.40        92\n",
      "          8       0.00      0.00      0.00        11\n",
      "          9       0.30      0.90      0.45        87\n",
      "         10       0.00      0.00      0.00        16\n",
      "         11       0.61      0.29      0.39        49\n",
      "         12       0.00      0.00      0.00        12\n",
      "         13       0.00      0.00      0.00        10\n",
      "         14       0.00      0.00      0.00        12\n",
      "         15       0.32      0.21      0.25        43\n",
      "         16       0.00      0.00      0.00        18\n",
      "         17       0.00      0.00      0.00        19\n",
      "         18       0.45      0.48      0.46        61\n",
      "         19       1.00      0.15      0.26        41\n",
      "         20       0.00      0.00      0.00        12\n",
      "         21       0.00      0.00      0.00        11\n",
      "         22       0.00      0.00      0.00        11\n",
      "         23       0.00      0.00      0.00        11\n",
      "         24       0.00      0.00      0.00        14\n",
      "         25       1.00      0.15      0.27        13\n",
      "         26       0.57      0.41      0.48        51\n",
      "         27       0.67      0.40      0.50        35\n",
      "         28       0.88      0.48      0.62        29\n",
      "\n",
      "avg / total       0.39      0.39      0.32       909\n",
      "\n",
      "[ 5  5  0  0  0  0  0 10  0  6  0  4  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  1  0 58  0  0  0  0  0  8  0  3  0  0  0  0  0  0  0  0  4\n",
      "  0  0  0  0  0  0  0  0  0  0  0  4  0  4  2  0  0  9  0  7  0  1  0  0\n",
      "  0  1  0  0  4  0  0  0  0  0  0  0  0  1  0  0  7  0 16  0  0  0  7  0\n",
      "  9  0  2  0  0  0  6  0  0  6  0  0  0  0  0  0  0  1  1  0  0  1  2  2\n",
      " 17  0  0  2  0  2  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  4  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  7  0  2  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0 67  0 18  0  0  0\n",
      "  0  0  1  0  0  2  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  3\n",
      "  0  6  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  4  0\n",
      "  0  0  0  0  3  0 78  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2\n",
      "  0  0  0  7  0  0  0  0  0  4  0  5  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  1 12  0  2  0  0  0  8  0  8  0 14  0  0  0  2  0\n",
      "  0  2  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  4  0  5  0  0\n",
      "  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0\n",
      "  4  0  1  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "  0  1  0  0  0  1  0  4  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "  3  1  0  0  2  1  7  2  0  0 12  0  6  0  0  0  0  0  9  0  0  4  0  0\n",
      "  0  0  0  0  0  0  0  0  0  2  0  1  0  0  0  9  0  3  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  2  1  0  0  2  0  1  0  0  0  5  0  7  0\n",
      "  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  2  0  0  3  1  2  1  0\n",
      "  0 11  0  9  0  0  0  0  0  3  0  0 29  0  0  0  0  0  0  0  1  0  1  0\n",
      " 10  0  0  0  0  0 13  0  9  0  0  0  0  0  1  0  0  0  6  0  0  0  0  0\n",
      "  0  1  1  0  0  1  0  0  0  0  0  6  0  3  0  0  0  0  0  1  0  0  0  0\n",
      "  0  0  0  0  0  0  1  0  0  0  5  0  0  0  0  0  4  0  2  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  3\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0\n",
      "  0  0  1  0  6  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  2  0  3  0  0  0  2  0  5  0  0  0  0  0  1  0  0  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  1  0  0  0  4  0  5  0  0  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0  2  0  0  0  0  1  0  0  0  0  0  9  0 17  0  0  0  0\n",
      "  0  1  0  0  2  0  0  0  0  0  0  0 21  0  0  0  2  0  0  0  0  0  7  0\n",
      " 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2 14  0  1  5  0  0\n",
      "  0  0  0  6  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 14]\n",
      "MNB Accuracy:  0.385038503850385\n",
      "MNB F1:  0.20356034574949328\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.58      0.61        31\n",
      "          1       0.86      0.82      0.84        73\n",
      "          2       0.46      0.33      0.39        33\n",
      "          3       0.47      0.42      0.44        55\n",
      "          4       0.73      0.68      0.70        28\n",
      "          5       1.00      0.50      0.67        14\n",
      "          6       0.62      0.29      0.40        17\n",
      "          7       0.32      0.89      0.47        92\n",
      "          8       1.00      0.27      0.43        11\n",
      "          9       0.81      0.87      0.84        87\n",
      "         10       0.50      0.31      0.38        16\n",
      "         11       0.59      0.39      0.47        49\n",
      "         12       1.00      0.75      0.86        12\n",
      "         13       1.00      0.50      0.67        10\n",
      "         14       0.50      0.25      0.33        12\n",
      "         15       0.31      0.26      0.28        43\n",
      "         16       0.22      0.22      0.22        18\n",
      "         17       0.64      0.47      0.55        19\n",
      "         18       0.47      0.59      0.52        61\n",
      "         19       0.87      0.49      0.62        41\n",
      "         20       0.88      0.58      0.70        12\n",
      "         21       1.00      0.27      0.43        11\n",
      "         22       0.00      0.00      0.00        11\n",
      "         23       1.00      0.27      0.43        11\n",
      "         24       0.50      0.07      0.12        14\n",
      "         25       1.00      0.77      0.87        13\n",
      "         26       0.72      0.51      0.60        51\n",
      "         27       0.70      0.66      0.68        35\n",
      "         28       0.95      0.62      0.75        29\n",
      "\n",
      "avg / total       0.64      0.57      0.57       909\n",
      "\n",
      "[18  0  0  0  0  0  0  7  0  0  1  2  0  0  0  1  0  0  2  0  0  0  0  0\n",
      "  0  0  0  0  0  0 60  0  0  0  0  0  8  0  0  1  0  0  0  0  0  0  0  4\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 11  4  3  0  0  8  0  0  0  0  0  0\n",
      "  0  3  0  0  2  0  0  0  0  0  0  0  1  1  0  0  1  3 23  1  0  0  8  0\n",
      "  1  0  0  0  0  0 10  1  0  5  0  0  0  0  0  0  0  1  1  0  0  0  4  2\n",
      " 19  0  1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  7  0  5  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  1  0  5  7  0  0  0  1  0  0  0  0  0  0\n",
      "  2  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 82  0  0  0  2  0\n",
      "  0  0  1  0  0  5  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  4\n",
      "  3  2  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  6  0 76  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  3\n",
      "  0  0  0  0  0  1  0  0  0  6  0  0  5  0  0  0  0  1  0  0  3  0  0  0\n",
      "  0  0  0  0  0  0  0  2  6  0  1  0  0  0 15  0  1  0 19  0  0  0  3  0\n",
      "  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0\n",
      "  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0\n",
      "  2  0  0  0  0  0  5  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  3  0  0  0  0  0  0  3  1  1  0  0  0  0  0  0  0  0  0\n",
      "  3  1  0  1  0  2  9  2  0  0  7  0  0  1  5  0  0  0 11  0  0  3  0  0\n",
      "  0  0  0  1  0  0  1  0  0  0  1  1  0  0  0  3  0  0  0  0  0  0  0  0\n",
      "  4  4  0  0  0  0  0  0  0  0  2  3  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  1  0  7  9  0  0  0  0  0  0  0  0  0  1  0  3  2  2  3  0  0\n",
      "  0  9  0  0  1  1  0  0  0  3  0  0 36  1  0  0  0  0  0  0  0  0  0  0\n",
      "  1  0  0  0  0  1 18  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0\n",
      "  0  0  1  0  0  0  0  0  0  0  0  2  0  2  0  0  0  0  0  0  0  0  1  0\n",
      "  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  2  0  1  0  0  0  0  0\n",
      "  0  0  0  4  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  7  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  3  0  0  0  0  0\n",
      "  0  0  0  3  0  0  0  7  0  0  1  0  0  0  0  1  0  0  1  0  0  0  0  0\n",
      "  1  0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  8  0 11  0  2  0  0\n",
      "  1  0  1  0  0  0  1  0  0  0  0  0 26  1  0  1  0  0  1  0  0  0  5  0\n",
      "  0  0  0  0  0  1  0  3  1  0  0  0  0  0  0  0  0  0 23  0  1  0  0  0\n",
      "  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 18]\n",
      "svc Accuracy:  0.5676567656765676\n",
      "svc F1:  0.5265337522910649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.58      0.62        31\n",
      "          1       0.65      0.81      0.72        73\n",
      "          2       0.38      0.18      0.24        33\n",
      "          3       0.49      0.40      0.44        55\n",
      "          4       0.76      0.68      0.72        28\n",
      "          5       0.80      0.57      0.67        14\n",
      "          6       0.00      0.00      0.00        17\n",
      "          7       0.33      0.77      0.46        92\n",
      "          8       0.00      0.00      0.00        11\n",
      "          9       0.63      0.87      0.73        87\n",
      "         10       0.57      0.25      0.35        16\n",
      "         11       0.57      0.41      0.48        49\n",
      "         12       1.00      0.50      0.67        12\n",
      "         13       1.00      0.30      0.46        10\n",
      "         14       0.25      0.08      0.12        12\n",
      "         15       0.34      0.28      0.31        43\n",
      "         16       0.18      0.11      0.14        18\n",
      "         17       0.56      0.47      0.51        19\n",
      "         18       0.45      0.57      0.50        61\n",
      "         19       1.00      0.49      0.66        41\n",
      "         20       0.88      0.58      0.70        12\n",
      "         21       0.00      0.00      0.00        11\n",
      "         22       0.00      0.00      0.00        11\n",
      "         23       1.00      0.09      0.17        11\n",
      "         24       0.00      0.00      0.00        14\n",
      "         25       1.00      0.77      0.87        13\n",
      "         26       0.59      0.47      0.52        51\n",
      "         27       0.38      0.66      0.48        35\n",
      "         28       0.78      0.62      0.69        29\n",
      "\n",
      "avg / total       0.53      0.52      0.50       909\n",
      "\n",
      "[18  1  1  0  0  0  0  4  0  0  1  3  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "  0  0  1  1  0  0 59  0  0  0  0  0  6  0  0  1  0  0  0  0  0  0  0  5\n",
      "  0  0  0  0  0  0  0  1  1  0  0  1  6  3  2  0  0  9  0  0  0  0  0  0\n",
      "  0  3  0  0  5  0  0  0  0  0  0  0  0  4  0  1  2  3 22  1  0  0  6  0\n",
      "  0  0  1  0  0  0 10  0  1  5  0  0  0  0  0  0  0  1  2  0  0  0  2  2\n",
      " 19  0  0  0  0  1  0  1  0  0  0  2  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  8  0  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  1  2  0  0  0  0  0  1  0 10  0  2  0  2  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  2  0  1  2  0  0  0  0  0 71  0  8  0  1  0\n",
      "  0  0  0  0  0  3  0  0  0  0  0  0  0  2  3  1  0  0  0  0  0  0  0  4\n",
      "  0  4  0  0  0  0  0  0  1  0  2  0  0  0  0  0  0  0  0  0  0  0  2  0\n",
      "  0  0  0  0  6  0 76  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  2\n",
      "  0  0  0  3  0  1  0  0  0  4  0  0  4  0  0  0  0  0  0  0  2  0  0  0\n",
      "  0  0  0  0  0  2  0  1  8  0  0  0  0  0 11  0  2  0 20  0  0  0  3  0\n",
      "  0  2  0  0  0  0  0  0  0  0  2  0  0  1  0  0  0  0  0  1  0  1  0  0\n",
      "  6  0  0  0  0  0  1  0  0  0  0  0  0  0  0  2  0  0  1  0  0  0  0  0\n",
      "  2  0  0  0  0  0  3  0  0  0  0  2  0  0  0  0  0  0  0  1  0  1  1  0\n",
      "  0  1  0  0  0  3  0  1  0  0  0  0  1  0  1  0  1  0  0  0  0  0  0  0\n",
      "  2  1  0  0  0  2  7  2  0  0  9  0  1  0  4  0  0  0 12  0  0  5  0  0\n",
      "  0  0  0  0  0  0  1  0  0  0  0  2  0  0  0  3  0  0  0  0  0  0  0  0\n",
      "  2  5  0  0  0  0  0  0  0  0  2  4  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  5  9  1  0  0  0  0  0  0  0  0  3  0  3  3  2  1  1  0\n",
      "  0  9  0  1  1  0  0  0  0  2  0  0 35  0  0  0  0  0  0  0  1  1  1  0\n",
      "  3  0  0  0  0  0 13  0  0  0  1  0  0  0  0  0  0  0 20  0  0  0  0  0\n",
      "  0  2  2  0  0  1  0  0  0  1  0  1  0  2  0  0  0  0  0  0  0  0  0  0\n",
      "  7  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  4  0  2  0  0  0  0  0\n",
      "  0  0  0  2  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0 11  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  4  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  3  0\n",
      "  0  1  0  3  0  0  0  6  0  1  0  0  0  0  0  2  0  0  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  2\n",
      "  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  5  0 14  0  2  0  0\n",
      "  2  0  0  0  2  0  1  0  0  0  0  0 24  1  0  1  0  0  2  0  0  0  2  0\n",
      "  2  0  0  0  0  1  0  2  1  0  0  0  0  0  0  0  0  1 23  0  1  1  0  0\n",
      "  0  0  0  8  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 18]\n",
      "LR Accuracy:  0.5214521452145214\n",
      "LR F1:  0.4216540863483447\n",
      "For name:  m_tseng\n",
      "total sample size before apply threshold:  141\n",
      "Counter({'0000-0002-9969-9055': 85, '0000-0002-0114-102X': 24, '0000-0001-8354-7586': 15, '0000-0003-3763-9548': 10, '0000-0002-2702-3590': 5, '0000-0001-6310-4390': 1, '0000-0001-8641-587X': 1})\n",
      "['0000-0003-3763-9548', '0000-0001-8354-7586', '0000-0002-0114-102X', '0000-0002-9969-9055']\n",
      "Total sample size after apply threshold:  134\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 53)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 14)\n",
      "2\n",
      "(134, 67)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.33      0.50        15\n",
      "          2       0.68      0.54      0.60        24\n",
      "          3       0.75      0.96      0.84        85\n",
      "\n",
      "avg / total       0.71      0.75      0.70       134\n",
      "\n",
      "[ 0  0  2  8  0  5  1  9  0  0 13 11  0  0  3 82]\n",
      "MNB Accuracy:  0.746268656716418\n",
      "MNB F1:  0.4864192009540847\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       1.00      0.60      0.75        15\n",
      "          2       0.76      0.54      0.63        24\n",
      "          3       0.77      0.96      0.86        85\n",
      "\n",
      "avg / total       0.81      0.79      0.77       134\n",
      "\n",
      "[ 2  0  1  7  0  9  0  6  0  0 13 11  0  0  3 82]\n",
      "svc Accuracy:  0.7910447761194029\n",
      "svc F1:  0.6440296045630612\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.47      0.64        15\n",
      "          2       0.83      0.42      0.56        24\n",
      "          3       0.73      0.99      0.84        85\n",
      "\n",
      "avg / total       0.72      0.75      0.70       134\n",
      "\n",
      "[ 0  0  1  9  0  7  0  8  0  0 10 14  0  0  1 84]\n",
      "LR Accuracy:  0.753731343283582\n",
      "LR F1:  0.507979797979798\n",
      "For name:  c_henderson\n",
      "total sample size before apply threshold:  107\n",
      "Counter({'0000-0002-4764-639X': 97, '0000-0002-9936-3279': 6, '0000-0001-6954-7328': 2, '0000-0002-4020-0854': 2})\n",
      "['0000-0002-4764-639X']\n",
      "Total sample size after apply threshold:  97\n",
      "For name:  j_mcdonald\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0003-1955-6052': 7, '0000-0002-7494-1466': 7, '0000-0002-8317-0069': 4, '0000-0002-7953-1458': 1, '0000-0003-4115-7875': 1, '0000-0002-6328-3752': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_ismail\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0003-3111-3588': 10, '0000-0002-5509-5735': 7, '0000-0003-1688-5096': 1, '0000-0002-0264-6476': 1, '0000-0002-1946-9007': 1, '0000-0003-2747-054X': 1, '0000-0002-7019-2146': 1, '0000-0002-1695-3119': 1, '0000-0001-7608-7884': 1})\n",
      "['0000-0003-3111-3588']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  x_xu\n",
      "total sample size before apply threshold:  408\n",
      "Counter({'0000-0002-7229-0081': 107, '0000-0002-4459-2082': 38, '0000-0002-4567-7117': 34, '0000-0002-7426-272X': 32, '0000-0003-4132-5322': 28, '0000-0002-2009-0483': 19, '0000-0003-2220-0890': 18, '0000-0001-6088-976X': 17, '0000-0002-3863-9593': 17, '0000-0002-5695-8213': 15, '0000-0001-6435-8181': 13, '0000-0003-0847-5871': 8, '0000-0003-3695-4845': 7, '0000-0003-1672-0830': 7, '0000-0002-5042-9505': 7, '0000-0002-4876-5710': 7, '0000-0002-3265-7678': 6, '0000-0003-0205-6342': 6, '0000-0003-1157-8660': 5, '0000-0002-1982-7062': 4, '0000-0001-6909-0743': 4, '0000-0002-6315-6083': 2, '0000-0003-2094-3164': 1, '0000-0003-1405-8089': 1, '0000-0001-6501-7442': 1, '0000-0002-9662-7582': 1, '0000-0003-3950-3425': 1, '0000-0001-9769-7323': 1, '0000-0003-2047-7298': 1})\n",
      "['0000-0001-6088-976X', '0000-0003-4132-5322', '0000-0001-6435-8181', '0000-0002-7229-0081', '0000-0002-3863-9593', '0000-0002-4567-7117', '0000-0002-5695-8213', '0000-0002-2009-0483', '0000-0002-7426-272X', '0000-0002-4459-2082', '0000-0003-2220-0890']\n",
      "Total sample size after apply threshold:  338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(338, 139)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(338, 28)\n",
      "2\n",
      "(338, 167)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.53      0.69        17\n",
      "          1       0.81      0.75      0.78        28\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.45      0.93      0.61       107\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.76      0.47      0.58        34\n",
      "          6       1.00      0.13      0.24        15\n",
      "          7       1.00      0.21      0.35        19\n",
      "          8       0.67      0.31      0.43        32\n",
      "          9       0.41      0.39      0.40        38\n",
      "         10       1.00      0.17      0.29        18\n",
      "\n",
      "avg / total       0.60      0.53      0.48       338\n",
      "\n",
      "[  9   0   0   7   0   0   0   0   0   1   0   0  21   0   6   0   0   0\n",
      "   0   0   1   0   0   0   0   8   0   0   0   0   0   5   0   0   0   0\n",
      " 100   0   3   0   0   0   4   0   0   1   0  16   0   0   0   0   0   0\n",
      "   0   0   1   0  16   0  16   0   0   0   1   0   0   0   0  10   0   1\n",
      "   2   0   0   2   0   0   1   0  14   0   0   0   4   0   0   0   0   0\n",
      "   0  16   0   0   0   0  10   6   0   0   2   0  15   0   1   0   0   5\n",
      "  15   0   0   0   0  13   0   0   0   0   0   2   3]\n",
      "MNB Accuracy:  0.5325443786982249\n",
      "MNB F1:  0.39600237769782826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.82      0.87        17\n",
      "          1       0.86      0.86      0.86        28\n",
      "          2       0.62      0.38      0.48        13\n",
      "          3       0.59      0.91      0.72       107\n",
      "          4       0.50      0.18      0.26        17\n",
      "          5       0.74      0.50      0.60        34\n",
      "          6       1.00      0.53      0.70        15\n",
      "          7       1.00      0.74      0.85        19\n",
      "          8       0.73      0.69      0.71        32\n",
      "          9       0.54      0.50      0.52        38\n",
      "         10       1.00      0.39      0.56        18\n",
      "\n",
      "avg / total       0.71      0.68      0.67       338\n",
      "\n",
      "[14  0  0  1  0  2  0  0  0  0  0  0 24  0  2  0  1  0  0  0  1  0  0  0\n",
      "  5  3  0  0  0  0  0  5  0  0  1  0 97  2  2  0  0  2  3  0  0  0  0 12\n",
      "  3  0  0  0  0  2  0  1  1  0 15  0 17  0  0  0  0  0  0  0  0  7  0  0\n",
      "  8  0  0  0  0  0  2  0  3  0  0  0 14  0  0  0  0  0  0  6  0  0  0  0\n",
      " 22  4  0  0  0  3 10  0  0  0  0  6 19  0  0  0  0  8  1  1  0  0  0  1\n",
      "  7]\n",
      "svc Accuracy:  0.6804733727810651\n",
      "svc F1:  0.6469021520227908\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.87        17\n",
      "          1       0.83      0.68      0.75        28\n",
      "          2       0.67      0.15      0.25        13\n",
      "          3       0.49      0.94      0.64       107\n",
      "          4       1.00      0.18      0.30        17\n",
      "          5       0.75      0.53      0.62        34\n",
      "          6       1.00      0.27      0.42        15\n",
      "          7       1.00      0.53      0.69        19\n",
      "          8       0.78      0.56      0.65        32\n",
      "          9       0.61      0.37      0.46        38\n",
      "         10       1.00      0.28      0.43        18\n",
      "\n",
      "avg / total       0.72      0.61      0.59       338\n",
      "\n",
      "[ 13   0   0   3   0   1   0   0   0   0   0   0  19   0   9   0   0   0\n",
      "   0   0   0   0   0   0   2   7   0   0   0   0   0   4   0   0   0   0\n",
      " 101   0   4   0   0   0   2   0   0   0   0  13   3   0   0   0   0   1\n",
      "   0   0   1   0  15   0  18   0   0   0   0   0   0   0   0  11   0   0\n",
      "   4   0   0   0   0   0   2   0   7   0   0   0  10   0   0   0   0   0\n",
      "   0  12   0   0   0   0  18   2   0   0   1   1  17   0   0   0   0   5\n",
      "  14   0   0   0   0  12   0   1   0   0   0   0   5]\n",
      "LR Accuracy:  0.6124260355029586\n",
      "LR F1:  0.5531653385129149\n",
      "For name:  f_liu\n",
      "total sample size before apply threshold:  185\n",
      "Counter({'0000-0003-3228-0943': 31, '0000-0001-6224-5167': 30, '0000-0001-9241-8161': 22, '0000-0003-3028-5927': 17, '0000-0002-1934-3674': 16, '0000-0002-5006-8965': 16, '0000-0002-2261-6899': 13, '0000-0002-8325-1213': 11, '0000-0001-6693-1981': 5, '0000-0002-8371-6316': 4, '0000-0002-1074-2601': 3, '0000-0001-7029-0312': 3, '0000-0002-7776-0222': 3, '0000-0002-1467-8328': 2, '0000-0001-8032-6681': 2, '0000-0003-2644-2416': 2, '0000-0002-2769-5012': 1, '0000-0003-1322-4997': 1, '0000-0001-8701-2984': 1, '0000-0002-6572-251X': 1, '0000-0001-5625-2969': 1})\n",
      "['0000-0003-3028-5927', '0000-0002-1934-3674', '0000-0002-8325-1213', '0000-0002-5006-8965', '0000-0002-2261-6899', '0000-0001-9241-8161', '0000-0001-6224-5167', '0000-0003-3228-0943']\n",
      "Total sample size after apply threshold:  156\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(156, 86)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(156, 14)\n",
      "2\n",
      "(156, 100)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.53      0.58        17\n",
      "          1       0.75      0.19      0.30        16\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.71      0.31      0.43        16\n",
      "          4       1.00      1.00      1.00        13\n",
      "          5       0.33      0.32      0.33        22\n",
      "          6       0.51      0.83      0.63        30\n",
      "          7       0.40      0.61      0.49        31\n",
      "\n",
      "avg / total       0.53      0.52      0.49       156\n",
      "\n",
      "[ 9  0  0  0  0  3  3  2  2  3  0  0  0  2  3  6  1  0  0  0  0  3  3  4\n",
      "  0  1  0  5  0  3  3  4  0  0  0  0 13  0  0  0  0  0  0  0  0  7  7  8\n",
      "  0  0  0  0  0  1 25  4  2  0  1  2  0  2  5 19]\n",
      "MNB Accuracy:  0.5192307692307693\n",
      "MNB F1:  0.4701375056149203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.41      0.48        17\n",
      "          1       0.83      0.62      0.71        16\n",
      "          2       0.50      0.18      0.27        11\n",
      "          3       0.73      0.50      0.59        16\n",
      "          4       1.00      1.00      1.00        13\n",
      "          5       0.60      0.55      0.57        22\n",
      "          6       0.79      0.73      0.76        30\n",
      "          7       0.34      0.61      0.44        31\n",
      "\n",
      "avg / total       0.65      0.60      0.60       156\n",
      "\n",
      "[ 7  1  0  0  0  1  3  5  0 10  0  1  0  1  0  4  1  0  2  0  0  1  1  6\n",
      "  0  1  0  8  0  0  0  7  0  0  0  0 13  0  0  0  1  0  0  0  0 12  1  8\n",
      "  0  0  0  0  0  1 22  7  3  0  2  2  0  4  1 19]\n",
      "svc Accuracy:  0.5961538461538461\n",
      "svc F1:  0.6028918080642218\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.41      0.45        17\n",
      "          1       0.86      0.38      0.52        16\n",
      "          2       0.50      0.09      0.15        11\n",
      "          3       0.70      0.44      0.54        16\n",
      "          4       1.00      1.00      1.00        13\n",
      "          5       0.47      0.41      0.44        22\n",
      "          6       0.63      0.73      0.68        30\n",
      "          7       0.36      0.65      0.46        31\n",
      "\n",
      "avg / total       0.59      0.54      0.54       156\n",
      "\n",
      "[ 7  0  0  0  0  3  2  5  2  6  0  1  0  0  2  5  2  0  1  0  0  2  1  5\n",
      "  0  1  0  7  0  1  1  6  0  0  0  0 13  0  0  0  1  0  0  0  0  9  3  9\n",
      "  0  0  0  0  0  2 22  6  2  0  1  2  0  2  4 20]\n",
      "LR Accuracy:  0.5448717948717948\n",
      "LR F1:  0.5301721635097236\n",
      "For name:  a_rego\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0003-0700-3776': 70, '0000-0002-3131-4219': 5, '0000-0003-0883-0511': 2, '0000-0002-4596-3703': 1})\n",
      "['0000-0003-0700-3776']\n",
      "Total sample size after apply threshold:  70\n",
      "For name:  s_hammad\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0003-0571-4208': 26, '0000-0003-2102-1081': 3, '0000-0002-1313-2542': 1, '0000-0003-3280-564X': 1, '0000-0001-6061-9962': 1})\n",
      "['0000-0003-0571-4208']\n",
      "Total sample size after apply threshold:  26\n",
      "For name:  k_johansson\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0003-3735-3611': 13, '0000-0002-3749-998X': 9, '0000-0001-9940-5929': 3, '0000-0002-1571-1775': 1})\n",
      "['0000-0003-3735-3611']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  m_barreto\n",
      "total sample size before apply threshold:  201\n",
      "Counter({'0000-0002-0215-4930': 181, '0000-0002-6973-7233': 9, '0000-0001-6464-548X': 7, '0000-0001-8377-616X': 3, '0000-0001-5797-8913': 1})\n",
      "['0000-0002-0215-4930']\n",
      "Total sample size after apply threshold:  181\n",
      "For name:  j_moore\n",
      "total sample size before apply threshold:  154\n",
      "Counter({'0000-0001-8451-9421': 63, '0000-0002-5486-0407': 22, '0000-0003-4750-1550': 19, '0000-0003-4059-0538': 13, '0000-0002-6028-2084': 13, '0000-0002-0053-3347': 6, '0000-0003-4028-811X': 6, '0000-0002-5496-752X': 5, '0000-0001-8245-9306': 2, '0000-0002-7273-974X': 1, '0000-0001-8503-4880': 1, '0000-0001-9039-1014': 1, '0000-0002-8698-6143': 1, '0000-0001-5682-6897': 1})\n",
      "['0000-0002-5486-0407', '0000-0003-4059-0538', '0000-0001-8451-9421', '0000-0003-4750-1550', '0000-0002-6028-2084']\n",
      "Total sample size after apply threshold:  130\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 77)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 16)\n",
      "2\n",
      "(130, 93)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.50      0.49        22\n",
      "          1       1.00      0.23      0.38        13\n",
      "          2       0.61      0.95      0.74        63\n",
      "          3       0.67      0.11      0.18        19\n",
      "          4       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.57      0.58      0.51       130\n",
      "\n",
      "[11  0 11  0  0  2  3  8  0  0  1  0 60  1  1  5  0 11  2  1  4  0  9  0\n",
      "  0]\n",
      "MNB Accuracy:  0.5846153846153846\n",
      "MNB F1:  0.3572895622895623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.59      0.53        22\n",
      "          1       1.00      0.54      0.70        13\n",
      "          2       0.69      0.90      0.78        63\n",
      "          3       0.78      0.37      0.50        19\n",
      "          4       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.63      0.65      0.61       130\n",
      "\n",
      "[13  0  7  1  1  2  7  3  0  1  4  0 57  1  1  4  0  7  7  1  4  0  9  0\n",
      "  0]\n",
      "svc Accuracy:  0.6461538461538462\n",
      "svc F1:  0.5022868325412356\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.45      0.44        22\n",
      "          1       1.00      0.54      0.70        13\n",
      "          2       0.62      0.95      0.75        63\n",
      "          3       0.50      0.05      0.10        19\n",
      "          4       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.55      0.60      0.52       130\n",
      "\n",
      "[10  0 12  0  0  2  7  4  0  0  2  0 60  1  0  5  0 12  1  1  4  0  9  0\n",
      "  0]\n",
      "LR Accuracy:  0.6\n",
      "LR F1:  0.397936507936508\n",
      "For name:  a_gray\n",
      "total sample size before apply threshold:  121\n",
      "Counter({'0000-0003-4299-2194': 107, '0000-0003-1062-7942': 5, '0000-0002-6273-0637': 5, '0000-0002-5711-4872': 3, '0000-0003-0239-7278': 1})\n",
      "['0000-0003-4299-2194']\n",
      "Total sample size after apply threshold:  107\n",
      "For name:  v_martins\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0002-2909-8502': 71, '0000-0001-7611-861X': 18, '0000-0001-7565-9641': 6, '0000-0003-2465-5880': 5, '0000-0002-8824-7328': 3, '0000-0002-0327-538X': 1})\n",
      "['0000-0002-2909-8502', '0000-0001-7611-861X']\n",
      "Total sample size after apply threshold:  89\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 63)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 22)\n",
      "2\n",
      "(89, 85)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.89        71\n",
      "          1       0.57      0.44      0.50        18\n",
      "\n",
      "avg / total       0.81      0.82      0.81        89\n",
      "\n",
      "[65  6 10  8]\n",
      "MNB Accuracy:  0.8202247191011236\n",
      "MNB F1:  0.6952054794520548\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.94      0.91        71\n",
      "          1       0.67      0.44      0.53        18\n",
      "\n",
      "avg / total       0.83      0.84      0.83        89\n",
      "\n",
      "[67  4 10  8]\n",
      "svc Accuracy:  0.8426966292134831\n",
      "svc F1:  0.7193693693693693\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89        71\n",
      "          1       1.00      0.06      0.11        18\n",
      "\n",
      "avg / total       0.85      0.81      0.73        89\n",
      "\n",
      "[71  0 17  1]\n",
      "LR Accuracy:  0.8089887640449438\n",
      "LR F1:  0.4991724594505131\n",
      "For name:  t_zhou\n",
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0002-3935-4637': 55, '0000-0002-7858-0047': 12, '0000-0002-8744-9083': 3, '0000-0001-7416-5594': 2, '0000-0002-5829-7279': 2, '0000-0003-2219-6385': 2})\n",
      "['0000-0002-7858-0047', '0000-0002-3935-4637']\n",
      "Total sample size after apply threshold:  67\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 25)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 15)\n",
      "2\n",
      "(67, 40)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        12\n",
      "          1       0.89      1.00      0.94        55\n",
      "\n",
      "avg / total       0.91      0.90      0.88        67\n",
      "\n",
      "[ 5  7  0 55]\n",
      "MNB Accuracy:  0.8955223880597015\n",
      "MNB F1:  0.7642031171442936\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       0.93      1.00      0.96        55\n",
      "\n",
      "avg / total       0.94      0.94      0.94        67\n",
      "\n",
      "[ 8  4  0 55]\n",
      "svc Accuracy:  0.9402985074626866\n",
      "svc F1:  0.8824561403508773\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29        12\n",
      "          1       0.85      1.00      0.92        55\n",
      "\n",
      "avg / total       0.87      0.85      0.80        67\n",
      "\n",
      "[ 2 10  0 55]\n",
      "LR Accuracy:  0.8507462686567164\n",
      "LR F1:  0.6011904761904762\n",
      "For name:  s_howell\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-8141-6515': 28, '0000-0001-8184-0324': 1, '0000-0001-5311-6996': 1, '0000-0002-5126-3228': 1})\n",
      "['0000-0001-8141-6515']\n",
      "Total sample size after apply threshold:  28\n",
      "For name:  m_larsson\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0003-3584-7829': 16, '0000-0003-4164-6513': 15, '0000-0002-5795-9867': 13, '0000-0002-6755-8418': 9, '0000-0002-3226-7397': 6, '0000-0001-7368-953X': 2})\n",
      "['0000-0003-3584-7829', '0000-0002-5795-9867', '0000-0003-4164-6513']\n",
      "Total sample size after apply threshold:  44\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 14)\n",
      "2\n",
      "(44, 42)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.56      0.51        16\n",
      "          1       0.75      0.46      0.57        13\n",
      "          2       0.53      0.60      0.56        15\n",
      "\n",
      "avg / total       0.57      0.55      0.55        44\n",
      "\n",
      "[9 1 6 5 6 2 5 1 9]\n",
      "MNB Accuracy:  0.5454545454545454\n",
      "MNB F1:  0.5494047619047618\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.62      0.57        16\n",
      "          1       0.58      0.54      0.56        13\n",
      "          2       0.69      0.60      0.64        15\n",
      "\n",
      "avg / total       0.60      0.59      0.59        44\n",
      "\n",
      "[10  3  3  5  7  1  4  2  9]\n",
      "svc Accuracy:  0.5909090909090909\n",
      "svc F1:  0.5914285714285713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.56      0.50        16\n",
      "          1       0.60      0.46      0.52        13\n",
      "          2       0.64      0.60      0.62        15\n",
      "\n",
      "avg / total       0.56      0.55      0.55        44\n",
      "\n",
      "[9 3 4 6 6 1 5 1 9]\n",
      "LR Accuracy:  0.5454545454545454\n",
      "LR F1:  0.5474762618690655\n",
      "For name:  s_morris\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0003-2551-9717': 14, '0000-0002-5334-5809': 11, '0000-0002-7023-8634': 4, '0000-0002-8056-0934': 2, '0000-0003-4866-110X': 2})\n",
      "['0000-0002-5334-5809', '0000-0003-2551-9717']\n",
      "Total sample size after apply threshold:  25\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 14)\n",
      "2\n",
      "(25, 33)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.45      0.53        11\n",
      "          1       0.65      0.79      0.71        14\n",
      "\n",
      "avg / total       0.64      0.64      0.63        25\n",
      "\n",
      "[ 5  6  3 11]\n",
      "MNB Accuracy:  0.64\n",
      "MNB F1:  0.6179966044142614\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.45      0.53        11\n",
      "          1       0.65      0.79      0.71        14\n",
      "\n",
      "avg / total       0.64      0.64      0.63        25\n",
      "\n",
      "[ 5  6  3 11]\n",
      "svc Accuracy:  0.64\n",
      "svc F1:  0.6179966044142614\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.45      0.53        11\n",
      "          1       0.65      0.79      0.71        14\n",
      "\n",
      "avg / total       0.64      0.64      0.63        25\n",
      "\n",
      "[ 5  6  3 11]\n",
      "LR Accuracy:  0.64\n",
      "LR F1:  0.6179966044142614\n",
      "For name:  s_biswas\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0001-5067-0174': 10, '0000-0002-0700-7286': 9, '0000-0002-1348-2358': 6, '0000-0003-3144-0060': 5, '0000-0001-9250-5556': 2, '0000-0003-3844-980X': 1, '0000-0001-6448-4487': 1, '0000-0001-7103-9939': 1, '0000-0002-4343-6926': 1, '0000-0001-5979-3605': 1})\n",
      "['0000-0001-5067-0174']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  s_patel\n",
      "total sample size before apply threshold:  416\n",
      "Counter({'0000-0002-9142-5172': 117, '0000-0001-7247-2013': 81, '0000-0003-0046-5513': 57, '0000-0003-0614-6951': 48, '0000-0002-2386-8940': 28, '0000-0002-0626-1899': 21, '0000-0001-6969-490X': 14, '0000-0002-1235-3458': 10, '0000-0002-4471-2996': 7, '0000-0002-5448-5926': 6, '0000-0002-6136-3556': 6, '0000-0003-1200-0254': 5, '0000-0002-4969-3317': 3, '0000-0003-1674-711X': 3, '0000-0001-9540-9957': 3, '0000-0001-9472-0188': 2, '0000-0002-2177-5038': 1, '0000-0002-8455-6545': 1, '0000-0001-7803-8920': 1, '0000-0002-3444-2179': 1, '0000-0002-6058-8382': 1})\n",
      "['0000-0002-2386-8940', '0000-0003-0046-5513', '0000-0002-1235-3458', '0000-0001-6969-490X', '0000-0002-0626-1899', '0000-0001-7247-2013', '0000-0003-0614-6951', '0000-0002-9142-5172']\n",
      "Total sample size after apply threshold:  376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(376, 161)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(376, 23)\n",
      "2\n",
      "(376, 184)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        28\n",
      "          1       0.79      0.47      0.59        57\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       1.00      0.07      0.13        14\n",
      "          4       0.00      0.00      0.00        21\n",
      "          5       0.68      0.74      0.71        81\n",
      "          6       0.88      0.90      0.89        48\n",
      "          7       0.57      0.91      0.70       117\n",
      "\n",
      "avg / total       0.67      0.68      0.63       376\n",
      "\n",
      "[ 16   0   0   0   0   3   2   7   0  27   0   0   0   4   1  25   0   1\n",
      "   0   0   0   1   0   8   0   2   0   1   0   2   0   9   0   0   0   0\n",
      "   0   9   1  11   0   3   0   0   0  60   0  18   0   0   0   0   0   2\n",
      "  43   3   0   1   0   0   0   7   2 107]\n",
      "MNB Accuracy:  0.675531914893617\n",
      "MNB F1:  0.46903863850211397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.61      0.76        28\n",
      "          1       0.81      0.67      0.73        57\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.83      0.36      0.50        14\n",
      "          4       0.09      0.05      0.06        21\n",
      "          5       0.95      0.73      0.83        81\n",
      "          6       1.00      0.90      0.95        48\n",
      "          7       0.58      0.93      0.71       117\n",
      "\n",
      "avg / total       0.75      0.72      0.71       376\n",
      "\n",
      "[ 17   0   1   0   2   0   0   8   0  38   0   0   0   2   0  17   0   1\n",
      "   0   0   2   0   0   7   0   1   0   5   0   1   0   7   0   1   0   0\n",
      "   1   0   0  19   0   2   0   1   3  59   0  16   0   0   0   0   0   0\n",
      "  43   5   0   4   1   0   3   0   0 109]\n",
      "svc Accuracy:  0.723404255319149\n",
      "svc F1:  0.5667260818644014\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.61      0.76        28\n",
      "          1       0.80      0.65      0.72        57\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       1.00      0.14      0.25        14\n",
      "          4       0.17      0.05      0.07        21\n",
      "          5       0.74      0.73      0.73        81\n",
      "          6       1.00      0.88      0.93        48\n",
      "          7       0.58      0.91      0.71       117\n",
      "\n",
      "avg / total       0.71      0.70      0.68       376\n",
      "\n",
      "[ 17   0   0   0   1   2   0   8   0  37   0   0   0   3   0  17   0   1\n",
      "   0   0   1   1   0   7   0   2   0   2   0   1   0   9   0   0   0   0\n",
      "   1   7   0  13   0   3   0   0   1  59   0  18   0   1   0   0   0   1\n",
      "  42   4   0   2   0   0   2   6   0 107]\n",
      "LR Accuracy:  0.7047872340425532\n",
      "LR F1:  0.5222077691120536\n",
      "For name:  m_white\n",
      "total sample size before apply threshold:  292\n",
      "Counter({'0000-0003-1543-9342': 115, '0000-0002-3617-3232': 71, '0000-0002-9826-3962': 47, '0000-0001-9472-7806': 14, '0000-0002-7399-8348': 11, '0000-0001-6719-790X': 6, '0000-0002-7655-8145': 6, '0000-0002-2760-9057': 4, '0000-0001-6817-7126': 4, '0000-0003-3271-1221': 4, '0000-0002-8611-9525': 3, '0000-0002-0238-8913': 2, '0000-0001-9912-5070': 2, '0000-0002-1861-6757': 2, '0000-0001-5022-5505': 1})\n",
      "['0000-0002-9826-3962', '0000-0002-7399-8348', '0000-0003-1543-9342', '0000-0002-3617-3232', '0000-0001-9472-7806']\n",
      "Total sample size after apply threshold:  258\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(258, 125)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(258, 27)\n",
      "2\n",
      "(258, 152)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.40      0.54        47\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.56      0.85      0.67       115\n",
      "          3       0.47      0.38      0.42        71\n",
      "          4       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.52      0.56      0.51       258\n",
      "\n",
      "[19  0 20  8  0  0  0 10  1  0  2  0 98 15  0  0  0 44 27  0  3  0  4  7\n",
      "  0]\n",
      "MNB Accuracy:  0.5581395348837209\n",
      "MNB F1:  0.32547108753375364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.60      0.70        47\n",
      "          1       0.67      0.18      0.29        11\n",
      "          2       0.62      0.81      0.70       115\n",
      "          3       0.49      0.46      0.48        71\n",
      "          4       0.75      0.21      0.33        14\n",
      "\n",
      "avg / total       0.63      0.62      0.60       258\n",
      "\n",
      "[28  0 13  6  0  0  2  4  5  0  2  1 93 18  1  0  0 38 33  0  3  0  3  5\n",
      "  3]\n",
      "svc Accuracy:  0.6162790697674418\n",
      "svc F1:  0.4993113217827177\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.40      0.52        47\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.56      0.83      0.66       115\n",
      "          3       0.48      0.39      0.43        71\n",
      "          4       1.00      0.21      0.35        14\n",
      "\n",
      "avg / total       0.57      0.56      0.53       258\n",
      "\n",
      "[19  0 21  7  0  0  0  9  2  0  3  0 95 17  0  0  0 43 28  0  4  0  3  4\n",
      "  3]\n",
      "LR Accuracy:  0.562015503875969\n",
      "LR F1:  0.39438666262870303\n",
      "For name:  s_sherman\n",
      "total sample size before apply threshold:  125\n",
      "Counter({'0000-0002-3079-5153': 107, '0000-0001-6708-3398': 8, '0000-0003-3667-9898': 6, '0000-0003-4903-0422': 4})\n",
      "['0000-0002-3079-5153']\n",
      "Total sample size after apply threshold:  107\n",
      "For name:  j_dai\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-7720-8032': 15, '0000-0002-1185-5165': 11, '0000-0002-0111-9009': 4, '0000-0002-7414-3659': 1})\n",
      "['0000-0002-7720-8032', '0000-0002-1185-5165']\n",
      "Total sample size after apply threshold:  26\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 17)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 8)\n",
      "2\n",
      "(26, 25)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.88      0.85      0.84        26\n",
      "\n",
      "[15  0  4  7]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.8300653594771241\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.88      0.85      0.84        26\n",
      "\n",
      "[15  0  4  7]\n",
      "svc Accuracy:  0.8461538461538461\n",
      "svc F1:  0.8300653594771241\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        15\n",
      "          1       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.90      0.88      0.88        26\n",
      "\n",
      "[15  0  3  8]\n",
      "LR Accuracy:  0.8846153846153846\n",
      "LR F1:  0.8755980861244019\n",
      "For name:  m_fischer\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0002-3429-1876': 10, '0000-0001-5133-1537': 9, '0000-0002-9429-0859': 8, '0000-0002-4014-3626': 8, '0000-0002-1888-1809': 7, '0000-0002-1885-0535': 3, '0000-0002-7826-9726': 2, '0000-0003-0810-6064': 1})\n",
      "['0000-0002-3429-1876']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  y_zeng\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0001-7483-5017': 20, '0000-0002-5310-0473': 3, '0000-0002-6164-5502': 1, '0000-0003-1193-3335': 1, '0000-0002-4237-6669': 1})\n",
      "['0000-0001-7483-5017']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  j_turner\n",
      "total sample size before apply threshold:  178\n",
      "Counter({'0000-0003-0076-8434': 78, '0000-0002-2760-1071': 26, '0000-0003-2427-1430': 23, '0000-0002-7258-1639': 17, '0000-0003-4106-6295': 14, '0000-0002-0023-4275': 13, '0000-0001-7311-0313': 4, '0000-0003-0286-8949': 1, '0000-0002-4327-9385': 1, '0000-0003-0793-4159': 1})\n",
      "['0000-0002-7258-1639', '0000-0003-2427-1430', '0000-0003-0076-8434', '0000-0003-4106-6295', '0000-0002-0023-4275', '0000-0002-2760-1071']\n",
      "Total sample size after apply threshold:  171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(171, 98)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(171, 18)\n",
      "2\n",
      "(171, 116)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        17\n",
      "          1       0.73      0.35      0.47        23\n",
      "          2       0.54      1.00      0.70        78\n",
      "          3       1.00      0.29      0.44        14\n",
      "          4       0.00      0.00      0.00        13\n",
      "          5       0.55      0.23      0.32        26\n",
      "\n",
      "avg / total       0.51      0.56      0.47       171\n",
      "\n",
      "[ 0  1 14  0  0  2  0  8 15  0  0  0  0  0 78  0  0  0  0  0 10  4  0  0\n",
      "  0  0 10  0  0  3  1  2 17  0  0  6]\n",
      "MNB Accuracy:  0.5614035087719298\n",
      "MNB F1:  0.3236766177942649\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.53      0.67        17\n",
      "          1       0.87      0.57      0.68        23\n",
      "          2       0.66      0.97      0.79        78\n",
      "          3       1.00      0.93      0.96        14\n",
      "          4       0.67      0.15      0.25        13\n",
      "          5       0.80      0.46      0.59        26\n",
      "\n",
      "avg / total       0.76      0.73      0.70       171\n",
      "\n",
      "[ 9  0  8  0  0  0  0 13 10  0  0  0  1  0 76  0  0  1  0  0  1 13  0  0\n",
      "  0  0  9  0  2  2  0  2 11  0  1 12]\n",
      "svc Accuracy:  0.7309941520467836\n",
      "svc F1:  0.6561284627405557\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.11        17\n",
      "          1       0.70      0.30      0.42        23\n",
      "          2       0.55      1.00      0.71        78\n",
      "          3       1.00      0.50      0.67        14\n",
      "          4       0.00      0.00      0.00        13\n",
      "          5       0.73      0.31      0.43        26\n",
      "\n",
      "avg / total       0.64      0.59      0.51       171\n",
      "\n",
      "[ 1  1 14  0  0  1  0  7 16  0  0  0  0  0 78  0  0  0  0  0  7  7  0  0\n",
      "  0  0 11  0  0  2  0  2 16  0  0  8]\n",
      "LR Accuracy:  0.5906432748538012\n",
      "LR F1:  0.3905905905905906\n",
      "For name:  c_cai\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-8701-2586': 28, '0000-0001-9008-6327': 19, '0000-0002-0167-1397': 7, '0000-0002-7213-621X': 2, '0000-0002-5047-0815': 1})\n",
      "['0000-0001-9008-6327', '0000-0002-8701-2586']\n",
      "Total sample size after apply threshold:  47\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 11)\n",
      "2\n",
      "(47, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.68      0.68        19\n",
      "          1       0.79      0.79      0.79        28\n",
      "\n",
      "avg / total       0.74      0.74      0.74        47\n",
      "\n",
      "[13  6  6 22]\n",
      "MNB Accuracy:  0.7446808510638298\n",
      "MNB F1:  0.7349624060150376\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.68      0.74        19\n",
      "          1       0.81      0.89      0.85        28\n",
      "\n",
      "avg / total       0.81      0.81      0.81        47\n",
      "\n",
      "[13  6  3 25]\n",
      "svc Accuracy:  0.8085106382978723\n",
      "svc F1:  0.7951573849878935\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.58      0.63        19\n",
      "          1       0.74      0.82      0.78        28\n",
      "\n",
      "avg / total       0.72      0.72      0.72        47\n",
      "\n",
      "[11  8  5 23]\n",
      "LR Accuracy:  0.723404255319149\n",
      "LR F1:  0.7041162227602906\n",
      "For name:  f_pereira\n",
      "total sample size before apply threshold:  86\n",
      "Counter({'0000-0001-8950-1036': 28, '0000-0002-9381-3320': 21, '0000-0003-3317-8756': 13, '0000-0003-4392-4644': 7, '0000-0003-3421-7833': 4, '0000-0003-2100-0280': 4, '0000-0002-1937-6548': 4, '0000-0002-9602-2452': 3, '0000-0001-9718-3867': 1, '0000-0002-8132-0625': 1})\n",
      "['0000-0003-3317-8756', '0000-0002-9381-3320', '0000-0001-8950-1036']\n",
      "Total sample size after apply threshold:  62\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 15)\n",
      "2\n",
      "(62, 59)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.60      0.71      0.65        21\n",
      "          2       0.63      0.79      0.70        28\n",
      "\n",
      "avg / total       0.49      0.60      0.54        62\n",
      "\n",
      "[ 0  5  8  1 15  5  1  5 22]\n",
      "MNB Accuracy:  0.5967741935483871\n",
      "MNB F1:  0.4501955371520589\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.65      0.62      0.63        21\n",
      "          2       0.61      0.82      0.70        28\n",
      "\n",
      "avg / total       0.49      0.58      0.53        62\n",
      "\n",
      "[ 0  4  9  2 13  6  2  3 23]\n",
      "svc Accuracy:  0.5806451612903226\n",
      "svc F1:  0.4437053461443705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.58      0.67      0.62        21\n",
      "          2       0.61      0.79      0.69        28\n",
      "\n",
      "avg / total       0.47      0.58      0.52        62\n",
      "\n",
      "[ 0  5  8  1 14  6  1  5 22]\n",
      "LR Accuracy:  0.5806451612903226\n",
      "LR F1:  0.43657407407407406\n",
      "For name:  a_vitale\n",
      "total sample size before apply threshold:  56\n",
      "Counter({'0000-0001-5586-2255': 43, '0000-0002-8682-3125': 7, '0000-0002-7339-4034': 4, '0000-0003-4980-5574': 2})\n",
      "['0000-0001-5586-2255']\n",
      "Total sample size after apply threshold:  43\n",
      "For name:  q_yang\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0002-3510-8906': 18, '0000-0001-9849-6996': 17, '0000-0003-4205-1909': 17, '0000-0001-6628-5393': 15, '0000-0002-4378-2335': 10, '0000-0003-4038-2464': 8, '0000-0002-6788-8775': 7, '0000-0003-0279-8784': 5, '0000-0001-6720-8795': 2, '0000-0001-8253-2278': 1, '0000-0002-1437-4498': 1, '0000-0003-2067-5999': 1})\n",
      "['0000-0001-9849-6996', '0000-0001-6628-5393', '0000-0002-4378-2335', '0000-0002-3510-8906', '0000-0003-4205-1909']\n",
      "Total sample size after apply threshold:  77\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 49)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 11)\n",
      "2\n",
      "(77, 60)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.35      0.39        17\n",
      "          1       0.46      0.40      0.43        15\n",
      "          2       1.00      0.60      0.75        10\n",
      "          3       0.73      0.89      0.80        18\n",
      "          4       0.50      0.65      0.56        17\n",
      "\n",
      "avg / total       0.59      0.58      0.58        77\n",
      "\n",
      "[ 6  4  0  2  5  4  6  0  2  3  0  1  6  1  2  1  0  0 16  1  3  2  0  1\n",
      " 11]\n",
      "MNB Accuracy:  0.5844155844155844\n",
      "MNB F1:  0.5859541533735082\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.53      0.55        17\n",
      "          1       0.60      0.60      0.60        15\n",
      "          2       1.00      1.00      1.00        10\n",
      "          3       0.75      0.83      0.79        18\n",
      "          4       0.56      0.53      0.55        17\n",
      "\n",
      "avg / total       0.67      0.68      0.67        77\n",
      "\n",
      "[ 9  3  0  1  4  3  9  0  2  1  0  0 10  0  0  0  1  0 15  2  4  2  0  2\n",
      "  9]\n",
      "svc Accuracy:  0.6753246753246753\n",
      "svc F1:  0.6960765550239234\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.35      0.39        17\n",
      "          1       0.50      0.47      0.48        15\n",
      "          2       1.00      1.00      1.00        10\n",
      "          3       0.80      0.89      0.84        18\n",
      "          4       0.53      0.59      0.56        17\n",
      "\n",
      "avg / total       0.63      0.64      0.63        77\n",
      "\n",
      "[ 6  4  0  2  5  4  7  0  1  3  0  0 10  0  0  0  1  0 16  1  4  2  0  1\n",
      " 10]\n",
      "LR Accuracy:  0.6363636363636364\n",
      "LR F1:  0.6535032427193308\n",
      "For name:  d_xue\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0002-0748-0962': 47, '0000-0002-8429-8136': 45, '0000-0001-9904-7615': 10, '0000-0001-6132-1236': 5, '0000-0003-1938-9055': 2, '0000-0001-5285-8867': 2})\n",
      "['0000-0002-0748-0962', '0000-0002-8429-8136', '0000-0001-9904-7615']\n",
      "Total sample size after apply threshold:  102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(102, 47)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(102, 16)\n",
      "2\n",
      "(102, 63)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.94      0.81        47\n",
      "          1       0.79      0.69      0.74        45\n",
      "          2       0.50      0.10      0.17        10\n",
      "\n",
      "avg / total       0.73      0.75      0.72       102\n",
      "\n",
      "[44  3  0 13 31  1  4  5  1]\n",
      "MNB Accuracy:  0.7450980392156863\n",
      "MNB F1:  0.5731922398589065\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.91      0.93        47\n",
      "          1       0.79      0.93      0.86        45\n",
      "          2       0.75      0.30      0.43        10\n",
      "\n",
      "avg / total       0.86      0.86      0.85       102\n",
      "\n",
      "[43  4  0  2 42  1  0  7  3]\n",
      "svc Accuracy:  0.8627450980392157\n",
      "svc F1:  0.7401656314699793\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.89      0.87        47\n",
      "          1       0.75      0.84      0.79        45\n",
      "          2       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.81      0.79      0.77       102\n",
      "\n",
      "[42  5  0  7 38  0  1  8  1]\n",
      "LR Accuracy:  0.7941176470588235\n",
      "LR F1:  0.6131547433093825\n",
      "For name:  m_sadeghi\n",
      "total sample size before apply threshold:  98\n",
      "Counter({'0000-0003-0401-3493': 54, '0000-0001-5055-4544': 37, '0000-0002-3586-3012': 3, '0000-0002-7698-5630': 3, '0000-0002-0751-1255': 1})\n",
      "['0000-0003-0401-3493', '0000-0001-5055-4544']\n",
      "Total sample size after apply threshold:  91\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 38)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 9)\n",
      "2\n",
      "(91, 47)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.91      0.88        54\n",
      "          1       0.85      0.76      0.80        37\n",
      "\n",
      "avg / total       0.85      0.85      0.84        91\n",
      "\n",
      "[49  5  9 28]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.8375000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        54\n",
      "          1       1.00      0.81      0.90        37\n",
      "\n",
      "avg / total       0.93      0.92      0.92        91\n",
      "\n",
      "[54  0  7 30]\n",
      "svc Accuracy:  0.9230769230769231\n",
      "svc F1:  0.917326411421155\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92        54\n",
      "          1       1.00      0.73      0.84        37\n",
      "\n",
      "avg / total       0.91      0.89      0.89        91\n",
      "\n",
      "[54  0 10 27]\n",
      "LR Accuracy:  0.8901098901098901\n",
      "LR F1:  0.8795021186440677\n",
      "For name:  h_chang\n",
      "total sample size before apply threshold:  182\n",
      "Counter({'0000-0001-5411-6680': 55, '0000-0002-7997-4822': 39, '0000-0002-8417-8847': 22, '0000-0001-8877-1886': 18, '0000-0001-5810-7562': 11, '0000-0001-5577-2356': 9, '0000-0002-9812-8015': 6, '0000-0002-5248-3433': 5, '0000-0003-4987-5943': 4, '0000-0003-1832-8509': 4, '0000-0002-9405-2121': 2, '0000-0001-7378-8212': 2, '0000-0003-4843-1259': 1, '0000-0002-5605-6500': 1, '0000-0002-5162-103X': 1, '0000-0003-0400-3658': 1, '0000-0002-7494-0033': 1})\n",
      "['0000-0002-8417-8847', '0000-0002-7997-4822', '0000-0001-5810-7562', '0000-0001-5411-6680', '0000-0001-8877-1886']\n",
      "Total sample size after apply threshold:  145\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(145, 89)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(145, 20)\n",
      "2\n",
      "(145, 109)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.23      0.30        22\n",
      "          1       0.67      0.77      0.71        39\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.51      0.76      0.61        55\n",
      "          4       0.67      0.22      0.33        18\n",
      "\n",
      "avg / total       0.52      0.56      0.51       145\n",
      "\n",
      "[ 5  1  0 15  1  0 30  0  9  0  0  5  0  6  0  6  6  0 42  1  0  3  0 11\n",
      "  4]\n",
      "MNB Accuracy:  0.5586206896551724\n",
      "MNB F1:  0.3918690005646527\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.41      0.53        22\n",
      "          1       0.74      0.79      0.77        39\n",
      "          2       1.00      0.55      0.71        11\n",
      "          3       0.65      0.87      0.74        55\n",
      "          4       0.82      0.50      0.62        18\n",
      "\n",
      "avg / total       0.74      0.71      0.70       145\n",
      "\n",
      "[ 9  1  0 11  1  0 31  0  8  0  0  3  6  2  0  3  3  0 48  1  0  4  0  5\n",
      "  9]\n",
      "svc Accuracy:  0.7103448275862069\n",
      "svc F1:  0.6731203836193065\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.23      0.33        22\n",
      "          1       0.67      0.67      0.67        39\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.53      0.85      0.65        55\n",
      "          4       0.78      0.39      0.52        18\n",
      "\n",
      "avg / total       0.57      0.59      0.54       145\n",
      "\n",
      "[ 5  1  0 15  1  0 26  0 13  0  0  5  0  6  0  3  4  0 47  1  0  3  0  8\n",
      "  7]\n",
      "LR Accuracy:  0.5862068965517241\n",
      "LR F1:  0.43425925925925923\n",
      "For name:  a_lombardi\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0002-2013-3009': 49, '0000-0001-5421-9970': 21, '0000-0002-7875-2697': 15, '0000-0002-4520-0183': 4, '0000-0002-0383-9579': 1})\n",
      "['0000-0001-5421-9970', '0000-0002-2013-3009', '0000-0002-7875-2697']\n",
      "Total sample size after apply threshold:  85\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 24)\n",
      "2\n",
      "(85, 72)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.62      0.60        21\n",
      "          1       0.82      0.84      0.83        49\n",
      "          2       0.77      0.67      0.71        15\n",
      "\n",
      "avg / total       0.75      0.75      0.75        85\n",
      "\n",
      "[13  7  1  6 41  2  3  2 10]\n",
      "MNB Accuracy:  0.7529411764705882\n",
      "MNB F1:  0.7157399017864133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.81      0.72        21\n",
      "          1       0.91      0.88      0.90        49\n",
      "          2       1.00      0.80      0.89        15\n",
      "\n",
      "avg / total       0.87      0.85      0.85        85\n",
      "\n",
      "[17  4  0  6 43  0  3  0 12]\n",
      "svc Accuracy:  0.8470588235294118\n",
      "svc F1:  0.8360421591804571\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.24      0.30        21\n",
      "          1       0.66      0.88      0.75        49\n",
      "          2       1.00      0.53      0.70        15\n",
      "\n",
      "avg / total       0.66      0.66      0.63        85\n",
      "\n",
      "[ 5 16  0  6 43  0  1  6  8]\n",
      "LR Accuracy:  0.6588235294117647\n",
      "LR F1:  0.5843561472852091\n",
      "For name:  c_correia\n",
      "total sample size before apply threshold:  55\n",
      "Counter({'0000-0001-5564-6675': 20, '0000-0001-5481-2010': 13, '0000-0002-4979-3254': 9, '0000-0002-6996-0734': 6, '0000-0003-2482-7873': 5, '0000-0002-0527-3206': 2})\n",
      "['0000-0001-5564-6675', '0000-0001-5481-2010']\n",
      "Total sample size after apply threshold:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 14)\n",
      "2\n",
      "(33, 33)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.90      0.88        20\n",
      "          1       0.83      0.77      0.80        13\n",
      "\n",
      "avg / total       0.85      0.85      0.85        33\n",
      "\n",
      "[18  2  3 10]\n",
      "MNB Accuracy:  0.8484848484848485\n",
      "MNB F1:  0.8390243902439024\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.80      0.84        20\n",
      "          1       0.73      0.85      0.79        13\n",
      "\n",
      "avg / total       0.83      0.82      0.82        33\n",
      "\n",
      "[16  4  2 11]\n",
      "svc Accuracy:  0.8181818181818182\n",
      "svc F1:  0.8139097744360901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86        20\n",
      "          1       0.82      0.69      0.75        13\n",
      "\n",
      "avg / total       0.82      0.82      0.81        33\n",
      "\n",
      "[18  2  4  9]\n",
      "LR Accuracy:  0.8181818181818182\n",
      "LR F1:  0.8035714285714286\n",
      "For name:  j_you\n",
      "total sample size before apply threshold:  239\n",
      "Counter({'0000-0002-2074-6745': 75, '0000-0002-4006-8339': 71, '0000-0002-5763-7403': 56, '0000-0002-4651-9081': 28, '0000-0001-8927-1015': 9})\n",
      "['0000-0002-5763-7403', '0000-0002-4651-9081', '0000-0002-4006-8339', '0000-0002-2074-6745']\n",
      "Total sample size after apply threshold:  230\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(230, 88)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(230, 15)\n",
      "2\n",
      "(230, 103)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.50      0.57        56\n",
      "          1       1.00      0.54      0.70        28\n",
      "          2       0.74      0.90      0.81        71\n",
      "          3       0.79      0.91      0.84        75\n",
      "\n",
      "avg / total       0.77      0.76      0.75       230\n",
      "\n",
      "[28  0 18 10  3 15  5  5  4  0 64  3  7  0  0 68]\n",
      "MNB Accuracy:  0.7608695652173914\n",
      "MNB F1:  0.7309875173015283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.96      0.79        56\n",
      "          1       1.00      0.71      0.83        28\n",
      "          2       0.98      0.90      0.94        71\n",
      "          3       0.95      0.81      0.88        75\n",
      "\n",
      "avg / total       0.90      0.87      0.87       230\n",
      "\n",
      "[54  0  0  2  8 20  0  0  6  0 64  1 13  0  1 61]\n",
      "svc Accuracy:  0.8652173913043478\n",
      "svc F1:  0.8601322033828497\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.84      0.73        56\n",
      "          1       1.00      0.57      0.73        28\n",
      "          2       0.91      0.89      0.90        71\n",
      "          3       0.86      0.84      0.85        75\n",
      "\n",
      "avg / total       0.84      0.82      0.82       230\n",
      "\n",
      "[47  0  5  4  9 16  0  3  5  0 63  3 11  0  1 63]\n",
      "LR Accuracy:  0.8217391304347826\n",
      "LR F1:  0.8032497696560197\n",
      "For name:  c_lopez\n",
      "total sample size before apply threshold:  53\n",
      "Counter({'0000-0001-9298-2969': 34, '0000-0003-3668-7468': 12, '0000-0001-6160-632X': 3, '0000-0001-5635-4463': 2, '0000-0002-7669-6572': 1, '0000-0002-3445-4284': 1})\n",
      "['0000-0003-3668-7468', '0000-0001-9298-2969']\n",
      "Total sample size after apply threshold:  46\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 13)\n",
      "2\n",
      "(46, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.33      0.40        12\n",
      "          1       0.79      0.88      0.83        34\n",
      "\n",
      "avg / total       0.71      0.74      0.72        46\n",
      "\n",
      "[ 4  8  4 30]\n",
      "MNB Accuracy:  0.7391304347826086\n",
      "MNB F1:  0.6166666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.42      0.48        12\n",
      "          1       0.81      0.88      0.85        34\n",
      "\n",
      "avg / total       0.74      0.76      0.75        46\n",
      "\n",
      "[ 5  7  4 30]\n",
      "svc Accuracy:  0.7608695652173914\n",
      "svc F1:  0.6606304493628438\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.08      0.14        12\n",
      "          1       0.75      0.97      0.85        34\n",
      "\n",
      "avg / total       0.68      0.74      0.66        46\n",
      "\n",
      "[ 1 11  1 33]\n",
      "LR Accuracy:  0.7391304347826086\n",
      "LR F1:  0.4945054945054944\n",
      "For name:  y_oh\n",
      "total sample size before apply threshold:  91\n",
      "Counter({'0000-0002-4438-8890': 55, '0000-0002-9636-3329': 17, '0000-0001-8233-1898': 14, '0000-0002-9055-6250': 2, '0000-0002-3832-6108': 1, '0000-0003-4936-7287': 1, '0000-0003-2761-7820': 1})\n",
      "['0000-0002-4438-8890', '0000-0002-9636-3329', '0000-0001-8233-1898']\n",
      "Total sample size after apply threshold:  86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 16)\n",
      "2\n",
      "(86, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89        55\n",
      "          1       0.73      0.47      0.57        17\n",
      "          2       0.85      0.79      0.81        14\n",
      "\n",
      "avg / total       0.82      0.83      0.81        86\n",
      "\n",
      "[52  2  1  8  8  1  2  1 11]\n",
      "MNB Accuracy:  0.8255813953488372\n",
      "MNB F1:  0.7583774250440917\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.91        55\n",
      "          1       0.90      0.53      0.67        17\n",
      "          2       1.00      0.86      0.92        14\n",
      "\n",
      "avg / total       0.88      0.87      0.86        86\n",
      "\n",
      "[54  1  0  8  9  0  2  0 12]\n",
      "svc Accuracy:  0.872093023255814\n",
      "svc F1:  0.8324355383178913\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        55\n",
      "          1       1.00      0.41      0.58        17\n",
      "          2       1.00      0.71      0.83        14\n",
      "\n",
      "avg / total       0.87      0.84      0.82        86\n",
      "\n",
      "[55  0  0 10  7  0  4  0 10]\n",
      "LR Accuracy:  0.8372093023255814\n",
      "LR F1:  0.767921146953405\n",
      "For name:  s_yoon\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-8556-423X': 27, '0000-0003-3487-6863': 16, '0000-0001-8904-0292': 15, '0000-0003-1787-7282': 8, '0000-0003-1868-1054': 1, '0000-0001-7263-8036': 1, '0000-0001-8323-6462': 1, '0000-0002-5330-8784': 1, '0000-0002-8361-9815': 1, '0000-0003-2695-9589': 1, '0000-0003-1384-3405': 1})\n",
      "['0000-0001-8904-0292', '0000-0002-8556-423X', '0000-0003-3487-6863']\n",
      "Total sample size after apply threshold:  58\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(58, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(58, 17)\n",
      "2\n",
      "(58, 48)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        15\n",
      "          1       0.74      0.63      0.68        27\n",
      "          2       0.60      0.56      0.58        16\n",
      "\n",
      "avg / total       0.70      0.71      0.70        58\n",
      "\n",
      "[15  0  0  4 17  6  1  6  9]\n",
      "MNB Accuracy:  0.7068965517241379\n",
      "MNB F1:  0.7059293394777265\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       0.75      0.78      0.76        27\n",
      "          2       0.60      0.56      0.58        16\n",
      "\n",
      "avg / total       0.77      0.78      0.77        58\n",
      "\n",
      "[15  0  0  0 21  6  0  7  9]\n",
      "svc Accuracy:  0.7758620689655172\n",
      "svc F1:  0.781427174975562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       0.75      0.89      0.81        27\n",
      "          2       0.73      0.50      0.59        16\n",
      "\n",
      "avg / total       0.81      0.81      0.80        58\n",
      "\n",
      "[15  0  0  0 24  3  0  8  8]\n",
      "LR Accuracy:  0.8103448275862069\n",
      "LR F1:  0.8020506382088303\n",
      "For name:  a_lima\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0002-1507-2264': 16, '0000-0002-9779-0584': 12, '0000-0002-3582-2640': 10, '0000-0002-2396-9880': 9, '0000-0003-2261-2801': 8, '0000-0001-6980-6553': 8, '0000-0001-8251-6286': 7, '0000-0002-3714-9904': 5, '0000-0002-1055-0554': 5, '0000-0002-9083-3377': 2, '0000-0002-4473-5311': 2, '0000-0002-4568-9126': 1})\n",
      "['0000-0002-1507-2264', '0000-0002-9779-0584', '0000-0002-3582-2640']\n",
      "Total sample size after apply threshold:  38\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 7)\n",
      "2\n",
      "(38, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.75      0.80        16\n",
      "          1       0.75      0.75      0.75        12\n",
      "          2       0.67      0.80      0.73        10\n",
      "\n",
      "avg / total       0.77      0.76      0.77        38\n",
      "\n",
      "[12  2  2  1  9  2  1  1  8]\n",
      "MNB Accuracy:  0.7631578947368421\n",
      "MNB F1:  0.7590909090909089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.88      0.90        16\n",
      "          1       0.86      1.00      0.92        12\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.93      0.92      0.92        38\n",
      "\n",
      "[14  2  0  0 12  0  1  0  9]\n",
      "svc Accuracy:  0.9210526315789473\n",
      "svc F1:  0.9245570501937225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88        16\n",
      "          1       0.75      0.75      0.75        12\n",
      "          2       0.80      0.80      0.80        10\n",
      "\n",
      "avg / total       0.82      0.82      0.82        38\n",
      "\n",
      "[14  2  0  1  9  2  1  1  8]\n",
      "LR Accuracy:  0.8157894736842105\n",
      "LR F1:  0.8083333333333335\n",
      "For name:  h_singh\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0002-8686-2802': 23, '0000-0002-9586-8544': 7, '0000-0002-6135-1897': 7, '0000-0001-9198-8779': 3, '0000-0002-2354-6474': 2, '0000-0002-1989-9066': 1, '0000-0002-9713-6048': 1, '0000-0003-1653-232X': 1})\n",
      "['0000-0002-8686-2802']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  s_scott\n",
      "total sample size before apply threshold:  143\n",
      "Counter({'0000-0001-7510-6297': 101, '0000-0002-8290-0461': 27, '0000-0002-4597-9094': 8, '0000-0002-8480-1547': 4, '0000-0002-5830-8943': 2, '0000-0002-4754-246X': 1})\n",
      "['0000-0002-8290-0461', '0000-0001-7510-6297']\n",
      "Total sample size after apply threshold:  128\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(128, 61)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(128, 24)\n",
      "2\n",
      "(128, 85)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.63      0.71        27\n",
      "          1       0.91      0.96      0.93       101\n",
      "\n",
      "avg / total       0.89      0.89      0.89       128\n",
      "\n",
      "[17 10  4 97]\n",
      "MNB Accuracy:  0.890625\n",
      "MNB F1:  0.8205128205128205\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.59      0.73        27\n",
      "          1       0.90      0.99      0.94       101\n",
      "\n",
      "avg / total       0.91      0.91      0.90       128\n",
      "\n",
      "[ 16  11   1 100]\n",
      "svc Accuracy:  0.90625\n",
      "svc F1:  0.8353344768439107\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.52      0.68        27\n",
      "          1       0.89      1.00      0.94       101\n",
      "\n",
      "avg / total       0.91      0.90      0.89       128\n",
      "\n",
      "[ 14  13   0 101]\n",
      "LR Accuracy:  0.8984375\n",
      "LR F1:  0.8112308564946115\n",
      "For name:  z_he\n",
      "total sample size before apply threshold:  160\n",
      "Counter({'0000-0002-6098-7893': 46, '0000-0001-6302-6556': 40, '0000-0001-9526-8816': 18, '0000-0003-3507-5013': 18, '0000-0001-6496-3971': 12, '0000-0003-1505-8750': 7, '0000-0003-3608-0244': 6, '0000-0002-3265-7539': 6, '0000-0001-8569-6008': 5, '0000-0003-3947-4011': 1, '0000-0002-8431-5274': 1})\n",
      "['0000-0001-6302-6556', '0000-0001-9526-8816', '0000-0002-6098-7893', '0000-0001-6496-3971', '0000-0003-3507-5013']\n",
      "Total sample size after apply threshold:  134\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 60)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 16)\n",
      "2\n",
      "(134, 76)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.80      0.74        40\n",
      "          1       0.93      0.72      0.81        18\n",
      "          2       0.68      0.78      0.73        46\n",
      "          3       1.00      0.25      0.40        12\n",
      "          4       0.76      0.72      0.74        18\n",
      "\n",
      "avg / total       0.75      0.72      0.71       134\n",
      "\n",
      "[32  0  8  0  0  2 13  3  0  0  6  0 36  0  4  3  1  5  3  0  4  0  1  0\n",
      " 13]\n",
      "MNB Accuracy:  0.7238805970149254\n",
      "MNB F1:  0.6836524108075832\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.80      0.83        40\n",
      "          1       1.00      0.72      0.84        18\n",
      "          2       0.72      0.96      0.82        46\n",
      "          3       1.00      0.67      0.80        12\n",
      "          4       0.80      0.67      0.73        18\n",
      "\n",
      "avg / total       0.84      0.81      0.81       134\n",
      "\n",
      "[32  0  7  0  1  1 13  4  0  0  0  0 44  0  2  1  0  3  8  0  3  0  3  0\n",
      " 12]\n",
      "svc Accuracy:  0.8134328358208955\n",
      "svc F1:  0.803916228480594\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.78      0.84        40\n",
      "          1       0.92      0.61      0.73        18\n",
      "          2       0.63      0.98      0.77        46\n",
      "          3       1.00      0.42      0.59        12\n",
      "          4       0.92      0.61      0.73        18\n",
      "\n",
      "avg / total       0.83      0.77      0.76       134\n",
      "\n",
      "[31  0  9  0  0  0 11  7  0  0  0  0 45  0  1  0  1  6  5  0  3  0  4  0\n",
      " 11]\n",
      "LR Accuracy:  0.7686567164179104\n",
      "LR F1:  0.7323941135705843\n",
      "For name:  s_mukherjee\n",
      "total sample size before apply threshold:  125\n",
      "Counter({'0000-0002-6715-3920': 38, '0000-0003-2522-2884': 20, '0000-0002-3295-9668': 17, '0000-0001-6031-2557': 13, '0000-0002-2932-2834': 8, '0000-0002-2449-2826': 5, '0000-0002-5479-3750': 5, '0000-0002-3417-4530': 3, '0000-0001-8371-4014': 3, '0000-0002-8445-0492': 3, '0000-0003-4794-137X': 2, '0000-0001-8743-7050': 2, '0000-0003-1668-0461': 2, '0000-0003-4176-3496': 1, '0000-0001-9651-6228': 1, '0000-0001-7299-0304': 1, '0000-0002-6157-1224': 1})\n",
      "['0000-0001-6031-2557', '0000-0002-3295-9668', '0000-0002-6715-3920', '0000-0003-2522-2884']\n",
      "Total sample size after apply threshold:  88\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 61)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 16)\n",
      "2\n",
      "(88, 77)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.45      0.29      0.36        17\n",
      "          2       0.70      0.82      0.76        38\n",
      "          3       0.47      0.75      0.58        20\n",
      "\n",
      "avg / total       0.50      0.58      0.53        88\n",
      "\n",
      "[ 0  2  3  8  0  5  8  4  0  2 31  5  1  2  2 15]\n",
      "MNB Accuracy:  0.5795454545454546\n",
      "MNB F1:  0.42254087376038596\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.15      0.24        13\n",
      "          1       0.50      0.18      0.26        17\n",
      "          2       0.59      0.89      0.71        38\n",
      "          3       0.65      0.65      0.65        20\n",
      "\n",
      "avg / total       0.57      0.59      0.54        88\n",
      "\n",
      "[ 2  1  6  4  0  3 13  1  0  2 34  2  2  0  5 13]\n",
      "svc Accuracy:  0.5909090909090909\n",
      "svc F1:  0.46362425404944585\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       0.60      0.18      0.27        17\n",
      "          2       0.56      0.92      0.69        38\n",
      "          3       0.78      0.70      0.74        20\n",
      "\n",
      "avg / total       0.68      0.61      0.56        88\n",
      "\n",
      "[ 2  0  9  2  0  3 13  1  0  2 35  1  0  0  6 14]\n",
      "LR Accuracy:  0.6136363636363636\n",
      "LR F1:  0.4923263378969475\n",
      "For name:  j_yue\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0001-9694-7722': 25, '0000-0001-6384-5447': 24, '0000-0002-2122-9221': 9, '0000-0002-2549-9261': 2, '0000-0003-4043-0737': 2})\n",
      "['0000-0001-6384-5447', '0000-0001-9694-7722']\n",
      "Total sample size after apply threshold:  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 27)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 12)\n",
      "2\n",
      "(49, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.71      0.79        24\n",
      "          1       0.77      0.92      0.84        25\n",
      "\n",
      "avg / total       0.83      0.82      0.81        49\n",
      "\n",
      "[17  7  2 23]\n",
      "MNB Accuracy:  0.8163265306122449\n",
      "MNB F1:  0.8135306553911205\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90        24\n",
      "          1       0.95      0.84      0.89        25\n",
      "\n",
      "avg / total       0.90      0.90      0.90        49\n",
      "\n",
      "[23  1  4 21]\n",
      "svc Accuracy:  0.8979591836734694\n",
      "svc F1:  0.8977889027951607\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90        24\n",
      "          1       0.95      0.84      0.89        25\n",
      "\n",
      "avg / total       0.90      0.90      0.90        49\n",
      "\n",
      "[23  1  4 21]\n",
      "LR Accuracy:  0.8979591836734694\n",
      "LR F1:  0.8977889027951607\n",
      "For name:  f_dias\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0001-9841-863X': 25, '0000-0001-9945-9185': 21, '0000-0002-5123-4929': 15, '0000-0002-4993-4467': 7})\n",
      "['0000-0001-9841-863X', '0000-0001-9945-9185', '0000-0002-5123-4929']\n",
      "Total sample size after apply threshold:  61\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 13)\n",
      "2\n",
      "(61, 43)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.88      0.77        25\n",
      "          1       0.63      0.57      0.60        21\n",
      "          2       0.60      0.40      0.48        15\n",
      "\n",
      "avg / total       0.65      0.66      0.64        61\n",
      "\n",
      "[22  2  1  6 12  3  4  5  6]\n",
      "MNB Accuracy:  0.6557377049180327\n",
      "MNB F1:  0.6173099415204678\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.88      0.86        25\n",
      "          1       0.70      0.90      0.79        21\n",
      "          2       1.00      0.53      0.70        15\n",
      "\n",
      "avg / total       0.83      0.80      0.80        61\n",
      "\n",
      "[22  3  0  2 19  0  2  5  8]\n",
      "svc Accuracy:  0.8032786885245902\n",
      "svc F1:  0.7833546462063086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.88      0.75        25\n",
      "          1       0.60      0.57      0.59        21\n",
      "          2       0.86      0.40      0.55        15\n",
      "\n",
      "avg / total       0.68      0.66      0.64        61\n",
      "\n",
      "[22  3  0  8 12  1  4  5  6]\n",
      "LR Accuracy:  0.6557377049180327\n",
      "LR F1:  0.6255277036591629\n",
      "For name:  r_walker\n",
      "total sample size before apply threshold:  87\n",
      "Counter({'0000-0002-5936-1068': 25, '0000-0003-0348-2407': 16, '0000-0001-7383-7846': 15, '0000-0002-6089-8225': 11, '0000-0003-0032-9925': 10, '0000-0001-9736-3497': 7, '0000-0002-2064-4546': 2, '0000-0002-5332-3562': 1})\n",
      "['0000-0001-7383-7846', '0000-0003-0348-2407', '0000-0002-5936-1068', '0000-0003-0032-9925', '0000-0002-6089-8225']\n",
      "Total sample size after apply threshold:  77\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 52)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 19)\n",
      "2\n",
      "(77, 71)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.40      0.46        15\n",
      "          1       0.83      0.62      0.71        16\n",
      "          2       0.53      0.80      0.63        25\n",
      "          3       0.67      0.20      0.31        10\n",
      "          4       0.46      0.55      0.50        11\n",
      "\n",
      "avg / total       0.60      0.57      0.56        77\n",
      "\n",
      "[ 6  2  4  0  3  1 10  5  0  0  1  0 20  1  3  2  0  5  2  1  1  0  4  0\n",
      "  6]\n",
      "MNB Accuracy:  0.5714285714285714\n",
      "MNB F1:  0.5236874236874236\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.47      0.47        15\n",
      "          1       1.00      0.75      0.86        16\n",
      "          2       0.47      0.72      0.57        25\n",
      "          3       0.40      0.20      0.27        10\n",
      "          4       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.65      0.60      0.60        77\n",
      "\n",
      "[ 7  0  7  1  0  0 12  4  0  0  5  0 18  2  0  3  0  5  2  0  0  0  4  0\n",
      "  7]\n",
      "svc Accuracy:  0.5974025974025974\n",
      "svc F1:  0.5879365079365079\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.40      0.44        15\n",
      "          1       1.00      0.69      0.81        16\n",
      "          2       0.50      0.88      0.64        25\n",
      "          3       0.67      0.20      0.31        10\n",
      "          4       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.70      0.62      0.61        77\n",
      "\n",
      "[ 6  0  8  1  0  0 11  5  0  0  3  0 22  0  0  3  0  5  2  0  0  0  4  0\n",
      "  7]\n",
      "LR Accuracy:  0.6233766233766234\n",
      "LR F1:  0.5964821008299268\n",
      "For name:  l_campos\n",
      "total sample size before apply threshold:  12\n",
      "Counter({'0000-0001-5414-8746': 10, '0000-0003-2431-3274': 1, '0000-0002-1610-7617': 1})\n",
      "['0000-0001-5414-8746']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  m_iqbal\n",
      "total sample size before apply threshold:  8\n",
      "Counter({'0000-0001-5891-9798': 3, '0000-0003-4790-3584': 2, '0000-0001-6241-7547': 2, '0000-0002-5535-0839': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_lim\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5475-4153': 27, '0000-0002-0360-6361': 23, '0000-0002-5192-0486': 20, '0000-0001-7589-5150': 15, '0000-0003-3807-4163': 13, '0000-0001-8471-5684': 6, '0000-0003-4528-8514': 6, '0000-0001-9086-5101': 5, '0000-0003-0312-9937': 5, '0000-0002-4890-0396': 4, '0000-0003-0377-9032': 3, '0000-0003-4246-6223': 3, '0000-0002-9783-9050': 1, '0000-0002-9907-0628': 1, '0000-0003-0845-9994': 1, '0000-0003-0598-4574': 1, '0000-0002-9460-5136': 1, '0000-0003-0204-4990': 1})\n",
      "['0000-0003-3807-4163', '0000-0002-5475-4153', '0000-0001-7589-5150', '0000-0002-0360-6361', '0000-0002-5192-0486']\n",
      "Total sample size after apply threshold:  98\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 62)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 13)\n",
      "2\n",
      "(98, 75)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       0.63      0.63      0.63        27\n",
      "          2       0.53      0.53      0.53        15\n",
      "          3       0.62      0.65      0.64        23\n",
      "          4       0.53      0.80      0.64        20\n",
      "\n",
      "avg / total       0.64      0.59      0.57        98\n",
      "\n",
      "[ 2  2  5  2  2  0 17  0  6  4  0  3  8  0  4  0  3  1 15  4  0  2  1  1\n",
      " 16]\n",
      "MNB Accuracy:  0.5918367346938775\n",
      "MNB F1:  0.541585500394011\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.23      0.35        13\n",
      "          1       0.59      0.70      0.64        27\n",
      "          2       0.60      0.80      0.69        15\n",
      "          3       0.68      0.65      0.67        23\n",
      "          4       0.80      0.80      0.80        20\n",
      "\n",
      "avg / total       0.68      0.66      0.65        98\n",
      "\n",
      "[ 3  4  5  1  0  0 19  1  5  2  0  2 12  0  1  1  5  1 15  1  0  2  1  1\n",
      " 16]\n",
      "svc Accuracy:  0.6632653061224489\n",
      "svc F1:  0.629877985092342\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.23      0.38        13\n",
      "          1       0.67      0.59      0.63        27\n",
      "          2       0.53      0.60      0.56        15\n",
      "          3       0.64      0.78      0.71        23\n",
      "          4       0.58      0.75      0.65        20\n",
      "\n",
      "avg / total       0.67      0.62      0.61        98\n",
      "\n",
      "[ 3  2  5  2  1  0 16  0  7  4  0  2  9  0  4  0  2  1 18  2  0  2  2  1\n",
      " 15]\n",
      "LR Accuracy:  0.6224489795918368\n",
      "LR F1:  0.5846014492753623\n",
      "For name:  p_li\n",
      "total sample size before apply threshold:  118\n",
      "Counter({'0000-0002-5715-548X': 20, '0000-0001-9602-9550': 18, '0000-0001-9098-7598': 14, '0000-0002-5876-2177': 9, '0000-0001-5836-1069': 9, '0000-0002-2572-5935': 7, '0000-0001-9339-3111': 7, '0000-0002-4273-4577': 7, '0000-0002-4684-4909': 6, '0000-0001-8771-3369': 5, '0000-0001-7960-1025': 4, '0000-0002-5192-8509': 4, '0000-0001-5761-9435': 3, '0000-0001-7603-7852': 2, '0000-0002-9330-5713': 1, '0000-0002-7112-9974': 1, '0000-0002-9445-506X': 1})\n",
      "['0000-0001-9098-7598', '0000-0001-9602-9550', '0000-0002-5715-548X']\n",
      "Total sample size after apply threshold:  52\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 33)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 14)\n",
      "2\n",
      "(52, 47)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.29      0.35        14\n",
      "          1       0.67      0.67      0.67        18\n",
      "          2       0.72      0.90      0.80        20\n",
      "\n",
      "avg / total       0.63      0.65      0.63        52\n",
      "\n",
      "[ 4  5  5  4 12  2  1  1 18]\n",
      "MNB Accuracy:  0.6538461538461539\n",
      "MNB F1:  0.6048309178743961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.29      0.31        14\n",
      "          1       0.63      0.67      0.65        18\n",
      "          2       0.81      0.85      0.83        20\n",
      "\n",
      "avg / total       0.62      0.63      0.63        52\n",
      "\n",
      "[ 4  6  4  6 12  0  2  1 17]\n",
      "svc Accuracy:  0.6346153846153846\n",
      "svc F1:  0.595203083007961\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.29      0.33        14\n",
      "          1       0.57      0.67      0.62        18\n",
      "          2       0.76      0.80      0.78        20\n",
      "\n",
      "avg / total       0.60      0.62      0.60        52\n",
      "\n",
      "[ 4  6  4  5 12  1  1  3 16]\n",
      "LR Accuracy:  0.6153846153846154\n",
      "LR F1:  0.5764019178653325\n",
      "For name:  f_andrade\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0002-3856-3816': 12, '0000-0003-1199-2837': 12, '0000-0002-4947-2346': 11, '0000-0001-6257-1712': 2})\n",
      "['0000-0002-4947-2346', '0000-0002-3856-3816', '0000-0003-1199-2837']\n",
      "Total sample size after apply threshold:  35\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 9)\n",
      "2\n",
      "(35, 40)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.09      0.12        11\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.39      0.75      0.51        12\n",
      "\n",
      "avg / total       0.19      0.29      0.21        35\n",
      "\n",
      "[1 4 6 4 0 8 1 2 9]\n",
      "MNB Accuracy:  0.2857142857142857\n",
      "MNB F1:  0.21064425770308126\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.22      0.18      0.20        11\n",
      "          1       0.27      0.33      0.30        12\n",
      "          2       0.73      0.67      0.70        12\n",
      "\n",
      "avg / total       0.41      0.40      0.40        35\n",
      "\n",
      "[2 8 1 6 4 2 1 3 8]\n",
      "svc Accuracy:  0.4\n",
      "svc F1:  0.39731615673644655\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.18      0.19        11\n",
      "          1       0.33      0.33      0.33        12\n",
      "          2       0.62      0.67      0.64        12\n",
      "\n",
      "avg / total       0.39      0.40      0.39        35\n",
      "\n",
      "[2 6 3 6 4 2 2 2 8]\n",
      "LR Accuracy:  0.4\n",
      "LR F1:  0.38793650793650797\n",
      "For name:  c_schmitt\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0003-2143-9226': 9, '0000-0002-7646-4739': 2, '0000-0003-3829-6970': 1, '0000-0002-8527-9682': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_tan\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0003-1228-9449': 40, '0000-0001-6624-1593': 18, '0000-0002-7589-602X': 11, '0000-0002-8547-6328': 3, '0000-0001-5329-7192': 1})\n",
      "['0000-0002-7589-602X', '0000-0001-6624-1593', '0000-0003-1228-9449']\n",
      "Total sample size after apply threshold:  69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 52)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 19)\n",
      "2\n",
      "(69, 71)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.09      0.15        11\n",
      "          1       0.58      0.83      0.68        18\n",
      "          2       0.88      0.90      0.89        40\n",
      "\n",
      "avg / total       0.74      0.75      0.72        69\n",
      "\n",
      "[ 1  7  3  1 15  2  0  4 36]\n",
      "MNB Accuracy:  0.7536231884057971\n",
      "MNB F1:  0.5748510748510749\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.45      0.59        11\n",
      "          1       0.71      0.83      0.77        18\n",
      "          2       0.90      0.95      0.93        40\n",
      "\n",
      "avg / total       0.84      0.84      0.83        69\n",
      "\n",
      "[ 5  4  2  1 15  2  0  2 38]\n",
      "svc Accuracy:  0.8405797101449275\n",
      "svc F1:  0.7614317772136997\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.62      0.83      0.71        18\n",
      "          2       0.86      0.95      0.90        40\n",
      "\n",
      "avg / total       0.66      0.77      0.71        69\n",
      "\n",
      "[ 0  7  4  1 15  2  0  2 38]\n",
      "LR Accuracy:  0.7681159420289855\n",
      "LR F1:  0.5396825396825397\n",
      "For name:  h_gomes\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0003-1131-7604': 7, '0000-0001-6898-2408': 2, '0000-0003-3664-4740': 1, '0000-0002-6222-9180': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_matos\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0001-6998-5133': 27, '0000-0002-9584-6636': 21, '0000-0003-1358-1054': 15, '0000-0001-7320-7107': 14, '0000-0002-5240-8070': 3, '0000-0003-4076-2459': 1, '0000-0003-1692-2205': 1})\n",
      "['0000-0003-1358-1054', '0000-0002-9584-6636', '0000-0001-7320-7107', '0000-0001-6998-5133']\n",
      "Total sample size after apply threshold:  77\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 15)\n",
      "2\n",
      "(77, 59)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.85        15\n",
      "          1       0.40      0.29      0.33        21\n",
      "          2       0.53      0.57      0.55        14\n",
      "          3       0.56      0.74      0.63        27\n",
      "\n",
      "avg / total       0.60      0.58      0.58        77\n",
      "\n",
      "[11  1  1  2  0  6  4 11  0  3  8  3  0  5  2 20]\n",
      "MNB Accuracy:  0.5844155844155844\n",
      "MNB F1:  0.5915329880847121\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       0.54      0.71      0.61        21\n",
      "          2       0.91      0.71      0.80        14\n",
      "          3       0.77      0.74      0.75        27\n",
      "\n",
      "avg / total       0.78      0.74      0.75        77\n",
      "\n",
      "[12  2  1  0  0 15  0  6  0  4 10  0  0  7  0 20]\n",
      "svc Accuracy:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7402597402597403\n",
      "svc F1:  0.7639626919950371\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.85        15\n",
      "          1       0.48      0.48      0.48        21\n",
      "          2       0.67      0.57      0.62        14\n",
      "          3       0.61      0.74      0.67        27\n",
      "\n",
      "avg / total       0.66      0.64      0.64        77\n",
      "\n",
      "[11  1  1  2  0 10  3  8  0  3  8  3  0  7  0 20]\n",
      "LR Accuracy:  0.6363636363636364\n",
      "LR F1:  0.651098901098901\n",
      "For name:  k_ryan\n",
      "total sample size before apply threshold:  182\n",
      "Counter({'0000-0002-1059-9681': 79, '0000-0003-3670-8505': 36, '0000-0001-5304-2026': 23, '0000-0003-4563-3744': 22, '0000-0001-9149-260X': 11, '0000-0002-0582-3693': 7, '0000-0002-9454-8768': 3, '0000-0002-6057-452X': 1})\n",
      "['0000-0001-9149-260X', '0000-0003-3670-8505', '0000-0001-5304-2026', '0000-0003-4563-3744', '0000-0002-1059-9681']\n",
      "Total sample size after apply threshold:  171\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(171, 83)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(171, 25)\n",
      "2\n",
      "(171, 108)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17        11\n",
      "          1       0.67      0.81      0.73        36\n",
      "          2       0.78      0.30      0.44        23\n",
      "          3       0.89      0.36      0.52        22\n",
      "          4       0.69      0.95      0.80        79\n",
      "\n",
      "avg / total       0.74      0.70      0.66       171\n",
      "\n",
      "[ 1  1  1  0  8  0 29  1  0  6  0  6  7  1  9  0  3  0  8 11  0  4  0  0\n",
      " 75]\n",
      "MNB Accuracy:  0.7017543859649122\n",
      "MNB F1:  0.5304690509080273\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       0.89      0.89      0.89        36\n",
      "          2       0.79      0.48      0.59        23\n",
      "          3       0.80      0.55      0.65        22\n",
      "          4       0.74      0.95      0.83        79\n",
      "\n",
      "avg / total       0.80      0.79      0.78       171\n",
      "\n",
      "[ 5  0  0  0  6  0 32  1  0  3  0  4 11  1  7  0  0  0 12 10  0  0  2  2\n",
      " 75]\n",
      "svc Accuracy:  0.7894736842105263\n",
      "svc F1:  0.7180930930930931\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17        11\n",
      "          1       0.82      0.75      0.78        36\n",
      "          2       0.60      0.13      0.21        23\n",
      "          3       0.78      0.32      0.45        22\n",
      "          4       0.63      0.99      0.77        79\n",
      "\n",
      "avg / total       0.71      0.68      0.62       171\n",
      "\n",
      "[ 1  0  1  0  9  0 27  1  0  8  0  4  3  2 14  0  1  0  7 14  0  1  0  0\n",
      " 78]\n",
      "LR Accuracy:  0.6783625730994152\n",
      "LR F1:  0.4774902415106267\n",
      "For name:  w_zheng\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-6236-9765': 48, '0000-0003-1034-0757': 24, '0000-0003-0021-6672': 9, '0000-0003-0799-3474': 7, '0000-0002-9915-6982': 3, '0000-0002-1750-4999': 2})\n",
      "['0000-0002-6236-9765', '0000-0003-1034-0757']\n",
      "Total sample size after apply threshold:  72\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 14)\n",
      "2\n",
      "(72, 42)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91        48\n",
      "          1       0.94      0.67      0.78        24\n",
      "\n",
      "avg / total       0.88      0.88      0.87        72\n",
      "\n",
      "[47  1  8 16]\n",
      "MNB Accuracy:  0.875\n",
      "MNB F1:  0.8465545820506748\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        48\n",
      "          1       1.00      0.71      0.83        24\n",
      "\n",
      "avg / total       0.92      0.90      0.90        72\n",
      "\n",
      "[48  0  7 17]\n",
      "svc Accuracy:  0.9027777777777778\n",
      "svc F1:  0.8806535638171915\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        48\n",
      "          1       1.00      0.58      0.74        24\n",
      "\n",
      "avg / total       0.89      0.86      0.85        72\n",
      "\n",
      "[48  0 10 14]\n",
      "LR Accuracy:  0.8611111111111112\n",
      "LR F1:  0.8212512413108242\n",
      "For name:  j_franco\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0002-3874-8618': 46, '0000-0001-9255-8084': 16, '0000-0002-0898-3510': 13, '0000-0002-3165-394X': 9, '0000-0002-8249-5224': 1})\n",
      "['0000-0001-9255-8084', '0000-0002-3874-8618', '0000-0002-0898-3510']\n",
      "Total sample size after apply threshold:  75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(75, 50)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(75, 14)\n",
      "2\n",
      "(75, 64)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.31      0.38        16\n",
      "          1       0.74      0.91      0.82        46\n",
      "          2       0.75      0.46      0.57        13\n",
      "\n",
      "avg / total       0.69      0.71      0.68        75\n",
      "\n",
      "[ 5 10  1  3 42  1  2  5  6]\n",
      "MNB Accuracy:  0.7066666666666667\n",
      "MNB F1:  0.5905259788754934\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.44      0.52        16\n",
      "          1       0.81      0.96      0.88        46\n",
      "          2       0.90      0.69      0.78        13\n",
      "\n",
      "avg / total       0.79      0.80      0.79        75\n",
      "\n",
      "[ 7  8  1  2 44  0  2  2  9]\n",
      "svc Accuracy:  0.8\n",
      "svc F1:  0.7270424047235641\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.19      0.32        16\n",
      "          1       0.70      1.00      0.82        46\n",
      "          2       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.81      0.73      0.68        75\n",
      "\n",
      "[ 3 13  0  0 46  0  0  7  6]\n",
      "LR Accuracy:  0.7333333333333333\n",
      "LR F1:  0.5895989974937343\n",
      "For name:  l_walker\n",
      "total sample size before apply threshold:  194\n",
      "Counter({'0000-0001-9166-3261': 107, '0000-0001-5986-5015': 42, '0000-0003-2556-8076': 29, '0000-0001-5865-7257': 12, '0000-0002-6939-9721': 2, '0000-0001-9726-1853': 1, '0000-0001-8375-8041': 1})\n",
      "['0000-0003-2556-8076', '0000-0001-9166-3261', '0000-0001-5865-7257', '0000-0001-5986-5015']\n",
      "Total sample size after apply threshold:  190\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(190, 97)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(190, 35)\n",
      "2\n",
      "(190, 132)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.55      0.65        29\n",
      "          1       0.72      0.93      0.81       107\n",
      "          2       1.00      0.17      0.29        12\n",
      "          3       0.77      0.55      0.64        42\n",
      "\n",
      "avg / total       0.76      0.74      0.71       190\n",
      "\n",
      "[16 11  0  2  3 99  0  5  0 10  2  0  1 18  0 23]\n",
      "MNB Accuracy:  0.7368421052631579\n",
      "MNB F1:  0.5964569160997732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.66      0.78        29\n",
      "          1       0.77      0.96      0.86       107\n",
      "          2       1.00      0.50      0.67        12\n",
      "          3       0.90      0.67      0.77        42\n",
      "\n",
      "avg / total       0.84      0.82      0.81       190\n",
      "\n",
      "[ 19  10   0   0   1 103   0   3   0   6   6   0   0  14   0  28]\n",
      "svc Accuracy:  0.8210526315789474\n",
      "svc F1:  0.7669083729382163\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        29\n",
      "          1       0.70      1.00      0.83       107\n",
      "          2       1.00      0.25      0.40        12\n",
      "          3       0.95      0.43      0.59        42\n",
      "\n",
      "avg / total       0.82      0.76      0.73       190\n",
      "\n",
      "[ 16  12   0   1   0 107   0   0   0   9   3   0   0  24   0  18]\n",
      "LR Accuracy:  0.7578947368421053\n",
      "LR F1:  0.6318824679480417\n",
      "For name:  a_gordon\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0003-1676-9853': 36, '0000-0002-0419-547X': 29, '0000-0002-9352-7877': 27, '0000-0002-1807-4644': 25, '0000-0002-0648-0346': 6, '0000-0002-5731-7215': 1, '0000-0003-2643-5419': 1, '0000-0001-6480-6095': 1})\n",
      "['0000-0003-1676-9853', '0000-0002-1807-4644', '0000-0002-0419-547X', '0000-0002-9352-7877']\n",
      "Total sample size after apply threshold:  117\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 52)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 14)\n",
      "2\n",
      "(117, 66)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.83      0.71        36\n",
      "          1       0.70      0.64      0.67        25\n",
      "          2       0.72      0.62      0.67        29\n",
      "          3       0.57      0.44      0.50        27\n",
      "\n",
      "avg / total       0.65      0.65      0.64       117\n",
      "\n",
      "[30  2  1  3  5 16  1  3  5  3 18  3  8  2  5 12]\n",
      "MNB Accuracy:  0.6495726495726496\n",
      "MNB F1:  0.6369047619047619\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.83      0.78        36\n",
      "          1       0.90      0.72      0.80        25\n",
      "          2       0.69      0.69      0.69        29\n",
      "          3       0.56      0.56      0.56        27\n",
      "\n",
      "avg / total       0.72      0.71      0.71       117\n",
      "\n",
      "[30  0  3  3  1 18  2  4  4  0 20  5  6  2  4 15]\n",
      "svc Accuracy:  0.7094017094017094\n",
      "svc F1:  0.706107876797532\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.81      0.75        36\n",
      "          1       0.78      0.72      0.75        25\n",
      "          2       0.68      0.66      0.67        29\n",
      "          3       0.56      0.52      0.54        27\n",
      "\n",
      "avg / total       0.68      0.68      0.68       117\n",
      "\n",
      "[29  2  2  3  1 18  2  4  4  2 19  4  7  1  5 14]\n",
      "LR Accuracy:  0.6837606837606838\n",
      "LR F1:  0.6770937395937395\n",
      "For name:  z_yin\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0003-1752-644X': 12, '0000-0002-3547-0606': 12, '0000-0002-7189-895X': 6, '0000-0002-4545-1783': 6, '0000-0002-1252-7809': 5, '0000-0003-4396-0215': 4, '0000-0001-8679-5251': 3, '0000-0001-5141-1967': 1, '0000-0002-7567-9084': 1, '0000-0003-0255-4421': 1, '0000-0002-7572-1748': 1})\n",
      "['0000-0003-1752-644X', '0000-0002-3547-0606']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  24\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 7)\n",
      "2\n",
      "(24, 30)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.75      0.67        12\n",
      "          1       0.67      0.50      0.57        12\n",
      "\n",
      "avg / total       0.63      0.62      0.62        24\n",
      "\n",
      "[9 3 6 6]\n",
      "MNB Accuracy:  0.625\n",
      "MNB F1:  0.6190476190476191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.75      0.67        12\n",
      "          1       0.67      0.50      0.57        12\n",
      "\n",
      "avg / total       0.63      0.62      0.62        24\n",
      "\n",
      "[9 3 6 6]\n",
      "svc Accuracy:  0.625\n",
      "svc F1:  0.6190476190476191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.75      0.67        12\n",
      "          1       0.67      0.50      0.57        12\n",
      "\n",
      "avg / total       0.63      0.62      0.62        24\n",
      "\n",
      "[9 3 6 6]\n",
      "LR Accuracy:  0.625\n",
      "LR F1:  0.6190476190476191\n",
      "For name:  c_gu\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0002-8527-8145': 57, '0000-0002-8152-1400': 4, '0000-0002-9294-314X': 3, '0000-0002-3571-4658': 1})\n",
      "['0000-0002-8527-8145']\n",
      "Total sample size after apply threshold:  57\n",
      "For name:  a_soto\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0002-0144-1399': 17, '0000-0001-9672-9004': 5, '0000-0002-7265-0956': 4, '0000-0002-2641-9032': 3, '0000-0001-8648-8032': 3})\n",
      "['0000-0002-0144-1399']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  h_hsieh\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0001-8302-2472': 53, '0000-0003-3201-3677': 13, '0000-0002-2583-7670': 3, '0000-0002-4483-1768': 1})\n",
      "['0000-0003-3201-3677', '0000-0001-8302-2472']\n",
      "Total sample size after apply threshold:  66\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 15)\n",
      "2\n",
      "(66, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.38      0.50        13\n",
      "          1       0.86      0.96      0.91        53\n",
      "\n",
      "avg / total       0.83      0.85      0.83        66\n",
      "\n",
      "[ 5  8  2 51]\n",
      "MNB Accuracy:  0.8484848484848485\n",
      "MNB F1:  0.7053571428571428\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.62      0.70        13\n",
      "          1       0.91      0.96      0.94        53\n",
      "\n",
      "avg / total       0.89      0.89      0.89        66\n",
      "\n",
      "[ 8  5  2 51]\n",
      "svc Accuracy:  0.8939393939393939\n",
      "svc F1:  0.8157159952134025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.23      0.38        13\n",
      "          1       0.84      1.00      0.91        53\n",
      "\n",
      "avg / total       0.87      0.85      0.81        66\n",
      "\n",
      "[ 3 10  0 53]\n",
      "LR Accuracy:  0.8484848484848485\n",
      "LR F1:  0.6443965517241379\n",
      "For name:  m_crespo\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0002-7732-7808': 20, '0000-0002-1852-2259': 12, '0000-0001-8762-7874': 9, '0000-0002-7086-9751': 8})\n",
      "['0000-0002-7732-7808', '0000-0002-1852-2259']\n",
      "Total sample size after apply threshold:  32\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 27)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 12)\n",
      "2\n",
      "(32, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80        20\n",
      "          1       0.67      0.67      0.67        12\n",
      "\n",
      "avg / total       0.75      0.75      0.75        32\n",
      "\n",
      "[16  4  4  8]\n",
      "MNB Accuracy:  0.75\n",
      "MNB F1:  0.7333333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.80      0.78        20\n",
      "          1       0.64      0.58      0.61        12\n",
      "\n",
      "avg / total       0.71      0.72      0.72        32\n",
      "\n",
      "[16  4  5  7]\n",
      "svc Accuracy:  0.71875\n",
      "svc F1:  0.694591728525981\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.85      0.74        20\n",
      "          1       0.50      0.25      0.33        12\n",
      "\n",
      "avg / total       0.60      0.62      0.59        32\n",
      "\n",
      "[17  3  9  3]\n",
      "LR Accuracy:  0.625\n",
      "LR F1:  0.5362318840579711\n",
      "For name:  s_phillips\n",
      "total sample size before apply threshold:  183\n",
      "Counter({'0000-0002-1956-4098': 138, '0000-0002-5694-0670': 20, '0000-0002-2549-8111': 11, '0000-0001-7157-4122': 6, '0000-0002-3720-6470': 5, '0000-0002-4230-4454': 2, '0000-0003-0858-4701': 1})\n",
      "['0000-0002-1956-4098', '0000-0002-5694-0670', '0000-0002-2549-8111']\n",
      "Total sample size after apply threshold:  169\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 60)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(169, 16)\n",
      "2\n",
      "(169, 76)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91       138\n",
      "          1       0.75      0.30      0.43        20\n",
      "          2       0.67      0.18      0.29        11\n",
      "\n",
      "avg / total       0.83      0.85      0.81       169\n",
      "\n",
      "[135   2   1  14   6   0   9   0   2]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.5421492921492922\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       138\n",
      "          1       0.79      0.55      0.65        20\n",
      "          2       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.88      0.88      0.85       169\n",
      "\n",
      "[135   3   0   9  11   0   9   0   2]\n",
      "svc Accuracy:  0.8757396449704142\n",
      "svc F1:  0.6275287275893705\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90       138\n",
      "          1       0.00      0.00      0.00        20\n",
      "          2       1.00      0.09      0.17        11\n",
      "\n",
      "avg / total       0.74      0.82      0.75       169\n",
      "\n",
      "[137   1   0  20   0   0   9   1   1]\n",
      "LR Accuracy:  0.8165680473372781\n",
      "LR F1:  0.3559941520467837\n",
      "For name:  r_rodrigues\n",
      "total sample size before apply threshold:  74\n",
      "Counter({'0000-0002-7631-743X': 30, '0000-0001-8592-850X': 22, '0000-0002-7557-1815': 10, '0000-0002-5894-2506': 2, '0000-0003-4493-2654': 2, '0000-0002-0437-2798': 2, '0000-0002-7589-7807': 1, '0000-0002-4261-1147': 1, '0000-0002-5115-6991': 1, '0000-0001-5631-0970': 1, '0000-0003-3522-9844': 1, '0000-0002-9952-3834': 1})\n",
      "['0000-0002-7557-1815', '0000-0002-7631-743X', '0000-0001-8592-850X']\n",
      "Total sample size after apply threshold:  62\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 38)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 14)\n",
      "2\n",
      "(62, 52)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       0.76      0.93      0.84        30\n",
      "          2       0.87      0.91      0.89        22\n",
      "\n",
      "avg / total       0.84      0.81      0.77        62\n",
      "\n",
      "[ 2  7  1  0 28  2  0  2 20]\n",
      "MNB Accuracy:  0.8064516129032258\n",
      "MNB F1:  0.6860143725815367\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.75      0.90      0.82        30\n",
      "          2       0.86      0.82      0.84        22\n",
      "\n",
      "avg / total       0.83      0.81      0.80        62\n",
      "\n",
      "[ 5  5  0  0 27  3  0  4 18]\n",
      "svc Accuracy:  0.8064516129032258\n",
      "svc F1:  0.7740192623913554\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        10\n",
      "          1       0.68      0.93      0.79        30\n",
      "          2       0.85      0.77      0.81        22\n",
      "\n",
      "avg / total       0.79      0.74      0.70        62\n",
      "\n",
      "[ 1  8  1  0 28  2  0  5 17]\n",
      "LR Accuracy:  0.7419354838709677\n",
      "LR F1:  0.5933581285693962\n",
      "For name:  a_mansour\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0003-2544-2705': 7, '0000-0002-7543-575X': 4, '0000-0001-7312-4299': 3, '0000-0001-5886-0650': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  a_lau\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-5933-9290': 21, '0000-0002-6489-204X': 8, '0000-0003-3802-828X': 4, '0000-0002-7338-7176': 2})\n",
      "['0000-0002-5933-9290']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  j_berg\n",
      "total sample size before apply threshold:  171\n",
      "Counter({'0000-0003-0157-5888': 86, '0000-0003-3022-0963': 66, '0000-0003-2360-2664': 11, '0000-0003-2126-6476': 4, '0000-0001-8583-6349': 2, '0000-0001-7947-5073': 2})\n",
      "['0000-0003-3022-0963', '0000-0003-2360-2664', '0000-0003-0157-5888']\n",
      "Total sample size after apply threshold:  163\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(163, 90)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(163, 29)\n",
      "2\n",
      "(163, 119)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.77      0.77        66\n",
      "          1       0.67      0.36      0.47        11\n",
      "          2       0.86      0.91      0.88        86\n",
      "\n",
      "avg / total       0.81      0.82      0.81       163\n",
      "\n",
      "[51  2 13  7  4  0  8  0 78]\n",
      "MNB Accuracy:  0.8159509202453987\n",
      "MNB F1:  0.7082238134082601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.71      0.79        66\n",
      "          1       0.71      0.91      0.80        11\n",
      "          2       0.84      0.94      0.89        86\n",
      "\n",
      "avg / total       0.85      0.85      0.84       163\n",
      "\n",
      "[47  4 15  1 10  0  5  0 81]\n",
      "svc Accuracy:  0.8466257668711656\n",
      "svc F1:  0.826675285498815\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.67      0.77        66\n",
      "          1       0.73      0.73      0.73        11\n",
      "          2       0.81      0.97      0.88        86\n",
      "\n",
      "avg / total       0.84      0.83      0.82       163\n",
      "\n",
      "[44  3 19  2  8  1  3  0 83]\n",
      "LR Accuracy:  0.8282208588957055\n",
      "LR F1:  0.7902656656279845\n",
      "For name:  l_wilson\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0001-8709-8968': 18, '0000-0003-4175-7125': 11, '0000-0001-6659-6001': 11, '0000-0002-3779-8277': 11, '0000-0002-3532-0309': 5, '0000-0002-8333-5660': 3})\n",
      "['0000-0001-8709-8968', '0000-0003-4175-7125', '0000-0001-6659-6001', '0000-0002-3779-8277']\n",
      "Total sample size after apply threshold:  51\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 26)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 11)\n",
      "2\n",
      "(51, 37)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.89      0.70        18\n",
      "          1       0.62      0.73      0.67        11\n",
      "          2       0.30      0.27      0.29        11\n",
      "          3       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.40      0.53      0.45        51\n",
      "\n",
      "[16  0  2  0  1  8  2  0  4  4  3  0  7  1  3  0]\n",
      "MNB Accuracy:  0.5294117647058824\n",
      "MNB F1:  0.41200828157349895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.83      0.86        18\n",
      "          1       0.89      0.73      0.80        11\n",
      "          2       0.43      0.55      0.48        11\n",
      "          3       0.45      0.45      0.45        11\n",
      "\n",
      "avg / total       0.69      0.67      0.68        51\n",
      "\n",
      "[15  0  1  2  0  8  2  1  1  1  6  3  1  0  5  5]\n",
      "svc Accuracy:  0.6666666666666666\n",
      "svc F1:  0.6479220779220779\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.83      0.79        18\n",
      "          1       0.89      0.73      0.80        11\n",
      "          2       0.41      0.64      0.50        11\n",
      "          3       0.40      0.18      0.25        11\n",
      "\n",
      "avg / total       0.63      0.63      0.61        51\n",
      "\n",
      "[15  0  2  1  0  8  3  0  2  0  7  2  3  1  5  2]\n",
      "LR Accuracy:  0.6274509803921569\n",
      "LR F1:  0.5848684210526316\n",
      "For name:  c_park\n",
      "total sample size before apply threshold:  360\n",
      "Counter({'0000-0003-4083-8791': 106, '0000-0002-2350-9876': 69, '0000-0003-1906-1308': 45, '0000-0002-9732-361X': 40, '0000-0002-3363-5788': 35, '0000-0002-7618-9028': 16, '0000-0003-1584-6896': 14, '0000-0002-1788-045X': 11, '0000-0001-9008-1964': 10, '0000-0003-4734-214X': 9, '0000-0002-0776-3188': 2, '0000-0003-0409-8132': 1, '0000-0003-0721-272X': 1, '0000-0002-5935-8264': 1})\n",
      "['0000-0002-3363-5788', '0000-0001-9008-1964', '0000-0002-7618-9028', '0000-0002-1788-045X', '0000-0002-2350-9876', '0000-0003-4083-8791', '0000-0002-9732-361X', '0000-0003-1584-6896', '0000-0003-1906-1308']\n",
      "Total sample size after apply threshold:  346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(346, 161)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(346, 20)\n",
      "2\n",
      "(346, 181)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.54      0.59        35\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00        16\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.59      0.74      0.65        69\n",
      "          5       0.46      0.79      0.58       106\n",
      "          6       1.00      0.35      0.52        40\n",
      "          7       1.00      0.21      0.35        14\n",
      "          8       0.57      0.36      0.44        45\n",
      "\n",
      "avg / total       0.55      0.54      0.50       346\n",
      "\n",
      "[19  0  0  0  3 10  0  0  3  0  0  0  0  3  7  0  0  0  3  0  0  0  3  9\n",
      "  0  0  1  3  0  0  0  0  7  0  0  1  0  0  0  0 51 18  0  0  0  0  0  0\n",
      "  0 17 84  0  0  5  0  0  0  0  3 21 14  0  2  3  0  0  0  2  6  0  3  0\n",
      "  1  0  2  0  5 21  0  0 16]\n",
      "MNB Accuracy:  0.5404624277456648\n",
      "MNB F1:  0.3487474324568395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.74      0.73        35\n",
      "          1       1.00      0.20      0.33        10\n",
      "          2       0.64      0.44      0.52        16\n",
      "          3       0.50      0.18      0.27        11\n",
      "          4       0.96      0.65      0.78        69\n",
      "          5       0.55      0.91      0.69       106\n",
      "          6       0.88      0.55      0.68        40\n",
      "          7       0.71      0.71      0.71        14\n",
      "          8       0.73      0.53      0.62        45\n",
      "\n",
      "avg / total       0.73      0.68      0.67       346\n",
      "\n",
      "[26  0  0  1  0  2  0  3  3  0  2  0  0  0  8  0  0  0  1  0  7  0  0  8\n",
      "  0  0  0  4  0  0  2  0  3  0  1  1  0  0  0  0 45 24  0  0  0  0  0  0\n",
      "  0  2 96  3  0  5  0  0  2  0  0 16 22  0  0  3  0  0  1  0  0  0 10  0\n",
      "  2  0  2  0  0 17  0  0 24]\n",
      "svc Accuracy:  0.6763005780346821\n",
      "svc F1:  0.5910091828876568\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.63      0.68        35\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.50      0.12      0.20        16\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.69      0.74      0.71        69\n",
      "          5       0.52      0.83      0.64       106\n",
      "          6       0.95      0.47      0.63        40\n",
      "          7       0.62      0.71      0.67        14\n",
      "          8       0.70      0.51      0.59        45\n",
      "\n",
      "avg / total       0.62      0.62      0.59       346\n",
      "\n",
      "[22  0  0  0  0  7  0  3  3  0  0  0  0  2  8  0  0  0  1  0  2  0  2 10\n",
      "  0  0  1  2  0  0  0  0  5  0  3  1  0  0  0  0 51 18  0  0  0  0  0  0\n",
      "  0 12 88  1  0  5  0  0  0  0  3 18 19  0  0  3  0  0  0  1  0  0 10  0\n",
      "  2  0  2  0  3 15  0  0 23]\n",
      "LR Accuracy:  0.6213872832369942\n",
      "LR F1:  0.4577725977725977\n",
      "For name:  r_thomas\n",
      "total sample size before apply threshold:  368\n",
      "Counter({'0000-0002-0518-8386': 95, '0000-0002-2340-0301': 95, '0000-0003-1448-7182': 74, '0000-0003-2062-8623': 46, '0000-0001-9251-5543': 13, '0000-0002-2970-6352': 10, '0000-0002-2165-5917': 8, '0000-0003-1282-7825': 5, '0000-0003-3588-2317': 5, '0000-0002-7286-2764': 4, '0000-0001-8784-1707': 2, '0000-0001-5256-3313': 2, '0000-0002-2069-1799': 2, '0000-0002-8745-7462': 2, '0000-0001-5296-3114': 1, '0000-0002-8872-7866': 1, '0000-0003-3473-2579': 1, '0000-0002-5362-4816': 1, '0000-0001-7194-3653': 1})\n",
      "['0000-0002-0518-8386', '0000-0003-2062-8623', '0000-0001-9251-5543', '0000-0003-1448-7182', '0000-0002-2340-0301', '0000-0002-2970-6352']\n",
      "Total sample size after apply threshold:  333\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(333, 159)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(333, 25)\n",
      "2\n",
      "(333, 184)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.77      0.74        95\n",
      "          1       0.91      0.43      0.59        46\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.74      0.80      0.77        74\n",
      "          4       0.58      0.80      0.68        95\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.66      0.68      0.66       333\n",
      "\n",
      "[73  0  0  4 18  0  5 20  0  6 15  0  2  0  0  3  8  0  9  0  0 59  6  0\n",
      " 12  0  0  7 76  0  0  2  0  1  7  0]\n",
      "MNB Accuracy:  0.6846846846846847\n",
      "MNB F1:  0.46248709584844044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.79      0.77        95\n",
      "          1       0.93      0.61      0.74        46\n",
      "          2       1.00      0.46      0.63        13\n",
      "          3       0.98      0.82      0.90        74\n",
      "          4       0.61      0.85      0.71        95\n",
      "          5       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.80      0.76      0.76       333\n",
      "\n",
      "[75  0  0  1 19  0  3 28  0  0 15  0  3  0  6  0  4  0  5  0  0 61  8  0\n",
      " 14  0  0  0 81  0  0  2  0  0  6  2]\n",
      "svc Accuracy:  0.7597597597597597\n",
      "svc F1:  0.6797617157524277\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.79      0.75        95\n",
      "          1       0.85      0.48      0.61        46\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.76      0.77      0.77        74\n",
      "          4       0.58      0.77      0.66        95\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.65      0.68      0.66       333\n",
      "\n",
      "[75  1  0  2 17  0  5 22  0  5 14  0  2  0  0  3  8  0  9  1  0 57  7  0\n",
      " 15  0  0  7 73  0  0  2  0  1  7  0]\n",
      "LR Accuracy:  0.6816816816816816\n",
      "LR F1:  0.46385232052189407\n",
      "For name:  j_fonseca\n",
      "total sample size before apply threshold:  170\n",
      "Counter({'0000-0003-1432-3671': 87, '0000-0002-0887-8796': 55, '0000-0001-6477-7028': 8, '0000-0001-6703-3278': 7, '0000-0001-7173-7374': 5, '0000-0003-1206-7969': 3, '0000-0003-2549-5823': 2, '0000-0002-3679-0337': 1, '0000-0002-6073-1791': 1, '0000-0002-2136-1011': 1})\n",
      "['0000-0003-1432-3671', '0000-0002-0887-8796']\n",
      "Total sample size after apply threshold:  142\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 55)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 20)\n",
      "2\n",
      "(142, 75)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.89        87\n",
      "          1       0.86      0.78      0.82        55\n",
      "\n",
      "avg / total       0.87      0.87      0.86       142\n",
      "\n",
      "[80  7 12 43]\n",
      "MNB Accuracy:  0.8661971830985915\n",
      "MNB F1:  0.8564511838254855\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93        87\n",
      "          1       0.96      0.80      0.87        55\n",
      "\n",
      "avg / total       0.91      0.91      0.91       142\n",
      "\n",
      "[85  2 11 44]\n",
      "svc Accuracy:  0.9084507042253521\n",
      "svc F1:  0.9001244386733755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.91        87\n",
      "          1       0.95      0.75      0.84        55\n",
      "\n",
      "avg / total       0.90      0.89      0.88       142\n",
      "\n",
      "[85  2 14 41]\n",
      "LR Accuracy:  0.8873239436619719\n",
      "LR F1:  0.8753565942506034\n",
      "For name:  s_henderson\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0002-1076-3867': 52, '0000-0002-9032-3828': 25, '0000-0003-3019-1891': 4, '0000-0001-6389-4927': 1})\n",
      "['0000-0002-1076-3867', '0000-0002-9032-3828']\n",
      "Total sample size after apply threshold:  77\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 62)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 18)\n",
      "2\n",
      "(77, 80)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.77      0.71        52\n",
      "          1       0.29      0.20      0.24        25\n",
      "\n",
      "avg / total       0.55      0.58      0.56        77\n",
      "\n",
      "[40 12 20  5]\n",
      "MNB Accuracy:  0.5844155844155844\n",
      "MNB F1:  0.47619047619047616\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.77      0.72        52\n",
      "          1       0.33      0.24      0.28        25\n",
      "\n",
      "avg / total       0.57      0.60      0.58        77\n",
      "\n",
      "[40 12 19  6]\n",
      "svc Accuracy:  0.5974025974025974\n",
      "svc F1:  0.4998952440812906\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.92      0.79        52\n",
      "          1       0.43      0.12      0.19        25\n",
      "\n",
      "avg / total       0.60      0.66      0.59        77\n",
      "\n",
      "[48  4 22  3]\n",
      "LR Accuracy:  0.6623376623376623\n",
      "LR F1:  0.4871926229508197\n",
      "For name:  m_coelho\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0003-3288-1693': 44, '0000-0002-7312-3429': 15, '0000-0002-5716-0561': 11, '0000-0002-6542-175X': 5, '0000-0003-3312-191X': 5, '0000-0002-7429-4967': 4, '0000-0002-0392-1118': 3, '0000-0002-9169-7776': 3, '0000-0002-0197-8081': 3})\n",
      "['0000-0003-3288-1693', '0000-0002-7312-3429', '0000-0002-5716-0561']\n",
      "Total sample size after apply threshold:  70\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 15)\n",
      "2\n",
      "(70, 54)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.98      0.77        44\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.40      0.61      0.48        70\n",
      "\n",
      "[43  0  1 14  0  1 11  0  0]\n",
      "MNB Accuracy:  0.6142857142857143\n",
      "MNB F1:  0.25595238095238093\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.98      0.82        44\n",
      "          1       0.88      0.47      0.61        15\n",
      "          2       1.00      0.09      0.17        11\n",
      "\n",
      "avg / total       0.79      0.73      0.67        70\n",
      "\n",
      "[43  1  0  8  7  0 10  0  1]\n",
      "svc Accuracy:  0.7285714285714285\n",
      "svc F1:  0.5314699792960663\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      1.00      0.77        44\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.40      0.63      0.49        70\n",
      "\n",
      "[44  0  0 15  0  0 11  0  0]\n",
      "LR Accuracy:  0.6285714285714286\n",
      "LR F1:  0.2573099415204678\n",
      "For name:  j_pearson\n",
      "total sample size before apply threshold:  119\n",
      "Counter({'0000-0002-3318-5406': 65, '0000-0001-5607-4517': 41, '0000-0002-2867-2269': 6, '0000-0002-3777-1453': 4, '0000-0002-9876-7837': 2, '0000-0002-1400-5932': 1})\n",
      "['0000-0001-5607-4517', '0000-0002-3318-5406']\n",
      "Total sample size after apply threshold:  106\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 67)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 21)\n",
      "2\n",
      "(106, 88)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.68      0.72        41\n",
      "          1       0.81      0.86      0.84        65\n",
      "\n",
      "avg / total       0.79      0.79      0.79       106\n",
      "\n",
      "[28 13  9 56]\n",
      "MNB Accuracy:  0.7924528301886793\n",
      "MNB F1:  0.776884806735553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.59      0.64        41\n",
      "          1       0.76      0.85      0.80        65\n",
      "\n",
      "avg / total       0.74      0.75      0.74       106\n",
      "\n",
      "[24 17 10 55]\n",
      "svc Accuracy:  0.7452830188679245\n",
      "svc F1:  0.7214598540145984\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.44      0.54        41\n",
      "          1       0.71      0.88      0.79        65\n",
      "\n",
      "avg / total       0.70      0.71      0.69       106\n",
      "\n",
      "[18 23  8 57]\n",
      "LR Accuracy:  0.7075471698113207\n",
      "LR F1:  0.6617601646937725\n",
      "For name:  z_xie\n",
      "total sample size before apply threshold:  99\n",
      "Counter({'0000-0003-2974-1825': 48, '0000-0001-5816-6159': 17, '0000-0002-8348-4455': 16, '0000-0002-1539-5100': 8, '0000-0002-4526-9746': 6, '0000-0003-0308-5233': 1, '0000-0002-3137-561X': 1, '0000-0003-2492-0592': 1, '0000-0002-6600-8190': 1})\n",
      "['0000-0003-2974-1825', '0000-0002-8348-4455', '0000-0001-5816-6159']\n",
      "Total sample size after apply threshold:  81\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 43)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 13)\n",
      "2\n",
      "(81, 56)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.98      0.82        48\n",
      "          1       0.83      0.31      0.45        16\n",
      "          2       0.78      0.41      0.54        17\n",
      "\n",
      "avg / total       0.75      0.73      0.69        81\n",
      "\n",
      "[47  0  1 10  5  1  9  1  7]\n",
      "MNB Accuracy:  0.7283950617283951\n",
      "MNB F1:  0.6058561321719216\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.98      0.86        48\n",
      "          1       0.80      0.50      0.62        16\n",
      "          2       0.70      0.41      0.52        17\n",
      "\n",
      "avg / total       0.76      0.77      0.74        81\n",
      "\n",
      "[47  0  1  6  8  2  8  2  7]\n",
      "svc Accuracy:  0.7654320987654321\n",
      "svc F1:  0.6654294850013504\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.98      0.79        48\n",
      "          1       0.67      0.12      0.21        16\n",
      "          2       0.71      0.29      0.42        17\n",
      "\n",
      "avg / total       0.67      0.67      0.60        81\n",
      "\n",
      "[47  0  1 13  2  1 11  1  5]\n",
      "LR Accuracy:  0.6666666666666666\n",
      "LR F1:  0.4723696496142317\n",
      "For name:  m_wright\n",
      "total sample size before apply threshold:  379\n",
      "Counter({'0000-0001-7133-4970': 213, '0000-0002-0541-7556': 87, '0000-0002-2650-2426': 25, '0000-0001-8036-1161': 17, '0000-0003-2731-4707': 15, '0000-0002-9348-8740': 13, '0000-0001-7121-504X': 6, '0000-0001-5522-7796': 2, '0000-0002-5731-2692': 1})\n",
      "['0000-0001-8036-1161', '0000-0001-7133-4970', '0000-0002-2650-2426', '0000-0002-9348-8740', '0000-0002-0541-7556', '0000-0003-2731-4707']\n",
      "Total sample size after apply threshold:  370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(370, 130)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(370, 22)\n",
      "2\n",
      "(370, 152)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        17\n",
      "          1       0.73      0.96      0.83       213\n",
      "          2       0.00      0.00      0.00        25\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.82      0.85      0.84        87\n",
      "          5       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.61      0.75      0.67       370\n",
      "\n",
      "[  0  15   0   0   2   0   0 204   0   0   9   0   0  20   0   0   5   0\n",
      "   0  13   0   0   0   0   0  13   0   0  74   0   0  15   0   0   0   0]\n",
      "MNB Accuracy:  0.7513513513513513\n",
      "MNB F1:  0.2772907331644912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.12      0.17        17\n",
      "          1       0.76      0.98      0.85       213\n",
      "          2       1.00      0.52      0.68        25\n",
      "          3       1.00      0.15      0.27        13\n",
      "          4       1.00      0.84      0.91        87\n",
      "          5       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.79      0.81      0.77       370\n",
      "\n",
      "[  2  15   0   0   0   0   4 209   0   0   0   0   0  12  13   0   0   0\n",
      "   0  11   0   2   0   0   0  14   0   0  73   0   0  15   0   0   0   0]\n",
      "svc Accuracy:  0.8081081081081081\n",
      "svc F1:  0.4820159937386812\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        17\n",
      "          1       0.74      1.00      0.85       213\n",
      "          2       1.00      0.44      0.61        25\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       1.00      0.80      0.89        87\n",
      "          5       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.73      0.79      0.74       370\n",
      "\n",
      "[  0  17   0   0   0   0   0 213   0   0   0   0   0  14  11   0   0   0\n",
      "   0  13   0   0   0   0   0  17   0   0  70   0   0  15   0   0   0   0]\n",
      "LR Accuracy:  0.7945945945945946\n",
      "LR F1:  0.39190607233721403\n",
      "For name:  j_song\n",
      "total sample size before apply threshold:  248\n",
      "Counter({'0000-0003-0224-6322': 70, '0000-0003-2434-7511': 33, '0000-0001-6303-3801': 26, '0000-0003-0420-2374': 23, '0000-0002-4379-0909': 19, '0000-0002-2736-4037': 13, '0000-0001-6623-4369': 11, '0000-0002-9971-0541': 10, '0000-0001-9223-8590': 9, '0000-0003-3053-0929': 8, '0000-0001-7886-1765': 5, '0000-0003-1265-0337': 3, '0000-0001-7350-9578': 3, '0000-0003-4262-1895': 3, '0000-0002-3863-1719': 2, '0000-0002-3463-0196': 2, '0000-0002-9252-0331': 2, '0000-0002-6631-3232': 2, '0000-0003-3160-4643': 1, '0000-0002-2932-440X': 1, '0000-0003-3497-2513': 1, '0000-0002-7357-2136': 1})\n",
      "['0000-0003-0420-2374', '0000-0001-6303-3801', '0000-0003-0224-6322', '0000-0003-2434-7511', '0000-0001-6623-4369', '0000-0002-2736-4037', '0000-0002-4379-0909', '0000-0002-9971-0541']\n",
      "Total sample size after apply threshold:  205\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(205, 127)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(205, 20)\n",
      "2\n",
      "(205, 147)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      0.17      0.21        23\n",
      "          1       0.70      0.27      0.39        26\n",
      "          2       0.39      0.83      0.53        70\n",
      "          3       0.25      0.12      0.16        33\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       1.00      0.23      0.38        13\n",
      "          6       0.58      0.37      0.45        19\n",
      "          7       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.41      0.40      0.35       205\n",
      "\n",
      "[ 4  0 16  3  0  0  0  0  1  7 16  1  0  0  1  0  2  3 58  3  0  0  4  0\n",
      "  4  0 25  4  0  0  0  0  4  0  7  0  0  0  0  0  0  0  8  2  0  3  0  0\n",
      "  1  0  9  2  0  0  7  0  0  0  9  1  0  0  0  0]\n",
      "MNB Accuracy:  0.40487804878048783\n",
      "MNB F1:  0.2645006743885586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      0.48      0.36        23\n",
      "          1       1.00      0.54      0.70        26\n",
      "          2       0.54      0.77      0.64        70\n",
      "          3       0.53      0.30      0.38        33\n",
      "          4       0.86      0.55      0.67        11\n",
      "          5       1.00      0.62      0.76        13\n",
      "          6       0.59      0.53      0.56        19\n",
      "          7       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.64      0.56      0.56       205\n",
      "\n",
      "[11  0 10  2  0  0  0  0  4 14  7  0  0  0  1  0  5  0 54  5  1  0  5  0\n",
      "  7  0 16 10  0  0  0  0  4  0  1  0  6  0  0  0  1  0  3  0  0  8  1  0\n",
      "  4  0  5  0  0  0 10  0  2  0  4  2  0  0  0  2]\n",
      "svc Accuracy:  0.5609756097560976\n",
      "svc F1:  0.5497531946784598\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.30      0.31        23\n",
      "          1       0.92      0.46      0.62        26\n",
      "          2       0.42      0.83      0.56        70\n",
      "          3       0.27      0.12      0.17        33\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       1.00      0.46      0.63        13\n",
      "          6       0.58      0.37      0.45        19\n",
      "          7       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.46      0.46      0.41       205\n",
      "\n",
      "[ 7  0 14  2  0  0  0  0  1 12 11  1  0  0  1  0  3  1 58  4  0  0  4  0\n",
      "  4  0 25  4  0  0  0  0  4  0  7  0  0  0  0  0  0  0  5  2  0  6  0  0\n",
      "  1  0  9  2  0  0  7  0  2  0  8  0  0  0  0  0]\n",
      "LR Accuracy:  0.4585365853658537\n",
      "LR F1:  0.34209258964832157\n",
      "For name:  k_becker\n",
      "total sample size before apply threshold:  394\n",
      "Counter({'0000-0002-6794-6656': 180, '0000-0002-6391-1341': 112, '0000-0002-6801-4498': 80, '0000-0003-4231-2590': 19, '0000-0001-6317-1884': 3})\n",
      "['0000-0002-6391-1341', '0000-0002-6801-4498', '0000-0002-6794-6656', '0000-0003-4231-2590']\n",
      "Total sample size after apply threshold:  391\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(391, 219)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(391, 24)\n",
      "2\n",
      "(391, 243)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.60      0.63       112\n",
      "          1       0.74      0.40      0.52        80\n",
      "          2       0.64      0.87      0.74       180\n",
      "          3       1.00      0.11      0.19        19\n",
      "\n",
      "avg / total       0.68      0.66      0.63       391\n",
      "\n",
      "[ 67   1  44   0  11  32  37   0  20   4 156   0   4   6   7   2]\n",
      "MNB Accuracy:  0.6572890025575447\n",
      "MNB F1:  0.5182046686577656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.49      0.63       112\n",
      "          1       0.91      0.53      0.67        80\n",
      "          2       0.64      0.94      0.76       180\n",
      "          3       0.61      0.58      0.59        19\n",
      "\n",
      "avg / total       0.76      0.71      0.70       391\n",
      "\n",
      "[ 55   1  56   0   2  42  32   4   5   3 169   3   0   0   8  11]\n",
      "svc Accuracy:  0.7084398976982097\n",
      "svc F1:  0.6632489327762479\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.54      0.63       112\n",
      "          1       0.90      0.35      0.50        80\n",
      "          2       0.62      0.93      0.74       180\n",
      "          3       0.78      0.37      0.50        19\n",
      "\n",
      "avg / total       0.72      0.67      0.65       391\n",
      "\n",
      "[ 60   1  51   0   7  28  43   2  10   2 168   0   2   0  10   7]\n",
      "LR Accuracy:  0.6726342710997443\n",
      "LR F1:  0.594034896917953\n",
      "For name:  r_sinha\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0001-5497-5055': 11, '0000-0001-8488-6280': 5, '0000-0003-4645-3243': 4, '0000-0003-4185-5198': 3, '0000-0002-7231-1356': 2, '0000-0001-8918-7585': 2})\n",
      "['0000-0001-5497-5055']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  c_turner\n",
      "total sample size before apply threshold:  88\n",
      "Counter({'0000-0002-2687-932X': 33, '0000-0001-9466-1149': 32, '0000-0002-4458-9748': 14, '0000-0001-7409-4386': 5, '0000-0002-1245-0741': 4})\n",
      "['0000-0001-9466-1149', '0000-0002-2687-932X', '0000-0002-4458-9748']\n",
      "Total sample size after apply threshold:  79\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 17)\n",
      "2\n",
      "(79, 65)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.75      0.74        32\n",
      "          1       0.74      0.85      0.79        33\n",
      "          2       0.75      0.43      0.55        14\n",
      "\n",
      "avg / total       0.74      0.73      0.73        79\n",
      "\n",
      "[24  6  2  5 28  0  4  4  6]\n",
      "MNB Accuracy:  0.7341772151898734\n",
      "MNB F1:  0.6908828260940937\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.75      0.75        32\n",
      "          1       0.73      0.91      0.81        33\n",
      "          2       0.67      0.29      0.40        14\n",
      "\n",
      "avg / total       0.73      0.73      0.71        79\n",
      "\n",
      "[24  6  2  3 30  0  5  5  4]\n",
      "svc Accuracy:  0.7341772151898734\n",
      "svc F1:  0.6536036036036036\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.78      0.75        32\n",
      "          1       0.77      0.91      0.83        33\n",
      "          2       0.80      0.29      0.42        14\n",
      "\n",
      "avg / total       0.75      0.75      0.73        79\n",
      "\n",
      "[25  6  1  3 30  0  7  3  4]\n",
      "LR Accuracy:  0.7468354430379747\n",
      "LR F1:  0.6668848738762327\n",
      "For name:  y_su\n",
      "total sample size before apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "Counter({'0000-0002-1771-9017': 83, '0000-0002-5390-4113': 24, '0000-0003-3537-6246': 23, '0000-0003-3398-6294': 17, '0000-0001-8434-1758': 15, '0000-0003-2660-9183': 10, '0000-0003-2193-5473': 5, '0000-0002-4293-5037': 2, '0000-0001-7557-8518': 2, '0000-0002-4643-917X': 1, '0000-0001-8528-0694': 1, '0000-0003-0790-5905': 1, '0000-0003-0355-3981': 1, '0000-0002-8201-1592': 1, '0000-0002-4172-7981': 1, '0000-0001-6544-126X': 1, '0000-0001-7622-7269': 1, '0000-0002-8466-0043': 1})\n",
      "['0000-0001-8434-1758', '0000-0003-3398-6294', '0000-0002-5390-4113', '0000-0003-3537-6246', '0000-0002-1771-9017', '0000-0003-2660-9183']\n",
      "Total sample size after apply threshold:  172\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(172, 90)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(172, 17)\n",
      "2\n",
      "(172, 107)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.27      0.38        15\n",
      "          1       1.00      0.12      0.21        17\n",
      "          2       0.87      0.54      0.67        24\n",
      "          3       0.84      0.70      0.76        23\n",
      "          4       0.60      0.94      0.73        83\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.68      0.66      0.60       172\n",
      "\n",
      "[ 4  0  0  1 10  0  0  2  0  0 15  0  0  0 13  1 10  0  0  0  0 16  7  0\n",
      "  2  0  2  1 78  0  0  0  0  0 10  0]\n",
      "MNB Accuracy:  0.6569767441860465\n",
      "MNB F1:  0.4587407485850777\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.73      0.81        15\n",
      "          1       1.00      0.71      0.83        17\n",
      "          2       0.95      0.75      0.84        24\n",
      "          3       1.00      0.83      0.90        23\n",
      "          4       0.75      0.99      0.85        83\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.80      0.83      0.80       172\n",
      "\n",
      "[11  0  0  0  4  0  1 12  0  0  4  0  0  0 18  0  6  0  0  0  0 19  4  0\n",
      "  0  0  1  0 82  0  0  0  0  0 10  0]\n",
      "svc Accuracy:  0.8255813953488372\n",
      "svc F1:  0.70568552690689\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        15\n",
      "          1       1.00      0.24      0.38        17\n",
      "          2       0.93      0.54      0.68        24\n",
      "          3       0.93      0.61      0.74        23\n",
      "          4       0.61      0.98      0.75        83\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.73      0.69      0.64       172\n",
      "\n",
      "[ 6  0  0  0  9  0  0  4  0  0 13  0  0  0 13  0 11  0  0  0  0 14  9  0\n",
      "  0  0  1  1 81  0  0  0  0  0 10  0]\n",
      "LR Accuracy:  0.686046511627907\n",
      "LR F1:  0.5205722639933167\n",
      "For name:  a_popov\n",
      "total sample size before apply threshold:  135\n",
      "Counter({'0000-0002-7596-0378': 99, '0000-0002-4678-6307': 15, '0000-0001-5024-5311': 13, '0000-0003-3881-7369': 3, '0000-0003-4602-5708': 3, '0000-0002-0889-6986': 1, '0000-0003-2643-4846': 1})\n",
      "['0000-0001-5024-5311', '0000-0002-4678-6307', '0000-0002-7596-0378']\n",
      "Total sample size after apply threshold:  127\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 15)\n",
      "2\n",
      "(127, 50)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.08      0.13        13\n",
      "          1       1.00      0.13      0.24        15\n",
      "          2       0.80      0.99      0.88        99\n",
      "\n",
      "avg / total       0.79      0.80      0.73       127\n",
      "\n",
      "[ 1  0 12  0  2 13  1  0 98]\n",
      "MNB Accuracy:  0.7952755905511811\n",
      "MNB F1:  0.4171701112877584\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.23      0.30        13\n",
      "          1       1.00      0.33      0.50        15\n",
      "          2       0.83      0.96      0.89        99\n",
      "\n",
      "avg / total       0.81      0.81      0.78       127\n",
      "\n",
      "[ 3  0 10  0  5 10  4  0 95]\n",
      "svc Accuracy:  0.8110236220472441\n",
      "svc F1:  0.5626168224299066\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.78      1.00      0.88        99\n",
      "\n",
      "avg / total       0.61      0.78      0.68       127\n",
      "\n",
      "[ 0  0 13  0  0 15  0  0 99]\n",
      "LR Accuracy:  0.7795275590551181\n",
      "LR F1:  0.29203539823008845\n",
      "For name:  w_liao\n",
      "total sample size before apply threshold:  79\n",
      "Counter({'0000-0001-5362-6953': 29, '0000-0001-6383-3470': 25, '0000-0002-5619-4997': 16, '0000-0002-9768-0959': 5, '0000-0001-7221-5906': 3, '0000-0002-5333-2717': 1})\n",
      "['0000-0001-5362-6953', '0000-0002-5619-4997', '0000-0001-6383-3470']\n",
      "Total sample size after apply threshold:  70\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 42)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 14)\n",
      "2\n",
      "(70, 56)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.83      0.70        29\n",
      "          1       0.82      0.56      0.67        16\n",
      "          2       0.63      0.48      0.55        25\n",
      "\n",
      "avg / total       0.66      0.64      0.64        70\n",
      "\n",
      "[24  0  5  5  9  2 11  2 12]\n",
      "MNB Accuracy:  0.6428571428571429\n",
      "MNB F1:  0.6359244620114185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.76      0.72        29\n",
      "          1       0.82      0.56      0.67        16\n",
      "          2       0.59      0.64      0.62        25\n",
      "\n",
      "avg / total       0.68      0.67      0.67        70\n",
      "\n",
      "[22  0  7  3  9  4  7  2 16]\n",
      "svc Accuracy:  0.6714285714285714\n",
      "svc F1:  0.6677875858203727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.79      0.70        29\n",
      "          1       0.90      0.56      0.69        16\n",
      "          2       0.65      0.60      0.63        25\n",
      "\n",
      "avg / total       0.70      0.67      0.67        70\n",
      "\n",
      "[23  0  6  5  9  2  9  1 15]\n",
      "LR Accuracy:  0.6714285714285714\n",
      "LR F1:  0.6714257964257965\n",
      "For name:  j_zhong\n",
      "total sample size before apply threshold:  280\n",
      "Counter({'0000-0002-2265-9338': 115, '0000-0002-1494-6396': 70, '0000-0003-3148-4143': 37, '0000-0002-3534-7480': 21, '0000-0003-1801-9642': 19, '0000-0001-7157-603X': 8, '0000-0002-8815-4105': 4, '0000-0002-8945-4599': 3, '0000-0002-0556-2964': 1, '0000-0003-2750-9782': 1, '0000-0001-8785-1729': 1})\n",
      "['0000-0003-3148-4143', '0000-0003-1801-9642', '0000-0002-3534-7480', '0000-0002-2265-9338', '0000-0002-1494-6396']\n",
      "Total sample size after apply threshold:  262\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(262, 118)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(262, 23)\n",
      "2\n",
      "(262, 141)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.11      0.20        37\n",
      "          1       1.00      0.16      0.27        19\n",
      "          2       0.00      0.00      0.00        21\n",
      "          3       0.71      0.93      0.80       115\n",
      "          4       0.63      0.93      0.75        70\n",
      "\n",
      "avg / total       0.69      0.68      0.60       262\n",
      "\n",
      "[  4   0   0  20  13   0   3   0  13   3   0   0   0   7  14   0   0   0\n",
      " 107   8   0   0   1   4  65]\n",
      "MNB Accuracy:  0.683206106870229\n",
      "MNB F1:  0.4047611177694952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.38      0.47        37\n",
      "          1       0.60      0.32      0.41        19\n",
      "          2       0.40      0.19      0.26        21\n",
      "          3       0.74      0.91      0.82       115\n",
      "          4       0.81      0.89      0.84        70\n",
      "\n",
      "avg / total       0.70      0.73      0.70       262\n",
      "\n",
      "[ 14   1   3  16   3   3   6   1   8   1   3   0   4   8   6   2   3   0\n",
      " 105   5   1   0   2   5  62]\n",
      "svc Accuracy:  0.7290076335877863\n",
      "svc F1:  0.5598364647556109\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.22      0.36        37\n",
      "          1       1.00      0.16      0.27        19\n",
      "          2       0.50      0.05      0.09        21\n",
      "          3       0.69      0.95      0.80       115\n",
      "          4       0.70      0.91      0.80        70\n",
      "\n",
      "avg / total       0.74      0.71      0.64       262\n",
      "\n",
      "[  8   0   0  20   9   0   3   0  15   1   0   0   1   9  11   0   0   0\n",
      " 109   6   0   0   1   5  64]\n",
      "LR Accuracy:  0.7061068702290076\n",
      "LR F1:  0.46176104089147574\n",
      "For name:  a_wheeler\n",
      "total sample size before apply threshold:  138\n",
      "Counter({'0000-0001-5230-7475': 72, '0000-0001-9288-8163': 43, '0000-0001-8617-827X': 15, '0000-0002-9926-1301': 5, '0000-0002-1120-3618': 2, '0000-0001-9755-674X': 1})\n",
      "['0000-0001-5230-7475', '0000-0001-8617-827X', '0000-0001-9288-8163']\n",
      "Total sample size after apply threshold:  130\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 15)\n",
      "2\n",
      "(130, 63)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.92      0.86        72\n",
      "          1       1.00      0.13      0.24        15\n",
      "          2       0.74      0.81      0.78        43\n",
      "\n",
      "avg / total       0.81      0.79      0.76       130\n",
      "\n",
      "[66  0  6  7  2  6  8  0 35]\n",
      "MNB Accuracy:  0.7923076923076923\n",
      "MNB F1:  0.6252723311546841\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        72\n",
      "          1       1.00      0.53      0.70        15\n",
      "          2       1.00      0.86      0.92        43\n",
      "\n",
      "avg / total       0.92      0.90      0.89       130\n",
      "\n",
      "[72  0  0  7  8  0  6  0 37]\n",
      "svc Accuracy:  0.9\n",
      "svc F1:  0.8459498753807809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.92      0.87        72\n",
      "          1       1.00      0.13      0.24        15\n",
      "          2       0.75      0.84      0.79        43\n",
      "\n",
      "avg / total       0.82      0.80      0.77       130\n",
      "\n",
      "[66  0  6  7  2  6  7  0 36]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.6316413204958096\n",
      "For name:  m_walsh\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0001-5683-1151': 30, '0000-0001-8920-7419': 3, '0000-0002-1770-3314': 2, '0000-0003-0982-4105': 2})\n",
      "['0000-0001-5683-1151']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  r_figueiredo\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0002-2122-6530': 29, '0000-0001-5806-0944': 17, '0000-0002-4304-6434': 1, '0000-0002-0933-4854': 1})\n",
      "['0000-0001-5806-0944', '0000-0002-2122-6530']\n",
      "Total sample size after apply threshold:  46\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 25)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 13)\n",
      "2\n",
      "(46, 38)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.29      0.38        17\n",
      "          1       0.68      0.86      0.76        29\n",
      "\n",
      "avg / total       0.63      0.65      0.62        46\n",
      "\n",
      "[ 5 12  4 25]\n",
      "MNB Accuracy:  0.6521739130434783\n",
      "MNB F1:  0.5710955710955711\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.71      0.71        17\n",
      "          1       0.83      0.83      0.83        29\n",
      "\n",
      "avg / total       0.78      0.78      0.78        46\n",
      "\n",
      "[12  5  5 24]\n",
      "svc Accuracy:  0.782608695652174\n",
      "svc F1:  0.7667342799188641\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.18      0.26        17\n",
      "          1       0.65      0.90      0.75        29\n",
      "\n",
      "avg / total       0.59      0.63      0.57        46\n",
      "\n",
      "[ 3 14  3 26]\n",
      "LR Accuracy:  0.6304347826086957\n",
      "LR F1:  0.5072463768115942\n",
      "For name:  y_lin\n",
      "total sample size before apply threshold:  785\n",
      "Counter({'0000-0003-3791-7587': 146, '0000-0001-8153-1441': 115, '0000-0003-1224-6561': 64, '0000-0002-4192-3165': 49, '0000-0002-2499-8632': 39, '0000-0001-8667-0811': 33, '0000-0002-5887-0880': 24, '0000-0001-5227-2663': 23, '0000-0002-4350-7755': 23, '0000-0003-4913-8003': 22, '0000-0001-6460-2877': 21, '0000-0003-1954-334X': 20, '0000-0001-8572-649X': 20, '0000-0001-5574-7062': 15, '0000-0002-0352-2694': 15, '0000-0002-9390-795X': 13, '0000-0001-8904-1287': 13, '0000-0003-3410-3588': 12, '0000-0003-4384-8354': 9, '0000-0001-6833-8276': 9, '0000-0002-8746-3387': 9, '0000-0002-0796-0130': 8, '0000-0002-0435-7694': 8, '0000-0001-6454-0901': 7, '0000-0002-0123-9836': 6, '0000-0001-7120-4690': 6, '0000-0001-5100-6072': 6, '0000-0003-3913-5298': 6, '0000-0003-3177-5186': 5, '0000-0003-1240-7011': 5, '0000-0003-1470-4159': 5, '0000-0001-7910-1223': 4, '0000-0003-4289-894X': 4, '0000-0002-7289-5347': 4, '0000-0003-1328-1641': 2, '0000-0002-2229-6354': 2, '0000-0002-6835-7116': 2, '0000-0001-6819-1235': 2, '0000-0003-2656-3613': 1, '0000-0002-5379-5359': 1, '0000-0003-4327-7432': 1, '0000-0001-7923-0789': 1, '0000-0002-7492-9985': 1, '0000-0002-7639-9594': 1, '0000-0002-2502-2412': 1, '0000-0001-7243-0980': 1, '0000-0002-8287-1429': 1})\n",
      "['0000-0002-9390-795X', '0000-0001-8904-1287', '0000-0002-2499-8632', '0000-0003-1954-334X', '0000-0001-8667-0811', '0000-0002-4192-3165', '0000-0001-8572-649X', '0000-0003-3791-7587', '0000-0001-5227-2663', '0000-0003-3410-3588', '0000-0002-5887-0880', '0000-0001-5574-7062', '0000-0001-8153-1441', '0000-0003-1224-6561', '0000-0002-0352-2694', '0000-0003-4913-8003', '0000-0001-6460-2877', '0000-0002-4350-7755']\n",
      "Total sample size after apply threshold:  667\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(667, 276)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(667, 22)\n",
      "2\n",
      "(667, 298)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.00      0.00      0.00        39\n",
      "          3       0.00      0.00      0.00        20\n",
      "          4       1.00      0.06      0.11        33\n",
      "          5       0.55      0.12      0.20        49\n",
      "          6       0.00      0.00      0.00        20\n",
      "          7       0.32      0.97      0.49       146\n",
      "          8       0.00      0.00      0.00        23\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       1.00      0.04      0.08        24\n",
      "         11       0.00      0.00      0.00        15\n",
      "         12       0.42      0.67      0.52       115\n",
      "         13       0.91      0.47      0.62        64\n",
      "         14       0.00      0.00      0.00        15\n",
      "         15       0.00      0.00      0.00        22\n",
      "         16       0.00      0.00      0.00        21\n",
      "         17       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.36      0.39      0.28       667\n",
      "\n",
      "[  0   0   0   0   0   0   0   8   0   0   0   0   5   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  11   0   0   0   0   1   1   0   0   0   0\n",
      "   0   0   0   0   0   4   0  23   0   0   0   0  12   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  16   0   0   0   0   4   0   0   0   0   0\n",
      "   0   0   0   0   2   0   0  29   0   0   0   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   6   0  32   0   0   0   0  10   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0  16   0   0   0   0   4   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 142   0   0   0   0   4   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  20   0   0   0   0   3   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   8   0   0   0   0   4   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  21   0   0   1   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   9   0   0   0   0   6   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0  36   0   0   0   0  77   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0  21   0   0   0   0  13  30   0   0   0   0\n",
      "   0   0   0   0   0   0   0   8   0   0   0   0   7   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  15   0   0   0   0   7   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  14   0   0   0   0   7   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   9   0   0   0   0  14   0   0   0   0   0]\n",
      "MNB Accuracy:  0.3868065967016492\n",
      "MNB F1:  0.11209235020545412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.15      0.24        13\n",
      "          1       0.75      0.23      0.35        13\n",
      "          2       0.72      0.33      0.46        39\n",
      "          3       1.00      0.75      0.86        20\n",
      "          4       0.80      0.36      0.50        33\n",
      "          5       0.71      0.45      0.55        49\n",
      "          6       0.25      0.20      0.22        20\n",
      "          7       0.68      0.78      0.73       146\n",
      "          8       0.24      0.17      0.20        23\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       0.87      0.83      0.85        24\n",
      "         11       1.00      0.27      0.42        15\n",
      "         12       0.38      0.93      0.54       115\n",
      "         13       0.92      0.53      0.67        64\n",
      "         14       1.00      0.40      0.57        15\n",
      "         15       1.00      0.45      0.62        22\n",
      "         16       0.50      0.24      0.32        21\n",
      "         17       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.63      0.56      0.54       667\n",
      "\n",
      "[  2   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   1   0\n",
      "   0   3   0   0   0   0   0   3   0   0   0   0   6   0   0   0   1   0\n",
      "   0   0  13   0   0   4   0   3   0   0   0   0  19   0   0   0   0   0\n",
      "   0   0   0  15   0   0   0   1   0   0   0   0   4   0   0   0   0   0\n",
      "   0   0   0   0  12   0   1  15   1   1   0   0   3   0   0   0   0   0\n",
      "   0   0   4   0   0  22   0   1   0   0   0   0  21   1   0   0   0   0\n",
      "   0   0   0   0   1   0   4   6   2   2   1   0   2   0   0   0   2   0\n",
      "   0   1   1   0   2   1   2 114   6   2   2   0  15   0   0   0   0   0\n",
      "   1   0   0   0   0   1   2  10   4   2   0   0   3   0   0   0   0   0\n",
      "   0   0   0   0   0   0   4   7   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   3   1   0  20   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   4  11   0   0   0   0   0\n",
      "   0   0   0   0   0   2   0   1   0   0   0   0 107   1   0   0   0   4\n",
      "   0   0   0   0   0   1   0   1   1   0   0   0  26  34   0   0   1   0\n",
      "   0   0   0   0   0   0   0   1   0   0   0   0   8   0   6   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0   0   0   0  11   0   0  10   0   0\n",
      "   1   0   0   0   0   0   3   1   1   0   0   0   9   1   0   0   5   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0]\n",
      "svc Accuracy:  0.5622188905547226\n",
      "svc F1:  0.45048764671203767\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       1.00      0.08      0.14        13\n",
      "          2       0.73      0.21      0.32        39\n",
      "          3       1.00      0.55      0.71        20\n",
      "          4       0.80      0.24      0.37        33\n",
      "          5       0.74      0.29      0.41        49\n",
      "          6       0.57      0.20      0.30        20\n",
      "          7       0.55      0.85      0.67       146\n",
      "          8       0.25      0.13      0.17        23\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       0.82      0.58      0.68        24\n",
      "         11       0.00      0.00      0.00        15\n",
      "         12       0.34      0.83      0.48       115\n",
      "         13       0.79      0.53      0.64        64\n",
      "         14       1.00      0.33      0.50        15\n",
      "         15       1.00      0.41      0.58        22\n",
      "         16       0.62      0.24      0.34        21\n",
      "         17       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.57      0.50      0.46       667\n",
      "\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0  12   1   0   0   0   0\n",
      "   0   1   0   0   0   0   0   5   0   0   0   0   5   2   0   0   0   0\n",
      "   0   0   8   0   0   4   0   8   0   0   0   0  19   0   0   0   0   0\n",
      "   0   0   0  11   0   0   0   3   0   0   0   0   6   0   0   0   0   0\n",
      "   0   0   0   0   8   0   0  21   1   0   0   0   3   0   0   0   0   0\n",
      "   0   0   3   0   0  14   0  13   0   0   0   0  18   1   0   0   0   0\n",
      "   0   0   0   0   0   0   4   7   1   1   1   0   4   0   0   0   2   0\n",
      "   0   0   0   0   2   0   0 124   4   2   2   0  12   0   0   0   0   0\n",
      "   0   0   0   0   0   0   1  12   3   1   0   0   6   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   6   2   0   0   0   4   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   4   0   0  14   0   6   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0   0   0   0  14   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0  14   0   0   0   0  95   3   0   0   0   2\n",
      "   0   0   0   0   0   0   0   4   0   0   0   0  25  34   0   0   1   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   9   1   5   0   0   0\n",
      "   0   0   0   0   0   0   0   2   0   0   0   0  10   1   0   9   0   0\n",
      "   1   0   0   0   0   0   2   2   1   0   0   0  10   0   0   0   5   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0]\n",
      "LR Accuracy:  0.5022488755622189\n",
      "LR F1:  0.35080530005537575\n",
      "For name:  k_sato\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0001-6110-9171': 35, '0000-0001-5768-2442': 9, '0000-0001-6706-2175': 7, '0000-0002-3998-7012': 7, '0000-0001-9078-2541': 6, '0000-0003-4045-7796': 1})\n",
      "['0000-0001-6110-9171']\n",
      "Total sample size after apply threshold:  35\n",
      "For name:  f_ahmed\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-7464-7726': 9, '0000-0003-1294-5274': 9, '0000-0002-9839-7039': 4, '0000-0002-8444-2038': 1, '0000-0003-4100-1571': 1, '0000-0001-5256-4666': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  y_watanabe\n",
      "total sample size before apply threshold:  98\n",
      "Counter({'0000-0002-7139-4903': 80, '0000-0001-7740-1361': 11, '0000-0002-7013-3613': 2, '0000-0002-7120-3097': 2, '0000-0001-9999-0486': 1, '0000-0002-6281-9295': 1, '0000-0002-9668-3592': 1})\n",
      "['0000-0002-7139-4903', '0000-0001-7740-1361']\n",
      "Total sample size after apply threshold:  91\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 38)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 31)\n",
      "2\n",
      "(91, 69)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.96        80\n",
      "          1       0.70      0.64      0.67        11\n",
      "\n",
      "avg / total       0.92      0.92      0.92        91\n",
      "\n",
      "[77  3  4  7]\n",
      "MNB Accuracy:  0.9230769230769231\n",
      "MNB F1:  0.8115942028985508\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97        80\n",
      "          1       0.88      0.64      0.74        11\n",
      "\n",
      "avg / total       0.94      0.95      0.94        91\n",
      "\n",
      "[79  1  4  7]\n",
      "svc Accuracy:  0.945054945054945\n",
      "svc F1:  0.8530836293186954\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        80\n",
      "          1       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.94      0.93      0.92        91\n",
      "\n",
      "[80  0  6  5]\n",
      "LR Accuracy:  0.9340659340659341\n",
      "LR F1:  0.7944277108433735\n",
      "For name:  k_singh\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-3152-1119': 10, '0000-0002-9375-3233': 6, '0000-0001-8352-5897': 3, '0000-0002-4126-9618': 3, '0000-0001-7187-4782': 1, '0000-0002-5199-9331': 1, '0000-0002-2913-6644': 1})\n",
      "['0000-0003-3152-1119']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  j_mcevoy\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0001-6530-5479': 53, '0000-0003-0382-1288': 8, '0000-0001-6843-5551': 2, '0000-0001-9591-1824': 2})\n",
      "['0000-0001-6530-5479']\n",
      "Total sample size after apply threshold:  53\n",
      "For name:  g_singh\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0003-1525-3898': 13, '0000-0001-9700-3344': 11, '0000-0002-1641-5070': 6, '0000-0002-4354-269X': 2, '0000-0002-2113-4230': 1, '0000-0002-9579-6093': 1, '0000-0001-5496-6992': 1, '0000-0002-2670-9814': 1})\n",
      "['0000-0001-9700-3344', '0000-0003-1525-3898']\n",
      "Total sample size after apply threshold:  24\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 5)\n",
      "2\n",
      "(24, 24)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.55      0.67        11\n",
      "          1       0.71      0.92      0.80        13\n",
      "\n",
      "avg / total       0.78      0.75      0.74        24\n",
      "\n",
      "[ 6  5  1 12]\n",
      "MNB Accuracy:  0.75\n",
      "MNB F1:  0.7333333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73        11\n",
      "          1       0.77      0.77      0.77        13\n",
      "\n",
      "avg / total       0.75      0.75      0.75        24\n",
      "\n",
      "[ 8  3  3 10]\n",
      "svc Accuracy:  0.75\n",
      "svc F1:  0.7482517482517483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.73      0.80        11\n",
      "          1       0.80      0.92      0.86        13\n",
      "\n",
      "avg / total       0.84      0.83      0.83        24\n",
      "\n",
      "[ 8  3  1 12]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.8285714285714285\n",
      "For name:  e_ford\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-7885-0019': 34, '0000-0001-5613-8509': 14, '0000-0001-7358-798X': 4, '0000-0003-0952-3660': 2})\n",
      "['0000-0002-7885-0019', '0000-0001-5613-8509']\n",
      "Total sample size after apply threshold:  48\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 25)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 13)\n",
      "2\n",
      "(48, 38)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88        34\n",
      "          1       0.71      0.71      0.71        14\n",
      "\n",
      "avg / total       0.83      0.83      0.83        48\n",
      "\n",
      "[30  4  4 10]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.7983193277310925\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.88      0.85        34\n",
      "          1       0.64      0.50      0.56        14\n",
      "\n",
      "avg / total       0.76      0.77      0.76        48\n",
      "\n",
      "[30  4  7  7]\n",
      "svc Accuracy:  0.7708333333333334\n",
      "svc F1:  0.7025352112676057\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.94      0.84        34\n",
      "          1       0.67      0.29      0.40        14\n",
      "\n",
      "avg / total       0.73      0.75      0.71        48\n",
      "\n",
      "[32  2 10  4]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.6210526315789473\n",
      "For name:  s_chou\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0001-9237-4517': 16, '0000-0003-1155-6082': 8, '0000-0003-0787-0044': 6, '0000-0001-8081-1679': 4, '0000-0001-5512-9977': 2, '0000-0002-4121-019X': 2, '0000-0001-8163-7430': 1})\n",
      "['0000-0001-9237-4517']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  s_hughes\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0001-8227-9225': 74, '0000-0002-9409-9405': 12, '0000-0001-8360-929X': 6, '0000-0002-2264-8479': 5, '0000-0002-9778-140X': 3, '0000-0001-6340-2646': 3, '0000-0001-7689-4272': 1, '0000-0002-8187-4871': 1, '0000-0003-4542-1821': 1})\n",
      "['0000-0002-9409-9405', '0000-0001-8227-9225']\n",
      "Total sample size after apply threshold:  86\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 30)\n",
      "2\n",
      "(86, 78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.25      0.32        12\n",
      "          1       0.89      0.95      0.92        74\n",
      "\n",
      "avg / total       0.82      0.85      0.83        86\n",
      "\n",
      "[ 3  9  4 70]\n",
      "MNB Accuracy:  0.8488372093023255\n",
      "MNB F1:  0.6154110767113863\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.50      0.55        12\n",
      "          1       0.92      0.95      0.93        74\n",
      "\n",
      "avg / total       0.88      0.88      0.88        86\n",
      "\n",
      "[ 6  6  4 70]\n",
      "svc Accuracy:  0.8837209302325582\n",
      "svc F1:  0.7393939393939393\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.86      0.99      0.92        74\n",
      "\n",
      "avg / total       0.74      0.85      0.79        86\n",
      "\n",
      "[ 0 12  1 73]\n",
      "LR Accuracy:  0.8488372093023255\n",
      "LR F1:  0.4591194968553459\n",
      "For name:  m_thomas\n",
      "total sample size before apply threshold:  225\n",
      "Counter({'0000-0002-2452-981X': 69, '0000-0001-5939-1155': 52, '0000-0001-6394-8710': 24, '0000-0003-4374-1039': 18, '0000-0002-4951-9925': 14, '0000-0003-2360-255X': 13, '0000-0002-3042-0669': 10, '0000-0002-5553-5825': 8, '0000-0002-5089-5610': 4, '0000-0003-0354-8779': 4, '0000-0003-2982-0291': 3, '0000-0001-8093-4919': 3, '0000-0002-7569-6896': 1, '0000-0003-2288-1104': 1, '0000-0001-6291-6426': 1})\n",
      "['0000-0001-6394-8710', '0000-0002-3042-0669', '0000-0002-4951-9925', '0000-0003-2360-255X', '0000-0001-5939-1155', '0000-0002-2452-981X', '0000-0003-4374-1039']\n",
      "Total sample size after apply threshold:  200\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(200, 120)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(200, 23)\n",
      "2\n",
      "(200, 143)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.54      0.57        24\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.40      0.14      0.21        14\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.59      0.77      0.67        52\n",
      "          5       0.60      0.88      0.71        69\n",
      "          6       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.46      0.58      0.50       200\n",
      "\n",
      "[13  0  1  0  5  4  1  2  0  0  0  3  5  0  4  0  2  0  3  4  1  1  0  0\n",
      "  0  4  7  1  1  0  0  0 40 11  0  0  0  0  0  8 61  0  1  0  2  0  5 10\n",
      "  0]\n",
      "MNB Accuracy:  0.58\n",
      "MNB F1:  0.30798009516544983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.54      0.59        24\n",
      "          1       1.00      0.80      0.89        10\n",
      "          2       0.44      0.29      0.35        14\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.67      0.79      0.73        52\n",
      "          5       0.68      0.91      0.78        69\n",
      "          6       0.29      0.11      0.16        18\n",
      "\n",
      "avg / total       0.59      0.66      0.61       200\n",
      "\n",
      "[13  0  0  0  5  4  2  1  8  0  0  0  1  0  2  0  4  0  3  3  2  1  0  0\n",
      "  0  4  7  1  1  0  3  0 41  7  0  0  0  0  2  4 63  0  2  0  2  0  4  8\n",
      "  2]\n",
      "svc Accuracy:  0.655\n",
      "svc F1:  0.4987236516209198\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.54      0.59        24\n",
      "          1       1.00      0.20      0.33        10\n",
      "          2       0.67      0.29      0.40        14\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.62      0.77      0.69        52\n",
      "          5       0.60      0.90      0.72        69\n",
      "          6       0.25      0.06      0.09        18\n",
      "\n",
      "avg / total       0.57      0.61      0.55       200\n",
      "\n",
      "[13  0  0  0  5  5  1  2  2  0  0  1  5  0  2  0  4  0  3  4  1  1  0  0\n",
      "  0  4  7  1  1  0  0  0 40 11  0  0  0  0  0  7 62  0  1  0  2  0  4 10\n",
      "  1]\n",
      "LR Accuracy:  0.61\n",
      "LR F1:  0.403081384763665\n",
      "For name:  j_liang\n",
      "total sample size before apply threshold:  105\n",
      "Counter({'0000-0002-0264-7735': 84, '0000-0002-4532-0118': 8, '0000-0001-6055-0918': 4, '0000-0001-9439-9320': 3, '0000-0002-2773-6427': 2, '0000-0001-8252-5502': 2, '0000-0003-3994-5709': 1, '0000-0002-8210-0210': 1})\n",
      "['0000-0002-0264-7735']\n",
      "Total sample size after apply threshold:  84\n",
      "For name:  t_wu\n",
      "total sample size before apply threshold:  168\n",
      "Counter({'0000-0003-0845-4827': 68, '0000-0001-8235-5929': 34, '0000-0002-0244-3046': 11, '0000-0003-1845-1769': 11, '0000-0002-2663-2001': 11, '0000-0002-9859-4534': 10, '0000-0002-0060-4408': 7, '0000-0001-5155-6189': 7, '0000-0002-6519-469X': 3, '0000-0002-3560-8898': 2, '0000-0001-6444-598X': 2, '0000-0001-6469-9613': 1, '0000-0002-8775-597X': 1})\n",
      "['0000-0002-0244-3046', '0000-0003-0845-4827', '0000-0003-1845-1769', '0000-0001-8235-5929', '0000-0002-2663-2001', '0000-0002-9859-4534']\n",
      "Total sample size after apply threshold:  145\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(145, 67)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(145, 14)\n",
      "2\n",
      "(145, 81)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.58      1.00      0.73        68\n",
      "          2       1.00      0.45      0.62        11\n",
      "          3       0.68      0.38      0.49        34\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       0.67      0.20      0.31        10\n",
      "\n",
      "avg / total       0.55      0.61      0.53       145\n",
      "\n",
      "[ 0 10  0  1  0  0  0 68  0  0  0  0  0  5  5  1  0  0  0 20  0 13  0  1\n",
      "  0 10  0  1  0  0  0  5  0  3  0  2]\n",
      "MNB Accuracy:  0.6068965517241379\n",
      "MNB F1:  0.3590735235211802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.27      0.33        11\n",
      "          1       0.73      0.90      0.81        68\n",
      "          2       1.00      0.73      0.84        11\n",
      "          3       0.56      0.59      0.57        34\n",
      "          4       0.71      0.45      0.56        11\n",
      "          5       0.50      0.20      0.29        10\n",
      "\n",
      "avg / total       0.67      0.68      0.66       145\n",
      "\n",
      "[ 3  5  0  3  0  0  4 61  0  3  0  0  0  2  8  1  0  0  0 12  0 20  1  1\n",
      "  0  1  0  4  5  1  0  2  0  5  1  2]\n",
      "svc Accuracy:  0.6827586206896552\n",
      "svc F1:  0.5660140048428651\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.60      0.96      0.73        68\n",
      "          2       1.00      0.73      0.84        11\n",
      "          3       0.70      0.47      0.56        34\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       0.67      0.20      0.31        10\n",
      "\n",
      "avg / total       0.56      0.63      0.56       145\n",
      "\n",
      "[ 0 10  0  1  0  0  2 65  0  1  0  0  0  2  8  1  0  0  0 17  0 16  0  1\n",
      "  0 10  0  1  0  0  0  5  0  3  0  2]\n",
      "LR Accuracy:  0.6275862068965518\n",
      "LR F1:  0.4076107260763817\n",
      "For name:  b_ahmed\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0001-6021-1414': 10, '0000-0001-9110-4136': 6, '0000-0002-6707-822X': 4, '0000-0002-4840-6945': 3})\n",
      "['0000-0001-6021-1414']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  m_takahashi\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-3799-2256': 41, '0000-0001-7273-1660': 11, '0000-0003-3233-6783': 1, '0000-0001-6141-0554': 1})\n",
      "['0000-0002-3799-2256', '0000-0001-7273-1660']\n",
      "Total sample size after apply threshold:  52\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 33)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 13)\n",
      "2\n",
      "(52, 46)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        41\n",
      "          1       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.86      0.83      0.78        52\n",
      "\n",
      "[41  0  9  2]\n",
      "MNB Accuracy:  0.8269230769230769\n",
      "MNB F1:  0.6043956043956045\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90        41\n",
      "          1       0.75      0.27      0.40        11\n",
      "\n",
      "avg / total       0.82      0.83      0.79        52\n",
      "\n",
      "[40  1  8  3]\n",
      "svc Accuracy:  0.8269230769230769\n",
      "svc F1:  0.649438202247191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        41\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.62      0.79      0.70        52\n",
      "\n",
      "[41  0 11  0]\n",
      "LR Accuracy:  0.7884615384615384\n",
      "LR F1:  0.44086021505376344\n",
      "For name:  i_lee\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-2588-1444': 41, '0000-0002-0098-392X': 16, '0000-0003-0520-4435': 7, '0000-0001-6057-7176': 5, '0000-0003-1923-0917': 1, '0000-0003-3760-4257': 1, '0000-0001-8167-7168': 1, '0000-0002-9103-0955': 1})\n",
      "['0000-0002-0098-392X', '0000-0002-2588-1444']\n",
      "Total sample size after apply threshold:  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 26)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 18)\n",
      "2\n",
      "(57, 44)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.38      0.48        16\n",
      "          1       0.79      0.93      0.85        41\n",
      "\n",
      "avg / total       0.76      0.77      0.75        57\n",
      "\n",
      "[ 6 10  3 38]\n",
      "MNB Accuracy:  0.7719298245614035\n",
      "MNB F1:  0.6669662921348315\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.55        16\n",
      "          1       0.80      1.00      0.89        41\n",
      "\n",
      "avg / total       0.86      0.82      0.79        57\n",
      "\n",
      "[ 6 10  0 41]\n",
      "svc Accuracy:  0.8245614035087719\n",
      "svc F1:  0.7183794466403162\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.19      0.32        16\n",
      "          1       0.76      1.00      0.86        41\n",
      "\n",
      "avg / total       0.83      0.77      0.71        57\n",
      "\n",
      "[ 3 13  0 41]\n",
      "LR Accuracy:  0.7719298245614035\n",
      "LR F1:  0.5894736842105264\n",
      "For name:  a_figueiredo\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-9105-9619': 79, '0000-0002-3239-3190': 19, '0000-0001-6956-0514': 16, '0000-0001-8156-7700': 14, '0000-0001-8386-8216': 9, '0000-0001-7039-5341': 6, '0000-0003-2329-2854': 3, '0000-0003-0487-8956': 3, '0000-0002-8555-8649': 1})\n",
      "['0000-0001-6956-0514', '0000-0001-8156-7700', '0000-0002-9105-9619', '0000-0002-3239-3190']\n",
      "Total sample size after apply threshold:  128\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(128, 75)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(128, 19)\n",
      "2\n",
      "(128, 94)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.19      0.32        16\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.64      0.96      0.77        79\n",
      "          3       0.60      0.16      0.25        19\n",
      "\n",
      "avg / total       0.61      0.64      0.55       128\n",
      "\n",
      "[ 3  0 13  0  0  0 14  0  0  1 76  2  0  0 16  3]\n",
      "MNB Accuracy:  0.640625\n",
      "MNB F1:  0.33336656034024453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        16\n",
      "          1       0.57      0.29      0.38        14\n",
      "          2       0.76      0.95      0.84        79\n",
      "          3       0.83      0.53      0.65        19\n",
      "\n",
      "avg / total       0.78      0.77      0.75       128\n",
      "\n",
      "[10  0  6  0  0  4 10  0  0  2 75  2  0  1  8 10]\n",
      "svc Accuracy:  0.7734375\n",
      "svc F1:  0.6595102674298035\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        16\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.65      1.00      0.79        79\n",
      "          3       1.00      0.11      0.19        19\n",
      "\n",
      "avg / total       0.67      0.66      0.56       128\n",
      "\n",
      "[ 4  0 12  0  0  0 14  0  0  0 79  0  0  0 17  2]\n",
      "LR Accuracy:  0.6640625\n",
      "LR F1:  0.344136460554371\n",
      "For name:  s_clark\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0001-5907-9671': 12, '0000-0002-7488-3438': 9, '0000-0001-7328-0726': 8, '0000-0002-6183-491X': 4, '0000-0001-8394-8355': 3, '0000-0003-4090-6002': 1, '0000-0002-2072-7499': 1, '0000-0002-7633-3376': 1})\n",
      "['0000-0001-5907-9671']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  a_schmid\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-5196-151X': 28, '0000-0001-7759-0211': 19, '0000-0001-6483-8759': 10, '0000-0002-0141-0971': 4})\n",
      "['0000-0001-7759-0211', '0000-0001-6483-8759', '0000-0002-5196-151X']\n",
      "Total sample size after apply threshold:  57\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 11)\n",
      "2\n",
      "(57, 48)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.37      0.45        19\n",
      "          1       0.67      0.20      0.31        10\n",
      "          2       0.62      0.93      0.74        28\n",
      "\n",
      "avg / total       0.62      0.61      0.57        57\n",
      "\n",
      "[ 7  0 12  4  2  4  1  1 26]\n",
      "MNB Accuracy:  0.6140350877192983\n",
      "MNB F1:  0.5007207845917524\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.68      0.59        19\n",
      "          1       0.50      0.20      0.29        10\n",
      "          2       0.75      0.75      0.75        28\n",
      "\n",
      "avg / total       0.63      0.63      0.62        57\n",
      "\n",
      "[13  2  4  5  2  3  7  0 21]\n",
      "svc Accuracy:  0.631578947368421\n",
      "svc F1:  0.5422077922077922\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.47      0.50        19\n",
      "          1       1.00      0.20      0.33        10\n",
      "          2       0.66      0.89      0.76        28\n",
      "\n",
      "avg / total       0.68      0.63      0.60        57\n",
      "\n",
      "[ 9  0 10  5  2  3  3  0 25]\n",
      "LR Accuracy:  0.631578947368421\n",
      "LR F1:  0.5303030303030304\n",
      "For name:  k_cheung\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0002-6759-4961': 9, '0000-0002-8348-1561': 4, '0000-0003-4107-7840': 2, '0000-0001-7648-4556': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_ma\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-1897-7069': 69, '0000-0002-2029-7943': 42, '0000-0002-1810-8357': 9, '0000-0002-0232-8590': 6, '0000-0001-8581-2216': 3, '0000-0002-2704-3540': 2, '0000-0001-8087-0249': 1, '0000-0001-6361-9706': 1, '0000-0002-7995-2041': 1, '0000-0003-4846-9513': 1, '0000-0002-8992-1177': 1})\n",
      "['0000-0002-2029-7943', '0000-0002-1897-7069']\n",
      "Total sample size after apply threshold:  111\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 12)\n",
      "2\n",
      "(111, 51)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.62      0.74        42\n",
      "          1       0.81      0.97      0.88        69\n",
      "\n",
      "avg / total       0.85      0.84      0.83       111\n",
      "\n",
      "[26 16  2 67]\n",
      "MNB Accuracy:  0.8378378378378378\n",
      "MNB F1:  0.8122180451127821\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        42\n",
      "          1       1.00      0.90      0.95        69\n",
      "\n",
      "avg / total       0.95      0.94      0.94       111\n",
      "\n",
      "[42  0  7 62]\n",
      "svc Accuracy:  0.9369369369369369\n",
      "svc F1:  0.9348209042865532\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.81      0.86        42\n",
      "          1       0.89      0.96      0.92        69\n",
      "\n",
      "avg / total       0.90      0.90      0.90       111\n",
      "\n",
      "[34  8  3 66]\n",
      "LR Accuracy:  0.9009009009009009\n",
      "LR F1:  0.8919182083739046\n",
      "For name:  m_marino\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0001-9155-6378': 14, '0000-0002-0045-0234': 11, '0000-0002-7470-7493': 11, '0000-0001-7443-3472': 9, '0000-0003-2031-1191': 8, '0000-0003-1226-6036': 7, '0000-0002-4323-3061': 5, '0000-0002-8672-0310': 3, '0000-0003-4651-6128': 1})\n",
      "['0000-0001-9155-6378', '0000-0002-0045-0234', '0000-0002-7470-7493']\n",
      "Total sample size after apply threshold:  36\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 29)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 14)\n",
      "2\n",
      "(36, 43)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.64      0.60        14\n",
      "          1       0.80      0.36      0.50        11\n",
      "          2       0.60      0.82      0.69        11\n",
      "\n",
      "avg / total       0.65      0.61      0.60        36\n",
      "\n",
      "[9 1 4 5 4 2 2 0 9]\n",
      "MNB Accuracy:  0.6111111111111112\n",
      "MNB F1:  0.5974358974358974\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.64      0.60        14\n",
      "          1       0.60      0.55      0.57        11\n",
      "          2       0.70      0.64      0.67        11\n",
      "\n",
      "avg / total       0.62      0.61      0.61        36\n",
      "\n",
      "[9 3 2 4 6 1 3 1 7]\n",
      "svc Accuracy:  0.6111111111111112\n",
      "svc F1:  0.6126984126984126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.64      0.64        14\n",
      "          1       0.62      0.45      0.53        11\n",
      "          2       0.64      0.82      0.72        11\n",
      "\n",
      "avg / total       0.64      0.64      0.63        36\n",
      "\n",
      "[9 2 3 4 5 2 1 1 9]\n",
      "LR Accuracy:  0.6388888888888888\n",
      "LR F1:  0.6297243107769424\n",
      "For name:  a_kirby\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0002-2440-9316': 26, '0000-0001-5663-2961': 25, '0000-0002-6928-668X': 9, '0000-0003-0395-6684': 4})\n",
      "['0000-0002-2440-9316', '0000-0001-5663-2961']\n",
      "Total sample size after apply threshold:  51\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 20)\n",
      "2\n",
      "(51, 57)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85        26\n",
      "          1       0.87      0.80      0.83        25\n",
      "\n",
      "avg / total       0.85      0.84      0.84        51\n",
      "\n",
      "[23  3  5 20]\n",
      "MNB Accuracy:  0.8431372549019608\n",
      "MNB F1:  0.8425925925925926\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.85      0.90        26\n",
      "          1       0.86      0.96      0.91        25\n",
      "\n",
      "avg / total       0.91      0.90      0.90        51\n",
      "\n",
      "[22  4  1 24]\n",
      "svc Accuracy:  0.9019607843137255\n",
      "svc F1:  0.9018097805159799\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.81      0.84        26\n",
      "          1       0.81      0.88      0.85        25\n",
      "\n",
      "avg / total       0.85      0.84      0.84        51\n",
      "\n",
      "[21  5  3 22]\n",
      "LR Accuracy:  0.8431372549019608\n",
      "LR F1:  0.8430769230769231\n",
      "For name:  d_roberts\n",
      "total sample size before apply threshold:  105\n",
      "Counter({'0000-0002-2481-2981': 47, '0000-0001-6111-6291': 20, '0000-0003-0261-691X': 14, '0000-0002-0668-2001': 12, '0000-0001-7175-7754': 10, '0000-0003-0264-921X': 1, '0000-0002-0780-7056': 1})\n",
      "['0000-0001-7175-7754', '0000-0001-6111-6291', '0000-0003-0261-691X', '0000-0002-2481-2981', '0000-0002-0668-2001']\n",
      "Total sample size after apply threshold:  103\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 73)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 14)\n",
      "2\n",
      "(103, 87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.54      0.35      0.42        20\n",
      "          2       0.50      0.07      0.12        14\n",
      "          3       0.53      0.87      0.66        47\n",
      "          4       0.75      0.50      0.60        12\n",
      "\n",
      "avg / total       0.60      0.56      0.52       103\n",
      "\n",
      "[ 3  0  0  7  0  0  7  0 13  0  0  1  1 11  1  0  4  1 41  1  0  1  0  5\n",
      "  6]\n",
      "MNB Accuracy:  0.5631067961165048\n",
      "MNB F1:  0.4544142416723062\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.30      0.43        10\n",
      "          1       0.56      0.45      0.50        20\n",
      "          2       0.43      0.21      0.29        14\n",
      "          3       0.55      0.79      0.65        47\n",
      "          4       0.78      0.58      0.67        12\n",
      "\n",
      "avg / total       0.58      0.57      0.55       103\n",
      "\n",
      "[ 3  0  0  7  0  0  9  0 11  0  0  2  3  8  1  0  5  4 37  1  1  0  0  4\n",
      "  7]\n",
      "svc Accuracy:  0.5728155339805825\n",
      "svc F1:  0.5060150375939849\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        10\n",
      "          1       0.50      0.30      0.37        20\n",
      "          2       1.00      0.07      0.13        14\n",
      "          3       0.51      0.89      0.65        47\n",
      "          4       0.86      0.50      0.63        12\n",
      "\n",
      "avg / total       0.66      0.54      0.48       103\n",
      "\n",
      "[ 1  0  0  9  0  0  6  0 14  0  0  1  1 11  1  0  5  0 42  0  0  0  0  6\n",
      "  6]\n",
      "LR Accuracy:  0.5436893203883495\n",
      "LR F1:  0.39457865064352216\n",
      "For name:  b_thompson\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0002-5885-0652': 65, '0000-0002-5358-0796': 8, '0000-0002-2302-0886': 7, '0000-0002-3845-824X': 3})\n",
      "['0000-0002-5885-0652']\n",
      "Total sample size after apply threshold:  65\n",
      "For name:  j_blanco\n",
      "total sample size before apply threshold:  362\n",
      "Counter({'0000-0003-0264-4136': 102, '0000-0002-2225-0217': 91, '0000-0001-8142-0450': 74, '0000-0003-3765-0640': 41, '0000-0003-0647-3856': 40, '0000-0002-5071-4760': 7, '0000-0002-6524-4335': 5, '0000-0002-7351-5342': 1, '0000-0003-0191-2063': 1})\n",
      "['0000-0003-0264-4136', '0000-0003-0647-3856', '0000-0002-2225-0217', '0000-0003-3765-0640', '0000-0001-8142-0450']\n",
      "Total sample size after apply threshold:  348\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(348, 141)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(348, 32)\n",
      "2\n",
      "(348, 173)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.88      0.72       102\n",
      "          1       1.00      0.40      0.57        40\n",
      "          2       0.62      0.82      0.71        91\n",
      "          3       0.90      0.22      0.35        41\n",
      "          4       0.75      0.55      0.64        74\n",
      "\n",
      "avg / total       0.72      0.66      0.64       348\n",
      "\n",
      "[90  0  8  0  4 11 16 12  0  1 12  0 75  0  4 11  0 16  9  5 23  0  9  1\n",
      " 41]\n",
      "MNB Accuracy:  0.6637931034482759\n",
      "MNB F1:  0.5987641405653102\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.83      0.77       102\n",
      "          1       1.00      0.68      0.81        40\n",
      "          2       0.65      0.86      0.74        91\n",
      "          3       0.80      0.39      0.52        41\n",
      "          4       0.76      0.64      0.69        74\n",
      "\n",
      "avg / total       0.75      0.73      0.72       348\n",
      "\n",
      "[85  0  9  0  8  5 27  8  0  0  7  0 78  2  4  5  0 17 16  3 17  0  8  2\n",
      " 47]\n",
      "svc Accuracy:  0.7270114942528736\n",
      "svc F1:  0.7060608091796314\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.82      0.74       102\n",
      "          1       1.00      0.53      0.69        40\n",
      "          2       0.63      0.86      0.73        91\n",
      "          3       0.92      0.27      0.42        41\n",
      "          4       0.69      0.62      0.65        74\n",
      "\n",
      "avg / total       0.73      0.69      0.67       348\n",
      "\n",
      "[84  0 10  0  8  6 21 11  0  2  9  0 78  0  4  6  0 17 11  7 19  0  8  1\n",
      " 46]\n",
      "LR Accuracy:  0.6896551724137931\n",
      "LR F1:  0.6450090852994733\n",
      "For name:  x_cai\n",
      "total sample size before apply threshold:  79\n",
      "Counter({'0000-0001-8933-7133': 32, '0000-0002-5654-7414': 31, '0000-0003-4907-154X': 9, '0000-0003-3706-4414': 4, '0000-0003-0222-553X': 2, '0000-0001-5238-6193': 1})\n",
      "['0000-0002-5654-7414', '0000-0001-8933-7133']\n",
      "Total sample size after apply threshold:  63\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 14)\n",
      "2\n",
      "(63, 49)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.87      0.81        31\n",
      "          1       0.85      0.72      0.78        32\n",
      "\n",
      "avg / total       0.80      0.79      0.79        63\n",
      "\n",
      "[27  4  9 23]\n",
      "MNB Accuracy:  0.7936507936507936\n",
      "MNB F1:  0.7928155831014418\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.61      0.69        31\n",
      "          1       0.69      0.84      0.76        32\n",
      "\n",
      "avg / total       0.74      0.73      0.73        63\n",
      "\n",
      "[19 12  5 27]\n",
      "svc Accuracy:  0.7301587301587301\n",
      "svc F1:  0.7257362355953906\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.65      0.70        31\n",
      "          1       0.70      0.81      0.75        32\n",
      "\n",
      "avg / total       0.74      0.73      0.73        63\n",
      "\n",
      "[20 11  6 26]\n",
      "LR Accuracy:  0.7301587301587301\n",
      "LR F1:  0.7276887871853547\n",
      "For name:  r_menezes\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0003-0552-8480': 15, '0000-0002-6612-3543': 6, '0000-0003-3109-9683': 5, '0000-0003-4316-2168': 2, '0000-0002-4842-641X': 1})\n",
      "['0000-0003-0552-8480']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  s_tsang\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0003-0788-4905': 6, '0000-0002-9862-8503': 5, '0000-0001-6099-6696': 5, '0000-0002-2232-9814': 4})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_king\n",
      "total sample size before apply threshold:  218\n",
      "Counter({'0000-0001-8349-9270': 145, '0000-0002-6078-2601': 65, '0000-0002-0892-1301': 4, '0000-0003-1157-5734': 2, '0000-0002-6641-237X': 2})\n",
      "['0000-0002-6078-2601', '0000-0001-8349-9270']\n",
      "Total sample size after apply threshold:  210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(210, 73)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(210, 32)\n",
      "2\n",
      "(210, 105)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.65      0.67        65\n",
      "          1       0.85      0.88      0.86       145\n",
      "\n",
      "avg / total       0.80      0.80      0.80       210\n",
      "\n",
      "[ 42  23  18 127]\n",
      "MNB Accuracy:  0.8047619047619048\n",
      "MNB F1:  0.7665084745762711\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.63      0.69        65\n",
      "          1       0.85      0.91      0.88       145\n",
      "\n",
      "avg / total       0.82      0.82      0.82       210\n",
      "\n",
      "[ 41  24  13 132]\n",
      "svc Accuracy:  0.8238095238095238\n",
      "svc F1:  0.7830760211061168\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.52      0.62        65\n",
      "          1       0.81      0.92      0.86       145\n",
      "\n",
      "avg / total       0.79      0.80      0.79       210\n",
      "\n",
      "[ 34  31  11 134]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.7413489736070382\n",
      "For name:  h_kobayashi\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0003-4965-0883': 16, '0000-0002-8460-587X': 9, '0000-0001-9091-3521': 2, '0000-0002-8956-0375': 1})\n",
      "['0000-0003-4965-0883']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  k_yang\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0002-9128-9166': 19, '0000-0002-3162-7709': 14, '0000-0001-5968-6738': 12, '0000-0003-0047-2238': 10, '0000-0002-9691-0636': 6, '0000-0002-0587-3201': 5, '0000-0002-0809-2371': 1, '0000-0002-3398-9332': 1, '0000-0001-7963-4337': 1, '0000-0002-8224-5161': 1})\n",
      "['0000-0002-3162-7709', '0000-0002-9128-9166', '0000-0001-5968-6738', '0000-0003-0047-2238']\n",
      "Total sample size after apply threshold:  55\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 13)\n",
      "2\n",
      "(55, 57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.50      0.52        14\n",
      "          1       0.50      0.74      0.60        19\n",
      "          2       0.44      0.33      0.38        12\n",
      "          3       0.60      0.30      0.40        10\n",
      "\n",
      "avg / total       0.52      0.51      0.49        55\n",
      "\n",
      "[ 7  4  1  2  2 14  3  0  2  6  4  0  2  4  1  3]\n",
      "MNB Accuracy:  0.509090909090909\n",
      "MNB F1:  0.4738038950804908\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.36      0.40        14\n",
      "          1       0.48      0.84      0.62        19\n",
      "          2       0.71      0.42      0.53        12\n",
      "          3       0.50      0.20      0.29        10\n",
      "\n",
      "avg / total       0.53      0.51      0.48        55\n",
      "\n",
      "[ 5  6  1  2  2 16  1  0  1  6  5  0  3  5  0  2]\n",
      "svc Accuracy:  0.509090909090909\n",
      "svc F1:  0.4568536726431463\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.43      0.46        14\n",
      "          1       0.48      0.74      0.58        19\n",
      "          2       0.44      0.33      0.38        12\n",
      "          3       0.60      0.30      0.40        10\n",
      "\n",
      "avg / total       0.50      0.49      0.47        55\n",
      "\n",
      "[ 6  4  2  2  2 14  3  0  2  6  4  0  2  5  0  3]\n",
      "LR Accuracy:  0.4909090909090909\n",
      "LR F1:  0.456456043956044\n",
      "For name:  b_zheng\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0002-7682-6648': 82, '0000-0002-3272-843X': 5, '0000-0003-1551-0970': 2, '0000-0002-2044-2848': 1})\n",
      "['0000-0002-7682-6648']\n",
      "Total sample size after apply threshold:  82\n",
      "For name:  f_xu\n",
      "total sample size before apply threshold:  94\n",
      "Counter({'0000-0003-4351-0222': 29, '0000-0002-8465-5834': 22, '0000-0001-5239-4572': 19, '0000-0001-7958-3787': 12, '0000-0002-0245-057X': 5, '0000-0002-8166-0275': 4, '0000-0003-1600-6346': 2, '0000-0002-2598-2528': 1})\n",
      "['0000-0001-7958-3787', '0000-0001-5239-4572', '0000-0003-4351-0222', '0000-0002-8465-5834']\n",
      "Total sample size after apply threshold:  82\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 46)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 12)\n",
      "2\n",
      "(82, 58)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.33      0.44        12\n",
      "          1       0.79      0.79      0.79        19\n",
      "          2       0.85      0.97      0.90        29\n",
      "          3       0.67      0.73      0.70        22\n",
      "\n",
      "avg / total       0.76      0.77      0.75        82\n",
      "\n",
      "[ 4  0  2  6  0 15  2  2  0  1 28  0  2  3  1 16]\n",
      "MNB Accuracy:  0.7682926829268293\n",
      "MNB F1:  0.7081990272549068\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.50      0.60        12\n",
      "          1       1.00      0.84      0.91        19\n",
      "          2       0.87      0.93      0.90        29\n",
      "          3       0.67      0.82      0.73        22\n",
      "\n",
      "avg / total       0.83      0.82      0.82        82\n",
      "\n",
      "[ 6  0  1  5  0 16  1  2  0  0 27  2  2  0  2 18]\n",
      "svc Accuracy:  0.8170731707317073\n",
      "svc F1:  0.7872448979591836\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.42      0.53        12\n",
      "          1       0.93      0.74      0.82        19\n",
      "          2       0.83      1.00      0.91        29\n",
      "          3       0.72      0.82      0.77        22\n",
      "\n",
      "avg / total       0.81      0.80      0.79        82\n",
      "\n",
      "[ 5  0  2  5  0 14  3  2  0  0 29  0  2  1  1 18]\n",
      "LR Accuracy:  0.8048780487804879\n",
      "LR F1:  0.7555131620117252\n",
      "For name:  r_day\n",
      "total sample size before apply threshold:  202\n",
      "Counter({'0000-0002-6045-6937': 149, '0000-0003-3442-2298': 39, '0000-0003-1766-4068': 6, '0000-0001-5913-2292': 5, '0000-0002-6155-5910': 2, '0000-0003-1467-3196': 1})\n",
      "['0000-0002-6045-6937', '0000-0003-3442-2298']\n",
      "Total sample size after apply threshold:  188\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(188, 92)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(188, 33)\n",
      "2\n",
      "(188, 125)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       149\n",
      "          1       0.82      0.46      0.59        39\n",
      "\n",
      "avg / total       0.86      0.87      0.85       188\n",
      "\n",
      "[145   4  21  18]\n",
      "MNB Accuracy:  0.8670212765957447\n",
      "MNB F1:  0.7553994275305751\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       149\n",
      "          1       1.00      0.56      0.72        39\n",
      "\n",
      "avg / total       0.92      0.91      0.90       188\n",
      "\n",
      "[149   0  17  22]\n",
      "svc Accuracy:  0.9095744680851063\n",
      "svc F1:  0.8336716107207911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       149\n",
      "          1       1.00      0.26      0.41        39\n",
      "\n",
      "avg / total       0.87      0.85      0.81       188\n",
      "\n",
      "[149   0  29  10]\n",
      "LR Accuracy:  0.8457446808510638\n",
      "LR F1:  0.6597391250078013\n",
      "For name:  j_young\n",
      "total sample size before apply threshold:  267\n",
      "Counter({'0000-0002-1514-1522': 124, '0000-0003-4182-341X': 40, '0000-0003-3849-3392': 30, '0000-0002-1294-942X': 23, '0000-0002-2711-9701': 17, '0000-0001-7219-7824': 16, '0000-0003-4886-9517': 10, '0000-0003-1745-2401': 4, '0000-0001-9791-2513': 2, '0000-0001-6583-7643': 1})\n",
      "['0000-0003-3849-3392', '0000-0002-1294-942X', '0000-0001-7219-7824', '0000-0003-4182-341X', '0000-0002-2711-9701', '0000-0003-4886-9517', '0000-0002-1514-1522']\n",
      "Total sample size after apply threshold:  260\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(260, 127)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(260, 27)\n",
      "2\n",
      "(260, 154)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.37      0.48        30\n",
      "          1       0.87      0.57      0.68        23\n",
      "          2       0.00      0.00      0.00        16\n",
      "          3       0.97      0.70      0.81        40\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.62      0.99      0.76       124\n",
      "\n",
      "avg / total       0.60      0.67      0.60       260\n",
      "\n",
      "[ 11   1   0   1   0   0  17   1  13   1   0   0   0   8   2   1   0   0\n",
      "   0   0  13   1   0   0  28   0   0  11   0   0   0   0   0   0  17   0\n",
      "   0   0   0   0   0  10   1   0   0   0   0   0 123]\n",
      "MNB Accuracy:  0.6730769230769231\n",
      "MNB F1:  0.3908107865571858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.47      0.57        30\n",
      "          1       0.76      0.57      0.65        23\n",
      "          2       0.83      0.31      0.45        16\n",
      "          3       1.00      0.75      0.86        40\n",
      "          4       1.00      0.41      0.58        17\n",
      "          5       1.00      0.60      0.75        10\n",
      "          6       0.70      0.99      0.82       124\n",
      "\n",
      "avg / total       0.80      0.76      0.74       260\n",
      "\n",
      "[ 14   2   0   0   0   0  14   1  13   1   0   0   0   8   2   2   5   0\n",
      "   0   0   7   0   0   0  30   0   0  10   1   0   0   0   7   0   9   0\n",
      "   0   0   0   0   6   4   1   0   0   0   0   0 123]\n",
      "svc Accuracy:  0.7615384615384615\n",
      "svc F1:  0.6698846701952293\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.30      0.41        30\n",
      "          1       0.92      0.48      0.63        23\n",
      "          2       0.00      0.00      0.00        16\n",
      "          3       0.96      0.60      0.74        40\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.58      0.98      0.73       124\n",
      "\n",
      "avg / total       0.58      0.64      0.57       260\n",
      "\n",
      "[  9   0   0   1   0   0  20   0  11   0   0   0   0  12   2   1   0   0\n",
      "   0   0  13   1   0   0  24   0   0  15   0   0   0   0   0   0  17   0\n",
      "   0   0   0   0   0  10   2   0   0   0   0   0 122]\n",
      "LR Accuracy:  0.6384615384615384\n",
      "LR F1:  0.35840808697951554\n",
      "For name:  c_black\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-0424-4593': 29, '0000-0003-2022-0337': 4, '0000-0003-2934-108X': 4, '0000-0002-1541-106X': 2, '0000-0001-8382-298X': 2})\n",
      "['0000-0002-0424-4593']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  s_joseph\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0003-4596-1270': 13, '0000-0002-4741-7183': 5, '0000-0003-1023-0718': 1, '0000-0002-9163-3027': 1})\n",
      "['0000-0003-4596-1270']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  z_fan\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0002-9312-2271': 13, '0000-0001-5385-9626': 13, '0000-0001-9492-5722': 6, '0000-0003-4623-6783': 4, '0000-0002-7818-153X': 1, '0000-0002-2145-2458': 1})\n",
      "['0000-0002-9312-2271', '0000-0001-5385-9626']\n",
      "Total sample size after apply threshold:  26\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 17)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 7)\n",
      "2\n",
      "(26, 24)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84        13\n",
      "          1       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.86      0.81      0.80        26\n",
      "\n",
      "[13  0  5  8]\n",
      "MNB Accuracy:  0.8076923076923077\n",
      "MNB F1:  0.8003072196620584\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.92      0.83        13\n",
      "          1       0.90      0.69      0.78        13\n",
      "\n",
      "avg / total       0.83      0.81      0.81        26\n",
      "\n",
      "[12  1  4  9]\n",
      "svc Accuracy:  0.8076923076923077\n",
      "svc F1:  0.8050974512743627\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.87        13\n",
      "          1       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.88      0.85      0.84        26\n",
      "\n",
      "[13  0  4  9]\n",
      "LR Accuracy:  0.8461538461538461\n",
      "LR F1:  0.8424242424242423\n",
      "For name:  j_matos\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-3754-3709': 12, '0000-0002-0505-8282': 5, '0000-0001-9917-6126': 4, '0000-0003-1335-0635': 3, '0000-0003-0570-7913': 1})\n",
      "['0000-0002-3754-3709']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  l_santos\n",
      "total sample size before apply threshold:  172\n",
      "Counter({'0000-0003-3040-0358': 55, '0000-0002-2712-0622': 32, '0000-0002-7013-8852': 15, '0000-0002-1915-6780': 13, '0000-0001-5166-530X': 11, '0000-0003-0986-9880': 10, '0000-0002-0694-733X': 9, '0000-0001-8366-1557': 5, '0000-0001-8906-9976': 5, '0000-0002-4453-5766': 4, '0000-0001-7551-5605': 3, '0000-0003-0458-427X': 3, '0000-0001-5915-1186': 2, '0000-0001-9172-6429': 1, '0000-0003-0568-917X': 1, '0000-0002-2221-6692': 1, '0000-0002-7992-7487': 1, '0000-0003-4466-1129': 1})\n",
      "['0000-0003-3040-0358', '0000-0002-1915-6780', '0000-0002-7013-8852', '0000-0003-0986-9880', '0000-0001-5166-530X', '0000-0002-2712-0622']\n",
      "Total sample size after apply threshold:  136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(136, 49)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(136, 16)\n",
      "2\n",
      "(136, 65)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.96      0.72        55\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       0.29      0.13      0.18        15\n",
      "          3       1.00      0.10      0.18        10\n",
      "          4       1.00      0.27      0.43        11\n",
      "          5       0.56      0.47      0.51        32\n",
      "\n",
      "avg / total       0.65      0.59      0.54       136\n",
      "\n",
      "[53  0  1  0  0  1  6  6  0  0  0  1  7  0  2  0  0  6  6  0  0  1  0  3\n",
      "  7  0  0  0  3  1 13  0  4  0  0 15]\n",
      "MNB Accuracy:  0.5882352941176471\n",
      "MNB F1:  0.4422249585369249\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.87      0.77        55\n",
      "          1       0.80      0.62      0.70        13\n",
      "          2       0.18      0.13      0.15        15\n",
      "          3       0.50      0.10      0.17        10\n",
      "          4       0.75      0.55      0.63        11\n",
      "          5       0.49      0.53      0.51        32\n",
      "\n",
      "avg / total       0.59      0.60      0.58       136\n",
      "\n",
      "[48  0  1  0  2  4  3  8  0  1  0  1  4  0  2  0  0  9  3  2  1  1  0  3\n",
      "  4  0  0  0  6  1  8  0  7  0  0 17]\n",
      "svc Accuracy:  0.6029411764705882\n",
      "svc F1:  0.48720110472690825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.91      0.72        55\n",
      "          1       1.00      0.54      0.70        13\n",
      "          2       0.25      0.13      0.17        15\n",
      "          3       0.50      0.10      0.17        10\n",
      "          4       0.67      0.36      0.47        11\n",
      "          5       0.53      0.50      0.52        32\n",
      "\n",
      "avg / total       0.58      0.59      0.55       136\n",
      "\n",
      "[50  0  1  0  2  2  4  7  0  1  0  1  7  0  2  0  0  6  5  0  0  1  0  4\n",
      "  6  0  0  0  4  1 11  0  5  0  0 16]\n",
      "LR Accuracy:  0.5882352941176471\n",
      "LR F1:  0.45865577647608835\n",
      "For name:  g_taylor\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-0817-2785': 22, '0000-0002-6925-7571': 12, '0000-0002-0988-7168': 4, '0000-0003-4787-9844': 2, '0000-0002-3611-5286': 2, '0000-0002-3773-2390': 1, '0000-0002-2916-4645': 1})\n",
      "['0000-0002-6925-7571', '0000-0002-0817-2785']\n",
      "Total sample size after apply threshold:  34\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 16)\n",
      "2\n",
      "(34, 38)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.67      0.70        12\n",
      "          1       0.83      0.86      0.84        22\n",
      "\n",
      "avg / total       0.79      0.79      0.79        34\n",
      "\n",
      "[ 8  4  3 19]\n",
      "MNB Accuracy:  0.7941176470588235\n",
      "MNB F1:  0.770048309178744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.58      0.61        12\n",
      "          1       0.78      0.82      0.80        22\n",
      "\n",
      "avg / total       0.73      0.74      0.73        34\n",
      "\n",
      "[ 7  5  4 18]\n",
      "svc Accuracy:  0.7352941176470589\n",
      "svc F1:  0.7043478260869566\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.50      0.63        12\n",
      "          1       0.78      0.95      0.86        22\n",
      "\n",
      "avg / total       0.81      0.79      0.78        34\n",
      "\n",
      "[ 6  6  1 21]\n",
      "LR Accuracy:  0.7941176470588235\n",
      "LR F1:  0.7443609022556391\n",
      "For name:  x_yang\n",
      "total sample size before apply threshold:  164\n",
      "Counter({'0000-0001-5207-4210': 40, '0000-0002-2036-1220': 32, '0000-0003-3454-3604': 13, '0000-0003-0437-2015': 12, '0000-0002-1142-3100': 10, '0000-0002-7398-4229': 7, '0000-0002-5118-7755': 6, '0000-0002-5083-1799': 6, '0000-0002-4862-7422': 6, '0000-0003-2642-4963': 4, '0000-0002-1375-4800': 4, '0000-0001-8231-5556': 3, '0000-0002-5095-6735': 3, '0000-0003-0219-0023': 3, '0000-0002-2686-745X': 2, '0000-0002-9462-7992': 2, '0000-0002-5871-7894': 1, '0000-0002-5948-2353': 1, '0000-0001-6136-3575': 1, '0000-0003-4097-6318': 1, '0000-0002-1689-2002': 1, '0000-0003-0081-0938': 1, '0000-0003-0073-0823': 1, '0000-0001-7501-1378': 1, '0000-0002-5583-4032': 1, '0000-0002-4617-0713': 1, '0000-0001-6710-0012': 1})\n",
      "['0000-0002-2036-1220', '0000-0002-1142-3100', '0000-0003-0437-2015', '0000-0003-3454-3604', '0000-0001-5207-4210']\n",
      "Total sample size after apply threshold:  107\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 55)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 13)\n",
      "2\n",
      "(107, 68)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.84      0.73        32\n",
      "          1       1.00      0.40      0.57        10\n",
      "          2       0.80      0.33      0.47        12\n",
      "          3       0.25      0.08      0.12        13\n",
      "          4       0.58      0.75      0.65        40\n",
      "\n",
      "avg / total       0.62      0.62      0.58       107\n",
      "\n",
      "[27  0  0  0  5  1  4  0  2  3  0  0  4  0  8  6  0  0  1  6  8  0  1  1\n",
      " 30]\n",
      "MNB Accuracy:  0.616822429906542\n",
      "MNB F1:  0.5083135016638854\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.84      0.89        32\n",
      "          1       0.75      0.60      0.67        10\n",
      "          2       1.00      0.33      0.50        12\n",
      "          3       0.62      0.38      0.48        13\n",
      "          4       0.69      1.00      0.82        40\n",
      "\n",
      "avg / total       0.79      0.77      0.75       107\n",
      "\n",
      "[27  0  0  1  4  1  6  0  2  1  0  0  4  0  8  1  2  0  5  5  0  0  0  0\n",
      " 40]\n",
      "svc Accuracy:  0.7663551401869159\n",
      "svc F1:  0.6688859150217464\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.81      0.84        32\n",
      "          1       0.80      0.40      0.53        10\n",
      "          2       1.00      0.33      0.50        12\n",
      "          3       0.40      0.15      0.22        13\n",
      "          4       0.60      0.95      0.74        40\n",
      "\n",
      "avg / total       0.72      0.69      0.66       107\n",
      "\n",
      "[26  0  0  1  5  0  4  0  2  4  0  0  4  0  8  2  1  0  2  8  2  0  0  0\n",
      " 38]\n",
      "LR Accuracy:  0.6915887850467289\n",
      "LR F1:  0.5664258621289627\n",
      "For name:  s_bianchi\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0002-1365-9408': 19, '0000-0001-7290-8489': 10, '0000-0001-7673-3030': 6, '0000-0003-3731-5463': 5, '0000-0003-2292-4303': 2, '0000-0002-4622-4240': 1, '0000-0002-9384-846X': 1, '0000-0002-6979-3622': 1})\n",
      "['0000-0002-1365-9408', '0000-0001-7290-8489']\n",
      "Total sample size after apply threshold:  29\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 17)\n",
      "2\n",
      "(29, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.90        19\n",
      "          1       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.89      0.86      0.85        29\n",
      "\n",
      "[19  0  4  6]\n",
      "MNB Accuracy:  0.8620689655172413\n",
      "MNB F1:  0.8273809523809523\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.90        19\n",
      "          1       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.89      0.86      0.85        29\n",
      "\n",
      "[19  0  4  6]\n",
      "svc Accuracy:  0.8620689655172413\n",
      "svc F1:  0.8273809523809523\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.83        19\n",
      "          1       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.81      0.72      0.66        29\n",
      "\n",
      "[19  0  8  2]\n",
      "LR Accuracy:  0.7241379310344828\n",
      "LR F1:  0.5797101449275363\n",
      "For name:  a_morales\n",
      "total sample size before apply threshold:  77\n",
      "Counter({'0000-0001-8702-2269': 47, '0000-0002-1526-3327': 19, '0000-0002-9518-3166': 9, '0000-0003-2081-6018': 1, '0000-0003-3656-2497': 1})\n",
      "['0000-0001-8702-2269', '0000-0002-1526-3327']\n",
      "Total sample size after apply threshold:  66\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 22)\n",
      "2\n",
      "(66, 61)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.96      0.87        47\n",
      "          1       0.78      0.37      0.50        19\n",
      "\n",
      "avg / total       0.79      0.79      0.76        66\n",
      "\n",
      "[45  2 12  7]\n",
      "MNB Accuracy:  0.7878787878787878\n",
      "MNB F1:  0.6826923076923077\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.96      0.87        47\n",
      "          1       0.80      0.42      0.55        19\n",
      "\n",
      "avg / total       0.80      0.80      0.78        66\n",
      "\n",
      "[45  2 11  8]\n",
      "svc Accuracy:  0.803030303030303\n",
      "svc F1:  0.7127552728490125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.98      0.84        47\n",
      "          1       0.67      0.11      0.18        19\n",
      "\n",
      "avg / total       0.71      0.73      0.65        66\n",
      "\n",
      "[46  1 17  2]\n",
      "LR Accuracy:  0.7272727272727273\n",
      "LR F1:  0.509090909090909\n",
      "For name:  p_wong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0002-6360-849X': 13, '0000-0003-1592-4823': 8, '0000-0001-7935-7245': 7, '0000-0003-4982-8127': 3, '0000-0003-4645-0384': 3, '0000-0003-3804-3041': 1, '0000-0002-8171-3242': 1})\n",
      "['0000-0002-6360-849X']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  a_cooper\n",
      "total sample size before apply threshold:  265\n",
      "Counter({'0000-0001-6709-7343': 112, '0000-0001-6050-3863': 72, '0000-0002-5897-2107': 23, '0000-0003-1025-0268': 16, '0000-0003-3975-3897': 15, '0000-0003-4588-2513': 12, '0000-0003-4097-5569': 4, '0000-0002-0815-0084': 4, '0000-0001-6027-8272': 3, '0000-0002-8305-8587': 2, '0000-0002-7328-4361': 1, '0000-0001-8763-8530': 1})\n",
      "['0000-0002-5897-2107', '0000-0001-6709-7343', '0000-0003-3975-3897', '0000-0003-4588-2513', '0000-0001-6050-3863', '0000-0003-1025-0268']\n",
      "Total sample size after apply threshold:  250\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(250, 127)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(250, 35)\n",
      "2\n",
      "(250, 162)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.04      0.08        23\n",
      "          1       0.68      0.88      0.77       112\n",
      "          2       0.00      0.00      0.00        15\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.53      0.75      0.62        72\n",
      "          5       1.00      0.19      0.32        16\n",
      "\n",
      "avg / total       0.57      0.62      0.55       250\n",
      "\n",
      "[ 1 11  0  0 11  0  0 98  0  0 14  0  1  6  0  0  8  0  0  5  0  0  7  0\n",
      "  0 18  0  0 54  0  0  6  0  0  7  3]\n",
      "MNB Accuracy:  0.624\n",
      "MNB F1:  0.2976153217219349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.48      0.48        23\n",
      "          1       0.78      0.89      0.83       112\n",
      "          2       0.78      0.47      0.58        15\n",
      "          3       0.17      0.08      0.11        12\n",
      "          4       0.73      0.75      0.74        72\n",
      "          5       0.80      0.50      0.62        16\n",
      "\n",
      "avg / total       0.71      0.72      0.71       250\n",
      "\n",
      "[ 11   7   1   0   4   0   3 100   0   0   7   2   1   3   7   3   1   0\n",
      "   2   3   0   1   6   0   4  11   1   2  54   0   2   4   0   0   2   8]\n",
      "svc Accuracy:  0.724\n",
      "svc F1:  0.5601915483541452\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.22      0.09      0.12        23\n",
      "          1       0.67      0.95      0.78       112\n",
      "          2       0.00      0.00      0.00        15\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.63      0.68      0.65        72\n",
      "          5       1.00      0.25      0.40        16\n",
      "\n",
      "avg / total       0.56      0.64      0.58       250\n",
      "\n",
      "[  2  12   0   0   9   0   0 106   0   0   6   0   2   8   0   0   5   0\n",
      "   1   6   0   0   5   0   3  20   0   0  49   0   1   7   0   0   4   4]\n",
      "LR Accuracy:  0.644\n",
      "LR F1:  0.32677019270192703\n",
      "For name:  j_nguyen\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0002-8578-7396': 20, '0000-0002-4747-5383': 2, '0000-0003-3574-6278': 1, '0000-0003-0778-3776': 1, '0000-0003-3394-7412': 1, '0000-0002-8410-7395': 1, '0000-0001-5755-5814': 1})\n",
      "['0000-0002-8578-7396']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  t_lang\n",
      "total sample size before apply threshold:  107\n",
      "Counter({'0000-0002-3720-8038': 83, '0000-0002-7482-7727': 11, '0000-0003-4206-8743': 7, '0000-0001-9619-6762': 6})\n",
      "['0000-0002-3720-8038', '0000-0002-7482-7727']\n",
      "Total sample size after apply threshold:  94\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 23)\n",
      "2\n",
      "(94, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        83\n",
      "          1       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.94      0.94      0.93        94\n",
      "\n",
      "[83  0  6  5]\n",
      "MNB Accuracy:  0.9361702127659575\n",
      "MNB F1:  0.7950581395348837\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        83\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.96      0.96      0.95        94\n",
      "\n",
      "[83  0  4  7]\n",
      "svc Accuracy:  0.9574468085106383\n",
      "svc F1:  0.8771241830065359\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        83\n",
      "          1       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.91      0.90      0.87        94\n",
      "\n",
      "[83  0  9  2]\n",
      "LR Accuracy:  0.9042553191489362\n",
      "LR F1:  0.6281318681318682\n",
      "For name:  s_russo\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0003-3589-3040': 33, '0000-0002-9699-4681': 10, '0000-0001-9137-9391': 1, '0000-0002-5490-3155': 1})\n",
      "['0000-0003-3589-3040', '0000-0002-9699-4681']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(43, 17)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(43, 12)\n",
      "2\n",
      "(43, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.85      0.82        33\n",
      "          1       0.38      0.30      0.33        10\n",
      "\n",
      "avg / total       0.70      0.72      0.71        43\n",
      "\n",
      "[28  5  7  3]\n",
      "MNB Accuracy:  0.7209302325581395\n",
      "MNB F1:  0.5784313725490196\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.88      0.87        33\n",
      "          1       0.56      0.50      0.53        10\n",
      "\n",
      "avg / total       0.78      0.79      0.79        43\n",
      "\n",
      "[29  4  5  5]\n",
      "svc Accuracy:  0.7906976744186046\n",
      "svc F1:  0.6959937156323645\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        33\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.59      0.77      0.67        43\n",
      "\n",
      "[33  0 10  0]\n",
      "LR Accuracy:  0.7674418604651163\n",
      "LR F1:  0.4342105263157895\n",
      "For name:  r_arora\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0002-5799-3619': 41, '0000-0002-2613-4539': 9, '0000-0002-4549-3860': 8, '0000-0001-6447-5628': 6})\n",
      "['0000-0002-5799-3619']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  c_porter\n",
      "total sample size before apply threshold:  157\n",
      "Counter({'0000-0003-3474-7551': 131, '0000-0001-8636-4515': 19, '0000-0001-8774-0180': 6, '0000-0002-4541-064X': 1})\n",
      "['0000-0001-8636-4515', '0000-0003-3474-7551']\n",
      "Total sample size after apply threshold:  150\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(150, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(150, 23)\n",
      "2\n",
      "(150, 71)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        19\n",
      "          1       0.92      1.00      0.96       131\n",
      "\n",
      "avg / total       0.93      0.93      0.91       150\n",
      "\n",
      "[  8  11   0 131]\n",
      "MNB Accuracy:  0.9266666666666666\n",
      "MNB F1:  0.7761497761497762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.26      0.42        19\n",
      "          1       0.90      1.00      0.95       131\n",
      "\n",
      "avg / total       0.92      0.91      0.88       150\n",
      "\n",
      "[  5  14   0 131]\n",
      "svc Accuracy:  0.9066666666666666\n",
      "svc F1:  0.6829710144927537\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        19\n",
      "          1       0.87      1.00      0.93       131\n",
      "\n",
      "avg / total       0.76      0.87      0.81       150\n",
      "\n",
      "[  0  19   0 131]\n",
      "LR Accuracy:  0.8733333333333333\n",
      "LR F1:  0.46619217081850534\n",
      "For name:  m_moore\n",
      "total sample size before apply threshold:  112\n",
      "Counter({'0000-0002-5127-4509': 45, '0000-0003-3074-6631': 38, '0000-0002-7853-5756': 18, '0000-0003-4768-5329': 7, '0000-0002-7914-0166': 4})\n",
      "['0000-0002-7853-5756', '0000-0003-3074-6631', '0000-0002-5127-4509']\n",
      "Total sample size after apply threshold:  101\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 19)\n",
      "2\n",
      "(101, 75)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.56      0.67        18\n",
      "          1       0.74      0.66      0.69        38\n",
      "          2       0.67      0.82      0.74        45\n",
      "\n",
      "avg / total       0.72      0.71      0.71       101\n",
      "\n",
      "[10  2  6  1 25 12  1  7 37]\n",
      "MNB Accuracy:  0.7128712871287128\n",
      "MNB F1:  0.7003703703703704\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.56      0.67        18\n",
      "          1       0.90      0.92      0.91        38\n",
      "          2       0.82      0.91      0.86        45\n",
      "\n",
      "avg / total       0.85      0.85      0.85       101\n",
      "\n",
      "[10  2  6  0 35  3  2  2 41]\n",
      "svc Accuracy:  0.8514851485148515\n",
      "svc F1:  0.8129718234981392\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.50      0.64        18\n",
      "          1       0.76      0.82      0.78        38\n",
      "          2       0.72      0.80      0.76        45\n",
      "\n",
      "avg / total       0.77      0.75      0.75       101\n",
      "\n",
      "[ 9  2  7  0 31  7  1  8 36]\n",
      "LR Accuracy:  0.7524752475247525\n",
      "LR F1:  0.7285206687605088\n",
      "For name:  c_johnson\n",
      "total sample size before apply threshold:  300\n",
      "Counter({'0000-0002-6864-6604': 114, '0000-0002-9719-3771': 47, '0000-0001-9616-6205': 44, '0000-0002-9511-905X': 21, '0000-0001-9190-8441': 18, '0000-0003-3892-7082': 16, '0000-0003-4428-3594': 14, '0000-0002-2298-7462': 12, '0000-0001-9079-813X': 5, '0000-0001-9616-5755': 2, '0000-0003-1954-5142': 2, '0000-0003-2192-3616': 1, '0000-0002-7390-9720': 1, '0000-0002-6679-833X': 1, '0000-0002-6616-4441': 1, '0000-0003-2733-3326': 1})\n",
      "['0000-0002-9511-905X', '0000-0001-9616-6205', '0000-0003-3892-7082', '0000-0002-2298-7462', '0000-0002-6864-6604', '0000-0001-9190-8441', '0000-0002-9719-3771', '0000-0003-4428-3594']\n",
      "Total sample size after apply threshold:  286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(286, 133)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(286, 24)\n",
      "2\n",
      "(286, 157)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        21\n",
      "          1       1.00      0.98      0.99        44\n",
      "          2       0.00      0.00      0.00        16\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.64      0.96      0.77       114\n",
      "          5       1.00      0.28      0.43        18\n",
      "          6       0.48      0.64      0.55        47\n",
      "          7       0.25      0.07      0.11        14\n",
      "\n",
      "avg / total       0.56      0.66      0.58       286\n",
      "\n",
      "[  0   0   0   0  10   0  11   0   0  43   0   0   1   0   0   0   0   0\n",
      "   0   0  11   0   5   0   0   0   0   0   5   0   7   0   0   0   0   0\n",
      " 110   0   1   3   0   0   0   0   7   5   6   0   0   0   0   0  17   0\n",
      "  30   0   0   0   0   0  11   0   2   1]\n",
      "MNB Accuracy:  0.6608391608391608\n",
      "MNB F1:  0.3567611189700375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.24      0.29        21\n",
      "          1       1.00      1.00      1.00        44\n",
      "          2       0.50      0.12      0.20        16\n",
      "          3       0.75      0.25      0.38        12\n",
      "          4       0.75      0.95      0.84       114\n",
      "          5       0.67      0.44      0.53        18\n",
      "          6       0.64      0.81      0.72        47\n",
      "          7       0.50      0.21      0.30        14\n",
      "\n",
      "avg / total       0.71      0.74      0.70       286\n",
      "\n",
      "[  5   0   0   0   4   2  10   0   0  44   0   0   0   0   0   0   0   0\n",
      "   2   0   9   0   5   0   2   0   0   3   4   1   2   0   2   0   1   0\n",
      " 108   0   0   3   0   0   0   0   7   8   3   0   4   0   1   1   3   0\n",
      "  38   0   0   0   0   0   9   1   1   3]\n",
      "svc Accuracy:  0.7377622377622378\n",
      "svc F1:  0.5320801768491512\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.17        21\n",
      "          1       1.00      0.98      0.99        44\n",
      "          2       0.00      0.00      0.00        16\n",
      "          3       1.00      0.08      0.15        12\n",
      "          4       0.65      1.00      0.79       114\n",
      "          5       0.60      0.33      0.43        18\n",
      "          6       0.56      0.64      0.59        47\n",
      "          7       1.00      0.07      0.13        14\n",
      "\n",
      "avg / total       0.71      0.69      0.62       286\n",
      "\n",
      "[  2   0   0   0   9   1   9   0   0  43   0   0   1   0   0   0   0   0\n",
      "   0   0  11   0   5   0   0   0   0   1   5   2   4   0   0   0   0   0\n",
      " 114   0   0   0   0   0   0   0   7   6   5   0   0   0   0   0  17   0\n",
      "  30   0   0   0   0   0  11   1   1   1]\n",
      "LR Accuracy:  0.6888111888111889\n",
      "LR F1:  0.40764455599204324\n",
      "For name:  e_henry\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-5648-8696': 18, '0000-0002-2547-3467': 10, '0000-0002-3884-2612': 2, '0000-0003-3178-2749': 1})\n",
      "['0000-0002-5648-8696', '0000-0002-2547-3467']\n",
      "Total sample size after apply threshold:  28\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 17)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 17)\n",
      "2\n",
      "(28, 34)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84        18\n",
      "          1       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.82      0.75      0.70        28\n",
      "\n",
      "[18  0  7  3]\n",
      "MNB Accuracy:  0.75\n",
      "MNB F1:  0.6493738819320214\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.83      0.77        18\n",
      "          1       0.57      0.40      0.47        10\n",
      "\n",
      "avg / total       0.66      0.68      0.66        28\n",
      "\n",
      "[15  3  6  4]\n",
      "svc Accuracy:  0.6785714285714286\n",
      "svc F1:  0.6199095022624435\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      1.00      0.82        18\n",
      "          1       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.80      0.71      0.65        28\n",
      "\n",
      "[18  0  8  2]\n",
      "LR Accuracy:  0.7142857142857143\n",
      "LR F1:  0.5757575757575757\n",
      "For name:  x_xie\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-2701-8660': 13, '0000-0002-1964-4370': 6, '0000-0003-2988-3065': 2, '0000-0002-6796-8521': 1, '0000-0002-3103-3724': 1, '0000-0002-7970-2974': 1})\n",
      "['0000-0002-2701-8660']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  x_jin\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0002-1550-2199': 27, '0000-0003-2454-1621': 11, '0000-0002-2809-7882': 11, '0000-0003-4293-8665': 9, '0000-0001-7339-2920': 2, '0000-0001-6742-1799': 1, '0000-0003-3033-758X': 1})\n",
      "['0000-0002-1550-2199', '0000-0003-2454-1621', '0000-0002-2809-7882']\n",
      "Total sample size after apply threshold:  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 29)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 10)\n",
      "2\n",
      "(49, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91        27\n",
      "          1       0.88      0.64      0.74        11\n",
      "          2       0.82      0.82      0.82        11\n",
      "\n",
      "avg / total       0.86      0.86      0.85        49\n",
      "\n",
      "[26  0  1  3  7  1  1  1  9]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.822434875066454\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92        27\n",
      "          1       1.00      0.82      0.90        11\n",
      "          2       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.91      0.90      0.90        49\n",
      "\n",
      "[27  0  0  2  9  0  3  0  8]\n",
      "svc Accuracy:  0.8979591836734694\n",
      "svc F1:  0.8857865001486768\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.96      0.85        27\n",
      "          1       0.89      0.73      0.80        11\n",
      "          2       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.85      0.82      0.81        49\n",
      "\n",
      "[26  1  0  3  8  0  5  0  6]\n",
      "LR Accuracy:  0.8163265306122449\n",
      "LR F1:  0.7861137897782063\n",
      "For name:  s_singh\n",
      "total sample size before apply threshold:  344\n",
      "Counter({'0000-0003-0912-941X': 70, '0000-0003-3454-2089': 61, '0000-0001-6545-583X': 40, '0000-0003-1033-2546': 19, '0000-0001-9115-3296': 18, '0000-0002-3656-2596': 15, '0000-0002-3482-7001': 14, '0000-0002-9391-0155': 13, '0000-0001-9984-5385': 11, '0000-0002-1028-6255': 9, '0000-0001-6820-9896': 9, '0000-0002-0900-8370': 7, '0000-0003-4404-6089': 6, '0000-0002-8730-524X': 5, '0000-0002-8114-1539': 5, '0000-0001-6521-0998': 5, '0000-0002-8524-0809': 4, '0000-0001-5482-9744': 3, '0000-0001-9505-4842': 3, '0000-0002-5154-3318': 2, '0000-0002-4038-5924': 2, '0000-0001-5545-7831': 2, '0000-0002-1878-8516': 2, '0000-0003-1914-4955': 2, '0000-0001-5361-4303': 2, '0000-0002-4897-8812': 2, '0000-0001-5935-3829': 2, '0000-0003-3562-6807': 1, '0000-0001-9826-2508': 1, '0000-0001-5985-5781': 1, '0000-0002-0193-9349': 1, '0000-0001-9754-1724': 1, '0000-0003-4805-7383': 1, '0000-0002-0022-6240': 1, '0000-0001-7509-3115': 1, '0000-0001-5412-2888': 1, '0000-0001-9669-3531': 1, '0000-0001-9338-1209': 1})\n",
      "['0000-0002-9391-0155', '0000-0002-3656-2596', '0000-0001-9115-3296', '0000-0002-3482-7001', '0000-0003-3454-2089', '0000-0003-0912-941X', '0000-0001-9984-5385', '0000-0001-6545-583X', '0000-0003-1033-2546']\n",
      "Total sample size after apply threshold:  261\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(261, 144)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(261, 18)\n",
      "2\n",
      "(261, 162)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       1.00      0.20      0.33        15\n",
      "          2       1.00      0.11      0.20        18\n",
      "          3       0.00      0.00      0.00        14\n",
      "          4       0.55      0.75      0.63        61\n",
      "          5       0.50      0.90      0.64        70\n",
      "          6       0.00      0.00      0.00        11\n",
      "          7       0.65      0.65      0.65        40\n",
      "          8       1.00      0.26      0.42        19\n",
      "\n",
      "avg / total       0.56      0.56      0.48       261\n",
      "\n",
      "[ 0  0  0  0  3 10  0  0  0  0  3  0  0  8  3  0  1  0  0  0  2  0  4 11\n",
      "  0  1  0  0  0  0  0  4  7  0  3  0  0  0  0  0 46 13  0  2  0  0  0  0\n",
      "  0  7 63  0  0  0  0  0  0  0  3  5  0  3  0  0  0  0  0  1 13  0 26  0\n",
      "  0  0  0  0  8  2  0  4  5]\n",
      "MNB Accuracy:  0.5555555555555556\n",
      "MNB F1:  0.31934185191668124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.15      0.25        13\n",
      "          1       0.83      0.33      0.48        15\n",
      "          2       0.75      0.33      0.46        18\n",
      "          3       1.00      0.79      0.88        14\n",
      "          4       0.63      0.77      0.69        61\n",
      "          5       0.58      0.94      0.72        70\n",
      "          6       1.00      0.27      0.43        11\n",
      "          7       0.81      0.55      0.66        40\n",
      "          8       0.57      0.42      0.48        19\n",
      "\n",
      "avg / total       0.70      0.65      0.63       261\n",
      "\n",
      "[ 2  1  1  0  1  8  0  0  0  0  5  0  0  7  2  0  1  0  1  0  6  0  4  6\n",
      "  0  1  0  0  0  0 11  0  2  0  0  1  0  0  0  0 47 12  0  2  0  0  0  1\n",
      "  0  3 66  0  0  0  0  0  0  0  4  2  3  0  2  0  0  0  0  1 14  0 22  3\n",
      "  0  0  0  0  8  2  0  1  8]\n",
      "svc Accuracy:  0.6513409961685823\n",
      "svc F1:  0.5607147826661512\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.86      0.40      0.55        15\n",
      "          2       0.80      0.22      0.35        18\n",
      "          3       1.00      0.64      0.78        14\n",
      "          4       0.61      0.75      0.68        61\n",
      "          5       0.53      0.91      0.67        70\n",
      "          6       1.00      0.18      0.31        11\n",
      "          7       0.74      0.62      0.68        40\n",
      "          8       0.75      0.32      0.44        19\n",
      "\n",
      "avg / total       0.65      0.62      0.58       261\n",
      "\n",
      "[ 0  1  1  0  2  9  0  0  0  0  6  0  0  6  3  0  0  0  0  0  4  0  3 10\n",
      "  0  1  0  0  0  0  9  1  3  0  0  1  0  0  0  0 46 14  0  1  0  0  0  0\n",
      "  0  6 64  0  0  0  0  0  0  0  3  3  2  3  0  0  0  0  0  1 13  0 25  1\n",
      "  0  0  0  0  7  2  0  4  6]\n",
      "LR Accuracy:  0.6206896551724138\n",
      "LR F1:  0.4944810457970878\n",
      "For name:  m_reid\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0003-4005-9384': 55, '0000-0002-4101-0921': 5, '0000-0002-0397-2556': 1, '0000-0002-3948-9347': 1})\n",
      "['0000-0003-4005-9384']\n",
      "Total sample size after apply threshold:  55\n",
      "For name:  m_wallace\n",
      "total sample size before apply threshold:  144\n",
      "Counter({'0000-0002-0166-906X': 57, '0000-0001-6894-4903': 52, '0000-0002-5692-8313': 30, '0000-0001-5407-8653': 3, '0000-0002-8318-7952': 2})\n",
      "['0000-0002-0166-906X', '0000-0002-5692-8313', '0000-0001-6894-4903']\n",
      "Total sample size after apply threshold:  139\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 57)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 29)\n",
      "2\n",
      "(139, 86)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.81      0.67        57\n",
      "          1       0.77      0.33      0.47        30\n",
      "          2       0.78      0.69      0.73        52\n",
      "\n",
      "avg / total       0.69      0.66      0.65       139\n",
      "\n",
      "[46  3  8 18 10  2 16  0 36]\n",
      "MNB Accuracy:  0.6618705035971223\n",
      "MNB F1:  0.6237810011120387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.82      0.67        57\n",
      "          1       0.75      0.40      0.52        30\n",
      "          2       0.82      0.63      0.72        52\n",
      "\n",
      "avg / total       0.70      0.66      0.66       139\n",
      "\n",
      "[47  4  6 17 12  1 19  0 33]\n",
      "svc Accuracy:  0.6618705035971223\n",
      "svc F1:  0.6368530020703934\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.77      0.66        57\n",
      "          1       0.71      0.33      0.45        30\n",
      "          2       0.77      0.71      0.74        52\n",
      "\n",
      "avg / total       0.68      0.65      0.64       139\n",
      "\n",
      "[44  4  9 18 10  2 15  0 37]\n",
      "LR Accuracy:  0.6546762589928058\n",
      "LR F1:  0.6170872908186341\n",
      "For name:  y_zhang\n",
      "total sample size before apply threshold:  1244\n",
      "Counter({'0000-0001-8642-4071': 104, '0000-0002-3254-8965': 64, '0000-0001-7307-9408': 56, '0000-0002-9956-3879': 48, '0000-0003-2932-4159': 48, '0000-0003-2317-2190': 45, '0000-0003-2753-7601': 37, '0000-0001-6118-6695': 31, '0000-0002-6460-6779': 29, '0000-0002-1079-4137': 28, '0000-0001-8357-5544': 28, '0000-0002-2663-1279': 27, '0000-0002-8457-5922': 27, '0000-0002-1239-3441': 26, '0000-0003-1148-949X': 26, '0000-0001-7436-9757': 23, '0000-0002-0045-0808': 22, '0000-0002-3859-3839': 22, '0000-0001-6777-3487': 22, '0000-0002-8448-3059': 21, '0000-0003-0592-9153': 21, '0000-0003-4698-5645': 20, '0000-0002-2832-2277': 20, '0000-0003-4082-5026': 20, '0000-0001-7433-1820': 17, '0000-0002-7339-8342': 16, '0000-0002-7926-9904': 14, '0000-0002-8270-1067': 14, '0000-0002-9548-0021': 14, '0000-0001-6577-5235': 14, '0000-0002-6035-8536': 14, '0000-0003-2212-1527': 13, '0000-0003-2560-3927': 13, '0000-0001-6751-9294': 12, '0000-0003-2351-5579': 11, '0000-0002-4405-4268': 9, '0000-0001-7882-5692': 9, '0000-0002-4477-7570': 8, '0000-0002-2559-3741': 8, '0000-0001-8759-0194': 7, '0000-0003-2968-0081': 7, '0000-0001-5562-9090': 7, '0000-0002-2614-5975': 7, '0000-0001-5734-0709': 7, '0000-0002-9263-6262': 7, '0000-0003-0022-1201': 6, '0000-0002-1990-9439': 6, '0000-0002-5765-0923': 6, '0000-0002-5715-2182': 5, '0000-0002-4762-6639': 5, '0000-0003-1204-8717': 5, '0000-0003-0614-2096': 5, '0000-0001-8938-1927': 5, '0000-0002-6764-3567': 5, '0000-0003-0522-6300': 5, '0000-0002-6201-7970': 5, '0000-0001-8286-300X': 5, '0000-0001-9983-5451': 5, '0000-0001-9321-9228': 4, '0000-0002-7422-8206': 4, '0000-0001-9157-5544': 4, '0000-0001-8702-909X': 4, '0000-0001-8915-1769': 4, '0000-0003-0919-2224': 4, '0000-0002-6893-2053': 4, '0000-0001-8537-8181': 4, '0000-0002-7468-2409': 4, '0000-0003-3531-0052': 4, '0000-0001-5996-5438': 4, '0000-0002-0814-2965': 4, '0000-0003-1011-3001': 4, '0000-0003-4355-9755': 4, '0000-0002-4870-1493': 4, '0000-0002-9731-5943': 3, '0000-0002-3562-2323': 3, '0000-0003-0757-1837': 3, '0000-0003-4353-593X': 3, '0000-0003-4638-0056': 3, '0000-0003-1608-4467': 3, '0000-0003-1620-3825': 2, '0000-0002-9738-5343': 2, '0000-0001-9126-4922': 2, '0000-0002-1634-5017': 2, '0000-0001-9934-7925': 2, '0000-0003-3709-7144': 2, '0000-0001-7636-7368': 2, '0000-0002-8663-5001': 2, '0000-0002-8754-8938': 2, '0000-0002-1084-9994': 2, '0000-0001-8474-5947': 2, '0000-0002-1483-9021': 2, '0000-0002-8121-3678': 2, '0000-0002-0238-0719': 2, '0000-0003-1174-6599': 2, '0000-0003-0182-4215': 1, '0000-0002-9318-0324': 1, '0000-0003-3770-0046': 1, '0000-0001-7783-8336': 1, '0000-0003-4267-0144': 1, '0000-0003-2179-3698': 1, '0000-0002-7484-8800': 1, '0000-0002-5254-6764': 1, '0000-0003-0859-9735': 1, '0000-0002-4087-420X': 1, '0000-0003-2158-6541': 1, '0000-0002-2684-7395': 1, '0000-0002-8123-7805': 1, '0000-0002-5901-4242': 1, '0000-0003-0397-7143': 1, '0000-0003-1614-1943': 1, '0000-0001-9588-2314': 1, '0000-0002-1259-020X': 1, '0000-0002-7175-6150': 1, '0000-0002-7627-488X': 1, '0000-0002-3873-4574': 1, '0000-0003-2903-2287': 1, '0000-0003-4114-7183': 1, '0000-0001-8738-1851': 1, '0000-0002-1566-098X': 1})\n",
      "['0000-0002-0045-0808', '0000-0002-7926-9904', '0000-0002-8448-3059', '0000-0003-4698-5645', '0000-0003-2212-1527', '0000-0002-3859-3839', '0000-0002-3254-8965', '0000-0001-7307-9408', '0000-0001-6777-3487', '0000-0002-1239-3441', '0000-0002-1079-4137', '0000-0002-9956-3879', '0000-0002-8270-1067', '0000-0001-6751-9294', '0000-0003-2932-4159', '0000-0002-2663-1279', '0000-0003-1148-949X', '0000-0003-2317-2190', '0000-0001-7436-9757', '0000-0001-8357-5544', '0000-0001-8642-4071', '0000-0002-9548-0021', '0000-0001-7433-1820', '0000-0003-2351-5579', '0000-0002-7339-8342', '0000-0001-6118-6695', '0000-0002-8457-5922', '0000-0001-6577-5235', '0000-0003-2560-3927', '0000-0002-2832-2277', '0000-0003-0592-9153', '0000-0002-6460-6779', '0000-0003-2753-7601', '0000-0002-6035-8536', '0000-0003-4082-5026']\n",
      "Total sample size after apply threshold:  967\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(967, 370)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(967, 24)\n",
      "2\n",
      "(967, 394)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.05      0.09        22\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.00      0.00      0.00        21\n",
      "          3       0.00      0.00      0.00        20\n",
      "          4       0.00      0.00      0.00        13\n",
      "          5       0.00      0.00      0.00        22\n",
      "          6       0.29      0.70      0.41        64\n",
      "          7       0.36      0.21      0.27        56\n",
      "          8       0.00      0.00      0.00        22\n",
      "          9       0.50      0.08      0.13        26\n",
      "         10       0.29      0.14      0.19        28\n",
      "         11       0.94      0.60      0.73        48\n",
      "         12       0.00      0.00      0.00        14\n",
      "         13       0.00      0.00      0.00        12\n",
      "         14       0.26      0.38      0.31        48\n",
      "         15       0.33      0.07      0.12        27\n",
      "         16       0.00      0.00      0.00        26\n",
      "         17       0.44      0.24      0.31        45\n",
      "         18       0.89      0.35      0.50        23\n",
      "         19       1.00      0.25      0.40        28\n",
      "         20       0.19      0.93      0.31       104\n",
      "         21       0.00      0.00      0.00        14\n",
      "         22       0.00      0.00      0.00        17\n",
      "         23       0.00      0.00      0.00        11\n",
      "         24       0.67      0.12      0.21        16\n",
      "         25       0.83      0.32      0.47        31\n",
      "         26       0.38      0.30      0.33        27\n",
      "         27       0.00      0.00      0.00        14\n",
      "         28       0.00      0.00      0.00        13\n",
      "         29       0.00      0.00      0.00        20\n",
      "         30       0.75      0.14      0.24        21\n",
      "         31       1.00      0.10      0.19        29\n",
      "         32       0.45      0.38      0.41        37\n",
      "         33       0.00      0.00      0.00        14\n",
      "         34       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.36      0.29      0.23       967\n",
      "\n",
      "[1 0 0 ... 1 0 0]\n",
      "MNB Accuracy:  0.2854188210961737\n",
      "MNB F1:  0.16075445005196454\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.45      0.49        22\n",
      "          1       0.18      0.14      0.16        14\n",
      "          2       0.26      0.24      0.25        21\n",
      "          3       0.50      0.15      0.23        20\n",
      "          4       0.62      0.62      0.62        13\n",
      "          5       0.50      0.18      0.27        22\n",
      "          6       0.41      0.58      0.48        64\n",
      "          7       0.23      0.68      0.34        56\n",
      "          8       0.75      0.27      0.40        22\n",
      "          9       0.53      0.31      0.39        26\n",
      "         10       0.48      0.39      0.43        28\n",
      "         11       1.00      0.58      0.74        48\n",
      "         12       0.00      0.00      0.00        14\n",
      "         13       0.00      0.00      0.00        12\n",
      "         14       0.25      0.40      0.31        48\n",
      "         15       0.13      0.07      0.10        27\n",
      "         16       0.15      0.12      0.13        26\n",
      "         17       0.48      0.31      0.38        45\n",
      "         18       1.00      0.39      0.56        23\n",
      "         19       0.95      0.71      0.82        28\n",
      "         20       0.51      0.80      0.62       104\n",
      "         21       0.18      0.14      0.16        14\n",
      "         22       0.67      0.24      0.35        17\n",
      "         23       0.33      0.18      0.24        11\n",
      "         24       0.58      0.44      0.50        16\n",
      "         25       0.81      0.68      0.74        31\n",
      "         26       0.40      0.52      0.45        27\n",
      "         27       0.25      0.07      0.11        14\n",
      "         28       0.83      0.38      0.53        13\n",
      "         29       0.50      0.30      0.37        20\n",
      "         30       0.42      0.24      0.30        21\n",
      "         31       1.00      0.72      0.84        29\n",
      "         32       0.46      0.43      0.44        37\n",
      "         33       0.75      0.21      0.33        14\n",
      "         34       0.30      0.35      0.33        20\n",
      "\n",
      "avg / total       0.50      0.44      0.43       967\n",
      "\n",
      "[10  0  3 ...  1  1  7]\n",
      "svc Accuracy:  0.4384694932781799\n",
      "svc F1:  0.3825858455306706\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.32      0.39        22\n",
      "          1       0.33      0.14      0.20        14\n",
      "          2       0.33      0.29      0.31        21\n",
      "          3       0.62      0.25      0.36        20\n",
      "          4       0.50      0.15      0.24        13\n",
      "          5       0.00      0.00      0.00        22\n",
      "          6       0.37      0.67      0.48        64\n",
      "          7       0.23      0.45      0.30        56\n",
      "          8       0.43      0.27      0.33        22\n",
      "          9       0.70      0.27      0.39        26\n",
      "         10       0.50      0.36      0.42        28\n",
      "         11       0.97      0.62      0.76        48\n",
      "         12       0.00      0.00      0.00        14\n",
      "         13       0.00      0.00      0.00        12\n",
      "         14       0.28      0.42      0.33        48\n",
      "         15       0.27      0.11      0.16        27\n",
      "         16       0.06      0.04      0.05        26\n",
      "         17       0.52      0.31      0.39        45\n",
      "         18       0.79      0.48      0.59        23\n",
      "         19       0.82      0.64      0.72        28\n",
      "         20       0.34      0.84      0.48       104\n",
      "         21       0.25      0.07      0.11        14\n",
      "         22       0.40      0.12      0.18        17\n",
      "         23       0.33      0.18      0.24        11\n",
      "         24       0.70      0.44      0.54        16\n",
      "         25       0.80      0.65      0.71        31\n",
      "         26       0.36      0.52      0.42        27\n",
      "         27       0.00      0.00      0.00        14\n",
      "         28       1.00      0.23      0.38        13\n",
      "         29       0.57      0.20      0.30        20\n",
      "         30       0.36      0.19      0.25        21\n",
      "         31       1.00      0.66      0.79        29\n",
      "         32       0.50      0.51      0.51        37\n",
      "         33       0.50      0.07      0.12        14\n",
      "         34       0.27      0.20      0.23        20\n",
      "\n",
      "avg / total       0.45      0.41      0.39       967\n",
      "\n",
      "[7 0 4 ... 1 1 4]\n",
      "LR Accuracy:  0.4105480868665977\n",
      "LR F1:  0.3333338182559818\n",
      "For name:  m_young\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0003-0450-5375': 51, '0000-0002-9615-9002': 27, '0000-0002-7263-6505': 9, '0000-0001-5168-9416': 8, '0000-0001-8479-9910': 4, '0000-0002-1262-5935': 2})\n",
      "['0000-0002-9615-9002', '0000-0003-0450-5375']\n",
      "Total sample size after apply threshold:  78\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 18)\n",
      "2\n",
      "(78, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.67      0.68        27\n",
      "          1       0.83      0.84      0.83        51\n",
      "\n",
      "avg / total       0.78      0.78      0.78        78\n",
      "\n",
      "[18  9  8 43]\n",
      "MNB Accuracy:  0.782051282051282\n",
      "MNB F1:  0.7570983696647737\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.70      0.76        27\n",
      "          1       0.85      0.92      0.89        51\n",
      "\n",
      "avg / total       0.84      0.85      0.84        78\n",
      "\n",
      "[19  8  4 47]\n",
      "svc Accuracy:  0.8461538461538461\n",
      "svc F1:  0.8233962264150944\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.63      0.74        27\n",
      "          1       0.83      0.96      0.89        51\n",
      "\n",
      "avg / total       0.85      0.85      0.84        78\n",
      "\n",
      "[17 10  2 49]\n",
      "LR Accuracy:  0.8461538461538461\n",
      "LR F1:  0.8150197628458499\n",
      "For name:  s_saraf\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-8384-9370': 38, '0000-0002-0569-1213': 13, '0000-0003-3905-0542': 2, '0000-0002-4180-0931': 1})\n",
      "['0000-0002-0569-1213', '0000-0002-8384-9370']\n",
      "Total sample size after apply threshold:  51\n",
      "(0, 0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 14)\n",
      "2\n",
      "(51, 44)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.38      0.50        13\n",
      "          1       0.82      0.95      0.88        38\n",
      "\n",
      "avg / total       0.79      0.80      0.78        51\n",
      "\n",
      "[ 5  8  2 36]\n",
      "MNB Accuracy:  0.803921568627451\n",
      "MNB F1:  0.6890243902439024\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.62      0.73        13\n",
      "          1       0.88      0.97      0.93        38\n",
      "\n",
      "avg / total       0.88      0.88      0.87        51\n",
      "\n",
      "[ 8  5  1 37]\n",
      "svc Accuracy:  0.8823529411764706\n",
      "svc F1:  0.8261363636363637\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       0.78      1.00      0.87        38\n",
      "\n",
      "avg / total       0.83      0.78      0.72        51\n",
      "\n",
      "[ 2 11  0 38]\n",
      "LR Accuracy:  0.7843137254901961\n",
      "LR F1:  0.5701149425287356\n",
      "For name:  r_pinto\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0002-1667-7871': 36, '0000-0002-2775-860X': 21, '0000-0001-5600-2396': 8, '0000-0002-6429-2087': 8, '0000-0003-0058-8652': 6, '0000-0002-4068-7391': 2, '0000-0001-9402-5775': 2, '0000-0002-1251-5007': 1, '0000-0002-4512-5566': 1})\n",
      "['0000-0002-1667-7871', '0000-0002-2775-860X']\n",
      "Total sample size after apply threshold:  57\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 42)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 16)\n",
      "2\n",
      "(57, 58)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84        36\n",
      "          1       0.79      0.52      0.63        21\n",
      "\n",
      "avg / total       0.77      0.77      0.76        57\n",
      "\n",
      "[33  3 10 11]\n",
      "MNB Accuracy:  0.7719298245614035\n",
      "MNB F1:  0.7320072332730561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.89      0.84        36\n",
      "          1       0.76      0.62      0.68        21\n",
      "\n",
      "avg / total       0.79      0.79      0.78        57\n",
      "\n",
      "[32  4  8 13]\n",
      "svc Accuracy:  0.7894736842105263\n",
      "svc F1:  0.7631578947368421\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.97      0.83        36\n",
      "          1       0.89      0.38      0.53        21\n",
      "\n",
      "avg / total       0.79      0.75      0.72        57\n",
      "\n",
      "[35  1 13  8]\n",
      "LR Accuracy:  0.7543859649122807\n",
      "LR F1:  0.6833333333333333\n",
      "For name:  m_brito\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  86\n",
      "Counter({'0000-0002-8493-4649': 51, '0000-0001-6394-658X': 31, '0000-0002-8973-104X': 2, '0000-0001-9689-7040': 1, '0000-0002-1779-4535': 1})\n",
      "['0000-0002-8493-4649', '0000-0001-6394-658X']\n",
      "Total sample size after apply threshold:  82\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 65)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 18)\n",
      "2\n",
      "(82, 83)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.80      0.77        51\n",
      "          1       0.62      0.52      0.56        31\n",
      "\n",
      "avg / total       0.69      0.70      0.69        82\n",
      "\n",
      "[41 10 15 16]\n",
      "MNB Accuracy:  0.6951219512195121\n",
      "MNB F1:  0.6638793244794229\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.80      0.80        51\n",
      "          1       0.67      0.65      0.66        31\n",
      "\n",
      "avg / total       0.74      0.74      0.74        82\n",
      "\n",
      "[41 10 11 20]\n",
      "svc Accuracy:  0.7439024390243902\n",
      "svc F1:  0.7259271048862008\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.86      0.75        51\n",
      "          1       0.53      0.26      0.35        31\n",
      "\n",
      "avg / total       0.61      0.63      0.60        82\n",
      "\n",
      "[44  7 23  8]\n",
      "LR Accuracy:  0.6341463414634146\n",
      "LR F1:  0.5467943994104643\n",
      "For name:  s_goel\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-7485-5392': 16, '0000-0003-2866-790X': 7, '0000-0001-7886-9441': 4, '0000-0002-8694-332X': 3, '0000-0002-9739-4178': 1})\n",
      "['0000-0001-7485-5392']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  y_park\n",
      "total sample size before apply threshold:  627\n",
      "Counter({'0000-0002-6281-489X': 171, '0000-0002-5879-6879': 78, '0000-0002-3671-6364': 67, '0000-0002-9553-8561': 56, '0000-0003-1191-7335': 35, '0000-0002-8288-9450': 32, '0000-0002-8808-4530': 28, '0000-0002-1310-148X': 28, '0000-0002-5466-2339': 22, '0000-0001-8336-8051': 20, '0000-0003-3652-591X': 16, '0000-0001-8583-4335': 15, '0000-0001-8495-9224': 14, '0000-0001-7025-8945': 13, '0000-0002-1959-0843': 9, '0000-0002-7574-4165': 7, '0000-0003-1997-6444': 6, '0000-0002-8536-0835': 3, '0000-0001-6587-6562': 3, '0000-0002-1702-0986': 1, '0000-0002-2801-2674': 1, '0000-0001-5110-5716': 1, '0000-0002-3019-5748': 1})\n",
      "['0000-0001-7025-8945', '0000-0002-5466-2339', '0000-0003-3652-591X', '0000-0002-3671-6364', '0000-0002-8808-4530', '0000-0003-1191-7335', '0000-0002-5879-6879', '0000-0001-8495-9224', '0000-0002-8288-9450', '0000-0001-8336-8051', '0000-0001-8583-4335', '0000-0002-1310-148X', '0000-0002-6281-489X', '0000-0002-9553-8561']\n",
      "Total sample size after apply threshold:  595\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(595, 260)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(595, 23)\n",
      "2\n",
      "(595, 283)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       1.00      0.18      0.31        22\n",
      "          2       0.00      0.00      0.00        16\n",
      "          3       0.34      0.30      0.32        67\n",
      "          4       0.82      0.32      0.46        28\n",
      "          5       1.00      0.26      0.41        35\n",
      "          6       0.45      0.50      0.47        78\n",
      "          7       0.00      0.00      0.00        14\n",
      "          8       1.00      0.16      0.27        32\n",
      "          9       0.00      0.00      0.00        20\n",
      "         10       0.00      0.00      0.00        15\n",
      "         11       1.00      0.04      0.07        28\n",
      "         12       0.42      0.97      0.59       171\n",
      "         13       0.90      0.32      0.47        56\n",
      "\n",
      "avg / total       0.54      0.46      0.39       595\n",
      "\n",
      "[  0   0   0   4   0   0   2   0   0   0   0   0   7   0   0   4   0   4\n",
      "   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   4   0\n",
      "   0   0   0   0  12   0   0   0   0  20   0   0   7   0   0   2   0   0\n",
      "  37   1   0   0   0   5   9   0   0   0   0   1   0   0  12   1   0   0\n",
      "   0   4   0   9   0   0   0   0   0   0  22   0   0   0   0   6   0   0\n",
      "  39   0   0   0   0   0  33   0   0   0   0   0   0   0   9   0   0   0\n",
      "   0   0   5   0   0   0   0   0   0   0  10   0   5   0   0   0  17   0\n",
      "   0   0   0   8   0   0   5   0   0   0   0   0   7   0   0   0   0   0\n",
      "   0   0   3   0   0   0   0   0  12   0   0   0   0   1   1   0   3   0\n",
      "   0   0   0   1  22   0   0   0   0   2   0   0   3   0   0   0   0   0\n",
      " 166   0   0   0   0   5   1   0   2   0   0   0   0   0  30  18]\n",
      "MNB Accuracy:  0.45546218487394957\n",
      "MNB F1:  0.24049765610132048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.69      0.75        13\n",
      "          1       0.82      0.64      0.72        22\n",
      "          2       1.00      0.81      0.90        16\n",
      "          3       0.35      0.64      0.45        67\n",
      "          4       0.76      0.57      0.65        28\n",
      "          5       0.85      0.49      0.62        35\n",
      "          6       0.48      0.56      0.52        78\n",
      "          7       1.00      0.07      0.13        14\n",
      "          8       0.87      0.41      0.55        32\n",
      "          9       0.50      0.25      0.33        20\n",
      "         10       1.00      0.60      0.75        15\n",
      "         11       1.00      0.29      0.44        28\n",
      "         12       0.66      0.85      0.74       171\n",
      "         13       0.80      0.50      0.62        56\n",
      "\n",
      "avg / total       0.69      0.61      0.61       595\n",
      "\n",
      "[  9   0   0   2   0   0   1   0   0   0   0   0   1   0   0  14   0   6\n",
      "   1   0   0   0   0   0   0   0   0   1   0   0  13   0   0   0   1   0\n",
      "   0   0   0   0   2   0   0   0   0  43   2   0   7   0   0   3   0   0\n",
      "  11   1   0   1   0   6  16   0   0   0   0   2   0   0   1   2   1   0\n",
      "   0  10   0  17   2   0   0   0   0   0   5   0   1   0   0  13   0   0\n",
      "  44   0   2   0   0   0  17   1   0   0   0   0   0   0   5   1   0   0\n",
      "   0   0   8   0   0   0   0   2   0   0   7   0  13   0   0   0  10   0\n",
      "   0   0   0   8   0   1   4   0   0   5   0   0   1   1   0   0   0   2\n",
      "   0   0   1   0   0   0   9   0   3   0   0   0   0   7   0   0   6   0\n",
      "   0   0   0   8   7   0   0   0   0  14   0   1  10   0   0   0   0   0\n",
      " 145   1   0   2   0  10   2   1   3   0   0   0   0   0  10  28]\n",
      "svc Accuracy:  0.6134453781512605\n",
      "svc F1:  0.5841834469358574\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       1.00      0.64      0.78        22\n",
      "          2       1.00      0.25      0.40        16\n",
      "          3       0.34      0.42      0.38        67\n",
      "          4       0.82      0.50      0.62        28\n",
      "          5       0.66      0.54      0.59        35\n",
      "          6       0.45      0.58      0.51        78\n",
      "          7       0.00      0.00      0.00        14\n",
      "          8       0.86      0.38      0.52        32\n",
      "          9       0.25      0.05      0.08        20\n",
      "         10       1.00      0.13      0.24        15\n",
      "         11       0.00      0.00      0.00        28\n",
      "         12       0.52      0.91      0.66       171\n",
      "         13       0.87      0.46      0.60        56\n",
      "\n",
      "avg / total       0.57      0.54      0.50       595\n",
      "\n",
      "[  2   0   0   5   0   0   1   0   0   0   0   0   5   0   0  14   0   2\n",
      "   0   0   0   0   0   0   0   0   6   0   0   0   4   1   0   0   3   0\n",
      "   0   0   0   0   8   0   0   0   0  28   1   1   8   0   0   2   0   0\n",
      "  26   1   0   0   0   5  14   2   0   0   0   1   0   0   4   2   0   0\n",
      "   0   7   0  19   0   0   0   0   0   0   8   1   0   0   0  10   0   0\n",
      "  45   0   2   0   0   0  21   0   0   0   0   0   0   0   9   0   0   0\n",
      "   0   0   5   0   0   0   0   1   0   0   9   0  12   0   0   0  10   0\n",
      "   0   0   0   9   0   0   5   0   0   1   0   0   5   0   0   0   0   0\n",
      "   0   0   3   0   0   0   2   0  10   0   0   0   0   2   1   3   6   0\n",
      "   0   0   0   0  16   0   0   0   0   6   0   1   9   0   0   0   0   0\n",
      " 155   0   0   0   0   6   1   3   2   0   0   0   0   0  18  26]\n",
      "LR Accuracy:  0.5411764705882353\n",
      "LR F1:  0.4035203197834492\n",
      "For name:  p_melo\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0003-0590-0684': 14, '0000-0002-4486-0200': 6, '0000-0002-3892-4140': 5, '0000-0002-4117-239X': 3})\n",
      "['0000-0003-0590-0684']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  c_lemos\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-9803-9584': 21, '0000-0003-3182-6289': 14, '0000-0001-8273-489X': 9, '0000-0002-3372-6719': 4, '0000-0003-3468-4191': 4})\n",
      "['0000-0003-3182-6289', '0000-0001-9803-9584']\n",
      "Total sample size after apply threshold:  35\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 10)\n",
      "2\n",
      "(35, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.86      0.89        14\n",
      "          1       0.91      0.95      0.93        21\n",
      "\n",
      "avg / total       0.91      0.91      0.91        35\n",
      "\n",
      "[12  2  1 20]\n",
      "MNB Accuracy:  0.9142857142857143\n",
      "MNB F1:  0.9095607235142119\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.86      0.89        14\n",
      "          1       0.91      0.95      0.93        21\n",
      "\n",
      "avg / total       0.91      0.91      0.91        35\n",
      "\n",
      "[12  2  1 20]\n",
      "svc Accuracy:  0.9142857142857143\n",
      "svc F1:  0.9095607235142119\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.86      0.89        14\n",
      "          1       0.91      0.95      0.93        21\n",
      "\n",
      "avg / total       0.91      0.91      0.91        35\n",
      "\n",
      "[12  2  1 20]\n",
      "LR Accuracy:  0.9142857142857143\n",
      "LR F1:  0.9095607235142119\n",
      "For name:  b_liu\n",
      "total sample size before apply threshold:  298\n",
      "Counter({'0000-0002-0956-2777': 97, '0000-0002-8662-0512': 24, '0000-0002-0787-5825': 18, '0000-0001-6052-8411': 15, '0000-0001-9992-9319': 14, '0000-0002-5836-2333': 14, '0000-0002-8676-4794': 12, '0000-0003-0122-3866': 11, '0000-0002-4948-2835': 10, '0000-0003-2211-5557': 10, '0000-0003-3060-3120': 9, '0000-0001-8211-6303': 8, '0000-0002-9318-1335': 8, '0000-0001-6655-1866': 7, '0000-0002-4511-6926': 6, '0000-0002-7257-2441': 5, '0000-0001-8806-820X': 5, '0000-0002-8550-1722': 3, '0000-0002-7347-1941': 3, '0000-0001-6221-1047': 3, '0000-0003-4532-3658': 3, '0000-0002-9539-2005': 2, '0000-0003-2529-0123': 2, '0000-0002-8318-9667': 2, '0000-0002-6825-3536': 2, '0000-0002-9495-6809': 2, '0000-0002-1677-2772': 1, '0000-0002-5272-3425': 1, '0000-0002-7543-1054': 1})\n",
      "['0000-0003-0122-3866', '0000-0001-6052-8411', '0000-0002-0787-5825', '0000-0002-8662-0512', '0000-0001-9992-9319', '0000-0002-4948-2835', '0000-0002-0956-2777', '0000-0003-2211-5557', '0000-0002-5836-2333', '0000-0002-8676-4794']\n",
      "Total sample size after apply threshold:  225\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(225, 96)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(225, 17)\n",
      "2\n",
      "(225, 113)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17        11\n",
      "          1       0.75      0.20      0.32        15\n",
      "          2       0.00      0.00      0.00        18\n",
      "          3       0.80      0.50      0.62        24\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       0.33      0.10      0.15        10\n",
      "          6       0.49      1.00      0.66        97\n",
      "          7       0.00      0.00      0.00        10\n",
      "          8       0.67      0.14      0.24        14\n",
      "          9       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.45      0.52      0.40       225\n",
      "\n",
      "[ 1  1  0  3  0  0  6  0  0  0  0  3  0  0  0  1 10  0  1  0  0  0  0  0\n",
      "  0  0 18  0  0  0  0  0  0 12  0  0 12  0  0  0  0  0  0  0  0  1 13  0\n",
      "  0  0  0  0  0  0  1  1  8  0  0  0  0  0  0  0  0  0 97  0  0  0  0  0\n",
      "  0  0  0  0 10  0  0  0  0  0  0  0  0  0 12  0  2  0  0  0  0  0  0  0\n",
      " 12  0  0  0]\n",
      "MNB Accuracy:  0.5155555555555555\n",
      "MNB F1:  0.21446081458727734\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.55      0.63        11\n",
      "          1       0.35      0.40      0.38        15\n",
      "          2       0.67      0.11      0.19        18\n",
      "          3       0.94      0.71      0.81        24\n",
      "          4       0.78      0.50      0.61        14\n",
      "          5       1.00      0.30      0.46        10\n",
      "          6       0.60      0.94      0.73        97\n",
      "          7       0.00      0.00      0.00        10\n",
      "          8       0.75      0.21      0.33        14\n",
      "          9       0.78      0.58      0.67        12\n",
      "\n",
      "avg / total       0.66      0.63      0.59       225\n",
      "\n",
      "[ 6  2  0  0  0  0  3  0  0  0  1  6  0  0  1  0  6  0  1  0  0  0  2  0\n",
      "  1  0 15  0  0  0  0  1  1 17  0  0  5  0  0  0  0  1  0  1  7  0  5  0\n",
      "  0  0  0  2  0  0  0  3  5  0  0  0  1  2  0  0  0  0 91  2  0  1  0  0\n",
      "  0  0  0  0  9  0  0  1  0  3  0  0  0  0  8  0  3  0  0  0  0  0  0  0\n",
      "  4  1  0  7]\n",
      "svc Accuracy:  0.6311111111111111\n",
      "svc F1:  0.4810684028822731\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       0.71      0.33      0.45        15\n",
      "          2       1.00      0.11      0.20        18\n",
      "          3       0.93      0.54      0.68        24\n",
      "          4       1.00      0.29      0.44        14\n",
      "          5       1.00      0.30      0.46        10\n",
      "          6       0.51      0.96      0.67        97\n",
      "          7       0.00      0.00      0.00        10\n",
      "          8       1.00      0.21      0.35        14\n",
      "          9       0.57      0.33      0.42        12\n",
      "\n",
      "avg / total       0.70      0.57      0.51       225\n",
      "\n",
      "[ 2  1  0  0  0  0  8  0  0  0  0  5  0  0  0  0 10  0  0  0  0  0  2  0\n",
      "  0  0 16  0  0  0  0  0  0 13  0  0 11  0  0  0  0  0  0  1  4  0  9  0\n",
      "  0  0  0  0  0  0  0  3  7  0  0  0  0  1  0  0  0  0 93  1  0  2  0  0\n",
      "  0  0  0  0  9  0  0  1  0  0  0  0  0  0 11  0  3  0  0  0  0  0  0  0\n",
      "  8  0  0  4]\n",
      "LR Accuracy:  0.5733333333333334\n",
      "LR F1:  0.399309166925266\n",
      "For name:  k_turner\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0002-8152-6017': 42, '0000-0003-3714-5118': 11, '0000-0002-3867-2684': 5, '0000-0001-8982-0301': 3, '0000-0002-1163-2201': 1})\n",
      "['0000-0002-8152-6017', '0000-0003-3714-5118']\n",
      "Total sample size after apply threshold:  53\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 12)\n",
      "2\n",
      "(53, 40)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.95      0.86        42\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.62      0.75      0.68        53\n",
      "\n",
      "[40  2 11  0]\n",
      "MNB Accuracy:  0.7547169811320755\n",
      "MNB F1:  0.4301075268817204\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        42\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.93      0.92      0.92        53\n",
      "\n",
      "[42  0  4  7]\n",
      "svc Accuracy:  0.9245283018867925\n",
      "svc F1:  0.8661616161616161\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        42\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.63      0.79      0.70        53\n",
      "\n",
      "[42  0 11  0]\n",
      "LR Accuracy:  0.7924528301886793\n",
      "LR F1:  0.4421052631578948\n",
      "For name:  r_rao\n",
      "total sample size before apply threshold:  94\n",
      "Counter({'0000-0002-5776-8366': 52, '0000-0002-0262-5122': 14, '0000-0002-2285-6788': 12, '0000-0002-1475-3893': 9, '0000-0002-6415-0185': 7})\n",
      "['0000-0002-2285-6788', '0000-0002-5776-8366', '0000-0002-0262-5122']\n",
      "Total sample size after apply threshold:  78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 50)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 13)\n",
      "2\n",
      "(78, 63)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.68      0.98      0.80        52\n",
      "          2       1.00      0.14      0.25        14\n",
      "\n",
      "avg / total       0.63      0.68      0.58        78\n",
      "\n",
      "[ 0 12  0  1 51  0  0 12  2]\n",
      "MNB Accuracy:  0.6794871794871795\n",
      "MNB F1:  0.35104986876640415\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.08      0.11        12\n",
      "          1       0.72      0.90      0.80        52\n",
      "          2       0.86      0.43      0.57        14\n",
      "\n",
      "avg / total       0.66      0.69      0.66        78\n",
      "\n",
      "[ 1 11  0  4 47  1  1  7  6]\n",
      "svc Accuracy:  0.6923076923076923\n",
      "svc F1:  0.4953194953194953\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.68      1.00      0.81        52\n",
      "          2       1.00      0.07      0.13        14\n",
      "\n",
      "avg / total       0.64      0.68      0.57        78\n",
      "\n",
      "[ 0 12  0  0 52  0  1 12  1]\n",
      "LR Accuracy:  0.6794871794871795\n",
      "LR F1:  0.3152777777777778\n",
      "For name:  b_barker\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-3439-4517': 21, '0000-0001-6932-479X': 8, '0000-0001-9327-7057': 5, '0000-0001-5732-9550': 1})\n",
      "['0000-0002-3439-4517']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  a_wright\n",
      "total sample size before apply threshold:  149\n",
      "Counter({'0000-0002-2369-0601': 67, '0000-0002-3172-5253': 31, '0000-0002-4866-5699': 21, '0000-0002-8718-8143': 13, '0000-0002-0373-5219': 11, '0000-0003-0721-7854': 4, '0000-0001-6442-5583': 1, '0000-0001-8428-890X': 1})\n",
      "['0000-0002-2369-0601', '0000-0002-8718-8143', '0000-0002-4866-5699', '0000-0002-3172-5253', '0000-0002-0373-5219']\n",
      "Total sample size after apply threshold:  143\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(143, 70)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(143, 14)\n",
      "2\n",
      "(143, 84)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      1.00      0.75        67\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       0.80      0.57      0.67        21\n",
      "          3       0.67      0.19      0.30        31\n",
      "          4       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.64      0.65      0.58       143\n",
      "\n",
      "[67  0  0  0  0  5  8  0  0  0  7  0 12  2  0 23  0  2  6  0  9  0  1  1\n",
      "  0]\n",
      "MNB Accuracy:  0.6503496503496503\n",
      "MNB F1:  0.4962760834670947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.93      0.88        67\n",
      "          1       0.92      0.85      0.88        13\n",
      "          2       0.82      0.67      0.74        21\n",
      "          3       0.58      0.71      0.64        31\n",
      "          4       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.80      0.78      0.76       143\n",
      "\n",
      "[62  0  0  5  0  0 11  0  2  0  3  0 14  4  0  6  1  2 22  0  3  0  1  5\n",
      "  2]\n",
      "svc Accuracy:  0.7762237762237763\n",
      "svc F1:  0.688329639297846\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.97      0.77        67\n",
      "          1       1.00      0.77      0.87        13\n",
      "          2       0.86      0.57      0.69        21\n",
      "          3       0.67      0.39      0.49        31\n",
      "          4       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.66      0.69      0.65       143\n",
      "\n",
      "[65  0  0  2  0  3 10  0  0  0  7  0 12  2  0 17  0  2 12  0  9  0  0  2\n",
      "  0]\n",
      "LR Accuracy:  0.6923076923076923\n",
      "LR F1:  0.5637769890564923\n",
      "For name:  z_ma\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0002-5426-0997': 36, '0000-0002-2391-4943': 18, '0000-0002-4429-5213': 15, '0000-0003-1186-9396': 12, '0000-0003-0257-5695': 11, '0000-0002-1629-7764': 9, '0000-0002-3164-6117': 5, '0000-0002-7276-2229': 4, '0000-0002-7120-9106': 1})\n",
      "['0000-0002-5426-0997', '0000-0002-4429-5213', '0000-0002-2391-4943', '0000-0003-0257-5695', '0000-0003-1186-9396']\n",
      "Total sample size after apply threshold:  92\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(92, 52)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(92, 15)\n",
      "2\n",
      "(92, 67)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.94      0.72        36\n",
      "          1       0.65      0.87      0.74        15\n",
      "          2       0.83      0.56      0.67        18\n",
      "          3       1.00      0.09      0.17        11\n",
      "          4       1.00      0.08      0.15        12\n",
      "\n",
      "avg / total       0.75      0.64      0.57        92\n",
      "\n",
      "[34  0  2  0  0  2 13  0  0  0  8  0 10  0  0  5  5  0  1  0  9  2  0  0\n",
      "  1]\n",
      "MNB Accuracy:  0.6413043478260869\n",
      "MNB F1:  0.4906881770711557\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.94      0.74        36\n",
      "          1       0.71      0.80      0.75        15\n",
      "          2       0.86      0.67      0.75        18\n",
      "          3       1.00      0.27      0.43        11\n",
      "          4       0.50      0.08      0.14        12\n",
      "\n",
      "avg / total       0.71      0.67      0.63        92\n",
      "\n",
      "[34  0  2  0  0  3 12  0  0  0  6  0 12  0  0  3  4  0  3  1 10  1  0  0\n",
      "  1]\n",
      "svc Accuracy:  0.6739130434782609\n",
      "svc F1:  0.562111801242236\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.94      0.73        36\n",
      "          1       0.65      0.87      0.74        15\n",
      "          2       0.83      0.56      0.67        18\n",
      "          3       1.00      0.09      0.17        11\n",
      "          4       0.50      0.08      0.14        12\n",
      "\n",
      "avg / total       0.69      0.64      0.58        92\n",
      "\n",
      "[34  0  2  0  0  2 13  0  0  0  8  0 10  0  0  4  5  0  1  1  9  2  0  0\n",
      "  1]\n",
      "LR Accuracy:  0.6413043478260869\n",
      "LR F1:  0.49004608294930874\n",
      "For name:  s_bose\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0001-7310-9881': 16, '0000-0003-2397-4740': 6, '0000-0002-6569-4643': 5, '0000-0003-0137-4322': 1})\n",
      "['0000-0001-7310-9881']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  j_dyer\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-7220-6062': 44, '0000-0002-3275-8612': 13, '0000-0002-7570-9941': 3, '0000-0001-6215-0053': 1})\n",
      "['0000-0002-3275-8612', '0000-0002-7220-6062']\n",
      "Total sample size after apply threshold:  57\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 12)\n",
      "2\n",
      "(57, 44)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.69      0.75        13\n",
      "          1       0.91      0.95      0.93        44\n",
      "\n",
      "avg / total       0.89      0.89      0.89        57\n",
      "\n",
      "[ 9  4  2 42]\n",
      "MNB Accuracy:  0.8947368421052632\n",
      "MNB F1:  0.8416666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.62      0.67        13\n",
      "          1       0.89      0.93      0.91        44\n",
      "\n",
      "avg / total       0.85      0.86      0.86        57\n",
      "\n",
      "[ 8  5  3 41]\n",
      "svc Accuracy:  0.8596491228070176\n",
      "svc F1:  0.788888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.46      0.60        13\n",
      "          1       0.86      0.98      0.91        44\n",
      "\n",
      "avg / total       0.86      0.86      0.84        57\n",
      "\n",
      "[ 6  7  1 43]\n",
      "LR Accuracy:  0.8596491228070176\n",
      "LR F1:  0.7574468085106383\n",
      "For name:  f_blanco\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0003-2545-4319': 55, '0000-0003-4332-434X': 38, '0000-0002-9929-6707': 16, '0000-0002-8380-8472': 14, '0000-0003-1283-8313': 5})\n",
      "['0000-0003-4332-434X', '0000-0002-8380-8472', '0000-0002-9929-6707', '0000-0003-2545-4319']\n",
      "Total sample size after apply threshold:  123\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(123, 62)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(123, 15)\n",
      "2\n",
      "(123, 77)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.89      0.71        38\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.00      0.00      0.00        16\n",
      "          3       0.69      0.76      0.72        55\n",
      "\n",
      "avg / total       0.49      0.62      0.54       123\n",
      "\n",
      "[34  0  0  4  8  0  2  4  4  1  0 11 12  0  1 42]\n",
      "MNB Accuracy:  0.6178861788617886\n",
      "MNB F1:  0.35811781609195403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        38\n",
      "          1       0.55      0.43      0.48        14\n",
      "          2       0.75      0.19      0.30        16\n",
      "          3       0.71      0.93      0.80        55\n",
      "\n",
      "avg / total       0.79      0.78      0.75       123\n",
      "\n",
      "[36  0  0  2  0  6  0  8  0  2  3 11  0  3  1 51]\n",
      "svc Accuracy:  0.7804878048780488\n",
      "svc F1:  0.6390306448180464\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        38\n",
      "          1       0.33      0.07      0.12        14\n",
      "          2       0.00      0.00      0.00        16\n",
      "          3       0.63      0.98      0.77        55\n",
      "\n",
      "avg / total       0.63      0.72      0.65       123\n",
      "\n",
      "[34  0  0  4  0  1  0 13  0  1  0 15  0  1  0 54]\n",
      "LR Accuracy:  0.7235772357723578\n",
      "LR F1:  0.4570122375191211\n",
      "For name:  s_ferreira\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0001-7159-2769': 20, '0000-0001-8308-2862': 17, '0000-0001-7486-5056': 10, '0000-0001-6475-5742': 6, '0000-0001-8174-0200': 6, '0000-0002-9969-2507': 2, '0000-0002-2519-8979': 2, '0000-0002-9209-7772': 2, '0000-0001-7469-3186': 2, '0000-0001-7698-6599': 2, '0000-0002-3527-1623': 1})\n",
      "['0000-0001-8308-2862', '0000-0001-7486-5056', '0000-0001-7159-2769']\n",
      "Total sample size after apply threshold:  47\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 26)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 15)\n",
      "2\n",
      "(47, 41)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.65      0.76        17\n",
      "          1       0.71      0.50      0.59        10\n",
      "          2       0.68      0.95      0.79        20\n",
      "\n",
      "avg / total       0.77      0.74      0.74        47\n",
      "\n",
      "[11  2  4  0  5  5  1  0 19]\n",
      "MNB Accuracy:  0.7446808510638298\n",
      "MNB F1:  0.7128408834798288\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.76      0.70        17\n",
      "          1       0.40      0.40      0.40        10\n",
      "          2       0.94      0.80      0.86        20\n",
      "\n",
      "avg / total       0.72      0.70      0.71        47\n",
      "\n",
      "[13  4  0  5  4  1  2  2 16]\n",
      "svc Accuracy:  0.7021276595744681\n",
      "svc F1:  0.6558558558558558\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.82      0.74        17\n",
      "          1       0.80      0.40      0.53        10\n",
      "          2       0.86      0.90      0.88        20\n",
      "\n",
      "avg / total       0.78      0.77      0.75        47\n",
      "\n",
      "[14  1  2  5  4  1  2  0 18]\n",
      "LR Accuracy:  0.7659574468085106\n",
      "LR F1:  0.7160747396947653\n",
      "For name:  j_ren\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0002-7978-8093': 38, '0000-0002-4161-1292': 30, '0000-0003-2806-7226': 17, '0000-0001-6116-3194': 6, '0000-0001-7461-0491': 6, '0000-0003-2711-2048': 4, '0000-0002-6905-2824': 1})\n",
      "['0000-0002-7978-8093', '0000-0003-2806-7226', '0000-0002-4161-1292']\n",
      "Total sample size after apply threshold:  85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 49)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 12)\n",
      "2\n",
      "(85, 61)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.89      0.82        38\n",
      "          1       0.81      0.76      0.79        17\n",
      "          2       0.88      0.70      0.78        30\n",
      "\n",
      "avg / total       0.81      0.80      0.80        85\n",
      "\n",
      "[34  1  3  4 13  0  7  2 21]\n",
      "MNB Accuracy:  0.8\n",
      "MNB F1:  0.7949778913634336\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.92      0.80        38\n",
      "          1       1.00      0.82      0.90        17\n",
      "          2       0.86      0.63      0.73        30\n",
      "\n",
      "avg / total       0.82      0.80      0.80        85\n",
      "\n",
      "[35  0  3  3 14  0 11  0 19]\n",
      "svc Accuracy:  0.8\n",
      "svc F1:  0.8128642461234229\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.87      0.80        38\n",
      "          1       0.93      0.76      0.84        17\n",
      "          2       0.81      0.70      0.75        30\n",
      "\n",
      "avg / total       0.80      0.79      0.79        85\n",
      "\n",
      "[33  0  5  4 13  0  8  1 21]\n",
      "LR Accuracy:  0.788235294117647\n",
      "LR F1:  0.7946301334369738\n",
      "For name:  j_muller\n",
      "total sample size before apply threshold:  113\n",
      "Counter({'0000-0001-6009-7471': 58, '0000-0002-7682-559X': 42, '0000-0002-1046-2968': 12, '0000-0002-0855-3852': 1})\n",
      "['0000-0002-7682-559X', '0000-0002-1046-2968', '0000-0001-6009-7471']\n",
      "Total sample size after apply threshold:  112\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(112, 64)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(112, 27)\n",
      "2\n",
      "(112, 91)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.81      0.76        42\n",
      "          1       0.88      0.58      0.70        12\n",
      "          2       0.84      0.83      0.83        58\n",
      "\n",
      "avg / total       0.80      0.79      0.79       112\n",
      "\n",
      "[34  1  7  3  7  2 10  0 48]\n",
      "MNB Accuracy:  0.7946428571428571\n",
      "MNB F1:  0.7662758508386256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.79      0.78        42\n",
      "          1       0.78      0.58      0.67        12\n",
      "          2       0.82      0.84      0.83        58\n",
      "\n",
      "avg / total       0.79      0.79      0.79       112\n",
      "\n",
      "[33  1  8  2  7  3  8  1 49]\n",
      "svc Accuracy:  0.7946428571428571\n",
      "svc F1:  0.7578819098260773\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.76      0.76        42\n",
      "          1       0.86      0.50      0.63        12\n",
      "          2       0.81      0.88      0.84        58\n",
      "\n",
      "avg / total       0.80      0.79      0.79       112\n",
      "\n",
      "[32  1  9  3  6  3  7  0 51]\n",
      "LR Accuracy:  0.7946428571428571\n",
      "LR F1:  0.7454863052949178\n",
      "For name:  h_tanaka\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-4378-5747': 21, '0000-0003-1511-8557': 4, '0000-0002-3153-8802': 1, '0000-0002-1760-691X': 1, '0000-0001-8622-7422': 1})\n",
      "['0000-0002-4378-5747']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  j_pierce\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-7107-4766': 24, '0000-0002-2861-0519': 10, '0000-0002-4241-838X': 3, '0000-0002-4241-993X': 1, '0000-0002-2558-8184': 1})\n",
      "['0000-0002-7107-4766', '0000-0002-2861-0519']\n",
      "Total sample size after apply threshold:  34\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 18)\n",
      "2\n",
      "(34, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        24\n",
      "          1       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.92      0.91      0.91        34\n",
      "\n",
      "[24  0  3  7]\n",
      "MNB Accuracy:  0.9117647058823529\n",
      "MNB F1:  0.8823529411764706\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        24\n",
      "          1       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.92      0.91      0.91        34\n",
      "\n",
      "[24  0  3  7]\n",
      "svc Accuracy:  0.9117647058823529\n",
      "svc F1:  0.8823529411764706\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        24\n",
      "          1       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.88      0.85      0.84        34\n",
      "\n",
      "[24  0  5  5]\n",
      "LR Accuracy:  0.8529411764705882\n",
      "LR F1:  0.7861635220125787\n",
      "For name:  j_guerrero\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0001-6729-585X': 10, '0000-0001-5209-2267': 2, '0000-0001-5236-4592': 2, '0000-0003-1442-9302': 1})\n",
      "['0000-0001-6729-585X']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  r_coelho\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0001-5790-8616': 12, '0000-0002-1127-1661': 7, '0000-0002-9340-3612': 4, '0000-0003-3813-5157': 3})\n",
      "['0000-0001-5790-8616']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  a_masi\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-0361-0950': 20, '0000-0002-7163-3978': 17, '0000-0001-9822-9767': 1, '0000-0002-9695-6634': 1})\n",
      "['0000-0002-0361-0950', '0000-0002-7163-3978']\n",
      "Total sample size after apply threshold:  37\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 13)\n",
      "2\n",
      "(37, 44)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70        20\n",
      "          1       0.65      0.65      0.65        17\n",
      "\n",
      "avg / total       0.68      0.68      0.68        37\n",
      "\n",
      "[14  6  6 11]\n",
      "MNB Accuracy:  0.6756756756756757\n",
      "MNB F1:  0.6735294117647059\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.80      0.82        20\n",
      "          1       0.78      0.82      0.80        17\n",
      "\n",
      "avg / total       0.81      0.81      0.81        37\n",
      "\n",
      "[16  4  3 14]\n",
      "svc Accuracy:  0.8108108108108109\n",
      "svc F1:  0.8102564102564103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.65      0.67        20\n",
      "          1       0.61      0.65      0.63        17\n",
      "\n",
      "avg / total       0.65      0.65      0.65        37\n",
      "\n",
      "[13  7  6 11]\n",
      "LR Accuracy:  0.6486486486486487\n",
      "LR F1:  0.6476190476190478\n",
      "For name:  b_jackson\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-4917-1199': 14, '0000-0001-6313-0812': 10, '0000-0002-7127-1735': 4, '0000-0001-6405-8111': 1})\n",
      "['0000-0001-6313-0812', '0000-0002-4917-1199']\n",
      "Total sample size after apply threshold:  24\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 10)\n",
      "2\n",
      "(24, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.10      0.17        10\n",
      "          1       0.59      0.93      0.72        14\n",
      "\n",
      "avg / total       0.55      0.58      0.49        24\n",
      "\n",
      "[ 1  9  1 13]\n",
      "MNB Accuracy:  0.5833333333333334\n",
      "MNB F1:  0.44444444444444453\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.36      0.40      0.38        10\n",
      "          1       0.54      0.50      0.52        14\n",
      "\n",
      "avg / total       0.47      0.46      0.46        24\n",
      "\n",
      "[4 6 7 7]\n",
      "svc Accuracy:  0.4583333333333333\n",
      "svc F1:  0.44973544973544977\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.10      0.15        10\n",
      "          1       0.57      0.86      0.69        14\n",
      "\n",
      "avg / total       0.47      0.54      0.46        24\n",
      "\n",
      "[ 1  9  2 12]\n",
      "LR Accuracy:  0.5416666666666666\n",
      "LR F1:  0.4197802197802198\n",
      "For name:  a_jha\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-8061-5085': 11, '0000-0001-9185-2249': 10, '0000-0002-6305-0721': 9, '0000-0002-6852-1641': 8, '0000-0001-9660-4308': 1})\n",
      "['0000-0001-9185-2249', '0000-0002-8061-5085']\n",
      "Total sample size after apply threshold:  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 15)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 6)\n",
      "2\n",
      "(21, 21)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.80      0.73        10\n",
      "          1       0.78      0.64      0.70        11\n",
      "\n",
      "avg / total       0.72      0.71      0.71        21\n",
      "\n",
      "[8 2 4 7]\n",
      "MNB Accuracy:  0.7142857142857143\n",
      "MNB F1:  0.7136363636363636\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80        10\n",
      "          1       0.82      0.82      0.82        11\n",
      "\n",
      "avg / total       0.81      0.81      0.81        21\n",
      "\n",
      "[8 2 2 9]\n",
      "svc Accuracy:  0.8095238095238095\n",
      "svc F1:  0.8090909090909092\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.70      0.67        10\n",
      "          1       0.70      0.64      0.67        11\n",
      "\n",
      "avg / total       0.67      0.67      0.67        21\n",
      "\n",
      "[7 3 4 7]\n",
      "LR Accuracy:  0.6666666666666666\n",
      "LR F1:  0.6666666666666666\n",
      "For name:  m_mosquera\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0003-2248-3050': 25, '0000-0002-5528-0535': 17, '0000-0003-4823-6154': 12, '0000-0002-4632-0195': 6})\n",
      "['0000-0003-4823-6154', '0000-0003-2248-3050', '0000-0002-5528-0535']\n",
      "Total sample size after apply threshold:  54\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 16)\n",
      "2\n",
      "(54, 38)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.61      0.88      0.72        25\n",
      "          2       0.64      0.53      0.58        17\n",
      "\n",
      "avg / total       0.71      0.65      0.63        54\n",
      "\n",
      "[ 4  6  2  0 22  3  0  8  9]\n",
      "MNB Accuracy:  0.6481481481481481\n",
      "MNB F1:  0.6006522122333862\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.67      0.80      0.73        25\n",
      "          2       0.61      0.65      0.63        17\n",
      "\n",
      "avg / total       0.72      0.69      0.68        54\n",
      "\n",
      "[ 6  4  2  0 20  5  0  6 11]\n",
      "svc Accuracy:  0.6851851851851852\n",
      "svc F1:  0.6741702741702742\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.67      0.88      0.76        25\n",
      "          2       0.71      0.71      0.71        17\n",
      "\n",
      "avg / total       0.75      0.70      0.68        54\n",
      "\n",
      "[ 4  6  2  0 22  3  0  5 12]\n",
      "LR Accuracy:  0.7037037037037037\n",
      "LR F1:  0.6548343475321164\n",
      "For name:  a_silva\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  786\n",
      "Counter({'0000-0003-2861-8286': 158, '0000-0001-5525-0494': 156, '0000-0002-8984-8600': 74, '0000-0001-5790-5116': 41, '0000-0002-7524-9914': 39, '0000-0002-7802-8690': 39, '0000-0003-4968-5138': 30, '0000-0002-7713-1813': 22, '0000-0002-9968-3707': 18, '0000-0002-6332-5182': 16, '0000-0002-5668-7134': 16, '0000-0001-5554-7714': 14, '0000-0002-4839-8279': 14, '0000-0002-1112-1209': 11, '0000-0003-0423-2514': 10, '0000-0002-4386-5851': 10, '0000-0002-9679-8357': 10, '0000-0003-3786-2889': 10, '0000-0002-1673-2164': 10, '0000-0001-7604-792X': 8, '0000-0002-1840-1473': 8, '0000-0003-0393-1655': 7, '0000-0003-4212-5955': 7, '0000-0002-0067-0288': 5, '0000-0002-0634-0546': 5, '0000-0003-2002-4774': 4, '0000-0001-5470-9523': 4, '0000-0002-4364-4979': 4, '0000-0002-5388-1732': 3, '0000-0001-5203-5908': 3, '0000-0001-7231-7021': 3, '0000-0002-5334-0047': 3, '0000-0002-1718-0744': 2, '0000-0003-0384-4447': 2, '0000-0002-2100-7223': 2, '0000-0003-4504-0607': 2, '0000-0003-3576-9023': 2, '0000-0002-3403-5792': 2, '0000-0003-2092-801X': 1, '0000-0002-9595-0038': 1, '0000-0003-4734-6538': 1, '0000-0001-6365-1407': 1, '0000-0002-5842-643X': 1, '0000-0002-8363-0109': 1, '0000-0002-7029-1048': 1, '0000-0002-4904-7470': 1, '0000-0002-3254-2598': 1, '0000-0002-5957-2711': 1, '0000-0002-1724-7777': 1, '0000-0001-6939-8430': 1})\n",
      "['0000-0002-7524-9914', '0000-0002-9968-3707', '0000-0001-5554-7714', '0000-0003-0423-2514', '0000-0002-4386-5851', '0000-0002-9679-8357', '0000-0001-5525-0494', '0000-0003-2861-8286', '0000-0002-8984-8600', '0000-0002-7713-1813', '0000-0003-3786-2889', '0000-0002-1673-2164', '0000-0002-6332-5182', '0000-0003-4968-5138', '0000-0001-5790-5116', '0000-0002-7802-8690', '0000-0002-4839-8279', '0000-0002-1112-1209', '0000-0002-5668-7134']\n",
      "Total sample size after apply threshold:  698\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(698, 313)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(698, 28)\n",
      "2\n",
      "(698, 341)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.21      0.33        39\n",
      "          1       0.00      0.00      0.00        18\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.64      0.78      0.70       156\n",
      "          7       0.38      0.96      0.54       158\n",
      "          8       0.46      0.42      0.44        74\n",
      "          9       0.00      0.00      0.00        22\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       0.00      0.00      0.00        10\n",
      "         12       0.00      0.00      0.00        16\n",
      "         13       0.00      0.00      0.00        30\n",
      "         14       0.68      0.32      0.43        41\n",
      "         15       0.50      0.08      0.13        39\n",
      "         16       0.00      0.00      0.00        14\n",
      "         17       0.00      0.00      0.00        11\n",
      "         18       1.00      0.12      0.22        16\n",
      "\n",
      "avg / total       0.42      0.47      0.38       698\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8   0   0   0   0   0   6  24   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1  16   0   0   0   0   0   0   0   1   0\n",
      "   0   0   0   0   0   0   0   0   2  11   1   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   2   7   1   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   1   7   2   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   6   3   0   0   0   0\n",
      "   0   1   0   0   0   0   1   0   0   0   0   0 122  23   6   0   0   0\n",
      "   0   0   2   2   0   0   0   0   0   0   0   0   0   7 151   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  11  29  31   0\n",
      "   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   2  18   2\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   7\n",
      "   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2\n",
      "   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   1  14   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   9  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   3  11  14   0   0   0   0   0  13   0   0   0   0   0   0   0\n",
      "   0   0   0  13  23   0   0   0   0   0   0   0   3   0   0   0   0   0\n",
      "   0   0   0   0   3   8   3   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   4   6   1   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   1  12   1   0   0   0   0   0   0   0   0   0\n",
      "   2]\n",
      "MNB Accuracy:  0.47277936962750716\n",
      "MNB F1:  0.14733037263711327\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.41      0.54        39\n",
      "          1       0.71      0.28      0.40        18\n",
      "          2       0.33      0.07      0.12        14\n",
      "          3       0.86      0.60      0.71        10\n",
      "          4       0.67      0.20      0.31        10\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.45      0.85      0.59       156\n",
      "          7       0.71      0.88      0.79       158\n",
      "          8       0.54      0.42      0.47        74\n",
      "          9       0.83      0.23      0.36        22\n",
      "         10       0.83      0.50      0.62        10\n",
      "         11       0.67      0.40      0.50        10\n",
      "         12       0.71      0.31      0.43        16\n",
      "         13       0.92      0.40      0.56        30\n",
      "         14       0.50      0.39      0.44        41\n",
      "         15       0.67      0.36      0.47        39\n",
      "         16       1.00      0.07      0.13        14\n",
      "         17       1.00      0.18      0.31        11\n",
      "         18       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       0.64      0.59      0.56       698\n",
      "\n",
      "[ 16   0   0   0   0   0  16   4   1   1   0   0   0   0   1   0   0   0\n",
      "   0   1   5   0   0   0   0   6   5   0   0   0   0   0   0   0   1   0\n",
      "   0   0   0   0   1   0   0   0   5   6   0   0   0   1   0   0   0   1\n",
      "   0   0   0   0   0   0   6   0   0   1   2   0   0   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   2   0   3   1   1   0   0   0   0   0\n",
      "   3   0   0   0   0   0   0   0   0   0   0   4   2   3   0   0   0   0\n",
      "   0   1   0   0   0   0   2   0   0   0   0   0 132  10   6   0   0   0\n",
      "   0   0   2   4   0   0   0   0   0   0   0   0   0  18 139   0   0   0\n",
      "   0   0   0   0   1   0   0   0   0   1   0   0   0   2  28   5  31   0\n",
      "   0   0   0   0   7   0   0   0   0   1   0   0   0   0   0  10   5   1\n",
      "   5   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   4   0\n",
      "   0   0   5   0   0   0   0   0   0   0   0   0   0   2   0   0   0   1\n",
      "   1   0   0   0   4   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   7   3   0   0   0   1   5   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  16   1   0   0   0   0   0  12   1   0   0   0   0   0   0   0   0\n",
      "   1   0  11   1  11   0   0   0   0   1  16   0   0   0   0   0   1   0\n",
      "   0   0   0  14   9   0   0   0   0   0   0   1  14   0   0   0   0   0\n",
      "   0   0   0   0  10   1   2   0   0   0   0   0   0   0   1   0   0   0\n",
      "   0   0   0   0   0   7   1   1   0   0   0   0   0   0   0   0   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  16]\n",
      "svc Accuracy:  0.5902578796561605\n",
      "svc F1:  0.4600670802507636\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.41      0.55        39\n",
      "          1       0.00      0.00      0.00        18\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       1.00      0.20      0.33        10\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.56      0.81      0.66       156\n",
      "          7       0.50      0.92      0.65       158\n",
      "          8       0.37      0.43      0.40        74\n",
      "          9       1.00      0.09      0.17        22\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       1.00      0.10      0.18        10\n",
      "         12       1.00      0.19      0.32        16\n",
      "         13       0.88      0.23      0.37        30\n",
      "         14       0.63      0.41      0.50        41\n",
      "         15       0.85      0.28      0.42        39\n",
      "         16       0.00      0.00      0.00        14\n",
      "         17       0.00      0.00      0.00        11\n",
      "         18       1.00      0.81      0.90        16\n",
      "\n",
      "avg / total       0.55      0.54      0.48       698\n",
      "\n",
      "[ 16   0   0   0   0   0   8  13   2   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   3   9   6   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   6   6   2   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   2   0   0   1   5   1   0   0   0   0   0   1\n",
      "   0   0   0   0   0   0   0   0   0   0   3   3   4   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   6   3   0   0   0   0\n",
      "   0   1   0   0   0   0   2   0   0   0   0   0 127  15   8   0   0   0\n",
      "   0   0   2   2   0   0   0   0   0   0   0   0   0   9 146   3   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   1  15  21  32   0\n",
      "   0   0   0   0   5   0   0   0   0   1   0   0   0   0   0   5  10   4\n",
      "   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   4\n",
      "   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   2\n",
      "   6   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   5   7   1   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  13  10   0   0   0   0   0   7   0   0   0   0   0   0   0   0   0\n",
      "   0   0   2   8  13   0   0   0   0   1  17   0   0   0   0   0   0   0\n",
      "   0   0   0  11  15   1   0   0   0   0   0   1  11   0   0   0   0   0\n",
      "   0   0   0   0   5   6   3   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   7   3   1   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   1   0   2   0   0   0   0   0   0   0   0   0\n",
      "  13]\n",
      "LR Accuracy:  0.5401146131805158\n",
      "LR F1:  0.2865160771278025\n",
      "For name:  m_guerra\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0001-6286-4048': 8, '0000-0003-1970-7439': 4, '0000-0002-3655-9004': 3, '0000-0003-3863-8520': 3})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_suzuki\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0003-4682-5086': 39, '0000-0002-8150-140X': 15, '0000-0003-4600-2506': 14, '0000-0002-8555-5448': 9, '0000-0001-5371-6385': 5})\n",
      "['0000-0003-4682-5086', '0000-0003-4600-2506', '0000-0002-8150-140X']\n",
      "Total sample size after apply threshold:  68\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(68, 45)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(68, 19)\n",
      "2\n",
      "(68, 64)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.87      0.83        39\n",
      "          1       0.90      0.64      0.75        14\n",
      "          2       0.60      0.60      0.60        15\n",
      "\n",
      "avg / total       0.77      0.76      0.76        68\n",
      "\n",
      "[34  0  5  4  9  1  5  1  9]\n",
      "MNB Accuracy:  0.7647058823529411\n",
      "MNB F1:  0.7264227642276423\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.97      0.88        39\n",
      "          1       1.00      0.64      0.78        14\n",
      "          2       0.92      0.73      0.81        15\n",
      "\n",
      "avg / total       0.87      0.85      0.85        68\n",
      "\n",
      "[38  0  1  5  9  0  4  0 11]\n",
      "svc Accuracy:  0.8529411764705882\n",
      "svc F1:  0.8270481468998491\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82        39\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       1.00      0.40      0.57        15\n",
      "\n",
      "avg / total       0.83      0.75      0.72        68\n",
      "\n",
      "[39  0  0  8  6  0  9  0  6]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.6641604010025063\n",
      "For name:  m_cohen\n",
      "total sample size before apply threshold:  251\n",
      "Counter({'0000-0003-2038-6070': 103, '0000-0002-1879-3593': 69, '0000-0002-6090-2394': 46, '0000-0001-6731-4053': 13, '0000-0003-3183-2558': 8, '0000-0002-1548-2773': 4, '0000-0001-6362-6148': 4, '0000-0002-5876-6565': 3, '0000-0002-1372-680X': 1})\n",
      "['0000-0001-6731-4053', '0000-0003-2038-6070', '0000-0002-6090-2394', '0000-0002-1879-3593']\n",
      "Total sample size after apply threshold:  231\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(231, 89)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(231, 24)\n",
      "2\n",
      "(231, 113)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       0.77      0.85      0.81       103\n",
      "          2       0.77      0.52      0.62        46\n",
      "          3       0.69      0.83      0.75        69\n",
      "\n",
      "avg / total       0.76      0.74      0.72       231\n",
      "\n",
      "[ 2  0  3  8  0 88  3 12  0 16 24  6  0 11  1 57]\n",
      "MNB Accuracy:  0.7402597402597403\n",
      "MNB F1:  0.6118456848961437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.23      0.33        13\n",
      "          1       0.82      0.87      0.85       103\n",
      "          2       0.89      0.70      0.78        46\n",
      "          3       0.79      0.91      0.85        69\n",
      "\n",
      "avg / total       0.81      0.81      0.80       231\n",
      "\n",
      "[ 3  5  1  4  1 90  2 10  1 10 32  3  0  5  1 63]\n",
      "svc Accuracy:  0.8138528138528138\n",
      "svc F1:  0.7011322861598027\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.72      0.86      0.78       103\n",
      "          2       0.82      0.59      0.68        46\n",
      "          3       0.76      0.81      0.78        69\n",
      "\n",
      "avg / total       0.71      0.74      0.72       231\n",
      "\n",
      "[ 0  7  2  4  0 89  3 11  0 16 27  3  0 12  1 56]\n",
      "LR Accuracy:  0.7445887445887446\n",
      "LR F1:  0.5627255140443118\n",
      "For name:  m_kobayashi\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-6657-1928': 33, '0000-0003-0219-9108': 9, '0000-0002-6554-8400': 4, '0000-0001-8116-0505': 2, '0000-0002-4001-3581': 2, '0000-0001-6539-7326': 1})\n",
      "['0000-0002-6657-1928']\n",
      "Total sample size after apply threshold:  33\n",
      "For name:  s_wright\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0001-9973-9697': 44, '0000-0002-8593-6056': 10, '0000-0002-1502-131X': 5, '0000-0003-1034-8054': 2})\n",
      "['0000-0001-9973-9697', '0000-0002-8593-6056']\n",
      "Total sample size after apply threshold:  54\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 9)\n",
      "2\n",
      "(54, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        44\n",
      "          1       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.86      0.83      0.77        54\n",
      "\n",
      "[44  0  9  1]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.5445173383317713\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        44\n",
      "          1       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.90      0.89      0.87        54\n",
      "\n",
      "[44  0  6  4]\n",
      "svc Accuracy:  0.8888888888888888\n",
      "svc F1:  0.7537993920972645\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90        44\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.66      0.81      0.73        54\n",
      "\n",
      "[44  0 10  0]\n",
      "LR Accuracy:  0.8148148148148148\n",
      "LR F1:  0.44897959183673464\n",
      "For name:  a_mills\n",
      "total sample size before apply threshold:  169\n",
      "Counter({'0000-0001-9863-9950': 115, '0000-0003-4880-7332': 34, '0000-0002-6997-5581': 15, '0000-0002-6893-3857': 3, '0000-0003-4932-8413': 1, '0000-0002-9065-0458': 1})\n",
      "['0000-0001-9863-9950', '0000-0002-6997-5581', '0000-0003-4880-7332']\n",
      "Total sample size after apply threshold:  164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(164, 46)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(164, 25)\n",
      "2\n",
      "(164, 71)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91       115\n",
      "          1       0.67      0.27      0.38        15\n",
      "          2       0.96      0.71      0.81        34\n",
      "\n",
      "avg / total       0.86      0.86      0.84       164\n",
      "\n",
      "[113   1   1  11   4   0   9   1  24]\n",
      "MNB Accuracy:  0.8597560975609756\n",
      "MNB F1:  0.7019340085223081\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       115\n",
      "          1       0.70      0.47      0.56        15\n",
      "          2       1.00      0.76      0.87        34\n",
      "\n",
      "avg / total       0.89      0.89      0.88       164\n",
      "\n",
      "[113   2   0   8   7   0   7   1  26]\n",
      "svc Accuracy:  0.8902439024390244\n",
      "svc F1:  0.7855692729766804\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       115\n",
      "          1       1.00      0.07      0.12        15\n",
      "          2       1.00      0.59      0.74        34\n",
      "\n",
      "avg / total       0.86      0.83      0.79       164\n",
      "\n",
      "[115   0   0  14   1   0  14   0  20]\n",
      "LR Accuracy:  0.8292682926829268\n",
      "LR F1:  0.5857378696525983\n",
      "For name:  c_west\n",
      "total sample size before apply threshold:  181\n",
      "Counter({'0000-0002-0839-3449': 155, '0000-0001-7595-6777': 20, '0000-0001-7649-9600': 3, '0000-0002-1149-3723': 2, '0000-0002-3799-4462': 1})\n",
      "['0000-0002-0839-3449', '0000-0001-7595-6777']\n",
      "Total sample size after apply threshold:  175\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 58)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 28)\n",
      "2\n",
      "(175, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99       155\n",
      "          1       1.00      0.80      0.89        20\n",
      "\n",
      "avg / total       0.98      0.98      0.98       175\n",
      "\n",
      "[155   0   4  16]\n",
      "MNB Accuracy:  0.9771428571428571\n",
      "MNB F1:  0.9380750176928521\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       155\n",
      "          1       1.00      0.90      0.95        20\n",
      "\n",
      "avg / total       0.99      0.99      0.99       175\n",
      "\n",
      "[155   0   2  18]\n",
      "svc Accuracy:  0.9885714285714285\n",
      "svc F1:  0.9704790823211876\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99       155\n",
      "          1       1.00      0.80      0.89        20\n",
      "\n",
      "avg / total       0.98      0.98      0.98       175\n",
      "\n",
      "[155   0   4  16]\n",
      "LR Accuracy:  0.9771428571428571\n",
      "LR F1:  0.9380750176928521\n",
      "For name:  a_marino\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0002-1709-538X': 7, '0000-0002-0528-4925': 6, '0000-0003-0308-859X': 1, '0000-0001-8751-8811': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_jiang\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0002-8280-6029': 54, '0000-0002-7533-3753': 28, '0000-0002-3816-4639': 19, '0000-0001-5857-8540': 1})\n",
      "['0000-0002-8280-6029', '0000-0002-3816-4639', '0000-0002-7533-3753']\n",
      "Total sample size after apply threshold:  101\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 50)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 16)\n",
      "2\n",
      "(101, 66)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.94      0.88        54\n",
      "          1       1.00      0.53      0.69        19\n",
      "          2       0.72      0.75      0.74        28\n",
      "\n",
      "avg / total       0.83      0.81      0.80       101\n",
      "\n",
      "[51  0  3  4 10  5  7  0 21]\n",
      "MNB Accuracy:  0.8118811881188119\n",
      "MNB F1:  0.7686025408348458\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91        54\n",
      "          1       1.00      0.84      0.91        19\n",
      "          2       0.84      0.75      0.79        28\n",
      "\n",
      "avg / total       0.88      0.88      0.88       101\n",
      "\n",
      "[52  0  2  1 16  2  7  0 21]\n",
      "svc Accuracy:  0.8811881188118812\n",
      "svc F1:  0.8730064154095931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.94      0.86        54\n",
      "          1       1.00      0.58      0.73        19\n",
      "          2       0.76      0.68      0.72        28\n",
      "\n",
      "avg / total       0.82      0.80      0.79       101\n",
      "\n",
      "[51  0  3  5 11  3  9  0 19]\n",
      "LR Accuracy:  0.801980198019802\n",
      "LR F1:  0.769152440850554\n",
      "For name:  t_becker\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0002-4117-8249': 12, '0000-0002-5656-4564': 5, '0000-0003-3432-783X': 3, '0000-0002-5193-4044': 1})\n",
      "['0000-0002-4117-8249']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  s_pedersen\n",
      "total sample size before apply threshold:  322\n",
      "Counter({'0000-0002-7838-8063': 166, '0000-0002-3044-7714': 80, '0000-0002-6500-9263': 40, '0000-0002-4786-6464': 21, '0000-0001-8055-3251': 11, '0000-0002-8566-7693': 1, '0000-0002-4355-1764': 1, '0000-0002-3822-5075': 1, '0000-0001-8017-4227': 1})\n",
      "['0000-0002-7838-8063', '0000-0002-3044-7714', '0000-0002-4786-6464', '0000-0001-8055-3251', '0000-0002-6500-9263']\n",
      "Total sample size after apply threshold:  318\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(318, 139)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(318, 28)\n",
      "2\n",
      "(318, 167)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.92      0.80       166\n",
      "          1       0.71      0.62      0.67        80\n",
      "          2       0.00      0.00      0.00        21\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.85      0.70      0.77        40\n",
      "\n",
      "avg / total       0.66      0.73      0.68       318\n",
      "\n",
      "[153   9   0   0   4  29  50   0   0   1  16   5   0   0   0   6   5   0\n",
      "   0   0  11   1   0   0  28]\n",
      "MNB Accuracy:  0.7264150943396226\n",
      "MNB F1:  0.44738791212742235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.94      0.82       166\n",
      "          1       0.75      0.55      0.63        80\n",
      "          2       1.00      0.43      0.60        21\n",
      "          3       1.00      0.45      0.62        11\n",
      "          4       1.00      0.78      0.87        40\n",
      "\n",
      "avg / total       0.79      0.77      0.76       318\n",
      "\n",
      "[156  10   0   0   0  36  44   0   0   0   9   3   9   0   0   5   1   0\n",
      "   5   0   8   1   0   0  31]\n",
      "svc Accuracy:  0.7704402515723271\n",
      "svc F1:  0.7104771186757044\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.95      0.79       166\n",
      "          1       0.76      0.51      0.61        80\n",
      "          2       1.00      0.10      0.17        21\n",
      "          3       1.00      0.09      0.17        11\n",
      "          4       1.00      0.65      0.79        40\n",
      "\n",
      "avg / total       0.77      0.72      0.68       318\n",
      "\n",
      "[158   8   0   0   0  39  41   0   0   0  14   5   2   0   0  10   0   0\n",
      "   1   0  14   0   0   0  26]\n",
      "LR Accuracy:  0.7169811320754716\n",
      "LR F1:  0.5056857443436421\n",
      "For name:  a_ali\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0003-0437-8919': 15, '0000-0002-7224-6654': 11, '0000-0001-7913-8544': 9, '0000-0002-4370-007X': 6, '0000-0003-2444-8400': 6, '0000-0003-0552-7322': 6, '0000-0001-5267-2608': 2, '0000-0001-9966-2917': 1, '0000-0001-9673-0080': 1, '0000-0001-6199-0034': 1, '0000-0002-7864-8240': 1, '0000-0003-3030-3371': 1, '0000-0003-4467-5387': 1, '0000-0002-6554-3378': 1})\n",
      "['0000-0003-0437-8919', '0000-0002-7224-6654']\n",
      "Total sample size after apply threshold:  26\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 10)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 11)\n",
      "2\n",
      "(26, 21)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90        15\n",
      "          1       0.90      0.82      0.86        11\n",
      "\n",
      "avg / total       0.89      0.88      0.88        26\n",
      "\n",
      "[14  1  2  9]\n",
      "MNB Accuracy:  0.8846153846153846\n",
      "MNB F1:  0.8801843317972351\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        15\n",
      "          1       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[14  1  0 11]\n",
      "svc Accuracy:  0.9615384615384616\n",
      "svc F1:  0.9610194902548725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90        15\n",
      "          1       0.90      0.82      0.86        11\n",
      "\n",
      "avg / total       0.89      0.88      0.88        26\n",
      "\n",
      "[14  1  2  9]\n",
      "LR Accuracy:  0.8846153846153846\n",
      "LR F1:  0.8801843317972351\n",
      "For name:  k_jones\n",
      "total sample size before apply threshold:  607\n",
      "Counter({'0000-0001-7108-9776': 331, '0000-0002-0294-0851': 74, '0000-0001-8923-2999': 55, '0000-0001-8398-2190': 32, '0000-0003-4764-7031': 29, '0000-0002-7380-9797': 18, '0000-0001-9136-0877': 15, '0000-0002-7216-2506': 13, '0000-0003-3815-5713': 9, '0000-0002-8819-8992': 6, '0000-0002-7127-1612': 4, '0000-0002-0242-7097': 4, '0000-0002-6916-8640': 4, '0000-0001-5692-653X': 3, '0000-0002-9982-8742': 3, '0000-0002-0478-8021': 2, '0000-0001-9373-0982': 1, '0000-0001-7335-1379': 1, '0000-0001-6553-8897': 1, '0000-0002-1552-7847': 1, '0000-0001-9115-4192': 1})\n",
      "['0000-0002-7380-9797', '0000-0001-8923-2999', '0000-0002-7216-2506', '0000-0003-4764-7031', '0000-0001-7108-9776', '0000-0001-9136-0877', '0000-0002-0294-0851', '0000-0001-8398-2190']\n",
      "Total sample size after apply threshold:  567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(567, 136)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(567, 27)\n",
      "2\n",
      "(567, 163)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        18\n",
      "          1       0.86      0.55      0.67        55\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.00      0.00      0.00        29\n",
      "          4       0.71      1.00      0.83       331\n",
      "          5       0.00      0.00      0.00        15\n",
      "          6       0.78      0.49      0.60        74\n",
      "          7       1.00      0.59      0.75        32\n",
      "\n",
      "avg / total       0.66      0.73      0.67       567\n",
      "\n",
      "[  0   2   0   0  16   0   0   0   0  30   0   0  25   0   0   0   0   0\n",
      "   0   0  13   0   0   0   0   1   0   0  22   0   6   0   0   1   0   0\n",
      " 330   0   0   0   0   0   0   0  12   0   3   0   0   1   0   1  36   0\n",
      "  36   0   0   0   0   0  12   0   1  19]\n",
      "MNB Accuracy:  0.7319223985890653\n",
      "MNB F1:  0.35498376263930914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.56      0.69        18\n",
      "          1       0.90      0.69      0.78        55\n",
      "          2       0.58      0.54      0.56        13\n",
      "          3       0.61      0.38      0.47        29\n",
      "          4       0.97      0.96      0.96       331\n",
      "          5       1.00      0.47      0.64        15\n",
      "          6       0.55      0.89      0.68        74\n",
      "          7       0.97      0.88      0.92        32\n",
      "\n",
      "avg / total       0.88      0.86      0.86       567\n",
      "\n",
      "[ 10   0   1   0   1   0   5   1   0  38   1   0   6   0  10   0   0   0\n",
      "   7   1   1   0   4   0   0   0   1  11   1   0  16   0   0   3   1   1\n",
      " 318   0   8   0   0   0   0   0   1   7   7   0   0   1   1   5   1   0\n",
      "  66   0   1   0   0   0   0   0   3  28]\n",
      "svc Accuracy:  0.855379188712522\n",
      "svc F1:  0.7129020055194237\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.11      0.19        18\n",
      "          1       0.87      0.62      0.72        55\n",
      "          2       1.00      0.31      0.47        13\n",
      "          3       0.80      0.14      0.24        29\n",
      "          4       0.82      0.98      0.89       331\n",
      "          5       1.00      0.13      0.24        15\n",
      "          6       0.60      0.77      0.67        74\n",
      "          7       1.00      0.72      0.84        32\n",
      "\n",
      "avg / total       0.81      0.80      0.76       567\n",
      "\n",
      "[  2   2   0   0  12   0   2   0   0  34   0   0  14   0   7   0   0   0\n",
      "   4   0   7   0   2   0   0   0   0   4  13   0  12   0   0   2   0   0\n",
      " 325   0   4   0   0   0   0   0   6   2   7   0   0   1   0   1  15   0\n",
      "  57   0   1   0   0   0   4   0   4  23]\n",
      "LR Accuracy:  0.7954144620811288\n",
      "LR F1:  0.5325077559682132\n",
      "For name:  m_becker\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0001-9890-8815': 32, '0000-0002-9235-0547': 24, '0000-0001-7233-6361': 3, '0000-0003-1187-1699': 3, '0000-0001-6526-1525': 2, '0000-0003-3450-5579': 2, '0000-0002-1751-1056': 1})\n",
      "['0000-0001-9890-8815', '0000-0002-9235-0547']\n",
      "Total sample size after apply threshold:  56\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 41)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 16)\n",
      "2\n",
      "(56, 57)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.94      0.88        32\n",
      "          1       0.90      0.75      0.82        24\n",
      "\n",
      "avg / total       0.86      0.86      0.85        56\n",
      "\n",
      "[30  2  6 18]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.8502673796791445\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91        32\n",
      "          1       0.95      0.79      0.86        24\n",
      "\n",
      "avg / total       0.90      0.89      0.89        56\n",
      "\n",
      "[31  1  5 19]\n",
      "svc Accuracy:  0.8928571428571429\n",
      "svc F1:  0.8877005347593583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.97      0.89        32\n",
      "          1       0.94      0.71      0.81        24\n",
      "\n",
      "avg / total       0.87      0.86      0.85        56\n",
      "\n",
      "[31  1  7 17]\n",
      "LR Accuracy:  0.8571428571428571\n",
      "LR F1:  0.8476190476190477\n",
      "For name:  c_marshall\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0003-4186-0368': 32, '0000-0002-7571-5700': 29, '0000-0001-5901-2004': 28, '0000-0002-1285-7648': 6, '0000-0002-8227-2354': 6, '0000-0001-6669-3231': 3, '0000-0002-7397-6472': 1, '0000-0002-0592-7716': 1})\n",
      "['0000-0001-5901-2004', '0000-0003-4186-0368', '0000-0002-7571-5700']\n",
      "Total sample size after apply threshold:  89\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 54)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 24)\n",
      "2\n",
      "(89, 78)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.54      0.59        28\n",
      "          1       0.56      0.59      0.58        32\n",
      "          2       0.47      0.52      0.49        29\n",
      "\n",
      "avg / total       0.56      0.55      0.55        89\n",
      "\n",
      "[15  6  7  3 19 10  5  9 15]\n",
      "MNB Accuracy:  0.550561797752809\n",
      "MNB F1:  0.5519320495212492\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.57      0.68        28\n",
      "          1       0.69      0.78      0.74        32\n",
      "          2       0.62      0.72      0.67        29\n",
      "\n",
      "avg / total       0.72      0.70      0.70        89\n",
      "\n",
      "[16  5  7  1 25  6  2  6 21]\n",
      "svc Accuracy:  0.6966292134831461\n",
      "svc F1:  0.6942706160478376\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.54      0.61        28\n",
      "          1       0.63      0.75      0.69        32\n",
      "          2       0.57      0.59      0.58        29\n",
      "\n",
      "avg / total       0.64      0.63      0.63        89\n",
      "\n",
      "[15  6  7  2 24  6  4  8 17]\n",
      "LR Accuracy:  0.6292134831460674\n",
      "LR F1:  0.6247434567047158\n",
      "For name:  s_rafiq\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0003-4873-4540': 23, '0000-0002-9295-3065': 9, '0000-0003-4821-5783': 1})\n",
      "['0000-0003-4873-4540']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  h_liang\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0003-0186-3126': 30, '0000-0001-7633-286X': 27, '0000-0002-3430-9167': 15, '0000-0001-9097-7357': 12, '0000-0001-9496-406X': 10, '0000-0001-5523-6799': 3, '0000-0001-9044-0509': 3, '0000-0002-2950-8559': 2, '0000-0003-1779-9552': 1, '0000-0002-9045-9717': 1})\n",
      "['0000-0002-3430-9167', '0000-0001-7633-286X', '0000-0003-0186-3126', '0000-0001-9496-406X', '0000-0001-9097-7357']\n",
      "Total sample size after apply threshold:  94\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 60)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 15)\n",
      "2\n",
      "(94, 75)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      0.07      0.11        15\n",
      "          1       0.63      0.63      0.63        27\n",
      "          2       0.55      0.80      0.65        30\n",
      "          3       1.00      0.50      0.67        10\n",
      "          4       0.64      0.75      0.69        12\n",
      "\n",
      "avg / total       0.58      0.60      0.56        94\n",
      "\n",
      "[ 1  2  7  0  5  0 17 10  0  0  1  5 24  0  0  1  2  2  5  0  1  1  1  0\n",
      "  9]\n",
      "MNB Accuracy:  0.5957446808510638\n",
      "MNB F1:  0.5485031590294749\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.40      0.41        15\n",
      "          1       0.65      0.63      0.64        27\n",
      "          2       0.54      0.70      0.61        30\n",
      "          3       1.00      0.60      0.75        10\n",
      "          4       0.89      0.67      0.76        12\n",
      "\n",
      "avg / total       0.65      0.62      0.62        94\n",
      "\n",
      "[ 6  2  6  0  1  0 17 10  0  0  3  6 21  0  0  1  1  2  6  0  4  0  0  0\n",
      "  8]\n",
      "svc Accuracy:  0.6170212765957447\n",
      "svc F1:  0.6351805902978429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.33      0.38        15\n",
      "          1       0.64      0.59      0.62        27\n",
      "          2       0.55      0.80      0.65        30\n",
      "          3       1.00      0.50      0.67        10\n",
      "          4       0.89      0.67      0.76        12\n",
      "\n",
      "avg / total       0.65      0.62      0.61        94\n",
      "\n",
      "[ 5  2  7  0  1  0 16 11  0  0  1  5 24  0  0  1  2  2  5  0  4  0  0  0\n",
      "  8]\n",
      "LR Accuracy:  0.6170212765957447\n",
      "LR F1:  0.6154440154440154\n",
      "For name:  c_davis\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0002-5045-0507': 34, '0000-0002-3971-3505': 2, '0000-0003-0866-7822': 2, '0000-0002-0024-2742': 2, '0000-0002-3274-5707': 2, '0000-0001-6205-9719': 1})\n",
      "['0000-0002-5045-0507']\n",
      "Total sample size after apply threshold:  34\n",
      "For name:  e_hall\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0001-5999-5020': 49, '0000-0002-5306-082X': 34, '0000-0002-9477-8619': 24, '0000-0002-9206-4436': 4, '0000-0002-2815-6651': 2, '0000-0003-0244-7458': 2})\n",
      "['0000-0001-5999-5020', '0000-0002-9477-8619', '0000-0002-5306-082X']\n",
      "Total sample size after apply threshold:  107\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 55)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 21)\n",
      "2\n",
      "(107, 76)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.84      0.77        49\n",
      "          1       0.81      0.54      0.65        24\n",
      "          2       0.79      0.79      0.79        34\n",
      "\n",
      "avg / total       0.76      0.76      0.75       107\n",
      "\n",
      "[41  2  6 10 13  1  6  1 27]\n",
      "MNB Accuracy:  0.7570093457943925\n",
      "MNB F1:  0.7392341842397335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.88      0.81        49\n",
      "          1       0.84      0.67      0.74        24\n",
      "          2       0.87      0.79      0.83        34\n",
      "\n",
      "avg / total       0.81      0.80      0.80       107\n",
      "\n",
      "[43  2  4  8 16  0  6  1 27]\n",
      "svc Accuracy:  0.8037383177570093\n",
      "svc F1:  0.79542534399928\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.84      0.76        49\n",
      "          1       0.79      0.46      0.58        24\n",
      "          2       0.79      0.79      0.79        34\n",
      "\n",
      "avg / total       0.75      0.74      0.73       107\n",
      "\n",
      "[41  2  6 12 11  1  6  1 27]\n",
      "LR Accuracy:  0.7383177570093458\n",
      "LR F1:  0.7107747582463784\n",
      "For name:  g_volpe\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-9993-5348': 15, '0000-0001-5057-1846': 14, '0000-0002-3916-5393': 1, '0000-0003-0760-4627': 1})\n",
      "['0000-0001-9993-5348', '0000-0001-5057-1846']\n",
      "Total sample size after apply threshold:  29\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 13)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 12)\n",
      "2\n",
      "(29, 25)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.60      0.62        15\n",
      "          1       0.60      0.64      0.62        14\n",
      "\n",
      "avg / total       0.62      0.62      0.62        29\n",
      "\n",
      "[9 6 5 9]\n",
      "MNB Accuracy:  0.6206896551724138\n",
      "MNB F1:  0.6206896551724138\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.47      0.47        15\n",
      "          1       0.43      0.43      0.43        14\n",
      "\n",
      "avg / total       0.45      0.45      0.45        29\n",
      "\n",
      "[7 8 8 6]\n",
      "svc Accuracy:  0.4482758620689655\n",
      "svc F1:  0.4476190476190476\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.53      0.52        15\n",
      "          1       0.46      0.43      0.44        14\n",
      "\n",
      "avg / total       0.48      0.48      0.48        29\n",
      "\n",
      "[8 7 8 6]\n",
      "LR Accuracy:  0.4827586206896552\n",
      "LR F1:  0.48028673835125457\n",
      "For name:  r_lewis\n",
      "total sample size before apply threshold:  427\n",
      "Counter({'0000-0003-3470-923X': 185, '0000-0002-2002-4339': 175, '0000-0003-4044-9104': 41, '0000-0002-4598-7553': 7, '0000-0003-1395-3276': 6, '0000-0003-1859-0021': 4, '0000-0001-9929-2629': 3, '0000-0001-6642-5771': 3, '0000-0002-2680-6235': 1, '0000-0002-6644-6385': 1, '0000-0003-1046-811X': 1})\n",
      "['0000-0002-2002-4339', '0000-0003-3470-923X', '0000-0003-4044-9104']\n",
      "Total sample size after apply threshold:  401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(401, 142)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(401, 32)\n",
      "2\n",
      "(401, 174)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.90      0.82       175\n",
      "          1       0.83      0.77      0.80       185\n",
      "          2       0.95      0.44      0.60        41\n",
      "\n",
      "avg / total       0.81      0.79      0.79       401\n",
      "\n",
      "[157  18   0  41 143   1  11  12  18]\n",
      "MNB Accuracy:  0.7930174563591023\n",
      "MNB F1:  0.7388636716325263\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.81      0.89       175\n",
      "          1       0.80      0.99      0.88       185\n",
      "          2       1.00      0.66      0.79        41\n",
      "\n",
      "avg / total       0.90      0.88      0.88       401\n",
      "\n",
      "[142  33   0   1 184   0   0  14  27]\n",
      "svc Accuracy:  0.8802992518703242\n",
      "svc F1:  0.8572715975601658\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.81      0.85       175\n",
      "          1       0.78      0.95      0.85       185\n",
      "          2       1.00      0.46      0.63        41\n",
      "\n",
      "avg / total       0.86      0.84      0.83       401\n",
      "\n",
      "[141  34   0   9 176   0   5  17  19]\n",
      "LR Accuracy:  0.8379052369077307\n",
      "LR F1:  0.780749239972541\n",
      "For name:  c_rodriguez\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0001-6697-1692': 23, '0000-0002-4042-4313': 18, '0000-0003-2289-4239': 1, '0000-0003-3927-6883': 1})\n",
      "['0000-0002-4042-4313', '0000-0001-6697-1692']\n",
      "Total sample size after apply threshold:  41\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 26)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 14)\n",
      "2\n",
      "(41, 40)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.78      0.82        18\n",
      "          1       0.84      0.91      0.87        23\n",
      "\n",
      "avg / total       0.86      0.85      0.85        41\n",
      "\n",
      "[14  4  2 21]\n",
      "MNB Accuracy:  0.8536585365853658\n",
      "MNB F1:  0.8492647058823529\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.67      0.73        18\n",
      "          1       0.77      0.87      0.82        23\n",
      "\n",
      "avg / total       0.78      0.78      0.78        41\n",
      "\n",
      "[12  6  3 20]\n",
      "svc Accuracy:  0.7804878048780488\n",
      "svc F1:  0.771799628942486\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.56      0.67        18\n",
      "          1       0.72      0.91      0.81        23\n",
      "\n",
      "avg / total       0.77      0.76      0.75        41\n",
      "\n",
      "[10  8  2 21]\n",
      "LR Accuracy:  0.7560975609756098\n",
      "LR F1:  0.7371794871794872\n",
      "For name:  p_hall\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0001-6015-7841': 11, '0000-0001-9218-6233': 9, '0000-0002-4239-4226': 1, '0000-0002-8214-0351': 1})\n",
      "['0000-0001-6015-7841']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  r_srivastava\n",
      "total sample size before apply threshold:  184\n",
      "Counter({'0000-0002-0065-4069': 144, '0000-0003-3112-4252': 22, '0000-0002-6703-9642': 7, '0000-0001-9328-146X': 6, '0000-0002-0165-1556': 3, '0000-0002-9965-851X': 2})\n",
      "['0000-0002-0065-4069', '0000-0003-3112-4252']\n",
      "Total sample size after apply threshold:  166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(166, 135)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(166, 3)\n",
      "2\n",
      "(166, 138)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       144\n",
      "          1       0.00      0.00      0.00        22\n",
      "\n",
      "avg / total       0.75      0.87      0.81       166\n",
      "\n",
      "[144   0  22   0]\n",
      "MNB Accuracy:  0.8674698795180723\n",
      "MNB F1:  0.46451612903225803\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.91       144\n",
      "          1       0.17      0.05      0.07        22\n",
      "\n",
      "avg / total       0.78      0.84      0.80       166\n",
      "\n",
      "[139   5  21   1]\n",
      "svc Accuracy:  0.8433734939759037\n",
      "svc F1:  0.49295112781954886\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       144\n",
      "          1       0.00      0.00      0.00        22\n",
      "\n",
      "avg / total       0.75      0.87      0.81       166\n",
      "\n",
      "[144   0  22   0]\n",
      "LR Accuracy:  0.8674698795180723\n",
      "LR F1:  0.46451612903225803\n",
      "For name:  a_macedo\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-2613-4838': 18, '0000-0003-3436-2010': 8, '0000-0002-6854-9855': 2, '0000-0001-6985-4520': 1})\n",
      "['0000-0002-2613-4838']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  m_schultz\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0003-3458-1811': 16, '0000-0002-7689-6531': 16, '0000-0003-3455-774X': 4, '0000-0001-7967-5147': 4})\n",
      "['0000-0003-3458-1811', '0000-0002-7689-6531']\n",
      "Total sample size after apply threshold:  32\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 8)\n",
      "2\n",
      "(32, 30)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.69      0.67        16\n",
      "          1       0.67      0.62      0.65        16\n",
      "\n",
      "avg / total       0.66      0.66      0.66        32\n",
      "\n",
      "[11  5  6 10]\n",
      "MNB Accuracy:  0.65625\n",
      "MNB F1:  0.6559139784946237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.69      0.71        16\n",
      "          1       0.71      0.75      0.73        16\n",
      "\n",
      "avg / total       0.72      0.72      0.72        32\n",
      "\n",
      "[11  5  4 12]\n",
      "svc Accuracy:  0.71875\n",
      "svc F1:  0.7184750733137829\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.69      0.69        16\n",
      "          1       0.69      0.69      0.69        16\n",
      "\n",
      "avg / total       0.69      0.69      0.69        32\n",
      "\n",
      "[11  5  5 11]\n",
      "LR Accuracy:  0.6875\n",
      "LR F1:  0.6875\n",
      "For name:  s_jacobs\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0002-6199-5748': 9, '0000-0002-9959-5627': 8, '0000-0003-4674-4817': 2, '0000-0002-9382-1646': 1, '0000-0002-8103-1700': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_hong\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0002-1058-3073': 23, '0000-0001-7745-9205': 7, '0000-0002-5118-620X': 1, '0000-0002-7397-1671': 1})\n",
      "['0000-0002-1058-3073']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  r_mohan\n",
      "total sample size before apply threshold:  7\n",
      "Counter({'0000-0001-5335-6631': 4, '0000-0002-1857-4200': 1, '0000-0002-2286-7081': 1, '0000-0002-9943-484X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_hill\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0003-0394-6048': 16, '0000-0002-2801-0505': 14, '0000-0002-7601-5802': 13, '0000-0002-4623-1563': 12, '0000-0001-6080-8712': 11, '0000-0001-9577-1622': 9, '0000-0002-1923-5673': 7, '0000-0001-7996-7887': 7, '0000-0001-5533-1139': 1})\n",
      "['0000-0002-2801-0505', '0000-0003-0394-6048', '0000-0001-6080-8712', '0000-0002-7601-5802', '0000-0002-4623-1563']\n",
      "Total sample size after apply threshold:  66\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 51)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 17)\n",
      "2\n",
      "(66, 68)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.64      0.58        14\n",
      "          1       0.43      0.56      0.49        16\n",
      "          2       0.55      0.55      0.55        11\n",
      "          3       0.50      0.23      0.32        13\n",
      "          4       0.45      0.42      0.43        12\n",
      "\n",
      "avg / total       0.49      0.48      0.47        66\n",
      "\n",
      "[9 4 0 1 0 2 9 2 1 2 0 3 6 0 2 5 3 0 3 2 1 2 3 1 5]\n",
      "MNB Accuracy:  0.48484848484848486\n",
      "MNB F1:  0.4726316551222435\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.43      0.52        14\n",
      "          1       0.33      0.50      0.40        16\n",
      "          2       0.58      0.64      0.61        11\n",
      "          3       0.31      0.31      0.31        13\n",
      "          4       0.50      0.33      0.40        12\n",
      "\n",
      "avg / total       0.47      0.44      0.44        66\n",
      "\n",
      "[6 4 0 4 0 0 8 2 4 2 0 3 7 0 1 2 6 0 4 1 1 3 3 1 4]\n",
      "svc Accuracy:  0.4393939393939394\n",
      "svc F1:  0.44762541806020073\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.57      0.55        14\n",
      "          1       0.43      0.56      0.49        16\n",
      "          2       0.58      0.64      0.61        11\n",
      "          3       0.50      0.31      0.38        13\n",
      "          4       0.50      0.42      0.45        12\n",
      "\n",
      "avg / total       0.50      0.50      0.49        66\n",
      "\n",
      "[8 4 0 2 0 2 9 2 1 2 0 3 7 0 1 4 3 0 4 2 1 2 3 1 5]\n",
      "LR Accuracy:  0.5\n",
      "LR F1:  0.49648082241785385\n",
      "For name:  q_shen\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-1491-5434': 36, '0000-0001-5579-036X': 9, '0000-0003-0968-8051': 7, '0000-0002-4621-4659': 3, '0000-0002-3111-2019': 1, '0000-0001-8767-6852': 1})\n",
      "['0000-0002-1491-5434']\n",
      "Total sample size after apply threshold:  36\n",
      "For name:  l_schmidt\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0002-3206-6659': 6, '0000-0002-9518-1734': 5, '0000-0001-7565-1455': 1, '0000-0002-3472-4635': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_qin\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-3323-8846': 30, '0000-0002-8127-4753': 7, '0000-0001-9437-6292': 4, '0000-0002-3591-4959': 1})\n",
      "['0000-0002-3323-8846']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  a_fabbri\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0003-2603-9715': 53, '0000-0003-0097-6348': 5, '0000-0003-2340-9338': 4, '0000-0002-3520-2417': 2})\n",
      "['0000-0003-2603-9715']\n",
      "Total sample size after apply threshold:  53\n",
      "For name:  l_robinson\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0003-0209-2503': 61, '0000-0002-9016-648X': 13, '0000-0001-6811-0140': 8, '0000-0003-1972-4204': 6, '0000-0001-9287-6082': 3, '0000-0001-9544-5923': 1, '0000-0002-2236-0651': 1})\n",
      "['0000-0002-9016-648X', '0000-0003-0209-2503']\n",
      "Total sample size after apply threshold:  74\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(74, 47)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(74, 11)\n",
      "2\n",
      "(74, 58)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.87      1.00      0.93        61\n",
      "\n",
      "avg / total       0.89      0.88      0.85        74\n",
      "\n",
      "[ 4  9  0 61]\n",
      "MNB Accuracy:  0.8783783783783784\n",
      "MNB F1:  0.7009429726088909\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        13\n",
      "          1       0.91      1.00      0.95        61\n",
      "\n",
      "avg / total       0.93      0.92      0.91        74\n",
      "\n",
      "[ 7  6  0 61]\n",
      "svc Accuracy:  0.918918918918919\n",
      "svc F1:  0.8265625000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.87      1.00      0.93        61\n",
      "\n",
      "avg / total       0.89      0.88      0.85        74\n",
      "\n",
      "[ 4  9  0 61]\n",
      "LR Accuracy:  0.8783783783783784\n",
      "LR F1:  0.7009429726088909\n",
      "For name:  r_gross\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0001-5884-3607': 38, '0000-0003-4524-7552': 23, '0000-0003-0311-3003': 10})\n",
      "['0000-0003-4524-7552', '0000-0001-5884-3607', '0000-0003-0311-3003']\n",
      "Total sample size after apply threshold:  71\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 27)\n",
      "2\n",
      "(71, 64)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.83      0.76        23\n",
      "          1       0.79      0.89      0.84        38\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.65      0.75      0.70        71\n",
      "\n",
      "[19  3  1  4 34  0  4  6  0]\n",
      "MNB Accuracy:  0.7464788732394366\n",
      "MNB F1:  0.5331687242798354\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.78      0.84        23\n",
      "          1       0.76      0.89      0.82        38\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.70      0.73      0.71        71\n",
      "\n",
      "[18  3  2  0 34  4  2  8  0]\n",
      "svc Accuracy:  0.7323943661971831\n",
      "svc F1:  0.5521621369197721\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        23\n",
      "          1       0.69      1.00      0.82        38\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.69      0.76      0.70        71\n",
      "\n",
      "[16  7  0  0 38  0  0 10  0]\n",
      "LR Accuracy:  0.7605633802816901\n",
      "LR F1:  0.5459057071960297\n",
      "For name:  j_ahn\n",
      "total sample size before apply threshold:  130\n",
      "Counter({'0000-0002-8135-7719': 69, '0000-0002-0177-0192': 26, '0000-0001-9341-009X': 14, '0000-0002-0394-9217': 6, '0000-0001-6928-4038': 4, '0000-0001-5097-2316': 3, '0000-0002-1431-6351': 3, '0000-0002-1050-8575': 1, '0000-0003-1733-1394': 1, '0000-0003-1807-035X': 1, '0000-0003-3625-9906': 1, '0000-0002-4530-0512': 1})\n",
      "['0000-0002-0177-0192', '0000-0001-9341-009X', '0000-0002-8135-7719']\n",
      "Total sample size after apply threshold:  109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 15)\n",
      "2\n",
      "(109, 63)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.42      0.54        26\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.69      0.94      0.80        69\n",
      "\n",
      "avg / total       0.61      0.70      0.63       109\n",
      "\n",
      "[11  0 15  0  0 14  4  0 65]\n",
      "MNB Accuracy:  0.6972477064220184\n",
      "MNB F1:  0.44471045937453235\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.50      0.60        26\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       0.77      0.96      0.85        69\n",
      "\n",
      "avg / total       0.80      0.78      0.76       109\n",
      "\n",
      "[13  0 13  1  6  7  3  0 66]\n",
      "svc Accuracy:  0.7798165137614679\n",
      "svc F1:  0.6854213553388346\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.23      0.38        26\n",
      "          1       1.00      0.14      0.25        14\n",
      "          2       0.68      1.00      0.81        69\n",
      "\n",
      "avg / total       0.80      0.71      0.64       109\n",
      "\n",
      "[ 6  0 20  0  2 12  0  0 69]\n",
      "LR Accuracy:  0.7064220183486238\n",
      "LR F1:  0.478921568627451\n",
      "For name:  j_john\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0003-3654-5099': 16, '0000-0001-8452-0676': 11, '0000-0001-6831-6501': 5, '0000-0002-6411-8927': 4, '0000-0002-6636-3440': 3, '0000-0003-3343-8677': 2, '0000-0003-2696-277X': 1, '0000-0003-2551-2320': 1})\n",
      "['0000-0003-3654-5099', '0000-0001-8452-0676']\n",
      "Total sample size after apply threshold:  27\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 9)\n",
      "2\n",
      "(27, 28)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.94      0.77        16\n",
      "          1       0.75      0.27      0.40        11\n",
      "\n",
      "avg / total       0.69      0.67      0.62        27\n",
      "\n",
      "[15  1  8  3]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.5846153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.75      0.69        16\n",
      "          1       0.50      0.36      0.42        11\n",
      "\n",
      "avg / total       0.58      0.59      0.58        27\n",
      "\n",
      "[12  4  7  4]\n",
      "svc Accuracy:  0.5925925925925926\n",
      "svc F1:  0.5533834586466165\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.75      0.67        16\n",
      "          1       0.43      0.27      0.33        11\n",
      "\n",
      "avg / total       0.53      0.56      0.53        27\n",
      "\n",
      "[12  4  8  3]\n",
      "LR Accuracy:  0.5555555555555556\n",
      "LR F1:  0.4999999999999999\n",
      "For name:  d_lloyd\n",
      "total sample size before apply threshold:  157\n",
      "Counter({'0000-0002-0824-9682': 104, '0000-0003-0658-8995': 50, '0000-0003-3589-7383': 1, '0000-0003-1759-6106': 1, '0000-0003-1497-6808': 1})\n",
      "['0000-0003-0658-8995', '0000-0002-0824-9682']\n",
      "Total sample size after apply threshold:  154\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(154, 68)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(154, 19)\n",
      "2\n",
      "(154, 87)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.70      0.75        50\n",
      "          1       0.86      0.92      0.89       104\n",
      "\n",
      "avg / total       0.85      0.85      0.85       154\n",
      "\n",
      "[35 15  8 96]\n",
      "MNB Accuracy:  0.8506493506493507\n",
      "MNB F1:  0.8228557139284822\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.64      0.77        50\n",
      "          1       0.85      0.99      0.92       104\n",
      "\n",
      "avg / total       0.89      0.88      0.87       154\n",
      "\n",
      "[ 32  18   1 103]\n",
      "svc Accuracy:  0.8766233766233766\n",
      "svc F1:  0.8433199464524765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.50      0.65        50\n",
      "          1       0.80      0.98      0.88       104\n",
      "\n",
      "avg / total       0.84      0.82      0.81       154\n",
      "\n",
      "[ 25  25   2 102]\n",
      "LR Accuracy:  0.8246753246753247\n",
      "LR F1:  0.7662337662337662\n",
      "For name:  a_mohammadi\n",
      "total sample size before apply threshold:  8\n",
      "Counter({'0000-0002-8345-8206': 3, '0000-0001-7845-1707': 2, '0000-0001-7491-6423': 1, '0000-0003-4272-2733': 1, '0000-0002-8477-0939': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_dean\n",
      "total sample size before apply threshold:  189\n",
      "Counter({'0000-0002-4512-9065': 174, '0000-0002-5688-703X': 10, '0000-0002-8599-773X': 2, '0000-0002-2279-3393': 2, '0000-0003-4793-6511': 1})\n",
      "['0000-0002-5688-703X', '0000-0002-4512-9065']\n",
      "Total sample size after apply threshold:  184\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(184, 62)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(184, 32)\n",
      "2\n",
      "(184, 94)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.80      0.73        10\n",
      "          1       0.99      0.98      0.98       174\n",
      "\n",
      "avg / total       0.97      0.97      0.97       184\n",
      "\n",
      "[  8   2   4 170]\n",
      "MNB Accuracy:  0.967391304347826\n",
      "MNB F1:  0.8549658434051497\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80        10\n",
      "          1       0.99      0.99      0.99       174\n",
      "\n",
      "avg / total       0.98      0.98      0.98       184\n",
      "\n",
      "[  8   2   2 172]\n",
      "svc Accuracy:  0.9782608695652174\n",
      "svc F1:  0.8942528735632185\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.97      1.00      0.98       174\n",
      "\n",
      "avg / total       0.97      0.97      0.96       184\n",
      "\n",
      "[  4   6   0 174]\n",
      "LR Accuracy:  0.967391304347826\n",
      "LR F1:  0.7772397094430993\n",
      "For name:  s_chang\n",
      "total sample size before apply threshold:  592\n",
      "Counter({'0000-0001-6505-4139': 322, '0000-0002-5620-0867': 61, '0000-0003-3751-1720': 37, '0000-0002-6164-0875': 28, '0000-0002-7624-439X': 22, '0000-0002-2663-5042': 20, '0000-0002-5015-8178': 19, '0000-0003-1523-7986': 15, '0000-0003-4160-7549': 12, '0000-0002-2564-2945': 11, '0000-0003-1488-1649': 11, '0000-0002-0558-0038': 8, '0000-0003-0880-2385': 7, '0000-0002-2163-3910': 6, '0000-0003-1095-4505': 2, '0000-0003-2821-7095': 2, '0000-0003-2929-1510': 2, '0000-0001-9347-3592': 2, '0000-0002-2262-0396': 1, '0000-0001-6364-2404': 1, '0000-0001-7038-6170': 1, '0000-0003-0723-3192': 1, '0000-0002-1267-7591': 1})\n",
      "['0000-0002-5015-8178', '0000-0001-6505-4139', '0000-0002-2564-2945', '0000-0003-1488-1649', '0000-0003-1523-7986', '0000-0003-3751-1720', '0000-0002-6164-0875', '0000-0002-5620-0867', '0000-0002-2663-5042', '0000-0003-4160-7549', '0000-0002-7624-439X']\n",
      "Total sample size after apply threshold:  558\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(558, 209)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(558, 27)\n",
      "2\n",
      "(558, 236)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        19\n",
      "          1       0.63      1.00      0.77       322\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       1.00      0.41      0.58        37\n",
      "          6       0.00      0.00      0.00        28\n",
      "          7       0.93      0.43      0.58        61\n",
      "          8       0.00      0.00      0.00        20\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       0.00      0.00      0.00        22\n",
      "\n",
      "avg / total       0.53      0.65      0.55       558\n",
      "\n",
      "[  0  19   0   0   0   0   0   0   0   0   0   0 322   0   0   0   0   0\n",
      "   0   0   0   0   0  11   0   0   0   0   0   0   0   0   0   0  11   0\n",
      "   0   0   0   0   0   0   0   0   0  15   0   0   0   0   0   0   0   0\n",
      "   0   0  21   0   0   0  15   0   1   0   0   0   0  27   0   0   0   0\n",
      "   0   1   0   0   0   0  34   0   0   0   0   0  26   0   1   0   0  20\n",
      "   0   0   0   0   0   0   0   0   0   0  12   0   0   0   0   0   0   0\n",
      "   0   0   0  22   0   0   0   0   0   0   0   0   0]\n",
      "MNB Accuracy:  0.6505376344086021\n",
      "MNB F1:  0.17559342437037184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.21      0.33        19\n",
      "          1       0.73      0.99      0.84       322\n",
      "          2       1.00      0.64      0.78        11\n",
      "          3       0.75      0.27      0.40        11\n",
      "          4       1.00      0.67      0.80        15\n",
      "          5       0.97      0.78      0.87        37\n",
      "          6       0.75      0.21      0.33        28\n",
      "          7       0.93      0.64      0.76        61\n",
      "          8       0.50      0.10      0.17        20\n",
      "          9       0.62      0.42      0.50        12\n",
      "         10       1.00      0.32      0.48        22\n",
      "\n",
      "avg / total       0.79      0.77      0.73       558\n",
      "\n",
      "[  4  13   0   0   0   0   0   1   0   1   0   1 318   0   0   0   1   1\n",
      "   0   1   0   0   0   4   7   0   0   0   0   0   0   0   0   0   7   0\n",
      "   3   0   0   0   1   0   0   0   0   5   0   0  10   0   0   0   0   0\n",
      "   0   0   8   0   0   0  29   0   0   0   0   0   0  21   0   0   0   0\n",
      "   6   0   1   0   0   0  19   0   1   0   0   0  39   0   2   0   0  17\n",
      "   0   0   0   0   1   0   2   0   0   0   6   0   0   0   0   0   1   0\n",
      "   5   0   0  15   0   0   0   0   0   0   0   0   7]\n",
      "svc Accuracy:  0.7706093189964157\n",
      "svc F1:  0.569018821177285\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        19\n",
      "          1       0.64      1.00      0.78       322\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.20      0.33        15\n",
      "          5       0.95      0.57      0.71        37\n",
      "          6       1.00      0.04      0.07        28\n",
      "          7       0.90      0.44      0.59        61\n",
      "          8       0.00      0.00      0.00        20\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       1.00      0.09      0.17        22\n",
      "\n",
      "avg / total       0.65      0.67      0.58       558\n",
      "\n",
      "[  0  18   0   0   0   0   0   1   0   0   0   0 321   0   0   0   1   0\n",
      "   0   0   0   0   0  11   0   0   0   0   0   0   0   0   0   0  11   0\n",
      "   0   0   0   0   0   0   0   0   0  12   0   0   3   0   0   0   0   0\n",
      "   0   0  16   0   0   0  21   0   0   0   0   0   0  27   0   0   0   0\n",
      "   1   0   0   0   0   0  34   0   0   0   0   0  27   0   0   0   0  20\n",
      "   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   2   0\n",
      "   0   0   0  20   0   0   0   0   0   0   0   0   2]\n",
      "LR Accuracy:  0.6720430107526881\n",
      "LR F1:  0.2413871286579866\n",
      "For name:  m_conte\n",
      "total sample size before apply threshold:  118\n",
      "Counter({'0000-0001-9405-7339': 48, '0000-0001-8558-2051': 23, '0000-0002-3622-1476': 21, '0000-0002-1399-0344': 16, '0000-0001-7377-163X': 9, '0000-0002-1770-8561': 1})\n",
      "['0000-0001-9405-7339', '0000-0002-3622-1476', '0000-0002-1399-0344', '0000-0001-8558-2051']\n",
      "Total sample size after apply threshold:  108\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(108, 65)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(108, 14)\n",
      "2\n",
      "(108, 79)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.88      0.66        48\n",
      "          1       0.78      0.33      0.47        21\n",
      "          2       0.67      0.12      0.21        16\n",
      "          3       0.50      0.35      0.41        23\n",
      "\n",
      "avg / total       0.59      0.55      0.50       108\n",
      "\n",
      "[42  1  0  5 12  7  0  2 13  0  2  1 13  1  1  8]\n",
      "MNB Accuracy:  0.5462962962962963\n",
      "MNB F1:  0.4359248481781377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.92      0.75        48\n",
      "          1       0.85      0.52      0.65        21\n",
      "          2       1.00      0.56      0.72        16\n",
      "          3       0.69      0.48      0.56        23\n",
      "\n",
      "avg / total       0.74      0.69      0.68       108\n",
      "\n",
      "[44  1  0  3  9 11  0  1  6  0  9  1 11  1  0 11]\n",
      "svc Accuracy:  0.6944444444444444\n",
      "svc F1:  0.6692310248740957\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.90      0.68        48\n",
      "          1       0.80      0.38      0.52        21\n",
      "          2       1.00      0.25      0.40        16\n",
      "          3       0.60      0.39      0.47        23\n",
      "\n",
      "avg / total       0.67      0.59      0.56       108\n",
      "\n",
      "[43  1  0  4 12  8  0  1 11  0  4  1 13  1  0  9]\n",
      "LR Accuracy:  0.5925925925925926\n",
      "LR F1:  0.5167446492787723\n",
      "For name:  i_wilson\n",
      "total sample size before apply threshold:  220\n",
      "Counter({'0000-0002-0246-738X': 102, '0000-0001-8996-1518': 85, '0000-0001-6893-2873': 27, '0000-0002-9620-7000': 3, '0000-0003-4236-5561': 2, '0000-0001-6670-9328': 1})\n",
      "['0000-0001-8996-1518', '0000-0002-0246-738X', '0000-0001-6893-2873']\n",
      "Total sample size after apply threshold:  214\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(214, 90)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(214, 23)\n",
      "2\n",
      "(214, 113)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.76      0.76        85\n",
      "          1       0.78      0.91      0.84       102\n",
      "          2       0.75      0.22      0.34        27\n",
      "\n",
      "avg / total       0.76      0.77      0.74       214\n",
      "\n",
      "[65 18  2  9 93  0 13  8  6]\n",
      "MNB Accuracy:  0.7663551401869159\n",
      "MNB F1:  0.6467666852071776\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.93      0.83        85\n",
      "          1       0.96      0.89      0.92       102\n",
      "          2       0.86      0.44      0.59        27\n",
      "\n",
      "avg / total       0.86      0.85      0.84       214\n",
      "\n",
      "[79  4  2 11 91  0 15  0 12]\n",
      "svc Accuracy:  0.8504672897196262\n",
      "svc F1:  0.7802675563490874\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.81      0.78        85\n",
      "          1       0.81      0.90      0.85       102\n",
      "          2       0.86      0.22      0.35        27\n",
      "\n",
      "avg / total       0.79      0.78      0.76       214\n",
      "\n",
      "[69 15  1 10 92  0 14  7  6]\n",
      "LR Accuracy:  0.780373831775701\n",
      "LR F1:  0.6600246423996149\n",
      "For name:  h_yoo\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0001-6186-3262': 11, '0000-0001-9677-0947': 4, '0000-0001-9819-3135': 3, '0000-0002-8039-9482': 3, '0000-0003-3810-1811': 1})\n",
      "['0000-0001-6186-3262']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  d_das\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-3833-1169': 8, '0000-0002-7153-4726': 7, '0000-0002-1643-6621': 1, '0000-0002-2548-2734': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_carr\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-9476-2166': 26, '0000-0002-8175-5303': 4, '0000-0003-1503-015X': 3, '0000-0003-1435-307X': 1})\n",
      "['0000-0002-9476-2166']\n",
      "Total sample size after apply threshold:  26\n",
      "For name:  s_sahu\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0002-9529-3939': 7, '0000-0002-7328-6471': 6, '0000-0001-9010-4572': 2, '0000-0003-2133-4694': 1, '0000-0002-4742-9870': 1, '0000-0002-8500-9711': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_tsai\n",
      "total sample size before apply threshold:  110\n",
      "Counter({'0000-0002-2962-8913': 48, '0000-0002-2862-7572': 37, '0000-0003-4277-1885': 12, '0000-0002-8597-4132': 5, '0000-0002-6216-8672': 5, '0000-0002-9314-5940': 1, '0000-0001-9556-5642': 1, '0000-0001-8246-7779': 1})\n",
      "['0000-0003-4277-1885', '0000-0002-2962-8913', '0000-0002-2862-7572']\n",
      "Total sample size after apply threshold:  97\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(97, 43)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(97, 17)\n",
      "2\n",
      "(97, 60)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.33      0.44        12\n",
      "          1       0.80      0.75      0.77        48\n",
      "          2       0.72      0.89      0.80        37\n",
      "\n",
      "avg / total       0.75      0.75      0.74        97\n",
      "\n",
      "[ 4  5  3  2 36 10  0  4 33]\n",
      "MNB Accuracy:  0.7525773195876289\n",
      "MNB F1:  0.6712729052410359\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.58      0.67        12\n",
      "          1       0.75      0.79      0.77        48\n",
      "          2       0.76      0.76      0.76        37\n",
      "\n",
      "avg / total       0.75      0.75      0.75        97\n",
      "\n",
      "[ 7  4  1  2 38  8  0  9 28]\n",
      "svc Accuracy:  0.7525773195876289\n",
      "svc F1:  0.7303667303667303\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        12\n",
      "          1       0.75      0.90      0.82        48\n",
      "          2       0.83      0.78      0.81        37\n",
      "\n",
      "avg / total       0.81      0.79      0.79        97\n",
      "\n",
      "[ 5  6  1  0 43  5  0  8 29]\n",
      "LR Accuracy:  0.7938144329896907\n",
      "LR F1:  0.7376128229069404\n",
      "For name:  m_vitale\n",
      "total sample size before apply threshold:  217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'0000-0002-3261-6868': 98, '0000-0001-5372-7885': 63, '0000-0003-2084-2718': 35, '0000-0002-6740-2472': 12, '0000-0002-3652-7029': 7, '0000-0001-9951-4674': 2})\n",
      "['0000-0002-3261-6868', '0000-0003-2084-2718', '0000-0001-5372-7885', '0000-0002-6740-2472']\n",
      "Total sample size after apply threshold:  208\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(208, 95)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(208, 32)\n",
      "2\n",
      "(208, 127)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.73      0.75        98\n",
      "          1       0.71      0.49      0.58        35\n",
      "          2       0.56      0.79      0.66        63\n",
      "          3       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.65      0.67      0.65       208\n",
      "\n",
      "[72  5 21  0  7 17 11  0 12  1 50  0  4  1  7  0]\n",
      "MNB Accuracy:  0.6682692307692307\n",
      "MNB F1:  0.49506997823002225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.91      0.81        98\n",
      "          1       0.84      0.60      0.70        35\n",
      "          2       0.82      0.71      0.76        63\n",
      "          3       1.00      0.42      0.59        12\n",
      "\n",
      "avg / total       0.79      0.77      0.76       208\n",
      "\n",
      "[89  2  7  0 11 21  3  0 17  1 45  0  6  1  0  5]\n",
      "svc Accuracy:  0.7692307692307693\n",
      "svc F1:  0.7140942556944552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.93      0.78        98\n",
      "          1       0.86      0.34      0.49        35\n",
      "          2       0.79      0.71      0.75        63\n",
      "          3       1.00      0.08      0.15        12\n",
      "\n",
      "avg / total       0.76      0.72      0.68       208\n",
      "\n",
      "[91  0  7  0 20 12  3  0 17  1 45  0  8  1  2  1]\n",
      "LR Accuracy:  0.7163461538461539\n",
      "LR F1:  0.5428549624978196\n",
      "For name:  r_castro\n",
      "total sample size before apply threshold:  116\n",
      "Counter({'0000-0002-0959-7363': 43, '0000-0002-7417-0091': 35, '0000-0002-1329-965X': 11, '0000-0002-1263-9034': 6, '0000-0002-4381-3605': 5, '0000-0002-0701-2528': 4, '0000-0002-8054-1469': 3, '0000-0001-6873-9854': 3, '0000-0002-9337-062X': 2, '0000-0002-4698-7993': 2, '0000-0002-3769-7660': 1, '0000-0002-7289-9081': 1})\n",
      "['0000-0002-0959-7363', '0000-0002-1329-965X', '0000-0002-7417-0091']\n",
      "Total sample size after apply threshold:  89\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 51)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 15)\n",
      "2\n",
      "(89, 66)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.81      0.73        43\n",
      "          1       1.00      0.18      0.31        11\n",
      "          2       0.56      0.54      0.55        35\n",
      "\n",
      "avg / total       0.66      0.63      0.61        89\n",
      "\n",
      "[35  0  8  2  2  7 16  0 19]\n",
      "MNB Accuracy:  0.6292134831460674\n",
      "MNB F1:  0.5291945373467112\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.79      0.77        43\n",
      "          1       1.00      0.45      0.62        11\n",
      "          2       0.64      0.71      0.68        35\n",
      "\n",
      "avg / total       0.74      0.72      0.72        89\n",
      "\n",
      "[34  0  9  1  5  5 10  0 25]\n",
      "svc Accuracy:  0.7191011235955056\n",
      "svc F1:  0.6911343161343161\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.81      0.74        43\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       0.57      0.60      0.58        35\n",
      "\n",
      "avg / total       0.68      0.64      0.61        89\n",
      "\n",
      "[35  0  8  2  1  8 14  0 21]\n",
      "LR Accuracy:  0.6404494382022472\n",
      "LR F1:  0.49822695035460995\n",
      "For name:  a_hassan\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-9509-9266': 7, '0000-0002-7719-0805': 4, '0000-0001-9346-3765': 2, '0000-0001-8842-1798': 1, '0000-0002-1853-7987': 1, '0000-0002-5574-8791': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  w_martin\n",
      "total sample size before apply threshold:  259\n",
      "Counter({'0000-0003-1478-6449': 180, '0000-0002-2749-3365': 60, '0000-0002-9947-4374': 18, '0000-0002-8952-3072': 1})\n",
      "['0000-0003-1478-6449', '0000-0002-2749-3365', '0000-0002-9947-4374']\n",
      "Total sample size after apply threshold:  258\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(258, 85)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(258, 31)\n",
      "2\n",
      "(258, 116)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91       180\n",
      "          1       0.83      0.58      0.69        60\n",
      "          2       1.00      0.61      0.76        18\n",
      "\n",
      "avg / total       0.86      0.86      0.85       258\n",
      "\n",
      "[175   5   0  25  35   0   5   2  11]\n",
      "MNB Accuracy:  0.8565891472868217\n",
      "MNB F1:  0.7846620361833344\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       180\n",
      "          1       1.00      0.70      0.82        60\n",
      "          2       1.00      0.61      0.76        18\n",
      "\n",
      "avg / total       0.91      0.90      0.90       258\n",
      "\n",
      "[180   0   0  18  42   0   7   0  11]\n",
      "svc Accuracy:  0.9031007751937985\n",
      "svc F1:  0.8390716788282712\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       180\n",
      "          1       1.00      0.45      0.62        60\n",
      "          2       1.00      0.61      0.76        18\n",
      "\n",
      "avg / total       0.87      0.84      0.83       258\n",
      "\n",
      "[180   0   0  33  27   0   7   0  11]\n",
      "LR Accuracy:  0.8449612403100775\n",
      "LR F1:  0.7597701149425288\n",
      "For name:  a_krishnan\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0002-9173-7811': 41, '0000-0002-7489-9229': 3, '0000-0002-7980-4110': 1, '0000-0002-9677-9092': 1})\n",
      "['0000-0002-9173-7811']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  l_tavares\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0001-8671-6285': 18, '0000-0001-9487-7978': 7, '0000-0001-8438-7887': 7, '0000-0002-1432-524X': 7, '0000-0003-3190-0194': 2})\n",
      "['0000-0001-8671-6285']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  t_murakami\n",
      "total sample size before apply threshold:  63\n",
      "Counter({'0000-0002-0314-8807': 59, '0000-0002-2661-2633': 2, '0000-0001-7924-8073': 1, '0000-0002-0754-2879': 1})\n",
      "['0000-0002-0314-8807']\n",
      "Total sample size after apply threshold:  59\n",
      "For name:  x_xiao\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-3987-8668': 11, '0000-0002-9753-6586': 8, '0000-0003-1749-4230': 7, '0000-0002-0240-0038': 5})\n",
      "['0000-0002-3987-8668']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  j_davies\n",
      "total sample size before apply threshold:  122\n",
      "Counter({'0000-0001-6660-4032': 55, '0000-0001-5888-664X': 14, '0000-0001-7415-6129': 10, '0000-0003-4035-6047': 9, '0000-0002-4108-4357': 8, '0000-0002-1694-5370': 7, '0000-0002-7415-3638': 6, '0000-0002-9482-1066': 4, '0000-0002-9409-8605': 2, '0000-0001-9832-7412': 2, '0000-0003-4664-6862': 2, '0000-0002-8235-5782': 1, '0000-0002-5883-2526': 1, '0000-0002-4986-8594': 1})\n",
      "['0000-0001-6660-4032', '0000-0001-7415-6129', '0000-0001-5888-664X']\n",
      "Total sample size after apply threshold:  79\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 51)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 23)\n",
      "2\n",
      "(79, 74)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.91      0.78        55\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.17      0.07      0.10        14\n",
      "\n",
      "avg / total       0.51      0.65      0.56        79\n",
      "\n",
      "[50  0  5 10  0  0 13  0  1]\n",
      "MNB Accuracy:  0.6455696202531646\n",
      "MNB F1:  0.29375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.89      0.80        55\n",
      "          1       0.50      0.10      0.17        10\n",
      "          2       0.44      0.29      0.35        14\n",
      "\n",
      "avg / total       0.64      0.68      0.64        79\n",
      "\n",
      "[49  1  5  9  1  0 10  0  4]\n",
      "svc Accuracy:  0.6835443037974683\n",
      "svc F1:  0.4370802403676211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82        55\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.48      0.70      0.57        79\n",
      "\n",
      "[55  0  0 10  0  0 14  0  0]\n",
      "LR Accuracy:  0.6962025316455697\n",
      "LR F1:  0.2736318407960199\n",
      "For name:  a_schmidt\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0002-1090-8165': 51, '0000-0002-3925-9429': 14, '0000-0003-1327-0424': 12, '0000-0002-1185-3012': 9, '0000-0001-8946-1310': 1, '0000-0002-9963-7786': 1, '0000-0002-6448-6367': 1, '0000-0001-6144-9950': 1})\n",
      "['0000-0003-1327-0424', '0000-0002-1090-8165', '0000-0002-3925-9429']\n",
      "Total sample size after apply threshold:  77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 47)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 14)\n",
      "2\n",
      "(77, 61)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.33      0.44        12\n",
      "          1       0.78      0.96      0.86        51\n",
      "          2       0.88      0.50      0.64        14\n",
      "\n",
      "avg / total       0.78      0.78      0.75        77\n",
      "\n",
      "[ 4  8  0  1 49  1  1  6  7]\n",
      "MNB Accuracy:  0.7792207792207793\n",
      "MNB F1:  0.6468190678716995\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       0.81      0.92      0.86        51\n",
      "          2       0.60      0.43      0.50        14\n",
      "\n",
      "avg / total       0.80      0.81      0.80        77\n",
      "\n",
      "[ 9  3  0  0 47  4  0  8  6]\n",
      "svc Accuracy:  0.8051948051948052\n",
      "svc F1:  0.7398427260812582\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29        12\n",
      "          1       0.71      0.98      0.83        51\n",
      "          2       0.80      0.29      0.42        14\n",
      "\n",
      "avg / total       0.77      0.73      0.67        77\n",
      "\n",
      "[ 2 10  0  0 50  1  0 10  4]\n",
      "LR Accuracy:  0.7272727272727273\n",
      "LR F1:  0.5110710660949894\n",
      "For name:  j_nieto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  56\n",
      "Counter({'0000-0002-0086-252X': 32, '0000-0002-5655-3320': 13, '0000-0001-9075-7100': 4, '0000-0003-2465-3033': 4, '0000-0002-4303-1574': 3})\n",
      "['0000-0002-0086-252X', '0000-0002-5655-3320']\n",
      "Total sample size after apply threshold:  45\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 16)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 15)\n",
      "2\n",
      "(45, 31)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        32\n",
      "          1       0.85      0.85      0.85        13\n",
      "\n",
      "avg / total       0.91      0.91      0.91        45\n",
      "\n",
      "[30  2  2 11]\n",
      "MNB Accuracy:  0.9111111111111111\n",
      "MNB F1:  0.8918269230769231\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        32\n",
      "          1       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.96      0.96      0.95        45\n",
      "\n",
      "[32  0  2 11]\n",
      "svc Accuracy:  0.9555555555555556\n",
      "svc F1:  0.9431818181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.96        32\n",
      "          1       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        45\n",
      "\n",
      "[32  0  3 10]\n",
      "LR Accuracy:  0.9333333333333333\n",
      "LR F1:  0.9123945489941597\n",
      "For name:  s_hasan\n",
      "total sample size before apply threshold:  12\n",
      "Counter({'0000-0002-9089-5367': 4, '0000-0002-0158-703X': 2, '0000-0002-7269-094X': 2, '0000-0001-5589-8741': 1, '0000-0001-7789-2842': 1, '0000-0003-4271-395X': 1, '0000-0001-6832-9150': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_teixeira\n",
      "total sample size before apply threshold:  313\n",
      "Counter({'0000-0003-4124-6237': 149, '0000-0002-5676-6174': 51, '0000-0002-4896-5982': 48, '0000-0001-9355-2143': 17, '0000-0002-9466-7951': 17, '0000-0002-6944-3008': 13, '0000-0001-7456-5192': 7, '0000-0002-3338-8588': 4, '0000-0003-3989-9474': 3, '0000-0002-2228-2673': 2, '0000-0003-1205-3233': 2})\n",
      "['0000-0002-4896-5982', '0000-0002-5676-6174', '0000-0001-9355-2143', '0000-0002-6944-3008', '0000-0003-4124-6237', '0000-0002-9466-7951']\n",
      "Total sample size after apply threshold:  295\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 136)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 27)\n",
      "2\n",
      "(295, 163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.98      0.84        48\n",
      "          1       0.67      0.20      0.30        51\n",
      "          2       0.00      0.00      0.00        17\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.69      0.99      0.81       149\n",
      "          5       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.58      0.69      0.60       295\n",
      "\n",
      "[ 47   1   0   0   0   0  13  10   0   0  28   0   2   2   0   0  13   0\n",
      "   0   0   0   0  13   0   0   1   0   0 148   0   2   1   0   0  14   0]\n",
      "MNB Accuracy:  0.6949152542372882\n",
      "MNB F1:  0.32554582023760104\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.96      0.85        48\n",
      "          1       0.64      0.45      0.53        51\n",
      "          2       1.00      0.41      0.58        17\n",
      "          3       0.50      0.15      0.24        13\n",
      "          4       0.77      0.95      0.85       149\n",
      "          5       1.00      0.18      0.30        17\n",
      "\n",
      "avg / total       0.76      0.76      0.72       295\n",
      "\n",
      "[ 46   2   0   0   0   0   9  23   0   0  19   0   2   4   7   0   4   0\n",
      "   0   0   0   2  11   0   1   5   0   1 142   0   2   2   0   1   9   3]\n",
      "svc Accuracy:  0.7559322033898305\n",
      "svc F1:  0.5582523893689594\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.98      0.84        48\n",
      "          1       0.50      0.16      0.24        51\n",
      "          2       1.00      0.12      0.21        17\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.69      0.99      0.81       149\n",
      "          5       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.61      0.69      0.60       295\n",
      "\n",
      "[ 47   1   0   0   0   0  13   8   0   0  30   0   2   3   2   0  10   0\n",
      "   0   0   0   0  13   0   0   2   0   0 147   0   2   2   0   0  13   0]\n",
      "LR Accuracy:  0.6915254237288135\n",
      "LR F1:  0.35012878272617304\n",
      "For name:  j_koh\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0002-1814-5051': 40, '0000-0001-6542-0493': 9, '0000-0002-6617-1449': 7, '0000-0002-1293-1932': 5, '0000-0002-3678-4789': 1})\n",
      "['0000-0002-1814-5051']\n",
      "Total sample size after apply threshold:  40\n",
      "For name:  m_amin\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0002-7822-1124': 4, '0000-0003-0404-2040': 2, '0000-0001-5617-1579': 2, '0000-0002-9701-7102': 2, '0000-0002-3602-5555': 2, '0000-0002-5630-069X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_cho\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-8629-8500': 21, '0000-0003-0861-523X': 17, '0000-0003-0623-5647': 8, '0000-0002-8267-3801': 7, '0000-0002-1737-5701': 7, '0000-0003-1897-1166': 6, '0000-0003-2651-6403': 3, '0000-0002-9799-1538': 2, '0000-0001-7443-167X': 1, '0000-0003-1634-7482': 1})\n",
      "['0000-0002-8629-8500', '0000-0003-0861-523X']\n",
      "Total sample size after apply threshold:  38\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 11)\n",
      "2\n",
      "(38, 32)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        21\n",
      "          1       0.68      1.00      0.81        17\n",
      "\n",
      "avg / total       0.86      0.79      0.78        38\n",
      "\n",
      "[13  8  0 17]\n",
      "MNB Accuracy:  0.7894736842105263\n",
      "MNB F1:  0.7871148459383754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.90      0.88        21\n",
      "          1       0.88      0.82      0.85        17\n",
      "\n",
      "avg / total       0.87      0.87      0.87        38\n",
      "\n",
      "[19  2  3 14]\n",
      "svc Accuracy:  0.868421052631579\n",
      "svc F1:  0.8661028893587033\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90        21\n",
      "          1       0.88      0.88      0.88        17\n",
      "\n",
      "avg / total       0.89      0.89      0.89        38\n",
      "\n",
      "[19  2  2 15]\n",
      "LR Accuracy:  0.8947368421052632\n",
      "LR F1:  0.8935574229691876\n",
      "For name:  s_lam\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0003-3294-6637': 69, '0000-0001-7468-1142': 6, '0000-0002-5318-1760': 5, '0000-0002-2982-9192': 3, '0000-0002-1888-1067': 3, '0000-0001-7943-5004': 3, '0000-0002-1471-5176': 1})\n",
      "['0000-0003-3294-6637']\n",
      "Total sample size after apply threshold:  69\n",
      "For name:  t_tran\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-4686-8601': 38, '0000-0002-5132-6495': 8, '0000-0001-6531-8907': 3, '0000-0002-9557-3340': 2, '0000-0002-3355-7951': 1, '0000-0002-0853-2226': 1, '0000-0002-7489-3126': 1})\n",
      "['0000-0002-4686-8601']\n",
      "Total sample size after apply threshold:  38\n",
      "For name:  c_su\n",
      "total sample size before apply threshold:  297\n",
      "Counter({'0000-0003-3604-7858': 140, '0000-0001-8392-7108': 89, '0000-0002-5211-3520': 27, '0000-0001-9295-7587': 12, '0000-0002-9483-4510': 12, '0000-0001-5428-0878': 6, '0000-0003-2504-0466': 5, '0000-0002-7624-1607': 4, '0000-0002-1035-4238': 1, '0000-0003-4580-9607': 1})\n",
      "['0000-0003-3604-7858', '0000-0002-5211-3520', '0000-0001-8392-7108', '0000-0001-9295-7587', '0000-0002-9483-4510']\n",
      "Total sample size after apply threshold:  280\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(280, 84)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(280, 23)\n",
      "2\n",
      "(280, 107)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.99      0.86       140\n",
      "          1       0.86      0.44      0.59        27\n",
      "          2       0.94      0.87      0.90        89\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.76      0.81      0.77       280\n",
      "\n",
      "[139   0   0   1   0  10  12   5   0   0  10   2  77   0   0  12   0   0\n",
      "   0   0  12   0   0   0   0]\n",
      "MNB Accuracy:  0.8142857142857143\n",
      "MNB F1:  0.46932635270625145\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.98      0.87       140\n",
      "          1       0.94      0.56      0.70        27\n",
      "          2       1.00      0.87      0.93        89\n",
      "          3       0.62      0.42      0.50        12\n",
      "          4       1.00      0.25      0.40        12\n",
      "\n",
      "avg / total       0.87      0.85      0.83       280\n",
      "\n",
      "[137   0   0   3   0  12  15   0   0   0  11   1  77   0   0   7   0   0\n",
      "   5   0   9   0   0   0   3]\n",
      "svc Accuracy:  0.8464285714285714\n",
      "svc F1:  0.6784947739146163\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.99      0.82       140\n",
      "          1       1.00      0.37      0.54        27\n",
      "          2       0.94      0.74      0.83        89\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.74      0.76      0.72       280\n",
      "\n",
      "[138   0   0   2   0  13  10   4   0   0  23   0  66   0   0  12   0   0\n",
      "   0   0  12   0   0   0   0]\n",
      "LR Accuracy:  0.7642857142857142\n",
      "LR F1:  0.4374594534246203\n",
      "For name:  s_george\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0002-8807-0737': 31, '0000-0002-0859-0215': 29, '0000-0002-0444-5870': 11, '0000-0001-6534-3846': 6, '0000-0001-9843-4816': 1})\n",
      "['0000-0002-0859-0215', '0000-0002-8807-0737', '0000-0002-0444-5870']\n",
      "Total sample size after apply threshold:  71\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 36)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 9)\n",
      "2\n",
      "(71, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.83      0.76        29\n",
      "          1       0.69      0.77      0.73        31\n",
      "          2       0.50      0.09      0.15        11\n",
      "\n",
      "avg / total       0.67      0.69      0.65        71\n",
      "\n",
      "[24  5  0  6 24  1  4  6  1]\n",
      "MNB Accuracy:  0.6901408450704225\n",
      "MNB F1:  0.5476745476745476\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.72      0.74        29\n",
      "          1       0.63      0.77      0.70        31\n",
      "          2       0.80      0.36      0.50        11\n",
      "\n",
      "avg / total       0.71      0.69      0.68        71\n",
      "\n",
      "[21  8  0  6 24  1  1  6  4]\n",
      "svc Accuracy:  0.6901408450704225\n",
      "svc F1:  0.6441647597254004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.83      0.77        29\n",
      "          1       0.65      0.77      0.71        31\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.58      0.68      0.62        71\n",
      "\n",
      "[24  5  0  6 24  1  3  8  0]\n",
      "LR Accuracy:  0.676056338028169\n",
      "LR F1:  0.49335863377609107\n",
      "For name:  j_hong\n",
      "total sample size before apply threshold:  143\n",
      "Counter({'0000-0002-2476-3737': 29, '0000-0002-4592-7083': 26, '0000-0002-2891-5785': 20, '0000-0001-9467-6463': 16, '0000-0001-9912-633X': 12, '0000-0003-2212-2861': 12, '0000-0002-9915-8072': 8, '0000-0003-0617-9307': 6, '0000-0001-7979-5966': 5, '0000-0002-0109-5975': 5, '0000-0001-5172-6889': 4})\n",
      "['0000-0001-9912-633X', '0000-0002-2891-5785', '0000-0003-2212-2861', '0000-0002-2476-3737', '0000-0001-9467-6463', '0000-0002-4592-7083']\n",
      "Total sample size after apply threshold:  115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(115, 76)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(115, 14)\n",
      "2\n",
      "(115, 90)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.36      0.40      0.38        20\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       0.48      0.83      0.61        29\n",
      "          4       0.30      0.19      0.23        16\n",
      "          5       0.43      0.46      0.44        26\n",
      "\n",
      "avg / total       0.32      0.41      0.35       115\n",
      "\n",
      "[ 0  7  0  5  0  0  3  8  0  1  3  5  0  2  0  4  0  6  1  0  0 24  2  2\n",
      "  1  3  0  6  3  3  0  2  0 10  2 12]\n",
      "MNB Accuracy:  0.40869565217391307\n",
      "MNB F1:  0.27729349881248616\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.42      0.43        12\n",
      "          1       0.41      0.60      0.49        20\n",
      "          2       0.40      0.17      0.24        12\n",
      "          3       0.55      0.79      0.65        29\n",
      "          4       0.67      0.38      0.48        16\n",
      "          5       0.84      0.62      0.71        26\n",
      "\n",
      "avg / total       0.58      0.56      0.55       115\n",
      "\n",
      "[ 5  5  0  1  1  0  3 12  2  1  0  2  1  5  2  4  0  0  1  2  0 23  2  1\n",
      "  1  2  1  6  6  0  0  3  0  7  0 16]\n",
      "svc Accuracy:  0.5565217391304348\n",
      "svc F1:  0.4998118466274719\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.08      0.11        12\n",
      "          1       0.33      0.45      0.38        20\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       0.50      0.76      0.60        29\n",
      "          4       0.40      0.25      0.31        16\n",
      "          5       0.56      0.58      0.57        26\n",
      "\n",
      "avg / total       0.38      0.44      0.40       115\n",
      "\n",
      "[ 1  6  0  5  0  0  3  9  0  1  3  4  1  4  0  4  0  3  1  2  0 22  2  2\n",
      "  1  3  0  5  4  3  0  3  0  7  1 15]\n",
      "LR Accuracy:  0.4434782608695652\n",
      "LR F1:  0.3274519418112923\n",
      "For name:  p_baptista\n",
      "total sample size before apply threshold:  114\n",
      "Counter({'0000-0001-5255-7095': 73, '0000-0001-6331-3731': 30, '0000-0003-1559-9151': 4, '0000-0003-1433-6456': 4, '0000-0001-7651-4700': 3})\n",
      "['0000-0001-5255-7095', '0000-0001-6331-3731']\n",
      "Total sample size after apply threshold:  103\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 58)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 13)\n",
      "2\n",
      "(103, 71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.89        73\n",
      "          1       0.77      0.67      0.71        30\n",
      "\n",
      "avg / total       0.84      0.84      0.84       103\n",
      "\n",
      "[67  6 10 20]\n",
      "MNB Accuracy:  0.8446601941747572\n",
      "MNB F1:  0.8038095238095238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94        73\n",
      "          1       0.96      0.73      0.83        30\n",
      "\n",
      "avg / total       0.92      0.91      0.91       103\n",
      "\n",
      "[72  1  8 22]\n",
      "svc Accuracy:  0.912621359223301\n",
      "svc F1:  0.8856825749167592\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        73\n",
      "          1       1.00      0.63      0.78        30\n",
      "\n",
      "avg / total       0.91      0.89      0.88       103\n",
      "\n",
      "[73  0 11 19]\n",
      "LR Accuracy:  0.8932038834951457\n",
      "LR F1:  0.8527232549070584\n",
      "For name:  p_thompson\n",
      "total sample size before apply threshold:  148\n",
      "Counter({'0000-0002-5910-7625': 69, '0000-0002-2268-9748': 48, '0000-0001-6195-3284': 10, '0000-0001-7562-6049': 8, '0000-0002-4688-3414': 6, '0000-0002-6851-8899': 3, '0000-0002-5278-9045': 2, '0000-0002-9161-167X': 1, '0000-0002-3141-3567': 1})\n",
      "['0000-0001-6195-3284', '0000-0002-2268-9748', '0000-0002-5910-7625']\n",
      "Total sample size after apply threshold:  127\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 75)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 18)\n",
      "2\n",
      "(127, 93)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.20      0.31        10\n",
      "          1       0.67      0.75      0.71        48\n",
      "          2       0.80      0.81      0.81        69\n",
      "\n",
      "avg / total       0.74      0.74      0.73       127\n",
      "\n",
      "[ 2  6  2  0 36 12  1 12 56]\n",
      "MNB Accuracy:  0.7401574803149606\n",
      "MNB F1:  0.6064433521056457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.30      0.40        10\n",
      "          1       1.00      0.62      0.77        48\n",
      "          2       0.74      0.99      0.84        69\n",
      "\n",
      "avg / total       0.83      0.80      0.78       127\n",
      "\n",
      "[ 3  0  7  1 30 17  1  0 68]\n",
      "svc Accuracy:  0.7952755905511811\n",
      "svc F1:  0.6713170887083931\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       0.72      0.54      0.62        48\n",
      "          2       0.67      0.87      0.76        69\n",
      "\n",
      "avg / total       0.72      0.69      0.67       127\n",
      "\n",
      "[ 2  1  7  0 26 22  0  9 60]\n",
      "LR Accuracy:  0.6929133858267716\n",
      "LR F1:  0.5706248744223428\n",
      "For name:  a_castro\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0001-7526-6717': 39, '0000-0002-8311-0840': 17, '0000-0003-0428-9174': 15, '0000-0002-9253-7926': 14, '0000-0001-6964-6879': 13, '0000-0003-4035-3444': 11, '0000-0003-0524-156X': 7, '0000-0003-3052-6225': 4, '0000-0003-0328-1381': 3, '0000-0002-8025-4945': 2, '0000-0003-3327-967X': 1})\n",
      "['0000-0002-8311-0840', '0000-0001-6964-6879', '0000-0002-9253-7926', '0000-0003-4035-3444', '0000-0003-0428-9174', '0000-0001-7526-6717']\n",
      "Total sample size after apply threshold:  109\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 25)\n",
      "2\n",
      "(109, 81)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.41      0.44        17\n",
      "          1       0.83      0.77      0.80        13\n",
      "          2       0.56      0.64      0.60        14\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.60      0.40      0.48        15\n",
      "          5       0.64      0.90      0.74        39\n",
      "\n",
      "avg / total       0.55      0.61      0.57       109\n",
      "\n",
      "[ 7  2  1  1  1  5  0 10  3  0  0  0  1  0  9  0  2  2  3  0  1  0  0  7\n",
      "  2  0  1  0  6  6  2  0  1  0  1 35]\n",
      "MNB Accuracy:  0.6146788990825688\n",
      "MNB F1:  0.510363475177305\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.65      0.61        17\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       0.73      0.79      0.76        14\n",
      "          3       0.50      0.18      0.27        11\n",
      "          4       0.75      0.40      0.52        15\n",
      "          5       0.69      0.90      0.78        39\n",
      "\n",
      "avg / total       0.70      0.71      0.68       109\n",
      "\n",
      "[11  0  1  1  1  3  0 12  1  0  0  0  1  0 11  0  0  2  3  0  1  2  0  5\n",
      "  2  0  0  1  6  6  2  0  1  0  1 35]\n",
      "svc Accuracy:  0.7064220183486238\n",
      "svc F1:  0.6493192292742518\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.53      0.53        17\n",
      "          1       1.00      0.77      0.87        13\n",
      "          2       0.79      0.79      0.79        14\n",
      "          3       0.50      0.09      0.15        11\n",
      "          4       0.62      0.33      0.43        15\n",
      "          5       0.60      0.90      0.72        39\n",
      "\n",
      "avg / total       0.66      0.65      0.62       109\n",
      "\n",
      "[ 9  0  0  1  1  6  0 10  1  0  0  2  1  0 11  0  1  1  3  0  0  1  0  7\n",
      "  2  0  1  0  5  7  2  0  1  0  1 35]\n",
      "LR Accuracy:  0.6513761467889908\n",
      "LR F1:  0.5824949191482268\n",
      "For name:  j_zhang\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  965\n",
      "Counter({'0000-0002-4319-4285': 188, '0000-0002-6601-9180': 58, '0000-0003-2493-5209': 58, '0000-0003-3373-9621': 57, '0000-0002-0889-7057': 40, '0000-0001-8041-1608': 28, '0000-0002-9831-6796': 24, '0000-0002-1905-8750': 24, '0000-0002-9231-0844': 21, '0000-0002-7737-0785': 20, '0000-0002-5822-2226': 20, '0000-0002-5108-2072': 19, '0000-0002-1138-2556': 19, '0000-0002-8798-7316': 18, '0000-0002-2195-2997': 18, '0000-0003-3460-0867': 16, '0000-0003-4649-6526': 16, '0000-0001-5903-6487': 15, '0000-0002-1041-793X': 14, '0000-0001-8683-509X': 14, '0000-0002-7068-5135': 14, '0000-0002-9405-9024': 12, '0000-0001-9803-7140': 11, '0000-0002-8344-5907': 10, '0000-0003-1338-8887': 9, '0000-0003-0391-7298': 9, '0000-0002-1221-3033': 9, '0000-0003-3812-3850': 9, '0000-0002-6457-0235': 8, '0000-0003-1572-8339': 8, '0000-0001-8828-114X': 8, '0000-0001-5289-6062': 8, '0000-0001-8970-4466': 7, '0000-0003-1113-6264': 7, '0000-0003-3526-4586': 7, '0000-0002-1559-1240': 6, '0000-0003-3099-6665': 6, '0000-0002-2540-2749': 6, '0000-0002-0912-1197': 5, '0000-0002-0906-0099': 5, '0000-0003-0589-6267': 5, '0000-0001-9732-798X': 5, '0000-0002-3163-6808': 5, '0000-0002-9976-1605': 5, '0000-0002-4758-0394': 5, '0000-0002-1225-6703': 4, '0000-0001-9697-6689': 4, '0000-0001-7869-8005': 4, '0000-0002-7959-2701': 4, '0000-0003-2725-1259': 4, '0000-0001-7533-998X': 4, '0000-0002-0841-1096': 3, '0000-0002-3267-542X': 3, '0000-0001-9275-5790': 3, '0000-0002-6078-4404': 3, '0000-0002-0437-9834': 3, '0000-0002-6196-8694': 3, '0000-0003-2799-9347': 2, '0000-0002-2282-8146': 2, '0000-0001-9143-2869': 2, '0000-0002-1624-9535': 2, '0000-0002-1161-5460': 2, '0000-0003-3195-9882': 2, '0000-0002-3731-4594': 2, '0000-0001-7238-4021': 2, '0000-0002-7937-1474': 2, '0000-0001-6516-0302': 2, '0000-0002-2261-7605': 2, '0000-0001-8385-2003': 2, '0000-0002-9478-8243': 2, '0000-0001-9777-7956': 2, '0000-0002-5785-2090': 2, '0000-0003-1386-6447': 2, '0000-0002-3063-2039': 2, '0000-0002-7841-3767': 1, '0000-0002-2257-1803': 1, '0000-0002-3412-7769': 1, '0000-0002-6358-0255': 1, '0000-0001-9408-138X': 1, '0000-0002-1994-8374': 1, '0000-0002-3574-8401': 1, '0000-0001-7612-8498': 1, '0000-0002-2114-173X': 1, '0000-0001-7228-6202': 1, '0000-0002-0946-5520': 1, '0000-0002-1397-5224': 1, '0000-0002-2222-3024': 1})\n",
      "['0000-0002-9831-6796', '0000-0002-9405-9024', '0000-0001-5903-6487', '0000-0001-8041-1608', '0000-0002-8798-7316', '0000-0003-3460-0867', '0000-0002-7737-0785', '0000-0002-8344-5907', '0000-0002-9231-0844', '0000-0002-4319-4285', '0000-0002-2195-2997', '0000-0002-1905-8750', '0000-0002-6601-9180', '0000-0003-4649-6526', '0000-0002-5108-2072', '0000-0002-1041-793X', '0000-0002-5822-2226', '0000-0002-1138-2556', '0000-0001-8683-509X', '0000-0002-7068-5135', '0000-0003-3373-9621', '0000-0003-2493-5209', '0000-0002-0889-7057', '0000-0001-9803-7140']\n",
      "Total sample size after apply threshold:  734\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(734, 246)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(734, 21)\n",
      "2\n",
      "(734, 267)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.50      0.62        24\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        15\n",
      "          3       0.96      0.79      0.86        28\n",
      "          4       0.00      0.00      0.00        18\n",
      "          5       0.00      0.00      0.00        16\n",
      "          6       0.86      0.30      0.44        20\n",
      "          7       0.00      0.00      0.00        10\n",
      "          8       0.00      0.00      0.00        21\n",
      "          9       0.37      0.98      0.54       188\n",
      "         10       0.67      0.11      0.19        18\n",
      "         11       0.00      0.00      0.00        24\n",
      "         12       0.62      0.31      0.41        58\n",
      "         13       1.00      0.25      0.40        16\n",
      "         14       0.00      0.00      0.00        19\n",
      "         15       0.00      0.00      0.00        14\n",
      "         16       0.00      0.00      0.00        20\n",
      "         17       1.00      0.16      0.27        19\n",
      "         18       0.00      0.00      0.00        14\n",
      "         19       0.00      0.00      0.00        14\n",
      "         20       0.59      0.93      0.72        57\n",
      "         21       0.55      0.48      0.51        58\n",
      "         22       0.50      0.12      0.20        40\n",
      "         23       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.41      0.46      0.36       734\n",
      "\n",
      "[ 12   0   0   1   0   0   0   0   0  10   0   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   0   0   0   0   0   0   0   1   0   0  11   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  15   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  22   0   0   0   0   0   6   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15   1   0\n",
      "   1   0   0   0   1   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "   0   0   0  12   0   0   1   0   0   0   0   0   0   0   1   0   1   0\n",
      "   0   0   0   0   0   0   6   0   0  12   0   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8   0   0\n",
      "   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 184   0   0   1   0   0   0   0   0\n",
      "   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0  15   2   0\n",
      "   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  23   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  37   0   0  18   0   0   0   0   0\n",
      "   0   0   1   2   0   0   1   0   0   0   0   0   0   0   0   2   0   0\n",
      "   0   4   0   0   0   0   0   0   6   3   0   0   0   0   0   0   0   0\n",
      "   0   0   0  18   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   7   0   0   0   0   0   0   0   0\n",
      "   0   0   2   5   0   0   0   0   0   0   1   0   0   0   0  17   0   0\n",
      "   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   1   0\n",
      "   0   0   0  12   0   0   0   0   0   0   0   3   0   0   1   2   0   0\n",
      "   0   0   0   0   0   0   0   0   0  12   0   0   1   0   0   0   0   0\n",
      "   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   4   0   0\n",
      "   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   4   0   0   0   0   0   0   0   0   0   0  53   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  16   0   0   0   0   0   0   0   0\n",
      "   0   0  10  28   4   0   1   0   0   0   0   0   0   0   0  24   0   0\n",
      "   1   0   0   0   0   0   0   0   3   6   5   0   0   0   0   0   0   0\n",
      "   0   0   0  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "MNB Accuracy:  0.4591280653950954\n",
      "MNB F1:  0.21551801348710442\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.79      0.78        24\n",
      "          1       0.70      0.58      0.64        12\n",
      "          2       0.25      0.13      0.17        15\n",
      "          3       0.93      0.96      0.95        28\n",
      "          4       0.33      0.17      0.22        18\n",
      "          5       0.38      0.19      0.25        16\n",
      "          6       0.69      0.45      0.55        20\n",
      "          7       0.60      0.30      0.40        10\n",
      "          8       0.86      0.57      0.69        21\n",
      "          9       0.57      0.97      0.72       188\n",
      "         10       0.50      0.28      0.36        18\n",
      "         11       0.67      0.33      0.44        24\n",
      "         12       0.57      0.47      0.51        58\n",
      "         13       0.57      0.25      0.35        16\n",
      "         14       1.00      0.37      0.54        19\n",
      "         15       0.00      0.00      0.00        14\n",
      "         16       0.43      0.30      0.35        20\n",
      "         17       0.71      0.53      0.61        19\n",
      "         18       0.75      0.43      0.55        14\n",
      "         19       0.00      0.00      0.00        14\n",
      "         20       0.62      0.88      0.73        57\n",
      "         21       0.62      0.57      0.59        58\n",
      "         22       0.48      0.30      0.37        40\n",
      "         23       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.59      0.60      0.57       734\n",
      "\n",
      "[ 19   0   0   1   0   0   0   0   0   3   0   0   0   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0   7   0   0   0   0   1   1   0   3   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0\n",
      "   0   0   0   8   0   0   3   0   0   0   0   0   0   0   0   0   1   0\n",
      "   0   0   0  27   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   1   0   3   0   0   0   0   6   1   0\n",
      "   1   0   0   0   4   1   0   0   0   0   1   0   1   0   0   0   0   3\n",
      "   0   0   0   6   0   1   1   0   0   1   0   0   0   0   0   0   3   0\n",
      "   0   1   0   0   0   0   9   0   0   8   0   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0   0   0   0   0   3   0   3   0   0\n",
      "   2   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  12   8   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   1 182   0   1   3   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   2   0   1   0   0   0   1   5   5   0\n",
      "   1   0   0   0   2   0   0   0   0   0   1   0   0   0   0   1   0   0\n",
      "   0   0   0  14   0   8   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   1   1   0   0  25   0   0  27   0   0   0   1   0\n",
      "   1   0   0   0   1   0   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   4   0   0   0   0   0   0   6   3   1   0   0   1   1   0   0   0\n",
      "   0   0   0   9   0   0   1   0   7   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   1   0   0   2   0   0   0   0   0   0   0   1\n",
      "   0   0   2   8   0   0   0   0   0   0   3   0   0   0   0   6   2   1\n",
      "   2   0   0   0   6   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "   0   1   0   3   0   0   0   0   0   0   0  10   1   0   1   2   0   0\n",
      "   0   0   0   0   0   0   0   0   0   5   0   0   2   0   0   0   0   1\n",
      "   6   0   0   0   0   0   2   0   0   0   0   0   0   0   0   2   0   0\n",
      "   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   2   0   0   0   0   0   0   0   0   0   4  50   1   0   0\n",
      "   0   0   0   0   0   2   1   0   0   5   0   0   0   1   0   2   0   0\n",
      "   0   1   8  33   5   0   1   0   1   0   0   1   0   0   0   9   1   0\n",
      "   2   1   0   0   0   0   0   3   3   6  12   0   0   0   0   0   0   0\n",
      "   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   6]\n",
      "svc Accuracy:  0.6008174386920981\n",
      "svc F1:  0.47753111540244\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.75      0.77        24\n",
      "          1       0.33      0.08      0.13        12\n",
      "          2       0.00      0.00      0.00        15\n",
      "          3       0.93      0.93      0.93        28\n",
      "          4       0.00      0.00      0.00        18\n",
      "          5       0.00      0.00      0.00        16\n",
      "          6       0.39      0.55      0.46        20\n",
      "          7       0.00      0.00      0.00        10\n",
      "          8       0.75      0.14      0.24        21\n",
      "          9       0.46      0.98      0.63       188\n",
      "         10       0.50      0.17      0.25        18\n",
      "         11       0.60      0.12      0.21        24\n",
      "         12       0.54      0.38      0.44        58\n",
      "         13       0.50      0.31      0.38        16\n",
      "         14       1.00      0.05      0.10        19\n",
      "         15       0.00      0.00      0.00        14\n",
      "         16       0.29      0.10      0.15        20\n",
      "         17       0.82      0.47      0.60        19\n",
      "         18       0.00      0.00      0.00        14\n",
      "         19       0.00      0.00      0.00        14\n",
      "         20       0.58      0.84      0.69        57\n",
      "         21       0.59      0.45      0.51        58\n",
      "         22       0.54      0.35      0.42        40\n",
      "         23       1.00      0.36      0.53        11\n",
      "\n",
      "avg / total       0.49      0.52      0.45       734\n",
      "\n",
      "[ 18   0   0   1   0   0   0   0   0   3   0   0   0   1   0   0   1   0\n",
      "   0   0   0   0   0   0   0   1   0   0   0   0   3   0   0   7   0   1\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   1   0   0  11   1   0   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  26   0   0   1   0   0   0   0   1   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13   0   0\n",
      "   1   0   0   0   2   0   0   0   0   0   1   0   1   0   0   0   0   0\n",
      "   1   0   0   9   0   0   1   0   0   0   0   0   0   0   1   0   3   0\n",
      "   0   1   0   0   0   0  11   0   0   6   0   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   7   0   0\n",
      "   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   3  17   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   1 185   1   0   1   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13   3   0\n",
      "   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "   0   0   0  19   0   3   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   0   1   0   0  33   0   0  22   0   0   0   1   0\n",
      "   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   1   0   0\n",
      "   0   5   0   0   0   0   0   0   6   2   0   0   0   0   0   0   0   0\n",
      "   1   0   0  15   0   0   2   0   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   1   0   0   4   0   0   0   0   0   0   0   1\n",
      "   0   0   2   6   0   0   0   0   0   0   3   0   0   0   0  13   1   0\n",
      "   1   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "   0   0   0   6   0   0   0   0   0   0   0   9   0   0   1   2   0   0\n",
      "   0   0   0   0   0   0   3   0   0   9   0   0   1   0   0   0   0   1\n",
      "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   2   0   0\n",
      "   1   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   3   0   0   0   1   0   0   0   0   0   3  48   2   0   0\n",
      "   0   0   0   0   0   0   3   0   0   6   0   0   1   1   0   1   0   0\n",
      "   0   0  12  26   8   0   1   0   0   0   0   0   0   0   0  13   0   0\n",
      "   1   2   0   0   0   0   0   0   3   6  14   0   0   0   0   0   0   0\n",
      "   1   0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   4]\n",
      "LR Accuracy:  0.5190735694822888\n",
      "LR F1:  0.3100657248944697\n",
      "For name:  j_rodrigues\n",
      "total sample size before apply threshold:  264\n",
      "Counter({'0000-0002-9347-5026': 39, '0000-0002-1418-7860': 34, '0000-0002-3950-528X': 24, '0000-0001-6143-2139': 23, '0000-0001-8657-3800': 20, '0000-0002-5605-656X': 19, '0000-0003-1889-4914': 16, '0000-0001-9796-3193': 13, '0000-0002-9756-1124': 12, '0000-0001-7006-3048': 12, '0000-0001-9187-8094': 9, '0000-0002-4279-6188': 7, '0000-0002-8621-5410': 6, '0000-0003-0424-3248': 5, '0000-0002-3562-6025': 5, '0000-0002-3217-2320': 4, '0000-0003-4552-1953': 3, '0000-0002-3387-2652': 3, '0000-0002-4031-8000': 3, '0000-0002-8315-8553': 2, '0000-0003-2187-9408': 2, '0000-0002-2793-8192': 1, '0000-0002-4790-7959': 1, '0000-0002-6446-6462': 1})\n",
      "['0000-0002-9756-1124', '0000-0001-6143-2139', '0000-0002-5605-656X', '0000-0003-1889-4914', '0000-0001-8657-3800', '0000-0002-3950-528X', '0000-0002-1418-7860', '0000-0002-9347-5026', '0000-0001-7006-3048', '0000-0001-9796-3193']\n",
      "Total sample size after apply threshold:  212\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(212, 123)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(212, 17)\n",
      "2\n",
      "(212, 140)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.80      0.17      0.29        23\n",
      "          2       0.00      0.00      0.00        19\n",
      "          3       0.60      0.38      0.46        16\n",
      "          4       0.83      0.50      0.62        20\n",
      "          5       0.85      0.46      0.59        24\n",
      "          6       0.38      0.88      0.54        34\n",
      "          7       0.33      0.79      0.47        39\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.43      0.43      0.36       212\n",
      "\n",
      "[ 0  0  0  1  0  0  8  3  0  0  0  4  0  0  1  0  4 14  0  0  0  0  0  1\n",
      "  0  0  9  9  0  0  0  0  0  6  0  0  7  3  0  0  0  0  0  0 10  0  2  8\n",
      "  0  0  0  0  0  1  0 11  4  8  0  0  0  0  0  1  0  0 30  3  0  0  0  0\n",
      "  0  0  1  1  6 31  0  0  0  1  0  0  0  0  7  4  0  0  0  0  0  0  0  1\n",
      "  1 11  0  0]\n",
      "MNB Accuracy:  0.4339622641509434\n",
      "MNB F1:  0.2968727041095462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.25      0.38        12\n",
      "          1       0.50      0.43      0.47        23\n",
      "          2       0.58      0.37      0.45        19\n",
      "          3       0.56      0.62      0.59        16\n",
      "          4       1.00      0.80      0.89        20\n",
      "          5       0.71      0.50      0.59        24\n",
      "          6       0.46      0.79      0.58        34\n",
      "          7       0.52      0.74      0.61        39\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.83      0.38      0.53        13\n",
      "\n",
      "avg / total       0.58      0.56      0.54       212\n",
      "\n",
      "[ 3  0  3  2  0  0  4  0  0  0  0 10  0  0  0  3  2  7  0  1  1  2  7  1\n",
      "  0  0  3  4  1  0  0  0  0 10  0  0  5  1  0  0  0  1  0  0 16  0  0  3\n",
      "  0  0  0  2  0  1  0 12  5  4  0  0  0  1  0  2  0  1 27  2  1  0  0  2\n",
      "  0  0  0  1  6 29  1  0  0  0  1  2  0  0  6  3  0  0  0  2  1  0  0  0\n",
      "  1  3  1  5]\n",
      "svc Accuracy:  0.5613207547169812\n",
      "svc F1:  0.5071706485514127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.42      0.22      0.29        23\n",
      "          2       0.43      0.16      0.23        19\n",
      "          3       0.53      0.50      0.52        16\n",
      "          4       1.00      0.80      0.89        20\n",
      "          5       0.61      0.71      0.65        24\n",
      "          6       0.44      0.88      0.59        34\n",
      "          7       0.51      0.77      0.61        39\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       1.00      0.38      0.56        13\n",
      "\n",
      "avg / total       0.51      0.54      0.49       212\n",
      "\n",
      "[ 0  0  1  2  0  0  7  2  0  0  0  5  0  0  0  5  4  9  0  0  1  2  3  1\n",
      "  0  1  6  4  1  0  0  0  0  8  0  0  6  2  0  0  0  0  0  0 16  2  0  2\n",
      "  0  0  0  1  0  1  0 17  2  3  0  0  0  1  0  2  0  1 30  0  0  0  0  1\n",
      "  0  0  0  2  6 30  0  0  0  1  2  1  0  0  6  2  0  0  0  1  1  0  0  0\n",
      "  1  5  0  5]\n",
      "LR Accuracy:  0.5377358490566038\n",
      "LR F1:  0.433138333910901\n",
      "For name:  s_watson\n",
      "total sample size before apply threshold:  117\n",
      "Counter({'0000-0001-6699-1765': 45, '0000-0002-2558-3367': 38, '0000-0002-9818-7429': 12, '0000-0002-9643-5580': 8, '0000-0002-9042-2391': 6, '0000-0001-6063-7327': 4, '0000-0002-8112-9687': 4})\n",
      "['0000-0002-2558-3367', '0000-0002-9818-7429', '0000-0001-6699-1765']\n",
      "Total sample size after apply threshold:  95\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 49)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 17)\n",
      "2\n",
      "(95, 66)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.74      0.79        38\n",
      "          1       0.70      0.58      0.64        12\n",
      "          2       0.73      0.84      0.78        45\n",
      "\n",
      "avg / total       0.77      0.77      0.77        95\n",
      "\n",
      "[28  1  9  0  7  5  5  2 38]\n",
      "MNB Accuracy:  0.7684210526315789\n",
      "MNB F1:  0.736200395123003\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.74      0.79        38\n",
      "          1       0.80      0.67      0.73        12\n",
      "          2       0.77      0.89      0.82        45\n",
      "\n",
      "avg / total       0.80      0.80      0.80        95\n",
      "\n",
      "[28  1  9  1  8  3  4  1 40]\n",
      "svc Accuracy:  0.8\n",
      "svc F1:  0.7802491298933872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.66      0.75        38\n",
      "          1       0.75      0.50      0.60        12\n",
      "          2       0.69      0.89      0.78        45\n",
      "\n",
      "avg / total       0.77      0.75      0.74        95\n",
      "\n",
      "[25  1 12  0  6  6  4  1 40]\n",
      "LR Accuracy:  0.7473684210526316\n",
      "LR F1:  0.7076558952808772\n",
      "For name:  c_barros\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0003-4666-5000': 16, '0000-0003-3244-7467': 13, '0000-0003-2330-398X': 2, '0000-0002-5863-2874': 2, '0000-0003-2236-4553': 1})\n",
      "['0000-0003-3244-7467', '0000-0003-4666-5000']\n",
      "Total sample size after apply threshold:  29\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 26)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 17)\n",
      "2\n",
      "(29, 43)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.36      0.38      0.37        13\n",
      "          1       0.47      0.44      0.45        16\n",
      "\n",
      "avg / total       0.42      0.41      0.42        29\n",
      "\n",
      "[5 8 9 7]\n",
      "MNB Accuracy:  0.41379310344827586\n",
      "MNB F1:  0.4109916367980884\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.38      0.43        13\n",
      "          1       0.58      0.69      0.63        16\n",
      "\n",
      "avg / total       0.54      0.55      0.54        29\n",
      "\n",
      "[ 5  8  5 11]\n",
      "svc Accuracy:  0.5517241379310345\n",
      "svc F1:  0.5316770186335404\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.31      0.36        13\n",
      "          1       0.55      0.69      0.61        16\n",
      "\n",
      "avg / total       0.50      0.52      0.50        29\n",
      "\n",
      "[ 4  9  5 11]\n",
      "LR Accuracy:  0.5172413793103449\n",
      "LR F1:  0.48737373737373746\n",
      "For name:  f_cardoso\n",
      "total sample size before apply threshold:  178\n",
      "Counter({'0000-0002-6692-2249': 139, '0000-0002-0068-9974': 18, '0000-0002-4391-1336': 9, '0000-0002-7042-1287': 7, '0000-0003-2249-9407': 5})\n",
      "['0000-0002-6692-2249', '0000-0002-0068-9974']\n",
      "Total sample size after apply threshold:  157\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(157, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 17)\n",
      "2\n",
      "(157, 73)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.95       139\n",
      "          1       0.75      0.17      0.27        18\n",
      "\n",
      "avg / total       0.88      0.90      0.87       157\n",
      "\n",
      "[138   1  15   3]\n",
      "MNB Accuracy:  0.8980891719745223\n",
      "MNB F1:  0.6089663760896639\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.96       139\n",
      "          1       1.00      0.28      0.43        18\n",
      "\n",
      "avg / total       0.92      0.92      0.90       157\n",
      "\n",
      "[139   0  13   5]\n",
      "svc Accuracy:  0.9171974522292994\n",
      "svc F1:  0.695054534588376\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       139\n",
      "          1       1.00      0.06      0.11        18\n",
      "\n",
      "avg / total       0.90      0.89      0.85       157\n",
      "\n",
      "[139   0  17   1]\n",
      "LR Accuracy:  0.89171974522293\n",
      "LR F1:  0.5238180196253346\n",
      "For name:  m_pinto\n",
      "total sample size before apply threshold:  201\n",
      "Counter({'0000-0002-4676-1409': 79, '0000-0002-8521-2904': 23, '0000-0002-8122-7084': 15, '0000-0001-9778-2093': 14, '0000-0003-3061-9632': 14, '0000-0003-4684-4797': 14, '0000-0003-3462-7277': 10, '0000-0001-9730-5772': 8, '0000-0002-5928-6483': 7, '0000-0001-9663-8399': 5, '0000-0001-6370-3051': 4, '0000-0001-6835-2561': 3, '0000-0002-6337-3459': 2, '0000-0002-5376-742X': 2, '0000-0002-9890-6657': 1})\n",
      "['0000-0002-8122-7084', '0000-0001-9778-2093', '0000-0002-4676-1409', '0000-0003-3061-9632', '0000-0003-3462-7277', '0000-0003-4684-4797', '0000-0002-8521-2904']\n",
      "Total sample size after apply threshold:  169\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 90)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 18)\n",
      "2\n",
      "(169, 108)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        15\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       0.53      1.00      0.69        79\n",
      "          3       1.00      0.14      0.25        14\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.00      0.00      0.00        14\n",
      "          6       0.62      0.22      0.32        23\n",
      "\n",
      "avg / total       0.59      0.56      0.47       169\n",
      "\n",
      "[ 3  0 12  0  0  0  0  0  6  8  0  0  0  0  0  0 79  0  0  0  0  0  0 10\n",
      "  2  0  0  2  0  0 10  0  0  0  0  0  0 13  0  0  0  1  0  0 18  0  0  0\n",
      "  5]\n",
      "MNB Accuracy:  0.5621301775147929\n",
      "MNB F1:  0.31369575862462185\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        15\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       0.63      0.96      0.76        79\n",
      "          3       0.86      0.43      0.57        14\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       1.00      0.07      0.13        14\n",
      "          6       0.80      0.52      0.63        23\n",
      "\n",
      "avg / total       0.73      0.68      0.64       169\n",
      "\n",
      "[10  0  4  0  1  0  0  0 10  4  0  0  0  0  0  0 76  1  2  0  0  0  0  6\n",
      "  6  1  0  1  0  0  9  0  0  0  1  0  0 11  0  1  1  1  0  0 11  0  0  0\n",
      " 12]\n",
      "svc Accuracy:  0.6804733727810651\n",
      "svc F1:  0.5328105979233799\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        15\n",
      "          1       1.00      0.57      0.73        14\n",
      "          2       0.58      1.00      0.73        79\n",
      "          3       1.00      0.21      0.35        14\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       1.00      0.07      0.13        14\n",
      "          6       0.82      0.39      0.53        23\n",
      "\n",
      "avg / total       0.72      0.64      0.58       169\n",
      "\n",
      "[ 9  0  6  0  0  0  0  0  8  6  0  0  0  0  0  0 79  0  0  0  0  0  0 11\n",
      "  3  0  0  0  0  0 10  0  0  0  0  0  0 11  0  0  1  2  0  0 14  0  0  0\n",
      "  9]\n",
      "LR Accuracy:  0.6449704142011834\n",
      "LR F1:  0.46063435475200176\n",
      "For name:  j_cuevas\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0003-2049-3554': 40, '0000-0001-7421-0682': 29, '0000-0001-6327-1404': 6, '0000-0002-6815-3383': 3})\n",
      "['0000-0001-7421-0682', '0000-0003-2049-3554']\n",
      "Total sample size after apply threshold:  69\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 16)\n",
      "2\n",
      "(69, 51)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.93      0.79        29\n",
      "          1       0.93      0.70      0.80        40\n",
      "\n",
      "avg / total       0.83      0.80      0.80        69\n",
      "\n",
      "[27  2 12 28]\n",
      "MNB Accuracy:  0.7971014492753623\n",
      "MNB F1:  0.7970588235294118\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.76      0.81        29\n",
      "          1       0.84      0.93      0.88        40\n",
      "\n",
      "avg / total       0.86      0.86      0.85        69\n",
      "\n",
      "[22  7  3 37]\n",
      "svc Accuracy:  0.855072463768116\n",
      "svc F1:  0.8478835978835979\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.72      0.75        29\n",
      "          1       0.81      0.85      0.83        40\n",
      "\n",
      "avg / total       0.80      0.80      0.80        69\n",
      "\n",
      "[21  8  6 34]\n",
      "LR Accuracy:  0.7971014492753623\n",
      "LR F1:  0.7896341463414634\n",
      "For name:  j_chang\n",
      "total sample size before apply threshold:  360\n",
      "Counter({'0000-0001-5726-9797': 85, '0000-0002-8423-5987': 38, '0000-0002-6596-931X': 33, '0000-0002-0890-9302': 31, '0000-0002-3880-3787': 29, '0000-0002-2717-0101': 23, '0000-0001-5582-0928': 17, '0000-0002-4655-1516': 17, '0000-0002-6477-6938': 15, '0000-0003-3773-182X': 12, '0000-0001-8651-2602': 11, '0000-0001-5039-2186': 9, '0000-0001-7843-2688': 9, '0000-0002-6711-1739': 8, '0000-0002-3974-8089': 5, '0000-0001-7449-4080': 4, '0000-0003-3469-9553': 4, '0000-0001-5241-8175': 3, '0000-0002-3811-1254': 2, '0000-0003-4633-587X': 2, '0000-0003-2613-7585': 1, '0000-0003-0041-4804': 1, '0000-0002-4296-4065': 1})\n",
      "['0000-0001-5726-9797', '0000-0003-3773-182X', '0000-0001-5582-0928', '0000-0002-2717-0101', '0000-0002-6596-931X', '0000-0002-6477-6938', '0000-0002-3880-3787', '0000-0002-0890-9302', '0000-0002-8423-5987', '0000-0002-4655-1516', '0000-0001-8651-2602']\n",
      "Total sample size after apply threshold:  311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(311, 140)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(311, 19)\n",
      "2\n",
      "(311, 159)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.95      0.54        85\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        17\n",
      "          3       0.35      0.30      0.33        23\n",
      "          4       0.14      0.09      0.11        33\n",
      "          5       0.00      0.00      0.00        15\n",
      "          6       0.65      0.38      0.48        29\n",
      "          7       0.50      0.23      0.31        31\n",
      "          8       0.32      0.18      0.23        38\n",
      "          9       1.00      0.18      0.30        17\n",
      "         10       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.35      0.38      0.30       311\n",
      "\n",
      "[81  0  0  0  1  0  1  1  1  0  0 11  0  0  0  1  0  0  0  0  0  0 15  0\n",
      "  0  0  0  0  0  0  2  0  0  8  0  0  7  8  0  0  0  0  0  0 20  0  0  8\n",
      "  3  0  0  0  2  0  0 13  0  0  0  2  0  0  0  0  0  0  9  0  0  0  5  0\n",
      " 11  0  4  0  0 21  0  0  0  1  0  0  7  2  0  0 18  0  0  5  1  0  3  4\n",
      "  7  0  0 11  0  0  0  0  0  0  1  2  3  0  6  0  0  0  0  0  2  1  2  0\n",
      "  0]\n",
      "MNB Accuracy:  0.38263665594855306\n",
      "MNB F1:  0.20918197995665758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.82      0.71        85\n",
      "          1       1.00      0.58      0.74        12\n",
      "          2       0.75      0.35      0.48        17\n",
      "          3       0.43      0.39      0.41        23\n",
      "          4       0.36      0.58      0.44        33\n",
      "          5       1.00      0.60      0.75        15\n",
      "          6       0.77      0.59      0.67        29\n",
      "          7       0.70      0.52      0.59        31\n",
      "          8       0.57      0.61      0.59        38\n",
      "          9       0.92      0.71      0.80        17\n",
      "         10       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.63      0.60      0.60       311\n",
      "\n",
      "[70  0  0  0  5  0  1  4  5  0  0  4  7  0  0  1  0  0  0  0  0  0  4  0\n",
      "  6  1  3  0  0  0  0  0  3  1  0  0  9 13  0  0  0  0  0  0  5  0  0  8\n",
      " 19  0  0  0  1  0  0  3  0  0  0  3  9  0  0  0  0  0  3  0  0  0  3  0\n",
      " 17  0  5  0  1 10  0  0  1  2  0  0 16  2  0  0  5  0  0  2  4  0  2  1\n",
      " 23  1  0  1  0  0  0  0  0  0  2  2 12  0  5  0  2  0  0  0  2  0  2  0\n",
      "  0]\n",
      "svc Accuracy:  0.6045016077170418\n",
      "svc F1:  0.561916549341719\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.86      0.67        85\n",
      "          1       1.00      0.50      0.67        12\n",
      "          2       0.75      0.18      0.29        17\n",
      "          3       0.41      0.48      0.44        23\n",
      "          4       0.30      0.42      0.35        33\n",
      "          5       1.00      0.40      0.57        15\n",
      "          6       0.73      0.55      0.63        29\n",
      "          7       0.58      0.48      0.53        31\n",
      "          8       0.48      0.37      0.42        38\n",
      "          9       0.92      0.65      0.76        17\n",
      "         10       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.58      0.54      0.53       311\n",
      "\n",
      "[73  0  0  0  4  0  1  5  2  0  0  5  6  0  0  1  0  0  0  0  0  0  7  0\n",
      "  3  2  3  0  0  0  2  0  0  1  0  0 11 10  0  0  0  1  0  0  7  0  0 10\n",
      " 14  0  0  0  2  0  0  5  0  0  0  4  6  0  0  0  0  0  7  0  0  0  3  0\n",
      " 16  0  2  0  1  8  0  0  1  3  0  0 15  4  0  0 11  0  0  3  3  0  3  3\n",
      " 14  1  0  2  0  0  0  1  0  0  2  1 11  0  6  0  1  0  0  0  2  1  1  0\n",
      "  0]\n",
      "LR Accuracy:  0.5434083601286174\n",
      "LR F1:  0.4837589882496729\n",
      "For name:  a_dias\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0003-3641-3248': 19, '0000-0001-7048-7991': 14, '0000-0002-2651-6270': 13, '0000-0001-6895-372X': 13, '0000-0002-0865-0257': 11, '0000-0003-3197-9146': 6, '0000-0001-8881-3564': 4, '0000-0002-5111-0774': 3, '0000-0002-6057-9531': 2, '0000-0003-1921-0510': 2, '0000-0003-0060-2872': 1, '0000-0002-6210-8872': 1, '0000-0002-6667-1961': 1})\n",
      "['0000-0002-0865-0257', '0000-0003-3641-3248', '0000-0002-2651-6270', '0000-0001-7048-7991', '0000-0001-6895-372X']\n",
      "Total sample size after apply threshold:  70\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 47)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 15)\n",
      "2\n",
      "(70, 62)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.09      0.13        11\n",
      "          1       0.43      0.53      0.48        19\n",
      "          2       0.52      0.85      0.65        13\n",
      "          3       0.67      0.43      0.52        14\n",
      "          4       0.42      0.38      0.40        13\n",
      "\n",
      "avg / total       0.46      0.47      0.45        70\n",
      "\n",
      "[ 1  5  3  1  1  0 10  2  2  5  2  0 11  0  0  1  3  3  6  1  1  5  2  0\n",
      "  5]\n",
      "MNB Accuracy:  0.4714285714285714\n",
      "MNB F1:  0.43399768603093414\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.27      0.35        11\n",
      "          1       0.57      0.68      0.62        19\n",
      "          2       0.71      0.77      0.74        13\n",
      "          3       0.64      0.64      0.64        14\n",
      "          4       0.38      0.38      0.38        13\n",
      "\n",
      "avg / total       0.56      0.57      0.56        70\n",
      "\n",
      "[ 3  4  1  2  1  0 13  0  1  5  0  0 10  2  1  2  1  1  9  1  1  5  2  0\n",
      "  5]\n",
      "svc Accuracy:  0.5714285714285714\n",
      "svc F1:  0.5480404127462951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.09      0.12        11\n",
      "          1       0.43      0.53      0.48        19\n",
      "          2       0.58      0.85      0.69        13\n",
      "          3       0.64      0.50      0.56        14\n",
      "          4       0.36      0.31      0.33        13\n",
      "\n",
      "avg / total       0.45      0.47      0.45        70\n",
      "\n",
      "[ 1  5  2  2  1  0 10  2  2  5  2  0 11  0  0  2  2  2  7  1  1  6  2  0\n",
      "  4]\n",
      "LR Accuracy:  0.4714285714285714\n",
      "LR F1:  0.43493417366946785\n",
      "For name:  j_choi\n",
      "total sample size before apply threshold:  441\n",
      "Counter({'0000-0002-2775-3315': 98, '0000-0002-8439-6035': 42, '0000-0003-0018-8712': 25, '0000-0003-2379-2226': 23, '0000-0001-9760-9514': 21, '0000-0002-7491-6711': 21, '0000-0003-2206-4593': 20, '0000-0002-4850-8204': 19, '0000-0003-4897-3277': 15, '0000-0003-3257-2508': 15, '0000-0001-5408-9029': 14, '0000-0002-1161-6586': 13, '0000-0002-9663-4790': 13, '0000-0001-7348-9861': 12, '0000-0002-7532-5315': 10, '0000-0002-9210-9681': 10, '0000-0003-4805-7930': 9, '0000-0001-6121-5804': 8, '0000-0002-3864-9521': 7, '0000-0001-9302-7840': 6, '0000-0003-2891-8086': 4, '0000-0003-3179-6892': 4, '0000-0001-7938-8420': 3, '0000-0001-6336-6462': 3, '0000-0003-3284-9407': 3, '0000-0001-5007-7469': 2, '0000-0002-3280-1991': 2, '0000-0002-2894-3364': 2, '0000-0003-3940-8663': 2, '0000-0002-5086-7345': 2, '0000-0001-8047-9821': 2, '0000-0002-6639-8002': 1, '0000-0002-0723-5035': 1, '0000-0002-8328-4082': 1, '0000-0002-4663-3263': 1, '0000-0001-8023-084X': 1, '0000-0002-3863-4442': 1, '0000-0003-2578-1213': 1, '0000-0003-3554-7033': 1, '0000-0003-1060-0096': 1, '0000-0003-2277-1095': 1, '0000-0003-3155-3196': 1})\n",
      "['0000-0003-4897-3277', '0000-0003-0018-8712', '0000-0003-2379-2226', '0000-0002-1161-6586', '0000-0002-8439-6035', '0000-0001-9760-9514', '0000-0002-7532-5315', '0000-0002-7491-6711', '0000-0003-3257-2508', '0000-0002-9663-4790', '0000-0003-2206-4593', '0000-0002-2775-3315', '0000-0001-5408-9029', '0000-0002-4850-8204', '0000-0001-7348-9861', '0000-0002-9210-9681']\n",
      "Total sample size after apply threshold:  371\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(371, 204)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(371, 18)\n",
      "2\n",
      "(371, 222)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        15\n",
      "          1       1.00      0.12      0.21        25\n",
      "          2       0.42      0.43      0.43        23\n",
      "          3       1.00      0.15      0.27        13\n",
      "          4       0.37      0.36      0.36        42\n",
      "          5       0.00      0.00      0.00        21\n",
      "          6       1.00      0.30      0.46        10\n",
      "          7       1.00      0.24      0.38        21\n",
      "          8       0.00      0.00      0.00        15\n",
      "          9       1.00      0.08      0.14        13\n",
      "         10       1.00      0.15      0.26        20\n",
      "         11       0.34      0.98      0.51        98\n",
      "         12       0.00      0.00      0.00        14\n",
      "         13       1.00      0.21      0.35        19\n",
      "         14       0.00      0.00      0.00        12\n",
      "         15       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.51      0.39      0.31       371\n",
      "\n",
      "[ 0  0  4  0  1  0  0  0  0  0  0 10  0  0  0  0  0  3  0  0  0  0  0  0\n",
      "  0  0  0 22  0  0  0  0  1  0 10  0  2  1  0  0  0  0  0  9  0  0  0  0\n",
      "  0  0  3  2  4  0  0  0  0  0  0  4  0  0  0  0  0  0  1  0 15  0  0  0\n",
      "  0  0  0 26  0  0  0  0  0  0  0  0  5  0  0  0  0  0  0 16  0  0  0  0\n",
      "  0  0  0  0  2  0  3  0  0  0  0  5  0  0  0  0  0  0  0  0  1  0  0  5\n",
      "  0  0  0 15  0  0  0  0  0  0  3  0  2  0  0  0  0  0  0 10  0  0  0  0\n",
      "  0  0  2  0  2  0  0  0  0  1  0  8  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  3 17  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0 96  0  0  0  0\n",
      "  0  0  0  0  1  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  2  0  0  0\n",
      "  0  0  0 13  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0\n",
      "  0  0  0  0  3  1  0  0  0  0  0  4  0  0  0  2]\n",
      "MNB Accuracy:  0.3881401617250674\n",
      "MNB F1:  0.23168166008957947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.27      0.36        15\n",
      "          1       1.00      0.40      0.57        25\n",
      "          2       0.35      0.39      0.37        23\n",
      "          3       0.60      0.23      0.33        13\n",
      "          4       0.56      0.45      0.50        42\n",
      "          5       0.80      0.38      0.52        21\n",
      "          6       1.00      0.40      0.57        10\n",
      "          7       1.00      0.67      0.80        21\n",
      "          8       1.00      0.20      0.33        15\n",
      "          9       1.00      0.69      0.82        13\n",
      "         10       0.82      0.45      0.58        20\n",
      "         11       0.46      0.96      0.62        98\n",
      "         12       1.00      0.50      0.67        14\n",
      "         13       1.00      0.63      0.77        19\n",
      "         14       1.00      0.58      0.74        12\n",
      "         15       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.71      0.59      0.58       371\n",
      "\n",
      "[ 4  0  4  0  1  0  0  0  0  0  0  6  0  0  0  0  0 10  0  0  0  0  0  0\n",
      "  0  0  0 15  0  0  0  0  3  0  9  0  2  1  0  0  0  0  0  8  0  0  0  0\n",
      "  0  0  3  3  3  0  0  0  0  0  0  4  0  0  0  0  0  0  3  1 19  1  0  0\n",
      "  0  0  1 17  0  0  0  0  0  0  0  0  3  8  0  0  0  0  0 10  0  0  0  0\n",
      "  0  0  1  0  1  0  4  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0 14\n",
      "  0  0  0  7  0  0  0  0  0  0  3  0  2  0  0  0  3  0  0  7  0  0  0  0\n",
      "  0  0  1  0  0  0  0  0  0  9  0  3  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  9 10  0  0  0  0  0  0  2  0  1  0  0  0  0  0  1 94  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  7  7  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  6  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0  7  0\n",
      "  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  8]\n",
      "svc Accuracy:  0.5929919137466307\n",
      "svc F1:  0.5902856805726931\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.27      0.36        15\n",
      "          1       1.00      0.24      0.39        25\n",
      "          2       0.43      0.39      0.41        23\n",
      "          3       1.00      0.15      0.27        13\n",
      "          4       0.50      0.40      0.45        42\n",
      "          5       0.60      0.14      0.23        21\n",
      "          6       0.43      0.30      0.35        10\n",
      "          7       1.00      0.62      0.76        21\n",
      "          8       1.00      0.07      0.12        15\n",
      "          9       1.00      0.46      0.63        13\n",
      "         10       0.88      0.35      0.50        20\n",
      "         11       0.40      0.96      0.57        98\n",
      "         12       1.00      0.43      0.60        14\n",
      "         13       1.00      0.58      0.73        19\n",
      "         14       1.00      0.33      0.50        12\n",
      "         15       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.69      0.52      0.49       371\n",
      "\n",
      "[ 4  0  3  0  0  0  1  0  0  0  0  7  0  0  0  0  0  6  0  0  1  0  0  0\n",
      "  0  0  0 18  0  0  0  0  3  0  9  0  1  1  1  0  0  0  0  8  0  0  0  0\n",
      "  0  0  3  2  4  0  0  0  0  0  0  4  0  0  0  0  0  0  1  0 17  0  1  0\n",
      "  0  0  0 23  0  0  0  0  0  0  0  0  3  3  0  0  0  0  0 15  0  0  0  0\n",
      "  0  0  0  0  2  0  3  0  0  0  0  5  0  0  0  0  0  0  0  0  1  0  0 13\n",
      "  0  0  0  7  0  0  0  0  0  0  3  0  1  0  1  0  1  0  0  9  0  0  0  0\n",
      "  0  0  1  0  0  0  0  0  0  6  0  6  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  7 13  0  0  0  0  0  0  1  0  2  0  0  0  0  0  1 94  0  0  0  0\n",
      "  0  0  0  0  0  1  0  0  0  0  0  7  6  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  7  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  4  0\n",
      "  0  0  0  0  1  0  0  0  0  0  0  3  0  0  0  6]\n",
      "LR Accuracy:  0.5175202156334232\n",
      "LR F1:  0.4767782978234748\n",
      "For name:  m_ahmed\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0002-4729-9068': 12, '0000-0002-1921-0724': 3, '0000-0002-4863-0402': 3, '0000-0002-4612-1815': 2, '0000-0002-3514-1327': 2, '0000-0002-7745-7522': 1, '0000-0002-9073-4969': 1, '0000-0002-3217-9688': 1, '0000-0002-2237-8456': 1, '0000-0001-7117-1032': 1})\n",
      "['0000-0002-4729-9068']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  j_jo\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0001-9721-7641': 7, '0000-0001-8939-1623': 4, '0000-0002-6080-7493': 1, '0000-0002-5366-7605': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  n_dawson\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-6607-9976': 14, '0000-0003-0123-897X': 14, '0000-0001-5389-8692': 2, '0000-0002-2658-8960': 1})\n",
      "['0000-0002-6607-9976', '0000-0003-0123-897X']\n",
      "Total sample size after apply threshold:  28\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 10)\n",
      "2\n",
      "(28, 32)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.93      0.74        14\n",
      "          1       0.86      0.43      0.57        14\n",
      "\n",
      "avg / total       0.74      0.68      0.66        28\n",
      "\n",
      "[13  1  8  6]\n",
      "MNB Accuracy:  0.6785714285714286\n",
      "MNB F1:  0.6571428571428573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.71      0.67        14\n",
      "          1       0.67      0.57      0.62        14\n",
      "\n",
      "avg / total       0.65      0.64      0.64        28\n",
      "\n",
      "[10  4  6  8]\n",
      "svc Accuracy:  0.6428571428571429\n",
      "svc F1:  0.641025641025641\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.86      0.75        14\n",
      "          1       0.80      0.57      0.67        14\n",
      "\n",
      "avg / total       0.73      0.71      0.71        28\n",
      "\n",
      "[12  2  6  8]\n",
      "LR Accuracy:  0.7142857142857143\n",
      "LR F1:  0.7083333333333333\n",
      "For name:  j_barbosa\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-1854-1572': 11, '0000-0001-5879-9458': 9, '0000-0002-8664-8152': 9, '0000-0003-4135-2347': 3, '0000-0002-7259-2901': 1, '0000-0002-7828-2912': 1, '0000-0001-7869-5533': 1})\n",
      "['0000-0002-1854-1572']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  e_o'connor\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0001-6727-6499': 8, '0000-0002-7810-1915': 5, '0000-0002-6961-6108': 3, '0000-0002-2971-6921': 1, '0000-0002-8228-796X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_zheng\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0001-5839-1305': 31, '0000-0002-7463-0289': 11, '0000-0002-0657-7914': 3, '0000-0002-6562-870X': 1})\n",
      "['0000-0001-5839-1305', '0000-0002-7463-0289']\n",
      "Total sample size after apply threshold:  42\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 10)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 15)\n",
      "2\n",
      "(42, 25)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        31\n",
      "          1       0.91      0.91      0.91        11\n",
      "\n",
      "avg / total       0.95      0.95      0.95        42\n",
      "\n",
      "[30  1  1 10]\n",
      "MNB Accuracy:  0.9523809523809523\n",
      "MNB F1:  0.9384164222873901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        31\n",
      "          1       0.82      0.82      0.82        11\n",
      "\n",
      "avg / total       0.90      0.90      0.90        42\n",
      "\n",
      "[29  2  2  9]\n",
      "svc Accuracy:  0.9047619047619048\n",
      "svc F1:  0.8768328445747801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91        31\n",
      "          1       0.86      0.55      0.67        11\n",
      "\n",
      "avg / total       0.86      0.86      0.85        42\n",
      "\n",
      "[30  1  5  6]\n",
      "LR Accuracy:  0.8571428571428571\n",
      "LR F1:  0.7878787878787877\n",
      "For name:  r_hall\n",
      "total sample size before apply threshold:  144\n",
      "Counter({'0000-0002-8318-8728': 92, '0000-0001-5504-6717': 41, '0000-0002-4908-8168': 6, '0000-0002-5460-0090': 3, '0000-0002-7743-630X': 2})\n",
      "['0000-0002-8318-8728', '0000-0001-5504-6717']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size after apply threshold:  133\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 71)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 25)\n",
      "2\n",
      "(133, 96)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.85      0.85        92\n",
      "          1       0.66      0.66      0.66        41\n",
      "\n",
      "avg / total       0.79      0.79      0.79       133\n",
      "\n",
      "[78 14 14 27]\n",
      "MNB Accuracy:  0.7894736842105263\n",
      "MNB F1:  0.7531813361611878\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91        92\n",
      "          1       0.90      0.66      0.76        41\n",
      "\n",
      "avg / total       0.88      0.87      0.87       133\n",
      "\n",
      "[89  3 14 27]\n",
      "svc Accuracy:  0.8721804511278195\n",
      "svc F1:  0.8366919465511016\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.96      0.87        92\n",
      "          1       0.82      0.44      0.57        41\n",
      "\n",
      "avg / total       0.80      0.80      0.78       133\n",
      "\n",
      "[88  4 23 18]\n",
      "LR Accuracy:  0.7969924812030075\n",
      "LR F1:  0.7192118226600985\n",
      "For name:  d_hwang\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0002-2487-2255': 40, '0000-0002-9684-3998': 9, '0000-0001-5275-0354': 2, '0000-0001-6899-1769': 1})\n",
      "['0000-0002-2487-2255']\n",
      "Total sample size after apply threshold:  40\n",
      "For name:  c_shen\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0002-0747-217X': 56, '0000-0003-2833-2771': 22, '0000-0002-2517-3472': 7, '0000-0001-7392-056X': 6, '0000-0002-5052-7762': 5, '0000-0002-0619-1309': 3, '0000-0001-8635-3429': 3, '0000-0002-3218-0689': 3, '0000-0002-3855-7360': 2, '0000-0003-1645-8211': 1, '0000-0002-0685-1901': 1, '0000-0002-9466-3838': 1, '0000-0002-5093-7657': 1})\n",
      "['0000-0003-2833-2771', '0000-0002-0747-217X']\n",
      "Total sample size after apply threshold:  78\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 18)\n",
      "2\n",
      "(78, 66)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        22\n",
      "          1       0.84      1.00      0.91        56\n",
      "\n",
      "avg / total       0.88      0.86      0.84        78\n",
      "\n",
      "[11 11  0 56]\n",
      "MNB Accuracy:  0.8589743589743589\n",
      "MNB F1:  0.7886178861788617\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.68      0.79        22\n",
      "          1       0.89      0.98      0.93        56\n",
      "\n",
      "avg / total       0.90      0.90      0.89        78\n",
      "\n",
      "[15  7  1 55]\n",
      "svc Accuracy:  0.8974358974358975\n",
      "svc F1:  0.8608385370205174\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        22\n",
      "          1       0.81      1.00      0.90        56\n",
      "\n",
      "avg / total       0.86      0.83      0.81        78\n",
      "\n",
      "[ 9 13  0 56]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.7383225806451613\n",
      "For name:  v_lopes\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0003-1599-2180': 20, '0000-0003-2278-8559': 3, '0000-0003-2079-4170': 2, '0000-0001-8276-4490': 1})\n",
      "['0000-0003-1599-2180']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  m_quintana\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0003-3601-0262': 29, '0000-0002-7036-8658': 17, '0000-0002-3808-8189': 16, '0000-0002-7934-4361': 3, '0000-0001-6190-3324': 2, '0000-0002-2677-6179': 1})\n",
      "['0000-0002-3808-8189', '0000-0002-7036-8658', '0000-0003-3601-0262']\n",
      "Total sample size after apply threshold:  62\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 18)\n",
      "2\n",
      "(62, 50)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.81      0.81        16\n",
      "          1       0.88      0.82      0.85        17\n",
      "          2       0.93      0.97      0.95        29\n",
      "\n",
      "avg / total       0.89      0.89      0.89        62\n",
      "\n",
      "[13  1  2  3 14  0  0  1 28]\n",
      "MNB Accuracy:  0.8870967741935484\n",
      "MNB F1:  0.8700457969525767\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.88      0.90        16\n",
      "          1       0.88      0.88      0.88        17\n",
      "          2       0.93      0.97      0.95        29\n",
      "\n",
      "avg / total       0.92      0.92      0.92        62\n",
      "\n",
      "[14  1  1  1 15  1  0  1 28]\n",
      "svc Accuracy:  0.9193548387096774\n",
      "svc F1:  0.9115770966669884\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.69      0.76        16\n",
      "          1       0.93      0.76      0.84        17\n",
      "          2       0.83      1.00      0.91        29\n",
      "\n",
      "avg / total       0.86      0.85      0.85        62\n",
      "\n",
      "[11  1  4  2 13  2  0  0 29]\n",
      "LR Accuracy:  0.8548387096774194\n",
      "LR F1:  0.8345267890248423\n",
      "For name:  j_nunes\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0001-6739-0304': 44, '0000-0001-6560-1518': 6, '0000-0003-0109-8268': 3, '0000-0002-0164-249X': 3, '0000-0002-9988-2060': 2, '0000-0002-3741-9513': 2, '0000-0002-9693-2827': 1, '0000-0003-4917-6771': 1})\n",
      "['0000-0001-6739-0304']\n",
      "Total sample size after apply threshold:  44\n",
      "For name:  z_nagy\n",
      "total sample size before apply threshold:  110\n",
      "Counter({'0000-0001-9756-5427': 57, '0000-0002-6700-4829': 50, '0000-0003-4196-2874': 1, '0000-0002-6014-3228': 1, '0000-0002-6493-5601': 1})\n",
      "['0000-0002-6700-4829', '0000-0001-9756-5427']\n",
      "Total sample size after apply threshold:  107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 68)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 23)\n",
      "2\n",
      "(107, 91)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.68      0.64        50\n",
      "          1       0.69      0.61      0.65        57\n",
      "\n",
      "avg / total       0.65      0.64      0.65       107\n",
      "\n",
      "[34 16 22 35]\n",
      "MNB Accuracy:  0.6448598130841121\n",
      "MNB F1:  0.6448287910552062\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.56      0.61        50\n",
      "          1       0.66      0.75      0.70        57\n",
      "\n",
      "avg / total       0.66      0.66      0.66       107\n",
      "\n",
      "[28 22 14 43]\n",
      "svc Accuracy:  0.6635514018691588\n",
      "svc F1:  0.6568068424803992\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.60      0.64        50\n",
      "          1       0.68      0.75      0.72        57\n",
      "\n",
      "avg / total       0.68      0.68      0.68       107\n",
      "\n",
      "[30 20 14 43]\n",
      "LR Accuracy:  0.6822429906542056\n",
      "LR F1:  0.6774822695035462\n",
      "For name:  e_brown\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0002-5995-834X': 28, '0000-0002-8438-6136': 8, '0000-0002-0209-3293': 8, '0000-0003-1411-5792': 7, '0000-0002-2641-1890': 6, '0000-0002-2762-2489': 5, '0000-0003-3806-5339': 4, '0000-0002-1575-2606': 2, '0000-0002-6611-5770': 1, '0000-0002-1398-5721': 1, '0000-0001-7523-0685': 1})\n",
      "['0000-0002-5995-834X']\n",
      "Total sample size after apply threshold:  28\n",
      "For name:  j_nielsen\n",
      "total sample size before apply threshold:  913\n",
      "Counter({'0000-0002-9955-6003': 487, '0000-0001-5568-2916': 105, '0000-0001-9414-1653': 104, '0000-0002-8747-6938': 57, '0000-0002-2831-7718': 39, '0000-0002-2854-8188': 35, '0000-0003-2228-5994': 24, '0000-0002-2058-3579': 23, '0000-0003-1730-3094': 13, '0000-0001-8521-7353': 9, '0000-0002-5211-948X': 8, '0000-0002-8112-8449': 6, '0000-0002-3418-4907': 2, '0000-0002-4760-3875': 1})\n",
      "['0000-0001-9414-1653', '0000-0002-2831-7718', '0000-0003-2228-5994', '0000-0002-9955-6003', '0000-0002-2854-8188', '0000-0002-8747-6938', '0000-0003-1730-3094', '0000-0002-2058-3579', '0000-0001-5568-2916']\n",
      "Total sample size after apply threshold:  887\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(887, 244)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(887, 28)\n",
      "2\n",
      "(887, 272)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83       104\n",
      "          1       1.00      0.23      0.38        39\n",
      "          2       0.00      0.00      0.00        24\n",
      "          3       0.68      1.00      0.81       487\n",
      "          4       1.00      0.09      0.16        35\n",
      "          5       1.00      0.18      0.30        57\n",
      "          6       0.00      0.00      0.00        13\n",
      "          7       0.00      0.00      0.00        23\n",
      "          8       0.88      0.63      0.73       105\n",
      "\n",
      "avg / total       0.74      0.73      0.67       887\n",
      "\n",
      "[ 74   0   0  30   0   0   0   0   0   0   9   0  30   0   0   0   0   0\n",
      "   0   0   0  24   0   0   0   0   0   0   0   0 486   0   0   0   0   1\n",
      "   0   0   0  32   3   0   0   0   0   0   0   0  47   0  10   0   0   0\n",
      "   0   0   0   7   0   0   0   0   6   0   0   0  21   0   0   0   0   2\n",
      "   0   0   0  39   0   0   0   0  66]\n",
      "MNB Accuracy:  0.7305524239007892\n",
      "MNB F1:  0.35601958409940226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91       104\n",
      "          1       0.72      0.46      0.56        39\n",
      "          2       1.00      0.71      0.83        24\n",
      "          3       0.79      0.98      0.88       487\n",
      "          4       0.92      0.34      0.50        35\n",
      "          5       0.87      0.46      0.60        57\n",
      "          6       0.67      0.15      0.25        13\n",
      "          7       0.94      0.65      0.77        23\n",
      "          8       0.91      0.77      0.84       105\n",
      "\n",
      "avg / total       0.84      0.83      0.82       887\n",
      "\n",
      "[ 87   0   0  17   0   0   0   0   0   0  18   0  20   1   0   0   0   0\n",
      "   0   0  17   7   0   0   0   0   0   0   4   0 479   0   3   0   0   1\n",
      "   0   2   0  20  12   1   0   0   0   0   1   0  30   0  26   0   0   0\n",
      "   0   0   0   4   0   0   2   0   7   0   0   0   8   0   0   0  15   0\n",
      "   0   0   0  22   0   0   1   1  81]\n",
      "svc Accuracy:  0.830890642615558\n",
      "svc F1:  0.6811591199683865\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.66      0.80       104\n",
      "          1       0.91      0.26      0.40        39\n",
      "          2       1.00      0.42      0.59        24\n",
      "          3       0.70      1.00      0.82       487\n",
      "          4       1.00      0.14      0.25        35\n",
      "          5       1.00      0.28      0.44        57\n",
      "          6       0.00      0.00      0.00        13\n",
      "          7       0.92      0.48      0.63        23\n",
      "          8       0.91      0.57      0.70       105\n",
      "\n",
      "avg / total       0.80      0.75      0.71       887\n",
      "\n",
      "[ 69   0   0  35   0   0   0   0   0   0  10   0  29   0   0   0   0   0\n",
      "   0   0  10  14   0   0   0   0   0   0   1   0 486   0   0   0   0   0\n",
      "   0   0   0  30   5   0   0   0   0   0   0   0  41   0  16   0   0   0\n",
      "   0   0   0   7   0   0   0   0   6   0   0   0  12   0   0   0  11   0\n",
      "   0   0   0  44   0   0   0   1  60]\n",
      "LR Accuracy:  0.7519729425028185\n",
      "LR F1:  0.5138731443184654\n",
      "For name:  w_choi\n",
      "total sample size before apply threshold:  118\n",
      "Counter({'0000-0003-1801-9386': 79, '0000-0002-7896-7655': 16, '0000-0002-6623-3806': 7, '0000-0002-4203-0457': 6, '0000-0001-8038-5876': 3, '0000-0002-7183-3400': 3, '0000-0003-4233-0174': 2, '0000-0001-5171-2890': 2})\n",
      "['0000-0003-1801-9386', '0000-0002-7896-7655']\n",
      "Total sample size after apply threshold:  95\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 26)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 15)\n",
      "2\n",
      "(95, 41)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.96        79\n",
      "          1       0.85      0.69      0.76        16\n",
      "\n",
      "avg / total       0.92      0.93      0.92        95\n",
      "\n",
      "[77  2  5 11]\n",
      "MNB Accuracy:  0.9263157894736842\n",
      "MNB F1:  0.8575712143928036\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96        79\n",
      "          1       0.86      0.75      0.80        16\n",
      "\n",
      "avg / total       0.93      0.94      0.94        95\n",
      "\n",
      "[77  2  4 12]\n",
      "svc Accuracy:  0.9368421052631579\n",
      "svc F1:  0.88125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        79\n",
      "          1       1.00      0.38      0.55        16\n",
      "\n",
      "avg / total       0.91      0.89      0.87        95\n",
      "\n",
      "[79  0 10  6]\n",
      "LR Accuracy:  0.8947368421052632\n",
      "LR F1:  0.7429653679653679\n",
      "For name:  d_tavares\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0002-3196-7922': 4, '0000-0002-6811-9572': 3, '0000-0002-6807-8504': 3, '0000-0002-3358-9443': 2, '0000-0003-4646-5914': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  l_alves\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0001-6245-775X': 14, '0000-0001-5855-2754': 11, '0000-0001-5369-5019': 9, '0000-0002-1972-2658': 5, '0000-0002-7938-9850': 4, '0000-0002-7531-3648': 2, '0000-0002-8944-1851': 2, '0000-0001-8069-6527': 1, '0000-0003-4650-3140': 1, '0000-0002-8400-6148': 1, '0000-0001-6659-6431': 1})\n",
      "['0000-0001-5855-2754', '0000-0001-6245-775X']\n",
      "Total sample size after apply threshold:  25\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 18)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 10)\n",
      "2\n",
      "(25, 28)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.73      0.76        11\n",
      "          1       0.80      0.86      0.83        14\n",
      "\n",
      "avg / total       0.80      0.80      0.80        25\n",
      "\n",
      "[ 8  3  2 12]\n",
      "MNB Accuracy:  0.8\n",
      "MNB F1:  0.794745484400657\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.73      0.70        11\n",
      "          1       0.77      0.71      0.74        14\n",
      "\n",
      "avg / total       0.72      0.72      0.72        25\n",
      "\n",
      "[ 8  3  4 10]\n",
      "svc Accuracy:  0.72\n",
      "svc F1:  0.7181964573268922\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.64      0.67        11\n",
      "          1       0.73      0.79      0.76        14\n",
      "\n",
      "avg / total       0.72      0.72      0.72        25\n",
      "\n",
      "[ 7  4  3 11]\n",
      "LR Accuracy:  0.72\n",
      "LR F1:  0.7126436781609196\n",
      "For name:  s_chan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  176\n",
      "Counter({'0000-0001-8238-798X': 76, '0000-0002-9554-7273': 27, '0000-0002-3270-0525': 19, '0000-0003-0274-7258': 11, '0000-0001-6322-2821': 11, '0000-0002-1568-0489': 11, '0000-0001-8322-7443': 9, '0000-0002-8524-229X': 5, '0000-0002-7707-656X': 3, '0000-0001-5326-2758': 2, '0000-0003-0488-1207': 1, '0000-0002-5193-7560': 1})\n",
      "['0000-0002-3270-0525', '0000-0003-0274-7258', '0000-0002-9554-7273', '0000-0001-8238-798X', '0000-0001-6322-2821', '0000-0002-1568-0489']\n",
      "Total sample size after apply threshold:  155\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(155, 82)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(155, 20)\n",
      "2\n",
      "(155, 102)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.42      0.50        19\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.64      0.59      0.62        27\n",
      "          3       0.62      0.95      0.75        76\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.49      0.62      0.53       155\n",
      "\n",
      "[ 8  0  3  8  0  0  0  0  1 10  0  0  3  0 16  8  0  0  1  0  3 72  0  0\n",
      "  1  0  1  9  0  0  0  0  1 10  0  0]\n",
      "MNB Accuracy:  0.6193548387096774\n",
      "MNB F1:  0.3102497675036535\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.42      0.44        19\n",
      "          1       1.00      0.82      0.90        11\n",
      "          2       0.54      0.48      0.51        27\n",
      "          3       0.69      0.89      0.78        76\n",
      "          4       1.00      0.18      0.31        11\n",
      "          5       1.00      0.36      0.53        11\n",
      "\n",
      "avg / total       0.70      0.67      0.65       155\n",
      "\n",
      "[ 8  0  4  7  0  0  0  9  0  2  0  0  5  0 13  9  0  0  2  0  6 68  0  0\n",
      "  2  0  1  6  2  0  0  0  0  7  0  4]\n",
      "svc Accuracy:  0.6709677419354839\n",
      "svc F1:  0.5787361440302616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.37      0.50        19\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.77      0.37      0.50        27\n",
      "          3       0.58      0.99      0.73        76\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       1.00      0.36      0.53        11\n",
      "\n",
      "avg / total       0.59      0.62      0.55       155\n",
      "\n",
      "[ 7  0  1 11  0  0  0  0  1 10  0  0  1  0 10 16  0  0  0  0  1 75  0  0\n",
      "  1  0  0 10  0  0  0  0  0  7  0  4]\n",
      "LR Accuracy:  0.6193548387096774\n",
      "LR F1:  0.3775067750677507\n",
      "For name:  b_ferreira\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-8565-3101': 10, '0000-0002-6781-2236': 6, '0000-0003-2156-2988': 6, '0000-0002-0221-3160': 3, '0000-0003-1388-5015': 3, '0000-0002-5612-5385': 1})\n",
      "['0000-0002-8565-3101']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  r_neves\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-4866-5215': 19, '0000-0001-6571-5697': 3, '0000-0003-3819-1714': 2, '0000-0003-2032-9308': 1})\n",
      "['0000-0003-4866-5215']\n",
      "Total sample size after apply threshold:  19\n",
      "For name:  m_cardoso\n",
      "total sample size before apply threshold:  105\n",
      "Counter({'0000-0003-0973-3908': 38, '0000-0002-8137-3700': 24, '0000-0003-2102-1225': 16, '0000-0001-7766-7557': 6, '0000-0001-5124-0432': 5, '0000-0001-8676-1115': 4, '0000-0002-3633-1659': 3, '0000-0002-7578-4052': 2, '0000-0002-9132-9703': 2, '0000-0003-4725-2996': 2, '0000-0003-2447-6882': 1, '0000-0003-0150-7359': 1, '0000-0002-8405-7471': 1})\n",
      "['0000-0002-8137-3700', '0000-0003-2102-1225', '0000-0003-0973-3908']\n",
      "Total sample size after apply threshold:  78\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 14)\n",
      "2\n",
      "(78, 62)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.62      0.62        24\n",
      "          1       0.25      0.06      0.10        16\n",
      "          2       0.58      0.76      0.66        38\n",
      "\n",
      "avg / total       0.53      0.58      0.53        78\n",
      "\n",
      "[15  1  8  2  1 13  7  2 29]\n",
      "MNB Accuracy:  0.5769230769230769\n",
      "MNB F1:  0.46136363636363636\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        24\n",
      "          1       0.50      0.31      0.38        16\n",
      "          2       0.64      0.89      0.75        38\n",
      "\n",
      "avg / total       0.72      0.69      0.68        78\n",
      "\n",
      "[15  1  8  0  5 11  0  4 34]\n",
      "svc Accuracy:  0.6923076923076923\n",
      "svc F1:  0.6336996336996338\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.54      0.67        24\n",
      "          1       0.50      0.12      0.20        16\n",
      "          2       0.58      0.89      0.70        38\n",
      "\n",
      "avg / total       0.65      0.63      0.59        78\n",
      "\n",
      "[13  0 11  0  2 14  2  2 34]\n",
      "LR Accuracy:  0.6282051282051282\n",
      "LR F1:  0.5225658648339061\n",
      "For name:  c_shao\n",
      "total sample size before apply threshold:  96\n",
      "Counter({'0000-0003-2618-9342': 61, '0000-0002-6953-2203': 23, '0000-0001-8260-4761': 9, '0000-0002-8691-5177': 3})\n",
      "['0000-0002-6953-2203', '0000-0003-2618-9342']\n",
      "Total sample size after apply threshold:  84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(84, 54)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(84, 18)\n",
      "2\n",
      "(84, 72)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.70      0.73        23\n",
      "          1       0.89      0.92      0.90        61\n",
      "\n",
      "avg / total       0.85      0.86      0.86        84\n",
      "\n",
      "[16  7  5 56]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.81524926686217\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.74      0.72        23\n",
      "          1       0.90      0.89      0.89        61\n",
      "\n",
      "avg / total       0.85      0.85      0.85        84\n",
      "\n",
      "[17  6  7 54]\n",
      "svc Accuracy:  0.8452380952380952\n",
      "svc F1:  0.8079831193951117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.35      0.44        23\n",
      "          1       0.79      0.92      0.85        61\n",
      "\n",
      "avg / total       0.74      0.76      0.74        84\n",
      "\n",
      "[ 8 15  5 56]\n",
      "LR Accuracy:  0.7619047619047619\n",
      "LR F1:  0.6464646464646464\n",
      "For name:  h_yeo\n",
      "total sample size before apply threshold:  10\n",
      "Counter({'0000-0003-2219-3483': 3, '0000-0003-2629-4353': 2, '0000-0002-2684-0978': 2, '0000-0002-1779-069X': 2, '0000-0002-8403-5790': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_goodman\n",
      "total sample size before apply threshold:  100\n",
      "Counter({'0000-0002-5810-1272': 57, '0000-0001-8932-624X': 41, '0000-0003-3880-7822': 1, '0000-0003-1779-4698': 1})\n",
      "['0000-0002-5810-1272', '0000-0001-8932-624X']\n",
      "Total sample size after apply threshold:  98\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 60)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 19)\n",
      "2\n",
      "(98, 79)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.75      0.80        57\n",
      "          1       0.70      0.80      0.75        41\n",
      "\n",
      "avg / total       0.78      0.78      0.78        98\n",
      "\n",
      "[43 14  8 33]\n",
      "MNB Accuracy:  0.7755102040816326\n",
      "MNB F1:  0.7731481481481483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.81      0.85        57\n",
      "          1       0.77      0.88      0.82        41\n",
      "\n",
      "avg / total       0.85      0.84      0.84        98\n",
      "\n",
      "[46 11  5 36]\n",
      "svc Accuracy:  0.8367346938775511\n",
      "svc F1:  0.835016835016835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.84      0.82        57\n",
      "          1       0.76      0.71      0.73        41\n",
      "\n",
      "avg / total       0.78      0.79      0.78        98\n",
      "\n",
      "[48  9 12 29]\n",
      "LR Accuracy:  0.7857142857142857\n",
      "LR F1:  0.7773450178513469\n",
      "For name:  r_dias\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0002-9214-2166': 15, '0000-0001-7921-405X': 7, '0000-0002-6804-7409': 3, '0000-0003-1503-998X': 1})\n",
      "['0000-0002-9214-2166']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  s_sengupta\n",
      "total sample size before apply threshold:  149\n",
      "Counter({'0000-0003-3357-1216': 64, '0000-0002-6365-1770': 31, '0000-0001-7441-5856': 31, '0000-0001-8187-3396': 9, '0000-0002-9665-0088': 7, '0000-0001-7452-979X': 6, '0000-0002-5933-4430': 1})\n",
      "['0000-0002-6365-1770', '0000-0001-7441-5856', '0000-0003-3357-1216']\n",
      "Total sample size after apply threshold:  126\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(126, 54)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(126, 18)\n",
      "2\n",
      "(126, 72)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.48      0.57        31\n",
      "          1       0.73      0.77      0.75        31\n",
      "          2       0.83      0.92      0.87        64\n",
      "\n",
      "avg / total       0.77      0.78      0.77       126\n",
      "\n",
      "[15  6 10  5 24  2  2  3 59]\n",
      "MNB Accuracy:  0.7777777777777778\n",
      "MNB F1:  0.730037269974377\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.58      0.60        31\n",
      "          1       0.79      0.74      0.77        31\n",
      "          2       0.82      0.88      0.85        64\n",
      "\n",
      "avg / total       0.77      0.77      0.77       126\n",
      "\n",
      "[18  3 10  6 23  2  5  3 56]\n",
      "svc Accuracy:  0.7698412698412699\n",
      "svc F1:  0.7383838383838385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.52      0.58        31\n",
      "          1       0.85      0.71      0.77        31\n",
      "          2       0.80      0.95      0.87        64\n",
      "\n",
      "avg / total       0.78      0.79      0.78       126\n",
      "\n",
      "[16  3 12  6 22  3  2  1 61]\n",
      "LR Accuracy:  0.7857142857142857\n",
      "LR F1:  0.7417255259360523\n",
      "For name:  y_jung\n",
      "total sample size before apply threshold:  180\n",
      "Counter({'0000-0002-9686-3120': 85, '0000-0003-2098-8143': 39, '0000-0002-2011-1459': 18, '0000-0002-0781-3608': 9, '0000-0003-0357-9508': 9, '0000-0002-9785-0348': 5, '0000-0002-1743-5049': 4, '0000-0003-0169-2865': 4, '0000-0002-8871-1979': 3, '0000-0002-4778-4629': 2, '0000-0001-6615-6401': 1, '0000-0001-7924-6967': 1})\n",
      "['0000-0002-2011-1459', '0000-0002-9686-3120', '0000-0003-2098-8143']\n",
      "Total sample size after apply threshold:  142\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 80)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 23)\n",
      "2\n",
      "(142, 103)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.33      0.48        18\n",
      "          1       0.78      0.86      0.82        85\n",
      "          2       0.56      0.59      0.57        39\n",
      "\n",
      "avg / total       0.73      0.72      0.71       142\n",
      "\n",
      "[ 6  6  6  0 73 12  1 15 23]\n",
      "MNB Accuracy:  0.7183098591549296\n",
      "MNB F1:  0.6235474860335196\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.44      0.59        18\n",
      "          1       0.73      0.87      0.79        85\n",
      "          2       0.58      0.46      0.51        39\n",
      "\n",
      "avg / total       0.71      0.70      0.69       142\n",
      "\n",
      "[ 8  8  2  0 74 11  1 20 18]\n",
      "svc Accuracy:  0.704225352112676\n",
      "svc F1:  0.6327740523818955\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.33      0.48        18\n",
      "          1       0.69      0.94      0.80        85\n",
      "          2       0.74      0.36      0.48        39\n",
      "\n",
      "avg / total       0.72      0.70      0.67       142\n",
      "\n",
      "[ 6 12  0  0 80  5  1 24 14]\n",
      "LR Accuracy:  0.704225352112676\n",
      "LR F1:  0.5862595070623892\n",
      "For name:  c_franco\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0003-1958-3851': 28, '0000-0003-2288-1518': 18, '0000-0002-2861-3883': 17, '0000-0003-2729-4064': 1})\n",
      "['0000-0003-2288-1518', '0000-0002-2861-3883', '0000-0003-1958-3851']\n",
      "Total sample size after apply threshold:  63\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 14)\n",
      "2\n",
      "(63, 53)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.56      0.63        18\n",
      "          1       0.67      0.35      0.46        17\n",
      "          2       0.62      0.89      0.74        28\n",
      "\n",
      "avg / total       0.66      0.65      0.63        63\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  2  6  2  6  9  2  1 25]\n",
      "MNB Accuracy:  0.6507936507936508\n",
      "MNB F1:  0.6072775263951735\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.67      0.67        18\n",
      "          1       0.64      0.53      0.58        17\n",
      "          2       0.74      0.82      0.78        28\n",
      "\n",
      "avg / total       0.69      0.70      0.69        63\n",
      "\n",
      "[12  3  3  3  9  5  3  2 23]\n",
      "svc Accuracy:  0.6984126984126984\n",
      "svc F1:  0.6756576149687139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.61      0.67        18\n",
      "          1       0.60      0.35      0.44        17\n",
      "          2       0.66      0.89      0.76        28\n",
      "\n",
      "avg / total       0.66      0.67      0.65        63\n",
      "\n",
      "[11  3  4  2  6  9  2  1 25]\n",
      "LR Accuracy:  0.6666666666666666\n",
      "LR F1:  0.622895622895623\n",
      "For name:  v_wong\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0001-6751-7942': 14, '0000-0002-2951-8108': 12, '0000-0001-9356-7556': 8, '0000-0003-2844-3789': 1})\n",
      "['0000-0001-6751-7942', '0000-0002-2951-8108']\n",
      "Total sample size after apply threshold:  26\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 9)\n",
      "2\n",
      "(26, 28)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        14\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[14  0  1 11]\n",
      "MNB Accuracy:  0.9615384615384616\n",
      "MNB F1:  0.9610194902548725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        14\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[14  0  1 11]\n",
      "svc Accuracy:  0.9615384615384616\n",
      "svc F1:  0.9610194902548725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93        14\n",
      "          1       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.93      0.92      0.92        26\n",
      "\n",
      "[14  0  2 10]\n",
      "LR Accuracy:  0.9230769230769231\n",
      "LR F1:  0.9212121212121211\n",
      "For name:  j_feng\n",
      "total sample size before apply threshold:  147\n",
      "Counter({'0000-0003-4762-7532': 102, '0000-0003-1944-718X': 13, '0000-0002-9410-7508': 13, '0000-0002-7141-5823': 12, '0000-0002-5683-849X': 3, '0000-0002-2894-4324': 2, '0000-0002-8662-2198': 1, '0000-0002-6974-2956': 1})\n",
      "['0000-0003-1944-718X', '0000-0003-4762-7532', '0000-0002-7141-5823', '0000-0002-9410-7508']\n",
      "Total sample size after apply threshold:  140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 51)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 21)\n",
      "2\n",
      "(140, 72)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.83      1.00      0.91       102\n",
      "          2       0.71      0.42      0.53        12\n",
      "          3       0.89      0.62      0.73        13\n",
      "\n",
      "avg / total       0.75      0.82      0.77       140\n",
      "\n",
      "[  0  13   0   0   0 102   0   0   1   5   5   1   0   3   2   8]\n",
      "MNB Accuracy:  0.8214285714285714\n",
      "MNB F1:  0.5400637958532696\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.23      0.30        13\n",
      "          1       0.86      1.00      0.93       102\n",
      "          2       0.83      0.42      0.56        12\n",
      "          3       0.89      0.62      0.73        13\n",
      "\n",
      "avg / total       0.82      0.84      0.82       140\n",
      "\n",
      "[  3   8   1   1   0 102   0   0   3   4   5   0   1   4   0   8]\n",
      "svc Accuracy:  0.8428571428571429\n",
      "svc F1:  0.6275252525252526\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.79      1.00      0.88       102\n",
      "          2       1.00      0.42      0.59        12\n",
      "          3       1.00      0.38      0.56        13\n",
      "\n",
      "avg / total       0.75      0.80      0.75       140\n",
      "\n",
      "[  0  13   0   0   0 102   0   0   1   6   5   0   0   8   0   5]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.5067269331975215\n",
      "For name:  s_murugesan\n",
      "total sample size before apply threshold:  7\n",
      "Counter({'0000-0003-0154-2859': 3, '0000-0001-8386-6536': 2, '0000-0003-3045-3513': 1, '0000-0003-4264-1984': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_camacho\n",
      "total sample size before apply threshold:  139\n",
      "Counter({'0000-0002-2507-9814': 81, '0000-0003-3182-5227': 33, '0000-0002-8095-4167': 17, '0000-0001-7528-558X': 8})\n",
      "['0000-0002-8095-4167', '0000-0002-2507-9814', '0000-0003-3182-5227']\n",
      "Total sample size after apply threshold:  131\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(131, 45)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(131, 23)\n",
      "2\n",
      "(131, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.53      0.56        17\n",
      "          1       0.86      0.91      0.89        81\n",
      "          2       0.90      0.82      0.86        33\n",
      "\n",
      "avg / total       0.84      0.84      0.84       131\n",
      "\n",
      "[ 9  8  0  4 74  3  2  4 27]\n",
      "MNB Accuracy:  0.8396946564885496\n",
      "MNB F1:  0.7686234673510123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.82      0.87        17\n",
      "          1       0.94      0.94      0.94        81\n",
      "          2       0.86      0.91      0.88        33\n",
      "\n",
      "avg / total       0.92      0.92      0.92       131\n",
      "\n",
      "[14  3  0  0 76  5  1  2 30]\n",
      "svc Accuracy:  0.916030534351145\n",
      "svc F1:  0.8985415153715807\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        17\n",
      "          1       0.82      0.96      0.89        81\n",
      "          2       0.90      0.79      0.84        33\n",
      "\n",
      "avg / total       0.86      0.85      0.84       131\n",
      "\n",
      "[ 7 10  0  0 78  3  0  7 26]\n",
      "LR Accuracy:  0.8473282442748091\n",
      "LR F1:  0.7694688823721082\n",
      "For name:  b_moreno\n",
      "total sample size before apply threshold:  8\n",
      "Counter({'0000-0001-5799-9802': 6, '0000-0002-8881-4329': 1, '0000-0002-1530-4977': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_andersen\n",
      "total sample size before apply threshold:  129\n",
      "Counter({'0000-0003-1710-1628': 40, '0000-0001-5613-5236': 19, '0000-0001-6300-9086': 19, '0000-0002-8067-3074': 18, '0000-0003-4528-2120': 15, '0000-0001-8902-8162': 6, '0000-0002-6062-7740': 5, '0000-0003-2444-6210': 4, '0000-0003-1402-8162': 2, '0000-0002-4089-4884': 1})\n",
      "['0000-0003-1710-1628', '0000-0001-5613-5236', '0000-0002-8067-3074', '0000-0003-4528-2120', '0000-0001-6300-9086']\n",
      "Total sample size after apply threshold:  111\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 57)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 18)\n",
      "2\n",
      "(111, 75)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.85      0.58        40\n",
      "          1       0.60      0.47      0.53        19\n",
      "          2       0.00      0.00      0.00        18\n",
      "          3       0.80      0.27      0.40        15\n",
      "          4       0.73      0.42      0.53        19\n",
      "\n",
      "avg / total       0.49      0.50      0.45       111\n",
      "\n",
      "[34  2  2  1  1  8  9  0  0  2 18  0  0  0  0  6  4  1  4  0 11  0  0  0\n",
      "  8]\n",
      "MNB Accuracy:  0.4954954954954955\n",
      "MNB F1:  0.40878833584715935\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.90      0.64        40\n",
      "          1       0.90      0.47      0.62        19\n",
      "          2       0.56      0.28      0.37        18\n",
      "          3       0.83      0.33      0.48        15\n",
      "          4       0.92      0.63      0.75        19\n",
      "\n",
      "avg / total       0.69      0.60      0.59       111\n",
      "\n",
      "[36  0  2  1  1 10  9  0  0  0 13  0  5  0  0  7  1  2  5  0  7  0  0  0\n",
      " 12]\n",
      "svc Accuracy:  0.6036036036036037\n",
      "svc F1:  0.5708837286652362\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.85      0.58        40\n",
      "          1       0.60      0.47      0.53        19\n",
      "          2       0.25      0.06      0.09        18\n",
      "          3       0.60      0.20      0.30        15\n",
      "          4       0.90      0.47      0.62        19\n",
      "\n",
      "avg / total       0.54      0.50      0.46       111\n",
      "\n",
      "[34  2  2  1  1 10  9  0  0  0 17  0  1  0  0  7  4  1  3  0  9  0  0  1\n",
      "  9]\n",
      "LR Accuracy:  0.5045045045045045\n",
      "LR F1:  0.42444141839679367\n",
      "For name:  j_bell\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0003-1455-3274': 15, '0000-0002-1926-7501': 10, '0000-0001-5480-7975': 5, '0000-0002-0233-9708': 3, '0000-0002-6145-5821': 1})\n",
      "['0000-0002-1926-7501', '0000-0003-1455-3274']\n",
      "Total sample size after apply threshold:  25\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 18)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 12)\n",
      "2\n",
      "(25, 30)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.40      0.50        10\n",
      "          1       0.68      0.87      0.76        15\n",
      "\n",
      "avg / total       0.68      0.68      0.66        25\n",
      "\n",
      "[ 4  6  2 13]\n",
      "MNB Accuracy:  0.68\n",
      "MNB F1:  0.6323529411764707\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.60      0.67        10\n",
      "          1       0.76      0.87      0.81        15\n",
      "\n",
      "avg / total       0.76      0.76      0.75        25\n",
      "\n",
      "[ 6  4  2 13]\n",
      "svc Accuracy:  0.76\n",
      "svc F1:  0.7395833333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.20      0.29        10\n",
      "          1       0.62      0.87      0.72        15\n",
      "\n",
      "avg / total       0.57      0.60      0.55        25\n",
      "\n",
      "[ 2  8  2 13]\n",
      "LR Accuracy:  0.6\n",
      "LR F1:  0.503968253968254\n",
      "For name:  m_bull\n",
      "total sample size before apply threshold:  5\n",
      "Counter({'0000-0002-4804-9992': 3, '0000-0002-9388-0021': 1, '0000-0002-2324-1195': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_gandhi\n",
      "total sample size before apply threshold:  9\n",
      "Counter({'0000-0002-9759-1745': 4, '0000-0002-3650-3780': 2, '0000-0002-6867-1447': 2, '0000-0002-6762-0867': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_yang\n",
      "total sample size before apply threshold:  514\n",
      "Counter({'0000-0002-4328-8716': 71, '0000-0002-3476-3802': 53, '0000-0001-6312-3719': 48, '0000-0003-4082-420X': 42, '0000-0002-0352-3144': 41, '0000-0001-9138-3075': 32, '0000-0001-8558-062X': 25, '0000-0003-0475-8399': 18, '0000-0001-5990-1346': 17, '0000-0002-2792-6247': 17, '0000-0002-6238-2871': 17, '0000-0003-0561-2340': 15, '0000-0001-8144-8496': 13, '0000-0001-8109-4974': 13, '0000-0002-9147-3879': 12, '0000-0002-8613-3597': 12, '0000-0002-0521-4230': 11, '0000-0003-4927-4814': 10, '0000-0002-5542-7576': 6, '0000-0003-0760-9209': 5, '0000-0002-0487-0420': 5, '0000-0002-3527-6600': 5, '0000-0003-1163-321X': 3, '0000-0003-3368-3082': 3, '0000-0002-5527-6819': 3, '0000-0002-6815-3316': 3, '0000-0003-3456-0455': 2, '0000-0001-5463-6926': 2, '0000-0001-6067-7505': 2, '0000-0002-9579-4426': 2, '0000-0002-2196-6854': 2, '0000-0002-5682-8531': 1, '0000-0002-1380-9533': 1, '0000-0001-7768-4066': 1, '0000-0001-5615-2693': 1})\n",
      "['0000-0002-3476-3802', '0000-0003-0561-2340', '0000-0001-8144-8496', '0000-0002-0352-3144', '0000-0002-4328-8716', '0000-0001-8109-4974', '0000-0002-9147-3879', '0000-0002-8613-3597', '0000-0003-4082-420X', '0000-0001-5990-1346', '0000-0003-4927-4814', '0000-0002-0521-4230', '0000-0001-9138-3075', '0000-0001-8558-062X', '0000-0001-6312-3719', '0000-0003-0475-8399', '0000-0002-2792-6247', '0000-0002-6238-2871']\n",
      "Total sample size after apply threshold:  467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(467, 211)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(467, 22)\n",
      "2\n",
      "(467, 233)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.87      0.69        53\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.47      0.44      0.46        41\n",
      "          4       0.29      0.83      0.43        71\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       1.00      0.50      0.67        12\n",
      "          7       0.00      0.00      0.00        12\n",
      "          8       0.54      0.31      0.39        42\n",
      "          9       0.00      0.00      0.00        17\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       1.00      0.09      0.17        11\n",
      "         12       0.79      0.59      0.68        32\n",
      "         13       0.89      0.32      0.47        25\n",
      "         14       0.32      0.46      0.38        48\n",
      "         15       1.00      0.61      0.76        18\n",
      "         16       1.00      0.12      0.21        17\n",
      "         17       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.46      0.44      0.39       467\n",
      "\n",
      "[46  0  0  1  3  0  0  0  0  0  0  0  0  0  3  0  0  0  4  0  0  1  7  0\n",
      "  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  2  4  0  0  0  0  0  0  0\n",
      "  0  0  7  0  0  0  3  0  0 18 15  0  0  0  0  0  0  0  2  0  3  0  0  0\n",
      "  1  0  0  1 59  0  0  0  4  0  0  0  0  0  6  0  0  0  4  0  0  0  4  0\n",
      "  0  0  1  0  0  0  0  0  4  0  0  0  2  0  0  0  2  0  6  0  0  0  0  0\n",
      "  0  0  2  0  0  0  4  0  0  1  6  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
      "  3  0  0  3 22  0  0  0 13  0  0  0  0  0  1  0  0  0  1  0  0  2 11  0\n",
      "  0  0  0  0  0  0  0  0  3  0  0  0  1  0  0  0  7  0  0  0  1  0  0  0\n",
      "  0  0  1  0  0  0  0  0  0  1  7  0  0  0  0  0  0  1  0  0  2  0  0  0\n",
      "  1  0  0  2  8  0  0  0  0  0  0  0 19  1  1  0  0  0  2  0  0  0  8  0\n",
      "  0  0  0  0  0  0  2  8  5  0  0  0  4  0  0  2 17  0  0  0  3  0  0  0\n",
      "  0  0 22  0  0  0  0  0  0  3  3  0  0  0  0  0  0  0  0  0  1 11  0  0\n",
      "  3  0  0  1  9  0  0  0  1  0  0  0  0  0  1  0  2  0  1  0  0  0 12  0\n",
      "  0  0  1  0  0  0  0  0  3  0  0  0]\n",
      "MNB Accuracy:  0.43897216274089934\n",
      "MNB F1:  0.29452256535229615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.89      0.93        53\n",
      "          1       0.29      0.40      0.33        15\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.32      0.61      0.42        41\n",
      "          4       0.61      0.80      0.69        71\n",
      "          5       1.00      0.38      0.56        13\n",
      "          6       1.00      0.75      0.86        12\n",
      "          7       1.00      0.17      0.29        12\n",
      "          8       0.55      0.26      0.35        42\n",
      "          9       0.25      0.06      0.10        17\n",
      "         10       1.00      0.20      0.33        10\n",
      "         11       0.83      0.45      0.59        11\n",
      "         12       0.74      0.78      0.76        32\n",
      "         13       1.00      0.68      0.81        25\n",
      "         14       0.35      0.73      0.48        48\n",
      "         15       0.93      0.78      0.85        18\n",
      "         16       0.29      0.12      0.17        17\n",
      "         17       0.40      0.12      0.18        17\n",
      "\n",
      "avg / total       0.62      0.57      0.55       467\n",
      "\n",
      "[47  1  0  3  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  6  0  4  1  0\n",
      "  0  0  0  0  0  0  0  0  3  0  1  0  0  0  0  4  1  0  0  0  0  0  0  0\n",
      "  0  0  8  0  0  0  0  2  1 25  3  0  0  0  2  0  0  0  2  0  6  0  0  0\n",
      "  0  0  0  3 57  0  0  0  5  0  0  0  0  0  6  0  0  0  0  2  0  1  2  5\n",
      "  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0\n",
      "  0  0  3  0  0  0  0  3  0  4  1  0  0  2  0  0  0  0  0  0  2  0  0  0\n",
      "  0  0  0  4 21  0  0  0 11  2  0  0  0  0  4  0  0  0  0  0  0  7  2  0\n",
      "  0  0  0  1  0  0  1  0  6  0  0  0  0  1  0  0  2  0  0  0  0  0  2  0\n",
      "  0  0  5  0  0  0  0  1  0  2  0  0  0  0  0  0  0  5  0  0  1  0  0  2\n",
      "  0  1  0  4  0  0  0  0  0  1  0  0 25  0  0  0  1  0  0  1  0  3  0  0\n",
      "  0  0  0  0  0  0  2 17  2  0  0  0  1  0  0  5  1  0  0  0  2  0  0  0\n",
      "  2  0 35  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4 14  0  0\n",
      "  0  3  0  4  1  0  0  0  0  0  0  0  1  0  4  1  2  1  0  0  0  5  2  0\n",
      "  0  0  0  0  0  1  1  0  5  0  1  2]\n",
      "svc Accuracy:  0.5674518201284796\n",
      "svc F1:  0.48252341287862105\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.85      0.91        53\n",
      "          1       0.33      0.20      0.25        15\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.37      0.51      0.43        41\n",
      "          4       0.41      0.83      0.55        71\n",
      "          5       1.00      0.23      0.38        13\n",
      "          6       1.00      0.67      0.80        12\n",
      "          7       1.00      0.17      0.29        12\n",
      "          8       0.50      0.33      0.40        42\n",
      "          9       0.00      0.00      0.00        17\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       0.75      0.27      0.40        11\n",
      "         12       0.83      0.78      0.81        32\n",
      "         13       1.00      0.52      0.68        25\n",
      "         14       0.30      0.60      0.40        48\n",
      "         15       1.00      0.67      0.80        18\n",
      "         16       0.60      0.18      0.27        17\n",
      "         17       0.50      0.12      0.19        17\n",
      "\n",
      "avg / total       0.58      0.52      0.50       467\n",
      "\n",
      "[45  0  0  1  3  0  0  0  0  0  0  0  0  0  4  0  0  0  0  3  0  3  6  0\n",
      "  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  4  2  0  0  0  0  0  0  0\n",
      "  0  0  7  0  0  0  0  2  1 21  8  0  0  0  1  2  0  0  1  0  5  0  0  0\n",
      "  0  0  0  2 59  0  0  0  4  0  0  0  0  0  6  0  0  0  0  0  0  1  4  3\n",
      "  0  0  1  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0\n",
      "  0  0  4  0  0  0  0  1  0  2  5  0  0  2  0  0  0  0  1  0  1  0  0  0\n",
      "  0  0  0  4 21  0  0  0 14  0  0  0  0  0  3  0  0  0  0  0  0  2  8  0\n",
      "  0  0  1  0  0  0  0  0  6  0  0  0  0  1  0  0  3  0  0  0  1  0  0  0\n",
      "  0  0  5  0  0  0  0  0  0  2  2  0  0  0  1  0  0  3  0  0  2  0  0  1\n",
      "  0  0  0  2  5  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0  1  2  0\n",
      "  0  0  0  0  0  0  2 13  7  0  0  0  1  0  0  5  9  0  0  0  3  0  0  0\n",
      "  0  0 29  0  1  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  4 12  0  0\n",
      "  0  2  0  3  2  0  0  0  1  0  0  0  1  0  4  0  3  1  0  0  0  2  6  0\n",
      "  0  0  1  0  0  1  0  0  4  0  1  2]\n",
      "LR Accuracy:  0.5182012847965739\n",
      "LR F1:  0.4192110442260001\n",
      "For name:  s_paul\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0002-9693-2915': 23, '0000-0001-7560-5512': 8, '0000-0003-1274-6670': 7, '0000-0002-8813-0437': 5, '0000-0003-4104-9209': 4, '0000-0002-7077-8235': 4, '0000-0001-9601-9109': 1})\n",
      "['0000-0002-9693-2915']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  l_roberts\n",
      "total sample size before apply threshold:  363\n",
      "Counter({'0000-0003-4270-253X': 206, '0000-0001-7885-8574': 120, '0000-0002-1455-5248': 18, '0000-0003-0085-9213': 14, '0000-0003-3892-2900': 3, '0000-0002-0329-8389': 2})\n",
      "['0000-0003-4270-253X', '0000-0003-0085-9213', '0000-0002-1455-5248', '0000-0001-7885-8574']\n",
      "Total sample size after apply threshold:  358\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(358, 134)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(358, 23)\n",
      "2\n",
      "(358, 157)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.93      0.87       206\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.00      0.00      0.00        18\n",
      "          3       0.77      0.80      0.79       120\n",
      "\n",
      "avg / total       0.73      0.80      0.76       358\n",
      "\n",
      "[191   0   0  15  10   0   0   4   9   0   0   9  24   0   0  96]\n",
      "MNB Accuracy:  0.8016759776536313\n",
      "MNB F1:  0.4137667660208644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.91      0.90       206\n",
      "          1       1.00      0.21      0.35        14\n",
      "          2       0.75      0.17      0.27        18\n",
      "          3       0.74      0.87      0.80       120\n",
      "\n",
      "avg / total       0.84      0.83      0.81       358\n",
      "\n",
      "[187   0   0  19   5   3   0   6   4   0   3  11  15   0   1 104]\n",
      "svc Accuracy:  0.8296089385474861\n",
      "svc F1:  0.5806377358006642\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.89       206\n",
      "          1       1.00      0.21      0.35        14\n",
      "          2       0.00      0.00      0.00        18\n",
      "          3       0.74      0.85      0.79       120\n",
      "\n",
      "avg / total       0.79      0.82      0.79       358\n",
      "\n",
      "[189   0   0  17   5   3   0   6   5   0   0  13  18   0   0 102]\n",
      "LR Accuracy:  0.8212290502793296\n",
      "LR F1:  0.5093139680414471\n",
      "For name:  s_keating\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-8324-3694': 28, '0000-0002-3356-3542': 14, '0000-0001-5357-2721': 10, '0000-0003-3685-2849': 1, '0000-0002-6817-925X': 1})\n",
      "['0000-0002-3356-3542', '0000-0002-8324-3694', '0000-0001-5357-2721']\n",
      "Total sample size after apply threshold:  52\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 33)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 13)\n",
      "2\n",
      "(52, 46)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.43      0.50        14\n",
      "          1       0.76      1.00      0.86        28\n",
      "          2       0.80      0.40      0.53        10\n",
      "\n",
      "avg / total       0.72      0.73      0.70        52\n",
      "\n",
      "[ 6  7  1  0 28  0  4  2  4]\n",
      "MNB Accuracy:  0.7307692307692307\n",
      "MNB F1:  0.6316239316239316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.43      0.52        14\n",
      "          1       0.76      1.00      0.86        28\n",
      "          2       0.67      0.40      0.50        10\n",
      "\n",
      "avg / total       0.72      0.73      0.70        52\n",
      "\n",
      "[ 6  6  2  0 28  0  3  3  4]\n",
      "svc Accuracy:  0.7307692307692307\n",
      "svc F1:  0.6277591973244148\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.29      0.38        14\n",
      "          1       0.72      1.00      0.84        28\n",
      "          2       0.67      0.40      0.50        10\n",
      "\n",
      "avg / total       0.67      0.69      0.65        52\n",
      "\n",
      "[ 4  8  2  0 28  0  3  3  4]\n",
      "LR Accuracy:  0.6923076923076923\n",
      "LR F1:  0.572257758824923\n",
      "For name:  a_bennett\n",
      "total sample size before apply threshold:  56\n",
      "Counter({'0000-0003-3829-0309': 51, '0000-0001-8895-6418': 2, '0000-0001-7448-8182': 1, '0000-0003-4194-9741': 1, '0000-0001-6968-9465': 1})\n",
      "['0000-0003-3829-0309']\n",
      "Total sample size after apply threshold:  51\n",
      "For name:  a_aggarwal\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0003-3096-3206': 10, '0000-0002-1755-8807': 6, '0000-0002-6696-0296': 5, '0000-0003-0458-5619': 1})\n",
      "['0000-0003-3096-3206']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  i_moura\n",
      "total sample size before apply threshold:  203\n",
      "Counter({'0000-0003-0971-4977': 149, '0000-0002-2977-0354': 48, '0000-0002-3019-7196': 5, '0000-0001-7859-1881': 1})\n",
      "['0000-0002-2977-0354', '0000-0003-0971-4977']\n",
      "Total sample size after apply threshold:  197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(197, 71)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(197, 29)\n",
      "2\n",
      "(197, 100)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.52      0.65        48\n",
      "          1       0.86      0.97      0.91       149\n",
      "\n",
      "avg / total       0.86      0.86      0.85       197\n",
      "\n",
      "[ 25  23   4 145]\n",
      "MNB Accuracy:  0.8629441624365483\n",
      "MNB F1:  0.7820885738866812\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.65      0.76        48\n",
      "          1       0.90      0.98      0.94       149\n",
      "\n",
      "avg / total       0.90      0.90      0.89       197\n",
      "\n",
      "[ 31  17   3 146]\n",
      "svc Accuracy:  0.8984771573604061\n",
      "svc F1:  0.8459974984365228\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.33      0.49        48\n",
      "          1       0.82      0.99      0.90       149\n",
      "\n",
      "avg / total       0.85      0.83      0.80       197\n",
      "\n",
      "[ 16  32   1 148]\n",
      "LR Accuracy:  0.8324873096446701\n",
      "LR F1:  0.6960018704699555\n",
      "For name:  d_teixeira\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0003-1799-1675': 13, '0000-0002-2162-1450': 12, '0000-0003-2110-4725': 1, '0000-0001-8172-7911': 1})\n",
      "['0000-0003-1799-1675', '0000-0002-2162-1450']\n",
      "Total sample size after apply threshold:  25\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 14)\n",
      "2\n",
      "(25, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.69      0.69        13\n",
      "          1       0.67      0.67      0.67        12\n",
      "\n",
      "avg / total       0.68      0.68      0.68        25\n",
      "\n",
      "[9 4 4 8]\n",
      "MNB Accuracy:  0.68\n",
      "MNB F1:  0.6794871794871795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.46      0.52        13\n",
      "          1       0.53      0.67      0.59        12\n",
      "\n",
      "avg / total       0.57      0.56      0.56        25\n",
      "\n",
      "[6 7 4 8]\n",
      "svc Accuracy:  0.56\n",
      "svc F1:  0.5571658615136876\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.62      0.64        13\n",
      "          1       0.62      0.67      0.64        12\n",
      "\n",
      "avg / total       0.64      0.64      0.64        25\n",
      "\n",
      "[8 5 4 8]\n",
      "LR Accuracy:  0.64\n",
      "LR F1:  0.64\n",
      "For name:  c_klein\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0003-3522-9182': 47, '0000-0002-8230-8038': 21, '0000-0003-2991-1791': 11, '0000-0002-7580-8536': 11, '0000-0001-9736-5994': 9, '0000-0003-1305-0114': 5, '0000-0002-7406-4010': 2})\n",
      "['0000-0003-2991-1791', '0000-0003-3522-9182', '0000-0002-7580-8536', '0000-0002-8230-8038']\n",
      "Total sample size after apply threshold:  90\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(90, 51)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(90, 20)\n",
      "2\n",
      "(90, 71)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.64      0.94      0.76        47\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.71      0.48      0.57        21\n",
      "\n",
      "avg / total       0.62      0.67      0.62        90\n",
      "\n",
      "[ 6  4  0  1  0 44  1  2  0 10  0  1  0 11  0 10]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.5089829035062301\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.74      0.91      0.82        47\n",
      "          2       0.50      0.09      0.15        11\n",
      "          3       0.59      0.62      0.60        21\n",
      "\n",
      "avg / total       0.71      0.72      0.69        90\n",
      "\n",
      "[ 8  1  0  2  0 43  1  3  0  6  1  4  0  8  0 13]\n",
      "svc Accuracy:  0.7222222222222222\n",
      "svc F1:  0.6049125497105914\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.63      0.96      0.76        47\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.69      0.43      0.53        21\n",
      "\n",
      "avg / total       0.61      0.67      0.61        90\n",
      "\n",
      "[ 6  4  0  1  0 45  0  2  0 10  0  1  0 12  0  9]\n",
      "LR Accuracy:  0.6666666666666666\n",
      "LR F1:  0.49950149551345957\n",
      "For name:  m_andersson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0001-7582-8791': 40, '0000-0002-7928-8216': 27, '0000-0003-4279-6572': 26, '0000-0002-4921-1461': 15, '0000-0002-3364-6647': 14, '0000-0002-1450-8046': 11, '0000-0002-7267-8377': 9, '0000-0003-3699-138X': 8, '0000-0003-0619-1074': 1, '0000-0001-5057-4908': 1})\n",
      "['0000-0002-1450-8046', '0000-0003-4279-6572', '0000-0001-7582-8791', '0000-0002-3364-6647', '0000-0002-4921-1461', '0000-0002-7928-8216']\n",
      "Total sample size after apply threshold:  133\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 79)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 28)\n",
      "2\n",
      "(133, 107)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.41      0.46      0.44        26\n",
      "          2       0.65      0.70      0.67        40\n",
      "          3       1.00      0.07      0.13        14\n",
      "          4       0.33      0.33      0.33        15\n",
      "          5       0.45      0.74      0.56        27\n",
      "\n",
      "avg / total       0.51      0.50      0.45       133\n",
      "\n",
      "[ 0  2  0  0  2  7  0 12  9  0  3  2  0  7 28  0  2  3  1  2  1  1  2  7\n",
      "  0  4  1  0  5  5  0  2  4  0  1 20]\n",
      "MNB Accuracy:  0.49624060150375937\n",
      "MNB F1:  0.35685156331686113\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.18      0.25        11\n",
      "          1       0.33      0.50      0.39        26\n",
      "          2       0.78      0.78      0.78        40\n",
      "          3       0.40      0.14      0.21        14\n",
      "          4       0.67      0.53      0.59        15\n",
      "          5       0.58      0.67      0.62        27\n",
      "\n",
      "avg / total       0.56      0.56      0.55       133\n",
      "\n",
      "[ 2  6  0  1  0  2  2 13  8  0  2  1  0  7 31  0  0  2  0  6  0  2  1  5\n",
      "  0  4  0  0  8  3  1  4  1  2  1 18]\n",
      "svc Accuracy:  0.556390977443609\n",
      "svc F1:  0.47379132624897896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.18      0.27        11\n",
      "          1       0.47      0.35      0.40        26\n",
      "          2       0.61      0.88      0.72        40\n",
      "          3       1.00      0.14      0.25        14\n",
      "          4       0.41      0.47      0.44        15\n",
      "          5       0.53      0.67      0.59        27\n",
      "\n",
      "avg / total       0.58      0.55      0.51       133\n",
      "\n",
      "[ 2  2  0  0  2  5  0  9 12  0  3  2  0  1 35  0  1  3  1  2  2  2  3  4\n",
      "  0  4  2  0  7  2  1  1  6  0  1 18]\n",
      "LR Accuracy:  0.5488721804511278\n",
      "LR F1:  0.4443300142714965\n",
      "For name:  h_shi\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0001-8421-0002': 5, '0000-0003-1920-5914': 4, '0000-0002-9523-7742': 4, '0000-0003-0713-4688': 4, '0000-0001-6269-742X': 2, '0000-0003-3831-6898': 1, '0000-0001-6482-8403': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_howard\n",
      "total sample size before apply threshold:  79\n",
      "Counter({'0000-0001-9516-9551': 31, '0000-0001-9141-5751': 28, '0000-0002-4907-4292': 19, '0000-0003-3333-9783': 1})\n",
      "['0000-0001-9141-5751', '0000-0002-4907-4292', '0000-0001-9516-9551']\n",
      "Total sample size after apply threshold:  78\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 38)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 25)\n",
      "2\n",
      "(78, 63)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.61      0.65        28\n",
      "          1       0.78      0.37      0.50        19\n",
      "          2       0.64      0.94      0.76        31\n",
      "\n",
      "avg / total       0.70      0.68      0.66        78\n",
      "\n",
      "[17  2  9  5  7  7  2  0 29]\n",
      "MNB Accuracy:  0.6794871794871795\n",
      "MNB F1:  0.6390013495276653\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.79      0.66        28\n",
      "          1       0.73      0.42      0.53        19\n",
      "          2       0.89      0.81      0.85        31\n",
      "\n",
      "avg / total       0.73      0.71      0.70        78\n",
      "\n",
      "[22  3  3 11  8  0  6  0 25]\n",
      "svc Accuracy:  0.7051282051282052\n",
      "svc F1:  0.6791691261208084\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.79      0.67        28\n",
      "          1       0.80      0.42      0.55        19\n",
      "          2       0.83      0.81      0.82        31\n",
      "\n",
      "avg / total       0.73      0.71      0.70        78\n",
      "\n",
      "[22  2  4 10  8  1  6  0 25]\n",
      "LR Accuracy:  0.7051282051282052\n",
      "LR F1:  0.6793543119150808\n",
      "For name:  j_thomsen\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-9336-5695': 18, '0000-0003-2143-8274': 8, '0000-0002-7368-6133': 1, '0000-0002-8275-4847': 1})\n",
      "['0000-0002-9336-5695']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  v_gupta\n",
      "total sample size before apply threshold:  238\n",
      "Counter({'0000-0002-8850-0485': 63, '0000-0002-6139-1346': 38, '0000-0002-1348-3545': 30, '0000-0002-9190-1757': 26, '0000-0003-4639-3316': 22, '0000-0001-6987-2550': 14, '0000-0002-6157-3705': 14, '0000-0002-1518-6624': 8, '0000-0002-2089-027X': 6, '0000-0003-2809-2966': 5, '0000-0003-1567-1037': 3, '0000-0001-7184-4663': 3, '0000-0003-1565-5918': 3, '0000-0003-2824-3402': 1, '0000-0001-6804-3830': 1, '0000-0001-6955-9134': 1})\n",
      "['0000-0001-6987-2550', '0000-0003-4639-3316', '0000-0002-6157-3705', '0000-0002-8850-0485', '0000-0002-1348-3545', '0000-0002-9190-1757', '0000-0002-6139-1346']\n",
      "Total sample size after apply threshold:  207\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(207, 110)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(207, 19)\n",
      "2\n",
      "(207, 129)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25        14\n",
      "          1       0.48      0.50      0.49        22\n",
      "          2       1.00      0.14      0.25        14\n",
      "          3       0.63      0.87      0.73        63\n",
      "          4       0.69      0.67      0.68        30\n",
      "          5       0.45      0.35      0.39        26\n",
      "          6       0.61      0.71      0.66        38\n",
      "\n",
      "avg / total       0.65      0.61      0.58       207\n",
      "\n",
      "[ 2  2  0  4  1  2  3  0 11  0  8  1  2  0  0  0  2  3  2  3  4  0  2  0\n",
      " 55  0  1  5  0  3  0  4 20  1  2  0  3  0  8  3  9  3  0  2  0  5  2  2\n",
      " 27]\n",
      "MNB Accuracy:  0.6086956521739131\n",
      "MNB F1:  0.49286132244415404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.29      0.42        14\n",
      "          1       0.76      0.59      0.67        22\n",
      "          2       1.00      0.43      0.60        14\n",
      "          3       0.73      0.87      0.80        63\n",
      "          4       1.00      0.73      0.85        30\n",
      "          5       0.43      0.50      0.46        26\n",
      "          6       0.54      0.74      0.62        38\n",
      "\n",
      "avg / total       0.72      0.68      0.68       207\n",
      "\n",
      "[ 4  0  0  3  0  4  3  0 13  0  4  0  3  2  0  0  6  2  0  1  5  0  1  0\n",
      " 55  0  3  4  0  0  0  2 22  2  4  0  2  0  5  0 13  6  1  1  0  4  0  4\n",
      " 28]\n",
      "svc Accuracy:  0.6811594202898551\n",
      "svc F1:  0.6310689328832514\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25        14\n",
      "          1       1.00      0.55      0.71        22\n",
      "          2       1.00      0.29      0.44        14\n",
      "          3       0.62      0.90      0.74        63\n",
      "          4       0.83      0.67      0.74        30\n",
      "          5       0.40      0.38      0.39        26\n",
      "          6       0.58      0.74      0.65        38\n",
      "\n",
      "avg / total       0.71      0.64      0.62       207\n",
      "\n",
      "[ 2  0  0  5  0  4  3  0 12  0  6  0  3  1  0  0  4  3  0  2  5  0  0  0\n",
      " 57  0  1  5  0  0  0  4 20  3  3  0  0  0 11  2 10  3  0  0  0  6  2  2\n",
      " 28]\n",
      "LR Accuracy:  0.642512077294686\n",
      "LR F1:  0.559981580362411\n",
      "For name:  j_manning\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-7613-4732': 8, '0000-0002-6077-4169': 6, '0000-0002-3572-8005': 1, '0000-0003-2257-6556': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_wood\n",
      "total sample size before apply threshold:  97\n",
      "Counter({'0000-0002-9495-6892': 82, '0000-0002-1694-3295': 11, '0000-0002-7906-3324': 2, '0000-0002-3476-395X': 1, '0000-0001-6389-1048': 1})\n",
      "['0000-0002-9495-6892', '0000-0002-1694-3295']\n",
      "Total sample size after apply threshold:  93\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(93, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(93, 28)\n",
      "2\n",
      "(93, 63)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.95        82\n",
      "          1       0.62      0.45      0.53        11\n",
      "\n",
      "avg / total       0.89      0.90      0.90        93\n",
      "\n",
      "[79  3  6  5]\n",
      "MNB Accuracy:  0.9032258064516129\n",
      "MNB F1:  0.736211786952411\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.95        82\n",
      "          1       0.62      0.45      0.53        11\n",
      "\n",
      "avg / total       0.89      0.90      0.90        93\n",
      "\n",
      "[79  3  6  5]\n",
      "svc Accuracy:  0.9032258064516129\n",
      "svc F1:  0.736211786952411\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95        82\n",
      "          1       0.67      0.36      0.47        11\n",
      "\n",
      "avg / total       0.89      0.90      0.89        93\n",
      "\n",
      "[80  2  7  4]\n",
      "LR Accuracy:  0.9032258064516129\n",
      "LR F1:  0.7086668987121476\n",
      "For name:  y_ding\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0003-1352-1000': 21, '0000-0002-6823-4722': 21, '0000-0001-7772-6449': 19, '0000-0002-8845-4618': 15, '0000-0001-7461-0213': 8, '0000-0001-8161-2743': 7, '0000-0003-4761-5486': 4, '0000-0003-0465-7870': 4, '0000-0003-1176-6397': 3, '0000-0001-8312-8672': 2, '0000-0002-9713-5694': 1, '0000-0002-0010-8279': 1})\n",
      "['0000-0003-1352-1000', '0000-0002-6823-4722', '0000-0002-8845-4618', '0000-0001-7772-6449']\n",
      "Total sample size after apply threshold:  76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(76, 38)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(76, 13)\n",
      "2\n",
      "(76, 51)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.67      0.70        21\n",
      "          1       0.74      0.95      0.83        21\n",
      "          2       0.78      0.93      0.85        15\n",
      "          3       0.92      0.58      0.71        19\n",
      "\n",
      "avg / total       0.79      0.78      0.77        76\n",
      "\n",
      "[14  4  2  1  1 20  0  0  0  1 14  0  4  2  2 11]\n",
      "MNB Accuracy:  0.7763157894736842\n",
      "MNB F1:  0.7728739002932552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.81      0.72        21\n",
      "          1       1.00      0.90      0.95        21\n",
      "          2       1.00      0.93      0.97        15\n",
      "          3       0.71      0.63      0.67        19\n",
      "\n",
      "avg / total       0.83      0.82      0.82        76\n",
      "\n",
      "[17  0  0  4  1 19  0  1  1  0 14  0  7  0  0 12]\n",
      "svc Accuracy:  0.8157894736842105\n",
      "svc F1:  0.8263970408412815\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.71      0.67        21\n",
      "          1       0.90      0.86      0.88        21\n",
      "          2       0.82      0.93      0.87        15\n",
      "          3       0.80      0.63      0.71        19\n",
      "\n",
      "avg / total       0.78      0.78      0.78        76\n",
      "\n",
      "[15  1  2  3  2 18  1  0  1  0 14  0  6  1  0 12]\n",
      "LR Accuracy:  0.7763157894736842\n",
      "LR F1:  0.781399450023912\n",
      "For name:  j_rasmussen\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0002-3543-690X': 15, '0000-0001-6997-3773': 9, '0000-0003-2898-1771': 6, '0000-0002-8389-6935': 1, '0000-0003-3426-551X': 1, '0000-0003-3257-5653': 1})\n",
      "['0000-0002-3543-690X']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  n_lee\n",
      "total sample size before apply threshold:  108\n",
      "Counter({'0000-0002-5011-7499': 74, '0000-0002-6663-0713': 20, '0000-0003-2628-6599': 12, '0000-0001-8009-2694': 1, '0000-0002-2756-1102': 1})\n",
      "['0000-0003-2628-6599', '0000-0002-5011-7499', '0000-0002-6663-0713']\n",
      "Total sample size after apply threshold:  106\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 63)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 11)\n",
      "2\n",
      "(106, 74)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.76      1.00      0.87        74\n",
      "          2       0.80      0.20      0.32        20\n",
      "\n",
      "avg / total       0.80      0.77      0.72       106\n",
      "\n",
      "[ 4  7  1  0 74  0  0 16  4]\n",
      "MNB Accuracy:  0.7735849056603774\n",
      "MNB F1:  0.5618323586744639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.42      0.56        12\n",
      "          1       0.81      1.00      0.90        74\n",
      "          2       0.89      0.40      0.55        20\n",
      "\n",
      "avg / total       0.83      0.82      0.79       106\n",
      "\n",
      "[ 5  6  1  0 74  0  1 11  8]\n",
      "svc Accuracy:  0.8207547169811321\n",
      "svc F1:  0.6680831301520956\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.73      1.00      0.85        74\n",
      "          2       1.00      0.05      0.10        20\n",
      "\n",
      "avg / total       0.81      0.75      0.66       106\n",
      "\n",
      "[ 4  8  0  0 74  0  0 19  1]\n",
      "LR Accuracy:  0.7452830188679245\n",
      "LR F1:  0.4803174603174603\n",
      "For name:  a_oliveira\n",
      "total sample size before apply threshold:  302\n",
      "Counter({'0000-0001-9103-6532': 41, '0000-0003-2186-8100': 24, '0000-0002-6714-5939': 24, '0000-0002-0107-9940': 24, '0000-0001-8012-4203': 20, '0000-0001-8638-5594': 20, '0000-0003-3787-9138': 12, '0000-0003-2790-6294': 12, '0000-0001-6837-5739': 10, '0000-0001-5445-1032': 8, '0000-0001-8753-4950': 8, '0000-0002-7898-5503': 7, '0000-0003-4516-6904': 6, '0000-0003-3162-250X': 6, '0000-0002-0330-3643': 5, '0000-0003-1554-4687': 5, '0000-0003-0402-2971': 5, '0000-0003-4158-6098': 5, '0000-0002-0747-7835': 4, '0000-0002-6477-5345': 4, '0000-0002-0841-4844': 4, '0000-0002-0685-2963': 4, '0000-0001-5526-8109': 4, '0000-0001-5611-6385': 3, '0000-0002-2308-9904': 3, '0000-0001-9287-0959': 3, '0000-0001-6532-1700': 3, '0000-0003-0593-4665': 3, '0000-0002-6859-084X': 3, '0000-0002-2220-5862': 2, '0000-0001-9605-6276': 2, '0000-0001-9955-0915': 2, '0000-0003-1202-7748': 2, '0000-0002-5614-229X': 2, '0000-0003-1214-8240': 2, '0000-0001-8144-4583': 1, '0000-0002-7284-9359': 1, '0000-0001-5098-3939': 1, '0000-0001-6422-9486': 1, '0000-0002-3070-1604': 1, '0000-0001-7690-7037': 1, '0000-0002-8453-1719': 1, '0000-0002-2977-6000': 1, '0000-0002-7537-0984': 1, '0000-0003-2763-9501': 1})\n",
      "['0000-0003-3787-9138', '0000-0001-8012-4203', '0000-0001-8638-5594', '0000-0003-2186-8100', '0000-0003-2790-6294', '0000-0001-6837-5739', '0000-0002-6714-5939', '0000-0002-0107-9940', '0000-0001-9103-6532']\n",
      "Total sample size after apply threshold:  187\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(187, 117)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(187, 21)\n",
      "2\n",
      "(187, 138)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.61      0.55      0.58        20\n",
      "          2       0.50      0.45      0.47        20\n",
      "          3       0.50      0.58      0.54        24\n",
      "          4       0.00      0.00      0.00        12\n",
      "          5       1.00      0.10      0.18        10\n",
      "          6       0.26      0.29      0.27        24\n",
      "          7       0.54      0.54      0.54        24\n",
      "          8       0.39      0.68      0.50        41\n",
      "\n",
      "avg / total       0.43      0.44      0.41       187\n",
      "\n",
      "[ 0  2  3  2  0  0  1  1  3  0 11  1  2  0  0  3  0  3  0  1  9  2  0  0\n",
      "  2  3  3  0  1  1 14  0  0  1  1  6  0  1  1  0  0  0  2  0  8  0  1  0\n",
      "  2  0  1  2  0  4  0  0  1  3  0  0  7  3 10  0  1  0  1  0  0  3 13  6\n",
      "  0  0  2  2  0  0  6  3 28]\n",
      "MNB Accuracy:  0.44385026737967914\n",
      "MNB F1:  0.3432319744239249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.42      0.56        12\n",
      "          1       0.94      0.75      0.83        20\n",
      "          2       0.92      0.55      0.69        20\n",
      "          3       0.52      0.62      0.57        24\n",
      "          4       0.89      0.67      0.76        12\n",
      "          5       1.00      0.20      0.33        10\n",
      "          6       0.28      0.38      0.32        24\n",
      "          7       0.80      0.50      0.62        24\n",
      "          8       0.41      0.66      0.50        41\n",
      "\n",
      "avg / total       0.66      0.56      0.57       187\n",
      "\n",
      "[ 5  0  0  2  0  0  2  0  3  0 15  0  2  0  0  1  0  2  0  0 11  2  0  0\n",
      "  4  0  3  0  0  1 15  0  0  0  2  6  0  0  0  0  8  0  2  0  2  0  0  0\n",
      "  3  0  2  1  0  4  1  0  0  1  0  0  9  0 13  0  0  0  2  1  0  3 12  6\n",
      "  0  1  0  2  0  0 10  1 27]\n",
      "svc Accuracy:  0.5561497326203209\n",
      "svc F1:  0.5754612004428321\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.70      0.70      0.70        20\n",
      "          2       0.58      0.55      0.56        20\n",
      "          3       0.61      0.58      0.60        24\n",
      "          4       1.00      0.25      0.40        12\n",
      "          5       1.00      0.10      0.18        10\n",
      "          6       0.38      0.42      0.40        24\n",
      "          7       0.80      0.50      0.62        24\n",
      "          8       0.37      0.71      0.48        41\n",
      "\n",
      "avg / total       0.63      0.51      0.49       187\n",
      "\n",
      "[ 1  1  2  1  0  0  2  1  4  0 14  0  2  0  0  1  0  3  0  1 11  1  0  0\n",
      "  3  0  4  0  1  1 14  0  0  0  0  8  0  1  1  0  3  0  1  0  6  0  1  0\n",
      "  2  0  1  1  0  5  0  0  1  1  0  0 10  0 12  0  1  0  1  0  0  2 12  8\n",
      "  0  0  3  1  0  0  6  2 29]\n",
      "LR Accuracy:  0.5080213903743316\n",
      "LR F1:  0.4549143921484347\n",
      "For name:  h_yin\n",
      "total sample size before apply threshold:  130\n",
      "Counter({'0000-0002-9762-4818': 69, '0000-0001-7693-377X': 32, '0000-0002-0720-5311': 13, '0000-0002-0810-1696': 5, '0000-0001-6553-0887': 5, '0000-0003-1765-496X': 4, '0000-0002-1175-4516': 1, '0000-0002-0682-6781': 1})\n",
      "['0000-0002-9762-4818', '0000-0001-7693-377X', '0000-0002-0720-5311']\n",
      "Total sample size after apply threshold:  114\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 75)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 15)\n",
      "2\n",
      "(114, 90)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.97      0.85        69\n",
      "          1       0.65      0.53      0.59        32\n",
      "          2       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.64      0.74      0.68       114\n",
      "\n",
      "[67  2  0 15 17  0  6  7  0]\n",
      "MNB Accuracy:  0.7368421052631579\n",
      "MNB F1:  0.47990336042169995\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.96      0.86        69\n",
      "          1       0.64      0.44      0.52        32\n",
      "          2       0.12      0.08      0.10        13\n",
      "\n",
      "avg / total       0.67      0.71      0.68       114\n",
      "\n",
      "[66  2  1 12 14  6  6  6  1]\n",
      "svc Accuracy:  0.7105263157894737\n",
      "svc F1:  0.4921672372652765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.97      0.81        69\n",
      "          1       0.80      0.38      0.51        32\n",
      "          2       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.65      0.69      0.63       114\n",
      "\n",
      "[67  0  2 19 12  1 10  3  0]\n",
      "LR Accuracy:  0.6929824561403509\n",
      "LR F1:  0.4409198366645175\n",
      "For name:  k_brown\n",
      "total sample size before apply threshold:  231\n",
      "Counter({'0000-0003-2434-0037': 89, '0000-0002-0729-4959': 61, '0000-0003-3382-5546': 33, '0000-0002-6803-5336': 12, '0000-0003-2472-5754': 9, '0000-0001-7716-1425': 7, '0000-0001-9428-9420': 6, '0000-0002-1047-4328': 3, '0000-0001-6836-1572': 3, '0000-0001-8350-5888': 2, '0000-0001-7766-6810': 1, '0000-0002-0201-0558': 1, '0000-0002-2358-8578': 1, '0000-0002-9093-8742': 1, '0000-0001-5348-7893': 1, '0000-0001-5748-5123': 1})\n",
      "['0000-0003-2434-0037', '0000-0003-3382-5546', '0000-0002-0729-4959', '0000-0002-6803-5336']\n",
      "Total sample size after apply threshold:  195\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(195, 85)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(195, 20)\n",
      "2\n",
      "(195, 105)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.87      0.80        89\n",
      "          1       0.92      0.33      0.49        33\n",
      "          2       0.63      0.82      0.71        61\n",
      "          3       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.69      0.71      0.67       195\n",
      "\n",
      "[77  1 11  0 10 11 12  0 11  0 50  0  6  0  6  0]\n",
      "MNB Accuracy:  0.7076923076923077\n",
      "MNB F1:  0.5002755160786249\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.87      0.81        89\n",
      "          1       0.91      0.64      0.75        33\n",
      "          2       0.73      0.75      0.74        61\n",
      "          3       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.79      0.78      0.78       195\n",
      "\n",
      "[77  1 11  0  8 21  4  0 14  1 46  0  2  0  2  8]\n",
      "svc Accuracy:  0.7794871794871795\n",
      "svc F1:  0.7756154499151104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.88      0.77        89\n",
      "          1       1.00      0.48      0.65        33\n",
      "          2       0.67      0.70      0.69        61\n",
      "          3       1.00      0.08      0.15        12\n",
      "\n",
      "avg / total       0.75      0.71      0.69       195\n",
      "\n",
      "[78  0 11  0 11 16  6  0 18  0 43  0  7  0  4  1]\n",
      "LR Accuracy:  0.7076923076923077\n",
      "LR F1:  0.5658450711849726\n",
      "For name:  s_hong\n",
      "total sample size before apply threshold:  383\n",
      "Counter({'0000-0002-8344-6774': 102, '0000-0002-8888-6007': 84, '0000-0002-0300-1944': 83, '0000-0002-6305-8731': 27, '0000-0001-7291-1020': 19, '0000-0002-0324-2414': 15, '0000-0003-3031-2753': 12, '0000-0003-2401-6368': 12, '0000-0002-2667-1983': 10, '0000-0003-4926-1044': 3, '0000-0002-0020-6215': 3, '0000-0002-8473-919X': 2, '0000-0002-4800-636X': 2, '0000-0001-8722-3124': 1, '0000-0002-6905-7932': 1, '0000-0002-3755-3683': 1, '0000-0002-2498-7546': 1, '0000-0002-9470-5700': 1, '0000-0003-1119-4456': 1, '0000-0001-5049-8810': 1, '0000-0003-0721-4012': 1, '0000-0003-4989-292X': 1})\n",
      "['0000-0002-8888-6007', '0000-0003-3031-2753', '0000-0002-2667-1983', '0000-0002-8344-6774', '0000-0001-7291-1020', '0000-0002-0324-2414', '0000-0003-2401-6368', '0000-0002-6305-8731', '0000-0002-0300-1944']\n",
      "Total sample size after apply threshold:  364\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(364, 136)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(364, 19)\n",
      "2\n",
      "(364, 155)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.69      0.69        84\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.60      0.92      0.73       102\n",
      "          4       0.33      0.05      0.09        19\n",
      "          5       0.67      0.40      0.50        15\n",
      "          6       0.00      0.00      0.00        12\n",
      "          7       0.74      0.52      0.61        27\n",
      "          8       0.75      0.82      0.78        83\n",
      "\n",
      "avg / total       0.60      0.66      0.61       364\n",
      "\n",
      "[58  0  0 22  0  0  0  0  4  3  0  0  3  0  1  0  0  5  4  0  0  1  1  0\n",
      "  0  0  4  3  0  0 94  0  1  0  0  4  4  0  0  5  1  1  0  5  3  4  0  0\n",
      "  5  0  6  0  0  0  5  0  0  5  0  0  0  0  2  0  0  0 11  1  0  0 14  1\n",
      "  4  0  0 11  0  0  0  0 68]\n",
      "MNB Accuracy:  0.6620879120879121\n",
      "MNB F1:  0.37705257743315634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.90      0.75        84\n",
      "          1       0.83      0.42      0.56        12\n",
      "          2       0.50      0.20      0.29        10\n",
      "          3       0.95      0.85      0.90       102\n",
      "          4       0.65      0.58      0.61        19\n",
      "          5       0.45      0.67      0.54        15\n",
      "          6       0.71      0.42      0.53        12\n",
      "          7       1.00      0.93      0.96        27\n",
      "          8       0.93      0.81      0.86        83\n",
      "\n",
      "avg / total       0.82      0.79      0.79       364\n",
      "\n",
      "[76  0  0  1  0  5  0  0  2  5  5  0  0  0  1  1  0  0  4  0  2  0  3  1\n",
      "  0  0  0  9  0  0 87  0  3  0  0  3  4  0  2  0 11  1  1  0  0  5  0  0\n",
      "  0  0 10  0  0  0  4  1  0  0  2  0  5  0  0  0  0  0  0  1  1  0 25  0\n",
      " 12  0  0  4  0  0  0  0 67]\n",
      "svc Accuracy:  0.7912087912087912\n",
      "svc F1:  0.6656630624852384\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.82      0.67        84\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.78      0.91      0.84       102\n",
      "          4       0.60      0.16      0.25        19\n",
      "          5       0.59      0.67      0.62        15\n",
      "          6       1.00      0.08      0.15        12\n",
      "          7       0.88      0.81      0.85        27\n",
      "          8       0.93      0.83      0.88        83\n",
      "\n",
      "avg / total       0.71      0.73      0.70       364\n",
      "\n",
      "[69  0  0 11  0  3  0  0  1  7  0  0  3  0  1  0  0  1  7  0  0  0  1  1\n",
      "  0  0  1  6  0  0 93  0  1  0  0  2  9  0  0  3  3  1  0  3  0  2  0  0\n",
      "  3  0 10  0  0  0  9  0  0  2  0  0  1  0  0  2  0  0  2  1  0  0 22  0\n",
      " 11  0  0  3  0  0  0  0 69]\n",
      "LR Accuracy:  0.7335164835164835\n",
      "LR F1:  0.4735246269087714\n",
      "For name:  l_zhou\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0001-5973-7873': 16, '0000-0003-2800-5981': 10, '0000-0001-9014-6350': 8, '0000-0001-8900-2835': 6, '0000-0002-0393-4787': 4, '0000-0001-9032-0910': 3, '0000-0002-0133-3048': 1, '0000-0001-8554-0900': 1})\n",
      "['0000-0001-5973-7873', '0000-0003-2800-5981']\n",
      "Total sample size after apply threshold:  26\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 6)\n",
      "2\n",
      "(26, 25)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.81      0.84        16\n",
      "          1       0.73      0.80      0.76        10\n",
      "\n",
      "avg / total       0.81      0.81      0.81        26\n",
      "\n",
      "[13  3  2  8]\n",
      "MNB Accuracy:  0.8076923076923077\n",
      "MNB F1:  0.8003072196620584\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.75      0.80        16\n",
      "          1       0.67      0.80      0.73        10\n",
      "\n",
      "avg / total       0.78      0.77      0.77        26\n",
      "\n",
      "[12  4  2  8]\n",
      "svc Accuracy:  0.7692307692307693\n",
      "svc F1:  0.7636363636363636\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.81      0.84        16\n",
      "          1       0.73      0.80      0.76        10\n",
      "\n",
      "avg / total       0.81      0.81      0.81        26\n",
      "\n",
      "[13  3  2  8]\n",
      "LR Accuracy:  0.8076923076923077\n",
      "LR F1:  0.8003072196620584\n",
      "For name:  h_jiang\n",
      "total sample size before apply threshold:  135\n",
      "Counter({'0000-0002-2975-7977': 52, '0000-0002-5778-4008': 16, '0000-0002-1947-4420': 15, '0000-0002-4388-6548': 13, '0000-0003-0561-5058': 10, '0000-0002-1156-9046': 8, '0000-0001-9892-4292': 4, '0000-0002-4577-2886': 4, '0000-0003-3187-2023': 3, '0000-0002-5840-007X': 3, '0000-0003-4173-8565': 3, '0000-0002-7827-0719': 1, '0000-0002-0962-902X': 1, '0000-0003-0951-0624': 1, '0000-0001-6460-408X': 1})\n",
      "['0000-0002-4388-6548', '0000-0002-1947-4420', '0000-0003-0561-5058', '0000-0002-5778-4008', '0000-0002-2975-7977']\n",
      "Total sample size after apply threshold:  106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 29)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 14)\n",
      "2\n",
      "(106, 43)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.15      0.25        13\n",
      "          1       0.43      0.20      0.27        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.84      1.00      0.91        16\n",
      "          4       0.67      0.98      0.80        52\n",
      "\n",
      "avg / total       0.60      0.68      0.60       106\n",
      "\n",
      "[ 2  2  0  0  9  0  3  1  3  8  0  2  0  0  8  0  0  0 16  0  1  0  0  0\n",
      " 51]\n",
      "MNB Accuracy:  0.6792452830188679\n",
      "MNB F1:  0.4467775974025974\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.54      0.52        13\n",
      "          1       0.56      0.60      0.58        15\n",
      "          2       0.80      0.40      0.53        10\n",
      "          3       1.00      1.00      1.00        16\n",
      "          4       0.82      0.87      0.84        52\n",
      "\n",
      "avg / total       0.77      0.76      0.76       106\n",
      "\n",
      "[ 7  2  0  0  4  3  9  1  0  2  0  2  4  0  4  0  0  0 16  0  4  3  0  0\n",
      " 45]\n",
      "svc Accuracy:  0.7641509433962265\n",
      "svc F1:  0.6947237016938554\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.15      0.25        13\n",
      "          1       0.25      0.13      0.17        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.94      0.94      0.94        16\n",
      "          4       0.67      1.00      0.80        52\n",
      "\n",
      "avg / total       0.59      0.67      0.59       106\n",
      "\n",
      "[ 2  4  0  0  7  1  2  1  1 10  0  2  0  0  8  0  0  0 15  1  0  0  0  0\n",
      " 52]\n",
      "LR Accuracy:  0.6698113207547169\n",
      "LR F1:  0.4322826086956521\n",
      "For name:  a_lewis\n",
      "total sample size before apply threshold:  98\n",
      "Counter({'0000-0002-4075-3651': 41, '0000-0002-2519-7976': 37, '0000-0002-7986-0956': 8, '0000-0002-0756-7320': 6, '0000-0002-4195-1035': 4, '0000-0001-5373-7231': 1, '0000-0003-4737-2525': 1})\n",
      "['0000-0002-2519-7976', '0000-0002-4075-3651']\n",
      "Total sample size after apply threshold:  78\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 16)\n",
      "2\n",
      "(78, 60)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.92      0.88        37\n",
      "          1       0.92      0.85      0.89        41\n",
      "\n",
      "avg / total       0.89      0.88      0.88        78\n",
      "\n",
      "[34  3  6 35]\n",
      "MNB Accuracy:  0.8846153846153846\n",
      "MNB F1:  0.8845964162419859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.89      0.90        37\n",
      "          1       0.90      0.93      0.92        41\n",
      "\n",
      "avg / total       0.91      0.91      0.91        78\n",
      "\n",
      "[33  4  3 38]\n",
      "svc Accuracy:  0.9102564102564102\n",
      "svc F1:  0.9098861198217527\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.81      0.85        37\n",
      "          1       0.84      0.90      0.87        41\n",
      "\n",
      "avg / total       0.86      0.86      0.86        78\n",
      "\n",
      "[30  7  4 37]\n",
      "LR Accuracy:  0.8589743589743589\n",
      "LR F1:  0.8578293289146645\n",
      "For name:  c_meyer\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0001-7599-3973': 34, '0000-0002-9877-1393': 29, '0000-0003-1334-2512': 27, '0000-0002-7214-9598': 18, '0000-0002-2268-3055': 14, '0000-0003-0851-2767': 6, '0000-0001-9958-8913': 5, '0000-0002-3166-3101': 3})\n",
      "['0000-0002-9877-1393', '0000-0001-7599-3973', '0000-0003-1334-2512', '0000-0002-7214-9598', '0000-0002-2268-3055']\n",
      "Total sample size after apply threshold:  122\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(122, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(122, 18)\n",
      "2\n",
      "(122, 74)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.79      0.71        29\n",
      "          1       0.79      1.00      0.88        34\n",
      "          2       0.89      0.59      0.71        27\n",
      "          3       0.91      0.56      0.69        18\n",
      "          4       0.93      0.93      0.93        14\n",
      "\n",
      "avg / total       0.81      0.79      0.78       122\n",
      "\n",
      "[23  4  2  0  0  0 34  0  0  0  5  4 16  1  1  7  1  0 10  0  1  0  0  0\n",
      " 13]\n",
      "MNB Accuracy:  0.7868852459016393\n",
      "MNB F1:  0.7840293805811047\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.86      0.74        29\n",
      "          1       1.00      1.00      1.00        34\n",
      "          2       0.88      0.81      0.85        27\n",
      "          3       0.91      0.56      0.69        18\n",
      "          4       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.87      0.85      0.85       122\n",
      "\n",
      "[25  0  3  1  0  0 34  0  0  0  5  0 22  0  0  8  0  0 10  0  1  0  0  0\n",
      " 13]\n",
      "svc Accuracy:  0.8524590163934426\n",
      "svc F1:  0.8468132198355323\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.90      0.75        29\n",
      "          1       1.00      1.00      1.00        34\n",
      "          2       0.79      0.70      0.75        27\n",
      "          3       0.92      0.61      0.73        18\n",
      "          4       0.92      0.79      0.85        14\n",
      "\n",
      "avg / total       0.85      0.83      0.83       122\n",
      "\n",
      "[26  0  3  0  0  0 34  0  0  0  6  0 19  1  1  7  0  0 11  0  1  0  2  0\n",
      " 11]\n",
      "LR Accuracy:  0.8278688524590164\n",
      "LR F1:  0.8156416814217327\n",
      "For name:  a_islam\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0003-3375-9817': 5, '0000-0001-9060-7970': 4, '0000-0002-2139-7508': 3, '0000-0003-1561-0680': 2, '0000-0002-7274-0855': 1, '0000-0002-9902-0639': 1, '0000-0001-8270-5968': 1, '0000-0001-9608-0823': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  k_fujita\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-3821-8393': 16, '0000-0002-6902-9085': 10, '0000-0002-2518-2125': 6, '0000-0002-1477-5187': 5, '0000-0001-7556-4714': 3, '0000-0002-1900-5325': 1, '0000-0002-1744-3583': 1})\n",
      "['0000-0002-6902-9085', '0000-0002-3821-8393']\n",
      "Total sample size after apply threshold:  26\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 14)\n",
      "2\n",
      "(26, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.40      0.47        10\n",
      "          1       0.68      0.81      0.74        16\n",
      "\n",
      "avg / total       0.64      0.65      0.64        26\n",
      "\n",
      "[ 4  6  3 13]\n",
      "MNB Accuracy:  0.6538461538461539\n",
      "MNB F1:  0.6067226890756303\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.40      0.42        10\n",
      "          1       0.65      0.69      0.67        16\n",
      "\n",
      "avg / total       0.57      0.58      0.57        26\n",
      "\n",
      "[ 4  6  5 11]\n",
      "svc Accuracy:  0.5769230769230769\n",
      "svc F1:  0.543859649122807\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.58      0.88      0.70        16\n",
      "\n",
      "avg / total       0.36      0.54      0.43        26\n",
      "\n",
      "[ 0 10  2 14]\n",
      "LR Accuracy:  0.5384615384615384\n",
      "LR F1:  0.35000000000000003\n",
      "For name:  a_khan\n",
      "total sample size before apply threshold:  226\n",
      "Counter({'0000-0001-8640-8530': 59, '0000-0002-2571-3600': 24, '0000-0001-5129-756X': 19, '0000-0002-0760-8647': 14, '0000-0003-3490-799X': 13, '0000-0003-3655-2854': 12, '0000-0003-0254-3546': 11, '0000-0002-0751-0930': 9, '0000-0001-5955-3783': 9, '0000-0002-9325-6640': 8, '0000-0002-8748-1841': 7, '0000-0002-8748-4065': 5, '0000-0003-4057-8053': 5, '0000-0002-3806-5956': 5, '0000-0002-5796-6573': 4, '0000-0002-6655-129X': 3, '0000-0001-6079-0567': 3, '0000-0002-0007-2536': 3, '0000-0001-9293-3999': 2, '0000-0002-3746-5034': 2, '0000-0002-2048-225X': 2, '0000-0001-9338-9323': 2, '0000-0002-7524-6270': 1, '0000-0003-3340-3036': 1, '0000-0003-1562-2577': 1, '0000-0001-7763-1490': 1, '0000-0002-0338-8325': 1})\n",
      "['0000-0003-3490-799X', '0000-0001-5129-756X', '0000-0002-0760-8647', '0000-0003-3655-2854', '0000-0003-0254-3546', '0000-0001-8640-8530', '0000-0002-2571-3600']\n",
      "Total sample size after apply threshold:  152\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(152, 86)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(152, 17)\n",
      "2\n",
      "(152, 103)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.70      0.37      0.48        19\n",
      "          2       1.00      0.07      0.13        14\n",
      "          3       0.40      0.17      0.24        12\n",
      "          4       1.00      0.18      0.31        11\n",
      "          5       0.47      0.90      0.62        59\n",
      "          6       0.45      0.42      0.43        24\n",
      "\n",
      "avg / total       0.54      0.49      0.42       152\n",
      "\n",
      "[ 0  0  0  0  0 13  0  0  7  0  0  0 10  2  0  0  1  0  0 10  3  0  0  0\n",
      "  2  0  7  3  0  0  0  0  2  7  2  0  1  0  3  0 53  2  0  2  0  0  0 12\n",
      " 10]\n",
      "MNB Accuracy:  0.4934210526315789\n",
      "MNB F1:  0.31624914699909706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.87      0.68      0.76        19\n",
      "          2       0.56      0.36      0.43        14\n",
      "          3       0.43      0.25      0.32        12\n",
      "          4       1.00      0.64      0.78        11\n",
      "          5       0.57      0.90      0.70        59\n",
      "          6       0.85      0.46      0.59        24\n",
      "\n",
      "avg / total       0.71      0.66      0.65       152\n",
      "\n",
      "[ 8  0  0  0  0  5  0  0 13  0  0  0  5  1  0  0  5  0  0  9  0  0  0  0\n",
      "  3  0  9  0  0  0  1  0  7  3  0  0  0  2  3  0 53  1  0  2  1  1  0  9\n",
      " 11]\n",
      "svc Accuracy:  0.6578947368421053\n",
      "svc F1:  0.6209890742946529\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.85      0.58      0.69        19\n",
      "          2       1.00      0.07      0.13        14\n",
      "          3       0.25      0.08      0.12        12\n",
      "          4       1.00      0.27      0.43        11\n",
      "          5       0.51      0.93      0.66        59\n",
      "          6       0.50      0.42      0.45        24\n",
      "\n",
      "avg / total       0.65      0.56      0.51       152\n",
      "\n",
      "[ 4  0  0  0  0  9  0  0 11  0  0  0  6  2  0  0  1  0  0 10  3  0  0  0\n",
      "  1  0  9  2  0  0  0  0  3  7  1  0  0  0  2  0 55  2  0  2  0  1  0 11\n",
      " 10]\n",
      "LR Accuracy:  0.5592105263157895\n",
      "LR F1:  0.423169864879139\n",
      "For name:  a_kim\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-4074-0516': 8, '0000-0001-8263-6528': 6, '0000-0003-2861-8366': 2, '0000-0003-4101-6642': 2, '0000-0003-1861-3801': 2, '0000-0002-8733-6046': 2, '0000-0002-8390-0041': 1, '0000-0001-8484-5892': 1, '0000-0003-1539-1246': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_martinez\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0002-6681-4950': 29, '0000-0003-2180-4537': 28, '0000-0002-6289-4586': 3, '0000-0003-0260-2366': 3, '0000-0003-2166-1097': 2, '0000-0002-4386-3290': 1, '0000-0001-9645-5058': 1, '0000-0003-0741-2940': 1, '0000-0003-2137-8048': 1})\n",
      "['0000-0002-6681-4950', '0000-0003-2180-4537']\n",
      "Total sample size after apply threshold:  57\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 20)\n",
      "2\n",
      "(57, 59)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.86      0.77        29\n",
      "          1       0.81      0.61      0.69        28\n",
      "\n",
      "avg / total       0.75      0.74      0.73        57\n",
      "\n",
      "[25  4 11 17]\n",
      "MNB Accuracy:  0.7368421052631579\n",
      "MNB F1:  0.7315541601255887\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.86      0.78        29\n",
      "          1       0.82      0.64      0.72        28\n",
      "\n",
      "avg / total       0.77      0.75      0.75        57\n",
      "\n",
      "[25  4 10 18]\n",
      "svc Accuracy:  0.7543859649122807\n",
      "svc F1:  0.7506250000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.83      0.76        29\n",
      "          1       0.78      0.64      0.71        28\n",
      "\n",
      "avg / total       0.74      0.74      0.73        57\n",
      "\n",
      "[24  5 10 18]\n",
      "LR Accuracy:  0.7368421052631579\n",
      "LR F1:  0.7338935574229692\n",
      "For name:  m_aslam\n",
      "total sample size before apply threshold:  55\n",
      "Counter({'0000-0003-1361-5357': 29, '0000-0002-8529-4217': 17, '0000-0001-8812-6887': 4, '0000-0001-9418-3714': 4, '0000-0003-2498-3526': 1})\n",
      "['0000-0003-1361-5357', '0000-0002-8529-4217']\n",
      "Total sample size after apply threshold:  46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 13)\n",
      "2\n",
      "(46, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.86      0.82        29\n",
      "          1       0.71      0.59      0.65        17\n",
      "\n",
      "avg / total       0.76      0.76      0.76        46\n",
      "\n",
      "[25  4  7 10]\n",
      "MNB Accuracy:  0.7608695652173914\n",
      "MNB F1:  0.7324167107350608\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.86      0.85        29\n",
      "          1       0.75      0.71      0.73        17\n",
      "\n",
      "avg / total       0.80      0.80      0.80        46\n",
      "\n",
      "[25  4  5 12]\n",
      "svc Accuracy:  0.8043478260869565\n",
      "svc F1:  0.7873651771956856\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.86      0.81        29\n",
      "          1       0.69      0.53      0.60        17\n",
      "\n",
      "avg / total       0.73      0.74      0.73        46\n",
      "\n",
      "[25  4  8  9]\n",
      "LR Accuracy:  0.7391304347826086\n",
      "LR F1:  0.7032258064516128\n",
      "For name:  j_wolf\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0003-3112-6602': 56, '0000-0003-4129-8221': 3, '0000-0002-7825-3118': 3, '0000-0002-1437-982X': 2, '0000-0002-7458-2002': 1})\n",
      "['0000-0003-3112-6602']\n",
      "Total sample size after apply threshold:  56\n",
      "For name:  s_agrawal\n",
      "total sample size before apply threshold:  30\n",
      "Counter({'0000-0002-2806-1943': 20, '0000-0001-6295-6954': 6, '0000-0003-3214-786X': 2, '0000-0002-5524-6206': 2})\n",
      "['0000-0002-2806-1943']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  a_othman\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0002-0092-5594': 22, '0000-0002-3827-8695': 13, '0000-0002-2437-8564': 3, '0000-0002-3708-985X': 1, '0000-0002-3982-3157': 1})\n",
      "['0000-0002-3827-8695', '0000-0002-0092-5594']\n",
      "Total sample size after apply threshold:  35\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 7)\n",
      "2\n",
      "(35, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.85      0.71        13\n",
      "          1       0.88      0.68      0.77        22\n",
      "\n",
      "avg / total       0.78      0.74      0.75        35\n",
      "\n",
      "[11  2  7 15]\n",
      "MNB Accuracy:  0.7428571428571429\n",
      "MNB F1:  0.7394540942928041\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.69      0.78        13\n",
      "          1       0.84      0.95      0.89        22\n",
      "\n",
      "avg / total       0.86      0.86      0.85        35\n",
      "\n",
      "[ 9  4  1 21]\n",
      "svc Accuracy:  0.8571428571428571\n",
      "svc F1:  0.8381128584643849\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.46      0.55        13\n",
      "          1       0.73      0.86      0.79        22\n",
      "\n",
      "avg / total       0.71      0.71      0.70        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  7  3 19]\n",
      "LR Accuracy:  0.7142857142857143\n",
      "LR F1:  0.6685606060606061\n",
      "For name:  k_evans\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-6856-8423': 16, '0000-0002-9819-1049': 9, '0000-0001-6981-7703': 3, '0000-0003-2850-7674': 1})\n",
      "['0000-0002-6856-8423']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  k_yoo\n",
      "total sample size before apply threshold:  10\n",
      "Counter({'0000-0002-5213-4575': 7, '0000-0001-7952-7902': 1, '0000-0002-6186-7535': 1, '0000-0002-5539-345X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_turner\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0002-3754-6459': 27, '0000-0003-1603-7994': 26, '0000-0002-3447-7662': 5, '0000-0002-0249-4513': 4, '0000-0002-8891-9155': 3, '0000-0002-7369-8791': 3, '0000-0002-2891-2664': 2, '0000-0001-6802-1703': 1})\n",
      "['0000-0002-3754-6459', '0000-0003-1603-7994']\n",
      "Total sample size after apply threshold:  53\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 15)\n",
      "2\n",
      "(53, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.81      0.86        27\n",
      "          1       0.83      0.92      0.87        26\n",
      "\n",
      "avg / total       0.87      0.87      0.87        53\n",
      "\n",
      "[22  5  2 24]\n",
      "MNB Accuracy:  0.8679245283018868\n",
      "MNB F1:  0.8677361853832442\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.93      0.91        27\n",
      "          1       0.92      0.88      0.90        26\n",
      "\n",
      "avg / total       0.91      0.91      0.91        53\n",
      "\n",
      "[25  2  3 23]\n",
      "svc Accuracy:  0.9056603773584906\n",
      "svc F1:  0.9055258467023173\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.81      0.85        27\n",
      "          1       0.82      0.88      0.85        26\n",
      "\n",
      "avg / total       0.85      0.85      0.85        53\n",
      "\n",
      "[22  5  3 23]\n",
      "LR Accuracy:  0.8490566037735849\n",
      "LR F1:  0.849002849002849\n",
      "For name:  j_king\n",
      "total sample size before apply threshold:  75\n",
      "Counter({'0000-0003-0596-4506': 21, '0000-0002-8174-9173': 20, '0000-0003-4530-9987': 20, '0000-0002-6048-8277': 7, '0000-0003-2171-8321': 5, '0000-0003-4947-0241': 1, '0000-0003-0494-153X': 1})\n",
      "['0000-0002-8174-9173', '0000-0003-4530-9987', '0000-0003-0596-4506']\n",
      "Total sample size after apply threshold:  61\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 11)\n",
      "2\n",
      "(61, 50)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.65      0.60        20\n",
      "          1       0.60      0.60      0.60        20\n",
      "          2       0.67      0.57      0.62        21\n",
      "\n",
      "avg / total       0.61      0.61      0.61        61\n",
      "\n",
      "[13  3  4  6 12  2  4  5 12]\n",
      "MNB Accuracy:  0.6065573770491803\n",
      "MNB F1:  0.6066785927251043\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.65      0.59        20\n",
      "          1       0.82      0.45      0.58        20\n",
      "          2       0.50      0.62      0.55        21\n",
      "\n",
      "avg / total       0.62      0.57      0.57        61\n",
      "\n",
      "[13  0  7  5  9  6  6  2 13]\n",
      "svc Accuracy:  0.5737704918032787\n",
      "svc F1:  0.5749152471870386\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.50      0.49        20\n",
      "          1       0.63      0.60      0.62        20\n",
      "          2       0.57      0.57      0.57        21\n",
      "\n",
      "avg / total       0.56      0.56      0.56        61\n",
      "\n",
      "[10  3  7  6 12  2  5  4 12]\n",
      "LR Accuracy:  0.5573770491803278\n",
      "LR F1:  0.5582060216206558\n",
      "For name:  b_shen\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0003-2899-1531': 29, '0000-0002-5237-6144': 4, '0000-0003-3287-9438': 2, '0000-0001-9687-9010': 1})\n",
      "['0000-0003-2899-1531']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  s_mishra\n",
      "total sample size before apply threshold:  116\n",
      "Counter({'0000-0001-8492-5470': 29, '0000-0003-4091-3018': 24, '0000-0001-6080-4148': 16, '0000-0002-0403-6575': 16, '0000-0003-3511-8319': 8, '0000-0002-3080-9754': 5, '0000-0003-3899-0495': 5, '0000-0001-8151-2988': 3, '0000-0002-1016-0206': 3, '0000-0003-2049-3618': 2, '0000-0003-1003-9884': 2, '0000-0001-6634-1877': 1, '0000-0003-2846-4221': 1, '0000-0002-5202-2645': 1})\n",
      "['0000-0001-8492-5470', '0000-0001-6080-4148', '0000-0002-0403-6575', '0000-0003-4091-3018']\n",
      "Total sample size after apply threshold:  85\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 14)\n",
      "2\n",
      "(85, 62)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.79      0.68        29\n",
      "          1       0.67      0.25      0.36        16\n",
      "          2       0.58      0.69      0.63        16\n",
      "          3       0.76      0.67      0.71        24\n",
      "\n",
      "avg / total       0.65      0.64      0.62        85\n",
      "\n",
      "[23  1  2  3  9  4  3  0  2  1 11  2  5  0  3 16]\n",
      "MNB Accuracy:  0.6352941176470588\n",
      "MNB F1:  0.5949473728885494\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.83      0.74        29\n",
      "          1       0.77      0.62      0.69        16\n",
      "          2       0.93      0.88      0.90        16\n",
      "          3       0.86      0.75      0.80        24\n",
      "\n",
      "avg / total       0.79      0.78      0.78        85\n",
      "\n",
      "[24  3  0  2  6 10  0  0  1  0 14  1  5  0  1 18]\n",
      "svc Accuracy:  0.7764705882352941\n",
      "svc F1:  0.7828356293317361\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.86      0.76        29\n",
      "          1       0.78      0.44      0.56        16\n",
      "          2       0.61      0.69      0.65        16\n",
      "          3       0.76      0.67      0.71        24\n",
      "\n",
      "avg / total       0.71      0.69      0.69        85\n",
      "\n",
      "[25  1  1  2  6  7  3  0  1  1 11  3  5  0  3 16]\n",
      "LR Accuracy:  0.6941176470588235\n",
      "LR F1:  0.6689364230540702\n",
      "For name:  c_o'connor\n",
      "total sample size before apply threshold:  10\n",
      "Counter({'0000-0001-8134-075X': 4, '0000-0002-3541-708X': 2, '0000-0002-7638-9804': 2, '0000-0002-8359-7759': 1, '0000-0002-1670-3937': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  e_svensson\n",
      "total sample size before apply threshold:  87\n",
      "Counter({'0000-0001-9006-016X': 56, '0000-0001-6706-6336': 23, '0000-0002-4349-849X': 7, '0000-0002-5565-3266': 1})\n",
      "['0000-0001-6706-6336', '0000-0001-9006-016X']\n",
      "Total sample size after apply threshold:  79\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 14)\n",
      "2\n",
      "(79, 53)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.13      0.22        23\n",
      "          1       0.73      0.98      0.84        56\n",
      "\n",
      "avg / total       0.74      0.73      0.66        79\n",
      "\n",
      "[ 3 20  1 55]\n",
      "MNB Accuracy:  0.7341772151898734\n",
      "MNB F1:  0.5309584393553859\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.43      0.49        23\n",
      "          1       0.79      0.86      0.82        56\n",
      "\n",
      "avg / total       0.72      0.73      0.72        79\n",
      "\n",
      "[10 13  8 48]\n",
      "svc Accuracy:  0.7341772151898734\n",
      "svc F1:  0.6541588492808005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.09      0.15        23\n",
      "          1       0.72      0.98      0.83        56\n",
      "\n",
      "avg / total       0.71      0.72      0.64        79\n",
      "\n",
      "[ 2 21  1 55]\n",
      "LR Accuracy:  0.7215189873417721\n",
      "LR F1:  0.4935897435897436\n",
      "For name:  o_ahmed\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-8129-0289': 23, '0000-0002-3204-381X': 18, '0000-0002-2854-2552': 3, '0000-0002-1439-0076': 3, '0000-0002-6519-6564': 1})\n",
      "['0000-0002-3204-381X', '0000-0001-8129-0289']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 18)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 15)\n",
      "2\n",
      "(41, 33)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.94      0.87        18\n",
      "          1       0.95      0.83      0.88        23\n",
      "\n",
      "avg / total       0.89      0.88      0.88        41\n",
      "\n",
      "[17  1  4 19]\n",
      "MNB Accuracy:  0.8780487804878049\n",
      "MNB F1:  0.8777579010137151\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.94      0.89        18\n",
      "          1       0.95      0.87      0.91        23\n",
      "\n",
      "avg / total       0.91      0.90      0.90        41\n",
      "\n",
      "[17  1  3 20]\n",
      "svc Accuracy:  0.9024390243902439\n",
      "svc F1:  0.901913875598086\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83        18\n",
      "          1       0.87      0.87      0.87        23\n",
      "\n",
      "avg / total       0.85      0.85      0.85        41\n",
      "\n",
      "[15  3  3 20]\n",
      "LR Accuracy:  0.8536585365853658\n",
      "LR F1:  0.8514492753623188\n",
      "For name:  t_shimada\n",
      "total sample size before apply threshold:  144\n",
      "Counter({'0000-0002-5791-0000': 111, '0000-0002-8361-0730': 26, '0000-0002-1685-6781': 4, '0000-0001-6647-5541': 3})\n",
      "['0000-0002-5791-0000', '0000-0002-8361-0730']\n",
      "Total sample size after apply threshold:  137\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(137, 54)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(137, 16)\n",
      "2\n",
      "(137, 70)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.95      0.93       111\n",
      "          1       0.73      0.62      0.67        26\n",
      "\n",
      "avg / total       0.88      0.88      0.88       137\n",
      "\n",
      "[105   6  10  16]\n",
      "MNB Accuracy:  0.8832116788321168\n",
      "MNB F1:  0.7979351032448379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       111\n",
      "          1       0.83      0.58      0.68        26\n",
      "\n",
      "avg / total       0.89      0.90      0.89       137\n",
      "\n",
      "[108   3  11  15]\n",
      "svc Accuracy:  0.8978102189781022\n",
      "svc F1:  0.8104743083003952\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91       111\n",
      "          1       0.78      0.27      0.40        26\n",
      "\n",
      "avg / total       0.84      0.85      0.81       137\n",
      "\n",
      "[109   2  19   7]\n",
      "LR Accuracy:  0.8467153284671532\n",
      "LR F1:  0.6560669456066945\n",
      "For name:  a_watts\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-4299-2717': 14, '0000-0002-8385-1091': 9, '0000-0003-0623-4601': 1, '0000-0003-3480-582X': 1})\n",
      "['0000-0003-4299-2717']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  b_oliveira\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0002-7710-4284': 22, '0000-0002-7687-4746': 17, '0000-0002-6767-6596': 13, '0000-0001-7712-0025': 6, '0000-0002-4817-6385': 2})\n",
      "['0000-0002-6767-6596', '0000-0002-7710-4284', '0000-0002-7687-4746']\n",
      "Total sample size after apply threshold:  52\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 13)\n",
      "2\n",
      "(52, 50)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.77      0.83        13\n",
      "          1       0.52      0.64      0.57        22\n",
      "          2       0.36      0.29      0.32        17\n",
      "\n",
      "avg / total       0.56      0.56      0.56        52\n",
      "\n",
      "[10  2  1  0 14  8  1 11  5]\n",
      "MNB Accuracy:  0.5576923076923077\n",
      "MNB F1:  0.5757808499743983\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.69      0.75        13\n",
      "          1       0.48      0.64      0.55        22\n",
      "          2       0.33      0.24      0.28        17\n",
      "\n",
      "avg / total       0.52      0.52      0.51        52\n",
      "\n",
      "[ 9  4  0  0 14  8  2 11  4]\n",
      "svc Accuracy:  0.5192307692307693\n",
      "svc F1:  0.5249605589362183\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82        13\n",
      "          1       0.47      0.64      0.54        22\n",
      "          2       0.31      0.24      0.27        17\n",
      "\n",
      "avg / total       0.55      0.52      0.52        52\n",
      "\n",
      "[ 9  3  1  0 14  8  0 13  4]\n",
      "LR Accuracy:  0.5192307692307693\n",
      "LR F1:  0.5411033411033411\n",
      "For name:  t_ito\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0001-7443-3157': 34, '0000-0003-4516-9283': 17, '0000-0003-0686-8129': 5, '0000-0002-4237-3564': 4, '0000-0003-1971-4313': 3, '0000-0001-9873-099X': 3, '0000-0003-1279-228X': 1, '0000-0001-6015-9302': 1, '0000-0002-9274-7050': 1})\n",
      "['0000-0003-4516-9283', '0000-0001-7443-3157']\n",
      "Total sample size after apply threshold:  51\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 15)\n",
      "2\n",
      "(51, 38)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.59      0.65        17\n",
      "          1       0.81      0.88      0.85        34\n",
      "\n",
      "avg / total       0.78      0.78      0.78        51\n",
      "\n",
      "[10  7  4 30]\n",
      "MNB Accuracy:  0.7843137254901961\n",
      "MNB F1:  0.745115856428896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.65      0.73        17\n",
      "          1       0.84      0.94      0.89        34\n",
      "\n",
      "avg / total       0.84      0.84      0.84        51\n",
      "\n",
      "[11  6  2 32]\n",
      "svc Accuracy:  0.8431372549019608\n",
      "svc F1:  0.8111111111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.53      0.67        17\n",
      "          1       0.80      0.97      0.88        34\n",
      "\n",
      "avg / total       0.84      0.82      0.81        51\n",
      "\n",
      "[ 9  8  1 33]\n",
      "LR Accuracy:  0.8235294117647058\n",
      "LR F1:  0.7733333333333334\n",
      "For name:  t_jackson\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0001-6351-2773': 23, '0000-0001-6749-9959': 9, '0000-0003-1669-6666': 6, '0000-0003-3214-3973': 3, '0000-0001-8404-4251': 2, '0000-0002-0248-2627': 2, '0000-0002-5489-6020': 1, '0000-0003-2387-6411': 1})\n",
      "['0000-0001-6351-2773']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  m_romero\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0003-0578-1099': 21, '0000-0003-4582-7397': 4, '0000-0003-1563-8149': 2, '0000-0001-6682-7025': 2})\n",
      "['0000-0003-0578-1099']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  j_west\n",
      "total sample size before apply threshold:  198\n",
      "Counter({'0000-0002-1135-9356': 125, '0000-0002-6004-0202': 41, '0000-0002-7252-8651': 13, '0000-0002-5211-2405': 7, '0000-0001-8369-0075': 4, '0000-0002-4118-0322': 4, '0000-0003-0021-9638': 2, '0000-0001-7340-2885': 1, '0000-0002-6268-9750': 1})\n",
      "['0000-0002-7252-8651', '0000-0002-1135-9356', '0000-0002-6004-0202']\n",
      "Total sample size after apply threshold:  179\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(179, 86)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(179, 14)\n",
      "2\n",
      "(179, 100)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.77      0.96      0.86       125\n",
      "          2       0.75      0.44      0.55        41\n",
      "\n",
      "avg / total       0.71      0.77      0.73       179\n",
      "\n",
      "[  0  12   1   0 120   5   0  23  18]\n",
      "MNB Accuracy:  0.770949720670391\n",
      "MNB F1:  0.47032967032967027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       0.81      0.98      0.89       125\n",
      "          2       0.92      0.59      0.72        41\n",
      "\n",
      "avg / total       0.85      0.83      0.81       179\n",
      "\n",
      "[  2  11   0   0 123   2   0  17  24]\n",
      "svc Accuracy:  0.8324022346368715\n",
      "svc F1:  0.624796308313505\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.77      1.00      0.87       125\n",
      "          2       0.94      0.37      0.53        41\n",
      "\n",
      "avg / total       0.75      0.78      0.73       179\n",
      "\n",
      "[  0  12   1   0 125   0   0  26  15]\n",
      "LR Accuracy:  0.7821229050279329\n",
      "LR F1:  0.46479044834308\n",
      "For name:  c_guo\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0001-9253-3469': 2, '0000-0002-0432-8121': 2, '0000-0002-4000-8141': 1, '0000-0003-2182-3287': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_hansen\n",
      "total sample size before apply threshold:  252\n",
      "Counter({'0000-0001-5372-4828': 55, '0000-0002-8087-8731': 40, '0000-0002-4663-8742': 29, '0000-0001-7114-8051': 27, '0000-0003-3333-2856': 24, '0000-0002-8619-1519': 17, '0000-0002-2607-461X': 16, '0000-0002-5695-6728': 11, '0000-0002-1582-7866': 6, '0000-0003-1684-8578': 6, '0000-0002-1940-0616': 5, '0000-0003-3083-4850': 4, '0000-0001-7879-2106': 4, '0000-0002-3621-1809': 4, '0000-0001-9681-2393': 2, '0000-0002-7589-0074': 1, '0000-0001-9611-8131': 1})\n",
      "['0000-0001-5372-4828', '0000-0002-8619-1519', '0000-0002-5695-6728', '0000-0003-3333-2856', '0000-0002-4663-8742', '0000-0001-7114-8051', '0000-0002-2607-461X', '0000-0002-8087-8731']\n",
      "Total sample size after apply threshold:  219\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(219, 96)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(219, 17)\n",
      "2\n",
      "(219, 113)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.89      0.60        55\n",
      "          1       1.00      0.41      0.58        17\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.90      0.38      0.53        24\n",
      "          4       0.52      0.48      0.50        29\n",
      "          5       0.82      0.52      0.64        27\n",
      "          6       0.00      0.00      0.00        16\n",
      "          7       0.70      0.88      0.78        40\n",
      "\n",
      "avg / total       0.59      0.58      0.54       219\n",
      "\n",
      "[49  0  0  0  4  0  0  2  5  7  0  0  2  0  0  3  3  0  0  0  4  0  0  4\n",
      " 10  0  0  9  1  1  1  2 10  0  0  0 14  2  0  3 10  0  0  1  1 14  0  1\n",
      " 15  0  0  0  1  0  0  0  5  0  0  0  0  0  0 35]\n",
      "MNB Accuracy:  0.5844748858447488\n",
      "MNB F1:  0.453978097973196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.82      0.68        55\n",
      "          1       0.92      0.65      0.76        17\n",
      "          2       1.00      0.27      0.43        11\n",
      "          3       0.70      0.58      0.64        24\n",
      "          4       0.61      0.69      0.65        29\n",
      "          5       0.60      0.56      0.58        27\n",
      "          6       0.46      0.38      0.41        16\n",
      "          7       0.97      0.88      0.92        40\n",
      "\n",
      "avg / total       0.71      0.68      0.68       219\n",
      "\n",
      "[45  0  0  2  5  2  1  0  3 11  0  0  0  2  0  1  3  0  3  0  3  2  0  0\n",
      "  5  0  0 14  0  3  2  0  6  0  0  0 20  1  2  0  5  1  0  1  3 15  2  0\n",
      "  6  0  0  2  2  0  6  0  4  0  0  1  0  0  0 35]\n",
      "svc Accuracy:  0.680365296803653\n",
      "svc F1:  0.6327880048351625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.80      0.70        55\n",
      "          1       1.00      0.59      0.74        17\n",
      "          2       1.00      0.18      0.31        11\n",
      "          3       0.58      0.46      0.51        24\n",
      "          4       0.54      0.72      0.62        29\n",
      "          5       0.74      0.63      0.68        27\n",
      "          6       0.45      0.31      0.37        16\n",
      "          7       0.76      0.85      0.80        40\n",
      "\n",
      "avg / total       0.68      0.66      0.64       219\n",
      "\n",
      "[44  0  0  2  5  2  1  1  1 10  0  0  2  1  0  3  1  0  2  0  5  0  0  3\n",
      "  5  0  0 11  2  2  3  1  4  0  0  0 21  1  1  2  5  0  0  1  2 17  1  1\n",
      "  6  0  0  4  1  0  5  0  4  0  0  1  1  0  0 34]\n",
      "LR Accuracy:  0.6575342465753424\n",
      "LR F1:  0.5915097980754616\n",
      "For name:  x_qian\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0003-1627-288X': 16, '0000-0003-2487-8785': 2, '0000-0002-4119-2913': 1, '0000-0002-8199-6502': 1})\n",
      "['0000-0003-1627-288X']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  m_wagner\n",
      "total sample size before apply threshold:  314\n",
      "Counter({'0000-0002-9778-7684': 141, '0000-0003-2589-6440': 98, '0000-0003-3421-4763': 16, '0000-0002-9831-9110': 15, '0000-0002-4402-3234': 15, '0000-0003-3967-9527': 10, '0000-0002-7367-5629': 8, '0000-0001-9742-0471': 5, '0000-0001-7609-9172': 3, '0000-0001-6501-839X': 2, '0000-0002-6924-7226': 1})\n",
      "['0000-0003-3967-9527', '0000-0002-9831-9110', '0000-0002-9778-7684', '0000-0003-3421-4763', '0000-0003-2589-6440', '0000-0002-4402-3234']\n",
      "Total sample size after apply threshold:  295\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 130)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 20)\n",
      "2\n",
      "(295, 150)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.87      0.95      0.91       141\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.67      0.96      0.79        98\n",
      "          5       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.64      0.77      0.70       295\n",
      "\n",
      "[  0   0   1   0   9   0   0   0   0   0  15   0   0   0 134   0   7   0\n",
      "   0   0   9   0   7   0   0   0   4   0  94   0   0   0   6   0   9   0]\n",
      "MNB Accuracy:  0.7728813559322034\n",
      "MNB F1:  0.2825142424887124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       0.80      0.27      0.40        15\n",
      "          2       0.90      0.93      0.91       141\n",
      "          3       1.00      0.31      0.48        16\n",
      "          4       0.71      0.98      0.82        98\n",
      "          5       1.00      0.13      0.24        15\n",
      "\n",
      "avg / total       0.84      0.81      0.78       295\n",
      "\n",
      "[  2   0   1   0   7   0   0   4   0   0  11   0   0   1 131   0   9   0\n",
      "   0   0   6   5   5   0   0   0   2   0  96   0   0   0   6   0   7   2]\n",
      "svc Accuracy:  0.8135593220338984\n",
      "svc F1:  0.5302907079995892\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.20      0.33        15\n",
      "          2       0.87      0.94      0.90       141\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.67      0.97      0.79        98\n",
      "          5       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.69      0.78      0.71       295\n",
      "\n",
      "[  0   0   1   0   9   0   0   3   0   0  12   0   0   0 132   0   9   0\n",
      "   0   0   9   0   7   0   0   0   3   0  95   0   0   0   6   0   9   0]\n",
      "LR Accuracy:  0.7796610169491526\n",
      "LR F1:  0.3387370003120562\n",
      "For name:  d_campos\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0003-1982-3288': 36, '0000-0002-3448-2111': 8, '0000-0003-0174-6640': 4, '0000-0003-0762-7124': 1})\n",
      "['0000-0003-1982-3288']\n",
      "Total sample size after apply threshold:  36\n",
      "For name:  r_clark\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0002-7291-8553': 77, '0000-0002-6807-5426': 60, '0000-0002-1194-5048': 9, '0000-0002-3534-698X': 3, '0000-0003-4368-5145': 2, '0000-0001-6779-3736': 1})\n",
      "['0000-0002-7291-8553', '0000-0002-6807-5426']\n",
      "Total sample size after apply threshold:  137\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(137, 69)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(137, 15)\n",
      "2\n",
      "(137, 84)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.86      0.85        77\n",
      "          1       0.81      0.80      0.81        60\n",
      "\n",
      "avg / total       0.83      0.83      0.83       137\n",
      "\n",
      "[66 11 12 48]\n",
      "MNB Accuracy:  0.8321167883211679\n",
      "MNB F1:  0.8291677961507183\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89        77\n",
      "          1       0.92      0.77      0.84        60\n",
      "\n",
      "avg / total       0.87      0.87      0.87       137\n",
      "\n",
      "[73  4 14 46]\n",
      "svc Accuracy:  0.8686131386861314\n",
      "svc F1:  0.8633037694013304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.91      0.85        77\n",
      "          1       0.86      0.72      0.78        60\n",
      "\n",
      "avg / total       0.83      0.82      0.82       137\n",
      "\n",
      "[70  7 17 43]\n",
      "LR Accuracy:  0.8248175182481752\n",
      "LR F1:  0.8177383592017737\n",
      "For name:  b_zhou\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-1535-6283': 13, '0000-0003-2846-1813': 2, '0000-0003-2634-1527': 1, '0000-0001-9774-2737': 1, '0000-0003-1560-4950': 1, '0000-0003-0638-2428': 1, '0000-0003-4421-9787': 1})\n",
      "['0000-0002-1535-6283']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  x_yan\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0002-6114-5743': 44, '0000-0001-8547-4210': 18, '0000-0003-3973-3669': 14, '0000-0002-7528-5771': 12, '0000-0001-9327-5756': 7, '0000-0003-2091-6967': 6, '0000-0001-8221-9345': 3, '0000-0001-5026-0239': 3, '0000-0001-5606-0158': 2, '0000-0002-8292-130X': 1, '0000-0002-1300-5498': 1})\n",
      "['0000-0001-8547-4210', '0000-0003-3973-3669', '0000-0002-7528-5771', '0000-0002-6114-5743']\n",
      "Total sample size after apply threshold:  88\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 9)\n",
      "2\n",
      "(88, 46)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.44      0.52        18\n",
      "          1       0.25      0.07      0.11        14\n",
      "          2       0.33      0.08      0.13        12\n",
      "          3       0.59      0.91      0.71        44\n",
      "\n",
      "avg / total       0.51      0.57      0.50        88\n",
      "\n",
      "[ 8  1  0  9  0  1  0 13  4  1  1  6  1  1  2 40]\n",
      "MNB Accuracy:  0.5681818181818182\n",
      "MNB F1:  0.36871479774705584\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.50      0.56        18\n",
      "          1       0.40      0.14      0.21        14\n",
      "          2       0.50      0.25      0.33        12\n",
      "          3       0.59      0.84      0.69        44\n",
      "\n",
      "avg / total       0.56      0.58      0.54        88\n",
      "\n",
      "[ 9  0  1  8  0  2  0 12  3  0  3  6  2  3  2 37]\n",
      "svc Accuracy:  0.5795454545454546\n",
      "svc F1:  0.44948710854238405\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.39      0.50        18\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.50      0.17      0.25        12\n",
      "          3       0.57      0.93      0.71        44\n",
      "\n",
      "avg / total       0.50      0.57      0.49        88\n",
      "\n",
      "[ 7  1  1  9  0  0  0 14  2  0  2  8  1  1  1 41]\n",
      "LR Accuracy:  0.5681818181818182\n",
      "LR F1:  0.3642241379310345\n",
      "For name:  x_li\n",
      "total sample size before apply threshold:  867\n",
      "Counter({'0000-0002-5555-9034': 244, '0000-0002-5981-2762': 71, '0000-0002-4044-2888': 67, '0000-0001-6508-8355': 51, '0000-0001-8791-7505': 30, '0000-0002-4115-3287': 30, '0000-0002-2497-020X': 26, '0000-0002-6200-1178': 26, '0000-0002-7844-8417': 22, '0000-0003-1359-5130': 21, '0000-0002-4793-0550': 20, '0000-0001-8718-2780': 18, '0000-0002-4446-2480': 16, '0000-0003-1568-1999': 14, '0000-0001-9814-0383': 13, '0000-0002-7646-1132': 13, '0000-0003-0724-0982': 12, '0000-0002-2510-2236': 11, '0000-0002-3828-0971': 10, '0000-0002-4675-5367': 10, '0000-0002-6646-0929': 8, '0000-0002-4350-3375': 7, '0000-0002-7939-5150': 7, '0000-0001-7038-5119': 6, '0000-0002-9121-7883': 5, '0000-0002-4828-4183': 5, '0000-0001-8184-3197': 5, '0000-0001-6449-1505': 5, '0000-0003-0606-434X': 5, '0000-0003-0220-9003': 5, '0000-0002-0046-2016': 5, '0000-0001-7111-8485': 4, '0000-0002-4230-5676': 4, '0000-0002-6007-5149': 4, '0000-0003-4514-0149': 4, '0000-0003-1117-9619': 4, '0000-0003-2999-9818': 3, '0000-0001-7073-7532': 3, '0000-0002-0986-6682': 3, '0000-0003-1382-3295': 3, '0000-0003-3882-7073': 3, '0000-0002-4842-5054': 3, '0000-0003-1990-0159': 3, '0000-0002-7270-3376': 3, '0000-0003-0493-417X': 2, '0000-0001-8662-0865': 2, '0000-0003-3050-8529': 2, '0000-0003-3272-5180': 2, '0000-0002-3428-3569': 2, '0000-0002-5263-7017': 2, '0000-0001-9790-5663': 2, '0000-0003-2747-644X': 2, '0000-0002-1959-2160': 2, '0000-0002-0377-2925': 2, '0000-0003-3951-9646': 2, '0000-0002-2397-6079': 1, '0000-0001-7458-8263': 1, '0000-0002-7671-6326': 1, '0000-0003-0191-9484': 1, '0000-0002-0220-8310': 1, '0000-0002-6433-2085': 1, '0000-0002-8669-6314': 1, '0000-0001-5580-5605': 1, '0000-0001-8088-2338': 1, '0000-0002-6093-1099': 1, '0000-0002-1708-4314': 1, '0000-0002-3919-2658': 1, '0000-0001-7420-6253': 1})\n",
      "['0000-0002-4446-2480', '0000-0001-9814-0383', '0000-0002-7646-1132', '0000-0003-1568-1999', '0000-0002-5555-9034', '0000-0001-8791-7505', '0000-0002-3828-0971', '0000-0003-0724-0982', '0000-0002-4044-2888', '0000-0002-7844-8417', '0000-0002-4793-0550', '0000-0001-8718-2780', '0000-0002-4675-5367', '0000-0002-2497-020X', '0000-0002-4115-3287', '0000-0002-6200-1178', '0000-0003-1359-5130', '0000-0002-5981-2762', '0000-0002-2510-2236', '0000-0001-6508-8355']\n",
      "Total sample size after apply threshold:  725\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(725, 242)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(725, 25)\n",
      "2\n",
      "(725, 267)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       1.00      0.15      0.27        13\n",
      "          3       0.00      0.00      0.00        14\n",
      "          4       0.44      0.98      0.61       244\n",
      "          5       1.00      0.17      0.29        30\n",
      "          6       0.00      0.00      0.00        10\n",
      "          7       0.00      0.00      0.00        12\n",
      "          8       0.79      0.73      0.76        67\n",
      "          9       0.00      0.00      0.00        22\n",
      "         10       0.00      0.00      0.00        20\n",
      "         11       0.00      0.00      0.00        18\n",
      "         12       0.00      0.00      0.00        10\n",
      "         13       0.00      0.00      0.00        26\n",
      "         14       0.90      0.30      0.45        30\n",
      "         15       0.83      0.38      0.53        26\n",
      "         16       0.00      0.00      0.00        21\n",
      "         17       0.97      0.48      0.64        71\n",
      "         18       0.00      0.00      0.00        11\n",
      "         19       0.51      0.51      0.51        51\n",
      "\n",
      "avg / total       0.48      0.52      0.43       725\n",
      "\n",
      "[  0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   2   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   3   0   0   2   0  10   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   0   0  14   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 240   0   0   0   2   0\n",
      "   0   0   0   0   0   0   0   1   0   1   0   0   0   0  25   5   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  18   0   0   0  49   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  11   0   0   0   0   0   0   0   0   0   1   2   0   0\n",
      "   0   8   0   0   0   0  19   0   0   0   1   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   8   0   0   0  10   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0   0   0   0  26   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  19   0   0   0\n",
      "   0   1   0   0   0   0   9   0   0   0   0   1   0   0   0   0  14   0\n",
      "   0   0   0   0   0   0   0   0   0  10   0   0   0   2   0   0   0   0\n",
      "  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  37   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0\n",
      "   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   6   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  26]\n",
      "MNB Accuracy:  0.5172413793103449\n",
      "MNB F1:  0.20232634106916078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.41      0.54      0.47        13\n",
      "          2       0.62      0.77      0.69        13\n",
      "          3       0.91      0.71      0.80        14\n",
      "          4       0.65      0.99      0.78       244\n",
      "          5       0.88      0.47      0.61        30\n",
      "          6       1.00      0.20      0.33        10\n",
      "          7       1.00      0.17      0.29        12\n",
      "          8       0.83      0.85      0.84        67\n",
      "          9       0.25      0.23      0.24        22\n",
      "         10       1.00      0.50      0.67        20\n",
      "         11       1.00      0.06      0.11        18\n",
      "         12       1.00      0.50      0.67        10\n",
      "         13       0.91      0.38      0.54        26\n",
      "         14       1.00      0.83      0.91        30\n",
      "         15       0.63      0.65      0.64        26\n",
      "         16       1.00      0.29      0.44        21\n",
      "         17       0.91      0.61      0.73        71\n",
      "         18       1.00      0.36      0.53        11\n",
      "         19       0.54      0.61      0.57        51\n",
      "\n",
      "avg / total       0.74      0.69      0.66       725\n",
      "\n",
      "[  0   0   4   0   6   0   0   0   0   0   0   0   0   0   0   1   0   1\n",
      "   0   4   0   7   0   0   1   0   0   0   0   2   0   0   0   0   0   1\n",
      "   0   0   0   2   0   0  10   0   2   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   0  10   4   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 242   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0   1   0   0   0   0  13  14   0   0\n",
      "   0   0   0   0   0   1   0   0   0   2   0   0   0   0   0   0   8   0\n",
      "   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   9   0   0   2   1   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "   0   1   8   0   0   0  57   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   2   0   0   0   0   0   0   0   5   0   0   0   0   0   6   0   0\n",
      "   0   9   0   0   0   0   9   0   0   0   1   0  10   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   6   0   0   0  10   0   0   1   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0\n",
      "   5   0   0   1   0   0   0   2   0   0   0   0  16   0   0   0   0   0\n",
      "   0   0   0  10   0   0   0   0   0   0   0   2   0   0   0   0   0   0\n",
      "   0   3   0   0   0   0  25   0   0   0   0   0   0   1   0   0   1   0\n",
      "   0   0   0   3   0   0   0   0   0  17   0   0   0   4   0   0   0   0\n",
      "  15   0   0   0   0   0   0   0   0   0   0   0   6   0   0   0   1   0\n",
      "   0   0  25   2   0   0   0   0   0   0   0   0   0   0   0  43   0   0\n",
      "   0   0   1   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   4   3   3   3   1   0   5   0   0   0   0   7   0   0   0   0   0   1\n",
      "   0   0   0  31]\n",
      "svc Accuracy:  0.6910344827586207\n",
      "svc F1:  0.5426352364497601\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.22      0.15      0.18        13\n",
      "          2       0.53      0.69      0.60        13\n",
      "          3       0.90      0.64      0.75        14\n",
      "          4       0.55      0.99      0.71       244\n",
      "          5       1.00      0.43      0.60        30\n",
      "          6       0.00      0.00      0.00        10\n",
      "          7       0.00      0.00      0.00        12\n",
      "          8       0.83      0.81      0.82        67\n",
      "          9       0.22      0.09      0.13        22\n",
      "         10       1.00      0.40      0.57        20\n",
      "         11       0.00      0.00      0.00        18\n",
      "         12       0.00      0.00      0.00        10\n",
      "         13       0.86      0.23      0.36        26\n",
      "         14       0.88      0.77      0.82        30\n",
      "         15       0.60      0.58      0.59        26\n",
      "         16       0.00      0.00      0.00        21\n",
      "         17       0.97      0.51      0.67        71\n",
      "         18       0.20      0.09      0.13        11\n",
      "         19       0.59      0.59      0.59        51\n",
      "\n",
      "avg / total       0.60      0.62      0.56       725\n",
      "\n",
      "[  0   0   4   0   7   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "   1   3   0   2   0   0   6   0   0   0   0   0   0   0   0   0   1   2\n",
      "   0   0   0   2   1   0   9   0   2   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   0   9   5   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 242   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0   1   0   0   0   0  16  13   0   0\n",
      "   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0  10   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "   0   1  10   0   0   0  54   0   0   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   6   0   0   0   0   2   0   0   0   0   2   5   0   0\n",
      "   0   7   0   0   0   0  11   0   0   0   1   0   8   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   7   0   0   0  10   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0\n",
      "   0   0   0   1   0   0   0   1   0   0   0   0  20   0   0   0   0   0\n",
      "   0   0   0   6   0   0   0   0   0   0   0   2   0   0   2   0   0   0\n",
      "   0   3   0   0   0   0  23   0   0   0   0   0   0   1   0   0   7   0\n",
      "   0   0   0   1   0   0   0   0   0  15   0   0   0   2   0   0   0   0\n",
      "  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  35   0   0   0   0   0   0   0   0   0   0   0   0  36   0   0\n",
      "   0   0   3   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   1   4   0   2   1   0  11   0   0   0   0   3   0   0   0   0   0   1\n",
      "   0   0   3  30]\n",
      "LR Accuracy:  0.6206896551724138\n",
      "LR F1:  0.37574417626581874\n",
      "For name:  j_burton\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0003-1176-7592': 34, '0000-0003-2817-7353': 6, '0000-0001-5267-1277': 4, '0000-0002-3205-8819': 2})\n",
      "['0000-0003-1176-7592']\n",
      "Total sample size after apply threshold:  34\n",
      "For name:  x_feng\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0001-6894-7979': 37, '0000-0002-3212-3051': 25, '0000-0002-9057-1549': 17, '0000-0002-6920-1519': 9, '0000-0002-9523-6096': 8, '0000-0002-0443-0628': 2, '0000-0002-9473-2848': 2, '0000-0003-1945-1605': 1, '0000-0001-8226-3389': 1})\n",
      "['0000-0002-3212-3051', '0000-0001-6894-7979', '0000-0002-9057-1549']\n",
      "Total sample size after apply threshold:  79\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 33)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 13)\n",
      "2\n",
      "(79, 46)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.76      0.70        25\n",
      "          1       0.74      0.76      0.75        37\n",
      "          2       0.92      0.65      0.76        17\n",
      "\n",
      "avg / total       0.75      0.73      0.74        79\n",
      "\n",
      "[19  6  0  8 28  1  2  4 11]\n",
      "MNB Accuracy:  0.7341772151898734\n",
      "MNB F1:  0.7363303533418476\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.72      0.82        25\n",
      "          1       0.80      0.95      0.86        37\n",
      "          2       0.88      0.82      0.85        17\n",
      "\n",
      "avg / total       0.86      0.85      0.85        79\n",
      "\n",
      "[18  6  1  1 35  1  0  3 14]\n",
      "svc Accuracy:  0.8481012658227848\n",
      "svc F1:  0.8436213991769548\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.68      0.77        25\n",
      "          1       0.75      0.97      0.85        37\n",
      "          2       0.92      0.65      0.76        17\n",
      "\n",
      "avg / total       0.83      0.81      0.80        79\n",
      "\n",
      "[17  8  0  0 36  1  2  4 11]\n",
      "LR Accuracy:  0.810126582278481\n",
      "LR F1:  0.792802261970619\n",
      "For name:  w_hussein\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0001-5392-1880': 18, '0000-0002-7416-4521': 13, '0000-0001-5928-6240': 1, '0000-0002-7589-7479': 1})\n",
      "['0000-0001-5392-1880', '0000-0002-7416-4521']\n",
      "Total sample size after apply threshold:  31\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(31, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(31, 15)\n",
      "2\n",
      "(31, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        18\n",
      "          1       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.87      0.84      0.83        31\n",
      "\n",
      "[18  0  5  8]\n",
      "MNB Accuracy:  0.8387096774193549\n",
      "MNB F1:  0.8199767711962835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.94      0.85        18\n",
      "          1       0.89      0.62      0.73        13\n",
      "\n",
      "avg / total       0.82      0.81      0.80        31\n",
      "\n",
      "[17  1  5  8]\n",
      "svc Accuracy:  0.8064516129032258\n",
      "svc F1:  0.7886363636363637\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        18\n",
      "          1       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.87      0.84      0.83        31\n",
      "\n",
      "[18  0  5  8]\n",
      "LR Accuracy:  0.8387096774193549\n",
      "LR F1:  0.8199767711962835\n",
      "For name:  c_santos\n",
      "total sample size before apply threshold:  293\n",
      "Counter({'0000-0002-0405-3500': 68, '0000-0003-4129-6381': 41, '0000-0001-6074-7825': 38, '0000-0002-7014-8014': 37, '0000-0002-7109-1101': 25, '0000-0002-4575-1807': 22, '0000-0003-4681-0941': 17, '0000-0002-6725-8925': 10, '0000-0003-0023-7203': 9, '0000-0003-4380-7990': 8, '0000-0002-8567-0032': 4, '0000-0001-6315-7433': 3, '0000-0002-4751-2180': 3, '0000-0001-5693-9795': 2, '0000-0001-9198-2668': 2, '0000-0002-0938-523X': 1, '0000-0001-7927-9718': 1, '0000-0001-5181-2461': 1, '0000-0001-5577-0799': 1})\n",
      "['0000-0003-4129-6381', '0000-0002-6725-8925', '0000-0002-7109-1101', '0000-0002-7014-8014', '0000-0001-6074-7825', '0000-0002-0405-3500', '0000-0003-4681-0941', '0000-0002-4575-1807']\n",
      "Total sample size after apply threshold:  258\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(258, 154)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(258, 20)\n",
      "2\n",
      "(258, 174)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.61      0.52        41\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00        25\n",
      "          3       0.54      0.38      0.44        37\n",
      "          4       0.73      0.29      0.42        38\n",
      "          5       0.42      0.85      0.56        68\n",
      "          6       0.00      0.00      0.00        17\n",
      "          7       0.61      0.64      0.62        22\n",
      "\n",
      "avg / total       0.42      0.47      0.41       258\n",
      "\n",
      "[25  0  0  3  0 13  0  0  4  0  0  0  1  5  0  0  5  0  0  1  0 17  0  2\n",
      "  5  0  0 14  1 16  0  1  4  0  0  1 11 19  0  3  3  0  0  3  2 58  0  2\n",
      "  5  0  0  4  0  7  0  1  4  0  0  0  0  4  0 14]\n",
      "MNB Accuracy:  0.4728682170542636\n",
      "MNB F1:  0.3203726016315742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.66      0.65        41\n",
      "          1       0.60      0.30      0.40        10\n",
      "          2       0.58      0.28      0.38        25\n",
      "          3       0.46      0.43      0.44        37\n",
      "          4       0.57      0.32      0.41        38\n",
      "          5       0.45      0.76      0.57        68\n",
      "          6       0.27      0.18      0.21        17\n",
      "          7       0.81      0.59      0.68        22\n",
      "\n",
      "avg / total       0.54      0.52      0.50       258\n",
      "\n",
      "[27  0  0  2  0 11  1  0  1  3  0  0  2  3  1  0  1  0  7  3  1 11  2  0\n",
      "  3  0  0 16  2 13  1  2  1  2  3  2 12 16  2  0  5  0  2  5  3 52  0  1\n",
      "  3  0  0  4  1  6  3  0  1  0  0  3  0  4  1 13]\n",
      "svc Accuracy:  0.5155038759689923\n",
      "svc F1:  0.4679898156730222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.61      0.54        41\n",
      "          1       1.00      0.30      0.46        10\n",
      "          2       1.00      0.12      0.21        25\n",
      "          3       0.60      0.41      0.48        37\n",
      "          4       0.55      0.32      0.40        38\n",
      "          5       0.42      0.84      0.56        68\n",
      "          6       1.00      0.06      0.11        17\n",
      "          7       0.88      0.64      0.74        22\n",
      "\n",
      "avg / total       0.63      0.50      0.47       258\n",
      "\n",
      "[25  0  0  3  0 13  0  0  2  3  0  0  2  3  0  0  4  0  3  2  2 14  0  0\n",
      "  5  0  0 15  2 14  0  1  3  0  0  1 12 22  0  0  5  0  0  2  3 57  0  1\n",
      "  5  0  0  1  1  9  1  0  2  0  0  1  0  5  0 14]\n",
      "LR Accuracy:  0.5038759689922481\n",
      "LR F1:  0.4384030227231944\n",
      "For name:  j_figueroa\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0003-3036-6604': 51, '0000-0003-4769-8736': 3, '0000-0002-7457-0650': 3, '0000-0002-3403-1484': 2})\n",
      "['0000-0003-3036-6604']\n",
      "Total sample size after apply threshold:  51\n",
      "For name:  w_cui\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0003-2245-6052': 7, '0000-0002-6324-5772': 4, '0000-0001-7281-3471': 1, '0000-0002-6938-9582': 1, '0000-0003-4875-4285': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_moreira\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0003-4517-244X': 18, '0000-0003-1961-7281': 4, '0000-0003-0605-8003': 2, '0000-0002-8257-5785': 1, '0000-0002-4801-2225': 1})\n",
      "['0000-0003-4517-244X']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  m_graham\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0002-7290-1217': 34, '0000-0003-4983-4949': 27, '0000-0002-4170-1095': 2, '0000-0003-0708-7957': 1})\n",
      "['0000-0002-7290-1217', '0000-0003-4983-4949']\n",
      "Total sample size after apply threshold:  61\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 18)\n",
      "2\n",
      "(61, 49)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.50      0.63        34\n",
      "          1       0.59      0.89      0.71        27\n",
      "\n",
      "avg / total       0.73      0.67      0.66        61\n",
      "\n",
      "[17 17  3 24]\n",
      "MNB Accuracy:  0.6721311475409836\n",
      "MNB F1:  0.667755991285403\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.85      0.84        34\n",
      "          1       0.81      0.78      0.79        27\n",
      "\n",
      "avg / total       0.82      0.82      0.82        61\n",
      "\n",
      "[29  5  6 21]\n",
      "svc Accuracy:  0.819672131147541\n",
      "svc F1:  0.8165162701668034\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.85      0.82        34\n",
      "          1       0.79      0.70      0.75        27\n",
      "\n",
      "avg / total       0.79      0.79      0.79        61\n",
      "\n",
      "[29  5  8 19]\n",
      "LR Accuracy:  0.7868852459016393\n",
      "LR F1:  0.7809997238331953\n",
      "For name:  g_dias\n",
      "total sample size before apply threshold:  9\n",
      "Counter({'0000-0002-3774-6661': 5, '0000-0001-8548-1146': 2, '0000-0001-7291-6569': 1, '0000-0002-0524-1239': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_yoshida\n",
      "total sample size before apply threshold:  72\n",
      "Counter({'0000-0001-6890-4397': 38, '0000-0002-2540-0225': 19, '0000-0001-6360-5988': 13, '0000-0002-7283-8617': 2})\n",
      "['0000-0002-2540-0225', '0000-0001-6360-5988', '0000-0001-6890-4397']\n",
      "Total sample size after apply threshold:  70"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 20)\n",
      "2\n",
      "(70, 42)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.53      0.54        19\n",
      "          1       1.00      0.23      0.38        13\n",
      "          2       0.73      0.95      0.83        38\n",
      "\n",
      "avg / total       0.74      0.70      0.67        70\n",
      "\n",
      "[10  0  9  6  3  4  2  0 36]\n",
      "MNB Accuracy:  0.7\n",
      "MNB F1:  0.5810422491456974\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.53      0.61        19\n",
      "          1       0.82      0.69      0.75        13\n",
      "          2       0.76      0.89      0.82        38\n",
      "\n",
      "avg / total       0.76      0.76      0.75        70\n",
      "\n",
      "[10  1  8  1  9  3  3  1 34]\n",
      "svc Accuracy:  0.7571428571428571\n",
      "svc F1:  0.7251125714981136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.42      0.57        19\n",
      "          1       0.75      0.46      0.57        13\n",
      "          2       0.70      0.97      0.81        38\n",
      "\n",
      "avg / total       0.76      0.73      0.70        70\n",
      "\n",
      "[ 8  1 10  1  6  6  0  1 37]\n",
      "LR Accuracy:  0.7285714285714285\n",
      "LR F1:  0.652014652014652\n",
      "For name:  m_branco\n",
      "total sample size before apply threshold:  56\n",
      "Counter({'0000-0001-9447-1548': 21, '0000-0002-8140-1257': 18, '0000-0003-4439-1923': 12, '0000-0001-5238-1069': 5})\n",
      "['0000-0002-8140-1257', '0000-0001-9447-1548', '0000-0003-4439-1923']\n",
      "Total sample size after apply threshold:  51\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 36)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 16)\n",
      "2\n",
      "(51, 52)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.61      0.59        18\n",
      "          1       0.59      0.81      0.68        21\n",
      "          2       0.67      0.17      0.27        12\n",
      "\n",
      "avg / total       0.60      0.59      0.55        51\n",
      "\n",
      "[11  6  1  4 17  0  4  6  2]\n",
      "MNB Accuracy:  0.5882352941176471\n",
      "MNB F1:  0.5137537537537538\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.61      0.59        18\n",
      "          1       0.57      0.76      0.65        21\n",
      "          2       0.50      0.17      0.25        12\n",
      "\n",
      "avg / total       0.56      0.57      0.54        51\n",
      "\n",
      "[11  6  1  4 16  1  4  6  2]\n",
      "svc Accuracy:  0.5686274509803921\n",
      "svc F1:  0.4992186063614635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.61      0.61        18\n",
      "          1       0.55      0.81      0.65        21\n",
      "          2       0.50      0.08      0.14        12\n",
      "\n",
      "avg / total       0.56      0.57      0.52        51\n",
      "\n",
      "[11  6  1  4 17  0  3  8  1]\n",
      "LR Accuracy:  0.5686274509803921\n",
      "LR F1:  0.46927146927146923\n",
      "For name:  k_chong\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0003-2587-1323': 28, '0000-0002-7350-597X': 4, '0000-0003-4754-8957': 4, '0000-0003-0786-842X': 3})\n",
      "['0000-0003-2587-1323']\n",
      "Total sample size after apply threshold:  28\n",
      "For name:  j_kumar\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0002-9754-3305': 9, '0000-0002-4153-1495': 3, '0000-0002-0159-0546': 2, '0000-0001-9666-8280': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  a_shenoy\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0001-6228-9303': 24, '0000-0003-4306-7582': 3, '0000-0001-8639-2751': 3, '0000-0003-4200-8599': 2, '0000-0003-4611-9333': 1})\n",
      "['0000-0001-6228-9303']\n",
      "Total sample size after apply threshold:  24\n",
      "For name:  h_yang\n",
      "total sample size before apply threshold:  417\n",
      "Counter({'0000-0002-8482-6031': 65, '0000-0003-3459-4516': 45, '0000-0003-3864-9895': 44, '0000-0002-7056-3648': 40, '0000-0003-3602-9772': 34, '0000-0001-6483-2373': 31, '0000-0002-6707-8481': 18, '0000-0002-0470-676X': 15, '0000-0002-1711-363X': 15, '0000-0002-2965-4353': 13, '0000-0001-5298-2462': 11, '0000-0002-4287-0026': 11, '0000-0002-0762-7194': 10, '0000-0003-4647-1388': 6, '0000-0002-0435-6763': 5, '0000-0003-3325-1378': 5, '0000-0001-5779-1833': 5, '0000-0002-9187-1367': 5, '0000-0001-8061-6179': 4, '0000-0003-1445-3468': 3, '0000-0002-9596-4907': 3, '0000-0003-4265-7492': 3, '0000-0001-7255-9653': 3, '0000-0003-0445-2824': 3, '0000-0001-9644-6207': 2, '0000-0003-1139-2751': 2, '0000-0002-2060-8991': 2, '0000-0002-4690-8503': 2, '0000-0002-3471-8235': 2, '0000-0003-0727-0874': 1, '0000-0001-5117-5394': 1, '0000-0001-6436-3036': 1, '0000-0003-1943-8857': 1, '0000-0002-2628-4676': 1, '0000-0002-4732-1990': 1, '0000-0001-5140-9664': 1, '0000-0002-2252-2606': 1, '0000-0003-4825-2867': 1, '0000-0003-2326-7317': 1})\n",
      "['0000-0002-2965-4353', '0000-0001-5298-2462', '0000-0002-7056-3648', '0000-0003-3459-4516', '0000-0002-0762-7194', '0000-0003-3602-9772', '0000-0002-6707-8481', '0000-0003-3864-9895', '0000-0002-8482-6031', '0000-0001-6483-2373', '0000-0002-0470-676X', '0000-0002-4287-0026', '0000-0002-1711-363X']\n",
      "Total sample size after apply threshold:  352\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(352, 199)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(352, 21)\n",
      "2\n",
      "(352, 220)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.23      0.38        13\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.78      0.35      0.48        40\n",
      "          3       0.62      0.64      0.63        45\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.62      0.44      0.52        34\n",
      "          6       0.50      0.06      0.10        18\n",
      "          7       0.37      0.77      0.50        44\n",
      "          8       0.37      0.75      0.49        65\n",
      "          9       0.48      0.52      0.50        31\n",
      "         10       0.00      0.00      0.00        15\n",
      "         11       0.00      0.00      0.00        11\n",
      "         12       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.45      0.46      0.40       352\n",
      "\n",
      "[ 3  0  0  1  0  1  0  1  4  3  0  0  0  0  0  0  1  0  1  0  1  6  2  0\n",
      "  0  0  0  0 14  2  0  2  0  8 13  1  0  0  0  0  0  0 29  0  0  1  4 10\n",
      "  1  0  0  0  0  0  0  0  0  5  0  2  3  0  0  0  0  0  0  3  0  0 15  0\n",
      "  9  6  1  0  0  0  0  0  0  7  0  0  1  5  5  0  0  0  0  0  0  0  1  0\n",
      "  0  0 34  7  2  0  0  0  0  0  1  2  0  0  0  9 49  4  0  0  0  0  0  0\n",
      "  1  0  0  0  4 10 16  0  0  0  0  0  0  0  0  0  0  5  7  3  0  0  0  0\n",
      "  0  0  1  0  0  0  7  3  0  0  0  0  0  0  0  2  0  0  0  3 10  0  0  0\n",
      "  0]\n",
      "MNB Accuracy:  0.45738636363636365\n",
      "MNB F1:  0.27695263673524545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        13\n",
      "          1       1.00      0.45      0.62        11\n",
      "          2       0.74      0.57      0.65        40\n",
      "          3       0.77      0.60      0.68        45\n",
      "          4       0.67      0.20      0.31        10\n",
      "          5       0.74      0.50      0.60        34\n",
      "          6       0.44      0.22      0.30        18\n",
      "          7       0.46      0.82      0.59        44\n",
      "          8       0.43      0.82      0.57        65\n",
      "          9       0.80      0.52      0.63        31\n",
      "         10       0.88      0.47      0.61        15\n",
      "         11       0.33      0.09      0.14        11\n",
      "         12       1.00      0.47      0.64        15\n",
      "\n",
      "avg / total       0.66      0.58      0.58       352\n",
      "\n",
      "[ 7  0  0  0  1  0  0  1  2  2  0  0  0  0  5  0  0  0  0  0  2  4  0  0\n",
      "  0  0  0  0 23  2  0  2  0  6  6  1  0  0  0  0  0  1 27  0  0  4  2 11\n",
      "  0  0  0  0  0  0  0  0  2  4  0  1  3  0  0  0  0  0  0  5  0  0 17  0\n",
      "  8  4  0  0  0  0  0  0  0  6  0  0  4  3  5  0  0  0  0  0  0  0  0  0\n",
      "  0  1 36  7  0  0  0  0  0  0  2  0  0  0  0  6 53  1  1  2  0  0  0  0\n",
      "  0  0  0  0  5 10 16  0  0  0  0  0  0  0  0  0  0  2  6  0  7  0  0  0\n",
      "  0  0  0  0  0  0  6  4  0  0  1  0  0  0  0  0  0  0  0  1  7  0  0  0\n",
      "  7]\n",
      "svc Accuracy:  0.5823863636363636\n",
      "svc F1:  0.5396881031718402\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       1.00      0.27      0.43        11\n",
      "          2       0.82      0.45      0.58        40\n",
      "          3       0.71      0.60      0.65        45\n",
      "          4       1.00      0.10      0.18        10\n",
      "          5       0.69      0.53      0.60        34\n",
      "          6       0.44      0.22      0.30        18\n",
      "          7       0.41      0.77      0.54        44\n",
      "          8       0.42      0.80      0.55        65\n",
      "          9       0.50      0.55      0.52        31\n",
      "         10       1.00      0.27      0.42        15\n",
      "         11       1.00      0.09      0.17        11\n",
      "         12       0.50      0.13      0.21        15\n",
      "\n",
      "avg / total       0.64      0.53      0.51       352\n",
      "\n",
      "[ 4  0  0  0  0  1  0  1  4  3  0  0  0  0  3  0  1  0  1  0  1  4  1  0\n",
      "  0  0  0  0 18  2  0  2  0  6 10  2  0  0  0  0  0  1 27  0  0  4  3  8\n",
      "  1  0  0  1  0  0  0  0  1  4  0  2  3  0  0  0  0  0  0  3  0  0 18  0\n",
      "  9  3  1  0  0  0  0  0  0  5  0  0  4  4  5  0  0  0  0  0  0  0  0  0\n",
      "  0  1 34  6  2  0  0  1  0  0  0  2  0  0  0  7 52  4  0  0  0  0  0  0\n",
      "  0  0  0  0  4 10 17  0  0  0  0  0  0  0  0  0  0  3  6  2  4  0  0  0\n",
      "  0  0  0  0  0  0  6  3  1  0  1  0  0  0  0  1  0  0  0  2 10  0  0  0\n",
      "  2]\n",
      "LR Accuracy:  0.5255681818181818\n",
      "LR F1:  0.4322916415360002\n",
      "For name:  m_magnusson\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0003-1710-5936': 24, '0000-0002-6565-4027': 22, '0000-0002-3141-8544': 10, '0000-0002-7574-1095': 7, '0000-0002-8049-2142': 3, '0000-0001-5388-6608': 1})\n",
      "['0000-0002-3141-8544', '0000-0002-6565-4027', '0000-0003-1710-5936']\n",
      "Total sample size after apply threshold:  56\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 15)\n",
      "2\n",
      "(56, 47)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.30      0.40        10\n",
      "          1       0.74      0.77      0.76        22\n",
      "          2       0.71      0.83      0.77        24\n",
      "\n",
      "avg / total       0.70      0.71      0.70        56\n",
      "\n",
      "[ 3  3  4  1 17  4  1  3 20]\n",
      "MNB Accuracy:  0.7142857142857143\n",
      "MNB F1:  0.6415954415954416\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.50      0.50        10\n",
      "          1       0.84      0.73      0.78        22\n",
      "          2       0.74      0.83      0.78        24\n",
      "\n",
      "avg / total       0.74      0.73      0.73        56\n",
      "\n",
      "[ 5  1  4  3 16  3  2  2 20]\n",
      "svc Accuracy:  0.7321428571428571\n",
      "svc F1:  0.688267176789415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.10      0.17        10\n",
      "          1       0.76      0.86      0.81        22\n",
      "          2       0.72      0.88      0.79        24\n",
      "\n",
      "avg / total       0.70      0.73      0.69        56\n",
      "\n",
      "[ 1  4  5  0 19  3  1  2 21]\n",
      "LR Accuracy:  0.7321428571428571\n",
      "LR F1:  0.5892100450510728\n",
      "For name:  m_foster\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0001-9645-7491': 43, '0000-0002-4524-141X': 43, '0000-0001-6392-7418': 6, '0000-0002-4453-7788': 5, '0000-0002-3100-0885': 3, '0000-0003-2257-4825': 3})\n",
      "['0000-0001-9645-7491', '0000-0002-4524-141X']\n",
      "Total sample size after apply threshold:  86\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 18)\n",
      "2\n",
      "(86, 38)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91        43\n",
      "          1       0.86      1.00      0.92        43\n",
      "\n",
      "avg / total       0.93      0.92      0.92        86\n",
      "\n",
      "[36  7  0 43]\n",
      "MNB Accuracy:  0.9186046511627907\n",
      "MNB F1:  0.918061793929495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        43\n",
      "          1       1.00      1.00      1.00        43\n",
      "\n",
      "avg / total       1.00      1.00      1.00        86\n",
      "\n",
      "[43  0  0 43]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        43\n",
      "          1       1.00      0.95      0.98        43\n",
      "\n",
      "avg / total       0.98      0.98      0.98        86\n",
      "\n",
      "[43  0  2 41]\n",
      "LR Accuracy:  0.9767441860465116\n",
      "LR F1:  0.9767316017316018\n",
      "For name:  j_lynch\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-1227-2252': 7, '0000-0003-0889-2616': 6, '0000-0003-3624-2741': 4, '0000-0003-0108-2127': 2, '0000-0002-4094-3738': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_boyle\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-9404-6901': 10, '0000-0002-5687-9857': 1, '0000-0002-3616-1637': 1, '0000-0001-6173-6765': 1, '0000-0002-6330-6870': 1})\n",
      "['0000-0002-9404-6901']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  r_turner\n",
      "total sample size before apply threshold:  147\n",
      "Counter({'0000-0001-5055-9644': 58, '0000-0001-7534-2935': 44, '0000-0003-4278-8302': 19, '0000-0001-5523-0645': 15, '0000-0002-0393-8593': 7, '0000-0002-9263-0776': 2, '0000-0002-3938-5513': 1, '0000-0003-0853-5360': 1})\n",
      "['0000-0001-7534-2935', '0000-0001-5055-9644', '0000-0001-5523-0645', '0000-0003-4278-8302']\n",
      "Total sample size after apply threshold:  136\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(136, 69)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(136, 20)\n",
      "2\n",
      "(136, 89)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.61      0.65        44\n",
      "          1       0.64      0.95      0.76        58\n",
      "          2       0.50      0.07      0.12        15\n",
      "          3       0.44      0.21      0.29        19\n",
      "\n",
      "avg / total       0.61      0.64      0.59       136\n",
      "\n",
      "[27 11  1  5  3 55  0  0  0 14  1  0  9  6  0  4]\n",
      "MNB Accuracy:  0.6397058823529411\n",
      "MNB F1:  0.45446316076631454\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.77      0.70        44\n",
      "          1       0.75      0.90      0.82        58\n",
      "          2       0.86      0.40      0.55        15\n",
      "          3       0.57      0.21      0.31        19\n",
      "\n",
      "avg / total       0.70      0.71      0.68       136\n",
      "\n",
      "[34  6  1  3  6 52  0  0  3  6  6  0 10  5  0  4]\n",
      "svc Accuracy:  0.7058823529411765\n",
      "svc F1:  0.593268854694295\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.73      0.70        44\n",
      "          1       0.67      0.90      0.76        58\n",
      "          2       0.80      0.27      0.40        15\n",
      "          3       0.80      0.21      0.33        19\n",
      "\n",
      "avg / total       0.70      0.68      0.64       136\n",
      "\n",
      "[32 10  1  1  6 52  0  0  1 10  4  0  9  6  0  4]\n",
      "LR Accuracy:  0.6764705882352942\n",
      "LR F1:  0.5484228473998295\n",
      "For name:  s_brooks\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-8437-9788': 32, '0000-0002-4592-4974': 16, '0000-0002-5701-0125': 7, '0000-0001-6377-1644': 3})\n",
      "['0000-0002-8437-9788', '0000-0002-4592-4974']\n",
      "Total sample size after apply threshold:  48\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 13)\n",
      "2\n",
      "(48, 33)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85        32\n",
      "          1       0.71      0.62      0.67        16\n",
      "\n",
      "avg / total       0.79      0.79      0.79        48\n",
      "\n",
      "[28  4  6 10]\n",
      "MNB Accuracy:  0.7916666666666666\n",
      "MNB F1:  0.7575757575757576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91        32\n",
      "          1       0.86      0.75      0.80        16\n",
      "\n",
      "avg / total       0.87      0.88      0.87        48\n",
      "\n",
      "[30  2  4 12]\n",
      "svc Accuracy:  0.875\n",
      "svc F1:  0.8545454545454545\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        32\n",
      "          1       1.00      0.62      0.77        16\n",
      "\n",
      "avg / total       0.89      0.88      0.87        48\n",
      "\n",
      "[32  0  6 10]\n",
      "LR Accuracy:  0.875\n",
      "LR F1:  0.8417582417582418\n",
      "For name:  p_moreira\n",
      "total sample size before apply threshold:  217\n",
      "Counter({'0000-0001-5177-6747': 133, '0000-0002-7035-7799': 68, '0000-0002-2800-3903': 6, '0000-0002-5454-7971': 4, '0000-0003-0452-6790': 2, '0000-0002-0004-851X': 2, '0000-0001-7247-6815': 1, '0000-0001-6919-0904': 1})\n",
      "['0000-0001-5177-6747', '0000-0002-7035-7799']\n",
      "Total sample size after apply threshold:  201\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(201, 120)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(201, 16)\n",
      "2\n",
      "(201, 136)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.95      0.85       133\n",
      "          1       0.83      0.44      0.58        68\n",
      "\n",
      "avg / total       0.79      0.78      0.76       201\n",
      "\n",
      "[127   6  38  30]\n",
      "MNB Accuracy:  0.7810945273631841\n",
      "MNB F1:  0.7146360351058338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.97      0.89       133\n",
      "          1       0.91      0.57      0.70        68\n",
      "\n",
      "avg / total       0.85      0.84      0.82       201\n",
      "\n",
      "[129   4  29  39]\n",
      "svc Accuracy:  0.835820895522388\n",
      "svc F1:  0.7946503204235162\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.95      0.84       133\n",
      "          1       0.80      0.35      0.49        68\n",
      "\n",
      "avg / total       0.76      0.75      0.72       201\n",
      "\n",
      "[127   6  44  24]\n",
      "LR Accuracy:  0.7512437810945274\n",
      "LR F1:  0.6626611170784104\n",
      "For name:  s_mukhopadhyay\n",
      "total sample size before apply threshold:  119\n",
      "Counter({'0000-0001-8033-5748': 49, '0000-0001-9660-2599': 37, '0000-0003-1242-9958': 18, '0000-0003-4790-3090': 8, '0000-0002-1838-2815': 5, '0000-0002-4056-2185': 1, '0000-0002-6290-6380': 1})\n",
      "['0000-0003-1242-9958', '0000-0001-8033-5748', '0000-0001-9660-2599']\n",
      "Total sample size after apply threshold:  104\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(104, 46)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(104, 14)\n",
      "2\n",
      "(104, 60)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.39      0.47        18\n",
      "          1       0.79      0.92      0.85        49\n",
      "          2       0.80      0.76      0.78        37\n",
      "\n",
      "avg / total       0.76      0.77      0.76       104\n",
      "\n",
      "[ 7  6  5  2 45  2  3  6 28]\n",
      "MNB Accuracy:  0.7692307692307693\n",
      "MNB F1:  0.6978336827393431\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.50      0.62        18\n",
      "          1       0.83      0.90      0.86        49\n",
      "          2       0.75      0.81      0.78        37\n",
      "\n",
      "avg / total       0.80      0.80      0.79       104\n",
      "\n",
      "[ 9  4  5  0 44  5  2  5 30]\n",
      "svc Accuracy:  0.7980769230769231\n",
      "svc F1:  0.7542185108108028\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.22      0.35        18\n",
      "          1       0.79      0.92      0.85        49\n",
      "          2       0.71      0.81      0.76        37\n",
      "\n",
      "avg / total       0.76      0.76      0.73       104\n",
      "\n",
      "[ 4  6  8  0 45  4  1  6 30]\n",
      "LR Accuracy:  0.7596153846153846\n",
      "LR F1:  0.6521254538720609\n",
      "For name:  a_hudson\n",
      "total sample size before apply threshold:  129\n",
      "Counter({'0000-0003-1105-7646': 86, '0000-0002-0192-776X': 15, '0000-0003-1849-9666': 13, '0000-0001-7292-5406': 6, '0000-0001-6436-2025': 5, '0000-0001-9016-6917': 4})\n",
      "['0000-0002-0192-776X', '0000-0003-1849-9666', '0000-0003-1105-7646']\n",
      "Total sample size after apply threshold:  114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 52)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 29)\n",
      "2\n",
      "(114, 81)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.73      0.71        15\n",
      "          1       0.67      0.15      0.25        13\n",
      "          2       0.87      0.97      0.92        86\n",
      "\n",
      "avg / total       0.83      0.84      0.81       114\n",
      "\n",
      "[11  0  4  3  2  8  2  1 83]\n",
      "MNB Accuracy:  0.8421052631578947\n",
      "MNB F1:  0.6256014970593476\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.87      0.90        15\n",
      "          1       0.33      0.15      0.21        13\n",
      "          2       0.89      0.98      0.93        86\n",
      "\n",
      "avg / total       0.83      0.87      0.85       114\n",
      "\n",
      "[13  2  0  1  2 10  0  2 84]\n",
      "svc Accuracy:  0.868421052631579\n",
      "svc F1:  0.680137124420246\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        15\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.77      1.00      0.87        86\n",
      "\n",
      "avg / total       0.72      0.78      0.70       114\n",
      "\n",
      "[ 3  0 12  0  0 13  0  0 86]\n",
      "LR Accuracy:  0.7807017543859649\n",
      "LR F1:  0.40214326001128037\n",
      "For name:  d_thomas\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0001-8832-5907': 17, '0000-0002-8141-3362': 11, '0000-0002-8278-5934': 10, '0000-0002-1307-6042': 6, '0000-0002-7976-4956': 6, '0000-0002-1053-129X': 5, '0000-0001-9415-5991': 4, '0000-0001-6867-5504': 2, '0000-0003-4295-9765': 1})\n",
      "['0000-0002-8278-5934', '0000-0001-8832-5907', '0000-0002-8141-3362']\n",
      "Total sample size after apply threshold:  38\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 25)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 10)\n",
      "2\n",
      "(38, 35)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.80      0.73        10\n",
      "          1       0.68      0.76      0.72        17\n",
      "          2       0.71      0.45      0.56        11\n",
      "\n",
      "avg / total       0.69      0.68      0.68        38\n",
      "\n",
      "[ 8  1  1  3 13  1  1  5  5]\n",
      "MNB Accuracy:  0.6842105263157895\n",
      "MNB F1:  0.6683501683501684\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.70      0.67        10\n",
      "          1       0.65      0.76      0.70        17\n",
      "          2       0.71      0.45      0.56        11\n",
      "\n",
      "avg / total       0.67      0.66      0.65        38\n",
      "\n",
      "[ 7  2  1  3 13  1  1  5  5]\n",
      "svc Accuracy:  0.6578947368421053\n",
      "svc F1:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6416416416416416\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70        10\n",
      "          1       0.62      0.76      0.68        17\n",
      "          2       0.71      0.45      0.56        11\n",
      "\n",
      "avg / total       0.67      0.66      0.65        38\n",
      "\n",
      "[ 7  2  1  3 13  1  0  6  5]\n",
      "LR Accuracy:  0.6578947368421053\n",
      "LR F1:  0.646588693957115\n",
      "For name:  w_smith\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-4610-998X': 37, '0000-0003-2108-3899': 11, '0000-0002-5785-6489': 6, '0000-0001-9640-1172': 4, '0000-0003-1749-023X': 1, '0000-0001-6611-0817': 1, '0000-0002-8814-015X': 1})\n",
      "['0000-0002-4610-998X', '0000-0003-2108-3899']\n",
      "Total sample size after apply threshold:  48\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 24)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 15)\n",
      "2\n",
      "(48, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.92      0.88        37\n",
      "          1       0.62      0.45      0.53        11\n",
      "\n",
      "avg / total       0.80      0.81      0.80        48\n",
      "\n",
      "[34  3  6  5]\n",
      "MNB Accuracy:  0.8125\n",
      "MNB F1:  0.7047163362952836\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.92      0.86        37\n",
      "          1       0.50      0.27      0.35        11\n",
      "\n",
      "avg / total       0.74      0.77      0.74        48\n",
      "\n",
      "[34  3  8  3]\n",
      "svc Accuracy:  0.7708333333333334\n",
      "svc F1:  0.606850335070737\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.95      0.88        37\n",
      "          1       0.60      0.27      0.37        11\n",
      "\n",
      "avg / total       0.76      0.79      0.76        48\n",
      "\n",
      "[35  2  8  3]\n",
      "LR Accuracy:  0.7916666666666666\n",
      "LR F1:  0.625\n",
      "For name:  l_martin\n",
      "total sample size before apply threshold:  253\n",
      "Counter({'0000-0001-8702-9946': 105, '0000-0003-4352-0914': 55, '0000-0002-5887-4937': 36, '0000-0003-1919-8646': 14, '0000-0001-7241-7110': 12, '0000-0002-1231-7932': 11, '0000-0002-0594-4516': 7, '0000-0002-5330-5700': 6, '0000-0003-1889-2513': 4, '0000-0002-4770-2849': 1, '0000-0001-9731-8071': 1, '0000-0001-9371-3402': 1})\n",
      "['0000-0001-7241-7110', '0000-0002-1231-7932', '0000-0002-5887-4937', '0000-0003-1919-8646', '0000-0001-8702-9946', '0000-0003-4352-0914']\n",
      "Total sample size after apply threshold:  233\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(233, 129)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(233, 19)\n",
      "2\n",
      "(233, 148)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.50      0.09      0.15        11\n",
      "          2       0.70      0.64      0.67        36\n",
      "          3       0.00      0.00      0.00        14\n",
      "          4       0.61      0.88      0.72       105\n",
      "          5       0.58      0.51      0.54        55\n",
      "\n",
      "avg / total       0.55      0.62      0.56       233\n",
      "\n",
      "[ 0  1  2  0  6  3  0  1  3  0  4  3  0  0 23  0 12  1  0  0  4  0  9  1\n",
      "  0  0  1  0 92 12  0  0  0  0 27 28]\n",
      "MNB Accuracy:  0.6180257510729614\n",
      "MNB F1:  0.347628461392025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.83      0.45      0.59        11\n",
      "          2       0.76      0.78      0.77        36\n",
      "          3       1.00      0.50      0.67        14\n",
      "          4       0.73      0.86      0.79       105\n",
      "          5       0.62      0.60      0.61        55\n",
      "\n",
      "avg / total       0.74      0.73      0.72       233\n",
      "\n",
      "[ 6  1  1  0  2  2  0  5  2  0  2  2  0  0 28  0  6  2  0  0  3  7  3  1\n",
      "  0  0  2  0 90 13  0  0  1  0 21 33]\n",
      "svc Accuracy:  0.7253218884120172\n",
      "svc F1:  0.6809715378511144\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        12\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       0.71      0.56      0.63        36\n",
      "          3       0.00      0.00      0.00        14\n",
      "          4       0.59      0.88      0.70       105\n",
      "          5       0.60      0.49      0.54        55\n",
      "\n",
      "avg / total       0.62      0.61      0.57       233\n",
      "\n",
      "[ 3  0  1  0  6  2  0  1  2  0  5  3  0  0 20  0 16  0  0  0  4  0  9  1\n",
      "  0  0  1  0 92 12  0  0  0  0 28 27]\n",
      "LR Accuracy:  0.6137339055793991\n",
      "LR F1:  0.40610791826309073\n",
      "For name:  c_garcia\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0003-2825-1701': 46, '0000-0002-7583-5585': 37, '0000-0002-4400-9141': 13, '0000-0001-5260-5093': 8, '0000-0001-5138-6191': 1, '0000-0001-7997-9837': 1})\n",
      "['0000-0002-7583-5585', '0000-0003-2825-1701', '0000-0002-4400-9141']\n",
      "Total sample size after apply threshold:  96\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(96, 53)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(96, 22)\n",
      "2\n",
      "(96, 75)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.86      0.74        37\n",
      "          1       0.82      0.80      0.81        46\n",
      "          2       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.64      0.72      0.67        96\n",
      "\n",
      "[32  5  0  8 37  1 10  3  0]\n",
      "MNB Accuracy:  0.71875\n",
      "MNB F1:  0.5162729990316196\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.86      0.85        37\n",
      "          1       0.80      0.89      0.85        46\n",
      "          2       0.86      0.46      0.60        13\n",
      "\n",
      "avg / total       0.83      0.82      0.82        96\n",
      "\n",
      "[32  5  0  4 41  1  2  5  6]\n",
      "svc Accuracy:  0.8229166666666666\n",
      "svc F1:  0.7662313860252005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.81      0.76        37\n",
      "          1       0.74      0.87      0.80        46\n",
      "          2       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.63      0.73      0.68        96\n",
      "\n",
      "[30  7  0  6 40  0  6  7  0]\n",
      "LR Accuracy:  0.7291666666666666\n",
      "LR F1:  0.5198312236286919\n",
      "For name:  g_huang\n",
      "total sample size before apply threshold:  160\n",
      "Counter({'0000-0001-7004-826X': 52, '0000-0003-2965-0341': 31, '0000-0002-0001-888X': 22, '0000-0002-8391-4013': 17, '0000-0003-2170-0084': 16, '0000-0002-2249-1248': 9, '0000-0003-2518-8145': 6, '0000-0003-1695-1153': 2, '0000-0003-1073-4967': 2, '0000-0002-7597-9386': 2, '0000-0001-7780-7409': 1})\n",
      "['0000-0003-2965-0341', '0000-0003-2170-0084', '0000-0001-7004-826X', '0000-0002-0001-888X', '0000-0002-8391-4013']\n",
      "Total sample size after apply threshold:  138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(138, 78)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(138, 24)\n",
      "2\n",
      "(138, 102)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.84      0.66        31\n",
      "          1       0.33      0.06      0.11        16\n",
      "          2       0.64      0.83      0.72        52\n",
      "          3       0.50      0.36      0.42        22\n",
      "          4       0.75      0.18      0.29        17\n",
      "\n",
      "avg / total       0.57      0.59      0.53       138\n",
      "\n",
      "[26  0  2  3  0  5  1  8  2  0  4  1 43  3  1  9  1  4  8  0  4  0 10  0\n",
      "  3]\n",
      "MNB Accuracy:  0.5869565217391305\n",
      "MNB F1:  0.43858939978389755\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.81      0.82        31\n",
      "          1       0.78      0.44      0.56        16\n",
      "          2       0.70      0.90      0.79        52\n",
      "          3       0.63      0.55      0.59        22\n",
      "          4       0.46      0.35      0.40        17\n",
      "\n",
      "avg / total       0.70      0.70      0.69       138\n",
      "\n",
      "[25  0  3  3  0  0  7  6  3  0  0  1 47  0  4  4  1  2 12  3  1  0  9  1\n",
      "  6]\n",
      "svc Accuracy:  0.7028985507246377\n",
      "svc F1:  0.6309907902385264\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.77      0.75        31\n",
      "          1       0.00      0.00      0.00        16\n",
      "          2       0.60      0.94      0.74        52\n",
      "          3       0.56      0.41      0.47        22\n",
      "          4       0.67      0.24      0.35        17\n",
      "\n",
      "avg / total       0.56      0.62      0.56       138\n",
      "\n",
      "[24  0  4  3  0  3  0 11  2  0  1  1 49  0  1  5  1  6  9  1  0  0 11  2\n",
      "  4]\n",
      "LR Accuracy:  0.6231884057971014\n",
      "LR F1:  0.46167048054919907\n",
      "For name:  j_huber\n",
      "total sample size before apply threshold:  96\n",
      "Counter({'0000-0001-7243-8958': 59, '0000-0002-4790-7633': 21, '0000-0003-1046-2754': 14, '0000-0003-0073-0321': 2})\n",
      "['0000-0001-7243-8958', '0000-0003-1046-2754', '0000-0002-4790-7633']\n",
      "Total sample size after apply threshold:  94\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 49)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 15)\n",
      "2\n",
      "(94, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        59\n",
      "          1       1.00      0.79      0.88        14\n",
      "          2       1.00      0.52      0.69        21\n",
      "\n",
      "avg / total       0.89      0.86      0.85        94\n",
      "\n",
      "[59  0  0  3 11  0 10  0 11]\n",
      "MNB Accuracy:  0.8617021276595744\n",
      "MNB F1:  0.8227544529262086\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        59\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       1.00      0.67      0.80        21\n",
      "\n",
      "avg / total       0.90      0.88      0.88        94\n",
      "\n",
      "[59  0  0  4 10  0  7  0 14]\n",
      "svc Accuracy:  0.8829787234042553\n",
      "svc F1:  0.8493540051679588\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        59\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       1.00      0.33      0.50        21\n",
      "\n",
      "avg / total       0.85      0.81      0.78        94\n",
      "\n",
      "[59  0  0  4 10  0 14  0  7]\n",
      "LR Accuracy:  0.8085106382978723\n",
      "LR F1:  0.7336601307189542\n",
      "For name:  j_qin\n",
      "total sample size before apply threshold:  96\n",
      "Counter({'0000-0002-8559-616X': 48, '0000-0003-2448-8058': 38, '0000-0002-8186-5705': 4, '0000-0001-6271-068X': 3, '0000-0002-9166-3533': 3})\n",
      "['0000-0003-2448-8058', '0000-0002-8559-616X']\n",
      "Total sample size after apply threshold:  86\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 47)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 10)\n",
      "2\n",
      "(86, 57)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.76      0.72        38\n",
      "          1       0.80      0.73      0.76        48\n",
      "\n",
      "avg / total       0.75      0.74      0.75        86\n",
      "\n",
      "[29  9 13 35]\n",
      "MNB Accuracy:  0.7441860465116279\n",
      "MNB F1:  0.7429347826086956\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.55      0.67        38\n",
      "          1       0.72      0.92      0.81        48\n",
      "\n",
      "avg / total       0.77      0.76      0.75        86\n",
      "\n",
      "[21 17  4 44]\n",
      "svc Accuracy:  0.7558139534883721\n",
      "svc F1:  0.7370030581039755\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.58      0.67        38\n",
      "          1       0.72      0.88      0.79        48\n",
      "\n",
      "avg / total       0.75      0.74      0.74        86\n",
      "\n",
      "[22 16  6 42]\n",
      "LR Accuracy:  0.7441860465116279\n",
      "LR F1:  0.729559748427673\n",
      "For name:  t_ho\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0002-3489-3594': 68, '0000-0003-0914-306X': 13, '0000-0003-1412-711X': 2})\n",
      "['0000-0002-3489-3594', '0000-0003-0914-306X']\n",
      "Total sample size after apply threshold:  81\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 40)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 21)\n",
      "2\n",
      "(81, 61)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.96      0.92        68\n",
      "          1       0.57      0.31      0.40        13\n",
      "\n",
      "avg / total       0.83      0.85      0.83        81\n",
      "\n",
      "[65  3  9  4]\n",
      "MNB Accuracy:  0.8518518518518519\n",
      "MNB F1:  0.6577464788732394\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.95        68\n",
      "          1       0.88      0.54      0.67        13\n",
      "\n",
      "avg / total       0.91      0.91      0.90        81\n",
      "\n",
      "[67  1  6  7]\n",
      "svc Accuracy:  0.9135802469135802\n",
      "svc F1:  0.8085106382978724\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        68\n",
      "          1       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.70      0.84      0.77        81\n",
      "\n",
      "[68  0 13  0]\n",
      "LR Accuracy:  0.8395061728395061\n",
      "LR F1:  0.4563758389261745\n",
      "For name:  c_keller\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0003-0529-3490': 10, '0000-0001-7400-9428': 2, '0000-0001-7915-7622': 2, '0000-0003-2505-7487': 1})\n",
      "['0000-0003-0529-3490']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  m_maia\n",
      "total sample size before apply threshold:  99\n",
      "Counter({'0000-0002-7034-8091': 88, '0000-0002-1716-6205': 6, '0000-0003-4383-3822': 3, '0000-0001-6395-1469': 1, '0000-0001-6688-2745': 1})\n",
      "['0000-0002-7034-8091']\n",
      "Total sample size after apply threshold:  88\n",
      "For name:  p_bates\n",
      "total sample size before apply threshold:  154\n",
      "Counter({'0000-0001-6861-5421': 87, '0000-0002-3918-5976': 49, '0000-0002-1291-3363': 17, '0000-0001-9192-9963': 1})\n",
      "['0000-0002-1291-3363', '0000-0002-3918-5976', '0000-0001-6861-5421']\n",
      "Total sample size after apply threshold:  153\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(153, 63)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(153, 34)\n",
      "2\n",
      "(153, 97)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.41      0.54        17\n",
      "          1       0.77      0.88      0.82        49\n",
      "          2       0.83      0.84      0.83        87\n",
      "\n",
      "avg / total       0.80      0.80      0.80       153\n",
      "\n",
      "[ 7  1  9  0 43  6  2 12 73]\n",
      "MNB Accuracy:  0.803921568627451\n",
      "MNB F1:  0.7305982905982905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.53      0.69        17\n",
      "          1       0.93      0.76      0.83        49\n",
      "          2       0.82      0.98      0.89        87\n",
      "\n",
      "avg / total       0.87      0.86      0.85       153\n",
      "\n",
      "[ 9  1  7  0 37 12  0  2 85]\n",
      "svc Accuracy:  0.8562091503267973\n",
      "svc F1:  0.8046069074953127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.12      0.21        17\n",
      "          1       0.97      0.71      0.82        49\n",
      "          2       0.76      1.00      0.86        87\n",
      "\n",
      "avg / total       0.85      0.81      0.78       153\n",
      "\n",
      "[ 2  1 14  0 35 14  0  0 87]\n",
      "LR Accuracy:  0.8104575163398693\n",
      "LR F1:  0.6318139553893469\n",
      "For name:  s_chow\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0001-9471-4722': 21, '0000-0002-3600-0497': 6, '0000-0003-0544-6928': 1, '0000-0002-4392-3863': 1})\n",
      "['0000-0001-9471-4722']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  m_simon\n",
      "total sample size before apply threshold:  66\n",
      "Counter({'0000-0003-3655-6329': 44, '0000-0003-2349-7219': 12, '0000-0003-0611-495X': 5, '0000-0002-1509-2847': 3, '0000-0003-3080-3675': 1, '0000-0002-0065-6486': 1})\n",
      "['0000-0003-3655-6329', '0000-0003-2349-7219']\n",
      "Total sample size after apply threshold:  56\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 13)\n",
      "2\n",
      "(56, 41)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.91        44\n",
      "          1       0.83      0.42      0.56        12\n",
      "\n",
      "avg / total       0.85      0.86      0.84        56\n",
      "\n",
      "[43  1  7  5]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.7352245862884161\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.95        44\n",
      "          1       0.89      0.67      0.76        12\n",
      "\n",
      "avg / total       0.91      0.91      0.91        56\n",
      "\n",
      "[43  1  4  8]\n",
      "svc Accuracy:  0.9107142857142857\n",
      "svc F1:  0.8534798534798536\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.98      0.88        44\n",
      "          1       0.50      0.08      0.14        12\n",
      "\n",
      "avg / total       0.73      0.79      0.72        56\n",
      "\n",
      "[43  1 11  1]\n",
      "LR Accuracy:  0.7857142857142857\n",
      "LR F1:  0.5102040816326531\n",
      "For name:  s_kar\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0002-9411-2091': 20, '0000-0002-3788-372X': 7, '0000-0002-5032-4770': 4, '0000-0003-3702-6207': 3, '0000-0002-0498-812X': 2})\n",
      "['0000-0002-9411-2091']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  d_vlachos\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0002-6795-8403': 80, '0000-0003-3740-2575': 19, '0000-0002-0430-2386': 1, '0000-0001-7225-2862': 1})\n",
      "['0000-0002-6795-8403', '0000-0003-3740-2575']\n",
      "Total sample size after apply threshold:  99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(99, 43)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(99, 14)\n",
      "2\n",
      "(99, 57)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.96        80\n",
      "          1       0.83      0.79      0.81        19\n",
      "\n",
      "avg / total       0.93      0.93      0.93        99\n",
      "\n",
      "[77  3  4 15]\n",
      "MNB Accuracy:  0.9292929292929293\n",
      "MNB F1:  0.8836662749706228\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.96        80\n",
      "          1       0.83      0.79      0.81        19\n",
      "\n",
      "avg / total       0.93      0.93      0.93        99\n",
      "\n",
      "[77  3  4 15]\n",
      "svc Accuracy:  0.9292929292929293\n",
      "svc F1:  0.8836662749706228\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92        80\n",
      "          1       0.86      0.32      0.46        19\n",
      "\n",
      "avg / total       0.86      0.86      0.83        99\n",
      "\n",
      "[79  1 13  6]\n",
      "LR Accuracy:  0.8585858585858586\n",
      "LR F1:  0.6900715563506261\n",
      "For name:  e_law\n",
      "total sample size before apply threshold:  12\n",
      "Counter({'0000-0002-4021-2150': 5, '0000-0001-5089-6341': 3, '0000-0003-4456-1259': 3, '0000-0001-5591-7316': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_ribeiro\n",
      "total sample size before apply threshold:  134\n",
      "Counter({'0000-0001-8906-0189': 25, '0000-0002-5964-5001': 17, '0000-0001-5693-7861': 16, '0000-0001-6422-3279': 13, '0000-0001-9365-6057': 12, '0000-0001-6357-8115': 10, '0000-0002-7434-4813': 7, '0000-0002-9350-6419': 7, '0000-0003-4529-7832': 5, '0000-0003-1167-5559': 5, '0000-0001-9538-821X': 5, '0000-0001-7350-8751': 4, '0000-0003-3373-3246': 3, '0000-0003-4684-1262': 2, '0000-0001-9575-008X': 1, '0000-0003-1704-1362': 1, '0000-0002-6071-6479': 1})\n",
      "['0000-0001-6422-3279', '0000-0001-6357-8115', '0000-0001-8906-0189', '0000-0002-5964-5001', '0000-0001-5693-7861', '0000-0001-9365-6057']\n",
      "Total sample size after apply threshold:  93\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(93, 69)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(93, 21)\n",
      "2\n",
      "(93, 90)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.26      0.44      0.33        25\n",
      "          3       0.31      0.29      0.30        17\n",
      "          4       0.42      0.50      0.46        16\n",
      "          5       0.38      0.25      0.30        12\n",
      "\n",
      "avg / total       0.25      0.29      0.26        93\n",
      "\n",
      "[ 0  1  6  2  3  1  2  0  6  2  0  0  2  1 11  4  5  2  0  0  8  5  3  1\n",
      "  1  0  5  1  8  1  1  0  6  2  0  3]\n",
      "MNB Accuracy:  0.2903225806451613\n",
      "MNB F1:  0.23142189485473066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.31      0.32        13\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.28      0.44      0.34        25\n",
      "          3       0.35      0.35      0.35        17\n",
      "          4       0.69      0.56      0.62        16\n",
      "          5       0.89      0.67      0.76        12\n",
      "\n",
      "avg / total       0.42      0.41      0.41        93\n",
      "\n",
      "[ 4  1  6  1  1  0  3  0  5  2  0  0  4  1 11  6  2  1  0  0 10  6  1  0\n",
      "  1  0  5  1  9  0  0  0  3  1  0  8]\n",
      "svc Accuracy:  0.40860215053763443\n",
      "svc F1:  0.39899952200155037\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.24      0.44      0.31        25\n",
      "          3       0.31      0.29      0.30        17\n",
      "          4       0.50      0.50      0.50        16\n",
      "          5       0.60      0.50      0.55        12\n",
      "\n",
      "avg / total       0.29      0.32      0.30        93\n",
      "\n",
      "[ 0  0  7  2  3  1  2  0  6  2  0  0  2  1 11  5  3  3  0  0 10  5  2  0\n",
      "  1  0  7  0  8  0  0  0  4  2  0  6]\n",
      "LR Accuracy:  0.3225806451612903\n",
      "LR F1:  0.2771284271284271\n",
      "For name:  r_king\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0001-7208-4387': 39, '0000-0002-3550-4255': 19, '0000-0003-1312-5593': 8, '0000-0001-7495-6599': 2, '0000-0002-7926-3764': 1})\n",
      "['0000-0001-7208-4387', '0000-0002-3550-4255']\n",
      "Total sample size after apply threshold:  58\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(58, 38)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(58, 23)\n",
      "2\n",
      "(58, 61)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.92      0.82        39\n",
      "          1       0.67      0.32      0.43        19\n",
      "\n",
      "avg / total       0.71      0.72      0.69        58\n",
      "\n",
      "[36  3 13  6]\n",
      "MNB Accuracy:  0.7241379310344828\n",
      "MNB F1:  0.6233766233766234\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.87        39\n",
      "          1       1.00      0.37      0.54        19\n",
      "\n",
      "avg / total       0.84      0.79      0.76        58\n",
      "\n",
      "[39  0 12  7]\n",
      "svc Accuracy:  0.7931034482758621\n",
      "svc F1:  0.7025641025641025\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        39\n",
      "          1       1.00      0.16      0.27        19\n",
      "\n",
      "avg / total       0.80      0.72      0.65        58\n",
      "\n",
      "[39  0 16  3]\n",
      "LR Accuracy:  0.7241379310344828\n",
      "LR F1:  0.5512572533849129\n",
      "For name:  o_nielsen\n",
      "total sample size before apply threshold:  212\n",
      "Counter({'0000-0003-4612-8635': 142, '0000-0003-3535-7862': 54, '0000-0002-0088-3937': 15, '0000-0001-8839-8671': 1})\n",
      "['0000-0003-4612-8635', '0000-0002-0088-3937', '0000-0003-3535-7862']\n",
      "Total sample size after apply threshold:  211\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(211, 106)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(211, 32)\n",
      "2\n",
      "(211, 138)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       142\n",
      "          1       1.00      0.27      0.42        15\n",
      "          2       0.89      0.74      0.81        54\n",
      "\n",
      "avg / total       0.87      0.86      0.84       211\n",
      "\n",
      "[137   0   5  11   4   0  14   0  40]\n",
      "MNB Accuracy:  0.8578199052132701\n",
      "MNB F1:  0.71014974304448\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       142\n",
      "          1       0.88      0.47      0.61        15\n",
      "          2       1.00      0.74      0.85        54\n",
      "\n",
      "avg / total       0.90      0.89      0.88       211\n",
      "\n",
      "[141   1   0   8   7   0  14   0  40]\n",
      "svc Accuracy:  0.8909952606635071\n",
      "svc F1:  0.7947832152985245\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.99      0.88       142\n",
      "          1       1.00      0.27      0.42        15\n",
      "          2       0.97      0.54      0.69        54\n",
      "\n",
      "avg / total       0.85      0.82      0.80       211\n",
      "\n",
      "[141   0   1  11   4   0  25   0  29]\n",
      "LR Accuracy:  0.8246445497630331\n",
      "LR F1:  0.665180453746697\n",
      "For name:  j_moreno\n",
      "total sample size before apply threshold:  138\n",
      "Counter({'0000-0003-0087-4659': 44, '0000-0002-8887-6087': 30, '0000-0002-7646-9345': 22, '0000-0001-9561-7764': 21, '0000-0002-3729-9523': 9, '0000-0002-0555-9888': 5, '0000-0002-3684-3726': 4, '0000-0001-6499-1120': 3})\n",
      "['0000-0002-8887-6087', '0000-0001-9561-7764', '0000-0002-7646-9345', '0000-0003-0087-4659']\n",
      "Total sample size after apply threshold:  117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 60)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 25)\n",
      "2\n",
      "(117, 85)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.40      0.52        30\n",
      "          1       0.91      0.48      0.62        21\n",
      "          2       0.83      0.68      0.75        22\n",
      "          3       0.57      0.93      0.71        44\n",
      "\n",
      "avg / total       0.73      0.67      0.65       117\n",
      "\n",
      "[12  0  2 16  1 10  0 10  1  1 15  5  2  0  1 41]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.6509089205397302\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.80      0.70        30\n",
      "          1       1.00      0.57      0.73        21\n",
      "          2       1.00      0.82      0.90        22\n",
      "          3       0.73      0.80      0.76        44\n",
      "\n",
      "avg / total       0.80      0.76      0.76       117\n",
      "\n",
      "[24  0  0  6  5 12  0  4  1  0 18  3  9  0  0 35]\n",
      "svc Accuracy:  0.7606837606837606\n",
      "svc F1:  0.7709486166007906\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.50      0.64        30\n",
      "          1       0.92      0.52      0.67        21\n",
      "          2       1.00      0.68      0.81        22\n",
      "          3       0.58      0.95      0.72        44\n",
      "\n",
      "avg / total       0.80      0.71      0.71       117\n",
      "\n",
      "[15  0  0 15  0 11  0 10  0  1 15  6  2  0  0 42]\n",
      "LR Accuracy:  0.7094017094017094\n",
      "LR F1:  0.7084310169416552\n",
      "For name:  f_yu\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0001-9306-1731': 30, '0000-0003-0268-199X': 23, '0000-0002-5221-281X': 7, '0000-0001-5808-9376': 6, '0000-0002-8140-8344': 5, '0000-0003-3859-4839': 5, '0000-0002-0358-2793': 2})\n",
      "['0000-0001-9306-1731', '0000-0003-0268-199X']\n",
      "Total sample size after apply threshold:  53\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 34)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 21)\n",
      "2\n",
      "(53, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.83      0.72        30\n",
      "          1       0.64      0.39      0.49        23\n",
      "\n",
      "avg / total       0.64      0.64      0.62        53\n",
      "\n",
      "[25  5 14  9]\n",
      "MNB Accuracy:  0.6415094339622641\n",
      "MNB F1:  0.6055620838229534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.77      0.70        30\n",
      "          1       0.59      0.43      0.50        23\n",
      "\n",
      "avg / total       0.62      0.62      0.61        53\n",
      "\n",
      "[23  7 13 10]\n",
      "svc Accuracy:  0.6226415094339622\n",
      "svc F1:  0.5984848484848485\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.80      0.71        30\n",
      "          1       0.60      0.39      0.47        23\n",
      "\n",
      "avg / total       0.62      0.62      0.61        53\n",
      "\n",
      "[24  6 14  9]\n",
      "LR Accuracy:  0.6226415094339622\n",
      "LR F1:  0.5897832817337462\n",
      "For name:  f_esposito\n",
      "total sample size before apply threshold:  342\n",
      "Counter({'0000-0002-5099-9786': 92, '0000-0003-1051-5924': 91, '0000-0001-9340-6875': 53, '0000-0002-4420-2611': 44, '0000-0003-2550-0805': 26, '0000-0001-9725-7977': 25, '0000-0001-7781-2558': 7, '0000-0003-0586-5866': 2, '0000-0001-9962-1648': 1, '0000-0002-1075-3239': 1})\n",
      "['0000-0003-2550-0805', '0000-0001-9340-6875', '0000-0002-4420-2611', '0000-0002-5099-9786', '0000-0001-9725-7977', '0000-0003-1051-5924']\n",
      "Total sample size after apply threshold:  331\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(331, 151)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(331, 30)\n",
      "2\n",
      "(331, 181)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.08      0.13        26\n",
      "          1       0.86      0.34      0.49        53\n",
      "          2       0.88      0.52      0.66        44\n",
      "          3       0.51      0.84      0.64        92\n",
      "          4       0.50      0.04      0.07        25\n",
      "          5       0.66      0.92      0.77        91\n",
      "\n",
      "avg / total       0.65      0.62      0.57       331\n",
      "\n",
      "[ 2  0  1 17  0  6  0 18  1 16  1 17  0  2 23 13  0  6  2  0  1 77  0 12\n",
      "  0  0  0 22  1  2  1  1  0  5  0 84]\n",
      "MNB Accuracy:  0.6193353474320241\n",
      "MNB F1:  0.45895691899440544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.58      0.67        26\n",
      "          1       0.74      0.55      0.63        53\n",
      "          2       1.00      0.66      0.79        44\n",
      "          3       0.54      0.88      0.67        92\n",
      "          4       0.62      0.20      0.30        25\n",
      "          5       0.90      0.85      0.87        91\n",
      "\n",
      "avg / total       0.76      0.71      0.71       331\n",
      "\n",
      "[15  0  0 10  0  1  0 29  0 19  2  3  0  2 29 12  0  1  3  4  0 81  0  4\n",
      "  0  3  0 17  5  0  1  1  0 11  1 77]\n",
      "svc Accuracy:  0.7129909365558912\n",
      "svc F1:  0.6556883808382197\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.31      0.43        26\n",
      "          1       0.76      0.49      0.60        53\n",
      "          2       1.00      0.55      0.71        44\n",
      "          3       0.53      0.84      0.65        92\n",
      "          4       0.60      0.12      0.20        25\n",
      "          5       0.73      0.90      0.81        91\n",
      "\n",
      "avg / total       0.71      0.66      0.64       331\n",
      "\n",
      "[ 8  1  0 14  0  3  0 26  0 16  2  9  0  4 24 11  0  5  3  1  0 77  0 11\n",
      "  0  0  0 20  3  2  0  2  0  7  0 82]\n",
      "LR Accuracy:  0.6646525679758308\n",
      "LR F1:  0.5656144562889628\n",
      "For name:  p_miranda\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0002-6793-8111': 37, '0000-0002-2890-0268': 14, '0000-0002-6418-3614': 7, '0000-0003-4348-110X': 6, '0000-0001-6496-697X': 3, '0000-0002-4288-9456': 1, '0000-0002-3249-0193': 1})\n",
      "['0000-0002-6793-8111', '0000-0002-2890-0268']\n",
      "Total sample size after apply threshold:  51\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 16)\n",
      "2\n",
      "(51, 44)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91        37\n",
      "          1       0.89      0.57      0.70        14\n",
      "\n",
      "avg / total       0.87      0.86      0.85        51\n",
      "\n",
      "[36  1  6  8]\n",
      "MNB Accuracy:  0.8627450980392157\n",
      "MNB F1:  0.8035222894881673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        37\n",
      "          1       1.00      0.64      0.78        14\n",
      "\n",
      "avg / total       0.91      0.90      0.89        51\n",
      "\n",
      "[37  0  5  9]\n",
      "svc Accuracy:  0.9019607843137255\n",
      "svc F1:  0.8596587782058338\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        37\n",
      "          1       1.00      0.43      0.60        14\n",
      "\n",
      "avg / total       0.87      0.84      0.82        51\n",
      "\n",
      "[37  0  8  6]\n",
      "LR Accuracy:  0.8431372549019608\n",
      "LR F1:  0.751219512195122\n",
      "For name:  s_yang\n",
      "total sample size before apply threshold:  611\n",
      "Counter({'0000-0002-6469-8415': 108, '0000-0003-1301-3030': 94, '0000-0002-8835-5302': 43, '0000-0001-6795-8879': 36, '0000-0003-1751-4975': 33, '0000-0002-8572-4977': 31, '0000-0002-9394-9148': 26, '0000-0002-9879-0164': 25, '0000-0001-7892-7648': 21, '0000-0002-1726-0576': 20, '0000-0001-5684-6388': 19, '0000-0002-6888-7993': 17, '0000-0001-9170-2566': 17, '0000-0003-1809-2938': 14, '0000-0001-9282-2041': 14, '0000-0003-3408-2019': 12, '0000-0002-8244-3002': 12, '0000-0001-9947-2822': 10, '0000-0002-4409-3160': 10, '0000-0002-0281-5858': 9, '0000-0002-2068-7618': 5, '0000-0001-6129-627X': 5, '0000-0002-8200-9898': 5, '0000-0001-8727-7528': 5, '0000-0001-7727-9669': 4, '0000-0002-8002-5800': 4, '0000-0001-7222-4917': 3, '0000-0002-5990-8529': 2, '0000-0003-0338-4268': 2, '0000-0002-6880-8861': 1, '0000-0001-7207-4082': 1, '0000-0001-7522-1463': 1, '0000-0003-3742-9989': 1, '0000-0002-3888-3211': 1})\n",
      "['0000-0002-6888-7993', '0000-0001-9947-2822', '0000-0003-1751-4975', '0000-0002-6469-8415', '0000-0003-3408-2019', '0000-0003-1809-2938', '0000-0003-1301-3030', '0000-0001-9282-2041', '0000-0002-8572-4977', '0000-0002-9394-9148', '0000-0002-4409-3160', '0000-0001-5684-6388', '0000-0001-7892-7648', '0000-0001-9170-2566', '0000-0002-8244-3002', '0000-0001-6795-8879', '0000-0002-9879-0164', '0000-0002-8835-5302', '0000-0002-1726-0576']\n",
      "Total sample size after apply threshold:  562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(562, 234)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(562, 16)\n",
      "2\n",
      "(562, 250)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        17\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.03      0.06        33\n",
      "          3       0.30      0.95      0.46       108\n",
      "          4       0.00      0.00      0.00        12\n",
      "          5       0.00      0.00      0.00        14\n",
      "          6       0.39      0.84      0.53        94\n",
      "          7       0.00      0.00      0.00        14\n",
      "          8       0.00      0.00      0.00        31\n",
      "          9       0.00      0.00      0.00        26\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       0.00      0.00      0.00        19\n",
      "         12       0.00      0.00      0.00        21\n",
      "         13       0.00      0.00      0.00        17\n",
      "         14       0.00      0.00      0.00        12\n",
      "         15       0.50      0.03      0.05        36\n",
      "         16       0.00      0.00      0.00        25\n",
      "         17       0.67      0.23      0.34        43\n",
      "         18       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.27      0.35      0.21       562\n",
      "\n",
      "[  0   0   0  15   0   0   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   6   0   0   2   0   0   0   0   0   0   0   0   0   0\n",
      "   2   0   0   0   1  20   0   0  12   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 103   0   0   4   0   0   0   0   0   0   0   0\n",
      "   1   0   0   0   0   0   0   6   0   0   6   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   7   0   0   7   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  15   0   0  79   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   4   0   0  10   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  26   0   0   5   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  16   0   0  10   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   6   0   0   4   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15   0   0   4\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8   0   0\n",
      "  13   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13   0\n",
      "   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7\n",
      "   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  26   0   0   9   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "   0  17   0   0   5   0   0   0   0   0   0   0   0   0   0   3   0   0\n",
      "   0   0  19   0   0  14   0   0   0   0   0   0   0   0   0   0  10   0\n",
      "   0   0   0  13   0   0   7   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "MNB Accuracy:  0.34519572953736655\n",
      "MNB F1:  0.07620232926987322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.65      0.79        17\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.42      0.60        33\n",
      "          3       0.36      0.86      0.51       108\n",
      "          4       1.00      0.25      0.40        12\n",
      "          5       0.30      0.21      0.25        14\n",
      "          6       0.62      0.79      0.69        94\n",
      "          7       1.00      0.21      0.35        14\n",
      "          8       0.90      0.29      0.44        31\n",
      "          9       0.47      0.35      0.40        26\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       0.29      0.11      0.15        19\n",
      "         12       1.00      0.19      0.32        21\n",
      "         13       0.83      0.29      0.43        17\n",
      "         14       0.00      0.00      0.00        12\n",
      "         15       0.65      0.42      0.51        36\n",
      "         16       0.33      0.16      0.22        25\n",
      "         17       0.33      0.37      0.35        43\n",
      "         18       0.50      0.25      0.33        20\n",
      "\n",
      "avg / total       0.56      0.48      0.45       562\n",
      "\n",
      "[11  0  0  4  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  5  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  2  3  0  0  0 14 11  0  0  6  0  0  0\n",
      "  0  0  0  0  0  0  0  2  0  0  0  0 93  0  3  1  0  0  0  0  3  0  0  2\n",
      "  6  0  0  0  0  0  0  3  3  0  4  0  0  2  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  7  0  3  2  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0 14  0  0\n",
      " 74  0  0  2  1  0  0  0  0  0  0  3  0  0  0  0  7  0  0  2  3  0  0  0\n",
      "  0  0  0  0  0  0  2  0  0  0  0 18  0  0  0  0  9  0  0  0  0  0  0  0\n",
      "  1  2  1  0  0  0  9  0  0  6  0  0  9  0  0  0  0  0  0  0  0  2  0  0\n",
      "  0  5  0  2  1  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0 11  0  1  3\n",
      "  0  0  0  0  2  0  0  0  0  0  0  2  0  0  0  8  0  0  7  0  0  1  0  0\n",
      "  4  0  0  0  0  1  0  0  0  0  8  0  0  1  0  0  1  0  0  0  5  0  0  0\n",
      "  2  0  0  0  0  7  0  1  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 17  0  0  0  0  0  0  1  0  0  0  0 15  0  3  0  0  1  0  7  0  0  0  0\n",
      "  1  0  0  0  0  0  0  0  4 12  0  0  1  0 14  0  0  5  0  0  1  0  0  0\n",
      "  1  0  0  5 16  0  0  0  0  7  0  0  3  0  0  3  0  2  0  0  0  0  0  0\n",
      "  5]\n",
      "svc Accuracy:  0.4804270462633452\n",
      "svc F1:  0.3550374343448599\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        17\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.39      0.57        33\n",
      "          3       0.37      0.89      0.53       108\n",
      "          4       0.00      0.00      0.00        12\n",
      "          5       0.25      0.14      0.18        14\n",
      "          6       0.47      0.80      0.59        94\n",
      "          7       1.00      0.07      0.13        14\n",
      "          8       0.62      0.16      0.26        31\n",
      "          9       0.47      0.27      0.34        26\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       0.17      0.05      0.08        19\n",
      "         12       1.00      0.14      0.25        21\n",
      "         13       1.00      0.18      0.30        17\n",
      "         14       0.00      0.00      0.00        12\n",
      "         15       0.64      0.44      0.52        36\n",
      "         16       0.36      0.16      0.22        25\n",
      "         17       0.45      0.35      0.39        43\n",
      "         18       0.50      0.20      0.29        20\n",
      "\n",
      "avg / total       0.51      0.45      0.40       562\n",
      "\n",
      "[ 8  0  0  6  0  0  2  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  4  0\n",
      "  0  2  0  0  0  0  0  0  0  0  0  2  2  0  0  0 13 11  0  1  8  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 96  0  1  2  0  0  0  0  3  0  0  1\n",
      "  5  0  0  0  0  0  0  4  0  0  5  0  0  2  0  0  0  0  0  0  0  1  0  0\n",
      "  0  0  8  0  2  2  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0 16  0  0\n",
      " 75  0  0  2  0  0  0  0  0  1  0  0  0  0  0  0  4  0  0  9  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 17  0  0  7  0  5  0  0  0  0  0  0  0\n",
      "  1  0  1  0  0  0  8  0  0  7  0  1  7  0  0  0  0  0  0  0  1  2  0  0\n",
      "  0  4  0  2  1  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0 14  0  1  2\n",
      "  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0  7  0  0  8  0  0  2  0  0\n",
      "  3  0  0  0  0  1  0  0  0  0 10  0  0  3  0  0  0  0  0  0  3  0  0  0\n",
      "  1  0  0  0  0  8  0  1  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 12  0  0  7  0  0  0  1  0  0  0  0 16  0  0  0  0  0  0  9  0  0  1  0\n",
      "  1  0  0  0  0  0  0  0  4 10  0  0  0  0 11  0  0 12  0  0  1  0  0  0\n",
      "  0  0  0  4 15  0  0  0  0  8  0  0  4  0  1  1  0  2  0  0  0  0  0  0\n",
      "  4]\n",
      "LR Accuracy:  0.4501779359430605\n",
      "LR F1:  0.27853077209679467\n",
      "For name:  d_huang\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0002-6192-259X': 20, '0000-0003-2048-4500': 15, '0000-0002-1497-1284': 2, '0000-0002-0658-8752': 1})\n",
      "['0000-0002-6192-259X', '0000-0003-2048-4500']\n",
      "Total sample size after apply threshold:  35\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 14)\n",
      "2\n",
      "(35, 33)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86        20\n",
      "          1       0.85      0.73      0.79        15\n",
      "\n",
      "avg / total       0.83      0.83      0.83        35\n",
      "\n",
      "[18  2  4 11]\n",
      "MNB Accuracy:  0.8285714285714286\n",
      "MNB F1:  0.8214285714285714\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.75      0.77        20\n",
      "          1       0.69      0.73      0.71        15\n",
      "\n",
      "avg / total       0.75      0.74      0.74        35\n",
      "\n",
      "[15  5  4 11]\n",
      "svc Accuracy:  0.7428571428571429\n",
      "svc F1:  0.7394540942928038\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86        20\n",
      "          1       0.85      0.73      0.79        15\n",
      "\n",
      "avg / total       0.83      0.83      0.83        35\n",
      "\n",
      "[18  2  4 11]\n",
      "LR Accuracy:  0.8285714285714286\n",
      "LR F1:  0.8214285714285714\n",
      "For name:  h_kuo\n",
      "total sample size before apply threshold:  144\n",
      "Counter({'0000-0002-3295-2984': 98, '0000-0003-1336-1203': 26, '0000-0001-6752-2231': 16, '0000-0002-0349-6983': 2, '0000-0001-9102-5104': 1, '0000-0002-0573-2636': 1})\n",
      "['0000-0003-1336-1203', '0000-0001-6752-2231', '0000-0002-3295-2984']\n",
      "Total sample size after apply threshold:  140\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 79)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 16)\n",
      "2\n",
      "(140, 95)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        26\n",
      "          1       0.00      0.00      0.00        16\n",
      "          2       0.77      1.00      0.87        98\n",
      "\n",
      "avg / total       0.72      0.79      0.72       140\n",
      "\n",
      "[12  0 14  0  0 16  0  0 98]\n",
      "MNB Accuracy:  0.7857142857142857\n",
      "MNB F1:  0.49961186151218756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.46      0.62        26\n",
      "          1       0.33      0.19      0.24        16\n",
      "          2       0.77      0.93      0.84        98\n",
      "\n",
      "avg / total       0.75      0.76      0.73       140\n",
      "\n",
      "[12  0 14  0  3 13  1  6 91]\n",
      "svc Accuracy:  0.7571428571428571\n",
      "svc F1:  0.5659924026590694\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        26\n",
      "          1       0.00      0.00      0.00        16\n",
      "          2       0.74      0.99      0.85        98\n",
      "\n",
      "avg / total       0.70      0.75      0.68       140\n",
      "\n",
      "[ 8  0 18  0  0 16  0  1 97]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.43924993578217314\n",
      "For name:  a_santoro\n",
      "total sample size before apply threshold:  189\n",
      "Counter({'0000-0002-0798-6816': 83, '0000-0003-1709-9492': 58, '0000-0002-5086-1453': 21, '0000-0003-2503-8219': 10, '0000-0002-1014-197X': 9, '0000-0002-6193-2050': 8})\n",
      "['0000-0003-1709-9492', '0000-0002-5086-1453', '0000-0003-2503-8219', '0000-0002-0798-6816']\n",
      "Total sample size after apply threshold:  172\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(172, 81)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(172, 30)\n",
      "2\n",
      "(172, 111)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89        58\n",
      "          1       0.80      0.19      0.31        21\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.81      0.93      0.87        83\n",
      "\n",
      "avg / total       0.76      0.81      0.76       172\n",
      "\n",
      "[58  0  0  0  7  4  0 10  2  0  0  8  5  1  0 77]\n",
      "MNB Accuracy:  0.8081395348837209\n",
      "MNB F1:  0.5162921348314607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90        58\n",
      "          1       0.85      0.52      0.65        21\n",
      "          2       1.00      0.50      0.67        10\n",
      "          3       0.88      0.90      0.89        83\n",
      "\n",
      "avg / total       0.87      0.86      0.85       172\n",
      "\n",
      "[57  0  0  1  4 11  0  6  2  0  5  3  6  2  0 75]\n",
      "svc Accuracy:  0.8604651162790697\n",
      "svc F1:  0.7760551070822029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.98      0.87        58\n",
      "          1       0.67      0.10      0.17        21\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.79      0.92      0.85        83\n",
      "\n",
      "avg / total       0.73      0.78      0.72       172\n",
      "\n",
      "[57  0  0  1  9  2  0 10  1  0  0  9  6  1  0 76]\n",
      "LR Accuracy:  0.7848837209302325\n",
      "LR F1:  0.4715144213683597\n",
      "For name:  q_lu\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-2804-0827': 22, '0000-0002-4261-5121': 5, '0000-0002-4514-0969': 4, '0000-0002-7952-2332': 3, '0000-0001-6234-4384': 1})\n",
      "['0000-0002-2804-0827']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  s_kumar\n",
      "total sample size before apply threshold:  419\n",
      "Counter({'0000-0003-4326-5941': 130, '0000-0002-4003-4411': 42, '0000-0003-2405-3791': 25, '0000-0003-0658-8709': 21, '0000-0001-8373-105X': 19, '0000-0001-5902-6641': 18, '0000-0001-5940-9490': 14, '0000-0003-0562-2645': 13, '0000-0003-2130-7493': 13, '0000-0003-0423-2880': 9, '0000-0001-9905-4831': 9, '0000-0002-5082-8602': 8, '0000-0002-1457-5804': 8, '0000-0001-9261-2263': 8, '0000-0002-0605-6908': 7, '0000-0001-5396-5509': 7, '0000-0002-6701-6889': 6, '0000-0002-5474-8095': 4, '0000-0002-0384-1580': 4, '0000-0003-2920-8924': 4, '0000-0003-3514-8999': 4, '0000-0001-9673-5842': 4, '0000-0001-6511-5309': 4, '0000-0002-2358-2344': 4, '0000-0002-4405-4444': 3, '0000-0003-2685-9940': 3, '0000-0002-4044-7005': 3, '0000-0001-6594-9266': 3, '0000-0001-5223-1466': 2, '0000-0001-8407-3562': 2, '0000-0001-9132-1202': 2, '0000-0002-9054-2123': 2, '0000-0002-6772-7250': 2, '0000-0001-6680-718X': 1, '0000-0001-9525-4836': 1, '0000-0001-7070-057X': 1, '0000-0002-6425-278X': 1, '0000-0003-0832-4811': 1, '0000-0002-5838-3994': 1, '0000-0002-2284-4576': 1, '0000-0001-6221-4512': 1, '0000-0001-9411-3863': 1, '0000-0002-0951-4214': 1, '0000-0003-3389-5368': 1, '0000-0002-4190-620X': 1})\n",
      "['0000-0001-8373-105X', '0000-0001-5940-9490', '0000-0003-4326-5941', '0000-0003-2405-3791', '0000-0002-4003-4411', '0000-0003-0658-8709', '0000-0003-0562-2645', '0000-0001-5902-6641', '0000-0003-2130-7493']\n",
      "Total sample size after apply threshold:  295\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 139)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 23)\n",
      "2\n",
      "(295, 162)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.16      0.24        19\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.60      0.95      0.74       130\n",
      "          3       0.65      0.96      0.77        25\n",
      "          4       0.62      0.57      0.59        42\n",
      "          5       1.00      0.33      0.50        21\n",
      "          6       0.00      0.00      0.00        13\n",
      "          7       0.00      0.00      0.00        18\n",
      "          8       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.51      0.62      0.53       295\n",
      "\n",
      "[  3   0  13   0   3   0   0   0   0   0   0  13   0   1   0   0   0   0\n",
      "   1   0 124   2   3   0   0   0   0   0   0   1  24   0   0   0   0   0\n",
      "   1   0  14   3  24   0   0   0   0   0   0  12   1   1   7   0   0   0\n",
      "   0   0  11   1   1   0   0   0   0   1   0  12   4   1   0   0   0   0\n",
      "   0   0   6   2   5   0   0   0   0]\n",
      "MNB Accuracy:  0.6169491525423729\n",
      "MNB F1:  0.3160979310083253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.47      0.58        19\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       0.70      0.97      0.81       130\n",
      "          3       1.00      0.92      0.96        25\n",
      "          4       0.79      0.64      0.71        42\n",
      "          5       1.00      0.86      0.92        21\n",
      "          6       1.00      0.54      0.70        13\n",
      "          7       0.60      0.17      0.26        18\n",
      "          8       1.00      0.38      0.56        13\n",
      "\n",
      "avg / total       0.80      0.77      0.75       295\n",
      "\n",
      "[  9   0   8   0   1   0   0   1   0   0  10   4   0   0   0   0   0   0\n",
      "   1   0 126   0   3   0   0   0   0   0   0   2  23   0   0   0   0   0\n",
      "   1   0  13   0  27   0   0   1   0   0   0   2   0   1  18   0   0   0\n",
      "   0   0   6   0   0   0   7   0   0   1   0  13   0   1   0   0   3   0\n",
      "   0   0   7   0   1   0   0   0   5]\n",
      "svc Accuracy:  0.7728813559322034\n",
      "svc F1:  0.7036255085182064\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.05      0.10        19\n",
      "          1       1.00      0.36      0.53        14\n",
      "          2       0.58      0.99      0.73       130\n",
      "          3       1.00      0.92      0.96        25\n",
      "          4       0.81      0.52      0.64        42\n",
      "          5       1.00      0.62      0.76        21\n",
      "          6       0.00      0.00      0.00        13\n",
      "          7       1.00      0.06      0.11        18\n",
      "          8       1.00      0.15      0.27        13\n",
      "\n",
      "avg / total       0.71      0.66      0.60       295\n",
      "\n",
      "[  1   0  16   0   2   0   0   0   0   0   5   9   0   0   0   0   0   0\n",
      "   0   0 129   0   1   0   0   0   0   0   0   2  23   0   0   0   0   0\n",
      "   0   0  20   0  22   0   0   0   0   0   0   8   0   0  13   0   0   0\n",
      "   0   0  12   0   1   0   0   0   0   1   0  16   0   0   0   0   1   0\n",
      "   0   0  10   0   1   0   0   0   2]\n",
      "LR Accuracy:  0.6644067796610169\n",
      "LR F1:  0.45412873664825476\n",
      "For name:  s_rocha\n",
      "total sample size before apply threshold:  139\n",
      "Counter({'0000-0002-2413-4981': 47, '0000-0003-4196-2217': 41, '0000-0002-0396-3019': 36, '0000-0002-9705-1511': 8, '0000-0002-4686-2410': 5, '0000-0002-1324-5707': 2})\n",
      "['0000-0002-2413-4981', '0000-0003-4196-2217', '0000-0002-0396-3019']\n",
      "Total sample size after apply threshold:  124\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(124, 72)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(124, 17)\n",
      "2\n",
      "(124, 89)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.77      0.77        47\n",
      "          1       0.81      0.71      0.75        41\n",
      "          2       0.71      0.81      0.75        36\n",
      "\n",
      "avg / total       0.76      0.76      0.76       124\n",
      "\n",
      "[36  4  7  7 29  5  4  3 29]\n",
      "MNB Accuracy:  0.7580645161290323\n",
      "MNB F1:  0.7574836511006723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.85      0.77        47\n",
      "          1       0.81      0.71      0.75        41\n",
      "          2       0.87      0.75      0.81        36\n",
      "\n",
      "avg / total       0.79      0.77      0.77       124\n",
      "\n",
      "[40  4  3 11 29  1  6  3 27]\n",
      "svc Accuracy:  0.7741935483870968\n",
      "svc F1:  0.7761492239104179\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.85      0.76        47\n",
      "          1       0.82      0.68      0.75        41\n",
      "          2       0.81      0.72      0.76        36\n",
      "\n",
      "avg / total       0.77      0.76      0.76       124\n",
      "\n",
      "[40  3  4 11 28  2  7  3 26]\n",
      "LR Accuracy:  0.7580645161290323\n",
      "LR F1:  0.7577591036414567\n",
      "For name:  t_han\n",
      "total sample size before apply threshold:  53\n",
      "Counter({'0000-0002-9063-4052': 42, '0000-0002-3095-7714': 8, '0000-0003-3535-8582': 2, '0000-0003-1404-1578': 1})\n",
      "['0000-0002-9063-4052']\n",
      "Total sample size after apply threshold:  42\n",
      "For name:  m_sandberg\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0002-4812-0103': 39, '0000-0001-5486-7556': 9, '0000-0002-8915-8730': 7, '0000-0003-0809-0656': 2, '0000-0001-9495-3571': 2})\n",
      "['0000-0002-4812-0103']\n",
      "Total sample size after apply threshold:  39\n",
      "For name:  j_marshall\n",
      "total sample size before apply threshold:  80\n",
      "Counter({'0000-0003-1361-2869': 28, '0000-0002-8344-2589': 16, '0000-0002-0494-2295': 11, '0000-0001-5491-2919': 10, '0000-0002-2784-1817': 8, '0000-0002-5829-9688': 5, '0000-0001-7617-4101': 1, '0000-0002-7864-803X': 1})\n",
      "['0000-0001-5491-2919', '0000-0002-0494-2295', '0000-0002-8344-2589', '0000-0003-1361-2869']\n",
      "Total sample size after apply threshold:  65\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 38)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 20)\n",
      "2\n",
      "(65, 58)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.20      0.31        10\n",
      "          1       0.44      0.36      0.40        11\n",
      "          2       0.61      0.69      0.65        16\n",
      "          3       0.66      0.82      0.73        28\n",
      "\n",
      "avg / total       0.61      0.62      0.59        65\n",
      "\n",
      "[ 2  2  2  4  0  4  2  5  1  1 11  3  0  2  3 23]\n",
      "MNB Accuracy:  0.6153846153846154\n",
      "MNB F1:  0.5212274653451123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.40      0.50        10\n",
      "          1       0.50      0.36      0.42        11\n",
      "          2       0.77      0.62      0.69        16\n",
      "          3       0.66      0.89      0.76        28\n",
      "\n",
      "avg / total       0.66      0.66      0.64        65\n",
      "\n",
      "[ 4  0  1  5  1  4  1  5  1  2 10  3  0  2  1 25]\n",
      "svc Accuracy:  0.6615384615384615\n",
      "svc F1:  0.5920708903921246\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       0.60      0.27      0.37        11\n",
      "          2       0.91      0.62      0.74        16\n",
      "          3       0.55      0.93      0.69        28\n",
      "\n",
      "avg / total       0.72      0.63      0.60        65\n",
      "\n",
      "[ 2  0  0  8  0  3  1  7  0  0 10  6  0  2  0 26]\n",
      "LR Accuracy:  0.6307692307692307\n",
      "LR F1:  0.5356018518518518\n",
      "For name:  f_bianchi\n",
      "total sample size before apply threshold:  131\n",
      "Counter({'0000-0002-3459-9301': 54, '0000-0001-7880-5624': 37, '0000-0002-2863-1598': 16, '0000-0003-2996-3604': 12, '0000-0001-5197-5279': 11, '0000-0002-7145-3846': 1})\n",
      "['0000-0001-7880-5624', '0000-0002-2863-1598', '0000-0003-2996-3604', '0000-0002-3459-9301', '0000-0001-5197-5279']\n",
      "Total sample size after apply threshold:  130\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 67)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 23)\n",
      "2\n",
      "(130, 90)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.81      0.77        37\n",
      "          1       0.76      0.81      0.79        16\n",
      "          2       0.50      0.17      0.25        12\n",
      "          3       0.70      0.85      0.77        54\n",
      "          4       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.72      0.72      0.68       130\n",
      "\n",
      "[30  0  1  6  0  0 13  0  3  0  2  2  2  6  0  7  0  1 46  0  2  2  0  5\n",
      "  2]\n",
      "MNB Accuracy:  0.7153846153846154\n",
      "MNB F1:  0.5762937062937062\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.84      0.85        37\n",
      "          1       1.00      0.94      0.97        16\n",
      "          2       0.80      0.33      0.47        12\n",
      "          3       0.74      0.93      0.82        54\n",
      "          4       0.67      0.36      0.47        11\n",
      "\n",
      "avg / total       0.80      0.80      0.78       130\n",
      "\n",
      "[31  0  0  6  0  0 15  0  1  0  1  0  4  5  2  4  0  0 50  0  0  0  1  6\n",
      "  4]\n",
      "svc Accuracy:  0.8\n",
      "svc F1:  0.7155811211425596\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.70      0.78        37\n",
      "          1       1.00      0.81      0.90        16\n",
      "          2       0.50      0.17      0.25        12\n",
      "          3       0.65      0.96      0.78        54\n",
      "          4       1.00      0.27      0.43        11\n",
      "\n",
      "avg / total       0.77      0.74      0.71       130\n",
      "\n",
      "[26  0  1 10  0  0 13  0  3  0  2  0  2  8  0  1  0  1 52  0  1  0  0  7\n",
      "  3]\n",
      "LR Accuracy:  0.7384615384615385\n",
      "LR F1:  0.6254723917359017\n",
      "For name:  c_liu\n",
      "total sample size before apply threshold:  681\n",
      "Counter({'0000-0003-3622-9707': 63, '0000-0001-7016-8990': 58, '0000-0003-2336-4731': 56, '0000-0001-8816-4832': 51, '0000-0002-0703-0742': 46, '0000-0002-6109-5707': 29, '0000-0002-2521-924X': 29, '0000-0001-7433-2081': 27, '0000-0002-5723-177X': 25, '0000-0001-8063-7906': 23, '0000-0001-5546-3852': 19, '0000-0001-9918-1638': 18, '0000-0001-7888-9725': 17, '0000-0002-5323-6733': 16, '0000-0003-3410-445X': 16, '0000-0003-1882-3892': 16, '0000-0002-3151-7956': 16, '0000-0001-7343-3884': 14, '0000-0002-6202-0993': 13, '0000-0001-7364-8412': 12, '0000-0002-8582-912X': 11, '0000-0002-4693-5667': 11, '0000-0001-8918-5627': 10, '0000-0002-6439-8754': 10, '0000-0002-6650-6245': 7, '0000-0003-1028-2454': 7, '0000-0001-7954-0736': 5, '0000-0002-9780-9062': 5, '0000-0002-6257-0389': 5, '0000-0002-2106-202X': 4, '0000-0002-2145-5034': 4, '0000-0002-5586-4776': 3, '0000-0002-9210-2754': 3, '0000-0003-2544-7215': 3, '0000-0001-6049-2615': 3, '0000-0003-1975-3988': 2, '0000-0003-2352-5734': 2, '0000-0003-3283-028X': 2, '0000-0002-4230-9159': 2, '0000-0002-8997-5941': 2, '0000-0001-5352-1326': 2, '0000-0001-6526-5024': 2, '0000-0002-1797-3920': 1, '0000-0001-5886-5785': 1, '0000-0001-9657-7717': 1, '0000-0001-7023-6578': 1, '0000-0001-5095-8039': 1, '0000-0002-4035-8686': 1, '0000-0002-7263-5289': 1, '0000-0003-1196-7447': 1, '0000-0002-2834-9461': 1, '0000-0002-8345-8847': 1, '0000-0002-9954-3755': 1, '0000-0002-5717-3370': 1})\n",
      "['0000-0001-7343-3884', '0000-0002-5723-177X', '0000-0001-7016-8990', '0000-0002-8582-912X', '0000-0002-5323-6733', '0000-0001-5546-3852', '0000-0002-6109-5707', '0000-0001-7888-9725', '0000-0002-0703-0742', '0000-0003-3622-9707', '0000-0002-6202-0993', '0000-0002-4693-5667', '0000-0001-7364-8412', '0000-0001-9918-1638', '0000-0001-8816-4832', '0000-0001-7433-2081', '0000-0001-8918-5627', '0000-0002-2521-924X', '0000-0001-8063-7906', '0000-0002-6439-8754', '0000-0003-2336-4731', '0000-0003-3410-445X', '0000-0003-1882-3892', '0000-0002-3151-7956']\n",
      "Total sample size after apply threshold:  606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(606, 266)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(606, 20)\n",
      "2\n",
      "(606, 286)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.21      0.33        14\n",
      "          1       1.00      0.08      0.15        25\n",
      "          2       0.27      0.79      0.40        58\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.19      0.32        16\n",
      "          5       1.00      0.21      0.35        19\n",
      "          6       0.65      0.38      0.48        29\n",
      "          7       1.00      0.06      0.11        17\n",
      "          8       0.31      0.67      0.43        46\n",
      "          9       0.35      0.73      0.47        63\n",
      "         10       1.00      0.15      0.27        13\n",
      "         11       0.00      0.00      0.00        11\n",
      "         12       0.00      0.00      0.00        12\n",
      "         13       0.50      0.11      0.18        18\n",
      "         14       0.72      0.65      0.68        51\n",
      "         15       0.71      0.19      0.29        27\n",
      "         16       0.00      0.00      0.00        10\n",
      "         17       0.63      0.90      0.74        29\n",
      "         18       0.00      0.00      0.00        23\n",
      "         19       0.00      0.00      0.00        10\n",
      "         20       0.42      0.50      0.46        56\n",
      "         21       1.00      0.19      0.32        16\n",
      "         22       0.00      0.00      0.00        16\n",
      "         23       1.00      0.25      0.40        16\n",
      "\n",
      "avg / total       0.51      0.41      0.36       606\n",
      "\n",
      "[ 3  0  5  0  0  0  0  0  2  1  0  0  0  0  0  0  0  0  0  0  3  0  0  0\n",
      "  0  2  5  0  0  0  0  0  5  5  0  0  0  0  4  0  0  1  0  0  3  0  0  0\n",
      "  0  0 46  0  0  0  0  0  2  3  0  0  0  0  2  0  0  1  0  0  4  0  0  0\n",
      "  0  0  7  0  0  0  0  0  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  5  0  3  0  0  0  2  5  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n",
      "  0  0  5  0  0  4  0  0  3  6  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  6  0  0  0 11  0  0 10  0  0  0  0  0  0  0  1  0  0  1  0  0  0\n",
      "  0  0  3  0  0  0  0  1  0  9  0  0  0  0  2  0  0  1  0  0  1  0  0  0\n",
      "  0  0  5  0  0  0  0  0 31  4  0  0  0  0  1  1  0  1  0  0  3  0  0  0\n",
      "  0  0  7  0  0  0  3  0  2 46  0  0  0  0  2  0  0  0  0  0  3  0  0  0\n",
      "  0  0  2  0  0  0  0  0  5  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  4  0  0  0  0  0  1  2  0  0  0  0  0  0  0  0  0  0  4  0  0  0\n",
      "  0  0  3  0  0  0  0  0  4  1  0  0  0  0  0  0  0  0  0  0  4  0  0  0\n",
      "  0  0  5  0  0  0  0  0  5  2  0  0  0  2  0  1  0  1  0  0  2  0  0  0\n",
      "  0  0 14  0  0  0  0  0  1  1  0  0  0  0 33  0  0  0  0  0  2  0  0  0\n",
      "  0  0  7  0  0  0  0  0  1  7  0  0  0  0  0  5  0  5  0  0  2  0  0  0\n",
      "  0  0  2  0  0  0  1  0  2  3  0  0  0  1  0  0  0  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0 26  0  0  1  0  0  0\n",
      "  0  0 12  0  0  0  0  0  4  6  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  6  0  0  0  0  0  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  7  0  0  0  1  0 11  6  0  0  0  0  1  0  0  2  0  0 28  0  0  0\n",
      "  0  0  3  0  0  0  0  0  6  1  0  0  0  0  0  0  0  0  0  0  3  3  0  0\n",
      "  0  0 10  0  0  0  0  0  2  3  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "  1  0  3  0  0  0  1  0  3  3  0  0  0  0  0  0  0  0  0  0  1  0  0  4]\n",
      "MNB Accuracy:  0.41254125412541254\n",
      "MNB F1:  0.26570666293668643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.64      0.75        14\n",
      "          1       0.83      0.40      0.54        25\n",
      "          2       0.40      0.74      0.52        58\n",
      "          3       0.40      0.18      0.25        11\n",
      "          4       0.89      0.50      0.64        16\n",
      "          5       0.71      0.63      0.67        19\n",
      "          6       0.83      0.52      0.64        29\n",
      "          7       0.71      0.71      0.71        17\n",
      "          8       0.60      0.54      0.57        46\n",
      "          9       0.46      0.71      0.56        63\n",
      "         10       0.46      0.46      0.46        13\n",
      "         11       0.80      0.36      0.50        11\n",
      "         12       1.00      0.42      0.59        12\n",
      "         13       0.41      0.39      0.40        18\n",
      "         14       0.77      0.65      0.70        51\n",
      "         15       0.80      0.30      0.43        27\n",
      "         16       1.00      0.80      0.89        10\n",
      "         17       0.84      0.90      0.87        29\n",
      "         18       1.00      0.17      0.30        23\n",
      "         19       0.20      0.10      0.13        10\n",
      "         20       0.35      0.64      0.45        56\n",
      "         21       0.75      0.38      0.50        16\n",
      "         22       0.67      0.25      0.36        16\n",
      "         23       1.00      0.75      0.86        16\n",
      "\n",
      "avg / total       0.65      0.56      0.56       606\n",
      "\n",
      "[ 9  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0\n",
      "  0 10  2  0  0  0  0  0  2  1  0  0  0  0  5  0  0  0  0  0  5  0  0  0\n",
      "  0  0 43  0  0  0  0  0  0  6  0  0  0  0  3  0  0  0  0  0  6  0  0  0\n",
      "  0  0  1  2  0  0  0  2  0  2  1  0  0  2  0  0  0  0  0  1  0  0  0  0\n",
      "  0  0  1  0  8  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  4  0  0  0\n",
      "  0  0  2  0  0 12  0  1  0  1  1  0  0  2  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  2  0  1  0 15  0  1  8  0  0  0  0  0  0  0  0  0  0  2  0  0  0\n",
      "  0  0  0  0  0  1  0 12  0  1  0  0  0  0  0  0  0  0  0  2  1  0  0  0\n",
      "  0  1  1  0  0  0  1  0 25  4  4  0  0  0  1  1  0  0  0  0  6  2  0  0\n",
      "  0  0  5  0  0  0  1  0  2 45  0  0  0  0  1  0  0  0  0  0  9  0  0  0\n",
      "  0  0  5  0  0  0  0  0  1  0  6  0  0  0  0  0  0  0  0  0  0  0  1  0\n",
      "  0  0  4  0  0  0  0  0  0  1  0  4  0  0  0  0  0  0  0  0  2  0  0  0\n",
      "  0  0  1  1  0  0  0  0  1  1  0  0  5  0  0  0  0  0  0  0  3  0  0  0\n",
      "  0  0  0  1  0  2  0  1  0  1  0  0  0  7  0  1  0  2  0  1  1  0  1  0\n",
      "  0  1 12  0  0  0  0  0  2  1  0  0  0  0 33  0  0  0  0  0  2  0  0  0\n",
      "  0  0  3  0  0  1  0  0  4  5  0  0  0  1  0  8  0  3  0  0  2  0  0  0\n",
      "  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  8  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0 26  0  0  2  0  0  0\n",
      "  0  0  6  0  0  0  0  0  1  4  0  0  0  0  0  0  0  0  4  0  8  0  0  0\n",
      "  0  0  1  1  0  1  0  1  0  1  0  0  0  2  0  0  0  0  0  1  2  0  0  0\n",
      "  0  0  6  0  0  0  1  0  0 11  1  1  0  0  0  0  0  0  0  0 36  0  0  0\n",
      "  0  0  2  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  6  6  0  0\n",
      "  0  0  6  0  0  0  0  0  1  0  0  0  0  1  0  0  0  0  0  0  4  0  4  0\n",
      "  1  0  2  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 12]\n",
      "svc Accuracy:  0.5627062706270627\n",
      "svc F1:  0.5533516580606113\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        14\n",
      "          1       0.89      0.32      0.47        25\n",
      "          2       0.37      0.72      0.49        58\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.44      0.61        16\n",
      "          5       0.87      0.68      0.76        19\n",
      "          6       0.57      0.55      0.56        29\n",
      "          7       0.64      0.53      0.58        17\n",
      "          8       0.41      0.65      0.50        46\n",
      "          9       0.46      0.75      0.57        63\n",
      "         10       0.38      0.46      0.41        13\n",
      "         11       0.67      0.18      0.29        11\n",
      "         12       1.00      0.42      0.59        12\n",
      "         13       0.38      0.28      0.32        18\n",
      "         14       0.80      0.65      0.72        51\n",
      "         15       0.55      0.22      0.32        27\n",
      "         16       1.00      0.80      0.89        10\n",
      "         17       0.79      0.90      0.84        29\n",
      "         18       1.00      0.13      0.23        23\n",
      "         19       0.00      0.00      0.00        10\n",
      "         20       0.43      0.59      0.50        56\n",
      "         21       0.86      0.38      0.52        16\n",
      "         22       1.00      0.19      0.32        16\n",
      "         23       0.85      0.69      0.76        16\n",
      "\n",
      "avg / total       0.62      0.54      0.52       606\n",
      "\n",
      "[ 6  0  2  0  0  0  0  0  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  2\n",
      "  0  8  2  0  0  0  1  0  3  3  1  0  0  0  4  0  0  0  0  0  3  0  0  0\n",
      "  0  0 42  0  0  0  0  0  2  3  0  0  0  0  3  0  0  0  0  0  8  0  0  0\n",
      "  0  0  2  0  0  0  0  2  1  0  1  0  0  3  0  0  0  0  0  1  1  0  0  0\n",
      "  0  0  2  0  7  0  1  0  1  4  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  1  0  0 13  0  0  0  1  1  0  0  1  0  1  0  0  0  0  1  0  0  0\n",
      "  0  0  3  0  0  0 16  0  0  7  0  0  0  0  0  0  0  0  0  0  3  0  0  0\n",
      "  0  0  0  0  0  0  1  9  0  3  0  0  0  0  0  0  0  0  0  2  2  0  0  0\n",
      "  0  1  2  0  0  0  0  0 30  4  3  0  0  0  1  1  0  0  0  0  3  1  0  0\n",
      "  0  0  3  0  0  0  4  0  3 47  0  0  0  0  0  1  0  0  0  0  5  0  0  0\n",
      "  0  0  3  0  0  0  0  0  0  4  6  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  4  0  0  0  0  0  1  1  0  2  0  0  0  0  0  0  0  0  3  0  0  0\n",
      "  0  0  2  0  0  0  0  1  2  0  1  0  5  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  2  1  0  0  0  1  4  1  0  0  0  5  0  1  0  1  0  1  1  0  0  0\n",
      "  0  0 11  0  0  0  0  0  1  2  1  0  0  0 33  1  0  0  0  0  2  0  0  0\n",
      "  0  0  6  0  0  1  2  0  2  4  0  0  0  0  0  6  0  6  0  0  0  0  0  0\n",
      "  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  8  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0 26  0  0  2  0  0  0\n",
      "  0  0  7  0  0  0  1  0  4  5  0  0  0  0  0  0  0  0  3  0  3  0  0  0\n",
      "  0  0  2  1  0  1  0  1  1  1  0  0  0  2  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  5  0  0  0  2  0  7  7  1  1  0  0  0  0  0  0  0  0 33  0  0  0\n",
      "  0  0  2  0  0  0  0  0  6  1  0  0  0  0  0  0  0  0  0  0  1  6  0  0\n",
      "  0  0  7  0  0  0  0  0  0  2  1  0  0  1  0  0  0  0  0  0  2  0  3  0\n",
      "  0  0  2  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  1  0  0 11]\n",
      "LR Accuracy:  0.5363036303630363\n",
      "LR F1:  0.49355945663570155\n",
      "For name:  d_sanders\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-5593-1564': 8, '0000-0003-2383-8693': 6, '0000-0002-6523-783X': 1, '0000-0001-6265-6249': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_brito\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0001-9128-2557': 28, '0000-0001-5214-9681': 11, '0000-0002-8488-6472': 8, '0000-0002-7807-3053': 2, '0000-0003-3633-6422': 2})\n",
      "['0000-0001-5214-9681', '0000-0001-9128-2557']\n",
      "Total sample size after apply threshold:  39\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 15)\n",
      "2\n",
      "(39, 46)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.55      0.60        11\n",
      "          1       0.83      0.89      0.86        28\n",
      "\n",
      "avg / total       0.79      0.79      0.79        39\n",
      "\n",
      "[ 6  5  3 25]\n",
      "MNB Accuracy:  0.7948717948717948\n",
      "MNB F1:  0.7310344827586206\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.55      0.60        11\n",
      "          1       0.83      0.89      0.86        28\n",
      "\n",
      "avg / total       0.79      0.79      0.79        39\n",
      "\n",
      "[ 6  5  3 25]\n",
      "svc Accuracy:  0.7948717948717948\n",
      "svc F1:  0.7310344827586206\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.09      0.14        11\n",
      "          1       0.72      0.93      0.81        28\n",
      "\n",
      "avg / total       0.61      0.69      0.62        39\n",
      "\n",
      "[ 1 10  2 26]\n",
      "LR Accuracy:  0.6923076923076923\n",
      "LR F1:  0.4776785714285715\n",
      "For name:  w_chang\n",
      "total sample size before apply threshold:  91\n",
      "Counter({'0000-0003-0116-1386': 50, '0000-0003-2283-1377': 23, '0000-0003-4880-6006': 14, '0000-0002-6155-8644': 2, '0000-0002-5268-290X': 1, '0000-0002-7437-4211': 1})\n",
      "['0000-0003-2283-1377', '0000-0003-4880-6006', '0000-0003-0116-1386']\n",
      "Total sample size after apply threshold:  87\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(87, 40)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(87, 14)\n",
      "2\n",
      "(87, 54)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.70      0.71        23\n",
      "          1       0.40      0.29      0.33        14\n",
      "          2       0.85      0.94      0.90        50\n",
      "\n",
      "avg / total       0.75      0.77      0.76        87\n",
      "\n",
      "[16  4  3  5  4  5  1  2 47]\n",
      "MNB Accuracy:  0.7701149425287356\n",
      "MNB F1:  0.6465608465608464\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.83      0.73        23\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       0.85      0.88      0.86        50\n",
      "\n",
      "avg / total       0.82      0.79      0.79        87\n",
      "\n",
      "[19  0  4  4  6  4  6  0 44]\n",
      "svc Accuracy:  0.7931034482758621\n",
      "svc F1:  0.7311714429361489\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.65      0.67        23\n",
      "          1       0.80      0.29      0.42        14\n",
      "          2       0.78      0.94      0.85        50\n",
      "\n",
      "avg / total       0.76      0.76      0.74        87\n",
      "\n",
      "[15  1  7  4  4  6  3  0 47]\n",
      "LR Accuracy:  0.7586206896551724\n",
      "LR F1:  0.6474215842636895\n",
      "For name:  a_murray\n",
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0002-4094-962X': 32, '0000-0002-0929-9315': 14, '0000-0001-7143-287X': 9, '0000-0001-6762-588X': 7, '0000-0001-5014-1096': 7, '0000-0001-7047-8139': 4, '0000-0001-9648-2902': 3})\n",
      "['0000-0002-4094-962X', '0000-0002-0929-9315']\n",
      "Total sample size after apply threshold:  46\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 14)\n",
      "2\n",
      "(46, 37)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.88      0.84        32\n",
      "          1       0.64      0.50      0.56        14\n",
      "\n",
      "avg / total       0.75      0.76      0.75        46\n",
      "\n",
      "[28  4  7  7]\n",
      "MNB Accuracy:  0.7608695652173914\n",
      "MNB F1:  0.6979104477611942\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.84      0.84        32\n",
      "          1       0.64      0.64      0.64        14\n",
      "\n",
      "avg / total       0.78      0.78      0.78        46\n",
      "\n",
      "[27  5  5  9]\n",
      "svc Accuracy:  0.782608695652174\n",
      "svc F1:  0.7433035714285714\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.97      0.85        32\n",
      "          1       0.80      0.29      0.42        14\n",
      "\n",
      "avg / total       0.77      0.76      0.72        46\n",
      "\n",
      "[31  1 10  4]\n",
      "LR Accuracy:  0.7608695652173914\n",
      "LR F1:  0.6351838500360489\n",
      "For name:  b_cao\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-9462-496X': 39, '0000-0003-3588-972X': 14, '0000-0003-3401-6900': 4, '0000-0003-4443-2326': 1})\n",
      "['0000-0002-9462-496X', '0000-0003-3588-972X']\n",
      "Total sample size after apply threshold:  53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 10)\n",
      "2\n",
      "(53, 33)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        39\n",
      "          1       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.89      0.87      0.85        53\n",
      "\n",
      "[39  0  7  7]\n",
      "MNB Accuracy:  0.8679245283018868\n",
      "MNB F1:  0.792156862745098\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        39\n",
      "          1       1.00      0.57      0.73        14\n",
      "\n",
      "avg / total       0.90      0.89      0.88        53\n",
      "\n",
      "[39  0  6  8]\n",
      "svc Accuracy:  0.8867924528301887\n",
      "svc F1:  0.827922077922078\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        39\n",
      "          1       1.00      0.29      0.44        14\n",
      "\n",
      "avg / total       0.85      0.81      0.77        53\n",
      "\n",
      "[39  0 10  4]\n",
      "LR Accuracy:  0.8113207547169812\n",
      "LR F1:  0.6654040404040404\n",
      "For name:  k_sohn\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-3237-044X': 17, '0000-0001-8941-1188': 12, '0000-0001-9791-2126': 1, '0000-0002-7270-7094': 1})\n",
      "['0000-0002-3237-044X', '0000-0001-8941-1188']\n",
      "Total sample size after apply threshold:  29\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 8)\n",
      "2\n",
      "(29, 31)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.65      0.63        17\n",
      "          1       0.45      0.42      0.43        12\n",
      "\n",
      "avg / total       0.55      0.55      0.55        29\n",
      "\n",
      "[11  6  7  5]\n",
      "MNB Accuracy:  0.5517241379310345\n",
      "MNB F1:  0.5316770186335404\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.59      0.59        17\n",
      "          1       0.42      0.42      0.42        12\n",
      "\n",
      "avg / total       0.52      0.52      0.52        29\n",
      "\n",
      "[10  7  7  5]\n",
      "svc Accuracy:  0.5172413793103449\n",
      "svc F1:  0.5024509803921569\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.71      0.65        17\n",
      "          1       0.44      0.33      0.38        12\n",
      "\n",
      "avg / total       0.54      0.55      0.54        29\n",
      "\n",
      "[12  5  8  4]\n",
      "LR Accuracy:  0.5517241379310345\n",
      "LR F1:  0.5148005148005148\n",
      "For name:  m_bennett\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  208\n",
      "Counter({'0000-0002-2565-1825': 110, '0000-0002-8369-8349': 90, '0000-0002-3063-8844': 7, '0000-0001-9914-3850': 1})\n",
      "['0000-0002-2565-1825', '0000-0002-8369-8349']\n",
      "Total sample size after apply threshold:  200\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(200, 82)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(200, 21)\n",
      "2\n",
      "(200, 103)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.81      0.86       110\n",
      "          1       0.80      0.92      0.86        90\n",
      "\n",
      "avg / total       0.87      0.86      0.86       200\n",
      "\n",
      "[89 21  7 83]\n",
      "MNB Accuracy:  0.86\n",
      "MNB F1:  0.859873886497848\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.95      0.90       110\n",
      "          1       0.92      0.81      0.86        90\n",
      "\n",
      "avg / total       0.89      0.89      0.88       200\n",
      "\n",
      "[104   6  17  73]\n",
      "svc Accuracy:  0.885\n",
      "svc F1:  0.8821691129383438\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.93      0.88       110\n",
      "          1       0.90      0.79      0.84        90\n",
      "\n",
      "avg / total       0.87      0.86      0.86       200\n",
      "\n",
      "[102   8  19  71]\n",
      "LR Accuracy:  0.865\n",
      "LR F1:  0.8616767847537079\n",
      "For name:  a_sharma\n",
      "total sample size before apply threshold:  223\n",
      "Counter({'0000-0002-2653-0806': 85, '0000-0003-3349-4417': 23, '0000-0002-7668-3501': 14, '0000-0002-0172-5033': 12, '0000-0003-2264-2007': 10, '0000-0003-0553-4039': 9, '0000-0001-6906-190X': 9, '0000-0002-7029-9867': 8, '0000-0002-7442-8494': 8, '0000-0003-3281-2081': 6, '0000-0001-6539-9970': 6, '0000-0001-5061-9731': 5, '0000-0002-6201-7639': 5, '0000-0002-4117-8775': 4, '0000-0002-8458-9216': 3, '0000-0002-5251-9045': 3, '0000-0001-7570-852X': 2, '0000-0002-1655-5997': 2, '0000-0002-4374-4259': 2, '0000-0003-4841-0108': 2, '0000-0002-6862-136X': 2, '0000-0002-4342-6656': 1, '0000-0003-4433-4355': 1, '0000-0002-7170-1627': 1})\n",
      "['0000-0003-3349-4417', '0000-0002-0172-5033', '0000-0002-7668-3501', '0000-0002-2653-0806', '0000-0003-2264-2007']\n",
      "Total sample size after apply threshold:  144\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(144, 53)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(144, 17)\n",
      "2\n",
      "(144, 70)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.52      0.63        23\n",
      "          1       1.00      0.67      0.80        12\n",
      "          2       1.00      0.79      0.88        14\n",
      "          3       0.78      0.99      0.87        85\n",
      "          4       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.77      0.80      0.77       144\n",
      "\n",
      "[12  0  0  9  2  0  8  0  4  0  0  0 11  3  0  1  0  0 84  0  2  0  0  8\n",
      "  0]\n",
      "MNB Accuracy:  0.7986111111111112\n",
      "MNB F1:  0.6364090537223889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.65      0.73        23\n",
      "          1       1.00      1.00      1.00        12\n",
      "          2       1.00      0.57      0.73        14\n",
      "          3       0.83      1.00      0.91        85\n",
      "          4       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.88      0.86      0.85       144\n",
      "\n",
      "[15  0  0  8  0  0 12  0  0  0  2  0  8  4  0  0  0  0 85  0  1  0  0  5\n",
      "  4]\n",
      "svc Accuracy:  0.8611111111111112\n",
      "svc F1:  0.7878999049730757\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        23\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       0.73      1.00      0.84        85\n",
      "          4       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.77      0.78      0.73       144\n",
      "\n",
      "[ 8  0  0 15  0  0 10  0  2  0  0  0  9  5  0  0  0  0 85  0  0  0  0 10\n",
      "  0]\n",
      "LR Accuracy:  0.7777777777777778\n",
      "LR F1:  0.6098825590833978\n",
      "For name:  z_wei\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0001-8747-2251': 11, '0000-0002-4446-6502': 11, '0000-0003-2687-0293': 8, '0000-0001-6948-7572': 7, '0000-0001-8558-4639': 5, '0000-0002-2311-9800': 4, '0000-0001-7436-6409': 4, '0000-0002-8694-1260': 2, '0000-0002-9670-4752': 2})\n",
      "['0000-0001-8747-2251', '0000-0002-4446-6502']\n",
      "Total sample size after apply threshold:  22\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 14)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 6)\n",
      "2\n",
      "(22, 20)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73        11\n",
      "          1       0.73      0.73      0.73        11\n",
      "\n",
      "avg / total       0.73      0.73      0.73        22\n",
      "\n",
      "[8 3 3 8]\n",
      "MNB Accuracy:  0.7272727272727273\n",
      "MNB F1:  0.7272727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.79      1.00      0.88        11\n",
      "\n",
      "avg / total       0.89      0.86      0.86        22\n",
      "\n",
      "[ 8  3  0 11]\n",
      "svc Accuracy:  0.8636363636363636\n",
      "svc F1:  0.8610526315789474\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.73      0.76        11\n",
      "          1       0.75      0.82      0.78        11\n",
      "\n",
      "avg / total       0.78      0.77      0.77        22\n",
      "\n",
      "[8 3 2 9]\n",
      "LR Accuracy:  0.7727272727272727\n",
      "LR F1:  0.7722567287784678\n",
      "For name:  x_gu\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-9373-987X': 23, '0000-0002-8521-3667': 13, '0000-0003-2266-5516': 7, '0000-0002-0437-5606': 5, '0000-0003-2641-1740': 5, '0000-0001-8299-6451': 4, '0000-0003-3803-3951': 4})\n",
      "['0000-0002-8521-3667', '0000-0002-9373-987X']\n",
      "Total sample size after apply threshold:  36\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 26)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 9)\n",
      "2\n",
      "(36, 35)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.46      0.60        13\n",
      "          1       0.76      0.96      0.85        23\n",
      "\n",
      "avg / total       0.79      0.78      0.76        36\n",
      "\n",
      "[ 6  7  1 22]\n",
      "MNB Accuracy:  0.7777777777777778\n",
      "MNB F1:  0.7230769230769231\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.69      0.78        13\n",
      "          1       0.85      0.96      0.90        23\n",
      "\n",
      "avg / total       0.87      0.86      0.86        36\n",
      "\n",
      "[ 9  4  1 22]\n",
      "svc Accuracy:  0.8611111111111112\n",
      "svc F1:  0.8402839396628217\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.46      0.60        13\n",
      "          1       0.76      0.96      0.85        23\n",
      "\n",
      "avg / total       0.79      0.78      0.76        36\n",
      "\n",
      "[ 6  7  1 22]\n",
      "LR Accuracy:  0.7777777777777778\n",
      "LR F1:  0.7230769230769231\n",
      "For name:  l_yang\n",
      "total sample size before apply threshold:  193\n",
      "Counter({'0000-0002-3756-8789': 48, '0000-0002-4351-2503': 30, '0000-0002-8654-4927': 23, '0000-0002-5964-3233': 23, '0000-0002-1698-6666': 11, '0000-0002-3681-2874': 9, '0000-0002-0192-4323': 8, '0000-0002-5392-558X': 8, '0000-0002-3294-0879': 6, '0000-0002-5421-9249': 5, '0000-0003-3894-873X': 5, '0000-0003-1057-9194': 5, '0000-0001-6573-6359': 2, '0000-0002-9937-1383': 2, '0000-0001-7965-2674': 2, '0000-0001-6497-1680': 2, '0000-0003-4294-9233': 1, '0000-0001-5709-6566': 1, '0000-0002-0639-0973': 1, '0000-0001-5396-7280': 1})\n",
      "['0000-0002-8654-4927', '0000-0002-4351-2503', '0000-0002-5964-3233', '0000-0002-1698-6666', '0000-0002-3756-8789']\n",
      "Total sample size after apply threshold:  135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(135, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(135, 16)\n",
      "2\n",
      "(135, 72)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.13      0.21        23\n",
      "          1       0.79      0.87      0.83        30\n",
      "          2       0.70      0.30      0.42        23\n",
      "          3       1.00      0.18      0.31        11\n",
      "          4       0.53      0.94      0.68        48\n",
      "\n",
      "avg / total       0.67      0.61      0.56       135\n",
      "\n",
      "[ 3  3  2  0 15  0 26  0  0  4  1  2  7  0 13  0  0  1  2  8  1  2  0  0\n",
      " 45]\n",
      "MNB Accuracy:  0.6148148148148148\n",
      "MNB F1:  0.489661800188116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.74      0.62        23\n",
      "          1       1.00      1.00      1.00        30\n",
      "          2       0.71      0.74      0.72        23\n",
      "          3       0.67      0.36      0.47        11\n",
      "          4       0.98      0.88      0.92        48\n",
      "\n",
      "avg / total       0.84      0.81      0.82       135\n",
      "\n",
      "[17  0  5  0  1  0 30  0  0  0  5  0 17  1  0  5  0  2  4  0  5  0  0  1\n",
      " 42]\n",
      "svc Accuracy:  0.8148148148148148\n",
      "svc F1:  0.7470502463744015\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.48      0.47        23\n",
      "          1       0.90      0.90      0.90        30\n",
      "          2       0.75      0.52      0.62        23\n",
      "          3       1.00      0.36      0.53        11\n",
      "          4       0.72      0.92      0.81        48\n",
      "\n",
      "avg / total       0.74      0.73      0.72       135\n",
      "\n",
      "[11  1  2  0  9  1 27  1  0  1  5  2 12  0  4  3  0  1  4  3  4  0  0  0\n",
      " 44]\n",
      "LR Accuracy:  0.725925925925926\n",
      "LR F1:  0.6648285009284424\n",
      "For name:  h_hassan\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0002-6035-0040': 9, '0000-0002-2815-7996': 5, '0000-0002-9567-0896': 3, '0000-0001-5167-8063': 2, '0000-0002-6166-1342': 1, '0000-0001-7274-9414': 1, '0000-0003-0359-1208': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  f_chen\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0002-2191-0930': 8, '0000-0002-9646-3338': 8, '0000-0002-8004-1720': 6, '0000-0002-7251-1956': 6, '0000-0003-0013-479X': 5, '0000-0002-6366-5064': 2, '0000-0002-9193-5412': 1, '0000-0001-9942-8872': 1, '0000-0002-4346-6906': 1, '0000-0002-1963-6784': 1, '0000-0003-2077-3812': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  g_rossi\n",
      "total sample size before apply threshold:  245\n",
      "Counter({'0000-0001-8377-2898': 86, '0000-0002-5588-1306': 85, '0000-0001-6916-2049': 24, '0000-0003-3519-2420': 19, '0000-0001-9688-9454': 14, '0000-0002-5102-5019': 10, '0000-0003-0984-3197': 3, '0000-0002-9926-115X': 2, '0000-0002-9761-6754': 1, '0000-0002-5572-1759': 1})\n",
      "['0000-0003-3519-2420', '0000-0002-5102-5019', '0000-0002-5588-1306', '0000-0001-9688-9454', '0000-0001-8377-2898', '0000-0001-6916-2049']\n",
      "Total sample size after apply threshold:  238\n",
      "(0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(238, 95)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(238, 29)\n",
      "2\n",
      "(238, 124)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.26      0.40        19\n",
      "          1       1.00      0.10      0.18        10\n",
      "          2       0.65      0.85      0.73        85\n",
      "          3       1.00      0.07      0.13        14\n",
      "          4       0.67      0.77      0.71        86\n",
      "          5       0.65      0.54      0.59        24\n",
      "\n",
      "avg / total       0.71      0.66      0.63       238\n",
      "\n",
      "[ 5  0  7  0  7  0  0  1  6  0  3  0  0  0 72  0 12  1  0  0  4  1  4  5\n",
      "  1  0 18  0 66  1  0  0  4  0  7 13]\n",
      "MNB Accuracy:  0.6638655462184874\n",
      "MNB F1:  0.4590446661875233\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.68      0.79        19\n",
      "          1       0.83      0.50      0.62        10\n",
      "          2       0.89      0.75      0.82        85\n",
      "          3       0.62      0.36      0.45        14\n",
      "          4       0.67      0.91      0.77        86\n",
      "          5       0.73      0.67      0.70        24\n",
      "\n",
      "avg / total       0.78      0.76      0.76       238\n",
      "\n",
      "[13  0  0  0  6  0  0  5  1  0  4  0  0  0 64  0 21  0  0  1  0  5  2  6\n",
      "  1  0  7  0 78  0  0  0  0  3  5 16]\n",
      "svc Accuracy:  0.7605042016806722\n",
      "svc F1:  0.69177337804398\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.37      0.52        19\n",
      "          1       1.00      0.30      0.46        10\n",
      "          2       0.80      0.75      0.78        85\n",
      "          3       0.50      0.14      0.22        14\n",
      "          4       0.63      0.92      0.75        86\n",
      "          5       0.72      0.54      0.62        24\n",
      "\n",
      "avg / total       0.73      0.71      0.68       238\n",
      "\n",
      "[ 7  0  3  0  9  0  0  3  4  0  3  0  0  0 64  0 21  0  0  0  1  2  6  5\n",
      "  1  0  6  0 79  0  0  0  2  2  7 13]\n",
      "LR Accuracy:  0.7058823529411765\n",
      "LR F1:  0.5576499271601957\n",
      "For name:  s_patil\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0001-8454-589X': 17, '0000-0001-6167-2511': 16, '0000-0001-8562-8670': 7, '0000-0003-4952-3120': 5, '0000-0002-0950-549X': 5, '0000-0003-3898-3594': 5, '0000-0002-9278-5786': 4, '0000-0002-1597-855X': 3, '0000-0002-9812-1972': 2, '0000-0001-8502-0884': 1})\n",
      "['0000-0001-8454-589X', '0000-0001-6167-2511']\n",
      "Total sample size after apply threshold:  33\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 11)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 6)\n",
      "2\n",
      "(33, 17)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.87        17\n",
      "          1       0.80      1.00      0.89        16\n",
      "\n",
      "avg / total       0.90      0.88      0.88        33\n",
      "\n",
      "[13  4  0 16]\n",
      "MNB Accuracy:  0.8787878787878788\n",
      "MNB F1:  0.8777777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        17\n",
      "          1       1.00      0.81      0.90        16\n",
      "\n",
      "avg / total       0.92      0.91      0.91        33\n",
      "\n",
      "[17  0  3 13]\n",
      "svc Accuracy:  0.9090909090909091\n",
      "svc F1:  0.907735321528425\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89        17\n",
      "          1       0.93      0.81      0.87        16\n",
      "\n",
      "avg / total       0.88      0.88      0.88        33\n",
      "\n",
      "[16  1  3 13]\n",
      "LR Accuracy:  0.8787878787878788\n",
      "LR F1:  0.8777777777777778\n",
      "For name:  m_kelly\n",
      "total sample size before apply threshold:  97\n",
      "Counter({'0000-0002-6380-1150': 19, '0000-0002-1735-3342': 17, '0000-0001-7963-2139': 16, '0000-0001-6221-7406': 12, '0000-0003-3114-8780': 11, '0000-0003-1799-055X': 10, '0000-0003-3210-0295': 4, '0000-0002-6541-2992': 3, '0000-0002-2029-5841': 2, '0000-0003-2882-4450': 1, '0000-0003-0900-0691': 1, '0000-0002-0995-2425': 1})\n",
      "['0000-0001-7963-2139', '0000-0003-3114-8780', '0000-0003-1799-055X', '0000-0001-6221-7406', '0000-0002-1735-3342', '0000-0002-6380-1150']\n",
      "Total sample size after apply threshold:  85\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 53)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 19)\n",
      "2\n",
      "(85, 72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.19      0.25        16\n",
      "          1       0.44      0.36      0.40        11\n",
      "          2       1.00      0.40      0.57        10\n",
      "          3       0.71      0.83      0.77        12\n",
      "          4       0.65      0.76      0.70        17\n",
      "          5       0.50      0.79      0.61        19\n",
      "\n",
      "avg / total       0.59      0.58      0.55        85\n",
      "\n",
      "[ 3  4  0  1  1  7  3  4  0  2  0  2  0  0  4  0  4  2  0  0  0 10  1  1\n",
      "  0  1  0  0 13  3  2  0  0  1  1 15]\n",
      "MNB Accuracy:  0.5764705882352941\n",
      "MNB F1:  0.5509344902202046\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.37      0.44      0.40        16\n",
      "          1       1.00      0.64      0.78        11\n",
      "          2       1.00      0.40      0.57        10\n",
      "          3       0.67      0.67      0.67        12\n",
      "          4       0.67      0.71      0.69        17\n",
      "          5       0.52      0.68      0.59        19\n",
      "\n",
      "avg / total       0.66      0.60      0.61        85\n",
      "\n",
      "[ 7  0  0  1  1  7  2  7  0  2  0  0  1  0  4  0  3  2  2  0  0  8  1  1\n",
      "  3  0  0  0 12  2  4  0  0  1  1 13]\n",
      "svc Accuracy:  0.6\n",
      "svc F1:  0.6154160654160653\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.19      0.25        16\n",
      "          1       0.36      0.36      0.36        11\n",
      "          2       1.00      0.40      0.57        10\n",
      "          3       0.67      0.67      0.67        12\n",
      "          4       0.64      0.82      0.72        17\n",
      "          5       0.54      0.79      0.64        19\n",
      "\n",
      "avg / total       0.58      0.56      0.54        85\n",
      "\n",
      "[ 3  4  0  1  1  7  3  4  0  2  0  2  0  0  4  0  5  1  0  2  0  8  1  1\n",
      "  0  1  0  0 14  2  2  0  0  1  1 15]\n",
      "LR Accuracy:  0.5647058823529412\n",
      "LR F1:  0.5346630320034576\n",
      "For name:  m_cheung\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0001-7144-618X': 8, '0000-0002-2764-2113': 2, '0000-0002-8076-0725': 2, '0000-0002-0021-3802': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_weaver\n",
      "total sample size before apply threshold:  7\n",
      "Counter({'0000-0001-7394-2443': 4, '0000-0001-6733-7554': 1, '0000-0003-3361-2946': 1, '0000-0002-5556-4757': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_chien\n",
      "total sample size before apply threshold:  157\n",
      "Counter({'0000-0002-6690-6038': 71, '0000-0001-9806-486X': 60, '0000-0001-8704-0336': 25, '0000-0002-5532-1018': 1})\n",
      "['0000-0001-9806-486X', '0000-0001-8704-0336', '0000-0002-6690-6038']\n",
      "Total sample size after apply threshold:  156\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(156, 93)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(156, 18)\n",
      "2\n",
      "(156, 111)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.58      0.64        60\n",
      "          1       0.65      0.52      0.58        25\n",
      "          2       0.65      0.79      0.71        71\n",
      "\n",
      "avg / total       0.67      0.67      0.66       156\n",
      "\n",
      "[35  3 22  4 13  8 11  4 56]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.6425057367732526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.67      0.69        60\n",
      "          1       0.94      0.64      0.76        25\n",
      "          2       0.69      0.80      0.74        71\n",
      "\n",
      "avg / total       0.74      0.72      0.72       156\n",
      "\n",
      "[40  0 20  3 16  6 13  1 57]\n",
      "svc Accuracy:  0.7243589743589743\n",
      "svc F1:  0.7306065581927651\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.57      0.63        60\n",
      "          1       1.00      0.52      0.68        25\n",
      "          2       0.64      0.86      0.73        71\n",
      "\n",
      "avg / total       0.72      0.69      0.69       156\n",
      "\n",
      "[34  0 26  4 13  8 10  0 61]\n",
      "LR Accuracy:  0.6923076923076923\n",
      "LR F1:  0.6829266383271878\n",
      "For name:  s_yun\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0001-7737-4746': 76, '0000-0002-1498-3701': 24, '0000-0002-3774-0622': 1, '0000-0002-9510-5133': 1})\n",
      "['0000-0001-7737-4746', '0000-0002-1498-3701']\n",
      "Total sample size after apply threshold:  100\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 45)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 13)\n",
      "2\n",
      "(100, 58)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        76\n",
      "          1       1.00      0.75      0.86        24\n",
      "\n",
      "avg / total       0.94      0.94      0.94       100\n",
      "\n",
      "[76  0  6 18]\n",
      "MNB Accuracy:  0.94\n",
      "MNB F1:  0.9095840867992767\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        76\n",
      "          1       1.00      0.75      0.86        24\n",
      "\n",
      "avg / total       0.94      0.94      0.94       100\n",
      "\n",
      "[76  0  6 18]\n",
      "svc Accuracy:  0.94\n",
      "svc F1:  0.9095840867992767\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        76\n",
      "          1       1.00      0.58      0.74        24\n",
      "\n",
      "avg / total       0.91      0.90      0.89       100\n",
      "\n",
      "[76  0 10 14]\n",
      "LR Accuracy:  0.9\n",
      "LR F1:  0.8375568551007148\n",
      "For name:  s_jung\n",
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0002-3174-8965': 57, '0000-0002-3566-5649': 9, '0000-0003-3670-1952': 4, '0000-0003-4864-8175': 1, '0000-0002-8196-1748': 1, '0000-0001-7266-1084': 1, '0000-0002-3884-4335': 1, '0000-0002-5194-7339': 1, '0000-0001-6389-2315': 1})\n",
      "['0000-0002-3174-8965']\n",
      "Total sample size after apply threshold:  57\n",
      "For name:  e_gomes\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0002-6941-4872': 20, '0000-0001-6378-6942': 8, '0000-0002-4238-3738': 8, '0000-0001-8528-8741': 2, '0000-0002-0636-6041': 2})\n",
      "['0000-0002-6941-4872']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  t_yamaguchi\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0003-4590-8592': 30, '0000-0001-9043-4408': 15, '0000-0003-0214-4983': 7, '0000-0002-7533-430X': 6, '0000-0002-5063-9924': 2, '0000-0001-8454-1995': 1, '0000-0001-5341-4184': 1})\n",
      "['0000-0001-9043-4408', '0000-0003-4590-8592']\n",
      "Total sample size after apply threshold:  45"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 12)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 14)\n",
      "2\n",
      "(45, 26)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.40      0.50        15\n",
      "          1       0.75      0.90      0.82        30\n",
      "\n",
      "avg / total       0.72      0.73      0.71        45\n",
      "\n",
      "[ 6  9  3 27]\n",
      "MNB Accuracy:  0.7333333333333333\n",
      "MNB F1:  0.6590909090909092\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.60      0.64        15\n",
      "          1       0.81      0.87      0.84        30\n",
      "\n",
      "avg / total       0.77      0.78      0.77        45\n",
      "\n",
      "[ 9  6  4 26]\n",
      "svc Accuracy:  0.7777777777777778\n",
      "svc F1:  0.7407834101382489\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.40      0.48        15\n",
      "          1       0.74      0.87      0.80        30\n",
      "\n",
      "avg / total       0.70      0.71      0.69        45\n",
      "\n",
      "[ 6  9  4 26]\n",
      "LR Accuracy:  0.7111111111111111\n",
      "LR F1:  0.64\n",
      "For name:  p_oliveira\n",
      "total sample size before apply threshold:  358\n",
      "Counter({'0000-0002-4989-5699': 71, '0000-0002-5201-9948': 71, '0000-0003-0307-354X': 55, '0000-0001-9519-4044': 50, '0000-0002-2470-0795': 40, '0000-0002-0938-152X': 20, '0000-0003-3161-8367': 16, '0000-0001-8478-7135': 8, '0000-0002-4989-2113': 7, '0000-0002-3078-2950': 7, '0000-0002-1850-6670': 5, '0000-0001-7217-5705': 2, '0000-0002-4460-9489': 2, '0000-0002-3898-2623': 1, '0000-0002-5799-390X': 1, '0000-0003-3123-4259': 1, '0000-0001-9843-7558': 1})\n",
      "['0000-0003-3161-8367', '0000-0001-9519-4044', '0000-0002-4989-5699', '0000-0002-0938-152X', '0000-0002-5201-9948', '0000-0003-0307-354X', '0000-0002-2470-0795']\n",
      "Total sample size after apply threshold:  323\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(323, 193)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(323, 24)\n",
      "2\n",
      "(323, 217)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.64      0.36      0.46        50\n",
      "          2       0.46      0.76      0.57        71\n",
      "          3       0.00      0.00      0.00        20\n",
      "          4       0.44      0.61      0.51        71\n",
      "          5       0.60      0.60      0.60        55\n",
      "          6       0.35      0.23      0.27        40\n",
      "\n",
      "avg / total       0.44      0.49      0.45       323\n",
      "\n",
      "[ 0  2  8  0  3  2  1  0 18 18  0 10  1  3  0  0 54  0 15  0  2  0  2  6\n",
      "  0  6  2  4  0  1 18  0 43  6  3  0  1  6  0 11 33  4  0  4  7  0  9 11\n",
      "  9]\n",
      "MNB Accuracy:  0.48606811145510836\n",
      "MNB F1:  0.3458055116109828\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.19      0.27        16\n",
      "          1       0.84      0.42      0.56        50\n",
      "          2       0.47      0.83      0.60        71\n",
      "          3       0.50      0.10      0.17        20\n",
      "          4       0.53      0.52      0.52        71\n",
      "          5       0.68      0.62      0.65        55\n",
      "          6       0.44      0.47      0.46        40\n",
      "\n",
      "avg / total       0.58      0.54      0.53       323\n",
      "\n",
      "[ 3  0  6  0  2  3  2  1 21 18  0  3  3  4  0  1 59  0  8  1  2  0  0  6\n",
      "  2  5  1  6  1  1 23  0 37  5  4  0  1  6  1  7 34  6  1  1  7  1  8  3\n",
      " 19]\n",
      "svc Accuracy:  0.541795665634675\n",
      "svc F1:  0.46167254623945475\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.86      0.36      0.51        50\n",
      "          2       0.49      0.79      0.61        71\n",
      "          3       0.00      0.00      0.00        20\n",
      "          4       0.48      0.59      0.53        71\n",
      "          5       0.59      0.65      0.62        55\n",
      "          6       0.42      0.42      0.42        40\n",
      "\n",
      "avg / total       0.50      0.52      0.49       323\n",
      "\n",
      "[ 0  1  7  0  3  2  3  0 18 16  0  8  4  4  0  0 56  0 13  1  1  0  0  7\n",
      "  0  5  2  6  0  0 16  0 42 10  3  0  0  6  0  7 36  6  0  2  6  0  9  6\n",
      " 17]\n",
      "LR Accuracy:  0.5232198142414861\n",
      "LR F1:  0.38425469767417125\n",
      "For name:  r_torres\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0002-9109-4035': 17, '0000-0001-8030-5522': 7, '0000-0002-4041-270X': 7, '0000-0002-3777-8671': 4, '0000-0002-8205-8518': 2, '0000-0001-7090-7925': 2, '0000-0001-9606-0398': 1})\n",
      "['0000-0002-9109-4035']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  a_esteves\n",
      "total sample size before apply threshold:  63\n",
      "Counter({'0000-0002-7983-5742': 22, '0000-0001-8403-2015': 19, '0000-0003-2239-2976': 11, '0000-0002-7837-5983': 4, '0000-0002-9614-0635': 4, '0000-0001-6769-1844': 3})\n",
      "['0000-0003-2239-2976', '0000-0001-8403-2015', '0000-0002-7983-5742']\n",
      "Total sample size after apply threshold:  52\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 16)\n",
      "2\n",
      "(52, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.55      0.67        11\n",
      "          1       0.65      0.58      0.61        19\n",
      "          2       0.68      0.86      0.76        22\n",
      "\n",
      "avg / total       0.70      0.69      0.69        52\n",
      "\n",
      "[ 6  3  2  1 11  7  0  3 19]\n",
      "MNB Accuracy:  0.6923076923076923\n",
      "MNB F1:  0.6792592592592591\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.55      0.67        11\n",
      "          1       0.62      0.68      0.65        19\n",
      "          2       0.71      0.77      0.74        22\n",
      "\n",
      "avg / total       0.71      0.69      0.69        52\n",
      "\n",
      "[ 6  3  2  1 13  5  0  5 17]\n",
      "svc Accuracy:  0.6923076923076923\n",
      "svc F1:  0.6852657004830918\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.55      0.67        11\n",
      "          1       0.67      0.63      0.65        19\n",
      "          2       0.70      0.86      0.78        22\n",
      "\n",
      "avg / total       0.72      0.71      0.71        52\n",
      "\n",
      "[ 6  3  2  1 12  6  0  3 19]\n",
      "LR Accuracy:  0.7115384615384616\n",
      "LR F1:  0.6969418397989826\n",
      "For name:  l_stevens\n",
      "total sample size before apply threshold:  77\n",
      "Counter({'0000-0003-3372-3419': 49, '0000-0003-3847-5979': 26, '0000-0002-6075-8273': 1, '0000-0002-1345-6520': 1})\n",
      "['0000-0003-3372-3419', '0000-0003-3847-5979']\n",
      "Total sample size after apply threshold:  75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(75, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(75, 20)\n",
      "2\n",
      "(75, 68)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      1.00      0.80        49\n",
      "          1       1.00      0.04      0.07        26\n",
      "\n",
      "avg / total       0.78      0.67      0.55        75\n",
      "\n",
      "[49  0 25  1]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.43541102077687444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.82      0.78        49\n",
      "          1       0.59      0.50      0.54        26\n",
      "\n",
      "avg / total       0.70      0.71      0.70        75\n",
      "\n",
      "[40  9 13 13]\n",
      "svc Accuracy:  0.7066666666666667\n",
      "svc F1:  0.6629901960784315\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.96      0.78        49\n",
      "          1       0.50      0.08      0.13        26\n",
      "\n",
      "avg / total       0.61      0.65      0.56        75\n",
      "\n",
      "[47  2 24  2]\n",
      "LR Accuracy:  0.6533333333333333\n",
      "LR F1:  0.45833333333333337\n",
      "For name:  a_chang\n",
      "total sample size before apply threshold:  178\n",
      "Counter({'0000-0001-9506-0425': 74, '0000-0002-6877-5510': 72, '0000-0001-7309-9687': 19, '0000-0002-8416-359X': 5, '0000-0001-7096-7151': 4, '0000-0002-5694-0136': 4})\n",
      "['0000-0001-7309-9687', '0000-0001-9506-0425', '0000-0002-6877-5510']\n",
      "Total sample size after apply threshold:  165\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(165, 83)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(165, 17)\n",
      "2\n",
      "(165, 100)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.37      0.54        19\n",
      "          1       0.84      0.93      0.88        74\n",
      "          2       0.84      0.89      0.86        72\n",
      "\n",
      "avg / total       0.86      0.85      0.84       165\n",
      "\n",
      "[ 7  5  7  0 69  5  0  8 64]\n",
      "MNB Accuracy:  0.8484848484848485\n",
      "MNB F1:  0.7626472626472628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.84      0.89        19\n",
      "          1       0.92      0.88      0.90        74\n",
      "          2       0.84      0.90      0.87        72\n",
      "\n",
      "avg / total       0.89      0.88      0.89       165\n",
      "\n",
      "[16  0  3  0 65  9  1  6 65]\n",
      "svc Accuracy:  0.8848484848484849\n",
      "svc F1:  0.8859746115011099\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.37      0.54        19\n",
      "          1       0.85      0.89      0.87        74\n",
      "          2       0.81      0.90      0.86        72\n",
      "\n",
      "avg / total       0.85      0.84      0.82       165\n",
      "\n",
      "[ 7  5  7  0 66  8  0  7 65]\n",
      "LR Accuracy:  0.8363636363636363\n",
      "LR F1:  0.7540485829959515\n",
      "For name:  l_song\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0003-0585-8519': 38, '0000-0003-1691-9583': 15, '0000-0002-0400-8283': 3, '0000-0003-2454-1576': 1, '0000-0002-7299-5719': 1})\n",
      "['0000-0003-1691-9583', '0000-0003-0585-8519']\n",
      "Total sample size after apply threshold:  53\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 13)\n",
      "2\n",
      "(53, 35)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90        15\n",
      "          1       0.97      0.95      0.96        38\n",
      "\n",
      "avg / total       0.95      0.94      0.94        53\n",
      "\n",
      "[14  1  2 36]\n",
      "MNB Accuracy:  0.9433962264150944\n",
      "MNB F1:  0.9316129032258064\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        15\n",
      "          1       0.97      0.97      0.97        38\n",
      "\n",
      "avg / total       0.96      0.96      0.96        53\n",
      "\n",
      "[14  1  1 37]\n",
      "svc Accuracy:  0.9622641509433962\n",
      "svc F1:  0.9535087719298245\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.67      0.77        15\n",
      "          1       0.88      0.97      0.93        38\n",
      "\n",
      "avg / total       0.89      0.89      0.88        53\n",
      "\n",
      "[10  5  1 37]\n",
      "LR Accuracy:  0.8867924528301887\n",
      "LR F1:  0.8471153846153846\n",
      "For name:  j_delgado\n",
      "total sample size before apply threshold:  123\n",
      "Counter({'0000-0002-5157-4376': 85, '0000-0002-6948-8062': 26, '0000-0003-4074-981X': 6, '0000-0002-8075-4704': 3, '0000-0002-0166-5464': 2, '0000-0002-1026-4523': 1})\n",
      "['0000-0002-6948-8062', '0000-0002-5157-4376']\n",
      "Total sample size after apply threshold:  111\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 51)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 18)\n",
      "2\n",
      "(111, 69)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.65      0.72        26\n",
      "          1       0.90      0.95      0.93        85\n",
      "\n",
      "avg / total       0.88      0.88      0.88       111\n",
      "\n",
      "[17  9  4 81]\n",
      "MNB Accuracy:  0.8828828828828829\n",
      "MNB F1:  0.8245592705167173\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        26\n",
      "          1       0.94      1.00      0.97        85\n",
      "\n",
      "avg / total       0.96      0.95      0.95       111\n",
      "\n",
      "[21  5  0 85]\n",
      "svc Accuracy:  0.954954954954955\n",
      "svc F1:  0.9325227963525835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        26\n",
      "          1       0.83      1.00      0.90        85\n",
      "\n",
      "avg / total       0.87      0.84      0.80       111\n",
      "\n",
      "[ 8 18  0 85]\n",
      "LR Accuracy:  0.8378378378378378\n",
      "LR F1:  0.6874217772215269\n",
      "For name:  p_jensen\n",
      "total sample size before apply threshold:  319\n",
      "Counter({'0000-0003-2387-0650': 98, '0000-0003-1648-7186': 65, '0000-0001-6524-7723': 55, '0000-0003-4359-848X': 28, '0000-0001-7058-6930': 17, '0000-0003-4718-1630': 16, '0000-0002-9819-1516': 14, '0000-0002-8856-2395': 12, '0000-0001-8792-7711': 11, '0000-0002-5248-0523': 1, '0000-0002-9588-3189': 1, '0000-0002-9297-2098': 1})\n",
      "['0000-0003-4359-848X', '0000-0002-9819-1516', '0000-0003-2387-0650', '0000-0001-8792-7711', '0000-0003-4718-1630', '0000-0001-6524-7723', '0000-0002-8856-2395', '0000-0003-1648-7186', '0000-0001-7058-6930']\n",
      "Total sample size after apply threshold:  316\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(316, 151)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(316, 24)\n",
      "2\n",
      "(316, 175)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        28\n",
      "          1       1.00      0.14      0.25        14\n",
      "          2       0.55      0.87      0.67        98\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.19      0.32        16\n",
      "          5       0.59      0.49      0.53        55\n",
      "          6       0.00      0.00      0.00        12\n",
      "          7       0.43      0.69      0.53        65\n",
      "          8       0.33      0.12      0.17        17\n",
      "\n",
      "avg / total       0.48      0.52      0.45       316\n",
      "\n",
      "[ 0  0 12  0  0  4  0 10  2  0  2  6  0  0  2  0  4  0  0  0 85  0  0  3\n",
      "  0  9  1  0  0  1  0  0  2  0  7  1  0  0  5  0  3  1  0  7  0  1  0 17\n",
      "  0  0 27  0 10  0  0  0  5  0  0  2  0  5  0  0  0 17  0  0  3  0 45  0\n",
      "  0  0  6  0  0  2  0  7  2]\n",
      "MNB Accuracy:  0.5189873417721519\n",
      "MNB F1:  0.2757226150900451\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.36      0.48        28\n",
      "          1       0.71      0.36      0.48        14\n",
      "          2       0.65      0.90      0.75        98\n",
      "          3       0.31      0.36      0.33        11\n",
      "          4       1.00      0.56      0.72        16\n",
      "          5       0.58      0.56      0.57        55\n",
      "          6       1.00      0.33      0.50        12\n",
      "          7       0.69      0.71      0.70        65\n",
      "          8       0.23      0.18      0.20        17\n",
      "\n",
      "avg / total       0.65      0.63      0.62       316\n",
      "\n",
      "[10  0  6  2  0  7  0  1  2  0  5  6  0  0  1  0  2  0  0  0 88  1  0  2\n",
      "  0  6  1  0  0  0  4  0  0  0  5  2  0  2  1  0  9  1  0  1  2  4  0 13\n",
      "  1  0 31  0  4  2  0  0  6  1  0  0  4  1  0  0  0  9  3  0  6  0 46  1\n",
      "  0  0  7  1  0  5  0  1  3]\n",
      "svc Accuracy:  0.6329113924050633\n",
      "svc F1:  0.5254327565438678\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.07      0.12        28\n",
      "          1       1.00      0.21      0.35        14\n",
      "          2       0.64      0.86      0.73        98\n",
      "          3       0.29      0.18      0.22        11\n",
      "          4       0.83      0.31      0.45        16\n",
      "          5       0.53      0.56      0.55        55\n",
      "          6       1.00      0.25      0.40        12\n",
      "          7       0.53      0.75      0.62        65\n",
      "          8       0.36      0.24      0.29        17\n",
      "\n",
      "avg / total       0.59      0.58      0.54       316\n",
      "\n",
      "[ 2  0  9  1  0  6  0  8  2  0  3  4  0  1  2  0  4  0  0  0 84  0  0  4\n",
      "  0  9  1  0  0  1  2  0  3  0  3  2  0  0  4  0  5  1  0  5  1  3  0 12\n",
      "  1  0 31  0  7  1  0  0  4  1  0  2  3  2  0  0  0 11  1  0  4  0 49  0\n",
      "  0  0  2  1  0  5  0  5  4]\n",
      "LR Accuracy:  0.5791139240506329\n",
      "LR F1:  0.41590401137120847\n",
      "For name:  t_allen\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0002-3911-7914': 17, '0000-0002-3512-9475': 14, '0000-0002-0667-6138': 10, '0000-0002-2372-7259': 3, '0000-0002-1107-1416': 2, '0000-0002-2972-7911': 1, '0000-0002-1252-6056': 1})\n",
      "['0000-0002-3512-9475', '0000-0002-0667-6138', '0000-0002-3911-7914']\n",
      "Total sample size after apply threshold:  41\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 11)\n",
      "2\n",
      "(41, 31)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.86      0.83        14\n",
      "          1       0.83      0.50      0.62        10\n",
      "          2       0.75      0.88      0.81        17\n",
      "\n",
      "avg / total       0.79      0.78      0.77        41\n",
      "\n",
      "[12  0  2  2  5  3  1  1 15]\n",
      "MNB Accuracy:  0.7804878048780488\n",
      "MNB F1:  0.7544656725691209\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.93      0.79        14\n",
      "          1       0.89      0.80      0.84        10\n",
      "          2       0.92      0.71      0.80        17\n",
      "\n",
      "avg / total       0.83      0.80      0.81        41\n",
      "\n",
      "[13  0  1  2  8  0  4  1 12]\n",
      "svc Accuracy:  0.8048780487804879\n",
      "svc F1:  0.8099946836788944\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.86      0.77        14\n",
      "          1       0.83      0.50      0.62        10\n",
      "          2       0.83      0.88      0.86        17\n",
      "\n",
      "avg / total       0.79      0.78      0.77        41\n",
      "\n",
      "[12  0  2  4  5  1  1  1 15]\n",
      "LR Accuracy:  0.7804878048780488\n",
      "LR F1:  0.7521121351766512\n",
      "For name:  j_sullivan\n",
      "total sample size before apply threshold:  79\n",
      "Counter({'0000-0003-1457-2950': 26, '0000-0001-5445-708X': 17, '0000-0003-4489-4926': 14, '0000-0003-3209-0218': 9, '0000-0001-6732-0699': 7, '0000-0002-5952-3805': 2, '0000-0003-2906-2232': 1, '0000-0002-7279-4319': 1, '0000-0002-3746-3047': 1, '0000-0002-5441-4343': 1})\n",
      "['0000-0003-4489-4926', '0000-0001-5445-708X', '0000-0003-1457-2950']\n",
      "Total sample size after apply threshold:  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 16)\n",
      "2\n",
      "(57, 48)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.71      0.74        14\n",
      "          1       0.75      0.71      0.73        17\n",
      "          2       0.79      0.85      0.81        26\n",
      "\n",
      "avg / total       0.77      0.77      0.77        57\n",
      "\n",
      "[10  1  3  2 12  3  1  3 22]\n",
      "MNB Accuracy:  0.7719298245614035\n",
      "MNB F1:  0.7609427609427609\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.80      0.71      0.75        17\n",
      "          2       0.79      0.88      0.84        26\n",
      "\n",
      "avg / total       0.85      0.84      0.84        57\n",
      "\n",
      "[13  0  1  0 12  5  0  3 23]\n",
      "svc Accuracy:  0.8421052631578947\n",
      "svc F1:  0.8497755331088666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        14\n",
      "          1       0.73      0.65      0.69        17\n",
      "          2       0.68      0.88      0.77        26\n",
      "\n",
      "avg / total       0.77      0.74      0.73        57\n",
      "\n",
      "[ 8  1  5  0 11  6  0  3 23]\n",
      "LR Accuracy:  0.7368421052631579\n",
      "LR F1:  0.7271464646464647\n",
      "For name:  s_rogers\n",
      "total sample size before apply threshold:  224\n",
      "Counter({'0000-0002-5989-6142': 200, '0000-0003-3578-4477': 9, '0000-0003-1139-4730': 8, '0000-0002-3432-5044': 3, '0000-0003-0516-7929': 2, '0000-0001-9974-7152': 1, '0000-0002-0809-2726': 1})\n",
      "['0000-0002-5989-6142']\n",
      "Total sample size after apply threshold:  200\n",
      "For name:  h_yoon\n",
      "total sample size before apply threshold:  72\n",
      "Counter({'0000-0002-5403-1617': 34, '0000-0003-2180-4940': 10, '0000-0002-7139-0419': 7, '0000-0002-7552-0479': 6, '0000-0003-3087-8853': 5, '0000-0002-9597-6342': 4, '0000-0002-6211-7680': 3, '0000-0002-8553-0152': 1, '0000-0001-7547-0320': 1, '0000-0003-3524-8762': 1})\n",
      "['0000-0002-5403-1617', '0000-0003-2180-4940']\n",
      "Total sample size after apply threshold:  44\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 13)\n",
      "2\n",
      "(44, 34)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.91      0.87        34\n",
      "          1       0.57      0.40      0.47        10\n",
      "\n",
      "avg / total       0.78      0.80      0.78        44\n",
      "\n",
      "[31  3  6  4]\n",
      "MNB Accuracy:  0.7954545454545454\n",
      "MNB F1:  0.671913835956918\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94        34\n",
      "          1       0.88      0.70      0.78        10\n",
      "\n",
      "avg / total       0.91      0.91      0.91        44\n",
      "\n",
      "[33  1  3  7]\n",
      "svc Accuracy:  0.9090909090909091\n",
      "svc F1:  0.8603174603174603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89        34\n",
      "          1       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.85      0.82      0.77        44\n",
      "\n",
      "[34  0  8  2]\n",
      "LR Accuracy:  0.8181818181818182\n",
      "LR F1:  0.6140350877192983\n",
      "For name:  a_young\n",
      "total sample size before apply threshold:  442\n",
      "Counter({'0000-0002-1202-6297': 138, '0000-0001-5702-4220': 78, '0000-0002-4163-6772': 54, '0000-0002-9367-9213': 38, '0000-0002-7288-3469': 31, '0000-0001-8551-5078': 25, '0000-0003-3969-3249': 22, '0000-0002-0077-137X': 22, '0000-0001-6251-0944': 20, '0000-0002-8486-0643': 8, '0000-0002-8127-7380': 2, '0000-0002-1994-9211': 1, '0000-0002-1486-5561': 1, '0000-0001-6800-1454': 1, '0000-0003-4822-6335': 1})\n",
      "['0000-0001-6251-0944', '0000-0001-8551-5078', '0000-0002-4163-6772', '0000-0002-7288-3469', '0000-0002-1202-6297', '0000-0001-5702-4220', '0000-0003-3969-3249', '0000-0002-0077-137X', '0000-0002-9367-9213']\n",
      "Total sample size after apply threshold:  428\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(428, 194)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(428, 41)\n",
      "2\n",
      "(428, 235)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        20\n",
      "          1       1.00      0.12      0.21        25\n",
      "          2       0.78      0.52      0.62        54\n",
      "          3       0.92      0.39      0.55        31\n",
      "          4       0.53      0.93      0.68       138\n",
      "          5       0.65      0.69      0.67        78\n",
      "          6       0.80      0.18      0.30        22\n",
      "          7       1.00      0.77      0.87        22\n",
      "          8       0.68      0.55      0.61        38\n",
      "\n",
      "avg / total       0.67      0.62      0.59       428\n",
      "\n",
      "[  0   0   2   0  15   1   0   0   2   0   3   1   1  14   4   1   0   1\n",
      "   0   0  28   0  20   4   0   0   2   0   0   1  12  11   6   0   0   1\n",
      "   0   0   2   0 128   6   0   0   2   0   0   1   0  21  54   0   0   2\n",
      "   0   0   0   0  15   3   4   0   0   0   0   1   0   4   0   0  17   0\n",
      "   0   0   0   0  12   5   0   0  21]\n",
      "MNB Accuracy:  0.6238317757009346\n",
      "MNB F1:  0.5007561592102655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        20\n",
      "          1       1.00      0.48      0.65        25\n",
      "          2       0.90      0.65      0.75        54\n",
      "          3       0.85      0.74      0.79        31\n",
      "          4       0.61      0.93      0.74       138\n",
      "          5       0.81      0.64      0.71        78\n",
      "          6       0.54      0.59      0.57        22\n",
      "          7       1.00      0.77      0.87        22\n",
      "          8       0.85      0.61      0.71        38\n",
      "\n",
      "avg / total       0.78      0.73      0.73       428\n",
      "\n",
      "[ 10   0   1   0   8   0   0   0   1   0  12   0   1   6   1   5   0   0\n",
      "   0   0  35   1  14   1   2   0   1   0   0   1  23   4   3   0   0   0\n",
      "   0   0   1   0 129   5   1   0   2   0   0   0   1  24  50   3   0   0\n",
      "   0   0   0   1   8   0  13   0   0   0   0   0   0   5   0   0  17   0\n",
      "   0   0   1   0  12   2   0   0  23]\n",
      "svc Accuracy:  0.7289719626168224\n",
      "svc F1:  0.7179418367840286\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.05      0.10        20\n",
      "          1       1.00      0.24      0.39        25\n",
      "          2       0.86      0.56      0.67        54\n",
      "          3       0.94      0.48      0.64        31\n",
      "          4       0.55      0.95      0.69       138\n",
      "          5       0.75      0.62      0.68        78\n",
      "          6       0.54      0.59      0.57        22\n",
      "          7       1.00      0.77      0.87        22\n",
      "          8       0.88      0.58      0.70        38\n",
      "\n",
      "avg / total       0.75      0.66      0.64       428\n",
      "\n",
      "[  1   0   1   0  17   0   0   0   1   0   6   1   1  10   2   5   0   0\n",
      "   0   0  30   0  19   2   2   0   1   0   0   1  15   9   6   0   0   0\n",
      "   0   0   2   0 131   3   2   0   0   0   0   0   0  27  48   2   0   1\n",
      "   0   0   0   0   8   1  13   0   0   0   0   0   0   5   0   0  17   0\n",
      "   0   0   0   0  14   2   0   0  22]\n",
      "LR Accuracy:  0.6612149532710281\n",
      "LR F1:  0.5888214486449594\n",
      "For name:  m_richardson\n",
      "total sample size before apply threshold:  175\n",
      "Counter({'0000-0001-5672-9552': 166, '0000-0002-1650-0064': 5, '0000-0002-7390-9480': 3, '0000-0003-2694-5486': 1})\n",
      "['0000-0001-5672-9552']\n",
      "Total sample size after apply threshold:  166\n",
      "For name:  c_ryan\n",
      "total sample size before apply threshold:  159\n",
      "Counter({'0000-0003-2158-9427': 71, '0000-0003-1915-546X': 29, '0000-0003-2750-9854': 17, '0000-0001-5864-4325': 15, '0000-0003-2891-3912': 14, '0000-0002-1802-0128': 9, '0000-0003-0986-6110': 2, '0000-0002-9674-3946': 1, '0000-0002-6455-936X': 1})\n",
      "['0000-0001-5864-4325', '0000-0003-1915-546X', '0000-0003-2750-9854', '0000-0003-2158-9427', '0000-0003-2891-3912']\n",
      "Total sample size after apply threshold:  146\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(146, 76)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(146, 16)\n",
      "2\n",
      "(146, 92)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.13      0.22        15\n",
      "          1       0.59      0.34      0.43        29\n",
      "          2       1.00      0.18      0.30        17\n",
      "          3       0.56      0.96      0.70        71\n",
      "          4       1.00      0.07      0.13        14\n",
      "\n",
      "avg / total       0.67      0.58      0.50       146\n",
      "\n",
      "[ 2  4  0  9  0  1 10  0 18  0  0  0  3 14  0  0  3  0 68  0  0  0  0 13\n",
      "  1]\n",
      "MNB Accuracy:  0.5753424657534246\n",
      "MNB F1:  0.3590002753372882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.27      0.38        15\n",
      "          1       0.52      0.59      0.55        29\n",
      "          2       0.83      0.29      0.43        17\n",
      "          3       0.69      0.90      0.78        71\n",
      "          4       0.62      0.36      0.45        14\n",
      "\n",
      "avg / total       0.66      0.65      0.62       146\n",
      "\n",
      "[ 4  3  0  8  0  1 17  1  9  1  0  4  5  6  2  1  6  0 64  0  0  3  0  6\n",
      "  5]\n",
      "svc Accuracy:  0.6506849315068494\n",
      "svc F1:  0.519831069169146\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.42        15\n",
      "          1       0.64      0.48      0.55        29\n",
      "          2       1.00      0.18      0.30        17\n",
      "          3       0.59      0.94      0.73        71\n",
      "          4       1.00      0.29      0.44        14\n",
      "\n",
      "avg / total       0.73      0.63      0.58       146\n",
      "\n",
      "[ 4  3  0  8  0  0 14  0 15  0  0  0  3 14  0  0  4  0 67  0  0  1  0  9\n",
      "  4]\n",
      "LR Accuracy:  0.6301369863013698\n",
      "LR F1:  0.48855551068634934\n",
      "For name:  l_jensen\n",
      "total sample size before apply threshold:  275\n",
      "Counter({'0000-0001-7885-715X': 140, '0000-0002-0267-8312': 37, '0000-0003-3199-1743': 37, '0000-0002-0020-1537': 28, '0000-0002-1446-2084': 22, '0000-0003-2338-357X': 8, '0000-0001-9059-5869': 1, '0000-0003-2786-5920': 1, '0000-0002-1648-3970': 1})\n",
      "['0000-0002-0020-1537', '0000-0002-1446-2084', '0000-0001-7885-715X', '0000-0002-0267-8312', '0000-0003-3199-1743']\n",
      "Total sample size after apply threshold:  264\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(264, 115)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(264, 24)\n",
      "2\n",
      "(264, 139)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        28\n",
      "          1       1.00      0.09      0.17        22\n",
      "          2       0.62      0.95      0.75       140\n",
      "          3       0.67      0.32      0.44        37\n",
      "          4       0.66      0.51      0.58        37\n",
      "\n",
      "avg / total       0.60      0.63      0.55       264\n",
      "\n",
      "[  0   0  28   0   0   0   2  20   0   0   0   0 133   2   5   0   0  20\n",
      "  12   5   0   0  14   4  19]\n",
      "MNB Accuracy:  0.6287878787878788\n",
      "MNB F1:  0.3856167306871532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.43      0.59        28\n",
      "          1       1.00      0.64      0.78        22\n",
      "          2       0.74      0.98      0.84       140\n",
      "          3       0.80      0.54      0.65        37\n",
      "          4       0.78      0.57      0.66        37\n",
      "\n",
      "avg / total       0.80      0.77      0.76       264\n",
      "\n",
      "[ 12   0  16   0   0   0  14   8   0   0   0   0 137   2   1   1   0  11\n",
      "  20   5   0   0  13   3  21]\n",
      "svc Accuracy:  0.7727272727272727\n",
      "svc F1:  0.7015263689671636\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.11      0.19        28\n",
      "          1       1.00      0.27      0.43        22\n",
      "          2       0.63      0.98      0.77       140\n",
      "          3       0.87      0.35      0.50        37\n",
      "          4       0.78      0.49      0.60        37\n",
      "\n",
      "avg / total       0.76      0.67      0.62       264\n",
      "\n",
      "[  3   0  25   0   0   0   6  16   0   0   0   0 137   2   1   0   0  20\n",
      "  13   4   0   0  19   0  18]\n",
      "LR Accuracy:  0.6704545454545454\n",
      "LR F1:  0.49792536369386464\n",
      "For name:  h_ferreira\n",
      "total sample size before apply threshold:  135\n",
      "Counter({'0000-0003-3611-6040': 53, '0000-0002-3261-3712': 22, '0000-0002-3770-9393': 16, '0000-0001-9143-504X': 13, '0000-0002-4323-3942': 12, '0000-0003-0834-2956': 12, '0000-0002-8895-2422': 7})\n",
      "['0000-0003-3611-6040', '0000-0001-9143-504X', '0000-0002-4323-3942', '0000-0002-3770-9393', '0000-0002-3261-3712', '0000-0003-0834-2956']\n",
      "Total sample size after apply threshold:  128\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(128, 94)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(128, 22)\n",
      "2\n",
      "(128, 116)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.89      0.60        53\n",
      "          1       0.25      0.08      0.12        13\n",
      "          2       1.00      0.17      0.29        12\n",
      "          3       1.00      0.06      0.12        16\n",
      "          4       0.41      0.32      0.36        22\n",
      "          5       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.50      0.45      0.36       128\n",
      "\n",
      "[47  1  0  0  5  0 12  1  0  0  0  0  6  0  2  0  4  0 13  1  0  1  1  0\n",
      " 14  1  0  0  7  0 12  0  0  0  0  0]\n",
      "MNB Accuracy:  0.453125\n",
      "MNB F1:  0.24645147949756419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.85      0.59        53\n",
      "          1       0.20      0.08      0.11        13\n",
      "          2       0.18      0.17      0.17        12\n",
      "          3       1.00      0.19      0.32        16\n",
      "          4       0.67      0.27      0.39        22\n",
      "          5       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.47      0.45      0.38       128\n",
      "\n",
      "[45  2  4  0  2  0 11  1  0  0  0  1 10  0  2  0  0  0 12  1  0  3  0  0\n",
      " 12  1  3  0  6  0  9  0  2  0  1  0]\n",
      "svc Accuracy:  0.4453125\n",
      "svc F1:  0.2633359442708376\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.89      0.58        53\n",
      "          1       0.33      0.08      0.12        13\n",
      "          2       0.17      0.08      0.11        12\n",
      "          3       1.00      0.06      0.12        16\n",
      "          4       0.67      0.27      0.39        22\n",
      "          5       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.47      0.44      0.35       128\n",
      "\n",
      "[47  1  3  0  2  0 11  1  0  0  0  1 11  0  1  0  0  0 13  1  0  1  1  0\n",
      " 15  0  1  0  6  0 11  0  1  0  0  0]\n",
      "LR Accuracy:  0.4375\n",
      "LR F1:  0.22078431263420129\n",
      "For name:  a_mahmoud\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0003-2459-5195': 19, '0000-0002-4716-7524': 15, '0000-0001-8905-9196': 7, '0000-0003-2959-0692': 4, '0000-0002-8703-841X': 3})\n",
      "['0000-0002-4716-7524', '0000-0003-2459-5195']\n",
      "Total sample size after apply threshold:  34\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 27)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 9)\n",
      "2\n",
      "(34, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       0.86      1.00      0.93        19\n",
      "\n",
      "avg / total       0.92      0.91      0.91        34\n",
      "\n",
      "[12  3  0 19]\n",
      "MNB Accuracy:  0.9117647058823529\n",
      "MNB F1:  0.9078590785907859\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        15\n",
      "          1       0.90      1.00      0.95        19\n",
      "\n",
      "avg / total       0.95      0.94      0.94        34\n",
      "\n",
      "[13  2  0 19]\n",
      "svc Accuracy:  0.9411764705882353\n",
      "svc F1:  0.9392857142857143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       0.86      1.00      0.93        19\n",
      "\n",
      "avg / total       0.92      0.91      0.91        34\n",
      "\n",
      "[12  3  0 19]\n",
      "LR Accuracy:  0.9117647058823529\n",
      "LR F1:  0.9078590785907859\n",
      "For name:  y_liao\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0002-4434-3780': 42, '0000-0001-9496-4190': 21, '0000-0002-9384-336X': 15, '0000-0002-8217-8202': 13, '0000-0002-0399-0201': 13, '0000-0002-4360-7932': 7, '0000-0001-5658-8948': 2, '0000-0002-4401-8275': 1, '0000-0002-2107-918X': 1})\n",
      "['0000-0002-9384-336X', '0000-0001-9496-4190', '0000-0002-8217-8202', '0000-0002-0399-0201', '0000-0002-4434-3780']\n",
      "Total sample size after apply threshold:  104\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(104, 57)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(104, 19)\n",
      "2\n",
      "(104, 76)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.47      0.54        15\n",
      "          1       0.67      0.57      0.62        21\n",
      "          2       0.30      0.23      0.26        13\n",
      "          3       0.50      0.15      0.24        13\n",
      "          4       0.57      0.83      0.68        42\n",
      "\n",
      "avg / total       0.56      0.57      0.54       104\n",
      "\n",
      "[ 7  2  1  0  5  1 12  1  0  7  1  3  3  0  6  0  0  3  2  8  2  1  2  2\n",
      " 35]\n",
      "MNB Accuracy:  0.5673076923076923\n",
      "MNB F1:  0.46592429743920816\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.53      0.62        15\n",
      "          1       0.85      0.52      0.65        21\n",
      "          2       0.64      0.54      0.58        13\n",
      "          3       0.44      0.31      0.36        13\n",
      "          4       0.57      0.81      0.67        42\n",
      "\n",
      "avg / total       0.64      0.62      0.61       104\n",
      "\n",
      "[ 8  0  0  0  7  0 11  1  1  8  0  1  7  1  4  1  0  1  4  7  2  1  2  3\n",
      " 34]\n",
      "svc Accuracy:  0.6153846153846154\n",
      "svc F1:  0.5752159605100782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.33      0.48        15\n",
      "          1       0.71      0.48      0.57        21\n",
      "          2       0.62      0.38      0.48        13\n",
      "          3       0.25      0.08      0.12        13\n",
      "          4       0.51      0.88      0.65        42\n",
      "\n",
      "avg / total       0.58      0.56      0.52       104\n",
      "\n",
      "[ 5  2  0  0  8  0 10  1  0 10  0  1  5  1  6  0  0  1  1 11  1  1  1  2\n",
      " 37]\n",
      "LR Accuracy:  0.5576923076923077\n",
      "LR F1:  0.45811587793011943\n",
      "For name:  m_svensson\n",
      "total sample size before apply threshold:  142\n",
      "Counter({'0000-0003-1179-7003': 40, '0000-0003-1695-7934': 35, '0000-0002-8304-1398': 20, '0000-0003-1113-7478': 18, '0000-0003-4972-4416': 17, '0000-0001-8077-9824': 12})\n",
      "['0000-0001-8077-9824', '0000-0002-8304-1398', '0000-0003-4972-4416', '0000-0003-1695-7934', '0000-0003-1113-7478', '0000-0003-1179-7003']\n",
      "Total sample size after apply threshold:  142\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 82)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 26)\n",
      "2\n",
      "(142, 108)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.67      0.64        12\n",
      "          1       0.74      0.85      0.79        20\n",
      "          2       1.00      0.18      0.30        17\n",
      "          3       0.52      0.66      0.58        35\n",
      "          4       0.25      0.17      0.20        18\n",
      "          5       0.70      0.82      0.76        40\n",
      "\n",
      "avg / total       0.63      0.61      0.58       142\n",
      "\n",
      "[ 8  0  0  3  1  0  0 17  0  1  0  2  1  0  3  7  2  4  1  2  0 23  5  4\n",
      "  3  3  0  5  3  4  0  1  0  5  1 33]\n",
      "MNB Accuracy:  0.6126760563380281\n",
      "MNB F1:  0.5452661408477392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.75      0.64        12\n",
      "          1       0.84      0.80      0.82        20\n",
      "          2       0.67      0.24      0.35        17\n",
      "          3       0.56      0.71      0.63        35\n",
      "          4       0.38      0.33      0.35        18\n",
      "          5       0.82      0.82      0.82        40\n",
      "\n",
      "avg / total       0.66      0.65      0.64       142\n",
      "\n",
      "[ 9  0  0  2  1  0  0 16  0  1  1  2  1  1  4  5  2  4  3  0  2 25  4  1\n",
      "  3  1  0  8  6  0  0  1  0  4  2 33]\n",
      "svc Accuracy:  0.6549295774647887\n",
      "svc F1:  0.602356204466179\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.58      0.56        12\n",
      "          1       0.89      0.85      0.87        20\n",
      "          2       1.00      0.18      0.30        17\n",
      "          3       0.52      0.66      0.58        35\n",
      "          4       0.38      0.17      0.23        18\n",
      "          5       0.62      0.85      0.72        40\n",
      "\n",
      "avg / total       0.64      0.61      0.58       142\n",
      "\n",
      "[ 7  0  0  4  1  0  0 17  0  1  0  2  1  0  3  7  0  6  2  0  0 23  3  7\n",
      "  3  2  0  4  3  6  0  0  0  5  1 34]\n",
      "LR Accuracy:  0.6126760563380281\n",
      "LR F1:  0.5434386762101618\n",
      "For name:  p_tsai\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-8650-647X': 31, '0000-0002-3095-3991': 14, '0000-0003-4681-0685': 12, '0000-0001-8217-6285': 9, '0000-0003-1274-574X': 4, '0000-0003-2809-0733': 2, '0000-0003-0005-1476': 1})\n",
      "['0000-0002-3095-3991', '0000-0002-8650-647X', '0000-0003-4681-0685']\n",
      "Total sample size after apply threshold:  57\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 20)\n",
      "2\n",
      "(57, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.57      0.62        14\n",
      "          1       0.73      0.97      0.83        31\n",
      "          2       0.75      0.25      0.38        12\n",
      "\n",
      "avg / total       0.72      0.72      0.68        57\n",
      "\n",
      "[ 8  5  1  1 30  0  3  6  3]\n",
      "MNB Accuracy:  0.7192982456140351\n",
      "MNB F1:  0.6079059829059829\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.57      0.70        14\n",
      "          1       0.72      1.00      0.84        31\n",
      "          2       0.60      0.25      0.35        12\n",
      "\n",
      "avg / total       0.74      0.74      0.70        57\n",
      "\n",
      "[ 8  4  2  0 31  0  1  8  3]\n",
      "svc Accuracy:  0.7368421052631579\n",
      "svc F1:  0.6288103960738232\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.50      0.61        14\n",
      "          1       0.69      1.00      0.82        31\n",
      "          2       0.67      0.17      0.27        12\n",
      "\n",
      "avg / total       0.71      0.70      0.65        57\n",
      "\n",
      "[ 7  6  1  0 31  0  2  8  2]\n",
      "LR Accuracy:  0.7017543859649122\n",
      "LR F1:  0.5637172641749301\n",
      "For name:  r_berry\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0002-7162-5046': 49, '0000-0002-6140-1583': 28, '0000-0002-1861-6722': 4, '0000-0002-4272-9858': 4})\n",
      "['0000-0002-6140-1583', '0000-0002-7162-5046']\n",
      "Total sample size after apply threshold:  77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 23)\n",
      "2\n",
      "(77, 62)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.86      0.77        28\n",
      "          1       0.91      0.80      0.85        49\n",
      "\n",
      "avg / total       0.83      0.82      0.82        77\n",
      "\n",
      "[24  4 10 39]\n",
      "MNB Accuracy:  0.8181818181818182\n",
      "MNB F1:  0.8110098176718092\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        28\n",
      "          1       0.86      1.00      0.92        49\n",
      "\n",
      "avg / total       0.91      0.90      0.89        77\n",
      "\n",
      "[20  8  0 49]\n",
      "svc Accuracy:  0.8961038961038961\n",
      "svc F1:  0.8789308176100629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        28\n",
      "          1       0.83      1.00      0.91        49\n",
      "\n",
      "avg / total       0.89      0.87      0.86        77\n",
      "\n",
      "[18 10  0 49]\n",
      "LR Accuracy:  0.8701298701298701\n",
      "LR F1:  0.8450080515297906\n",
      "For name:  j_kwok\n",
      "total sample size before apply threshold:  100\n",
      "Counter({'0000-0001-9574-6195': 76, '0000-0002-9798-9083': 23, '0000-0001-7444-6935': 1})\n",
      "['0000-0001-9574-6195', '0000-0002-9798-9083']\n",
      "Total sample size after apply threshold:  99\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(99, 55)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(99, 23)\n",
      "2\n",
      "(99, 78)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.95      0.89        76\n",
      "          1       0.71      0.43      0.54        23\n",
      "\n",
      "avg / total       0.82      0.83      0.81        99\n",
      "\n",
      "[72  4 13 10]\n",
      "MNB Accuracy:  0.8282828282828283\n",
      "MNB F1:  0.7174752392143695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91        76\n",
      "          1       0.85      0.48      0.61        23\n",
      "\n",
      "avg / total       0.86      0.86      0.84        99\n",
      "\n",
      "[74  2 12 11]\n",
      "svc Accuracy:  0.8585858585858586\n",
      "svc F1:  0.7623456790123457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.99      0.87        76\n",
      "          1       0.67      0.09      0.15        23\n",
      "\n",
      "avg / total       0.75      0.78      0.71        99\n",
      "\n",
      "[75  1 21  2]\n",
      "LR Accuracy:  0.7777777777777778\n",
      "LR F1:  0.5129695885509838\n",
      "For name:  m_schneider\n",
      "total sample size before apply threshold:  367\n",
      "Counter({'0000-0001-9645-1938': 110, '0000-0002-9570-3491': 91, '0000-0002-9260-7357': 56, '0000-0001-7190-3379': 34, '0000-0002-7114-2060': 29, '0000-0002-1223-1266': 14, '0000-0001-7147-8915': 10, '0000-0002-3842-2618': 10, '0000-0003-1488-4743': 8, '0000-0001-7534-5431': 2, '0000-0001-9846-7132': 2, '0000-0002-4918-1389': 1})\n",
      "['0000-0002-9570-3491', '0000-0002-9260-7357', '0000-0001-9645-1938', '0000-0001-7190-3379', '0000-0001-7147-8915', '0000-0002-3842-2618', '0000-0002-7114-2060', '0000-0002-1223-1266']\n",
      "Total sample size after apply threshold:  354\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(354, 160)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(354, 17)\n",
      "2\n",
      "(354, 177)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.74      0.57        91\n",
      "          1       0.68      0.57      0.62        56\n",
      "          2       0.70      0.85      0.77       110\n",
      "          3       1.00      0.53      0.69        34\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       1.00      0.31      0.47        29\n",
      "          7       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.62      0.62      0.59       354\n",
      "\n",
      "[67  2 22  0  0  0  0  0 15 32  9  0  0  0  0  0 13  3 94  0  0  0  0  0\n",
      " 13  3  0 18  0  0  0  0  9  1  0  0  0  0  0  0  6  0  4  0  0  0  0  0\n",
      " 11  4  5  0  0  0  9  0 12  2  0  0  0  0  0  0]\n",
      "MNB Accuracy:  0.6214689265536724\n",
      "MNB F1:  0.3904054716619405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.81      0.62        91\n",
      "          1       0.94      0.57      0.71        56\n",
      "          2       0.71      0.82      0.76       110\n",
      "          3       1.00      0.62      0.76        34\n",
      "          4       0.75      0.30      0.43        10\n",
      "          5       0.67      0.20      0.31        10\n",
      "          6       0.88      0.52      0.65        29\n",
      "          7       1.00      0.14      0.25        14\n",
      "\n",
      "avg / total       0.75      0.68      0.67       354\n",
      "\n",
      "[74  0 17  0  0  0  0  0 14 32  9  0  0  0  1  0 17  0 90  0  1  1  1  0\n",
      " 10  0  3 21  0  0  0  0  6  0  1  0  3  0  0  0  6  0  2  0  0  2  0  0\n",
      "  9  2  3  0  0  0 15  0 11  0  1  0  0  0  0  2]\n",
      "svc Accuracy:  0.6751412429378532\n",
      "svc F1:  0.5622182159946585\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.77      0.59        91\n",
      "          1       0.71      0.54      0.61        56\n",
      "          2       0.70      0.85      0.77       110\n",
      "          3       1.00      0.53      0.69        34\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       1.00      0.45      0.62        29\n",
      "          7       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.63      0.63      0.60       354\n",
      "\n",
      "[70  2 19  0  0  0  0  0 14 30 12  0  0  0  0  0 13  4 93  0  0  0  0  0\n",
      " 13  1  2 18  0  0  0  0  9  1  0  0  0  0  0  0  8  0  2  0  0  0  0  0\n",
      "  9  2  5  0  0  0 13  0 12  2  0  0  0  0  0  0]\n",
      "LR Accuracy:  0.632768361581921\n",
      "LR F1:  0.40935079583216666\n",
      "For name:  k_wood\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-8774-8112': 17, '0000-0001-9170-6129': 4, '0000-0002-1020-7860': 3})\n",
      "['0000-0002-8774-8112']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  c_viegas\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0002-1545-6479': 26, '0000-0002-8796-5037': 21, '0000-0003-1394-0731': 19, '0000-0002-5765-3665': 1})\n",
      "['0000-0002-1545-6479', '0000-0002-8796-5037', '0000-0003-1394-0731']\n",
      "Total sample size after apply threshold:  66\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 18)\n",
      "2\n",
      "(66, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      1.00      0.71        26\n",
      "          1       0.89      0.38      0.53        21\n",
      "          2       1.00      0.53      0.69        19\n",
      "\n",
      "avg / total       0.79      0.67      0.65        66\n",
      "\n",
      "[26  0  0 13  8  0  8  1 10]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.6451057576234714\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88        26\n",
      "          1       0.74      0.81      0.77        21\n",
      "          2       0.82      0.74      0.78        19\n",
      "\n",
      "avg / total       0.82      0.82      0.82        66\n",
      "\n",
      "[23  3  0  1 17  3  2  3 14]\n",
      "svc Accuracy:  0.8181818181818182\n",
      "svc F1:  0.8117068117068117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.92      0.87        26\n",
      "          1       0.75      0.71      0.73        21\n",
      "          2       0.82      0.74      0.78        19\n",
      "\n",
      "avg / total       0.80      0.80      0.80        66\n",
      "\n",
      "[24  2  0  3 15  3  2  3 14]\n",
      "LR Accuracy:  0.803030303030303\n",
      "LR F1:  0.7940707891927404\n",
      "For name:  r_d'souza"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0002-1505-5173': 67, '0000-0002-9724-4540': 9, '0000-0001-9028-1990': 6, '0000-0001-7887-5016': 1})\n",
      "['0000-0002-1505-5173']\n",
      "Total sample size after apply threshold:  67\n",
      "For name:  s_shim\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0001-8043-2257': 14, '0000-0003-4143-7383': 10, '0000-0001-5203-6038': 10, '0000-0002-5188-688X': 7})\n",
      "['0000-0001-8043-2257', '0000-0003-4143-7383', '0000-0001-5203-6038']\n",
      "Total sample size after apply threshold:  34\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 10)\n",
      "2\n",
      "(34, 31)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.93      0.72        14\n",
      "          1       0.50      0.10      0.17        10\n",
      "          2       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.66      0.68      0.61        34\n",
      "\n",
      "[13  1  0  8  1  1  1  0  9]\n",
      "MNB Accuracy:  0.6764705882352942\n",
      "MNB F1:  0.5962962962962964\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.86      0.71        14\n",
      "          1       0.60      0.30      0.40        10\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.72      0.71      0.69        34\n",
      "\n",
      "[12  2  0  7  3  0  1  0  9]\n",
      "svc Accuracy:  0.7058823529411765\n",
      "svc F1:  0.6844169246646027\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.86      0.69        14\n",
      "          1       0.33      0.10      0.15        10\n",
      "          2       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.60      0.65      0.59        34\n",
      "\n",
      "[12  2  0  8  1  1  1  0  9]\n",
      "LR Accuracy:  0.6470588235294118\n",
      "LR F1:  0.5798534798534799\n",
      "For name:  j_herrero\n",
      "total sample size before apply threshold:  105\n",
      "Counter({'0000-0003-1986-3482': 51, '0000-0001-7313-717X': 46, '0000-0002-0146-2464': 6, '0000-0001-8501-1187': 2})\n",
      "['0000-0003-1986-3482', '0000-0001-7313-717X']\n",
      "Total sample size after apply threshold:  97\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(97, 36)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(97, 26)\n",
      "2\n",
      "(97, 62)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.90      0.92        51\n",
      "          1       0.90      0.93      0.91        46\n",
      "\n",
      "avg / total       0.92      0.92      0.92        97\n",
      "\n",
      "[46  5  3 43]\n",
      "MNB Accuracy:  0.9175257731958762\n",
      "MNB F1:  0.9174468085106383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96        51\n",
      "          1       0.98      0.93      0.96        46\n",
      "\n",
      "avg / total       0.96      0.96      0.96        97\n",
      "\n",
      "[50  1  3 43]\n",
      "svc Accuracy:  0.9587628865979382\n",
      "svc F1:  0.9585470085470087\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.94      0.92        51\n",
      "          1       0.93      0.89      0.91        46\n",
      "\n",
      "avg / total       0.92      0.92      0.92        97\n",
      "\n",
      "[48  3  5 41]\n",
      "LR Accuracy:  0.9175257731958762\n",
      "LR F1:  0.917094017094017\n",
      "For name:  m_acosta\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0002-5018-339X': 24, '0000-0003-4827-7271': 17, '0000-0003-0611-6672': 4, '0000-0001-9504-883X': 2})\n",
      "['0000-0003-4827-7271', '0000-0002-5018-339X']\n",
      "Total sample size after apply threshold:  41\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 27)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 14)\n",
      "2\n",
      "(41, 41)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.24      0.35        17\n",
      "          1       0.63      0.92      0.75        24\n",
      "\n",
      "avg / total       0.64      0.63      0.58        41\n",
      "\n",
      "[ 4 13  2 22]\n",
      "MNB Accuracy:  0.6341463414634146\n",
      "MNB F1:  0.5467943994104643\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.71      0.69        17\n",
      "          1       0.78      0.75      0.77        24\n",
      "\n",
      "avg / total       0.73      0.73      0.73        41\n",
      "\n",
      "[12  5  6 18]\n",
      "svc Accuracy:  0.7317073170731707\n",
      "svc F1:  0.7258358662613982\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.24      0.35        17\n",
      "          1       0.63      0.92      0.75        24\n",
      "\n",
      "avg / total       0.64      0.63      0.58        41\n",
      "\n",
      "[ 4 13  2 22]\n",
      "LR Accuracy:  0.6341463414634146\n",
      "LR F1:  0.5467943994104643\n",
      "For name:  a_chan\n",
      "total sample size before apply threshold:  249\n",
      "Counter({'0000-0003-1551-3995': 218, '0000-0002-2886-2513': 10, '0000-0002-1771-163X': 7, '0000-0003-3553-7249': 5, '0000-0003-2267-4949': 4, '0000-0001-6953-0120': 3, '0000-0001-7216-191X': 1, '0000-0002-5788-333X': 1})\n",
      "['0000-0003-1551-3995', '0000-0002-2886-2513']\n",
      "Total sample size after apply threshold:  228\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(228, 77)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(228, 22)\n",
      "2\n",
      "(228, 99)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       218\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.91      0.96      0.93       228\n",
      "\n",
      "[218   0  10   0]\n",
      "MNB Accuracy:  0.956140350877193\n",
      "MNB F1:  0.4887892376681614\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       218\n",
      "          1       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.99      0.99      0.99       228\n",
      "\n",
      "[218   0   2   8]\n",
      "svc Accuracy:  0.9912280701754386\n",
      "svc F1:  0.9421613394216135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       218\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.91      0.96      0.93       228\n",
      "\n",
      "[218   0  10   0]\n",
      "LR Accuracy:  0.956140350877193\n",
      "LR F1:  0.4887892376681614\n",
      "For name:  p_kelly\n",
      "total sample size before apply threshold:  55\n",
      "Counter({'0000-0003-0500-1865': 27, '0000-0001-9040-1868': 11, '0000-0001-8933-2367': 6, '0000-0003-4338-6225': 5, '0000-0002-7490-5772': 5, '0000-0002-8813-8877': 1})\n",
      "['0000-0001-9040-1868', '0000-0003-0500-1865']\n",
      "Total sample size after apply threshold:  38\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 15)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 14)\n",
      "2\n",
      "(38, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.91      0.80        11\n",
      "          1       0.96      0.85      0.90        27\n",
      "\n",
      "avg / total       0.89      0.87      0.87        38\n",
      "\n",
      "[10  1  4 23]\n",
      "MNB Accuracy:  0.868421052631579\n",
      "MNB F1:  0.8509803921568628\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.96      1.00      0.98        27\n",
      "\n",
      "avg / total       0.97      0.97      0.97        38\n",
      "\n",
      "[10  1  0 27]\n",
      "svc Accuracy:  0.9736842105263158\n",
      "svc F1:  0.967099567099567\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.96      1.00      0.98        27\n",
      "\n",
      "avg / total       0.97      0.97      0.97        38\n",
      "\n",
      "[10  1  0 27]\n",
      "LR Accuracy:  0.9736842105263158\n",
      "LR F1:  0.967099567099567\n",
      "For name:  j_weiner\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-3352-2847': 35, '0000-0002-0736-7943': 15, '0000-0001-5810-5807': 10, '0000-0002-8099-760X': 1})\n",
      "['0000-0002-3352-2847', '0000-0002-0736-7943', '0000-0001-5810-5807']\n",
      "Total sample size after apply threshold:  60\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 40)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 23)\n",
      "2\n",
      "(60, 63)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.91      0.75        35\n",
      "          1       0.50      0.27      0.35        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.50      0.60      0.53        60\n",
      "\n",
      "[32  2  1 10  4  1  8  2  0]\n",
      "MNB Accuracy:  0.6\n",
      "MNB F1:  0.36692242114237006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.91      0.76        35\n",
      "          1       0.62      0.33      0.43        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.54      0.62      0.55        60\n",
      "\n",
      "[32  2  1  8  5  2  9  1  0]\n",
      "svc Accuracy:  0.6166666666666667\n",
      "svc F1:  0.398895790200138\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      1.00      0.74        35\n",
      "          1       1.00      0.07      0.12        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.60      0.60      0.47        60\n",
      "\n",
      "[35  0  0 14  1  0 10  0  0]\n",
      "LR Accuracy:  0.6\n",
      "LR F1:  0.2898936170212766\n",
      "For name:  b_yu\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-1258-4168': 9, '0000-0002-0531-2236': 8, '0000-0002-7259-8190': 5, '0000-0001-6013-5220': 1, '0000-0001-7266-4197': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_lucas\n",
      "total sample size before apply threshold:  96\n",
      "Counter({'0000-0002-8713-2457': 64, '0000-0003-1287-7996': 19, '0000-0002-5555-5594': 10, '0000-0002-3409-2033': 2, '0000-0003-3059-7453': 1})\n",
      "['0000-0002-8713-2457', '0000-0002-5555-5594', '0000-0003-1287-7996']\n",
      "Total sample size after apply threshold:  93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(93, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(93, 19)\n",
      "2\n",
      "(93, 75)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        64\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.47      0.64        19\n",
      "\n",
      "avg / total       0.73      0.78      0.73        93\n",
      "\n",
      "[64  0  0 10  0  0 10  0  9]\n",
      "MNB Accuracy:  0.7849462365591398\n",
      "MNB F1:  0.5025740025740025\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        64\n",
      "          1       1.00      0.10      0.18        10\n",
      "          2       1.00      0.63      0.77        19\n",
      "\n",
      "avg / total       0.86      0.83      0.79        93\n",
      "\n",
      "[64  0  0  9  1  0  7  0 12]\n",
      "svc Accuracy:  0.8279569892473119\n",
      "svc F1:  0.6149668730313892\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        64\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.16      0.27        19\n",
      "\n",
      "avg / total       0.69      0.72      0.63        93\n",
      "\n",
      "[64  0  0 10  0  0 16  0  3]\n",
      "LR Accuracy:  0.7204301075268817\n",
      "LR F1:  0.367965367965368\n",
      "For name:  e_davis\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0002-3529-098X': 17, '0000-0001-5413-5398': 2, '0000-0002-4731-1602': 1, '0000-0002-4925-1447': 1})\n",
      "['0000-0002-3529-098X']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  z_yu\n",
      "total sample size before apply threshold:  135\n",
      "Counter({'0000-0002-2979-9608': 62, '0000-0002-6165-8522': 24, '0000-0003-4420-5836': 12, '0000-0002-9152-6491': 11, '0000-0002-1401-2294': 9, '0000-0002-5797-5373': 7, '0000-0001-5828-2635': 4, '0000-0002-8762-999X': 2, '0000-0001-5913-9646': 2, '0000-0002-2311-4030': 1, '0000-0001-6348-5293': 1})\n",
      "['0000-0002-6165-8522', '0000-0002-2979-9608', '0000-0002-9152-6491', '0000-0003-4420-5836']\n",
      "Total sample size after apply threshold:  109\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 69)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 14)\n",
      "2\n",
      "(109, 83)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.54      0.65        24\n",
      "          1       0.66      0.98      0.79        62\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.08      0.15        12\n",
      "\n",
      "avg / total       0.67      0.69      0.61       109\n",
      "\n",
      "[13 11  0  0  1 61  0  0  0 11  0  0  2  9  0  1]\n",
      "MNB Accuracy:  0.6880733944954128\n",
      "MNB F1:  0.39901348651348645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.75      0.82        24\n",
      "          1       0.70      0.98      0.82        62\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.17      0.29        12\n",
      "\n",
      "avg / total       0.71      0.74      0.68       109\n",
      "\n",
      "[18  6  0  0  1 61  0  0  0 11  0  0  1  9  0  2]\n",
      "svc Accuracy:  0.7431192660550459\n",
      "svc F1:  0.4806720125512072\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.54      0.68        24\n",
      "          1       0.67      1.00      0.80        62\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.17      0.29        12\n",
      "\n",
      "avg / total       0.69      0.71      0.64       109\n",
      "\n",
      "[13 11  0  0  0 62  0  0  0 11  0  0  1  9  0  2]\n",
      "LR Accuracy:  0.7064220183486238\n",
      "LR F1:  0.4424812030075188\n",
      "For name:  c_pan\n",
      "total sample size before apply threshold:  161\n",
      "Counter({'0000-0002-2652-5134': 66, '0000-0002-6654-9309': 33, '0000-0001-8700-583X': 23, '0000-0001-6327-9692': 15, '0000-0003-0108-3138': 11, '0000-0002-1031-7488': 7, '0000-0002-0089-7482': 6})\n",
      "['0000-0002-6654-9309', '0000-0001-8700-583X', '0000-0003-0108-3138', '0000-0002-2652-5134', '0000-0001-6327-9692']\n",
      "Total sample size after apply threshold:  148\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(148, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(148, 26)\n",
      "2\n",
      "(148, 82)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.52      0.51        33\n",
      "          1       0.50      0.35      0.41        23\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.79      1.00      0.88        66\n",
      "          4       0.64      0.60      0.62        15\n",
      "\n",
      "avg / total       0.60      0.68      0.63       148\n",
      "\n",
      "[17  5  0  9  2  8  8  0  4  3  7  0  0  4  0  0  0  0 66  0  2  3  0  1\n",
      "  9]\n",
      "MNB Accuracy:  0.6756756756756757\n",
      "MNB F1:  0.4836817503991976\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.73      0.63        33\n",
      "          1       0.52      0.48      0.50        23\n",
      "          2       0.75      0.55      0.63        11\n",
      "          3       1.00      0.97      0.98        66\n",
      "          4       0.92      0.73      0.81        15\n",
      "\n",
      "avg / total       0.80      0.78      0.79       148\n",
      "\n",
      "[24  6  2  0  1 12 11  0  0  0  4  1  6  0  0  2  0  0 64  0  1  3  0  0\n",
      " 11]\n",
      "svc Accuracy:  0.7837837837837838\n",
      "svc F1:  0.7125176188334084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.61      0.52        33\n",
      "          1       0.45      0.39      0.42        23\n",
      "          2       0.50      0.09      0.15        11\n",
      "          3       0.90      0.97      0.93        66\n",
      "          4       0.73      0.53      0.62        15\n",
      "\n",
      "avg / total       0.68      0.69      0.67       148\n",
      "\n",
      "[20  7  1  4  1 11  9  0  1  2  8  1  1  1  0  2  0  0 64  0  3  3  0  1\n",
      "  8]\n",
      "LR Accuracy:  0.6891891891891891\n",
      "LR F1:  0.528324501843429\n",
      "For name:  x_cao\n",
      "total sample size before apply threshold:  74\n",
      "Counter({'0000-0002-3004-7518': 25, '0000-0001-7222-5450': 14, '0000-0002-3476-9833': 12, '0000-0002-4782-853X': 11, '0000-0001-7571-6482': 10, '0000-0002-6771-0571': 1, '0000-0001-8124-7491': 1})\n",
      "['0000-0001-7571-6482', '0000-0002-3004-7518', '0000-0001-7222-5450', '0000-0002-4782-853X', '0000-0002-3476-9833']\n",
      "Total sample size after apply threshold:  72\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 8)\n",
      "2\n",
      "(72, 43)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.50      0.62        10\n",
      "          1       0.50      0.92      0.65        25\n",
      "          2       0.67      0.14      0.24        14\n",
      "          3       0.50      0.27      0.35        11\n",
      "          4       0.73      0.67      0.70        12\n",
      "\n",
      "avg / total       0.62      0.57      0.53        72\n",
      "\n",
      "[ 5  4  0  1  0  0 23  1  1  0  0 10  2  0  2  1  6  0  3  1  0  3  0  1\n",
      "  8]\n",
      "MNB Accuracy:  0.5694444444444444\n",
      "MNB F1:  0.5113549583948706\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.60      0.71        10\n",
      "          1       0.69      0.88      0.77        25\n",
      "          2       0.67      0.57      0.62        14\n",
      "          3       0.44      0.36      0.40        11\n",
      "          4       0.83      0.83      0.83        12\n",
      "\n",
      "avg / total       0.69      0.69      0.69        72\n",
      "\n",
      "[ 6  1  1  2  0  0 22  1  2  0  0  5  8  0  1  1  4  1  4  1  0  0  1  1\n",
      " 10]\n",
      "svc Accuracy:  0.6944444444444444\n",
      "svc F1:  0.6653060252441058\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.50      0.62        10\n",
      "          1       0.55      0.88      0.68        25\n",
      "          2       0.67      0.29      0.40        14\n",
      "          3       0.57      0.36      0.44        11\n",
      "          4       0.77      0.83      0.80        12\n",
      "\n",
      "avg / total       0.65      0.62      0.60        72\n",
      "\n",
      "[ 5  4  0  1  0  0 22  2  1  0  0  8  4  0  2  1  5  0  4  1  0  1  0  1\n",
      " 10]\n",
      "LR Accuracy:  0.625\n",
      "LR F1:  0.5892735042735042\n",
      "For name:  j_yoo\n",
      "total sample size before apply threshold:  112\n",
      "Counter({'0000-0001-8378-1583': 41, '0000-0001-7120-8464': 19, '0000-0002-3924-6919': 15, '0000-0002-3150-1727': 9, '0000-0002-5488-7925': 7, '0000-0001-7119-5421': 6, '0000-0003-3881-1995': 5, '0000-0003-2611-3399': 5, '0000-0002-0259-6237': 2, '0000-0003-0639-3944': 1, '0000-0002-2330-4053': 1, '0000-0002-9508-0757': 1})\n",
      "['0000-0001-7120-8464', '0000-0002-3924-6919', '0000-0001-8378-1583']\n",
      "Total sample size after apply threshold:  75\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(75, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(75, 11)\n",
      "2\n",
      "(75, 48)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.53      0.62        19\n",
      "          1       0.71      0.33      0.45        15\n",
      "          2       0.73      0.98      0.83        41\n",
      "\n",
      "avg / total       0.74      0.73      0.70        75\n",
      "\n",
      "[10  2  7  2  5  8  1  0 40]\n",
      "MNB Accuracy:  0.7333333333333333\n",
      "MNB F1:  0.6376262626262627\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.47      0.58        19\n",
      "          1       0.58      0.47      0.52        15\n",
      "          2       0.73      0.90      0.80        41\n",
      "\n",
      "avg / total       0.70      0.71      0.69        75\n",
      "\n",
      "[ 9  4  6  0  7  8  3  1 37]\n",
      "svc Accuracy:  0.7066666666666667\n",
      "svc F1:  0.6345038352985992\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.47      0.62        19\n",
      "          1       0.71      0.33      0.45        15\n",
      "          2       0.69      0.98      0.81        41\n",
      "\n",
      "avg / total       0.75      0.72      0.69        75\n",
      "\n",
      "[ 9  2  8  0  5 10  1  0 40]\n",
      "LR Accuracy:  0.72\n",
      "LR F1:  0.6277719725995587\n",
      "For name:  l_wong\n",
      "total sample size before apply threshold:  131\n",
      "Counter({'0000-0003-1241-5441': 66, '0000-0002-4005-7330': 38, '0000-0002-7437-123X': 16, '0000-0003-0569-3398': 4, '0000-0001-8449-4973': 4, '0000-0001-8653-2734': 3})\n",
      "['0000-0003-1241-5441', '0000-0002-7437-123X', '0000-0002-4005-7330']\n",
      "Total sample size after apply threshold:  120\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(120, 53)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(120, 19)\n",
      "2\n",
      "(120, 72)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.89      0.83        66\n",
      "          1       0.75      0.19      0.30        16\n",
      "          2       0.67      0.68      0.68        38\n",
      "\n",
      "avg / total       0.73      0.73      0.71       120\n",
      "\n",
      "[59  0  7  7  3  6 11  1 26]\n",
      "MNB Accuracy:  0.7333333333333333\n",
      "MNB F1:  0.6001665001665002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.92      0.87        66\n",
      "          1       0.78      0.44      0.56        16\n",
      "          2       0.81      0.76      0.78        38\n",
      "\n",
      "avg / total       0.81      0.81      0.80       120\n",
      "\n",
      "[61  1  4  6  7  3  8  1 29]\n",
      "svc Accuracy:  0.8083333333333333\n",
      "svc F1:  0.7363440035780462\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.95      0.86        66\n",
      "          1       1.00      0.19      0.32        16\n",
      "          2       0.81      0.76      0.78        38\n",
      "\n",
      "avg / total       0.82      0.79      0.76       120\n",
      "\n",
      "[63  0  3  9  3  4  9  0 29]\n",
      "LR Accuracy:  0.7916666666666666\n",
      "LR F1:  0.6522387048702839\n",
      "For name:  h_chen\n",
      "total sample size before apply threshold:  986\n",
      "Counter({'0000-0001-5108-8338': 147, '0000-0002-5799-6705': 93, '0000-0003-0708-6073': 73, '0000-0001-6758-1995': 49, '0000-0001-5051-9896': 40, '0000-0003-0676-4610': 40, '0000-0002-7748-4440': 39, '0000-0001-6883-3752': 36, '0000-0003-3191-0093': 28, '0000-0002-0753-6161': 25, '0000-0002-5958-9361': 24, '0000-0001-9751-5729': 22, '0000-0002-3319-5743': 21, '0000-0001-5972-2778': 20, '0000-0001-9477-5541': 20, '0000-0002-7823-3272': 19, '0000-0003-1158-5510': 19, '0000-0003-4876-634X': 18, '0000-0002-7480-9940': 16, '0000-0003-2014-7571': 16, '0000-0002-9510-4923': 15, '0000-0002-4074-5838': 15, '0000-0003-4053-7147': 14, '0000-0002-9835-5138': 12, '0000-0001-6208-1481': 12, '0000-0003-1663-1598': 10, '0000-0001-7897-9851': 9, '0000-0003-0676-3079': 9, '0000-0002-4292-0441': 9, '0000-0001-6315-9850': 8, '0000-0002-3800-5013': 8, '0000-0002-3722-5399': 8, '0000-0002-5037-4559': 7, '0000-0002-0595-3420': 7, '0000-0002-8795-1911': 6, '0000-0003-4060-9489': 6, '0000-0001-7900-3391': 6, '0000-0002-2883-4627': 5, '0000-0002-0310-0088': 5, '0000-0002-7516-9092': 4, '0000-0003-3111-9824': 4, '0000-0003-1997-5476': 3, '0000-0002-5498-5621': 3, '0000-0002-9330-5473': 3, '0000-0002-5905-8050': 2, '0000-0002-1724-8649': 2, '0000-0003-1211-3259': 2, '0000-0001-9998-1205': 2, '0000-0001-9644-8202': 2, '0000-0002-5662-5945': 2, '0000-0001-7775-8571': 1, '0000-0001-6260-1117': 1, '0000-0002-5266-9975': 1, '0000-0002-6181-5292': 1, '0000-0003-2117-7385': 1, '0000-0002-1124-0312': 1, '0000-0002-4796-8452': 1, '0000-0001-8234-1535': 1, '0000-0001-6171-1162': 1, '0000-0002-2456-5271': 1, '0000-0002-4242-216X': 1, '0000-0002-8400-3780': 1, '0000-0002-0978-1806': 1, '0000-0002-9840-4876': 1, '0000-0001-6524-1292': 1, '0000-0002-5378-2697': 1, '0000-0003-1613-468X': 1, '0000-0002-0457-9895': 1, '0000-0002-2121-1822': 1, '0000-0002-4425-3128': 1, '0000-0002-7431-6046': 1})\n",
      "['0000-0002-7480-9940', '0000-0001-5972-2778', '0000-0003-4876-634X', '0000-0002-9835-5138', '0000-0002-7748-4440', '0000-0001-6883-3752', '0000-0001-9477-5541', '0000-0002-0753-6161', '0000-0003-1663-1598', '0000-0002-7823-3272', '0000-0003-3191-0093', '0000-0001-5051-9896', '0000-0003-0708-6073', '0000-0003-0676-4610', '0000-0002-9510-4923', '0000-0002-5799-6705', '0000-0003-4053-7147', '0000-0001-6208-1481', '0000-0001-5108-8338', '0000-0003-2014-7571', '0000-0002-3319-5743', '0000-0002-4074-5838', '0000-0002-5958-9361', '0000-0001-6758-1995', '0000-0001-9751-5729', '0000-0003-1158-5510']\n",
      "Total sample size after apply threshold:  843\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(843, 392)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(843, 25)\n",
      "2\n",
      "(843, 417)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.00      0.00      0.00        20\n",
      "          2       0.00      0.00      0.00        18\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.82      0.23      0.36        39\n",
      "          5       0.00      0.00      0.00        36\n",
      "          6       1.00      0.25      0.40        20\n",
      "          7       0.00      0.00      0.00        25\n",
      "          8       0.00      0.00      0.00        10\n",
      "          9       1.00      0.05      0.10        19\n",
      "         10       0.00      0.00      0.00        28\n",
      "         11       0.60      0.07      0.13        40\n",
      "         12       0.63      0.70      0.66        73\n",
      "         13       0.60      0.07      0.13        40\n",
      "         14       0.00      0.00      0.00        15\n",
      "         15       0.31      0.26      0.28        93\n",
      "         16       0.00      0.00      0.00        14\n",
      "         17       0.00      0.00      0.00        12\n",
      "         18       0.22      0.97      0.36       147\n",
      "         19       0.00      0.00      0.00        16\n",
      "         20       0.00      0.00      0.00        21\n",
      "         21       0.00      0.00      0.00        15\n",
      "         22       0.00      0.00      0.00        24\n",
      "         23       1.00      0.39      0.56        49\n",
      "         24       0.00      0.00      0.00        22\n",
      "         25       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.33      0.30      0.23       843\n",
      "\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0\n",
      "  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  20   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  17   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   1   0   0   2   0   0   9   0   0   0   0   0   0   0   0   0   0   0\n",
      "   9   0   0   0   0   0   0   1   3   0   0   5   0   0  21   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   3   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   5   0   0   0   0   0   0   0   0   2   0   0  13   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   4\n",
      "   0   0  20   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   4   0   0\n",
      "  13   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   1   0   0  26   0   0   0   0   0   0   0   0   0\n",
      "   0   0   2   0   0   0   0   0   0   3   0   0   0   4   0   0  31   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  51   0   0   1   0   0  21   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   2   3   0   0   0   0  35   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   1   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   7   0   0  24   0   0  62   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "   0   0  13   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   2   0   0  10   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   4   0   0\n",
      " 142   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   2   0   0  13   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   1   0   2   0   0  18   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   4   0   0  11   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   4   1   0   1   0   0  18   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   3   0\n",
      "   0   2   0   0  24   0   0   0   0  19   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   4   0   0   4   0   0  14   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2\n",
      "   0   0  17   0   0   0   0   0   0   0]\n",
      "MNB Accuracy:  0.30486358244365364\n",
      "MNB F1:  0.11505784441572496\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.25      0.33        16\n",
      "          1       1.00      0.60      0.75        20\n",
      "          2       0.67      0.11      0.19        18\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.74      0.59      0.66        39\n",
      "          5       0.25      0.25      0.25        36\n",
      "          6       0.56      0.50      0.53        20\n",
      "          7       0.40      0.16      0.23        25\n",
      "          8       0.89      0.80      0.84        10\n",
      "          9       0.76      0.84      0.80        19\n",
      "         10       0.52      0.50      0.51        28\n",
      "         11       0.46      0.33      0.38        40\n",
      "         12       0.92      0.78      0.84        73\n",
      "         13       0.70      0.35      0.47        40\n",
      "         14       0.91      0.67      0.77        15\n",
      "         15       0.26      0.74      0.39        93\n",
      "         16       0.67      0.43      0.52        14\n",
      "         17       0.60      0.25      0.35        12\n",
      "         18       0.65      0.79      0.71       147\n",
      "         19       0.64      0.44      0.52        16\n",
      "         20       0.82      0.67      0.74        21\n",
      "         21       1.00      0.33      0.50        15\n",
      "         22       0.87      0.54      0.67        24\n",
      "         23       0.94      0.59      0.72        49\n",
      "         24       0.00      0.00      0.00        22\n",
      "         25       0.86      0.32      0.46        19\n",
      "\n",
      "avg / total       0.62      0.55      0.55       843\n",
      "\n",
      "[  4   0   0   0   0   0   1   0   0   0   0   1   0   0   0   6   1   0\n",
      "   0   0   2   0   1   0   0   0   0  12   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   2   0   0   2   0   1   0   0   3   0   0   0   0   7   0   0   2   0\n",
      "   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "   0   0   0   8   0   0   3   0   0   0   0   0   0   0   0   0   0   0\n",
      "  23   0   0   0   0   0   0   1   0   1   0  10   0   0   1   0   0   0\n",
      "   0   0   3   0   0   0   1   0   0   9   0   0   0   0   0   1   0   0\n",
      "   0  21   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "  10   0   0   0   2   0   0   0   0   2   0   1   0   2   0   0   0   0\n",
      "   0   0   0   0   0   0   0   2   0   4   0   0   2   3   0   0   0  10\n",
      "   0   0   3   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "   8   0   0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  16   0   2   0   0   0   1   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0\n",
      "  14   0   0   0   0  11   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "   0   0   2   3   1   2   1   1   0  13   0   0   0   9   0   0   7   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0\n",
      "  57   0   0  12   0   1   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "   1   1   1   0   0   0   1   0   0  14   1  12   0   0   9   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "  10   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4\n",
      "   0   1   0   0   0   3   0   0   0  69   0   0  13   0   0   0   0   0\n",
      "   1   0   1   0   0   0   0   0   1   0   0   0   1   0   0   0   0   3\n",
      "   6   0   0   0   1   0   1   0   0   0   0   0   0   0   0   3   1   0\n",
      "   0   0   1   0   1   0   0   1   0   3   2   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   3   1   0   0   0   2   1   0   0   0  23   0   0\n",
      " 116   0   0   0   0   0   1   0   0   0   0   0   0   1   2   0   0   0\n",
      "   0   0   1   1   0   2   0   0   2   7   0   0   0   0   0   0   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   1   0   3   1   0   0   0\n",
      "  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   7   0   0   3   0   0   5   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   3   0   3   1   0   4   0   0   0\n",
      "  13   0   0   0   0   0   0   0   0   1   0   2   0   1   0   1   3   0\n",
      "   0   9   0   0   3   0   0   0   0  29   0   0   0   0   0   0   3   0\n",
      "   0   0   0   1   0   1   0   0   0  15   0   0   1   0   0   0   0   1\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7\n",
      "   0   0   4   2   0   0   0   0   0   6]\n",
      "svc Accuracy:  0.5504151838671412\n",
      "svc F1:  0.5051299010519891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.06      0.11        16\n",
      "          1       1.00      0.50      0.67        20\n",
      "          2       0.00      0.00      0.00        18\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.67      0.41      0.51        39\n",
      "          5       0.18      0.08      0.11        36\n",
      "          6       0.55      0.30      0.39        20\n",
      "          7       0.60      0.12      0.20        25\n",
      "          8       1.00      0.40      0.57        10\n",
      "          9       0.89      0.84      0.86        19\n",
      "         10       0.47      0.29      0.36        28\n",
      "         11       0.33      0.12      0.18        40\n",
      "         12       0.59      0.74      0.65        73\n",
      "         13       0.79      0.28      0.41        40\n",
      "         14       0.86      0.40      0.55        15\n",
      "         15       0.24      0.65      0.35        93\n",
      "         16       0.50      0.21      0.30        14\n",
      "         17       0.00      0.00      0.00        12\n",
      "         18       0.45      0.85      0.59       147\n",
      "         19       0.70      0.44      0.54        16\n",
      "         20       0.78      0.67      0.72        21\n",
      "         21       1.00      0.13      0.24        15\n",
      "         22       0.89      0.33      0.48        24\n",
      "         23       0.93      0.51      0.66        49\n",
      "         24       0.00      0.00      0.00        22\n",
      "         25       1.00      0.05      0.10        19\n",
      "\n",
      "avg / total       0.53      0.46      0.43       843\n",
      "\n",
      "[  1   0   0   0   0   0   0   0   0   0   0   1   1   0   0   6   1   0\n",
      "   4   0   2   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   4   0   0   6   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   2   0   0   0   0   2   0   2   0   0   4   0   0   8   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "   0   0   0   7   0   0   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "  16   0   0   0   0   0   0   1   3   0   0  12   0   0   4   0   0   0\n",
      "   0   0   3   0   0   0   0   0   0   3   0   0   0   0   0   2   2   0\n",
      "   0  18   0   0  11   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "   6   0   0   0   0   1   0   0   0   6   0   1   4   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0   3   0   0   2   2   0   0   0  10\n",
      "   0   0   6   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "   4   0   0   0   1   0   0   4   0   0   1   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  16   0   1   0   0   0   2   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   3   1   0   0   0\n",
      "   8   0   1   0   0  10   0   0   5   0   0   0   0   0   0   0   0   0\n",
      "   0   0   3   2   0   2   0   0   0   5   1   0   0  14   0   0  13   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "  54   0   0  10   0   1   7   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   0   1   0   1  11   1  10   0   0  15   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   2   0\n",
      "   6   5   0   0   1   0   0   0   0   0   0   0   0   0   0   0   2   2\n",
      "   0   0   0   0   0   0   9   0   0  60   0   0  20   0   0   0   0   0\n",
      "   0   0   1   0   0   0   0   0   1   0   0   0   1   0   2   0   0   5\n",
      "   3   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "   0   0   1   0   1   0   0   4   0   0   5   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0  17   0   0\n",
      " 125   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "   0   1   0   0   0   3   0   0   3   7   0   0   1   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   1   1   0   3   1   0   1   0\n",
      "  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   8   0   0   5   0   0   2   0   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   0   0   0   0   2   0   3   1   0   7   0   2   0\n",
      "   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0\n",
      "   0   7   0   0  12   0   0   0   0  25   0   0   0   0   0   0   3   0\n",
      "   0   0   0   1   0   0   2   0   0  12   0   0   3   0   0   0   0   1\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   8\n",
      "   0   0   6   2   0   0   0   0   0   1]\n",
      "LR Accuracy:  0.46026097271648875\n",
      "LR F1:  0.36688421201408034\n",
      "For name:  c_huang\n",
      "total sample size before apply threshold:  425\n",
      "Counter({'0000-0002-6557-211X': 117, '0000-0002-5234-4986': 48, '0000-0001-5357-0451': 36, '0000-0001-9521-5650': 33, '0000-0002-5824-3318': 17, '0000-0002-1486-741X': 15, '0000-0002-1956-6229': 14, '0000-0003-1019-784X': 14, '0000-0001-9993-8004': 13, '0000-0001-8736-9545': 10, '0000-0002-0266-3233': 9, '0000-0002-4390-6502': 9, '0000-0002-1941-1200': 8, '0000-0001-6052-0663': 8, '0000-0002-4704-548X': 8, '0000-0002-8062-8708': 8, '0000-0001-6946-2105': 7, '0000-0002-9174-7542': 7, '0000-0002-9769-8075': 5, '0000-0003-4187-2967': 4, '0000-0002-9020-305X': 4, '0000-0003-2981-4537': 4, '0000-0003-3905-8915': 3, '0000-0003-3331-181X': 2, '0000-0001-5958-5849': 2, '0000-0003-3445-4353': 2, '0000-0001-7266-3610': 2, '0000-0003-4378-4776': 2, '0000-0002-2921-4294': 2, '0000-0001-7865-1020': 1, '0000-0001-9824-5716': 1, '0000-0001-7392-6363': 1, '0000-0002-1366-5170': 1, '0000-0002-0425-8311': 1, '0000-0002-4803-1477': 1, '0000-0002-0972-6444': 1, '0000-0001-5179-0872': 1, '0000-0003-1446-6787': 1, '0000-0003-3527-2789': 1, '0000-0002-6987-0536': 1, '0000-0003-0055-9798': 1})\n",
      "['0000-0001-5357-0451', '0000-0001-9993-8004', '0000-0001-8736-9545', '0000-0002-1486-741X', '0000-0002-6557-211X', '0000-0002-5234-4986', '0000-0002-5824-3318', '0000-0002-1956-6229', '0000-0003-1019-784X', '0000-0001-9521-5650']\n",
      "Total sample size after apply threshold:  317\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(317, 191)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(317, 22)\n",
      "2\n",
      "(317, 213)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.36      0.11      0.17        36\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       1.00      0.20      0.33        10\n",
      "          3       0.00      0.00      0.00        15\n",
      "          4       0.39      0.94      0.55       117\n",
      "          5       0.54      0.15      0.23        48\n",
      "          6       1.00      0.24      0.38        17\n",
      "          7       0.00      0.00      0.00        14\n",
      "          8       0.00      0.00      0.00        14\n",
      "          9       1.00      0.12      0.22        33\n",
      "\n",
      "avg / total       0.46      0.41      0.31       317\n",
      "\n",
      "[  4   0   0   0  30   2   0   0   0   0   1   0   0   0  11   1   0   0\n",
      "   0   0   0   0   2   0   8   0   0   0   0   0   0   0   0   0  14   1\n",
      "   0   0   0   0   5   0   0   0 110   2   0   0   0   0   0   0   0   0\n",
      "  41   7   0   0   0   0   0   0   0   0  13   0   4   0   0   0   1   0\n",
      "   0   0  13   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0\n",
      "   0   0   0   0  29   0   0   0   0   4]\n",
      "MNB Accuracy:  0.41324921135646686\n",
      "MNB F1:  0.18802228931806889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.33      0.40        36\n",
      "          1       0.75      0.23      0.35        13\n",
      "          2       1.00      1.00      1.00        10\n",
      "          3       0.67      0.13      0.22        15\n",
      "          4       0.50      0.90      0.64       117\n",
      "          5       0.64      0.38      0.47        48\n",
      "          6       1.00      0.94      0.97        17\n",
      "          7       0.20      0.07      0.11        14\n",
      "          8       0.75      0.21      0.33        14\n",
      "          9       0.92      0.33      0.49        33\n",
      "\n",
      "avg / total       0.62      0.57      0.53       317\n",
      "\n",
      "[ 12   0   0   0  22   2   0   0   0   0   1   3   0   0   8   1   0   0\n",
      "   0   0   0   0  10   0   0   0   0   0   0   0   0   1   0   2  11   1\n",
      "   0   0   0   0   7   0   0   1 105   2   0   1   0   1   4   0   0   0\n",
      "  26  18   0   0   0   0   0   0   0   0   1   0  16   0   0   0   0   0\n",
      "   0   0  11   1   0   1   1   0   0   0   0   0   9   1   0   1   3   0\n",
      "   0   0   0   0  18   2   0   2   0  11]\n",
      "svc Accuracy:  0.5709779179810726\n",
      "svc F1:  0.4986273861472079\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.28      0.38        36\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       1.00      1.00      1.00        10\n",
      "          3       0.00      0.00      0.00        15\n",
      "          4       0.44      0.93      0.60       117\n",
      "          5       0.46      0.23      0.31        48\n",
      "          6       1.00      0.71      0.83        17\n",
      "          7       0.00      0.00      0.00        14\n",
      "          8       1.00      0.07      0.13        14\n",
      "          9       1.00      0.18      0.31        33\n",
      "\n",
      "avg / total       0.53      0.50      0.42       317\n",
      "\n",
      "[ 10   0   0   0  25   1   0   0   0   0   1   0   0   0  11   1   0   0\n",
      "   0   0   0   0  10   0   0   0   0   0   0   0   0   1   0   0  10   4\n",
      "   0   0   0   0   4   0   0   0 109   4   0   0   0   0   0   0   0   0\n",
      "  37  11   0   0   0   0   0   0   0   0   5   0  12   0   0   0   2   0\n",
      "   0   0  11   1   0   0   0   0   0   0   0   0  11   2   0   0   1   0\n",
      "   0   0   0   0  27   0   0   0   0   6]\n",
      "LR Accuracy:  0.501577287066246\n",
      "LR F1:  0.35520768582311135\n",
      "For name:  s_chong\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0001-8062-7281': 24, '0000-0002-3095-875X': 12, '0000-0002-8854-9529': 2, '0000-0003-3054-9275': 1, '0000-0002-3627-4025': 1})\n",
      "['0000-0001-8062-7281', '0000-0002-3095-875X']\n",
      "Total sample size after apply threshold:  36\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 14)\n",
      "2\n",
      "(36, 42)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        24\n",
      "          1       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[23  1  0 12]\n",
      "MNB Accuracy:  0.9722222222222222\n",
      "MNB F1:  0.9693617021276596\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        24\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[24  0  1 11]\n",
      "svc Accuracy:  0.9722222222222222\n",
      "svc F1:  0.9680567879325643\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        24\n",
      "          1       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.93      0.92      0.91        36\n",
      "\n",
      "[24  0  3  9]\n",
      "LR Accuracy:  0.9166666666666666\n",
      "LR F1:  0.8991596638655461\n",
      "For name:  z_wu\n",
      "total sample size before apply threshold:  221\n",
      "Counter({'0000-0003-0807-7195': 52, '0000-0002-9596-9134': 35, '0000-0002-2982-2177': 31, '0000-0002-4468-3240': 25, '0000-0002-0708-6770': 14, '0000-0002-4004-9728': 11, '0000-0002-3719-406X': 9, '0000-0002-6424-6777': 8, '0000-0003-1660-0724': 6, '0000-0002-1824-9563': 5, '0000-0002-2463-242X': 5, '0000-0003-2009-991X': 5, '0000-0002-9383-1270': 4, '0000-0002-4739-1139': 4, '0000-0003-4460-9785': 3, '0000-0002-9774-7770': 2, '0000-0002-7776-563X': 1, '0000-0002-8687-0466': 1})\n",
      "['0000-0002-4004-9728', '0000-0002-0708-6770', '0000-0002-9596-9134', '0000-0003-0807-7195', '0000-0002-4468-3240', '0000-0002-2982-2177']\n",
      "Total sample size after apply threshold:  168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(168, 82)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(168, 20)\n",
      "2\n",
      "(168, 102)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.07      0.13        14\n",
      "          2       0.52      0.43      0.47        35\n",
      "          3       0.61      0.85      0.71        52\n",
      "          4       0.73      0.76      0.75        25\n",
      "          5       0.72      0.94      0.82        31\n",
      "\n",
      "avg / total       0.62      0.64      0.59       168\n",
      "\n",
      "[ 0  0  1  6  3  1  0  1  4  5  1  3  0  0 15 15  1  4  0  0  5 44  1  2\n",
      "  0  0  4  1 19  1  0  0  0  1  1 29]\n",
      "MNB Accuracy:  0.6428571428571429\n",
      "MNB F1:  0.4789600333924271\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       0.63      0.83      0.72        35\n",
      "          3       0.75      0.85      0.79        52\n",
      "          4       0.91      0.84      0.87        25\n",
      "          5       1.00      0.87      0.93        31\n",
      "\n",
      "avg / total       0.83      0.80      0.80       168\n",
      "\n",
      "[ 7  0  0  3  1  0  0  6  3  5  0  0  0  0 29  5  1  0  0  0  8 44  0  0\n",
      "  0  0  4  0 21  0  0  0  2  2  0 27]\n",
      "svc Accuracy:  0.7976190476190477\n",
      "svc F1:  0.7821090726742068\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       0.53      0.71      0.61        35\n",
      "          3       0.68      0.83      0.75        52\n",
      "          4       0.78      0.72      0.75        25\n",
      "          5       1.00      0.87      0.93        31\n",
      "\n",
      "avg / total       0.77      0.72      0.71       168\n",
      "\n",
      "[ 2  0  2  5  2  0  0  6  3  5  0  0  0  0 25  9  1  0  0  0  8 43  1  0\n",
      "  0  0  7  0 18  0  0  0  2  1  1 27]\n",
      "LR Accuracy:  0.7202380952380952\n",
      "LR F1:  0.6577181624947376\n",
      "For name:  m_swamy\n",
      "total sample size before apply threshold:  134\n",
      "Counter({'0000-0002-3108-3633': 96, '0000-0003-3977-3425': 25, '0000-0002-8084-5534': 9, '0000-0002-7834-7480': 4})\n",
      "['0000-0002-3108-3633', '0000-0003-3977-3425']\n",
      "Total sample size after apply threshold:  121\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(121, 46)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(121, 28)\n",
      "2\n",
      "(121, 74)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        96\n",
      "          1       1.00      0.52      0.68        25\n",
      "\n",
      "avg / total       0.91      0.90      0.89       121\n",
      "\n",
      "[96  0 12 13]\n",
      "MNB Accuracy:  0.9008264462809917\n",
      "MNB F1:  0.8126934984520124\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94        96\n",
      "          1       0.88      0.56      0.68        25\n",
      "\n",
      "avg / total       0.89      0.89      0.88       121\n",
      "\n",
      "[94  2 11 14]\n",
      "svc Accuracy:  0.8925619834710744\n",
      "svc F1:  0.8091251061764348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        96\n",
      "          1       1.00      0.36      0.53        25\n",
      "\n",
      "avg / total       0.89      0.87      0.84       121\n",
      "\n",
      "[96  0 16  9]\n",
      "LR Accuracy:  0.8677685950413223\n",
      "LR F1:  0.7262443438914027\n",
      "For name:  k_nomura\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0003-3661-6328': 32, '0000-0002-6425-4574': 3, '0000-0003-0625-1778': 1, '0000-0002-5912-074X': 1, '0000-0001-7891-9795': 1})\n",
      "['0000-0003-3661-6328']\n",
      "Total sample size after apply threshold:  32\n",
      "For name:  m_wu\n",
      "total sample size before apply threshold:  658\n",
      "Counter({'0000-0002-1940-6428': 219, '0000-0002-7074-8087': 194, '0000-0002-1674-443X': 56, '0000-0003-3327-828X': 42, '0000-0001-6587-7055': 33, '0000-0002-8811-9203': 29, '0000-0002-7509-1643': 22, '0000-0003-2045-9372': 13, '0000-0002-9161-7940': 11, '0000-0003-3712-1554': 10, '0000-0001-7672-9357': 6, '0000-0003-2113-0245': 5, '0000-0001-6847-7065': 5, '0000-0003-0977-3600': 4, '0000-0003-1372-4764': 2, '0000-0003-1734-7994': 2, '0000-0002-3269-1681': 2, '0000-0002-0183-0490': 1, '0000-0001-6646-050X': 1, '0000-0002-6646-951X': 1})\n",
      "['0000-0002-8811-9203', '0000-0001-6587-7055', '0000-0002-9161-7940', '0000-0003-3712-1554', '0000-0003-3327-828X', '0000-0003-2045-9372', '0000-0002-7509-1643', '0000-0002-1674-443X', '0000-0002-1940-6428', '0000-0002-7074-8087']\n",
      "Total sample size after apply threshold:  629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(629, 243)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(629, 28)\n",
      "2\n",
      "(629, 271)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        29\n",
      "          1       1.00      0.36      0.53        33\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.86      0.14      0.24        42\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       0.00      0.00      0.00        22\n",
      "          7       0.88      0.12      0.22        56\n",
      "          8       0.58      0.93      0.71       219\n",
      "          9       0.64      0.82      0.72       194\n",
      "\n",
      "avg / total       0.58      0.62      0.53       629\n",
      "\n",
      "[  0   0   0   0   0   0   0   0  19  10   0  12   0   0   0   0   0   0\n",
      "  10  11   0   0   0   0   1   0   0   0   8   2   0   0   0   0   0   0\n",
      "   0   0   6   4   0   0   0   0   6   0   0   0  23  13   0   0   0   0\n",
      "   0   0   0   0   7   6   0   0   0   0   0   0   0   0  14   8   0   0\n",
      "   0   0   0   0   0   7  29  20   0   0   0   0   0   0   0   0 203  16\n",
      "   0   0   0   0   0   0   0   1  34 159]\n",
      "MNB Accuracy:  0.615262321144674\n",
      "MNB F1:  0.2424604459417826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.38      0.54        29\n",
      "          1       0.96      0.79      0.87        33\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.33      0.10      0.15        10\n",
      "          4       0.77      0.57      0.66        42\n",
      "          5       1.00      0.77      0.87        13\n",
      "          6       0.00      0.00      0.00        22\n",
      "          7       0.83      0.52      0.64        56\n",
      "          8       0.61      0.96      0.74       219\n",
      "          9       0.95      0.79      0.86       194\n",
      "\n",
      "avg / total       0.75      0.74      0.72       629\n",
      "\n",
      "[ 11   0   0   0   0   0   0   1  16   1   0  26   0   0   0   0   1   0\n",
      "   5   1   0   0   0   1   1   0   0   0   9   0   0   0   0   1   0   0\n",
      "   0   1   8   0   0   0   0   0  24   0   0   0  16   2   0   0   0   0\n",
      "   0  10   0   0   3   0   0   1   0   0   0   0   0   2  17   2   0   0\n",
      "   0   0   0   0   2  29  24   1   1   0   1   1   4   0   1   0 210   1\n",
      "   0   0   0   0   2   0   0   2  37 153]\n",
      "svc Accuracy:  0.7376788553259142\n",
      "svc F1:  0.5328212969745508\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.03      0.07        29\n",
      "          1       0.95      0.58      0.72        33\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.91      0.24      0.38        42\n",
      "          5       1.00      0.38      0.56        13\n",
      "          6       0.00      0.00      0.00        22\n",
      "          7       0.86      0.21      0.34        56\n",
      "          8       0.58      0.94      0.72       219\n",
      "          9       0.70      0.81      0.75       194\n",
      "\n",
      "avg / total       0.67      0.65      0.59       629\n",
      "\n",
      "[  1   0   0   0   0   0   0   1  21   6   0  19   0   0   0   0   0   0\n",
      "   6   8   0   0   0   0   1   0   0   0   8   2   0   0   0   0   0   0\n",
      "   0   0   8   2   0   0   0   0  10   0   0   0  20  12   0   0   0   0\n",
      "   0   5   0   0   5   3   0   1   0   0   0   0   0   0  12   9   0   0\n",
      "   0   0   0   0   0  12  33  11   0   0   0   0   0   0   0   0 206  13\n",
      "   0   0   0   0   0   0   0   1  36 157]\n",
      "LR Accuracy:  0.6518282988871225\n",
      "LR F1:  0.3530186624482545\n",
      "For name:  e_lee\n",
      "total sample size before apply threshold:  300\n",
      "Counter({'0000-0003-0232-7704': 81, '0000-0003-0418-1454': 48, '0000-0001-7494-1776': 48, '0000-0003-1255-9808': 40, '0000-0001-7188-3857': 29, '0000-0002-6369-7429': 16, '0000-0001-9670-3242': 10, '0000-0001-8131-6872': 8, '0000-0001-5144-2552': 3, '0000-0003-4725-4959': 3, '0000-0001-6506-4150': 3, '0000-0003-2848-7298': 2, '0000-0001-9580-8974': 2, '0000-0002-3156-2036': 1, '0000-0002-4156-9637': 1, '0000-0002-4513-9888': 1, '0000-0001-5816-2449': 1, '0000-0002-0934-3187': 1, '0000-0002-2674-912X': 1, '0000-0001-7976-5724': 1})\n",
      "['0000-0001-9670-3242', '0000-0003-1255-9808', '0000-0003-0418-1454', '0000-0002-6369-7429', '0000-0001-7494-1776', '0000-0001-7188-3857', '0000-0003-0232-7704']\n",
      "Total sample size after apply threshold:  272\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(272, 126)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(272, 17)\n",
      "2\n",
      "(272, 143)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.89      0.40      0.55        40\n",
      "          2       0.56      0.46      0.51        48\n",
      "          3       0.86      0.38      0.52        16\n",
      "          4       0.72      0.85      0.78        48\n",
      "          5       0.78      0.24      0.37        29\n",
      "          6       0.51      0.90      0.65        81\n",
      "\n",
      "avg / total       0.64      0.61      0.57       272\n",
      "\n",
      "[ 0  0  2  0  0  0  8  0 16  3  0  7  0 14  0  1 22  0  1  1 23  0  0  3\n",
      "  6  1  1  5  0  0  0  0 41  0  7  0  0  7  1  2  7 12  0  1  2  0  5  0\n",
      " 73]\n",
      "MNB Accuracy:  0.6066176470588235\n",
      "MNB F1:  0.4833274783665616\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.92      0.55      0.69        40\n",
      "          2       0.47      0.75      0.58        48\n",
      "          3       0.92      0.75      0.83        16\n",
      "          4       0.93      0.83      0.88        48\n",
      "          5       0.93      0.45      0.60        29\n",
      "          6       0.73      0.89      0.80        81\n",
      "\n",
      "avg / total       0.79      0.73      0.73       272\n",
      "\n",
      "[ 4  0  4  0  0  0  2  0 22  9  0  3  0  6  0  1 36  0  0  1 10  0  0  4\n",
      " 12  0  0  0  0  0  2  0 40  0  6  0  0 13  1  0 13  2  0  1  8  0  0  0\n",
      " 72]\n",
      "svc Accuracy:  0.7316176470588235\n",
      "svc F1:  0.707914465038577\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.86      0.45      0.59        40\n",
      "          2       0.52      0.56      0.54        48\n",
      "          3       1.00      0.56      0.72        16\n",
      "          4       0.93      0.81      0.87        48\n",
      "          5       0.86      0.41      0.56        29\n",
      "          6       0.59      0.95      0.73        81\n",
      "\n",
      "avg / total       0.74      0.68      0.67       272\n",
      "\n",
      "[ 3  0  4  0  0  0  3  0 18  4  0  3  0 15  0  1 27  0  0  2 18  0  1  4\n",
      "  9  0  0  2  0  0  0  0 39  0  9  0  0 10  0  0 12  7  0  1  3  0  0  0\n",
      " 77]\n",
      "LR Accuracy:  0.6801470588235294\n",
      "LR F1:  0.6375605274078143\n",
      "For name:  j_weber\n",
      "total sample size before apply threshold:  146\n",
      "Counter({'0000-0003-2218-2952': 37, '0000-0002-5493-5886': 34, '0000-0002-2799-7352': 29, '0000-0001-9062-3591': 17, '0000-0002-6835-5065': 16, '0000-0001-5817-0975': 10, '0000-0003-3758-1569': 3})\n",
      "['0000-0002-5493-5886', '0000-0001-9062-3591', '0000-0002-2799-7352', '0000-0001-5817-0975', '0000-0003-2218-2952', '0000-0002-6835-5065']\n",
      "Total sample size after apply threshold:  143\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(143, 71)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(143, 23)\n",
      "2\n",
      "(143, 94)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.88      0.66        34\n",
      "          1       0.50      0.12      0.19        17\n",
      "          2       0.64      0.48      0.55        29\n",
      "          3       1.00      0.10      0.18        10\n",
      "          4       0.75      0.81      0.78        37\n",
      "          5       0.58      0.69      0.63        16\n",
      "\n",
      "avg / total       0.64      0.62      0.58       143\n",
      "\n",
      "[30  0  1  0  0  3  7  2  3  0  3  2  6  2 14  0  6  1  5  0  1  1  1  2\n",
      "  4  0  3  0 30  0  5  0  0  0  0 11]\n",
      "MNB Accuracy:  0.6153846153846154\n",
      "MNB F1:  0.49807447454506276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.82      0.86        34\n",
      "          1       0.41      0.41      0.41        17\n",
      "          2       0.51      0.69      0.59        29\n",
      "          3       0.60      0.30      0.40        10\n",
      "          4       0.79      0.70      0.74        37\n",
      "          5       0.61      0.69      0.65        16\n",
      "\n",
      "avg / total       0.68      0.66      0.67       143\n",
      "\n",
      "[28  1  1  0  0  4  0  7  6  2  1  1  0  4 20  0  4  1  0  3  3  3  1  0\n",
      "  0  1  9  0 26  1  3  1  0  0  1 11]\n",
      "svc Accuracy:  0.6643356643356644\n",
      "svc F1:  0.6085757379875026\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.82      0.86        34\n",
      "          1       0.64      0.41      0.50        17\n",
      "          2       0.61      0.69      0.65        29\n",
      "          3       0.67      0.20      0.31        10\n",
      "          4       0.68      0.81      0.74        37\n",
      "          5       0.52      0.69      0.59        16\n",
      "\n",
      "avg / total       0.69      0.69      0.67       143\n",
      "\n",
      "[28  1  1  0  1  3  0  7  4  1  3  2  0  2 20  0  6  1  0  0  2  2  3  3\n",
      "  0  1  5  0 30  1  3  0  1  0  1 11]\n",
      "LR Accuracy:  0.6853146853146853\n",
      "LR F1:  0.6082878991481141\n",
      "For name:  c_fox\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0001-9480-5704': 54, '0000-0002-4644-2619': 35, '0000-0001-6934-3624': 11, '0000-0002-9278-1777': 2})\n",
      "['0000-0001-9480-5704', '0000-0002-4644-2619', '0000-0001-6934-3624']\n",
      "Total sample size after apply threshold:  100\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 65)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 17)\n",
      "2\n",
      "(100, 82)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.76      0.71        54\n",
      "          1       0.58      0.51      0.55        35\n",
      "          2       0.75      0.55      0.63        11\n",
      "\n",
      "avg / total       0.65      0.65      0.65       100\n",
      "\n",
      "[41 11  2 17 18  0  3  2  6]\n",
      "MNB Accuracy:  0.65\n",
      "MNB F1:  0.6300256570279453\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.87      0.75        54\n",
      "          1       0.76      0.46      0.57        35\n",
      "          2       0.75      0.55      0.63        11\n",
      "\n",
      "avg / total       0.71      0.69      0.68       100\n",
      "\n",
      "[47  5  2 19 16  0  5  0  6]\n",
      "svc Accuracy:  0.69\n",
      "svc F1:  0.6516691729323308\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.87      0.71        54\n",
      "          1       0.63      0.34      0.44        35\n",
      "          2       0.67      0.18      0.29        11\n",
      "\n",
      "avg / total       0.62      0.61      0.57       100\n",
      "\n",
      "[47  6  1 23 12  0  8  1  2]\n",
      "LR Accuracy:  0.61\n",
      "LR F1:  0.4807599807599808\n",
      "For name:  s_thompson\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0003-0327-7155': 36, '0000-0003-4784-8386': 3, '0000-0001-9689-1490': 2, '0000-0001-9637-2041': 2, '0000-0002-6847-0397': 1, '0000-0002-0457-6926': 1})\n",
      "['0000-0003-0327-7155']\n",
      "Total sample size after apply threshold:  36\n",
      "For name:  b_choi\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-6090-869X': 12, '0000-0002-8657-7497': 4, '0000-0002-1461-9985': 3, '0000-0002-8381-336X': 1, '0000-0002-1412-9951': 1, '0000-0002-4984-5958': 1, '0000-0002-2950-2069': 1, '0000-0002-6561-8851': 1})\n",
      "['0000-0002-6090-869X']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  j_schwartz\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-6472-0184': 34, '0000-0001-8239-8857': 10, '0000-0003-2057-1831': 5, '0000-0001-5487-7260': 1, '0000-0001-9636-8181': 1})\n",
      "['0000-0002-6472-0184', '0000-0001-8239-8857']\n",
      "Total sample size after apply threshold:  44\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 17)\n",
      "2\n",
      "(44, 47)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.94      0.88        34\n",
      "          1       0.60      0.30      0.40        10\n",
      "\n",
      "avg / total       0.77      0.80      0.77        44\n",
      "\n",
      "[32  2  7  3]\n",
      "MNB Accuracy:  0.7954545454545454\n",
      "MNB F1:  0.6383561643835616\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.90        34\n",
      "          1       0.80      0.40      0.53        10\n",
      "\n",
      "avg / total       0.84      0.84      0.82        44\n",
      "\n",
      "[33  1  6  4]\n",
      "svc Accuracy:  0.8409090909090909\n",
      "svc F1:  0.7187214611872146\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        34\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.60      0.77      0.67        44\n",
      "\n",
      "[34  0 10  0]\n",
      "LR Accuracy:  0.7727272727272727\n",
      "LR F1:  0.4358974358974359\n",
      "For name:  a_brooks\n",
      "total sample size before apply threshold:  185\n",
      "Counter({'0000-0002-4085-9683': 134, '0000-0002-2691-1668': 19, '0000-0003-3551-6982': 14, '0000-0002-8486-4441': 9, '0000-0002-5309-7307': 6, '0000-0003-1334-6230': 3})\n",
      "['0000-0003-3551-6982', '0000-0002-4085-9683', '0000-0002-2691-1668']\n",
      "Total sample size after apply threshold:  167\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(167, 67)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(167, 23)\n",
      "2\n",
      "(167, 90)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.80      0.99      0.89       134\n",
      "          2       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.65      0.79      0.71       167\n",
      "\n",
      "[  0  14   0   2 132   0   1  18   0]\n",
      "MNB Accuracy:  0.7904191616766467\n",
      "MNB F1:  0.29530201342281875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.81      0.98      0.89       134\n",
      "          2       1.00      0.11      0.19        19\n",
      "\n",
      "avg / total       0.77      0.80      0.73       167\n",
      "\n",
      "[  0  14   0   3 131   0   1  16   2]\n",
      "svc Accuracy:  0.7964071856287425\n",
      "svc F1:  0.35953726123217655\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.80      1.00      0.89       134\n",
      "          2       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.64      0.80      0.71       167\n",
      "\n",
      "[  0  14   0   0 134   0   0  19   0]\n",
      "LR Accuracy:  0.8023952095808383\n",
      "LR F1:  0.2967884828349945\n",
      "For name:  l_rocha\n",
      "total sample size before apply threshold:  81\n",
      "Counter({'0000-0001-9402-887X': 24, '0000-0002-4345-6994': 20, '0000-0002-5469-0911': 11, '0000-0001-7832-058X': 8, '0000-0001-8184-8801': 6, '0000-0003-2146-9708': 5, '0000-0002-7219-1518': 5, '0000-0002-5070-9013': 1, '0000-0002-5190-9279': 1})\n",
      "['0000-0002-5469-0911', '0000-0001-9402-887X', '0000-0002-4345-6994']\n",
      "Total sample size after apply threshold:  55\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 43)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 15)\n",
      "2\n",
      "(55, 58)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.36      0.44        11\n",
      "          1       0.44      0.71      0.54        24\n",
      "          2       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.30      0.38      0.32        55\n",
      "\n",
      "[ 4  4  3  1 17  6  2 18  0]\n",
      "MNB Accuracy:  0.38181818181818183\n",
      "MNB F1:  0.3280423280423281\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.55      0.60        11\n",
      "          1       0.79      0.62      0.70        24\n",
      "          2       0.52      0.70      0.60        20\n",
      "\n",
      "avg / total       0.67      0.64      0.64        55\n",
      "\n",
      "[ 6  0  5  1 15  8  2  4 14]\n",
      "svc Accuracy:  0.6363636363636364\n",
      "svc F1:  0.6311396998185717\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.36      0.50        11\n",
      "          1       0.41      0.62      0.49        24\n",
      "          2       0.15      0.10      0.12        20\n",
      "\n",
      "avg / total       0.39      0.38      0.36        55\n",
      "\n",
      "[ 4  4  3  1 15  8  0 18  2]\n",
      "LR Accuracy:  0.38181818181818183\n",
      "LR F1:  0.37100513330021534\n",
      "For name:  s_fleming\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-4095-9924': 12, '0000-0001-7205-2051': 11, '0000-0003-2223-3975': 6, '0000-0002-6242-8083': 4, '0000-0001-5385-7233': 2})\n",
      "['0000-0001-7205-2051', '0000-0002-4095-9924']\n",
      "Total sample size after apply threshold:  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 13)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 11)\n",
      "2\n",
      "(23, 24)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.80      1.00      0.89        12\n",
      "\n",
      "avg / total       0.90      0.87      0.87        23\n",
      "\n",
      "[ 8  3  0 12]\n",
      "MNB Accuracy:  0.8695652173913043\n",
      "MNB F1:  0.8654970760233919\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        23\n",
      "\n",
      "[11  0  0 12]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        23\n",
      "\n",
      "[11  0  0 12]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  w_tsai\n",
      "total sample size before apply threshold:  113\n",
      "Counter({'0000-0002-2316-5751': 63, '0000-0003-1332-2650': 26, '0000-0002-9437-5131': 22, '0000-0002-4490-3581': 1, '0000-0002-1123-6954': 1})\n",
      "['0000-0003-1332-2650', '0000-0002-9437-5131', '0000-0002-2316-5751']\n",
      "Total sample size after apply threshold:  111\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 51)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 21)\n",
      "2\n",
      "(111, 72)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.42      0.52        26\n",
      "          1       1.00      0.14      0.24        22\n",
      "          2       0.66      0.97      0.79        63\n",
      "\n",
      "avg / total       0.74      0.68      0.62       111\n",
      "\n",
      "[11  0 15  3  3 16  2  0 61]\n",
      "MNB Accuracy:  0.6756756756756757\n",
      "MNB F1:  0.516968766001024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.65      0.76        26\n",
      "          1       1.00      0.32      0.48        22\n",
      "          2       0.73      0.98      0.84        63\n",
      "\n",
      "avg / total       0.82      0.77      0.75       111\n",
      "\n",
      "[17  0  9  1  7 14  1  0 62]\n",
      "svc Accuracy:  0.7747747747747747\n",
      "svc F1:  0.6920506713610162\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.42      0.56        26\n",
      "          1       1.00      0.14      0.24        22\n",
      "          2       0.65      0.98      0.78        63\n",
      "\n",
      "avg / total       0.77      0.68      0.63       111\n",
      "\n",
      "[11  0 15  1  3 18  1  0 62]\n",
      "LR Accuracy:  0.6846846846846847\n",
      "LR F1:  0.5296375635616143\n",
      "For name:  m_rodriguez\n",
      "total sample size before apply threshold:  214\n",
      "Counter({'0000-0001-6328-6497': 195, '0000-0001-8926-2987': 8, '0000-0002-9380-6614': 4, '0000-0002-4476-004X': 3, '0000-0001-6778-1663': 2, '0000-0002-4452-7627': 1, '0000-0002-2640-5888': 1})\n",
      "['0000-0001-6328-6497']\n",
      "Total sample size after apply threshold:  195\n",
      "For name:  r_miranda\n",
      "total sample size before apply threshold:  81\n",
      "Counter({'0000-0002-8467-5464': 69, '0000-0003-4798-314X': 7, '0000-0002-6551-9677': 4, '0000-0003-3222-7368': 1})\n",
      "['0000-0002-8467-5464']\n",
      "Total sample size after apply threshold:  69\n",
      "For name:  j_richardson\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0001-6521-610X': 70, '0000-0002-9429-151X': 9, '0000-0003-2733-9736': 3, '0000-0002-8895-8365': 2})\n",
      "['0000-0001-6521-610X']\n",
      "Total sample size after apply threshold:  70\n",
      "For name:  a_chin\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-0417-8653': 50, '0000-0002-0332-0048': 19, '0000-0002-8539-754X': 3, '0000-0003-1813-4042': 1})\n",
      "['0000-0002-0332-0048', '0000-0002-0417-8653']\n",
      "Total sample size after apply threshold:  69\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 29)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 31)\n",
      "2\n",
      "(69, 60)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.79      0.81        19\n",
      "          1       0.92      0.94      0.93        50\n",
      "\n",
      "avg / total       0.90      0.90      0.90        69\n",
      "\n",
      "[15  4  3 47]\n",
      "MNB Accuracy:  0.8985507246376812\n",
      "MNB F1:  0.8707519400588708\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        19\n",
      "          1       0.89      1.00      0.94        50\n",
      "\n",
      "avg / total       0.92      0.91      0.91        69\n",
      "\n",
      "[13  6  0 50]\n",
      "svc Accuracy:  0.9130434782608695\n",
      "svc F1:  0.8779481132075473\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.37      0.50        19\n",
      "          1       0.80      0.96      0.87        50\n",
      "\n",
      "avg / total       0.79      0.80      0.77        69\n",
      "\n",
      "[ 7 12  2 48]\n",
      "LR Accuracy:  0.7971014492753623\n",
      "LR F1:  0.6863636363636364\n",
      "For name:  h_madsen\n",
      "total sample size before apply threshold:  8\n",
      "Counter({'0000-0002-2498-8709': 3, '0000-0001-7103-5380': 3, '0000-0003-2542-3109': 1, '0000-0002-0612-3437': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_ferguson\n",
      "total sample size before apply threshold:  168\n",
      "Counter({'0000-0003-1321-8714': 157, '0000-0003-0760-757X': 9, '0000-0002-7780-6462': 1, '0000-0002-5463-1874': 1})\n",
      "['0000-0003-1321-8714']\n",
      "Total sample size after apply threshold:  157\n",
      "For name:  s_mitra\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-7923-8887': 21, '0000-0001-7620-4809': 11, '0000-0002-0800-4626': 10, '0000-0001-6381-5344': 3, '0000-0003-3526-9942': 1, '0000-0001-5744-3935': 1, '0000-0002-3938-6516': 1})\n",
      "['0000-0001-7620-4809', '0000-0001-7923-8887', '0000-0002-0800-4626']\n",
      "Total sample size after apply threshold:  42\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 12)\n",
      "2\n",
      "(42, 32)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.91      1.00      0.95        21\n",
      "          2       0.82      0.90      0.86        10\n",
      "\n",
      "avg / total       0.91      0.90      0.90        42\n",
      "\n",
      "[ 8  1  2  0 21  0  0  1  9]\n",
      "MNB Accuracy:  0.9047619047619048\n",
      "MNB F1:  0.8845978582820688\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.95      1.00      0.98        21\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.98      0.98      0.98        42\n",
      "\n",
      "[10  1  0  0 21  0  0  0 10]\n",
      "svc Accuracy:  0.9761904761904762\n",
      "svc F1:  0.976375046142488\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.88      1.00      0.93        21\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.94      0.93      0.93        42\n",
      "\n",
      "[ 8  3  0  0 21  0  0  0 10]\n",
      "LR Accuracy:  0.9285714285714286\n",
      "LR F1:  0.9251461988304094\n",
      "For name:  v_pinto\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0002-6600-1781': 29, '0000-0002-1152-1667': 11, '0000-0003-3871-9152': 7, '0000-0003-3395-1251': 1})\n",
      "['0000-0002-6600-1781', '0000-0002-1152-1667']\n",
      "Total sample size after apply threshold:  40\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 25)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 16)\n",
      "2\n",
      "(40, 41)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.93      0.83        29\n",
      "          1       0.50      0.18      0.27        11\n",
      "\n",
      "avg / total       0.68      0.72      0.68        40\n",
      "\n",
      "[27  2  9  2]\n",
      "MNB Accuracy:  0.725\n",
      "MNB F1:  0.5487179487179488\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.93      0.86        29\n",
      "          1       0.67      0.36      0.47        11\n",
      "\n",
      "avg / total       0.76      0.78      0.75        40\n",
      "\n",
      "[27  2  7  4]\n",
      "svc Accuracy:  0.775\n",
      "svc F1:  0.6638655462184874\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84        29\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.53      0.72      0.61        40\n",
      "\n",
      "[29  0 11  0]\n",
      "LR Accuracy:  0.725\n",
      "LR F1:  0.42028985507246375\n",
      "For name:  m_field\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0002-4866-2885': 114, '0000-0003-1310-5074': 6, '0000-0002-8350-417X': 5, '0000-0002-6169-6721': 1})\n",
      "['0000-0002-4866-2885']\n",
      "Total sample size after apply threshold:  114\n",
      "For name:  c_jones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  354\n",
      "Counter({'0000-0002-0026-9494': 194, '0000-0001-7630-7285': 31, '0000-0001-8594-9554': 28, '0000-0003-0541-0431': 23, '0000-0003-3672-6631': 11, '0000-0002-7249-2580': 11, '0000-0001-9096-9728': 9, '0000-0001-6159-1842': 9, '0000-0003-3430-8110': 7, '0000-0001-6275-0235': 6, '0000-0001-7065-1157': 6, '0000-0003-4680-7080': 4, '0000-0002-1698-0408': 3, '0000-0001-9753-0777': 2, '0000-0002-7196-5825': 2, '0000-0001-6136-7111': 2, '0000-0002-6319-2068': 2, '0000-0002-3708-5859': 1, '0000-0003-1523-2368': 1, '0000-0002-0669-7860': 1, '0000-0002-8765-5178': 1})\n",
      "['0000-0003-0541-0431', '0000-0003-3672-6631', '0000-0001-7630-7285', '0000-0002-7249-2580', '0000-0001-8594-9554', '0000-0002-0026-9494']\n",
      "Total sample size after apply threshold:  298\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(298, 147)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(298, 39)\n",
      "2\n",
      "(298, 186)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.39      0.50        23\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.92      0.35      0.51        31\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.80      0.29      0.42        28\n",
      "          5       0.72      0.97      0.83       194\n",
      "\n",
      "avg / total       0.69      0.73      0.67       298\n",
      "\n",
      "[  9   0   0   0   0  14   0   0   0   0   0  11   0   0  11   0   0  20\n",
      "   1   0   0   0   0  10   1   0   0   0   8  19   2   0   1   0   2 189]\n",
      "MNB Accuracy:  0.7281879194630873\n",
      "MNB F1:  0.3766356696279909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.57      0.57        23\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.95      0.68      0.79        31\n",
      "          3       0.67      0.18      0.29        11\n",
      "          4       1.00      0.68      0.81        28\n",
      "          5       0.83      0.95      0.88       194\n",
      "\n",
      "avg / total       0.80      0.80      0.79       298\n",
      "\n",
      "[ 13   3   0   0   0   7   2   0   0   0   0   9   0   0  21   0   0  10\n",
      "   2   1   0   2   0   6   1   1   0   0  19   7   5   3   1   1   0 184]\n",
      "svc Accuracy:  0.802013422818792\n",
      "svc F1:  0.5557315250502247\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.39      0.53        23\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.39      0.56        31\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.25      0.40        28\n",
      "          5       0.72      0.99      0.83       194\n",
      "\n",
      "avg / total       0.73      0.74      0.68       298\n",
      "\n",
      "[  9   0   0   0   0  14   0   0   0   0   0  11   0   0  12   0   0  19\n",
      "   0   0   0   0   0  11   0   0   0   0   7  21   2   0   0   0   0 192]\n",
      "LR Accuracy:  0.738255033557047\n",
      "LR F1:  0.3864533551264057\n",
      "For name:  k_hong\n",
      "total sample size before apply threshold:  127\n",
      "Counter({'0000-0002-4684-6111': 44, '0000-0002-2852-5111': 29, '0000-0001-7325-1036': 20, '0000-0003-3334-817X': 12, '0000-0002-3489-9056': 11, '0000-0002-8308-585X': 6, '0000-0003-1931-0933': 3, '0000-0002-8299-7128': 1, '0000-0001-6213-1848': 1})\n",
      "['0000-0002-3489-9056', '0000-0002-4684-6111', '0000-0002-2852-5111', '0000-0003-3334-817X', '0000-0001-7325-1036']\n",
      "Total sample size after apply threshold:  116\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(116, 53)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(116, 12)\n",
      "2\n",
      "(116, 65)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        11\n",
      "          1       0.75      0.91      0.82        44\n",
      "          2       0.63      0.76      0.69        29\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       0.74      0.70      0.72        20\n",
      "\n",
      "avg / total       0.77      0.73      0.72       116\n",
      "\n",
      "[ 3  3  5  0  0  0 40  3  0  1  0  4 22  0  3  0  3  2  6  1  0  3  3  0\n",
      " 14]\n",
      "MNB Accuracy:  0.7327586206896551\n",
      "MNB F1:  0.6650858162456101\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.55      0.63        11\n",
      "          1       0.80      0.98      0.88        44\n",
      "          2       0.71      0.76      0.73        29\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       0.94      0.80      0.86        20\n",
      "\n",
      "avg / total       0.82      0.80      0.79       116\n",
      "\n",
      "[ 6  2  2  0  1  0 43  1  0  0  2  5 22  0  0  0  4  2  6  0  0  0  4  0\n",
      " 16]\n",
      "svc Accuracy:  0.8017241379310345\n",
      "svc F1:  0.7547989665282898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.75      0.91      0.82        44\n",
      "          2       0.65      0.83      0.73        29\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       0.93      0.65      0.76        20\n",
      "\n",
      "avg / total       0.81      0.77      0.76       116\n",
      "\n",
      "[ 6  2  3  0  0  0 40  4  0  0  0  4 24  0  1  0  5  1  6  0  0  2  5  0\n",
      " 13]\n",
      "LR Accuracy:  0.7672413793103449\n",
      "LR F1:  0.7378539794549497\n",
      "For name:  t_williams\n",
      "total sample size before apply threshold:  190\n",
      "Counter({'0000-0003-3414-3440': 78, '0000-0002-5857-3851': 42, '0000-0003-1072-0223': 25, '0000-0001-6299-3747': 24, '0000-0003-1710-3914': 9, '0000-0002-3866-1344': 6, '0000-0003-0072-3316': 3, '0000-0002-9319-1701': 2, '0000-0003-3463-9200': 1})\n",
      "['0000-0001-6299-3747', '0000-0003-1072-0223', '0000-0003-3414-3440', '0000-0002-5857-3851']\n",
      "Total sample size after apply threshold:  169\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 74)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 24)\n",
      "2\n",
      "(169, 98)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.46      0.59        24\n",
      "          1       0.56      0.20      0.29        25\n",
      "          2       0.64      0.90      0.74        78\n",
      "          3       0.65      0.57      0.61        42\n",
      "\n",
      "avg / total       0.66      0.65      0.62       169\n",
      "\n",
      "[11  1  9  3  0  5 17  3  1  0 70  7  1  3 14 24]\n",
      "MNB Accuracy:  0.650887573964497\n",
      "MNB F1:  0.5602470073565272\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.58      0.72        24\n",
      "          1       0.48      0.48      0.48        25\n",
      "          2       0.82      0.92      0.87        78\n",
      "          3       0.68      0.67      0.67        42\n",
      "\n",
      "avg / total       0.75      0.75      0.74       169\n",
      "\n",
      "[14  4  2  4  0 12  6  7  1  3 72  2  0  6  8 28]\n",
      "svc Accuracy:  0.7455621301775148\n",
      "svc F1:  0.6850293481618783\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.42      0.57        24\n",
      "          1       0.70      0.28      0.40        25\n",
      "          2       0.63      0.94      0.75        78\n",
      "          3       0.75      0.57      0.65        42\n",
      "\n",
      "avg / total       0.71      0.67      0.65       169\n",
      "\n",
      "[10  1 10  3  0  7 16  2  1  1 73  3  0  1 17 24]\n",
      "LR Accuracy:  0.6745562130177515\n",
      "LR F1:  0.5931636349162123\n",
      "For name:  j_xavier\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0002-0702-6700': 12, '0000-0003-1386-4492': 7, '0000-0002-7836-4598': 2, '0000-0002-9669-8532': 1})\n",
      "['0000-0002-0702-6700']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  b_bhushan\n",
      "total sample size before apply threshold:  187\n",
      "Counter({'0000-0001-7161-6601': 163, '0000-0002-4182-9478': 19, '0000-0002-1716-9764': 3, '0000-0001-5073-0640': 1, '0000-0001-9244-209X': 1})\n",
      "['0000-0001-7161-6601', '0000-0002-4182-9478']\n",
      "Total sample size after apply threshold:  182\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(182, 43)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(182, 17)\n",
      "2\n",
      "(182, 60)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       163\n",
      "          1       1.00      0.21      0.35        19\n",
      "\n",
      "avg / total       0.92      0.92      0.89       182\n",
      "\n",
      "[163   0  15   4]\n",
      "MNB Accuracy:  0.9175824175824175\n",
      "MNB F1:  0.6519189085809002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97       163\n",
      "          1       0.90      0.47      0.62        19\n",
      "\n",
      "avg / total       0.94      0.94      0.93       182\n",
      "\n",
      "[162   1  10   9]\n",
      "svc Accuracy:  0.9395604395604396\n",
      "svc F1:  0.7939269171384458\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       163\n",
      "          1       1.00      0.11      0.19        19\n",
      "\n",
      "avg / total       0.92      0.91      0.87       182\n",
      "\n",
      "[163   0  17   2]\n",
      "LR Accuracy:  0.9065934065934066\n",
      "LR F1:  0.5704567541302236\n",
      "For name:  r_ellis\n",
      "total sample size before apply threshold:  176\n",
      "Counter({'0000-0003-4931-752X': 158, '0000-0001-7691-5205': 16, '0000-0002-9755-9913': 1, '0000-0003-2355-5407': 1})\n",
      "['0000-0001-7691-5205', '0000-0003-4931-752X']\n",
      "Total sample size after apply threshold:  174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(174, 64)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(174, 22)\n",
      "2\n",
      "(174, 86)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.38      0.48        16\n",
      "          1       0.94      0.98      0.96       158\n",
      "\n",
      "avg / total       0.91      0.93      0.92       174\n",
      "\n",
      "[  6  10   3 155]\n",
      "MNB Accuracy:  0.9252873563218391\n",
      "MNB F1:  0.719876160990712\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.81        16\n",
      "          1       0.97      1.00      0.98       158\n",
      "\n",
      "avg / total       0.97      0.97      0.97       174\n",
      "\n",
      "[ 11   5   0 158]\n",
      "svc Accuracy:  0.9712643678160919\n",
      "svc F1:  0.8996192454136379\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.12      0.22        16\n",
      "          1       0.92      1.00      0.96       158\n",
      "\n",
      "avg / total       0.93      0.92      0.89       174\n",
      "\n",
      "[  2  14   0 158]\n",
      "LR Accuracy:  0.9195402298850575\n",
      "LR F1:  0.5898989898989899\n",
      "For name:  v_saini\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0002-0258-2871': 11, '0000-0002-9944-0262': 5, '0000-0003-2734-0120': 1, '0000-0002-6796-5881': 1})\n",
      "['0000-0002-0258-2871']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  a_ellis\n",
      "total sample size before apply threshold:  168\n",
      "Counter({'0000-0001-7456-9214': 47, '0000-0002-0725-2353': 41, '0000-0002-0417-0547': 40, '0000-0002-0053-5641': 37, '0000-0002-8164-1146': 3})\n",
      "['0000-0002-0417-0547', '0000-0001-7456-9214', '0000-0002-0725-2353', '0000-0002-0053-5641']\n",
      "Total sample size after apply threshold:  165\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(165, 62)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(165, 19)\n",
      "2\n",
      "(165, 81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.97      0.85        40\n",
      "          1       0.76      0.79      0.77        47\n",
      "          2       0.88      0.68      0.77        41\n",
      "          3       0.72      0.62      0.67        37\n",
      "\n",
      "avg / total       0.78      0.77      0.77       165\n",
      "\n",
      "[39  0  0  1  4 37  3  3  4  4 28  5  5  8  1 23]\n",
      "MNB Accuracy:  0.7696969696969697\n",
      "MNB F1:  0.7631123436569387\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        40\n",
      "          1       0.79      0.79      0.79        47\n",
      "          2       0.79      0.66      0.72        41\n",
      "          3       0.66      0.78      0.72        37\n",
      "\n",
      "avg / total       0.81      0.81      0.81       165\n",
      "\n",
      "[40  0  0  0  0 37  4  6  0  5 27  9  0  5  3 29]\n",
      "svc Accuracy:  0.806060606060606\n",
      "svc F1:  0.8058208563173103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        40\n",
      "          1       0.66      0.81      0.72        47\n",
      "          2       0.76      0.71      0.73        41\n",
      "          3       0.72      0.62      0.67        37\n",
      "\n",
      "avg / total       0.78      0.77      0.77       165\n",
      "\n",
      "[37  2  0  1  0 38  6  3  0  7 29  5  0 11  3 23]\n",
      "LR Accuracy:  0.7696969696969697\n",
      "LR F1:  0.7714230916762563\n",
      "For name:  f_reis\n",
      "total sample size before apply threshold:  222\n",
      "Counter({'0000-0002-9258-7472': 111, '0000-0003-3401-9554': 92, '0000-0002-9159-0530': 12, '0000-0003-1546-963X': 4, '0000-0003-2256-4379': 2, '0000-0002-9471-1174': 1})\n",
      "['0000-0002-9159-0530', '0000-0002-9258-7472', '0000-0003-3401-9554']\n",
      "Total sample size after apply threshold:  215\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(215, 109)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(215, 21)\n",
      "2\n",
      "(215, 130)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.82      0.85      0.84       111\n",
      "          2       0.74      0.82      0.78        92\n",
      "\n",
      "avg / total       0.74      0.79      0.76       215\n",
      "\n",
      "[ 0  3  9  0 94 17  0 17 75]\n",
      "MNB Accuracy:  0.786046511627907\n",
      "MNB F1:  0.5375858760314718\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        12\n",
      "          1       0.90      0.85      0.87       111\n",
      "          2       0.82      0.89      0.85        92\n",
      "\n",
      "avg / total       0.87      0.87      0.87       215\n",
      "\n",
      "[10  1  1  0 94 17  0 10 82]\n",
      "svc Accuracy:  0.8651162790697674\n",
      "svc F1:  0.8778759820426486\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.82      0.86      0.84       111\n",
      "          2       0.76      0.80      0.78        92\n",
      "\n",
      "avg / total       0.75      0.79      0.77       215\n",
      "\n",
      "[ 0  3  9  0 96 15  0 18 74]\n",
      "LR Accuracy:  0.7906976744186046\n",
      "LR F1:  0.5403508771929825\n",
      "For name:  j_gray\n",
      "total sample size before apply threshold:  112\n",
      "Counter({'0000-0001-6380-2324': 55, '0000-0003-4146-7902': 24, '0000-0003-2338-0301': 17, '0000-0002-7287-0748': 8, '0000-0001-5863-6835': 3, '0000-0001-9972-5156': 2, '0000-0001-6668-5899': 1, '0000-0003-3554-0499': 1, '0000-0001-8572-0020': 1})\n",
      "['0000-0003-4146-7902', '0000-0001-6380-2324', '0000-0003-2338-0301']\n",
      "Total sample size after apply threshold:  96\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(96, 46)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(96, 13)\n",
      "2\n",
      "(96, 59)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.38      0.46        24\n",
      "          1       0.65      0.91      0.76        55\n",
      "          2       0.75      0.18      0.29        17\n",
      "\n",
      "avg / total       0.65      0.65      0.60        96\n",
      "\n",
      "[ 9 14  1  5 50  0  1 13  3]\n",
      "MNB Accuracy:  0.6458333333333334\n",
      "MNB F1:  0.5016095016095016\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.50      0.59        24\n",
      "          1       0.70      0.91      0.79        55\n",
      "          2       0.75      0.35      0.48        17\n",
      "\n",
      "avg / total       0.71      0.71      0.69        96\n",
      "\n",
      "[12 11  1  4 50  1  1 10  6]\n",
      "svc Accuracy:  0.7083333333333334\n",
      "svc F1:  0.6196722157697767\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.42      0.56        24\n",
      "          1       0.68      0.98      0.80        55\n",
      "          2       0.75      0.18      0.29        17\n",
      "\n",
      "avg / total       0.73      0.70      0.65        96\n",
      "\n",
      "[10 13  1  1 54  0  1 13  3]\n",
      "LR Accuracy:  0.6979166666666666\n",
      "LR F1:  0.5470899470899471\n",
      "For name:  r_hughes\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0001-9910-6566': 30, '0000-0002-4465-4212': 18, '0000-0002-6307-4432': 7, '0000-0002-2875-2103': 2})\n",
      "['0000-0002-4465-4212', '0000-0001-9910-6566']\n",
      "Total sample size after apply threshold:  48\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 26)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 20)\n",
      "2\n",
      "(48, 46)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.50      0.55        18\n",
      "          1       0.73      0.80      0.76        30\n",
      "\n",
      "avg / total       0.68      0.69      0.68        48\n",
      "\n",
      "[ 9  9  6 24]\n",
      "MNB Accuracy:  0.6875\n",
      "MNB F1:  0.6536796536796536\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.50      0.56        18\n",
      "          1       0.74      0.83      0.78        30\n",
      "\n",
      "avg / total       0.70      0.71      0.70        48\n",
      "\n",
      "[ 9  9  5 25]\n",
      "svc Accuracy:  0.7083333333333334\n",
      "svc F1:  0.671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.50      0.60        18\n",
      "          1       0.75      0.90      0.82        30\n",
      "\n",
      "avg / total       0.75      0.75      0.74        48\n",
      "\n",
      "[ 9  9  3 27]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.7090909090909091\n",
      "For name:  a_green\n",
      "total sample size before apply threshold:  169\n",
      "Counter({'0000-0002-2753-4841': 79, '0000-0002-1268-4951': 39, '0000-0003-2058-1204': 35, '0000-0003-0454-1798': 8, '0000-0002-3674-4242': 4, '0000-0001-7666-5584': 2, '0000-0002-1241-4230': 1, '0000-0003-3404-4995': 1})\n",
      "['0000-0002-1268-4951', '0000-0002-2753-4841', '0000-0003-2058-1204']\n",
      "Total sample size after apply threshold:  153\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(153, 85)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(153, 31)\n",
      "2\n",
      "(153, 116)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.62      0.62        39\n",
      "          1       0.83      0.78      0.81        79\n",
      "          2       0.80      0.91      0.85        35\n",
      "\n",
      "avg / total       0.77      0.77      0.77       153\n",
      "\n",
      "[24 11  4 13 62  4  1  2 32]\n",
      "MNB Accuracy:  0.7712418300653595\n",
      "MNB F1:  0.7606349206349204\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.56      0.65        39\n",
      "          1       0.74      0.89      0.81        79\n",
      "          2       0.90      0.77      0.83        35\n",
      "\n",
      "avg / total       0.78      0.78      0.77       153\n",
      "\n",
      "[22 17  0  6 70  3  1  7 27]\n",
      "svc Accuracy:  0.7777777777777778\n",
      "svc F1:  0.7623588697373124\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.44      0.56        39\n",
      "          1       0.70      0.90      0.79        79\n",
      "          2       0.77      0.66      0.71        35\n",
      "\n",
      "avg / total       0.74      0.73      0.71       153\n",
      "\n",
      "[17 18  4  5 71  3  0 12 23]\n",
      "LR Accuracy:  0.7254901960784313\n",
      "LR F1:  0.6846527485871747\n",
      "For name:  c_reis\n",
      "total sample size before apply threshold:  77\n",
      "Counter({'0000-0002-0286-6639': 54, '0000-0002-1046-4031': 19, '0000-0001-6585-3993': 2, '0000-0002-8193-6964': 2})\n",
      "['0000-0002-0286-6639', '0000-0002-1046-4031']\n",
      "Total sample size after apply threshold:  73"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 54)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 10)\n",
      "2\n",
      "(73, 64)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        54\n",
      "          1       1.00      0.37      0.54        19\n",
      "\n",
      "avg / total       0.87      0.84      0.81        73\n",
      "\n",
      "[54  0 12  7]\n",
      "MNB Accuracy:  0.8356164383561644\n",
      "MNB F1:  0.7192307692307692\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92        54\n",
      "          1       1.00      0.47      0.64        19\n",
      "\n",
      "avg / total       0.88      0.86      0.84        73\n",
      "\n",
      "[54  0 10  9]\n",
      "svc Accuracy:  0.863013698630137\n",
      "svc F1:  0.7790556900726393\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        54\n",
      "          1       1.00      0.16      0.27        19\n",
      "\n",
      "avg / total       0.83      0.78      0.72        73\n",
      "\n",
      "[54  0 16  3]\n",
      "LR Accuracy:  0.7808219178082192\n",
      "LR F1:  0.5718475073313783\n",
      "For name:  f_scott\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0002-6021-0419': 15, '0000-0003-0229-3698': 8, '0000-0003-2041-4641': 3})\n",
      "['0000-0002-6021-0419']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  l_han\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0003-4180-1288': 8, '0000-0002-0577-9661': 7, '0000-0002-2955-6307': 2, '0000-0003-3436-2811': 2, '0000-0003-3204-6313': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_martins\n",
      "total sample size before apply threshold:  121\n",
      "Counter({'0000-0001-8634-6878': 38, '0000-0001-6600-6163': 18, '0000-0002-7901-7600': 17, '0000-0002-8488-5103': 16, '0000-0003-3506-674X': 11, '0000-0001-8710-1856': 4, '0000-0001-8561-5167': 4, '0000-0002-9335-6027': 3, '0000-0003-4341-1005': 3, '0000-0002-8269-9550': 2, '0000-0001-5953-3758': 2, '0000-0002-4886-9261': 1, '0000-0002-7090-6030': 1, '0000-0003-3634-0624': 1})\n",
      "['0000-0001-8634-6878', '0000-0002-8488-5103', '0000-0003-3506-674X', '0000-0001-6600-6163', '0000-0002-7901-7600']\n",
      "Total sample size after apply threshold:  100\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 64)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 21)\n",
      "2\n",
      "(100, 85)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.87      0.65        38\n",
      "          1       0.44      0.25      0.32        16\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.65      0.61      0.63        18\n",
      "          4       1.00      0.59      0.74        17\n",
      "\n",
      "avg / total       0.55      0.58      0.54       100\n",
      "\n",
      "[33  1  0  4  0 11  4  0  1  0 10  1  0  0  0  6  1  0 11  0  4  2  0  1\n",
      " 10]\n",
      "MNB Accuracy:  0.58\n",
      "MNB F1:  0.4672741985683162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.92      0.70        38\n",
      "          1       0.50      0.31      0.38        16\n",
      "          2       1.00      0.64      0.78        11\n",
      "          3       1.00      0.61      0.76        18\n",
      "          4       1.00      0.59      0.74        17\n",
      "\n",
      "avg / total       0.75      0.68      0.68       100\n",
      "\n",
      "[35  3  0  0  0 11  5  0  0  0  4  0  7  0  0  6  1  0 11  0  6  1  0  0\n",
      " 10]\n",
      "svc Accuracy:  0.68\n",
      "svc F1:  0.6723509185578151\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.89      0.64        38\n",
      "          1       0.57      0.25      0.35        16\n",
      "          2       1.00      0.27      0.43        11\n",
      "          3       0.83      0.56      0.67        18\n",
      "          4       0.90      0.53      0.67        17\n",
      "\n",
      "avg / total       0.69      0.60      0.58       100\n",
      "\n",
      "[34  1  0  2  1 12  4  0  0  0  8  0  3  0  0  7  1  0 10  0  7  1  0  0\n",
      "  9]\n",
      "LR Accuracy:  0.6\n",
      "LR F1:  0.5502480565647095\n",
      "For name:  r_schneider\n",
      "total sample size before apply threshold:  158\n",
      "Counter({'0000-0002-6870-6902': 43, '0000-0003-2228-1248': 42, '0000-0002-2626-3111': 29, '0000-0003-0012-4962': 25, '0000-0003-3279-5365': 7, '0000-0003-1400-8401': 5, '0000-0001-9317-2888': 2, '0000-0002-0329-5778': 2, '0000-0001-9628-0809': 1, '0000-0001-9501-8489': 1, '0000-0001-5496-7020': 1})\n",
      "['0000-0003-0012-4962', '0000-0003-2228-1248', '0000-0002-6870-6902', '0000-0002-2626-3111']\n",
      "Total sample size after apply threshold:  139\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 84)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 18)\n",
      "2\n",
      "(139, 102)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.44      0.55        25\n",
      "          1       0.55      0.71      0.62        42\n",
      "          2       0.50      0.58      0.54        43\n",
      "          3       0.63      0.41      0.50        29\n",
      "\n",
      "avg / total       0.58      0.56      0.56       139\n",
      "\n",
      "[11  9  5  0  1 30 10  1  1 11 25  6  2  5 10 12]\n",
      "MNB Accuracy:  0.5611510791366906\n",
      "MNB F1:  0.5515477774082695\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.52      0.68        25\n",
      "          1       0.66      0.74      0.70        42\n",
      "          2       0.47      0.63      0.53        43\n",
      "          3       0.57      0.41      0.48        29\n",
      "\n",
      "avg / total       0.64      0.60      0.60       139\n",
      "\n",
      "[13  5  6  1  0 31  9  2  0 10 27  6  0  1 16 12]\n",
      "svc Accuracy:  0.5971223021582733\n",
      "svc F1:  0.5988733012863676\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        25\n",
      "          1       0.57      0.74      0.65        42\n",
      "          2       0.46      0.60      0.53        43\n",
      "          3       0.63      0.41      0.50        29\n",
      "\n",
      "avg / total       0.63      0.57      0.56       139\n",
      "\n",
      "[10  9  6  0  0 31 10  1  0 11 26  6  0  3 14 12]\n",
      "LR Accuracy:  0.5683453237410072\n",
      "LR F1:  0.5606286075036075\n",
      "For name:  j_regan\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0003-2164-9151': 10, '0000-0001-5816-4516': 9, '0000-0001-9987-7942': 7, '0000-0002-3516-5046': 1})\n",
      "['0000-0003-2164-9151']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  s_brennan\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0003-1789-8809': 12, '0000-0003-3601-9769': 12, '0000-0002-8719-4367': 6, '0000-0002-7634-9546': 1})\n",
      "['0000-0003-1789-8809', '0000-0003-3601-9769']\n",
      "Total sample size after apply threshold:  24\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 17)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 10)\n",
      "2\n",
      "(24, 27)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83        12\n",
      "          1       0.83      0.83      0.83        12\n",
      "\n",
      "avg / total       0.83      0.83      0.83        24\n",
      "\n",
      "[10  2  2 10]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.8333333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.67      0.70        12\n",
      "          1       0.69      0.75      0.72        12\n",
      "\n",
      "avg / total       0.71      0.71      0.71        24\n",
      "\n",
      "[8 4 3 9]\n",
      "svc Accuracy:  0.7083333333333334\n",
      "svc F1:  0.7078260869565216\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.67      0.73        12\n",
      "          1       0.71      0.83      0.77        12\n",
      "\n",
      "avg / total       0.76      0.75      0.75        24\n",
      "\n",
      "[ 8  4  2 10]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.7482517482517481\n",
      "For name:  v_patel\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0003-2875-4659': 20, '0000-0001-6616-3628': 4, '0000-0002-8949-139X': 2, '0000-0003-2844-2698': 1})\n",
      "['0000-0003-2875-4659']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  d_johnston\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-2487-1084': 15, '0000-0003-2424-036X': 7, '0000-0003-0065-1105': 6, '0000-0002-6885-5369': 1})\n",
      "['0000-0002-2487-1084']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  r_gupta\n",
      "total sample size before apply threshold:  188\n",
      "Counter({'0000-0003-2583-563X': 46, '0000-0002-2984-5010': 36, '0000-0001-6841-6676': 28, '0000-0001-7461-2083': 14, '0000-0002-8328-9780': 9, '0000-0002-5537-8057': 8, '0000-0001-9959-3501': 8, '0000-0001-6819-2748': 6, '0000-0002-6608-9867': 6, '0000-0002-4231-9592': 5, '0000-0001-5755-1143': 5, '0000-0002-6257-1285': 4, '0000-0001-9031-1109': 3, '0000-0002-6585-1725': 3, '0000-0002-1414-2830': 1, '0000-0002-9907-5795': 1, '0000-0002-1334-9186': 1, '0000-0002-8634-7501': 1, '0000-0001-9751-1808': 1, '0000-0003-2958-1526': 1, '0000-0002-3345-7862': 1})\n",
      "['0000-0003-2583-563X', '0000-0001-7461-2083', '0000-0002-2984-5010', '0000-0001-6841-6676']\n",
      "Total sample size after apply threshold:  124\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(124, 69)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(124, 16)\n",
      "2\n",
      "(124, 85)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.91      0.76        46\n",
      "          1       1.00      0.50      0.67        14\n",
      "          2       0.71      0.75      0.73        36\n",
      "          3       0.73      0.39      0.51        28\n",
      "\n",
      "avg / total       0.73      0.70      0.69       124\n",
      "\n",
      "[42  0  2  2  2  7  4  1  8  0 27  1 12  0  5 11]\n",
      "MNB Accuracy:  0.7016129032258065\n",
      "MNB F1:  0.667915166752376\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.83      0.81        46\n",
      "          1       1.00      0.57      0.73        14\n",
      "          2       0.73      0.67      0.70        36\n",
      "          3       0.54      0.68      0.60        28\n",
      "\n",
      "avg / total       0.74      0.72      0.72       124\n",
      "\n",
      "[38  0  2  6  2  8  2  2  4  0 24  8  4  0  5 19]\n",
      "svc Accuracy:  0.717741935483871\n",
      "svc F1:  0.7086525356645614\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.96      0.79        46\n",
      "          1       0.80      0.57      0.67        14\n",
      "          2       0.74      0.64      0.69        36\n",
      "          3       0.67      0.43      0.52        28\n",
      "\n",
      "avg / total       0.71      0.70      0.69       124\n",
      "\n",
      "[44  0  0  2  2  8  3  1  8  2 23  3 11  0  5 12]\n",
      "LR Accuracy:  0.7016129032258065\n",
      "LR F1:  0.6669414385183366\n",
      "For name:  s_reddy\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-9177-0857': 27, '0000-0002-7362-184X': 13, '0000-0002-1458-6853': 7, '0000-0003-2735-9550': 2, '0000-0002-1924-8976': 1, '0000-0002-4726-5714': 1})\n",
      "['0000-0002-9177-0857', '0000-0002-7362-184X']\n",
      "Total sample size after apply threshold:  40\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 14)\n",
      "2\n",
      "(40, 42)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.89        27\n",
      "          1       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.86      0.82      0.80        40\n",
      "\n",
      "[27  0  7  6]\n",
      "MNB Accuracy:  0.825\n",
      "MNB F1:  0.7584124245038826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.93      0.86        27\n",
      "          1       0.78      0.54      0.64        13\n",
      "\n",
      "avg / total       0.80      0.80      0.79        40\n",
      "\n",
      "[25  2  6  7]\n",
      "svc Accuracy:  0.8\n",
      "svc F1:  0.7492163009404389\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        27\n",
      "          1       1.00      0.15      0.27        13\n",
      "\n",
      "avg / total       0.80      0.72      0.65        40\n",
      "\n",
      "[27  0 11  2]\n",
      "LR Accuracy:  0.725\n",
      "LR F1:  0.5487179487179488\n",
      "For name:  y_yao\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0001-5827-8716': 19, '0000-0002-4338-2606': 18, '0000-0002-0814-6675': 11, '0000-0002-2943-5994': 3, '0000-0003-4892-052X': 3, '0000-0003-1132-592X': 1, '0000-0001-6502-6226': 1, '0000-0001-9359-2030': 1, '0000-0003-3612-3742': 1})\n",
      "['0000-0002-4338-2606', '0000-0001-5827-8716', '0000-0002-0814-6675']\n",
      "Total sample size after apply threshold:  48\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 9)\n",
      "2\n",
      "(48, 41)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.61      0.61        18\n",
      "          1       0.65      0.89      0.76        19\n",
      "          2       0.50      0.18      0.27        11\n",
      "\n",
      "avg / total       0.60      0.62      0.59        48\n",
      "\n",
      "[11  6  1  1 17  1  6  3  2]\n",
      "MNB Accuracy:  0.625\n",
      "MNB F1:  0.5444444444444444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.72      0.63        18\n",
      "          1       0.74      0.74      0.74        19\n",
      "          2       0.33      0.18      0.24        11\n",
      "\n",
      "avg / total       0.58      0.60      0.58        48\n",
      "\n",
      "[13  2  3  4 14  1  6  3  2]\n",
      "svc Accuracy:  0.6041666666666666\n",
      "svc F1:  0.5354275214578771\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.67      0.63        18\n",
      "          1       0.73      0.84      0.78        19\n",
      "          2       0.33      0.18      0.24        11\n",
      "\n",
      "avg / total       0.59      0.62      0.60        48\n",
      "\n",
      "[12  3  3  2 16  1  6  3  2]\n",
      "LR Accuracy:  0.625\n",
      "LR F1:  0.5491202899645096\n",
      "For name:  a_huang\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-5701-4521': 38, '0000-0002-5037-6829': 16, '0000-0002-7848-6755': 2, '0000-0003-1939-9149': 1, '0000-0003-1997-1758': 1})\n",
      "['0000-0002-5701-4521', '0000-0002-5037-6829']\n",
      "Total sample size after apply threshold:  54\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 40)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 16)\n",
      "2\n",
      "(54, 56)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.87      0.82        38\n",
      "          1       0.58      0.44      0.50        16\n",
      "\n",
      "avg / total       0.73      0.74      0.73        54\n",
      "\n",
      "[33  5  9  7]\n",
      "MNB Accuracy:  0.7407407407407407\n",
      "MNB F1:  0.6625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.95      0.88        38\n",
      "          1       0.80      0.50      0.62        16\n",
      "\n",
      "avg / total       0.81      0.81      0.80        54\n",
      "\n",
      "[36  2  8  8]\n",
      "svc Accuracy:  0.8148148148148148\n",
      "svc F1:  0.7467166979362101\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        38\n",
      "          1       1.00      0.25      0.40        16\n",
      "\n",
      "avg / total       0.83      0.78      0.73        54\n",
      "\n",
      "[38  0 12  4]\n",
      "LR Accuracy:  0.7777777777777778\n",
      "LR F1:  0.6318181818181818\n",
      "For name:  d_ghosh\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0002-6571-304X': 9, '0000-0003-0256-1998': 6, '0000-0003-3266-9262': 6, '0000-0001-9691-1498': 1, '0000-0001-8222-5737': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_morgan\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0003-1664-5316': 8, '0000-0003-0194-0304': 4, '0000-0002-3881-7257': 1, '0000-0002-2842-4441': 1, '0000-0002-7060-7735': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  q_li\n",
      "total sample size before apply threshold:  227\n",
      "Counter({'0000-0002-5941-1985': 36, '0000-0001-9565-0855': 33, '0000-0002-5993-0312': 20, '0000-0002-3934-6004': 20, '0000-0002-3876-0617': 15, '0000-0002-8447-9770': 14, '0000-0001-5015-0750': 14, '0000-0002-2450-3628': 11, '0000-0002-7280-5508': 8, '0000-0002-1644-0508': 7, '0000-0002-5143-6678': 6, '0000-0002-2870-4101': 5, '0000-0002-9522-073X': 5, '0000-0003-3370-471X': 5, '0000-0002-8792-0592': 4, '0000-0002-4822-2863': 3, '0000-0002-7724-1289': 3, '0000-0002-1838-3885': 2, '0000-0002-9128-7005': 2, '0000-0001-5699-9843': 2, '0000-0001-9365-3788': 2, '0000-0002-1116-7215': 2, '0000-0002-1990-8233': 2, '0000-0002-0105-4030': 1, '0000-0002-8633-8859': 1, '0000-0003-0463-1590': 1, '0000-0001-7526-2425': 1, '0000-0002-9023-6185': 1, '0000-0003-3752-4716': 1})\n",
      "['0000-0002-2450-3628', '0000-0002-3876-0617', '0000-0002-8447-9770', '0000-0002-5941-1985', '0000-0002-5993-0312', '0000-0001-5015-0750', '0000-0001-9565-0855', '0000-0002-3934-6004']\n",
      "Total sample size after apply threshold:  163\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(163, 84)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(163, 22)\n",
      "2\n",
      "(163, 106)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       0.62      0.53      0.57        15\n",
      "          2       1.00      0.07      0.13        14\n",
      "          3       0.55      0.67      0.60        36\n",
      "          4       0.48      0.50      0.49        20\n",
      "          5       0.73      0.57      0.64        14\n",
      "          6       0.48      0.82      0.61        33\n",
      "          7       0.60      0.45      0.51        20\n",
      "\n",
      "avg / total       0.62      0.55      0.52       163\n",
      "\n",
      "[ 2  0  0  1  0  0  8  0  0  8  0  1  2  0  2  2  0  0  1  5  3  1  4  0\n",
      "  0  1  0 24  1  1  6  3  0  2  0  4 10  1  3  0  0  0  0  2  0  8  4  0\n",
      "  0  0  0  3  2  0 27  1  0  2  0  4  3  0  2  9]\n",
      "MNB Accuracy:  0.5460122699386503\n",
      "MNB F1:  0.4826607972278019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.23      0.27      0.25        11\n",
      "          1       0.47      0.60      0.53        15\n",
      "          2       0.12      0.14      0.13        14\n",
      "          3       0.55      0.61      0.58        36\n",
      "          4       0.52      0.60      0.56        20\n",
      "          5       1.00      0.57      0.73        14\n",
      "          6       0.77      0.82      0.79        33\n",
      "          7       0.89      0.40      0.55        20\n",
      "\n",
      "avg / total       0.61      0.56      0.56       163\n",
      "\n",
      "[ 3  0  2  3  1  0  2  0  1  9  2  2  1  0  0  0  3  3  2  5  0  0  1  0\n",
      "  1  2  6 22  1  0  3  1  2  2  0  3 12  0  1  0  1  0  1  2  2  8  0  0\n",
      "  1  0  0  1  4  0 27  0  1  3  3  2  2  0  1  8]\n",
      "svc Accuracy:  0.558282208588957\n",
      "svc F1:  0.5153683142008219\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.27      0.40        11\n",
      "          1       0.57      0.53      0.55        15\n",
      "          2       0.20      0.07      0.11        14\n",
      "          3       0.50      0.75      0.60        36\n",
      "          4       0.50      0.55      0.52        20\n",
      "          5       0.64      0.64      0.64        14\n",
      "          6       0.77      0.82      0.79        33\n",
      "          7       0.60      0.45      0.51        20\n",
      "\n",
      "avg / total       0.58      0.58      0.56       163\n",
      "\n",
      "[ 3  0  0  3  0  2  2  1  0  8  1  2  2  0  1  1  0  1  1  9  2  1  0  0\n",
      "  0  0  1 27  1  1  3  3  0  3  0  4 11  1  1  0  0  0  0  4  1  9  0  0\n",
      "  0  0  0  3  2  0 27  1  1  2  2  2  3  0  1  9]\n",
      "LR Accuracy:  0.5828220858895705\n",
      "LR F1:  0.5165071654796219\n",
      "For name:  w_wang\n",
      "total sample size before apply threshold:  765\n",
      "Counter({'0000-0001-9033-0158': 194, '0000-0002-1430-1360': 101, '0000-0001-9093-412X': 39, '0000-0003-0509-2605': 30, '0000-0001-5983-3937': 29, '0000-0002-5369-5446': 28, '0000-0003-4287-1704': 27, '0000-0003-4053-5088': 24, '0000-0001-6022-1567': 21, '0000-0002-4309-9077': 19, '0000-0002-9852-1589': 19, '0000-0003-3987-9270': 16, '0000-0002-1935-6301': 15, '0000-0001-9208-7569': 14, '0000-0003-4163-3173': 14, '0000-0002-5257-7675': 13, '0000-0002-6652-5964': 13, '0000-0002-2269-1952': 13, '0000-0002-4628-1755': 12, '0000-0002-5943-4589': 11, '0000-0003-1319-1988': 10, '0000-0003-3007-1750': 9, '0000-0002-3780-5158': 8, '0000-0002-1083-6720': 7, '0000-0002-7762-7560': 6, '0000-0001-6587-8859': 5, '0000-0002-8330-9913': 5, '0000-0001-7496-4548': 5, '0000-0001-9568-3876': 4, '0000-0002-1260-2098': 4, '0000-0001-8947-4867': 4, '0000-0002-6154-7750': 4, '0000-0001-6109-1645': 4, '0000-0003-1567-2371': 4, '0000-0003-1788-2727': 4, '0000-0003-3941-4860': 4, '0000-0002-8814-525X': 3, '0000-0002-9303-516X': 3, '0000-0002-9865-6811': 2, '0000-0002-3245-9049': 2, '0000-0001-9223-6472': 2, '0000-0001-6818-7711': 2, '0000-0002-2468-5222': 2, '0000-0003-1930-4891': 1, '0000-0002-3116-5954': 1, '0000-0002-1225-4011': 1, '0000-0003-4712-3692': 1, '0000-0001-7511-3497': 1, '0000-0002-3709-021X': 1, '0000-0002-2914-1638': 1, '0000-0003-4426-019X': 1, '0000-0002-6983-2548': 1, '0000-0002-5812-6744': 1})\n",
      "['0000-0002-5369-5446', '0000-0002-4309-9077', '0000-0003-1319-1988', '0000-0003-3987-9270', '0000-0002-4628-1755', '0000-0001-5983-3937', '0000-0002-5257-7675', '0000-0001-9033-0158', '0000-0001-9093-412X', '0000-0003-0509-2605', '0000-0001-9208-7569', '0000-0003-4287-1704', '0000-0002-1935-6301', '0000-0002-1430-1360', '0000-0001-6022-1567', '0000-0002-6652-5964', '0000-0002-9852-1589', '0000-0003-4053-5088', '0000-0002-2269-1952', '0000-0002-5943-4589', '0000-0003-4163-3173']\n",
      "Total sample size after apply threshold:  662\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(662, 286)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(662, 21)\n",
      "2\n",
      "(662, 307)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        28\n",
      "          1       0.00      0.00      0.00        19\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.00      0.00      0.00        12\n",
      "          5       1.00      0.10      0.19        29\n",
      "          6       0.00      0.00      0.00        13\n",
      "          7       0.36      0.99      0.53       194\n",
      "          8       1.00      0.05      0.10        39\n",
      "          9       1.00      0.03      0.06        30\n",
      "         10       0.00      0.00      0.00        14\n",
      "         11       1.00      0.07      0.14        27\n",
      "         12       0.00      0.00      0.00        15\n",
      "         13       0.46      0.45      0.45       101\n",
      "         14       0.00      0.00      0.00        21\n",
      "         15       0.00      0.00      0.00        13\n",
      "         16       1.00      0.16      0.27        19\n",
      "         17       0.69      0.38      0.49        24\n",
      "         18       0.00      0.00      0.00        13\n",
      "         19       0.00      0.00      0.00        11\n",
      "         20       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.42      0.39      0.27       662\n",
      "\n",
      "[  0   0   0   0   0   0   0  23   0   0   0   0   0   5   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18   0   0   0   0   0   1   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0\n",
      "   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13   0\n",
      "   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   3   0  24   0   0   0   0   0   2   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  11   0   0   0   0   0   2   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 193   0   0   0   0   0   1   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  30   2   0   0   0\n",
      "   0   5   0   0   0   2   0   0   0   0   0   0   0   0   0   0  25   0\n",
      "   1   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  11   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  18   0   0   0   2   0   6   0   0   0   1   0   0   0\n",
      "   0   0   0   0   0   0   0  15   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  56   0   0   0   0   0  45   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0   0   0   0\n",
      "   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0  12   0\n",
      "   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  13   0   0   0   0   0   3   0   0   3   0   0   0   0   0   0   0\n",
      "   0   0   0   0  10   0   0   0   0   0   5   0   0   0   9   0   0   0\n",
      "   0   0   0   0   0   0   0  10   0   0   0   0   0   3   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0\n",
      "   0   4   0   0   0   1   0   0   0]\n",
      "MNB Accuracy:  0.38972809667673713\n",
      "MNB F1:  0.1060208295671999\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.36      0.34        28\n",
      "          1       0.83      0.79      0.81        19\n",
      "          2       0.29      0.20      0.24        10\n",
      "          3       1.00      0.38      0.55        16\n",
      "          4       0.40      0.33      0.36        12\n",
      "          5       0.54      0.66      0.59        29\n",
      "          6       0.45      0.38      0.42        13\n",
      "          7       0.98      0.95      0.96       194\n",
      "          8       0.55      0.44      0.49        39\n",
      "          9       0.88      0.23      0.37        30\n",
      "         10       0.57      0.29      0.38        14\n",
      "         11       0.67      0.37      0.48        27\n",
      "         12       0.33      0.20      0.25        15\n",
      "         13       0.41      0.85      0.55       101\n",
      "         14       1.00      0.14      0.25        21\n",
      "         15       0.00      0.00      0.00        13\n",
      "         16       0.69      0.58      0.63        19\n",
      "         17       0.39      0.62      0.48        24\n",
      "         18       0.33      0.23      0.27        13\n",
      "         19       0.50      0.36      0.42        11\n",
      "         20       0.33      0.07      0.12        14\n",
      "\n",
      "avg / total       0.66      0.62      0.60       662\n",
      "\n",
      "[ 10   0   0   0   0   0   0   0   0   0   0   1   0  15   0   0   0   2\n",
      "   0   0   0   0  15   0   0   0   0   0   0   1   0   1   0   0   0   0\n",
      "   0   0   1   0   1   0   0   0   2   0   0   2   5   0   0   0   0   0\n",
      "   1   0   0   0   0   0   0   0   0   1   0   0   6   0   0   0   0   0\n",
      "   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   4   3\n",
      "   0   0   1   0   0   0   1   2   0   0   0   0   0   1   0   0   1   1\n",
      "   0   2  19   0   1   0   1   0   0   1   2   0   0   0   0   0   1   0\n",
      "   0   0   4   0   0   0   5   0   1   0   0   0   0   3   0   0   0   0\n",
      "   0   0   0   1   0   0   0   0   3   0 184   0   0   0   0   1   5   0\n",
      "   0   0   0   0   0   0   1   0   0   0   0   0   0   0  17   0   0   0\n",
      "   0  15   0   0   0   6   0   0   0   2   0   0   0   0   0   0   0   1\n",
      "   7   0   1   0  17   0   0   0   2   0   0   0   1   1   0   0   1   0\n",
      "   0   0   0   0   4   0   0   6   0   0   0   0   0   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  10   0  11   0   0   0   6   0   0   0\n",
      "   0   0   0   0   2   1   1   2   0   0   0   0   3   5   0   0   0   0\n",
      "   1   0   0   9   0   0   0   0   0   0   0   1   0   0   3   0  86   0\n",
      "   0   0   2   0   0   0   3   0   0   0   0   0   0   0   2   0   0   0\n",
      "   0  13   3   0   0   0   0   0   0   3   0   0   0   0   0   0   1   0\n",
      "   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   6   0   0  11   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   5   0   0   0   0   4   0   0   0  15   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   1   0   2   1   0   0   4   0\n",
      "   3   0   2   0   0   0   0   1   4   0   0   1   0   1   0   0   0   0\n",
      "   0   0   0   0   4   0   0   1   0   0   0   3   0   0   1   0   0   0\n",
      "   0   0   0   0   1   4   3   0   1]\n",
      "svc Accuracy:  0.6178247734138973\n",
      "svc F1:  0.42656821928630817\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.35      0.21      0.27        28\n",
      "          1       0.92      0.58      0.71        19\n",
      "          2       0.50      0.30      0.37        10\n",
      "          3       1.00      0.06      0.12        16\n",
      "          4       0.50      0.17      0.25        12\n",
      "          5       0.65      0.38      0.48        29\n",
      "          6       0.71      0.38      0.50        13\n",
      "          7       0.76      0.95      0.84       194\n",
      "          8       0.57      0.41      0.48        39\n",
      "          9       1.00      0.17      0.29        30\n",
      "         10       0.00      0.00      0.00        14\n",
      "         11       0.46      0.22      0.30        27\n",
      "         12       0.00      0.00      0.00        15\n",
      "         13       0.34      0.84      0.49       101\n",
      "         14       0.00      0.00      0.00        21\n",
      "         15       0.00      0.00      0.00        13\n",
      "         16       0.62      0.42      0.50        19\n",
      "         17       0.33      0.50      0.40        24\n",
      "         18       0.20      0.08      0.11        13\n",
      "         19       1.00      0.27      0.43        11\n",
      "         20       0.33      0.07      0.12        14\n",
      "\n",
      "avg / total       0.55      0.55      0.49       662\n",
      "\n",
      "[  6   0   0   0   0   0   0   4   0   0   0   0   0  15   0   0   0   3\n",
      "   0   0   0   0  11   0   0   0   0   0   2   1   0   1   1   0   3   0\n",
      "   0   0   0   0   0   0   0   0   3   0   0   1   2   1   0   0   0   0\n",
      "   0   3   0   0   0   0   0   0   0   3   0   0   1   0   0   0   2   0\n",
      "   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   2   1\n",
      "   0   3   1   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  11   0   8   1   0   0   0   0   8   0   0   0   1   0   0   0\n",
      "   0   0   3   0   0   0   5   0   1   0   0   0   0   4   0   0   0   0\n",
      "   0   0   0   1   0   0   0   0   3   0 185   0   0   0   0   0   5   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   4  16   0   0   1\n",
      "   0  14   0   0   0   4   0   0   0   1   0   0   0   0   0   0   2   1\n",
      "   5   0   2   0  18   0   0   0   1   0   0   0   1   0   0   0   0   0\n",
      "   0   1   0   0   0   0   0  12   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   6   0  14   0   0   0   6   0   0   0\n",
      "   0   0   0   0   1   0   0   7   0   0   0   0   0   7   0   0   0   0\n",
      "   0   0   0   2   0   0   0   0   0   0  10   1   0   0   1   0  85   0\n",
      "   0   0   2   0   0   0   1   0   0   0   0   0   0   4   2   0   0   0\n",
      "   0  14   0   0   0   0   0   0   0   2   0   0   0   0   0   0   4   0\n",
      "   0   0   0   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   2   0   0   0   0   0   7   0   0   8   1   1   0   0   0   0   0\n",
      "   0   0   0   0   1   3   0   0   1   0   7   0   0   0  12   0   0   0\n",
      "   0   0   0   0   0   0   0   3   0   0   0   0   0   2   0   0   5   0\n",
      "   1   0   2   0   0   0   0   1   1   0   1   0   0   0   1   0   3   0\n",
      "   0   0   1   0   3   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "   0   4   0   0   0   5   3   0   1]\n",
      "LR Accuracy:  0.5453172205438066\n",
      "LR F1:  0.3167220211668114\n",
      "For name:  r_ross\n",
      "total sample size before apply threshold:  374\n",
      "Counter({'0000-0003-4876-8839': 356, '0000-0002-3987-881X': 17, '0000-0002-7825-9974': 1})\n",
      "['0000-0003-4876-8839', '0000-0002-3987-881X']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size after apply threshold:  373\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(373, 113)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(373, 23)\n",
      "2\n",
      "(373, 136)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97       356\n",
      "          1       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.91      0.95      0.93       373\n",
      "\n",
      "[354   2  17   0]\n",
      "MNB Accuracy:  0.9490616621983914\n",
      "MNB F1:  0.4869325997248969\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       356\n",
      "          1       1.00      0.47      0.64        17\n",
      "\n",
      "avg / total       0.98      0.98      0.97       373\n",
      "\n",
      "[356   0   9   8]\n",
      "svc Accuracy:  0.9758713136729222\n",
      "svc F1:  0.81375866851595\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98       356\n",
      "          1       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.91      0.95      0.93       373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[356   0  17   0]\n",
      "LR Accuracy:  0.9544235924932976\n",
      "LR F1:  0.4883401920438957\n",
      "For name:  k_yamamoto\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0002-7935-7015': 93, '0000-0003-0866-3207': 4, '0000-0002-7590-3568': 4, '0000-0001-6642-7961': 2, '0000-0002-6831-5346': 2, '0000-0002-1619-4407': 1})\n",
      "['0000-0002-7935-7015']\n",
      "Total sample size after apply threshold:  93\n",
      "For name:  j_silva\n",
      "total sample size before apply threshold:  268\n",
      "Counter({'0000-0001-9523-9441': 128, '0000-0003-3977-7418': 28, '0000-0002-3696-3955': 22, '0000-0002-6725-5767': 14, '0000-0003-2583-9518': 13, '0000-0001-9959-4272': 8, '0000-0002-5656-0897': 7, '0000-0001-9487-4259': 6, '0000-0002-6041-1763': 6, '0000-0002-1520-0799': 4, '0000-0001-8055-8925': 3, '0000-0001-9708-1043': 3, '0000-0002-7268-6465': 3, '0000-0003-1224-1699': 2, '0000-0002-7211-1661': 2, '0000-0002-7206-0550': 2, '0000-0003-1244-6483': 2, '0000-0003-4180-565X': 2, '0000-0001-9522-6181': 2, '0000-0001-9554-8797': 2, '0000-0002-6455-9618': 1, '0000-0003-2863-8068': 1, '0000-0003-2318-3893': 1, '0000-0002-9230-7135': 1, '0000-0003-4773-6771': 1, '0000-0002-1134-1252': 1, '0000-0002-1956-5779': 1, '0000-0003-1778-3833': 1, '0000-0001-5722-0213': 1})\n",
      "['0000-0002-6725-5767', '0000-0003-2583-9518', '0000-0003-3977-7418', '0000-0002-3696-3955', '0000-0001-9523-9441']\n",
      "Total sample size after apply threshold:  205\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(205, 88)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(205, 29)\n",
      "2\n",
      "(205, 117)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.35        14\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.73      0.29      0.41        28\n",
      "          3       0.67      0.09      0.16        22\n",
      "          4       0.67      0.98      0.80       128\n",
      "\n",
      "avg / total       0.66      0.68      0.60       205\n",
      "\n",
      "[  3   0   1   0  10   0   0   0   0  13   0   0   8   0  20   0   0   1\n",
      "   2  19   0   0   1   1 126]\n",
      "MNB Accuracy:  0.6780487804878049\n",
      "MNB F1:  0.34413318823147565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        14\n",
      "          1       0.71      0.38      0.50        13\n",
      "          2       0.93      0.50      0.65        28\n",
      "          3       0.83      0.23      0.36        22\n",
      "          4       0.75      0.98      0.85       128\n",
      "\n",
      "avg / total       0.80      0.78      0.75       205\n",
      "\n",
      "[ 11   0   0   0   3   0   5   0   0   8   0   1  14   0  13   0   0   0\n",
      "   5  17   0   1   1   1 125]\n",
      "svc Accuracy:  0.7804878048780488\n",
      "svc F1:  0.6477291567789907\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        14\n",
      "          1       1.00      0.15      0.27        13\n",
      "          2       1.00      0.29      0.44        28\n",
      "          3       1.00      0.09      0.17        22\n",
      "          4       0.68      1.00      0.81       128\n",
      "\n",
      "avg / total       0.80      0.71      0.64       205\n",
      "\n",
      "[  6   0   0   0   8   0   2   0   0  11   0   0   8   0  20   0   0   0\n",
      "   2  20   0   0   0   0 128]\n",
      "LR Accuracy:  0.7121951219512195\n",
      "LR F1:  0.45809523809523806\n",
      "For name:  m_pellegrini\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0003-3817-4412': 31, '0000-0001-8505-9260': 15, '0000-0001-9355-9564': 14, '0000-0003-4878-4505': 3, '0000-0003-3527-9542': 1})\n",
      "['0000-0001-9355-9564', '0000-0003-3817-4412', '0000-0001-8505-9260']\n",
      "Total sample size after apply threshold:  60\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 38)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 17)\n",
      "2\n",
      "(60, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       0.76      0.84      0.80        31\n",
      "          2       0.58      0.47      0.52        15\n",
      "\n",
      "avg / total       0.77      0.78      0.78        60\n",
      "\n",
      "[14  0  0  0 26  5  0  8  7]\n",
      "MNB Accuracy:  0.7833333333333333\n",
      "MNB F1:  0.7728395061728395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       0.74      0.81      0.77        31\n",
      "          2       0.50      0.40      0.44        15\n",
      "\n",
      "avg / total       0.74      0.75      0.74        60\n",
      "\n",
      "[14  0  0  0 25  6  0  9  6]\n",
      "svc Accuracy:  0.75\n",
      "svc F1:  0.7378917378917379\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       0.71      0.87      0.78        31\n",
      "          2       0.50      0.27      0.35        15\n",
      "\n",
      "avg / total       0.73      0.75      0.72        60\n",
      "\n",
      "[14  0  0  0 27  4  0 11  4]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.7101449275362319\n",
      "For name:  s_kwon\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-8490-9101': 17, '0000-0002-0679-1523': 15, '0000-0002-1857-3515': 9, '0000-0002-8215-442X': 5, '0000-0001-5265-862X': 1, '0000-0002-9121-3954': 1, '0000-0003-0249-4190': 1, '0000-0001-9287-4490': 1, '0000-0003-1147-8037': 1})\n",
      "['0000-0002-0679-1523', '0000-0002-8490-9101']\n",
      "Total sample size after apply threshold:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 24)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 16)\n",
      "2\n",
      "(32, 40)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.80      0.75        15\n",
      "          1       0.80      0.71      0.75        17\n",
      "\n",
      "avg / total       0.76      0.75      0.75        32\n",
      "\n",
      "[12  3  5 12]\n",
      "MNB Accuracy:  0.75\n",
      "MNB F1:  0.7500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80        15\n",
      "          1       0.82      0.82      0.82        17\n",
      "\n",
      "avg / total       0.81      0.81      0.81        32\n",
      "\n",
      "[12  3  3 14]\n",
      "svc Accuracy:  0.8125\n",
      "svc F1:  0.8117647058823529\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.67      0.69        15\n",
      "          1       0.72      0.76      0.74        17\n",
      "\n",
      "avg / total       0.72      0.72      0.72        32\n",
      "\n",
      "[10  5  4 13]\n",
      "LR Accuracy:  0.71875\n",
      "LR F1:  0.7162561576354679\n",
      "For name:  m_correa\n",
      "total sample size before apply threshold:  72\n",
      "Counter({'0000-0002-9868-3131': 63, '0000-0003-4856-7578': 7, '0000-0001-8464-2673': 1, '0000-0003-4985-3330': 1})\n",
      "['0000-0002-9868-3131']\n",
      "Total sample size after apply threshold:  63\n",
      "For name:  a_pal\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0003-3893-1305': 6, '0000-0002-0850-3118': 4, '0000-0001-5425-5218': 3, '0000-0001-7615-7811': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  v_costa\n",
      "total sample size before apply threshold:  141\n",
      "Counter({'0000-0002-0471-2756': 33, '0000-0002-7868-4663': 32, '0000-0002-7294-6933': 27, '0000-0002-2113-7482': 18, '0000-0002-5412-8945': 18, '0000-0001-8188-831X': 7, '0000-0002-1513-0284': 2, '0000-0001-5786-633X': 2, '0000-0003-0122-3567': 1, '0000-0001-8801-5669': 1})\n",
      "['0000-0002-2113-7482', '0000-0002-7294-6933', '0000-0002-5412-8945', '0000-0002-0471-2756', '0000-0002-7868-4663']\n",
      "Total sample size after apply threshold:  128\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(128, 83)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(128, 17)\n",
      "2\n",
      "(128, 100)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.33      0.44        18\n",
      "          1       0.41      0.26      0.32        27\n",
      "          2       0.80      0.22      0.35        18\n",
      "          3       0.38      0.76      0.51        33\n",
      "          4       0.44      0.44      0.44        32\n",
      "\n",
      "avg / total       0.50      0.44      0.42       128\n",
      "\n",
      "[ 6  2  1  8  1  2  7  0 11  7  0  1  4  8  5  0  3  0 25  5  1  4  0 13\n",
      " 14]\n",
      "MNB Accuracy:  0.4375\n",
      "MNB F1:  0.4116312862430875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        18\n",
      "          1       0.35      0.26      0.30        27\n",
      "          2       1.00      0.56      0.71        18\n",
      "          3       0.52      0.76      0.62        33\n",
      "          4       0.45      0.53      0.49        32\n",
      "\n",
      "avg / total       0.60      0.55      0.56       128\n",
      "\n",
      "[12  2  0  2  2  0  7  0  9 11  0  1 10  4  3  0  3  0 25  5  0  7  0  8\n",
      " 17]\n",
      "svc Accuracy:  0.5546875\n",
      "svc F1:  0.5830312582085633\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        18\n",
      "          1       0.35      0.26      0.30        27\n",
      "          2       0.88      0.39      0.54        18\n",
      "          3       0.49      0.73      0.59        33\n",
      "          4       0.45      0.59      0.51        32\n",
      "\n",
      "avg / total       0.58      0.52      0.51       128\n",
      "\n",
      "[ 9  2  0  5  2  0  7  0 10 10  0  2  7  3  6  0  3  1 24  5  0  6  0  7\n",
      " 19]\n",
      "LR Accuracy:  0.515625\n",
      "LR F1:  0.5203759825451575\n",
      "For name:  j_allen\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0001-5219-4423': 36, '0000-0002-3829-066X': 27, '0000-0001-9974-4226': 12, '0000-0003-3566-3747': 12, '0000-0003-4740-9404': 11, '0000-0002-3894-4854': 5, '0000-0002-6576-2132': 3, '0000-0002-0950-0429': 3, '0000-0002-3084-7785': 1, '0000-0002-6717-8693': 1})\n",
      "['0000-0002-3829-066X', '0000-0003-4740-9404', '0000-0001-9974-4226', '0000-0003-3566-3747', '0000-0001-5219-4423']\n",
      "Total sample size after apply threshold:  98\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 70)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 16)\n",
      "2\n",
      "(98, 86)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.81      0.68        27\n",
      "          1       0.50      0.09      0.15        11\n",
      "          2       1.00      0.17      0.29        12\n",
      "          3       0.50      0.08      0.14        12\n",
      "          4       0.54      0.81      0.64        36\n",
      "\n",
      "avg / total       0.60      0.56      0.49        98\n",
      "\n",
      "[22  0  0  0  5  3  1  0  0  7  4  0  2  0  6  3  1  0  1  7  6  0  0  1\n",
      " 29]\n",
      "MNB Accuracy:  0.5612244897959183\n",
      "MNB F1:  0.3807570207570208\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.81      0.71        27\n",
      "          1       0.89      0.73      0.80        11\n",
      "          2       1.00      0.67      0.80        12\n",
      "          3       0.60      0.25      0.35        12\n",
      "          4       0.71      0.81      0.75        36\n",
      "\n",
      "avg / total       0.73      0.71      0.70        98\n",
      "\n",
      "[22  0  0  0  5  2  8  0  1  0  2  0  8  0  2  3  1  0  3  5  6  0  0  1\n",
      " 29]\n",
      "svc Accuracy:  0.7142857142857143\n",
      "svc F1:  0.683173069814436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.78      0.68        27\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       1.00      0.25      0.40        12\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.53      0.86      0.65        36\n",
      "\n",
      "avg / total       0.59      0.57      0.49        98\n",
      "\n",
      "[21  0  0  0  6  2  1  0  0  8  4  0  3  0  5  3  0  0  0  9  5  0  0  0\n",
      " 31]\n",
      "LR Accuracy:  0.5714285714285714\n",
      "LR F1:  0.379343520090549\n",
      "For name:  y_dong\n",
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0003-0016-9028': 42, '0000-0002-1737-6536': 16, '0000-0003-4550-2322': 9, '0000-0003-1294-4888': 4, '0000-0002-4129-4637': 2, '0000-0001-8595-2868': 2, '0000-0003-1774-1553': 1})\n",
      "['0000-0002-1737-6536', '0000-0003-0016-9028']\n",
      "Total sample size after apply threshold:  58\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(58, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(58, 13)\n",
      "2\n",
      "(58, 44)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.25      0.35        16\n",
      "          1       0.76      0.93      0.84        42\n",
      "\n",
      "avg / total       0.71      0.74      0.70        58\n",
      "\n",
      "[ 4 12  3 39]\n",
      "MNB Accuracy:  0.7413793103448276\n",
      "MNB F1:  0.5932678821879382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.31      0.43        16\n",
      "          1       0.78      0.95      0.86        42\n",
      "\n",
      "avg / total       0.76      0.78      0.74        58\n",
      "\n",
      "[ 5 11  2 40]\n",
      "svc Accuracy:  0.7758620689655172\n",
      "svc F1:  0.6474988312295464\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.12        16\n",
      "          1       0.74      1.00      0.85        42\n",
      "\n",
      "avg / total       0.81      0.74      0.65        58\n",
      "\n",
      "[ 1 15  0 42]\n",
      "LR Accuracy:  0.7413793103448276\n",
      "LR F1:  0.4830659536541889\n",
      "For name:  m_fitzgerald\n",
      "total sample size before apply threshold:  133\n",
      "Counter({'0000-0003-0183-7761': 81, '0000-0002-4823-8179': 38, '0000-0002-4535-0966': 10, '0000-0002-0176-8973': 4})\n",
      "['0000-0002-4535-0966', '0000-0002-4823-8179', '0000-0003-0183-7761']\n",
      "Total sample size after apply threshold:  129\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(129, 63)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(129, 17)\n",
      "2\n",
      "(129, 80)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.65      0.39      0.49        38\n",
      "          2       0.75      0.95      0.84        81\n",
      "\n",
      "avg / total       0.74      0.74      0.71       129\n",
      "\n",
      "[ 3  4  3  0 15 23  0  4 77]\n",
      "MNB Accuracy:  0.7364341085271318\n",
      "MNB F1:  0.5967660873220388\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       0.67      0.58      0.62        38\n",
      "          2       0.80      0.88      0.84        81\n",
      "\n",
      "avg / total       0.77      0.78      0.77       129\n",
      "\n",
      "[ 7  1  2  0 22 16  0 10 71]\n",
      "svc Accuracy:  0.7751937984496124\n",
      "svc F1:  0.7595139464236399\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.67      0.32      0.43        38\n",
      "          2       0.71      0.95      0.81        81\n",
      "\n",
      "avg / total       0.72      0.71      0.67       129\n",
      "\n",
      "[ 3  2  5  0 12 26  0  4 77]\n",
      "LR Accuracy:  0.7131782945736435\n",
      "LR F1:  0.5683082349749017\n",
      "For name:  m_ferreira\n",
      "total sample size before apply threshold:  253\n",
      "Counter({'0000-0002-5293-9090': 80, '0000-0002-6814-6773': 33, '0000-0002-9459-8167': 23, '0000-0001-8362-0819': 16, '0000-0003-2098-066X': 15, '0000-0002-0856-9811': 14, '0000-0002-0075-2400': 10, '0000-0002-2071-9851': 10, '0000-0002-8452-2222': 10, '0000-0002-7909-637X': 6, '0000-0001-6789-3796': 5, '0000-0001-8962-7157': 4, '0000-0001-9609-5099': 4, '0000-0003-1137-9776': 4, '0000-0001-6475-9401': 3, '0000-0001-8316-7022': 3, '0000-0002-3740-6069': 3, '0000-0001-5586-6328': 2, '0000-0002-4294-7003': 2, '0000-0002-4741-8661': 2, '0000-0002-0595-620X': 1, '0000-0002-0159-7422': 1, '0000-0002-2437-7780': 1, '0000-0003-0570-6259': 1})\n",
      "['0000-0002-0075-2400', '0000-0003-2098-066X', '0000-0002-2071-9851', '0000-0002-5293-9090', '0000-0002-0856-9811', '0000-0001-8362-0819', '0000-0002-9459-8167', '0000-0002-6814-6773', '0000-0002-8452-2222']\n",
      "Total sample size after apply threshold:  211\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(211, 111)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(211, 25)\n",
      "2\n",
      "(211, 136)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.50      0.96      0.66        80\n",
      "          4       1.00      0.29      0.44        14\n",
      "          5       0.57      0.25      0.35        16\n",
      "          6       0.38      0.26      0.31        23\n",
      "          7       0.72      0.39      0.51        33\n",
      "          8       0.82      0.90      0.86        10\n",
      "\n",
      "avg / total       0.49      0.54      0.46       211\n",
      "\n",
      "[ 0  0  0  7  0  1  2  0  0  0  0  0 15  0  0  0  0  0  0  0  0  7  0  0\n",
      "  3  0  0  0  1  0 77  0  0  0  2  0  0  0  0  6  4  1  2  1  0  0  0  0\n",
      "  9  0  4  3  0  0  0  0  0 13  0  1  6  2  1  0  0  0 19  0  0  0 13  1\n",
      "  0  0  0  1  0  0  0  0  9]\n",
      "MNB Accuracy:  0.5355450236966824\n",
      "MNB F1:  0.34722547510271295\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.73      0.53      0.62        15\n",
      "          2       0.43      0.30      0.35        10\n",
      "          3       0.61      0.97      0.75        80\n",
      "          4       0.86      0.43      0.57        14\n",
      "          5       0.62      0.31      0.42        16\n",
      "          6       0.50      0.39      0.44        23\n",
      "          7       1.00      0.52      0.68        33\n",
      "          8       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.67      0.64      0.61       211\n",
      "\n",
      "[ 0  0  0  7  0  1  2  0  0  1  8  0  6  0  0  0  0  0  0  0  3  2  1  0\n",
      "  4  0  0  0  0  0 78  0  2  0  0  0  1  0  0  5  6  0  2  0  0  1  0  1\n",
      "  8  0  5  1  0  0  1  3  3  7  0  0  9  0  0  1  0  0 15  0  0  0 17  0\n",
      "  1  0  0  0  0  0  0  0  9]\n",
      "svc Accuracy:  0.6398104265402843\n",
      "svc F1:  0.5303126490274417\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.07      0.12        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.50      0.97      0.66        80\n",
      "          4       0.86      0.43      0.57        14\n",
      "          5       0.71      0.31      0.43        16\n",
      "          6       0.50      0.30      0.38        23\n",
      "          7       0.86      0.36      0.51        33\n",
      "          8       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.61      0.56      0.50       211\n",
      "\n",
      "[ 0  0  0  8  0  0  2  0  0  0  1  0 14  0  0  0  0  0  0  0  0  8  0  0\n",
      "  2  0  0  0  0  0 78  0  1  0  1  0  0  0  0  6  6  0  2  0  0  0  0  0\n",
      " 10  0  5  1  0  0  0  0  2 12  1  0  7  1  0  0  0  0 20  0  1  0 12  0\n",
      "  0  0  0  1  0  0  0  0  9]\n",
      "LR Accuracy:  0.5592417061611374\n",
      "LR F1:  0.40286934728098217\n",
      "For name:  m_roberts\n",
      "total sample size before apply threshold:  320\n",
      "Counter({'0000-0003-3894-5301': 251, '0000-0002-1441-7363': 26, '0000-0003-0552-7402': 20, '0000-0002-8010-1068': 15, '0000-0002-9396-9720': 3, '0000-0002-0931-9363': 2, '0000-0002-2220-582X': 1, '0000-0003-2693-5093': 1, '0000-0003-2769-7365': 1})\n",
      "['0000-0003-0552-7402', '0000-0002-8010-1068', '0000-0003-3894-5301', '0000-0002-1441-7363']\n",
      "Total sample size after apply threshold:  312\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(312, 137)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(312, 39)\n",
      "2\n",
      "(312, 176)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.30      0.44        20\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.83      1.00      0.90       251\n",
      "          3       1.00      0.04      0.07        26\n",
      "\n",
      "avg / total       0.80      0.83      0.76       312\n",
      "\n",
      "[  6   0  14   0   1   0  14   0   0   0 251   0   0   0  25   1]\n",
      "MNB Accuracy:  0.8269230769230769\n",
      "MNB F1:  0.3557557557557558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.40      0.43        20\n",
      "          1       0.80      0.27      0.40        15\n",
      "          2       0.89      0.98      0.94       251\n",
      "          3       1.00      0.58      0.73        26\n",
      "\n",
      "avg / total       0.87      0.88      0.86       312\n",
      "\n",
      "[  8   0  12   0   2   4   9   0   5   0 246   0   2   1   8  15]\n",
      "svc Accuracy:  0.875\n",
      "svc F1:  0.6248752415589103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.05      0.09        20\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.81      0.99      0.89       251\n",
      "          3       0.00      0.00      0.00        26\n",
      "\n",
      "avg / total       0.67      0.80      0.72       312\n",
      "\n",
      "[  1   0  19   0   0   0  15   0   2   0 249   0   0   0  26   0]\n",
      "LR Accuracy:  0.8012820512820513\n",
      "LR F1:  0.24406055900621118\n",
      "For name:  y_lim\n",
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0002-3484-045X': 21, '0000-0002-8472-289X': 21, '0000-0003-1377-7655': 10, '0000-0002-4181-2916': 8, '0000-0001-5000-5991': 5, '0000-0003-4390-4010': 3, '0000-0003-4050-6332': 2, '0000-0002-3408-8595': 2, '0000-0002-0346-2345': 1, '0000-0002-3279-332X': 1, '0000-0002-4082-3322': 1, '0000-0003-3678-0080': 1})\n",
      "['0000-0002-3484-045X', '0000-0003-1377-7655', '0000-0002-8472-289X']\n",
      "Total sample size after apply threshold:  52\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 14)\n",
      "2\n",
      "(52, 44)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.95      0.78        21\n",
      "          1       0.60      0.30      0.40        10\n",
      "          2       0.82      0.67      0.74        21\n",
      "\n",
      "avg / total       0.72      0.71      0.69        52\n",
      "\n",
      "[20  0  1  5  3  2  5  2 14]\n",
      "MNB Accuracy:  0.7115384615384616\n",
      "MNB F1:  0.6403852769177846\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.86      0.88        21\n",
      "          1       0.50      0.30      0.37        10\n",
      "          2       0.69      0.86      0.77        21\n",
      "\n",
      "avg / total       0.74      0.75      0.74        52\n",
      "\n",
      "[18  1  2  1  3  6  1  2 18]\n",
      "svc Accuracy:  0.75\n",
      "svc F1:  0.6730020757654386\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.86      0.86        21\n",
      "          1       0.60      0.30      0.40        10\n",
      "          2       0.69      0.86      0.77        21\n",
      "\n",
      "avg / total       0.74      0.75      0.73        52\n",
      "\n",
      "[18  0  3  2  3  5  1  2 18]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.6743667679837894\n",
      "For name:  g_miller\n",
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0002-4743-8187': 26, '0000-0001-8984-1284': 23, '0000-0001-6533-3306': 13, '0000-0003-4527-3814': 11, '0000-0002-1108-0654': 3})\n",
      "['0000-0001-6533-3306', '0000-0001-8984-1284', '0000-0003-4527-3814', '0000-0002-4743-8187']\n",
      "Total sample size after apply threshold:  73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 47)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 14)\n",
      "2\n",
      "(73, 61)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.31      0.44        13\n",
      "          1       0.64      1.00      0.78        23\n",
      "          2       0.75      0.27      0.40        11\n",
      "          3       0.75      0.81      0.78        26\n",
      "\n",
      "avg / total       0.72      0.70      0.66        73\n",
      "\n",
      "[ 4  7  1  1  0 23  0  0  0  2  3  6  1  4  0 21]\n",
      "MNB Accuracy:  0.6986301369863014\n",
      "MNB F1:  0.6004708097928437\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.38      0.48        13\n",
      "          1       0.57      0.87      0.69        23\n",
      "          2       0.60      0.27      0.37        11\n",
      "          3       0.68      0.65      0.67        26\n",
      "\n",
      "avg / total       0.62      0.62      0.60        73\n",
      "\n",
      "[ 5  7  1  0  1 20  0  2  1  1  3  6  1  7  1 17]\n",
      "svc Accuracy:  0.6164383561643836\n",
      "svc F1:  0.551878078817734\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.31      0.44        13\n",
      "          1       0.59      0.87      0.70        23\n",
      "          2       1.00      0.27      0.43        11\n",
      "          3       0.65      0.77      0.70        26\n",
      "\n",
      "avg / total       0.71      0.64      0.61        73\n",
      "\n",
      "[ 4  7  0  2  0 20  0  3  0  2  3  6  1  5  0 20]\n",
      "LR Accuracy:  0.6438356164383562\n",
      "LR F1:  0.5691311612364245\n",
      "For name:  x_kong\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0003-0676-6923': 34, '0000-0002-4475-2162': 10, '0000-0002-1725-4619': 6, '0000-0003-0659-4084': 6, '0000-0002-8554-0369': 6, '0000-0002-2195-268X': 3, '0000-0003-3290-025X': 2, '0000-0003-1039-494X': 1, '0000-0003-2698-3319': 1})\n",
      "['0000-0002-4475-2162', '0000-0003-0676-6923']\n",
      "Total sample size after apply threshold:  44\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 16)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 11)\n",
      "2\n",
      "(44, 27)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.70      0.78        10\n",
      "          1       0.92      0.97      0.94        34\n",
      "\n",
      "avg / total       0.91      0.91      0.91        44\n",
      "\n",
      "[ 7  3  1 33]\n",
      "MNB Accuracy:  0.9090909090909091\n",
      "MNB F1:  0.8603174603174603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.94      1.00      0.97        34\n",
      "\n",
      "avg / total       0.96      0.95      0.95        44\n",
      "\n",
      "[ 8  2  0 34]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.9301587301587302\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.83      1.00      0.91        34\n",
      "\n",
      "avg / total       0.87      0.84      0.81        44\n",
      "\n",
      "[ 3  7  0 34]\n",
      "LR Accuracy:  0.8409090909090909\n",
      "LR F1:  0.6841025641025641\n",
      "For name:  w_cao\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0002-2447-1486': 91, '0000-0002-8952-9159': 27, '0000-0002-5369-9682': 7, '0000-0001-6209-3482': 1})\n",
      "['0000-0002-8952-9159', '0000-0002-2447-1486']\n",
      "Total sample size after apply threshold:  118\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(118, 62)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(118, 21)\n",
      "2\n",
      "(118, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.52      0.58        27\n",
      "          1       0.87      0.92      0.89        91\n",
      "\n",
      "avg / total       0.82      0.83      0.82       118\n",
      "\n",
      "[14 13  7 84]\n",
      "MNB Accuracy:  0.8305084745762712\n",
      "MNB F1:  0.7384751773049645\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.37      0.50        27\n",
      "          1       0.84      0.97      0.90        91\n",
      "\n",
      "avg / total       0.82      0.83      0.81       118\n",
      "\n",
      "[10 17  3 88]\n",
      "svc Accuracy:  0.8305084745762712\n",
      "svc F1:  0.6989795918367347\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.19      0.30        27\n",
      "          1       0.80      0.99      0.89        91\n",
      "\n",
      "avg / total       0.81      0.81      0.75       118\n",
      "\n",
      "[ 5 22  1 90]\n",
      "LR Accuracy:  0.8050847457627118\n",
      "LR F1:  0.5948649052097328\n",
      "For name:  c_ma\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0001-8818-6396': 31, '0000-0002-7480-5528': 28, '0000-0001-9245-0356': 18, '0000-0001-7092-7715': 16, '0000-0003-2054-0445': 15, '0000-0001-9612-7898': 9, '0000-0001-6478-5917': 3, '0000-0001-6507-2329': 2, '0000-0002-5936-789X': 2, '0000-0003-1073-4502': 1, '0000-0001-8942-3912': 1})\n",
      "['0000-0001-7092-7715', '0000-0003-2054-0445', '0000-0002-7480-5528', '0000-0001-9245-0356', '0000-0001-8818-6396']\n",
      "Total sample size after apply threshold:  108\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(108, 56)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(108, 16)\n",
      "2\n",
      "(108, 72)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.33      0.07      0.11        15\n",
      "          2       0.72      0.93      0.81        28\n",
      "          3       0.70      0.78      0.74        18\n",
      "          4       0.67      0.77      0.72        31\n",
      "\n",
      "avg / total       0.69      0.72      0.69       108\n",
      "\n",
      "[13  0  0  1  2  0  1  2  5  7  0  0 26  0  2  0  2  1 14  1  0  0  7  0\n",
      " 24]\n",
      "MNB Accuracy:  0.7222222222222222\n",
      "MNB F1:  0.6546845701919921\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.57      0.27      0.36        15\n",
      "          2       1.00      0.89      0.94        28\n",
      "          3       0.75      0.83      0.79        18\n",
      "          4       0.74      1.00      0.85        31\n",
      "\n",
      "avg / total       0.82      0.82      0.81       108\n",
      "\n",
      "[14  0  0  1  1  0  4  0  4  7  0  1 25  0  2  0  2  0 15  1  0  0  0  0\n",
      " 31]\n",
      "svc Accuracy:  0.8240740740740741\n",
      "svc F1:  0.7758309352176938\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.25      0.07      0.11        15\n",
      "          2       0.96      0.86      0.91        28\n",
      "          3       0.70      0.78      0.74        18\n",
      "          4       0.67      1.00      0.81        31\n",
      "\n",
      "avg / total       0.74      0.77      0.74       108\n",
      "\n",
      "[13  0  0  1  2  0  1  1  5  8  0  1 24  0  3  0  2  0 14  2  0  0  0  0\n",
      " 31]\n",
      "LR Accuracy:  0.7685185185185185\n",
      "LR F1:  0.6899024339698243\n",
      "For name:  j_chin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0003-3932-8639': 13, '0000-0002-1840-325X': 9, '0000-0002-2878-8544': 3, '0000-0001-9809-6976': 1, '0000-0001-7626-6778': 1})\n",
      "['0000-0003-3932-8639']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  h_kwon\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0003-4979-8749': 13, '0000-0002-6919-833X': 7, '0000-0002-0960-0198': 5, '0000-0001-6941-4808': 3, '0000-0003-4026-4572': 3, '0000-0002-2936-1358': 1, '0000-0002-8509-3968': 1, '0000-0003-4465-2708': 1, '0000-0001-9772-1354': 1})\n",
      "['0000-0003-4979-8749']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  s_gao\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-7020-037X': 28, '0000-0002-8919-1338': 1, '0000-0002-3574-6393': 1, '0000-0003-3320-8505': 1})\n",
      "['0000-0002-7020-037X']\n",
      "Total sample size after apply threshold:  28\n",
      "For name:  f_tian\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-1247-6896': 9, '0000-0003-3580-022X': 4, '0000-0002-9680-4518': 1, '0000-0003-0534-9749': 1, '0000-0002-9686-2769': 1, '0000-0001-8985-9679': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  f_martins\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0003-0960-4620': 19, '0000-0003-4189-1228': 10, '0000-0003-2668-2401': 9, '0000-0002-1812-2300': 8, '0000-0003-2161-459X': 6, '0000-0002-9863-6255': 5, '0000-0002-3277-1809': 4, '0000-0002-0680-3643': 3, '0000-0003-4997-3973': 1})\n",
      "['0000-0003-4189-1228', '0000-0003-0960-4620']\n",
      "Total sample size after apply threshold:  29\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 18)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 11)\n",
      "2\n",
      "(29, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.60      0.71        10\n",
      "          1       0.82      0.95      0.88        19\n",
      "\n",
      "avg / total       0.83      0.83      0.82        29\n",
      "\n",
      "[ 6  4  1 18]\n",
      "MNB Accuracy:  0.8275862068965517\n",
      "MNB F1:  0.7919655667144907\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.60      0.71        10\n",
      "          1       0.82      0.95      0.88        19\n",
      "\n",
      "avg / total       0.83      0.83      0.82        29\n",
      "\n",
      "[ 6  4  1 18]\n",
      "svc Accuracy:  0.8275862068965517\n",
      "svc F1:  0.7919655667144907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.20      0.31        10\n",
      "          1       0.69      0.95      0.80        19\n",
      "\n",
      "avg / total       0.68      0.69      0.63        29\n",
      "\n",
      "[ 2  8  1 18]\n",
      "LR Accuracy:  0.6896551724137931\n",
      "LR F1:  0.5538461538461538\n",
      "For name:  s_wolf\n",
      "total sample size before apply threshold:  363\n",
      "Counter({'0000-0003-2972-3440': 173, '0000-0002-7467-7028': 102, '0000-0002-5337-5063': 46, '0000-0003-0832-6315': 15, '0000-0002-3747-8097': 12, '0000-0003-1752-6175': 9, '0000-0003-3921-6629': 3, '0000-0001-7717-6993': 2, '0000-0002-6748-3911': 1})\n",
      "['0000-0002-7467-7028', '0000-0002-5337-5063', '0000-0003-0832-6315', '0000-0003-2972-3440', '0000-0002-3747-8097']\n",
      "Total sample size after apply threshold:  348\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(348, 116)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(348, 31)\n",
      "2\n",
      "(348, 147)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.84      0.87       102\n",
      "          1       0.67      0.26      0.38        46\n",
      "          2       0.00      0.00      0.00        15\n",
      "          3       0.73      0.99      0.84       173\n",
      "          4       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.72      0.78      0.72       348\n",
      "\n",
      "[ 86   1   0  15   0   7  12   0  27   0   1   2   0  12   0   1   0   0\n",
      " 172   0   0   3   0   9   0]\n",
      "MNB Accuracy:  0.7758620689655172\n",
      "MNB F1:  0.4182467403204937\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.86      0.92       102\n",
      "          1       0.67      0.48      0.56        46\n",
      "          2       0.83      0.33      0.48        15\n",
      "          3       0.80      0.99      0.88       173\n",
      "          4       0.50      0.17      0.25        12\n",
      "\n",
      "avg / total       0.83      0.83      0.81       348\n",
      "\n",
      "[ 88   3   0  11   0   1  22   1  20   2   0   3   5   7   0   0   1   0\n",
      " 172   0   0   4   0   6   2]\n",
      "svc Accuracy:  0.8304597701149425\n",
      "svc F1:  0.6177874472320315\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.81      0.86       102\n",
      "          1       0.63      0.26      0.37        46\n",
      "          2       0.00      0.00      0.00        15\n",
      "          3       0.73      0.99      0.84       173\n",
      "          4       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.71      0.77      0.72       348\n",
      "\n",
      "[ 83   1   0  18   0   6  12   0  28   0   2   2   0  11   0   1   0   0\n",
      " 172   0   0   4   0   8   0]\n",
      "LR Accuracy:  0.7672413793103449\n",
      "LR F1:  0.412785052513491\n",
      "For name:  m_goldman\n",
      "total sample size before apply threshold:  81\n",
      "Counter({'0000-0002-6786-9320': 74, '0000-0001-6771-169X': 5, '0000-0002-3667-1477': 1, '0000-0001-8908-3356': 1})\n",
      "['0000-0002-6786-9320']\n",
      "Total sample size after apply threshold:  74\n",
      "For name:  d_tang\n",
      "total sample size before apply threshold:  89\n",
      "Counter({'0000-0002-7339-9249': 40, '0000-0001-7136-7481': 39, '0000-0002-4790-9014': 5, '0000-0002-5443-4619': 3, '0000-0002-7615-0246': 2})\n",
      "['0000-0002-7339-9249', '0000-0001-7136-7481']\n",
      "Total sample size after apply threshold:  79\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 34)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 15)\n",
      "2\n",
      "(79, 49)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96        40\n",
      "          1       0.95      0.97      0.96        39\n",
      "\n",
      "avg / total       0.96      0.96      0.96        79\n",
      "\n",
      "[38  2  1 38]\n",
      "MNB Accuracy:  0.9620253164556962\n",
      "MNB F1:  0.9620253164556962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95        40\n",
      "          1       0.93      0.97      0.95        39\n",
      "\n",
      "avg / total       0.95      0.95      0.95        79\n",
      "\n",
      "[37  3  1 38]\n",
      "svc Accuracy:  0.9493670886075949\n",
      "svc F1:  0.9493589743589745\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.90      0.92        40\n",
      "          1       0.90      0.95      0.92        39\n",
      "\n",
      "avg / total       0.93      0.92      0.92        79\n",
      "\n",
      "[36  4  2 37]\n",
      "LR Accuracy:  0.9240506329113924\n",
      "LR F1:  0.9240384615384616\n",
      "For name:  m_adams\n",
      "total sample size before apply threshold:  190\n",
      "Counter({'0000-0003-0435-8651': 59, '0000-0001-8989-508X': 46, '0000-0001-6310-1472': 30, '0000-0002-7743-4515': 29, '0000-0003-2849-9096': 12, '0000-0002-5277-5487': 7, '0000-0002-3878-7684': 5, '0000-0002-3602-6849': 1, '0000-0002-4645-2593': 1})\n",
      "['0000-0002-7743-4515', '0000-0001-6310-1472', '0000-0003-2849-9096', '0000-0003-0435-8651', '0000-0001-8989-508X']\n",
      "Total sample size after apply threshold:  176\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(176, 79)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(176, 26)\n",
      "2\n",
      "(176, 105)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.55      0.67        29\n",
      "          1       0.76      0.63      0.69        30\n",
      "          2       1.00      0.25      0.40        12\n",
      "          3       0.65      0.86      0.74        59\n",
      "          4       0.63      0.70      0.66        46\n",
      "\n",
      "avg / total       0.72      0.69      0.68       176\n",
      "\n",
      "[16  2  0  5  6  1 19  0  7  3  0  0  3  4  5  1  2  0 51  5  1  2  0 11\n",
      " 32]\n",
      "MNB Accuracy:  0.6875\n",
      "MNB F1:  0.6323790238908005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.66      0.73        29\n",
      "          1       0.64      0.77      0.70        30\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       0.75      0.90      0.82        59\n",
      "          4       0.94      0.74      0.83        46\n",
      "\n",
      "avg / total       0.81      0.79      0.79       176\n",
      "\n",
      "[19  4  0  5  1  1 23  0  6  0  0  1 10  0  1  2  4  0 53  0  1  4  0  7\n",
      " 34]\n",
      "svc Accuracy:  0.7897727272727273\n",
      "svc F1:  0.7962965489794758\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.66      0.75        29\n",
      "          1       0.69      0.60      0.64        30\n",
      "          2       1.00      0.42      0.59        12\n",
      "          3       0.65      0.86      0.74        59\n",
      "          4       0.69      0.67      0.68        46\n",
      "\n",
      "avg / total       0.73      0.70      0.70       176\n",
      "\n",
      "[19  3  0  2  5  0 18  0  9  3  1  0  5  4  2  1  3  0 51  4  1  2  0 12\n",
      " 31]\n",
      "LR Accuracy:  0.7045454545454546\n",
      "LR F1:  0.6804069409908826\n",
      "For name:  t_singh\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-7935-0457': 13, '0000-0001-7420-6739': 11, '0000-0001-7051-6529': 11, '0000-0002-0413-1935': 10, '0000-0003-1007-4540': 2, '0000-0002-5870-6204': 1, '0000-0003-0377-6122': 1, '0000-0002-9740-7776': 1, '0000-0002-7740-4826': 1, '0000-0003-1109-5626': 1})\n",
      "['0000-0002-0413-1935', '0000-0001-7420-6739', '0000-0001-7935-0457', '0000-0001-7051-6529']\n",
      "Total sample size after apply threshold:  45\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 14)\n",
      "2\n",
      "(45, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.70      0.61        10\n",
      "          1       0.33      0.18      0.24        11\n",
      "          2       0.56      0.69      0.62        13\n",
      "          3       0.40      0.36      0.38        11\n",
      "\n",
      "avg / total       0.46      0.49      0.47        45\n",
      "\n",
      "[7 1 2 0 4 2 2 3 1 0 9 3 1 3 3 4]\n",
      "MNB Accuracy:  0.4888888888888889\n",
      "MNB F1:  0.46140795148644165\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.70      0.74        10\n",
      "          1       0.40      0.55      0.46        11\n",
      "          2       0.75      0.69      0.72        13\n",
      "          3       0.44      0.36      0.40        11\n",
      "\n",
      "avg / total       0.60      0.58      0.58        45\n",
      "\n",
      "[7 2 0 1 2 6 1 2 0 2 9 2 0 5 2 4]\n",
      "svc Accuracy:  0.5777777777777777\n",
      "svc F1:  0.5795951417004047\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.70      0.61        10\n",
      "          1       0.33      0.18      0.24        11\n",
      "          2       0.57      0.62      0.59        13\n",
      "          3       0.33      0.36      0.35        11\n",
      "\n",
      "avg / total       0.45      0.47      0.45        45\n",
      "\n",
      "[7 2 1 0 3 2 2 4 1 0 8 4 2 2 3 4]\n",
      "LR Accuracy:  0.4666666666666667\n",
      "LR F1:  0.44610211234252156\n",
      "For name:  m_thompson\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-7764-4096': 80, '0000-0001-8958-0336': 29, '0000-0002-4933-009X': 11, '0000-0002-2865-9558': 10, '0000-0002-5649-1203': 6, '0000-0002-1789-312X': 6, '0000-0002-6910-4938': 4, '0000-0002-1194-1506': 1, '0000-0002-8551-4806': 1, '0000-0002-1358-1962': 1, '0000-0001-7006-3646': 1})\n",
      "['0000-0001-8958-0336', '0000-0002-4933-009X', '0000-0002-2865-9558', '0000-0002-7764-4096']\n",
      "Total sample size after apply threshold:  130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 51)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 17)\n",
      "2\n",
      "(130, 68)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.45      0.55        29\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.72      0.97      0.83        80\n",
      "\n",
      "avg / total       0.60      0.70      0.63       130\n",
      "\n",
      "[13  1  0 15  1  0  1  9  2  1  0  7  2  0  0 78]\n",
      "MNB Accuracy:  0.7\n",
      "MNB F1:  0.3446470786896319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.59      0.63        29\n",
      "          1       0.33      0.09      0.14        11\n",
      "          2       0.56      0.50      0.53        10\n",
      "          3       0.77      0.90      0.83        80\n",
      "\n",
      "avg / total       0.70      0.73      0.71       130\n",
      "\n",
      "[17  0  0 12  1  1  3  6  0  2  5  3  7  0  1 72]\n",
      "svc Accuracy:  0.7307692307692307\n",
      "svc F1:  0.5327931260392471\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.45      0.58        29\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.71      0.99      0.82        80\n",
      "\n",
      "avg / total       0.62      0.71      0.64       130\n",
      "\n",
      "[13  0  0 16  0  0  1 10  2  1  0  7  1  0  0 79]\n",
      "LR Accuracy:  0.7076923076923077\n",
      "LR F1:  0.3501736111111111\n",
      "For name:  s_garcia\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-3143-0527': 16, '0000-0003-4190-6055': 2, '0000-0001-5161-0085': 1, '0000-0001-7317-1423': 1})\n",
      "['0000-0002-3143-0527']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  e_wang\n",
      "total sample size before apply threshold:  155\n",
      "Counter({'0000-0002-2243-4964': 64, '0000-0002-1180-5854': 53, '0000-0003-3394-2670': 14, '0000-0002-4942-3771': 10, '0000-0001-9335-5457': 6, '0000-0003-1302-9745': 4, '0000-0002-6653-5791': 2, '0000-0002-5178-3530': 1, '0000-0002-1084-7059': 1})\n",
      "['0000-0002-1180-5854', '0000-0003-3394-2670', '0000-0002-4942-3771', '0000-0002-2243-4964']\n",
      "Total sample size after apply threshold:  141\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(141, 75)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(141, 22)\n",
      "2\n",
      "(141, 97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.94      0.75        53\n",
      "          1       1.00      0.14      0.25        14\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.81      0.75      0.78        64\n",
      "\n",
      "avg / total       0.70      0.71      0.66       141\n",
      "\n",
      "[50  0  0  3  5  2  0  7  9  0  0  1 16  0  0 48]\n",
      "MNB Accuracy:  0.7092198581560284\n",
      "MNB F1:  0.4455918760315423\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.92      0.92        53\n",
      "          1       1.00      0.36      0.53        14\n",
      "          2       1.00      0.50      0.67        10\n",
      "          3       0.81      0.97      0.88        64\n",
      "\n",
      "avg / total       0.88      0.86      0.84       141\n",
      "\n",
      "[49  0  0  4  1  5  0  8  2  0  5  3  2  0  0 62]\n",
      "svc Accuracy:  0.8581560283687943\n",
      "svc F1:  0.7470757326802789\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.89      0.85        53\n",
      "          1       1.00      0.14      0.25        14\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.72      0.92      0.81        64\n",
      "\n",
      "avg / total       0.74      0.77      0.71       141\n",
      "\n",
      "[47  0  0  6  1  2  0 11  4  0  0  6  5  0  0 59]\n",
      "LR Accuracy:  0.7659574468085106\n",
      "LR F1:  0.4781911581569116\n",
      "For name:  c_scott\n",
      "total sample size before apply threshold:  162\n",
      "Counter({'0000-0003-1340-0647': 98, '0000-0001-6110-6982': 39, '0000-0001-9363-1829': 21, '0000-0003-0860-4805': 3, '0000-0003-3254-8647': 1})\n",
      "['0000-0001-9363-1829', '0000-0001-6110-6982', '0000-0003-1340-0647']\n",
      "Total sample size after apply threshold:  158\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(158, 86)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(158, 23)\n",
      "2\n",
      "(158, 109)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.44        21\n",
      "          1       0.71      0.56      0.63        39\n",
      "          2       0.76      0.94      0.84        98\n",
      "\n",
      "avg / total       0.78      0.76      0.74       158\n",
      "\n",
      "[ 6  3 12  0 22 17  0  6 92]\n",
      "MNB Accuracy:  0.759493670886076\n",
      "MNB F1:  0.6377328404725665\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.38      0.50        21\n",
      "          1       0.91      0.54      0.68        39\n",
      "          2       0.76      0.96      0.85        98\n",
      "\n",
      "avg / total       0.79      0.78      0.76       158\n",
      "\n",
      "[ 8  0 13  1 21 17  2  2 94]\n",
      "svc Accuracy:  0.7784810126582279\n",
      "svc F1:  0.674755400561852\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.17        21\n",
      "          1       0.90      0.49      0.63        39\n",
      "          2       0.71      0.98      0.82        98\n",
      "\n",
      "avg / total       0.80      0.74      0.69       158\n",
      "\n",
      "[ 2  0 19  0 19 20  0  2 96]\n",
      "LR Accuracy:  0.740506329113924\n",
      "LR F1:  0.5437602371918476\n",
      "For name:  m_mukherjee\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0003-3706-406X': 4, '0000-0002-7924-7211': 4, '0000-0002-3083-436X': 3, '0000-0003-0376-8173': 2, '0000-0002-3615-7574': 2, '0000-0001-9653-0556': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_schroeder\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-3283-5972': 146, '0000-0002-4136-843X': 2, '0000-0002-3860-8498': 1, '0000-0002-1975-721X': 1})\n",
      "['0000-0002-3283-5972']\n",
      "Total sample size after apply threshold:  146\n",
      "For name:  a_mayer\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-6859-0612': 10, '0000-0003-3278-1182': 4, '0000-0002-6975-7082': 2, '0000-0002-8765-6373': 1})\n",
      "['0000-0002-6859-0612']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  e_wright\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0001-7041-5138': 20, '0000-0002-2390-8017': 3, '0000-0002-2187-7114': 3, '0000-0003-1721-4104': 2})\n",
      "['0000-0001-7041-5138']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  c_moreno\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5582-0028': 37, '0000-0003-0541-4846': 35, '0000-0001-6472-6044': 16, '0000-0003-1839-9673': 16, '0000-0002-1660-7072': 13, '0000-0003-2682-211X': 6, '0000-0002-0876-0341': 6, '0000-0003-4816-8040': 6, '0000-0002-9584-2619': 1})\n",
      "['0000-0001-6472-6044', '0000-0002-1660-7072', '0000-0003-1839-9673', '0000-0003-0541-4846', '0000-0002-5582-0028']\n",
      "Total sample size after apply threshold:  117\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 74)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 19)\n",
      "2\n",
      "(117, 93)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.56      0.72        16\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       1.00      0.56      0.72        16\n",
      "          3       0.47      0.80      0.60        35\n",
      "          4       0.60      0.65      0.62        37\n",
      "\n",
      "avg / total       0.61      0.60      0.57       117\n",
      "\n",
      "[ 9  0  0  5  2  0  0  0 10  3  0  0  9  3  4  0  0  0 28  7  0  0  0 13\n",
      " 24]\n",
      "MNB Accuracy:  0.5982905982905983\n",
      "MNB F1:  0.5318242608455375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        16\n",
      "          1       0.40      0.31      0.35        13\n",
      "          2       1.00      0.62      0.77        16\n",
      "          3       0.54      0.63      0.58        35\n",
      "          4       0.59      0.70      0.64        37\n",
      "\n",
      "avg / total       0.67      0.63      0.64       117\n",
      "\n",
      "[12  0  0  1  3  0  4  0  5  4  0  0 10  2  4  0  6  0 22  7  0  0  0 11\n",
      " 26]\n",
      "svc Accuracy:  0.6324786324786325\n",
      "svc F1:  0.6390244780786352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.56      0.72        16\n",
      "          1       1.00      0.08      0.14        13\n",
      "          2       1.00      0.44      0.61        16\n",
      "          3       0.50      0.74      0.60        35\n",
      "          4       0.52      0.68      0.59        37\n",
      "\n",
      "avg / total       0.70      0.58      0.56       117\n",
      "\n",
      "[ 9  0  0  5  2  0  1  0  6  6  0  0  7  3  6  0  0  0 26  9  0  0  0 12\n",
      " 25]\n",
      "LR Accuracy:  0.5811965811965812\n",
      "LR F1:  0.5314978477147981\n",
      "For name:  a_moura\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0003-0339-1230': 15, '0000-0002-2105-7319': 14, '0000-0003-2140-0196': 4, '0000-0002-1513-5448': 3})\n",
      "['0000-0002-2105-7319', '0000-0003-0339-1230']\n",
      "Total sample size after apply threshold:  29\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 16)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 12)\n",
      "2\n",
      "(29, 28)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82        14\n",
      "          1       1.00      0.60      0.75        15\n",
      "\n",
      "avg / total       0.86      0.79      0.79        29\n",
      "\n",
      "[14  0  6  9]\n",
      "MNB Accuracy:  0.7931034482758621\n",
      "MNB F1:  0.7867647058823528\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        29\n",
      "\n",
      "[14  0  0 15]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.93      0.87        14\n",
      "          1       0.92      0.80      0.86        15\n",
      "\n",
      "avg / total       0.87      0.86      0.86        29\n",
      "\n",
      "[13  1  3 12]\n",
      "LR Accuracy:  0.8620689655172413\n",
      "LR F1:  0.8619047619047618\n",
      "For name:  j_lopez\n",
      "total sample size before apply threshold:  122\n",
      "Counter({'0000-0002-9097-6060': 27, '0000-0003-0842-5348': 23, '0000-0002-5234-1478': 17, '0000-0001-9370-1516': 9, '0000-0001-6884-5577': 6, '0000-0003-3001-1109': 6, '0000-0002-1637-4125': 6, '0000-0003-0821-7530': 4, '0000-0002-5390-6610': 4, '0000-0002-7645-1620': 4, '0000-0002-4104-6262': 3, '0000-0001-5684-4913': 3, '0000-0001-8723-6347': 2, '0000-0003-2213-1186': 2, '0000-0003-0370-4727': 2, '0000-0003-4662-7928': 1, '0000-0003-1028-779X': 1, '0000-0002-4627-2277': 1, '0000-0001-8066-9991': 1})\n",
      "['0000-0003-0842-5348', '0000-0002-9097-6060', '0000-0002-5234-1478']\n",
      "Total sample size after apply threshold:  67\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 45)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 22)\n",
      "2\n",
      "(67, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.65      0.68        23\n",
      "          1       0.61      0.81      0.70        27\n",
      "          2       0.70      0.41      0.52        17\n",
      "\n",
      "avg / total       0.67      0.66      0.65        67\n",
      "\n",
      "[15  7  1  3 22  2  3  7  7]\n",
      "MNB Accuracy:  0.6567164179104478\n",
      "MNB F1:  0.6329164662497996\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.65      0.68        23\n",
      "          1       0.68      0.85      0.75        27\n",
      "          2       0.83      0.59      0.69        17\n",
      "\n",
      "avg / total       0.73      0.72      0.71        67\n",
      "\n",
      "[15  7  1  3 23  1  3  4 10]\n",
      "svc Accuracy:  0.7164179104477612\n",
      "svc F1:  0.708523904962571\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.65      0.67        23\n",
      "          1       0.56      0.81      0.67        27\n",
      "          2       0.67      0.24      0.35        17\n",
      "\n",
      "avg / total       0.63      0.61      0.59        67\n",
      "\n",
      "[15  8  0  3 22  2  4  9  4]\n",
      "LR Accuracy:  0.6119402985074627\n",
      "LR F1:  0.5603864734299517\n",
      "For name:  a_logan\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0002-1179-5879': 22, '0000-0001-9140-5545': 2, '0000-0002-4403-7329': 1, '0000-0003-3215-5042': 1})\n",
      "['0000-0002-1179-5879']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  l_williams\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-7860-0319': 21, '0000-0002-0021-5613': 9, '0000-0002-8643-4920': 2, '0000-0002-8577-6339': 2, '0000-0001-8439-5270': 2, '0000-0001-6790-1362': 2, '0000-0002-3964-2356': 1, '0000-0003-2404-1985': 1, '0000-0003-2860-1150': 1, '0000-0002-6317-1718': 1})\n",
      "['0000-0002-7860-0319']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  h_young\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0002-0457-8710': 75, '0000-0003-1538-445X': 28, '0000-0002-4249-9060': 5, '0000-0002-8866-7648': 1})\n",
      "['0000-0003-1538-445X', '0000-0002-0457-8710']\n",
      "Total sample size after apply threshold:  103\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 48)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 26)\n",
      "2\n",
      "(103, 74)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.71      0.75        28\n",
      "          1       0.90      0.93      0.92        75\n",
      "\n",
      "avg / total       0.87      0.87      0.87       103\n",
      "\n",
      "[20  8  5 70]\n",
      "MNB Accuracy:  0.8737864077669902\n",
      "MNB F1:  0.8348748304353188\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        28\n",
      "          1       0.89      1.00      0.94        75\n",
      "\n",
      "avg / total       0.92      0.91      0.91       103\n",
      "\n",
      "[19  9  0 75]\n",
      "svc Accuracy:  0.912621359223301\n",
      "svc F1:  0.8759534323564835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.39      0.56        28\n",
      "          1       0.82      1.00      0.90        75\n",
      "\n",
      "avg / total       0.87      0.83      0.81       103\n",
      "\n",
      "[11 17  0 75]\n",
      "LR Accuracy:  0.8349514563106796\n",
      "LR F1:  0.7311530784584677\n",
      "For name:  a_vincent\n",
      "total sample size before apply threshold:  79\n",
      "Counter({'0000-0002-4185-3267': 39, '0000-0001-6446-3846': 21, '0000-0002-3760-7266': 12, '0000-0002-0360-6644': 7})\n",
      "['0000-0002-4185-3267', '0000-0002-3760-7266', '0000-0001-6446-3846']\n",
      "Total sample size after apply threshold:  72\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 34)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 14)\n",
      "2\n",
      "(72, 48)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.72      0.74        39\n",
      "          1       0.85      0.92      0.88        12\n",
      "          2       0.55      0.57      0.56        21\n",
      "\n",
      "avg / total       0.71      0.71      0.71        72\n",
      "\n",
      "[28  1 10  1 11  0  8  1 12]\n",
      "MNB Accuracy:  0.7083333333333334\n",
      "MNB F1:  0.7249938800489595\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.77      0.72        39\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       0.47      0.38      0.42        21\n",
      "\n",
      "avg / total       0.67      0.68      0.67        72\n",
      "\n",
      "[30  0  9  1 11  0 13  0  8]\n",
      "svc Accuracy:  0.6805555555555556\n",
      "svc F1:  0.7001553123248141\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.85      0.74        39\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       0.54      0.33      0.41        21\n",
      "\n",
      "avg / total       0.68      0.68      0.66        72\n",
      "\n",
      "[33  0  6  3  9  0 14  0  7]\n",
      "LR Accuracy:  0.6805555555555556\n",
      "LR F1:  0.6701601989110251\n",
      "For name:  a_monteiro\n",
      "total sample size before apply threshold:  132\n",
      "Counter({'0000-0002-8448-4801': 76, '0000-0001-9696-459X': 35, '0000-0001-8182-3380': 7, '0000-0002-2185-0720': 5, '0000-0002-7839-2556': 4, '0000-0002-2322-3624': 2, '0000-0002-3392-2664': 1, '0000-0002-1976-6538': 1, '0000-0003-0499-6522': 1})\n",
      "['0000-0001-9696-459X', '0000-0002-8448-4801']\n",
      "Total sample size after apply threshold:  111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 65)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 22)\n",
      "2\n",
      "(111, 87)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.40      0.44        35\n",
      "          1       0.75      0.82      0.78        76\n",
      "\n",
      "avg / total       0.67      0.68      0.67       111\n",
      "\n",
      "[14 21 14 62]\n",
      "MNB Accuracy:  0.6846846846846847\n",
      "MNB F1:  0.6121593291404611\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.40      0.52        35\n",
      "          1       0.77      0.93      0.85        76\n",
      "\n",
      "avg / total       0.76      0.77      0.74       111\n",
      "\n",
      "[14 21  5 71]\n",
      "svc Accuracy:  0.7657657657657657\n",
      "svc F1:  0.6818783068783069\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.23      0.36        35\n",
      "          1       0.74      0.99      0.84        76\n",
      "\n",
      "avg / total       0.78      0.75      0.69       111\n",
      "\n",
      "[ 8 27  1 75]\n",
      "LR Accuracy:  0.7477477477477478\n",
      "LR F1:  0.6031664964249234\n",
      "For name:  d_park\n",
      "total sample size before apply threshold:  156\n",
      "Counter({'0000-0003-2307-8575': 95, '0000-0002-6001-4223': 17, '0000-0001-9209-0493': 14, '0000-0003-0147-2424': 13, '0000-0002-7507-1175': 9, '0000-0002-7325-5480': 2, '0000-0001-9675-7179': 2, '0000-0002-5560-873X': 1, '0000-0003-4991-5247': 1, '0000-0002-1007-8595': 1, '0000-0001-9969-3051': 1})\n",
      "['0000-0001-9209-0493', '0000-0002-6001-4223', '0000-0003-0147-2424', '0000-0003-2307-8575']\n",
      "Total sample size after apply threshold:  139\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 61)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 17)\n",
      "2\n",
      "(139, 78)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.44        14\n",
      "          1       0.78      0.41      0.54        17\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.75      0.99      0.85        95\n",
      "\n",
      "avg / total       0.71      0.76      0.69       139\n",
      "\n",
      "[ 4  1  0  9  0  7  0 10  0  0  0 13  0  1  0 94]\n",
      "MNB Accuracy:  0.7553956834532374\n",
      "MNB F1:  0.4583961789844143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        14\n",
      "          1       0.58      0.41      0.48        17\n",
      "          2       0.89      0.62      0.73        13\n",
      "          3       0.85      0.98      0.91        95\n",
      "\n",
      "avg / total       0.83      0.83      0.82       139\n",
      "\n",
      "[ 8  1  0  5  0  7  1  9  0  2  8  3  0  2  0 93]\n",
      "svc Accuracy:  0.8345323741007195\n",
      "svc F1:  0.7111552871014604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.44        14\n",
      "          1       0.50      0.12      0.19        17\n",
      "          2       1.00      0.23      0.38        13\n",
      "          3       0.74      1.00      0.85        95\n",
      "\n",
      "avg / total       0.76      0.75      0.69       139\n",
      "\n",
      "[ 4  1  0  9  0  2  0 15  0  1  3  9  0  0  0 95]\n",
      "LR Accuracy:  0.7482014388489209\n",
      "LR F1:  0.46548464303509146\n",
      "For name:  d_gao\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0003-1821-2741': 14, '0000-0002-9391-1756': 7, '0000-0001-8725-5740': 1, '0000-0002-2472-7349': 1})\n",
      "['0000-0003-1821-2741']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  d_quinn\n",
      "total sample size before apply threshold:  145\n",
      "Counter({'0000-0002-1411-0417': 139, '0000-0002-6338-5265': 2, '0000-0003-0321-2255': 2, '0000-0001-7790-7768': 2})\n",
      "['0000-0002-1411-0417']\n",
      "Total sample size after apply threshold:  139\n",
      "For name:  n_dias\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-0498-4612': 13, '0000-0002-6907-6148': 2, '0000-0002-4731-0968': 1, '0000-0002-9019-8406': 1})\n",
      "['0000-0002-0498-4612']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  k_fisher\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-2751-156X': 11, '0000-0001-7381-9648': 8, '0000-0002-0828-6395': 3, '0000-0002-1774-4431': 1, '0000-0002-5581-8892': 1})\n",
      "['0000-0002-2751-156X']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  m_schubert\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0003-0278-4091': 22, '0000-0003-2401-9921': 18, '0000-0002-0994-8805': 14, '0000-0001-6238-663X': 12, '0000-0002-8739-4852': 7, '0000-0002-6862-5221': 6, '0000-0002-2911-8075': 5})\n",
      "['0000-0003-2401-9921', '0000-0003-0278-4091', '0000-0001-6238-663X', '0000-0002-0994-8805']\n",
      "Total sample size after apply threshold:  66\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 14)\n",
      "2\n",
      "(66, 58)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.67      0.59        18\n",
      "          1       0.70      0.73      0.71        22\n",
      "          2       0.50      0.17      0.25        12\n",
      "          3       0.50      0.57      0.53        14\n",
      "\n",
      "avg / total       0.57      0.58      0.56        66\n",
      "\n",
      "[12  1  0  5  3 16  2  1  2  6  2  2  6  0  0  8]\n",
      "MNB Accuracy:  0.5757575757575758\n",
      "MNB F1:  0.5199525745257452\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.78      0.62        18\n",
      "          1       0.81      0.77      0.79        22\n",
      "          2       0.89      0.67      0.76        12\n",
      "          3       0.78      0.50      0.61        14\n",
      "\n",
      "avg / total       0.74      0.70      0.70        66\n",
      "\n",
      "[14  2  0  2  4 17  1  0  2  2  8  0  7  0  0  7]\n",
      "svc Accuracy:  0.696969696969697\n",
      "svc F1:  0.6958800776798755\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.56      0.50        18\n",
      "          1       0.63      0.77      0.69        22\n",
      "          2       0.67      0.17      0.27        12\n",
      "          3       0.50      0.50      0.50        14\n",
      "\n",
      "avg / total       0.56      0.55      0.52        66\n",
      "\n",
      "[10  4  0  4  3 17  1  1  2  6  2  2  7  0  0  7]\n",
      "LR Accuracy:  0.5454545454545454\n",
      "LR F1:  0.4901360544217687\n",
      "For name:  j_peters\n",
      "total sample size before apply threshold:  154\n",
      "Counter({'0000-0001-8503-1452': 57, '0000-0002-6725-2814': 36, '0000-0001-8309-3297': 22, '0000-0003-3150-3973': 17, '0000-0003-4592-7275': 13, '0000-0002-5266-8091': 8, '0000-0002-1456-5390': 1})\n",
      "['0000-0001-8309-3297', '0000-0002-6725-2814', '0000-0003-3150-3973', '0000-0001-8503-1452', '0000-0003-4592-7275']\n",
      "Total sample size after apply threshold:  145\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(145, 77)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(145, 22)\n",
      "2\n",
      "(145, 99)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        22\n",
      "          1       0.62      0.78      0.69        36\n",
      "          2       0.77      0.59      0.67        17\n",
      "          3       0.68      0.96      0.80        57\n",
      "          4       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.66      0.68      0.63       145\n",
      "\n",
      "[ 6  5  1 10  0  0 28  1  7  0  0  6 10  1  0  0  2  0 55  0  0  4  1  8\n",
      "  0]\n",
      "MNB Accuracy:  0.6827586206896552\n",
      "MNB F1:  0.5167395138409632\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.41      0.55        22\n",
      "          1       0.61      0.78      0.68        36\n",
      "          2       0.73      0.65      0.69        17\n",
      "          3       0.76      0.89      0.82        57\n",
      "          4       0.67      0.31      0.42        13\n",
      "\n",
      "avg / total       0.72      0.71      0.69       145\n",
      "\n",
      "[ 9  8  1  4  0  1 28  1  5  1  1  4 11  1  0  0  4  1 51  1  0  2  1  6\n",
      "  4]\n",
      "svc Accuracy:  0.7103448275862069\n",
      "svc F1:  0.6319029302926152\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        22\n",
      "          1       0.62      0.78      0.69        36\n",
      "          2       0.77      0.59      0.67        17\n",
      "          3       0.69      0.96      0.80        57\n",
      "          4       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.67      0.69      0.64       145\n",
      "\n",
      "[ 7  5  1  9  0  0 28  1  7  0  0  6 10  1  0  0  2  0 55  0  0  4  1  8\n",
      "  0]\n",
      "LR Accuracy:  0.6896551724137931\n",
      "LR F1:  0.5287406040153754\n",
      "For name:  e_zimmermann\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0001-9927-3372': 24, '0000-0001-5854-0542': 16, '0000-0002-1964-2711': 15, '0000-0002-4268-9729': 2})\n",
      "['0000-0002-1964-2711', '0000-0001-5854-0542', '0000-0001-9927-3372']\n",
      "Total sample size after apply threshold:  55\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 11)\n",
      "2\n",
      "(55, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        15\n",
      "          1       0.81      0.81      0.81        16\n",
      "          2       0.76      0.92      0.83        24\n",
      "\n",
      "avg / total       0.84      0.82      0.82        55\n",
      "\n",
      "[10  1  4  0 13  3  0  2 22]\n",
      "MNB Accuracy:  0.8181818181818182\n",
      "MNB F1:  0.8142295597484277\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       0.82      0.56      0.67        16\n",
      "          2       0.69      0.92      0.79        24\n",
      "\n",
      "avg / total       0.81      0.78      0.78        55\n",
      "\n",
      "[12  0  3  0  9  7  0  2 22]\n",
      "svc Accuracy:  0.7818181818181819\n",
      "svc F1:  0.7804232804232805\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        15\n",
      "          1       0.81      0.81      0.81        16\n",
      "          2       0.76      0.92      0.83        24\n",
      "\n",
      "avg / total       0.84      0.82      0.82        55\n",
      "\n",
      "[10  1  4  0 13  3  0  2 22]\n",
      "LR Accuracy:  0.8181818181818182\n",
      "LR F1:  0.8142295597484277\n",
      "For name:  c_zhang\n",
      "total sample size before apply threshold:  321\n",
      "Counter({'0000-0002-7784-1188': 120, '0000-0003-2349-3138': 52, '0000-0002-1581-5806': 25, '0000-0001-9042-4007': 13, '0000-0002-6502-288X': 10, '0000-0002-5957-2287': 9, '0000-0002-3721-8586': 8, '0000-0002-4067-2798': 7, '0000-0003-3435-0247': 7, '0000-0002-7687-0518': 7, '0000-0001-8663-3674': 6, '0000-0001-8222-4566': 5, '0000-0003-0679-7623': 4, '0000-0003-3212-4270': 4, '0000-0001-6885-1678': 4, '0000-0003-1616-4715': 4, '0000-0001-8206-5171': 4, '0000-0001-6685-0137': 3, '0000-0002-7913-4858': 3, '0000-0002-7167-0840': 3, '0000-0002-1207-4264': 3, '0000-0003-0399-1201': 3, '0000-0002-9461-1755': 2, '0000-0003-4968-8793': 2, '0000-0003-2693-6643': 2, '0000-0003-3871-0342': 2, '0000-0001-5249-141X': 2, '0000-0003-1095-9939': 1, '0000-0002-3065-3497': 1, '0000-0002-1607-5563': 1, '0000-0002-7704-9318': 1, '0000-0001-5552-1960': 1, '0000-0002-1458-8170': 1, '0000-0003-2346-6770': 1})\n",
      "['0000-0002-7784-1188', '0000-0002-1581-5806', '0000-0001-9042-4007', '0000-0003-2349-3138', '0000-0002-6502-288X']\n",
      "Total sample size after apply threshold:  220\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(220, 86)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(220, 19)\n",
      "2\n",
      "(220, 105)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.98      0.86       120\n",
      "          1       1.00      0.44      0.61        25\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.79      0.81      0.80        52\n",
      "          4       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.71      0.78      0.72       220\n",
      "\n",
      "[118   0   0   2   0   9  11   0   5   0  13   0   0   0   0  10   0   0\n",
      "  42   0   6   0   0   4   0]\n",
      "MNB Accuracy:  0.7772727272727272\n",
      "MNB F1:  0.45323671497584533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.97      0.87       120\n",
      "          1       0.90      0.72      0.80        25\n",
      "          2       0.67      0.31      0.42        13\n",
      "          3       0.93      0.77      0.84        52\n",
      "          4       0.50      0.10      0.17        10\n",
      "\n",
      "avg / total       0.81      0.82      0.80       220\n",
      "\n",
      "[117   2   1   0   0   4  18   1   2   0   9   0   4   0   0  11   0   0\n",
      "  40   1   8   0   0   1   1]\n",
      "svc Accuracy:  0.8181818181818182\n",
      "svc F1:  0.619942607447988\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.99      0.82       120\n",
      "          1       1.00      0.52      0.68        25\n",
      "          2       0.50      0.08      0.13        13\n",
      "          3       0.94      0.65      0.77        52\n",
      "          4       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.75      0.76      0.72       220\n",
      "\n",
      "[119   0   1   0   0  10  13   0   2   0  12   0   1   0   0  18   0   0\n",
      "  34   0  10   0   0   0   0]\n",
      "LR Accuracy:  0.759090909090909\n",
      "LR F1:  0.48276010882822024\n",
      "For name:  h_shin\n",
      "total sample size before apply threshold:  114\n",
      "Counter({'0000-0001-7615-9809': 34, '0000-0001-7080-6075': 24, '0000-0003-1226-3206': 20, '0000-0002-3353-0310': 13, '0000-0002-6750-118X': 10, '0000-0001-6504-3413': 9, '0000-0002-3398-1074': 2, '0000-0002-1410-9731': 1, '0000-0002-5161-661X': 1})\n",
      "['0000-0002-6750-118X', '0000-0001-7080-6075', '0000-0001-7615-9809', '0000-0003-1226-3206', '0000-0002-3353-0310']\n",
      "Total sample size after apply threshold:  101\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 64)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 14)\n",
      "2\n",
      "(101, 78)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.69      0.38      0.49        24\n",
      "          2       0.57      0.97      0.72        34\n",
      "          3       0.62      0.65      0.63        20\n",
      "          4       0.78      0.54      0.64        13\n",
      "\n",
      "avg / total       0.58      0.61      0.56       101\n",
      "\n",
      "[ 0  2  5  2  1  0  9 10  4  1  0  0 33  1  0  0  1  6 13  0  0  1  4  1\n",
      "  7]\n",
      "MNB Accuracy:  0.6138613861386139\n",
      "MNB F1:  0.4948775537322727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.20      0.31        10\n",
      "          1       0.48      0.58      0.53        24\n",
      "          2       0.79      0.91      0.85        34\n",
      "          3       0.72      0.65      0.68        20\n",
      "          4       0.67      0.62      0.64        13\n",
      "\n",
      "avg / total       0.68      0.67      0.66       101\n",
      "\n",
      "[ 2  4  2  1  1  1 14  3  3  3  0  3 31  0  0  0  4  3 13  0  0  4  0  1\n",
      "  8]\n",
      "svc Accuracy:  0.6732673267326733\n",
      "svc F1:  0.6019039578587402\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.45      0.42      0.43        24\n",
      "          2       0.61      0.91      0.73        34\n",
      "          3       0.62      0.65      0.63        20\n",
      "          4       1.00      0.54      0.70        13\n",
      "\n",
      "avg / total       0.56      0.60      0.56       101\n",
      "\n",
      "[ 0  3  5  2  0  0 10 10  4  0  0  2 31  1  0  0  4  3 13  0  0  3  2  1\n",
      "  7]\n",
      "LR Accuracy: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.6039603960396039\n",
      "LR F1:  0.49966814297298984\n",
      "For name:  r_reis\n",
      "total sample size before apply threshold:  615\n",
      "Counter({'0000-0002-4295-6129': 423, '0000-0002-9639-7940': 113, '0000-0002-9872-9865': 27, '0000-0001-9689-4085': 21, '0000-0002-0681-4721': 10, '0000-0003-0328-1840': 7, '0000-0003-0937-8045': 7, '0000-0003-3746-6894': 4, '0000-0002-6618-2412': 2, '0000-0002-6935-3459': 1})\n",
      "['0000-0002-9639-7940', '0000-0001-9689-4085', '0000-0002-9872-9865', '0000-0002-0681-4721', '0000-0002-4295-6129']\n",
      "Total sample size after apply threshold:  594\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(594, 202)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(594, 21)\n",
      "2\n",
      "(594, 223)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.31      0.45       113\n",
      "          1       1.00      0.05      0.09        21\n",
      "          2       0.00      0.00      0.00        27\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.76      0.99      0.86       423\n",
      "\n",
      "avg / total       0.73      0.77      0.70       594\n",
      "\n",
      "[ 35   0   0   0  78   2   1   0   0  18   1   0   0   0  26   2   0   0\n",
      "   0   8   3   0   0   0 420]\n",
      "MNB Accuracy:  0.7676767676767676\n",
      "MNB F1:  0.28058727842900505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.54      0.65       113\n",
      "          1       0.80      0.19      0.31        21\n",
      "          2       0.93      0.52      0.67        27\n",
      "          3       1.00      0.60      0.75        10\n",
      "          4       0.84      0.98      0.90       423\n",
      "\n",
      "avg / total       0.84      0.84      0.82       594\n",
      "\n",
      "[ 61   0   1   0  51   4   4   0   0  13   2   0  14   0  11   1   0   0\n",
      "   6   3   8   1   0   0 414]\n",
      "svc Accuracy:  0.8400673400673401\n",
      "svc F1:  0.6549559305297011\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.35      0.49       113\n",
      "          1       0.00      0.00      0.00        21\n",
      "          2       1.00      0.26      0.41        27\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.78      0.99      0.87       423\n",
      "\n",
      "avg / total       0.75      0.78      0.73       594\n",
      "\n",
      "[ 40   0   0   0  73   2   0   0   0  19   1   0   7   0  19   2   0   0\n",
      "   0   8   5   0   0   0 418]\n",
      "LR Accuracy:  0.7828282828282829\n",
      "LR F1:  0.35467911704559124\n",
      "For name:  z_ren\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-7606-0331': 25, '0000-0001-7265-065X': 4, '0000-0002-4559-4637': 1, '0000-0003-4208-5076': 1})\n",
      "['0000-0001-7606-0331']\n",
      "Total sample size after apply threshold:  25\n",
      "For name:  m_kumar\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0003-3769-052X': 22, '0000-0003-1656-1649': 16, '0000-0003-0970-4875': 14, '0000-0001-9173-3872': 10, '0000-0002-0855-3406': 9, '0000-0002-9049-2760': 6, '0000-0002-3554-0563': 4, '0000-0002-4198-5892': 4, '0000-0003-3490-5062': 3, '0000-0002-7630-7389': 2, '0000-0001-6657-1277': 2, '0000-0002-0141-5318': 2, '0000-0001-6745-7425': 2, '0000-0001-5606-401X': 2, '0000-0001-6389-2040': 2, '0000-0002-7936-9892': 1, '0000-0001-5545-3793': 1, '0000-0002-7728-5572': 1, '0000-0001-6578-9741': 1})\n",
      "['0000-0003-1656-1649', '0000-0003-3769-052X', '0000-0003-0970-4875', '0000-0001-9173-3872']\n",
      "Total sample size after apply threshold:  62\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 36)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 13)\n",
      "2\n",
      "(62, 49)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.75      0.63        16\n",
      "          1       0.67      0.82      0.73        22\n",
      "          2       0.60      0.43      0.50        14\n",
      "          3       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.67      0.63      0.61        62\n",
      "\n",
      "[12  4  0  0  3 18  1  0  5  3  6  0  2  2  3  3]\n",
      "MNB Accuracy:  0.6290322580645161\n",
      "MNB F1:  0.5819528216144757\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.81      0.70        16\n",
      "          1       0.67      0.82      0.73        22\n",
      "          2       0.88      0.50      0.64        14\n",
      "          3       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.76      0.71      0.71        62\n",
      "\n",
      "[13  3  0  0  3 18  1  0  4  3  7  0  1  3  0  6]\n",
      "svc Accuracy:  0.7096774193548387\n",
      "svc F1:  0.7059400541543398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.69      0.61        16\n",
      "          1       0.60      0.82      0.69        22\n",
      "          2       0.67      0.43      0.52        14\n",
      "          3       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.67      0.61      0.60        62\n",
      "\n",
      "[11  5  0  0  3 18  1  0  5  3  6  0  1  4  2  3]\n",
      "LR Accuracy:  0.6129032258064516\n",
      "LR F1:  0.5716740988480119\n",
      "For name:  j_wong\n",
      "total sample size before apply threshold:  183\n",
      "Counter({'0000-0003-2953-7728': 59, '0000-0003-2592-3226': 30, '0000-0002-7213-4898': 24, '0000-0001-5572-4143': 21, '0000-0002-8167-540X': 17, '0000-0001-8268-5610': 10, '0000-0001-8080-1294': 8, '0000-0002-9206-3257': 5, '0000-0002-9329-1075': 4, '0000-0003-3897-7725': 4, '0000-0002-6317-2067': 1})\n",
      "['0000-0003-2592-3226', '0000-0001-5572-4143', '0000-0002-8167-540X', '0000-0001-8268-5610', '0000-0003-2953-7728', '0000-0002-7213-4898']\n",
      "Total sample size after apply threshold:  161\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(161, 96)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(161, 17)\n",
      "2\n",
      "(161, 113)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.33      0.38        30\n",
      "          1       0.14      0.05      0.07        21\n",
      "          2       0.43      0.18      0.25        17\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.51      0.93      0.66        59\n",
      "          5       1.00      0.71      0.83        24\n",
      "\n",
      "avg / total       0.48      0.53      0.47       161\n",
      "\n",
      "[10  2  1  0 17  0  4  1  2  0 14  0  2  2  3  0 10  0  3  0  0  0  7  0\n",
      "  1  2  1  0 55  0  2  0  0  0  5 17]\n",
      "MNB Accuracy:  0.5341614906832298\n",
      "MNB F1:  0.36566581390957026\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.37      0.46        30\n",
      "          1       0.08      0.05      0.06        21\n",
      "          2       0.33      0.18      0.23        17\n",
      "          3       0.71      0.50      0.59        10\n",
      "          4       0.54      0.86      0.67        59\n",
      "          5       1.00      0.83      0.91        24\n",
      "\n",
      "avg / total       0.55      0.57      0.53       161\n",
      "\n",
      "[11  3  2  1 13  0  3  1  3  0 14  0  1  3  3  1  9  0  2  0  0  5  3  0\n",
      "  1  6  1  0 51  0  0  0  0  0  4 20]\n",
      "svc Accuracy:  0.5652173913043478\n",
      "svc F1:  0.48531982723159195\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.30      0.37        30\n",
      "          1       0.14      0.05      0.07        21\n",
      "          2       0.50      0.18      0.26        17\n",
      "          3       0.50      0.10      0.17        10\n",
      "          4       0.50      0.95      0.65        59\n",
      "          5       1.00      0.67      0.80        24\n",
      "\n",
      "avg / total       0.53      0.53      0.48       161\n",
      "\n",
      "[ 9  2  0  1 18  0  3  1  2  0 15  0  1  3  3  0 10  0  2  0  0  1  7  0\n",
      "  1  1  1  0 56  0  2  0  0  0  6 16]\n",
      "LR Accuracy:  0.5341614906832298\n",
      "LR F1:  0.38815592725775794\n",
      "For name:  s_turner\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0003-4859-1068': 40, '0000-0002-8439-4507': 32, '0000-0002-1002-0000': 16, '0000-0001-8692-8210': 5, '0000-0003-2308-158X': 4, '0000-0001-5108-7976': 2, '0000-0003-2541-6072': 1, '0000-0003-2735-3220': 1})\n",
      "['0000-0002-1002-0000', '0000-0003-4859-1068', '0000-0002-8439-4507']\n",
      "Total sample size after apply threshold:  88\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 42)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 22)\n",
      "2\n",
      "(88, 64)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.06      0.09        16\n",
      "          1       0.74      0.80      0.77        40\n",
      "          2       0.54      0.66      0.59        32\n",
      "\n",
      "avg / total       0.56      0.61      0.58        88\n",
      "\n",
      "[ 1  4 11  1 32  7  4  7 21]\n",
      "MNB Accuracy:  0.6136363636363636\n",
      "MNB F1:  0.48451424134437876\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.44      0.41        16\n",
      "          1       0.74      0.70      0.72        40\n",
      "          2       0.62      0.62      0.62        32\n",
      "\n",
      "avg / total       0.63      0.62      0.63        88\n",
      "\n",
      "[ 7  3  6  6 28  6  5  7 20]\n",
      "svc Accuracy:  0.625\n",
      "svc F1:  0.584904474610357\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.66      0.78      0.71        40\n",
      "          2       0.56      0.62      0.59        32\n",
      "\n",
      "avg / total       0.50      0.58      0.54        88\n",
      "\n",
      "[ 0  7  9  2 31  7  3  9 20]\n",
      "LR Accuracy:  0.5795454545454546\n",
      "LR F1:  0.4336263240928555\n",
      "For name:  y_yuan\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0003-1376-0028': 17, '0000-0001-7094-4419': 11, '0000-0003-4284-3973': 10, '0000-0003-4706-7897': 10, '0000-0002-7577-3257': 9, '0000-0003-3020-0700': 4, '0000-0002-1761-9040': 3, '0000-0002-6719-2567': 1, '0000-0002-1823-3174': 1, '0000-0002-2292-7339': 1})\n",
      "['0000-0003-1376-0028', '0000-0003-4284-3973', '0000-0003-4706-7897', '0000-0001-7094-4419']\n",
      "Total sample size after apply threshold:  48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 34)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 14)\n",
      "2\n",
      "(48, 48)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.82      0.68        17\n",
      "          1       0.83      0.50      0.62        10\n",
      "          2       0.36      0.40      0.38        10\n",
      "          3       0.43      0.27      0.33        11\n",
      "\n",
      "avg / total       0.55      0.54      0.53        48\n",
      "\n",
      "[14  0  2  1  4  5  1  0  2  1  4  3  4  0  4  3]\n",
      "MNB Accuracy:  0.5416666666666666\n",
      "MNB F1:  0.5055531358885017\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.76      0.63        17\n",
      "          1       0.86      0.60      0.71        10\n",
      "          2       0.50      0.50      0.50        10\n",
      "          3       0.86      0.55      0.67        11\n",
      "\n",
      "avg / total       0.67      0.62      0.63        48\n",
      "\n",
      "[13  1  3  0  4  6  0  0  4  0  5  1  3  0  2  6]\n",
      "svc Accuracy:  0.625\n",
      "svc F1:  0.6266738402678144\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.82      0.70        17\n",
      "          1       0.86      0.60      0.71        10\n",
      "          2       0.40      0.40      0.40        10\n",
      "          3       0.50      0.36      0.42        11\n",
      "\n",
      "avg / total       0.59      0.58      0.57        48\n",
      "\n",
      "[14  0  2  1  4  6  0  0  2  1  4  3  3  0  4  4]\n",
      "LR Accuracy:  0.5833333333333334\n",
      "LR F1:  0.556733746130031\n",
      "For name:  l_liu\n",
      "total sample size before apply threshold:  267\n",
      "Counter({'0000-0003-2732-7399': 36, '0000-0003-1844-338X': 35, '0000-0001-6997-8101': 24, '0000-0003-4934-0367': 17, '0000-0002-6944-5417': 15, '0000-0002-8884-4819': 14, '0000-0003-3631-2148': 13, '0000-0001-5868-4482': 11, '0000-0002-5696-3151': 10, '0000-0002-1450-4950': 9, '0000-0002-5054-2372': 9, '0000-0003-3269-8741': 8, '0000-0002-3710-7042': 8, '0000-0002-8396-0554': 7, '0000-0003-2949-6348': 7, '0000-0002-8924-4890': 6, '0000-0002-4604-4629': 6, '0000-0001-5476-0169': 4, '0000-0002-0493-9272': 4, '0000-0002-6159-7475': 4, '0000-0002-7775-5933': 4, '0000-0003-2741-2542': 2, '0000-0001-8689-1788': 2, '0000-0002-4852-1580': 2, '0000-0002-4811-4897': 1, '0000-0003-1506-2370': 1, '0000-0002-4561-1433': 1, '0000-0001-5056-1517': 1, '0000-0003-2230-2934': 1, '0000-0003-0030-3581': 1, '0000-0002-6506-3462': 1, '0000-0002-2213-8057': 1, '0000-0003-0194-1454': 1, '0000-0002-8468-327X': 1})\n",
      "['0000-0002-8884-4819', '0000-0003-3631-2148', '0000-0001-6997-8101', '0000-0003-4934-0367', '0000-0003-1844-338X', '0000-0002-5696-3151', '0000-0002-6944-5417', '0000-0001-5868-4482', '0000-0003-2732-7399']\n",
      "Total sample size after apply threshold:  175\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 87)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 13)\n",
      "2\n",
      "(175, 100)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.29      0.42        14\n",
      "          1       0.71      0.38      0.50        13\n",
      "          2       0.43      0.50      0.46        24\n",
      "          3       0.45      0.76      0.57        17\n",
      "          4       0.40      0.54      0.46        35\n",
      "          5       1.00      0.20      0.33        10\n",
      "          6       1.00      0.07      0.12        15\n",
      "          7       0.00      0.00      0.00        11\n",
      "          8       0.51      0.78      0.62        36\n",
      "\n",
      "avg / total       0.55      0.48      0.44       175\n",
      "\n",
      "[ 4  0  3  1  4  0  0  0  2  0  5  2  1  3  0  0  0  2  1  0 12  2  5  0\n",
      "  0  0  4  0  0  1 13  1  0  0  0  2  0  1  4  2 19  0  0  0  9  0  0  2\n",
      "  3  3  2  0  0  0  0  0  3  1  4  0  1  0  6  0  1  0  0  8  0  0  0  2\n",
      "  0  0  1  6  1  0  0  0 28]\n",
      "MNB Accuracy:  0.48\n",
      "MNB F1:  0.3865953064934345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.36      0.48        14\n",
      "          1       1.00      0.69      0.82        13\n",
      "          2       0.47      0.58      0.52        24\n",
      "          3       0.83      0.59      0.69        17\n",
      "          4       0.47      0.77      0.59        35\n",
      "          5       1.00      0.80      0.89        10\n",
      "          6       1.00      0.73      0.85        15\n",
      "          7       0.00      0.00      0.00        11\n",
      "          8       0.78      0.78      0.78        36\n",
      "\n",
      "avg / total       0.67      0.64      0.64       175\n",
      "\n",
      "[ 5  0  4  0  5  0  0  0  0  0  9  1  0  1  0  0  1  1  1  0 14  0  9  0\n",
      "  0  0  0  0  0  1 10  1  0  0  0  5  1  0  5  0 27  0  0  2  0  0  0  1\n",
      "  0  1  8  0  0  0  0  0  1  0  3  0 11  0  0  0  0  1  0  8  0  0  0  2\n",
      "  0  0  2  2  2  0  0  2 28]\n",
      "svc Accuracy:  0.64\n",
      "svc F1:  0.6224803355404721\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.36      0.50        14\n",
      "          1       0.75      0.46      0.57        13\n",
      "          2       0.42      0.58      0.49        24\n",
      "          3       0.86      0.71      0.77        17\n",
      "          4       0.47      0.63      0.54        35\n",
      "          5       1.00      0.60      0.75        10\n",
      "          6       1.00      0.47      0.64        15\n",
      "          7       0.00      0.00      0.00        11\n",
      "          8       0.56      0.81      0.66        36\n",
      "\n",
      "avg / total       0.62      0.58      0.57       175\n",
      "\n",
      "[ 5  0  4  0  2  0  0  0  3  0  6  2  0  3  0  0  1  1  1  0 14  0  5  0\n",
      "  0  0  4  0  0  1 12  1  0  0  0  3  0  1  4  0 22  0  0  1  7  0  0  1\n",
      "  0  3  6  0  0  0  0  0  2  0  3  0  7  0  3  0  1  1  0  7  0  0  0  2\n",
      "  0  0  4  2  1  0  0  0 29]\n",
      "LR Accuracy:  0.5771428571428572\n",
      "LR F1:  0.5465433445888123\n",
      "For name:  a_fonseca\n",
      "total sample size before apply threshold:  91\n",
      "Counter({'0000-0001-6913-5526': 24, '0000-0001-6237-417X': 13, '0000-0003-1395-1406': 7, '0000-0001-8413-9744': 6, '0000-0003-1118-5525': 6, '0000-0001-9624-7208': 5, '0000-0002-7145-2472': 5, '0000-0001-7505-7878': 4, '0000-0002-6382-6833': 4, '0000-0001-6792-8047': 4, '0000-0002-9087-1306': 4, '0000-0002-1715-5469': 3, '0000-0002-6925-1671': 2, '0000-0002-3207-4819': 2, '0000-0002-6661-5185': 1, '0000-0001-7410-269X': 1})\n",
      "['0000-0001-6237-417X', '0000-0001-6913-5526']\n",
      "Total sample size after apply threshold:  37\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 25)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 11)\n",
      "2\n",
      "(37, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.38      0.50        13\n",
      "          1       0.73      0.92      0.81        24\n",
      "\n",
      "avg / total       0.73      0.73      0.70        37\n",
      "\n",
      "[ 5  8  2 22]\n",
      "MNB Accuracy:  0.7297297297297297\n",
      "MNB F1:  0.6574074074074074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.54      0.64        13\n",
      "          1       0.79      0.92      0.85        24\n",
      "\n",
      "avg / total       0.78      0.78      0.77        37\n",
      "\n",
      "[ 7  6  2 22]\n",
      "svc Accuracy:  0.7837837837837838\n",
      "svc F1:  0.7412587412587412\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.23      0.35        13\n",
      "          1       0.70      0.96      0.81        24\n",
      "\n",
      "avg / total       0.72      0.70      0.65        37\n",
      "\n",
      "[ 3 10  1 23]\n",
      "LR Accuracy:  0.7027027027027027\n",
      "LR F1:  0.5799793601651188\n",
      "For name:  r_francis\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0002-3995-7040': 6, '0000-0001-8240-4903': 4, '0000-0002-4598-0861': 2, '0000-0003-1580-7934': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  l_castro\n",
      "total sample size before apply threshold:  74\n",
      "Counter({'0000-0001-7697-386X': 47, '0000-0003-3384-3832': 9, '0000-0002-0852-8235': 7, '0000-0003-3048-933X': 4, '0000-0002-1312-0154': 4, '0000-0002-1359-5272': 3})\n",
      "['0000-0001-7697-386X']\n",
      "Total sample size after apply threshold:  47\n",
      "For name:  k_zhou\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-1898-6379': 5, '0000-0002-0351-8812': 3, '0000-0002-2844-1604': 3, '0000-0001-6645-5102': 2, '0000-0001-6442-0475': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_macdonald\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-9851-3610': 38, '0000-0001-7946-0023': 11, '0000-0002-6295-6978': 2, '0000-0001-5421-3536': 1})\n",
      "['0000-0001-7946-0023', '0000-0001-9851-3610']\n",
      "Total sample size after apply threshold:  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 11)\n",
      "2\n",
      "(49, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        11\n",
      "          1       0.84      1.00      0.92        38\n",
      "\n",
      "avg / total       0.88      0.86      0.83        49\n",
      "\n",
      "[ 4  7  0 38]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.7244979919678715\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.88      1.00      0.94        38\n",
      "\n",
      "avg / total       0.91      0.90      0.89        49\n",
      "\n",
      "[ 6  5  0 38]\n",
      "svc Accuracy:  0.8979591836734694\n",
      "svc F1:  0.822076978939724\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       0.81      1.00      0.89        38\n",
      "\n",
      "avg / total       0.85      0.82      0.76        49\n",
      "\n",
      "[ 2  9  0 38]\n",
      "LR Accuracy:  0.8163265306122449\n",
      "LR F1:  0.6009049773755656\n",
      "For name:  h_guan\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-4683-601X': 17, '0000-0002-4858-3159': 16, '0000-0002-2282-3193': 8, '0000-0001-5425-6974': 3})\n",
      "['0000-0002-4858-3159', '0000-0002-4683-601X']\n",
      "Total sample size after apply threshold:  33\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 11)\n",
      "2\n",
      "(33, 31)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.69      0.73        16\n",
      "          1       0.74      0.82      0.78        17\n",
      "\n",
      "avg / total       0.76      0.76      0.76        33\n",
      "\n",
      "[11  5  3 14]\n",
      "MNB Accuracy:  0.7575757575757576\n",
      "MNB F1:  0.7555555555555555\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.81      0.87        16\n",
      "          1       0.84      0.94      0.89        17\n",
      "\n",
      "avg / total       0.88      0.88      0.88        33\n",
      "\n",
      "[13  3  1 16]\n",
      "svc Accuracy:  0.8787878787878788\n",
      "svc F1:  0.8777777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.69      0.76        16\n",
      "          1       0.75      0.88      0.81        17\n",
      "\n",
      "avg / total       0.80      0.79      0.79        33\n",
      "\n",
      "[11  5  2 15]\n",
      "LR Accuracy:  0.7878787878787878\n",
      "LR F1:  0.7847157502329916\n",
      "For name:  t_miller\n",
      "total sample size before apply threshold:  165\n",
      "Counter({'0000-0002-0958-2639': 102, '0000-0003-0731-8006': 42, '0000-0002-1269-1895': 11, '0000-0002-5585-7736': 6, '0000-0002-9749-1656': 3, '0000-0003-4027-7066': 1})"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['0000-0002-0958-2639', '0000-0002-1269-1895', '0000-0003-0731-8006']\n",
      "Total sample size after apply threshold:  155\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(155, 58)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(155, 25)\n",
      "2\n",
      "(155, 83)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92       102\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.83      0.90      0.86        42\n",
      "\n",
      "avg / total       0.81      0.87      0.84       155\n",
      "\n",
      "[97  0  5  8  0  3  4  0 38]\n",
      "MNB Accuracy:  0.8709677419354839\n",
      "MNB F1:  0.5943558810857389\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       102\n",
      "          1       0.67      0.18      0.29        11\n",
      "          2       0.97      0.83      0.90        42\n",
      "\n",
      "avg / total       0.89      0.90      0.88       155\n",
      "\n",
      "[102   0   0   8   2   1   6   1  35]\n",
      "svc Accuracy:  0.896774193548387\n",
      "svc F1:  0.7063099998879815\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       102\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.76      0.86        42\n",
      "\n",
      "avg / total       0.82      0.86      0.83       155\n",
      "\n",
      "[102   0   0  11   0   0  10   0  32]\n",
      "LR Accuracy:  0.864516129032258\n",
      "LR F1:  0.5905105105105105\n",
      "For name:  m_kang\n",
      "total sample size before apply threshold:  131\n",
      "Counter({'0000-0003-1595-1717': 38, '0000-0003-3245-144X': 19, '0000-0002-2039-4866': 18, '0000-0002-4778-8240': 13, '0000-0002-1530-7254': 12, '0000-0003-2140-4234': 10, '0000-0002-8795-2973': 8, '0000-0001-5266-2290': 5, '0000-0002-5054-7587': 4, '0000-0003-4946-8512': 2, '0000-0001-6991-0481': 1, '0000-0001-7600-7469': 1})\n",
      "['0000-0003-1595-1717', '0000-0002-4778-8240', '0000-0002-1530-7254', '0000-0003-2140-4234', '0000-0002-2039-4866', '0000-0003-3245-144X']\n",
      "Total sample size after apply threshold:  110\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(110, 63)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(110, 14)\n",
      "2\n",
      "(110, 77)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.95      0.68        38\n",
      "          1       0.50      0.15      0.24        13\n",
      "          2       0.62      0.67      0.64        12\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.71      0.67      0.69        18\n",
      "          5       0.71      0.26      0.38        19\n",
      "\n",
      "avg / total       0.55      0.57      0.51       110\n",
      "\n",
      "[36  0  1  0  1  0  8  2  1  1  1  0  3  0  8  0  0  1  9  0  0  0  1  0\n",
      "  4  1  0  0 12  1  8  1  3  0  2  5]\n",
      "MNB Accuracy:  0.5727272727272728\n",
      "MNB F1:  0.4374781784992661\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.89      0.74        38\n",
      "          1       0.40      0.31      0.35        13\n",
      "          2       0.71      0.83      0.77        12\n",
      "          3       0.75      0.30      0.43        10\n",
      "          4       0.76      0.72      0.74        18\n",
      "          5       0.91      0.53      0.67        19\n",
      "\n",
      "avg / total       0.69      0.67      0.66       110\n",
      "\n",
      "[34  1  1  0  2  0  6  4  1  1  1  0  2  0 10  0  0  0  5  2  0  3  0  0\n",
      "  3  1  0  0 13  1  4  2  2  0  1 10]\n",
      "svc Accuracy:  0.6727272727272727\n",
      "svc F1:  0.6157137548441896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.92      0.71        38\n",
      "          1       0.38      0.23      0.29        13\n",
      "          2       0.67      0.83      0.74        12\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.75      0.67      0.71        18\n",
      "          5       0.80      0.42      0.55        19\n",
      "\n",
      "avg / total       0.58      0.62      0.57       110\n",
      "\n",
      "[35  0  1  0  1  1  8  3  1  0  1  0  2  0 10  0  0  0  8  1  0  0  1  0\n",
      "  4  1  0  0 12  1  4  3  3  0  1  8]\n",
      "LR Accuracy:  0.6181818181818182\n",
      "LR F1:  0.4985220373996575\n",
      "For name:  z_shi\n",
      "total sample size before apply threshold:  180\n",
      "Counter({'0000-0002-3099-3299': 94, '0000-0002-9624-4960': 25, '0000-0003-2388-6695': 22, '0000-0001-5357-1171': 13, '0000-0002-3928-2960': 12, '0000-0002-3865-0098': 9, '0000-0001-9922-3957': 2, '0000-0002-7798-1121': 1, '0000-0002-8328-0305': 1, '0000-0002-5828-1904': 1})\n",
      "['0000-0002-3099-3299', '0000-0001-5357-1171', '0000-0002-3928-2960', '0000-0002-9624-4960', '0000-0003-2388-6695']\n",
      "Total sample size after apply threshold:  166\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(166, 90)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(166, 13)\n",
      "2\n",
      "(166, 103)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      1.00      0.77        94\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       0.90      0.36      0.51        25\n",
      "          4       1.00      0.32      0.48        22\n",
      "\n",
      "avg / total       0.63      0.66      0.58       166\n",
      "\n",
      "[94  0  0  0  0 12  0  0  1  0 12  0  0  0  0 16  0  0  9  0 15  0  0  0\n",
      "  7]\n",
      "MNB Accuracy:  0.6626506024096386\n",
      "MNB F1:  0.35414137728313977\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84        94\n",
      "          1       1.00      0.54      0.70        13\n",
      "          2       1.00      0.42      0.59        12\n",
      "          3       0.94      0.60      0.73        25\n",
      "          4       1.00      0.32      0.48        22\n",
      "\n",
      "avg / total       0.83      0.77      0.74       166\n",
      "\n",
      "[94  0  0  0  0  5  7  0  1  0  7  0  5  0  0 10  0  0 15  0 15  0  0  0\n",
      "  7]\n",
      "svc Accuracy:  0.7710843373493976\n",
      "svc F1:  0.6676513574872056\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      1.00      0.77        94\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       1.00      0.08      0.15        12\n",
      "          3       0.89      0.32      0.47        25\n",
      "          4       1.00      0.32      0.48        22\n",
      "\n",
      "avg / total       0.70      0.66      0.58       166\n",
      "\n",
      "[94  0  0  0  0 12  0  0  1  0 11  0  1  0  0 17  0  0  8  0 15  0  0  0\n",
      "  7]\n",
      "LR Accuracy:  0.6626506024096386\n",
      "LR F1:  0.3761711122540512\n",
      "For name:  t_johnson\n",
      "total sample size before apply threshold:  293\n",
      "Counter({'0000-0001-7147-8237': 174, '0000-0002-5998-3270': 76, '0000-0003-3377-6692': 21, '0000-0002-5372-5457': 17, '0000-0002-9499-3538': 2, '0000-0002-6170-5077': 1, '0000-0002-2724-7017': 1, '0000-0001-6596-6437': 1})\n",
      "['0000-0001-7147-8237', '0000-0003-3377-6692', '0000-0002-5372-5457', '0000-0002-5998-3270']\n",
      "Total sample size after apply threshold:  288\n",
      "(0, 0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(288, 103)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(288, 37)\n",
      "2\n",
      "(288, 140)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91       174\n",
      "          1       0.00      0.00      0.00        21\n",
      "          2       1.00      0.06      0.11        17\n",
      "          3       0.66      0.87      0.75        76\n",
      "\n",
      "avg / total       0.76      0.80      0.75       288\n",
      "\n",
      "[163   0   0  11   9   0   0  12   5   0   1  11   9   1   0  66]\n",
      "MNB Accuracy:  0.7986111111111112\n",
      "MNB F1:  0.44166666666666665\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.92       174\n",
      "          1       0.00      0.00      0.00        21\n",
      "          2       0.89      0.47      0.62        17\n",
      "          3       0.68      0.79      0.73        76\n",
      "\n",
      "avg / total       0.77      0.81      0.78       288\n",
      "\n",
      "[164   0   0  10   8   0   1  12   2   1   8   6  10   6   0  60]\n",
      "svc Accuracy:  0.8055555555555556\n",
      "svc F1:  0.5658232624440555\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.90       174\n",
      "          1       0.00      0.00      0.00        21\n",
      "          2       1.00      0.12      0.21        17\n",
      "          3       0.71      0.79      0.75        76\n",
      "\n",
      "avg / total       0.75      0.80      0.75       288\n",
      "\n",
      "[167   0   0   7  11   0   0  10   7   0   2   8  14   2   0  60]\n",
      "LR Accuracy:  0.7951388888888888\n",
      "LR F1:  0.46282757248640893\n",
      "For name:  m_ferretti\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0003-0280-3598': 29, '0000-0003-2961-6362': 8, '0000-0003-0709-3281': 5, '0000-0002-7578-6699': 1})\n",
      "['0000-0003-0280-3598']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  b_peng\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0001-8225-2284': 19, '0000-0003-4183-5939': 4, '0000-0002-5599-6779': 1, '0000-0002-1099-1229': 1})\n",
      "['0000-0001-8225-2284']\n",
      "Total sample size after apply threshold:  19\n",
      "For name:  m_fernandes\n",
      "total sample size before apply threshold:  118\n",
      "Counter({'0000-0001-9391-9574': 60, '0000-0002-1840-616X': 28, '0000-0002-0765-474X': 7, '0000-0001-6533-4309': 6, '0000-0001-7969-2107': 3, '0000-0002-1206-1367': 3, '0000-0001-9239-1202': 3, '0000-0001-7536-2506': 3, '0000-0002-0051-3389': 2, '0000-0002-8009-7513': 2, '0000-0002-9556-7741': 1})\n",
      "['0000-0001-9391-9574', '0000-0002-1840-616X']\n",
      "Total sample size after apply threshold:  88\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 52)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 17)\n",
      "2\n",
      "(88, 69)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.95      0.88        60\n",
      "          1       0.84      0.57      0.68        28\n",
      "\n",
      "avg / total       0.83      0.83      0.82        88\n",
      "\n",
      "[57  3 12 16]\n",
      "MNB Accuracy:  0.8295454545454546\n",
      "MNB F1:  0.7822859970311727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91        60\n",
      "          1       0.90      0.64      0.75        28\n",
      "\n",
      "avg / total       0.87      0.86      0.86        88\n",
      "\n",
      "[58  2 10 18]\n",
      "svc Accuracy:  0.8636363636363636\n",
      "svc F1:  0.828125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        60\n",
      "          1       1.00      0.32      0.49        28\n",
      "\n",
      "avg / total       0.84      0.78      0.74        88\n",
      "\n",
      "[60  0 19  9]\n",
      "LR Accuracy:  0.7840909090909091\n",
      "LR F1:  0.6748979195022361\n",
      "For name:  l_cui\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0001-5549-8780': 18, '0000-0001-5706-9525': 3, '0000-0002-5546-5097': 2, '0000-0002-9818-4543': 1, '0000-0001-5907-0538': 1})\n",
      "['0000-0001-5549-8780']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  s_monteiro\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0002-4026-5965': 19, '0000-0002-7069-0591': 14, '0000-0003-0059-9837': 7, '0000-0002-3037-9635': 4, '0000-0001-5040-6170': 2, '0000-0002-8784-7276': 2, '0000-0002-1389-3851': 1, '0000-0003-3507-9911': 1})\n",
      "['0000-0002-4026-5965', '0000-0002-7069-0591']\n",
      "Total sample size after apply threshold:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 12)\n",
      "2\n",
      "(33, 32)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      1.00      0.81        19\n",
      "          1       1.00      0.36      0.53        14\n",
      "\n",
      "avg / total       0.81      0.73      0.69        33\n",
      "\n",
      "[19  0  9  5]\n",
      "MNB Accuracy:  0.7272727272727273\n",
      "MNB F1:  0.6674132138857782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.95      0.88        19\n",
      "          1       0.91      0.71      0.80        14\n",
      "\n",
      "avg / total       0.86      0.85      0.84        33\n",
      "\n",
      "[18  1  4 10]\n",
      "svc Accuracy:  0.8484848484848485\n",
      "svc F1:  0.8390243902439025\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.95      0.82        19\n",
      "          1       0.88      0.50      0.64        14\n",
      "\n",
      "avg / total       0.79      0.76      0.74        33\n",
      "\n",
      "[18  1  7  7]\n",
      "LR Accuracy:  0.7575757575757576\n",
      "LR F1:  0.7272727272727273\n",
      "For name:  m_hsieh\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0003-3636-6250': 15, '0000-0001-5254-1341': 10, '0000-0002-3396-8427': 5, '0000-0002-7833-847X': 4, '0000-0002-3706-6615': 1})\n",
      "['0000-0003-3636-6250', '0000-0001-5254-1341']\n",
      "Total sample size after apply threshold:  25\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 15)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 10)\n",
      "2\n",
      "(25, 25)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.87      0.81        15\n",
      "          1       0.75      0.60      0.67        10\n",
      "\n",
      "avg / total       0.76      0.76      0.75        25\n",
      "\n",
      "[13  2  4  6]\n",
      "MNB Accuracy:  0.76\n",
      "MNB F1:  0.7395833333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        15\n",
      "          1       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.90      0.88      0.87        25\n",
      "\n",
      "[15  0  3  7]\n",
      "svc Accuracy:  0.88\n",
      "svc F1:  0.8663101604278074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.87      0.81        15\n",
      "          1       0.75      0.60      0.67        10\n",
      "\n",
      "avg / total       0.76      0.76      0.75        25\n",
      "\n",
      "[13  2  4  6]\n",
      "LR Accuracy:  0.76\n",
      "LR F1:  0.7395833333333333\n",
      "For name:  c_nelson\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0003-1034-140X': 16, '0000-0003-0195-5610': 6, '0000-0001-5824-2457': 1, '0000-0003-2525-3496': 1, '0000-0001-6287-1598': 1, '0000-0002-4114-1710': 1})\n",
      "['0000-0003-1034-140X']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  j_barnett\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0003-0664-4168': 13, '0000-0002-0862-0808': 5, '0000-0001-5381-0064': 4, '0000-0002-4213-4010': 1})\n",
      "['0000-0003-0664-4168']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  j_tian\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0002-4008-0469': 10, '0000-0001-6373-6953': 9, '0000-0001-5313-1600': 1, '0000-0002-5896-2515': 1, '0000-0001-9555-0387': 1})\n",
      "['0000-0002-4008-0469']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  f_costa\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0002-3097-2834': 22, '0000-0001-5398-3942': 14, '0000-0002-6547-6005': 3, '0000-0001-9368-5640': 3, '0000-0001-8981-7049': 3, '0000-0003-3914-6317': 2, '0000-0001-8729-714X': 2, '0000-0003-0562-2514': 1, '0000-0002-1409-5325': 1, '0000-0001-7572-2014': 1})\n",
      "['0000-0002-3097-2834', '0000-0001-5398-3942']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  36\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 25)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 10)\n",
      "2\n",
      "(36, 35)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        22\n",
      "          1       1.00      0.57      0.73        14\n",
      "\n",
      "avg / total       0.87      0.83      0.82        36\n",
      "\n",
      "[22  0  6  8]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.8036363636363637\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        22\n",
      "          1       1.00      0.86      0.92        14\n",
      "\n",
      "avg / total       0.95      0.94      0.94        36\n",
      "\n",
      "[22  0  2 12]\n",
      "svc Accuracy:  0.9444444444444444\n",
      "svc F1:  0.939799331103679\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        22\n",
      "          1       1.00      0.86      0.92        14\n",
      "\n",
      "avg / total       0.95      0.94      0.94        36\n",
      "\n",
      "[22  0  2 12]\n",
      "LR Accuracy:  0.9444444444444444\n",
      "LR F1:  0.939799331103679\n",
      "For name:  a_mccarthy\n",
      "total sample size before apply threshold:  88\n",
      "Counter({'0000-0001-7195-6366': 56, '0000-0002-8979-2926': 26, '0000-0001-6896-0225': 4, '0000-0002-3355-9965': 2})\n",
      "['0000-0002-8979-2926', '0000-0001-7195-6366']\n",
      "Total sample size after apply threshold:  82\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 58)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 18)\n",
      "2\n",
      "(82, 76)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.54      0.61        26\n",
      "          1       0.81      0.89      0.85        56\n",
      "\n",
      "avg / total       0.77      0.78      0.77        82\n",
      "\n",
      "[14 12  6 50]\n",
      "MNB Accuracy:  0.7804878048780488\n",
      "MNB F1:  0.7280766396462784\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.73      0.76        26\n",
      "          1       0.88      0.91      0.89        56\n",
      "\n",
      "avg / total       0.85      0.85      0.85        82\n",
      "\n",
      "[19  7  5 51]\n",
      "svc Accuracy:  0.8536585365853658\n",
      "svc F1:  0.8273684210526315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.42      0.54        26\n",
      "          1       0.78      0.93      0.85        56\n",
      "\n",
      "avg / total       0.76      0.77      0.75        82\n",
      "\n",
      "[11 15  4 52]\n",
      "LR Accuracy:  0.7682926829268293\n",
      "LR F1:  0.6910569105691057\n",
      "For name:  y_cheng\n",
      "total sample size before apply threshold:  177\n",
      "Counter({'0000-0001-9150-4690': 38, '0000-0001-7112-8835': 29, '0000-0002-4423-4381': 17, '0000-0003-0125-4267': 16, '0000-0002-2583-228X': 15, '0000-0001-9776-395X': 14, '0000-0002-7529-4408': 11, '0000-0001-6874-8187': 9, '0000-0003-2571-4707': 8, '0000-0002-2077-5335': 5, '0000-0003-4912-9879': 3, '0000-0002-5939-0010': 2, '0000-0002-2431-3197': 2, '0000-0002-1468-6686': 2, '0000-0001-5858-6161': 2, '0000-0002-5906-7694': 1, '0000-0002-2352-8647': 1, '0000-0003-1137-2099': 1, '0000-0003-0822-4458': 1})\n",
      "['0000-0001-9776-395X', '0000-0002-4423-4381', '0000-0003-0125-4267', '0000-0002-2583-228X', '0000-0002-7529-4408', '0000-0001-7112-8835', '0000-0001-9150-4690']\n",
      "Total sample size after apply threshold:  140\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 92)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 19)\n",
      "2\n",
      "(140, 111)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.07      0.12        14\n",
      "          1       1.00      0.12      0.21        17\n",
      "          2       1.00      0.38      0.55        16\n",
      "          3       0.40      0.27      0.32        15\n",
      "          4       0.50      0.09      0.15        11\n",
      "          5       0.62      0.69      0.66        29\n",
      "          6       0.42      0.95      0.59        38\n",
      "\n",
      "avg / total       0.60      0.50      0.44       140\n",
      "\n",
      "[ 1  0  0  0  0  0 13  0  2  0  1  0  3 11  0  0  6  3  0  2  5  0  0  0\n",
      "  4  0  4  7  0  0  0  1  1  2  7  1  0  0  1  1 20  6  1  0  0  0  0  1\n",
      " 36]\n",
      "MNB Accuracy:  0.5\n",
      "MNB F1:  0.3697968046414674\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.11      0.07      0.09        14\n",
      "          1       0.70      0.41      0.52        17\n",
      "          2       1.00      0.56      0.72        16\n",
      "          3       0.38      0.33      0.36        15\n",
      "          4       0.33      0.09      0.14        11\n",
      "          5       0.58      0.72      0.65        29\n",
      "          6       0.52      0.82      0.63        38\n",
      "\n",
      "avg / total       0.54      0.54      0.51       140\n",
      "\n",
      "[ 1  0  0  0  0  2 11  1  7  0  1  1  3  4  0  1  9  2  0  0  4  0  1  0\n",
      "  5  1  5  3  1  1  0  2  1  2  4  3  0  0  2  0 21  3  3  0  0  1  0  3\n",
      " 31]\n",
      "svc Accuracy:  0.5357142857142857\n",
      "svc F1:  0.4434688496622835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.07      0.11        14\n",
      "          1       0.60      0.18      0.27        17\n",
      "          2       1.00      0.38      0.55        16\n",
      "          3       0.42      0.33      0.37        15\n",
      "          4       0.50      0.09      0.15        11\n",
      "          5       0.57      0.72      0.64        29\n",
      "          6       0.45      0.87      0.59        38\n",
      "\n",
      "avg / total       0.53      0.50      0.45       140\n",
      "\n",
      "[ 1  0  0  0  0  2 11  0  3  0  1  0  2 11  0  1  6  3  0  2  4  0  0  0\n",
      "  5  0  6  4  0  1  0  1  1  3  5  1  0  0  1  1 21  5  3  0  0  1  0  1\n",
      " 33]\n",
      "LR Accuracy:  0.5\n",
      "LR F1:  0.38265996160733007\n",
      "For name:  i_hwang\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0002-6122-4417': 51, '0000-0002-5388-1919': 14, '0000-0002-4973-6823': 7, '0000-0003-2949-3075': 7, '0000-0002-5720-1765': 2, '0000-0002-1291-8973': 1, '0000-0002-4479-9374': 1, '0000-0002-0533-4638': 1})\n",
      "['0000-0002-6122-4417', '0000-0002-5388-1919']\n",
      "Total sample size after apply threshold:  65\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 45)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 10)\n",
      "2\n",
      "(65, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95        51\n",
      "          1       0.91      0.71      0.80        14\n",
      "\n",
      "avg / total       0.92      0.92      0.92        65\n",
      "\n",
      "[50  1  4 10]\n",
      "MNB Accuracy:  0.9230769230769231\n",
      "MNB F1:  0.8761904761904762\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93        51\n",
      "          1       0.89      0.57      0.70        14\n",
      "\n",
      "avg / total       0.89      0.89      0.88        65\n",
      "\n",
      "[50  1  6  8]\n",
      "svc Accuracy:  0.8923076923076924\n",
      "svc F1:  0.81511580658269\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        51\n",
      "          1       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.91      0.89      0.88        65\n",
      "\n",
      "[51  0  7  7]\n",
      "LR Accuracy:  0.8923076923076924\n",
      "LR F1:  0.8012232415902141\n",
      "For name:  y_liu\n",
      "total sample size before apply threshold:  965\n",
      "Counter({'0000-0001-8327-3108': 54, '0000-0002-4423-6045': 50, '0000-0002-1862-3121': 46, '0000-0002-2245-4893': 42, '0000-0002-7078-5937': 41, '0000-0002-5247-1678': 38, '0000-0002-6388-9674': 38, '0000-0002-7968-0162': 37, '0000-0001-6677-7961': 28, '0000-0003-0802-3832': 27, '0000-0002-1282-4897': 26, '0000-0002-8417-2488': 23, '0000-0003-1590-0995': 22, '0000-0002-6535-6169': 21, '0000-0002-5880-8649': 21, '0000-0001-9636-990X': 19, '0000-0002-7135-723X': 18, '0000-0002-2885-1670': 18, '0000-0001-6222-5641': 18, '0000-0002-4638-0788': 17, '0000-0001-5304-3459': 17, '0000-0003-1112-4255': 17, '0000-0002-2253-3698': 16, '0000-0003-0180-4142': 15, '0000-0001-5293-5930': 15, '0000-0002-4300-4349': 15, '0000-0002-8320-8725': 14, '0000-0003-4439-8818': 12, '0000-0001-8404-3806': 11, '0000-0001-8181-1080': 11, '0000-0002-3961-2691': 11, '0000-0003-4150-1111': 10, '0000-0001-5198-3674': 10, '0000-0003-1278-7114': 10, '0000-0002-2491-9439': 9, '0000-0003-1618-8813': 9, '0000-0002-8637-661X': 9, '0000-0001-6076-9733': 8, '0000-0003-3205-8963': 8, '0000-0001-6506-5903': 7, '0000-0002-2144-4474': 7, '0000-0003-1420-0276': 7, '0000-0002-8784-8543': 6, '0000-0002-5867-5065': 6, '0000-0001-5960-8166': 5, '0000-0002-4428-3562': 5, '0000-0002-7232-144X': 5, '0000-0001-8903-9101': 4, '0000-0003-2728-4907': 4, '0000-0001-9954-7214': 4, '0000-0001-8118-7775': 4, '0000-0002-6622-6489': 3, '0000-0001-8518-5734': 3, '0000-0002-2883-8329': 3, '0000-0001-6188-993X': 3, '0000-0003-2165-775X': 3, '0000-0002-2923-0729': 2, '0000-0002-0084-863X': 2, '0000-0002-4345-0138': 2, '0000-0002-3483-5909': 2, '0000-0003-3698-4892': 2, '0000-0002-1109-7704': 2, '0000-0003-3687-1337': 2, '0000-0002-8903-2062': 2, '0000-0003-1630-4052': 2, '0000-0001-8672-6301': 2, '0000-0002-8195-7706': 2, '0000-0001-9319-5940': 1, '0000-0002-9005-9166': 1, '0000-0001-5030-2435': 1, '0000-0002-1899-2082': 1, '0000-0001-8371-9579': 1, '0000-0002-2089-2486': 1, '0000-0002-4715-3800': 1, '0000-0003-4912-1746': 1, '0000-0003-4464-1785': 1, '0000-0003-4897-5299': 1, '0000-0003-2706-383X': 1, '0000-0003-4671-698X': 1, '0000-0001-8473-0024': 1, '0000-0002-7571-3123': 1, '0000-0002-6893-6724': 1, '0000-0002-3426-8780': 1, '0000-0002-2515-4431': 1, '0000-0001-5617-661X': 1, '0000-0001-5562-7757': 1, '0000-0002-9754-6370': 1, '0000-0001-9642-1042': 1, '0000-0001-6504-4598': 1, '0000-0003-4861-6915': 1, '0000-0002-8843-1555': 1, '0000-0001-8922-9976': 1, '0000-0002-6003-9121': 1, '0000-0002-9665-7140': 1, '0000-0002-9465-1220': 1, '0000-0002-8591-2599': 1, '0000-0002-0949-6917': 1, '0000-0001-6624-7549': 1, '0000-0003-3703-2498': 1, '0000-0002-8681-4472': 1})\n",
      "['0000-0002-7078-5937', '0000-0001-6677-7961', '0000-0002-8320-8725', '0000-0002-5247-1678', '0000-0002-2245-4893', '0000-0002-4638-0788', '0000-0002-6535-6169', '0000-0002-7968-0162', '0000-0003-4439-8818', '0000-0003-1590-0995', '0000-0002-4423-6045', '0000-0003-0802-3832', '0000-0002-7135-723X', '0000-0002-2253-3698', '0000-0002-2885-1670', '0000-0001-8404-3806', '0000-0003-0180-4142', '0000-0002-1282-4897', '0000-0001-9636-990X', '0000-0001-5293-5930', '0000-0003-4150-1111', '0000-0001-5304-3459', '0000-0002-4300-4349', '0000-0001-6222-5641', '0000-0001-8181-1080', '0000-0002-8417-2488', '0000-0002-6388-9674', '0000-0003-1112-4255', '0000-0001-5198-3674', '0000-0002-1862-3121', '0000-0002-3961-2691', '0000-0001-8327-3108', '0000-0003-1278-7114', '0000-0002-5880-8649']\n",
      "Total sample size after apply threshold:  788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(788, 288)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(788, 20)\n",
      "2\n",
      "(788, 308)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.16      0.37      0.22        41\n",
      "          1       0.45      0.64      0.53        28\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.62      0.26      0.37        38\n",
      "          4       0.27      0.67      0.39        42\n",
      "          5       0.80      0.24      0.36        17\n",
      "          6       0.21      0.24      0.22        21\n",
      "          7       0.50      0.19      0.27        37\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.44      0.50      0.47        22\n",
      "         10       0.38      0.64      0.48        50\n",
      "         11       0.00      0.00      0.00        27\n",
      "         12       0.20      0.06      0.09        18\n",
      "         13       0.00      0.00      0.00        16\n",
      "         14       1.00      0.11      0.20        18\n",
      "         15       0.00      0.00      0.00        11\n",
      "         16       0.00      0.00      0.00        15\n",
      "         17       0.54      0.27      0.36        26\n",
      "         18       1.00      0.47      0.64        19\n",
      "         19       0.00      0.00      0.00        15\n",
      "         20       0.00      0.00      0.00        10\n",
      "         21       0.00      0.00      0.00        17\n",
      "         22       0.00      0.00      0.00        15\n",
      "         23       0.17      0.06      0.08        18\n",
      "         24       0.00      0.00      0.00        11\n",
      "         25       0.00      0.00      0.00        23\n",
      "         26       0.44      0.53      0.48        38\n",
      "         27       1.00      0.12      0.21        17\n",
      "         28       0.00      0.00      0.00        10\n",
      "         29       0.28      0.72      0.40        46\n",
      "         30       0.83      0.45      0.59        11\n",
      "         31       0.26      0.78      0.39        54\n",
      "         32       0.00      0.00      0.00        10\n",
      "         33       0.21      0.14      0.17        21\n",
      "\n",
      "avg / total       0.32      0.32      0.27       788\n",
      "\n",
      "[15  2  0 ...  2  0  3]\n",
      "MNB Accuracy:  0.3236040609137056\n",
      "MNB F1:  0.2040834740425633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.11      0.34      0.17        41\n",
      "          1       0.47      0.57      0.52        28\n",
      "          2       0.58      0.50      0.54        14\n",
      "          3       0.45      0.45      0.45        38\n",
      "          4       0.48      0.62      0.54        42\n",
      "          5       0.44      0.24      0.31        17\n",
      "          6       0.58      0.52      0.55        21\n",
      "          7       0.35      0.41      0.38        37\n",
      "          8       0.50      0.17      0.25        12\n",
      "          9       0.48      0.55      0.51        22\n",
      "         10       0.44      0.62      0.51        50\n",
      "         11       0.20      0.19      0.19        27\n",
      "         12       0.35      0.33      0.34        18\n",
      "         13       0.36      0.25      0.30        16\n",
      "         14       0.35      0.33      0.34        18\n",
      "         15       0.00      0.00      0.00        11\n",
      "         16       0.57      0.53      0.55        15\n",
      "         17       0.50      0.23      0.32        26\n",
      "         18       1.00      0.63      0.77        19\n",
      "         19       0.06      0.07      0.06        15\n",
      "         20       0.56      0.50      0.53        10\n",
      "         21       0.43      0.18      0.25        17\n",
      "         22       0.00      0.00      0.00        15\n",
      "         23       0.24      0.22      0.23        18\n",
      "         24       0.25      0.09      0.13        11\n",
      "         25       0.62      0.22      0.32        23\n",
      "         26       0.58      0.58      0.58        38\n",
      "         27       0.80      0.24      0.36        17\n",
      "         28       0.50      0.30      0.37        10\n",
      "         29       0.48      0.50      0.49        46\n",
      "         30       0.75      0.82      0.78        11\n",
      "         31       0.66      0.74      0.70        54\n",
      "         32       0.00      0.00      0.00        10\n",
      "         33       0.17      0.10      0.12        21\n",
      "\n",
      "avg / total       0.44      0.41      0.41       788\n",
      "\n",
      "[14  3  2 ...  0  0  2]\n",
      "svc Accuracy:  0.41116751269035534\n",
      "svc F1:  0.36673215541699244\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.39      0.26        41\n",
      "          1       0.52      0.61      0.56        28\n",
      "          2       0.44      0.29      0.35        14\n",
      "          3       0.41      0.42      0.42        38\n",
      "          4       0.47      0.67      0.55        42\n",
      "          5       0.57      0.24      0.33        17\n",
      "          6       0.21      0.33      0.26        21\n",
      "          7       0.34      0.35      0.35        37\n",
      "          8       0.33      0.17      0.22        12\n",
      "          9       0.43      0.59      0.50        22\n",
      "         10       0.52      0.68      0.59        50\n",
      "         11       0.22      0.19      0.20        27\n",
      "         12       0.33      0.17      0.22        18\n",
      "         13       0.25      0.12      0.17        16\n",
      "         14       0.50      0.39      0.44        18\n",
      "         15       0.00      0.00      0.00        11\n",
      "         16       0.67      0.40      0.50        15\n",
      "         17       0.40      0.38      0.39        26\n",
      "         18       1.00      0.53      0.69        19\n",
      "         19       0.19      0.20      0.19        15\n",
      "         20       0.71      0.50      0.59        10\n",
      "         21       0.75      0.18      0.29        17\n",
      "         22       0.00      0.00      0.00        15\n",
      "         23       0.32      0.33      0.32        18\n",
      "         24       0.00      0.00      0.00        11\n",
      "         25       0.67      0.17      0.28        23\n",
      "         26       0.56      0.63      0.59        38\n",
      "         27       0.20      0.12      0.15        17\n",
      "         28       0.67      0.20      0.31        10\n",
      "         29       0.41      0.61      0.49        46\n",
      "         30       0.82      0.82      0.82        11\n",
      "         31       0.49      0.74      0.59        54\n",
      "         32       0.00      0.00      0.00        10\n",
      "         33       0.19      0.14      0.16        21\n",
      "\n",
      "avg / total       0.42      0.41      0.39       788\n",
      "\n",
      "[16  2  2 ...  0  0  3]\n",
      "LR Accuracy:  0.4137055837563452\n",
      "LR F1:  0.3462211724280242\n",
      "For name:  m_engel\n",
      "total sample size before apply threshold:  100\n",
      "Counter({'0000-0003-3067-077X': 75, '0000-0002-7031-3825': 19, '0000-0001-7602-1340': 4, '0000-0002-2271-4229': 1, '0000-0002-1474-4161': 1})\n",
      "['0000-0002-7031-3825', '0000-0003-3067-077X']\n",
      "Total sample size after apply threshold:  94\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 26)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 13)\n",
      "2\n",
      "(94, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.37      0.45        19\n",
      "          1       0.85      0.93      0.89        75\n",
      "\n",
      "avg / total       0.80      0.82      0.80        94\n",
      "\n",
      "[ 7 12  5 70]\n",
      "MNB Accuracy:  0.8191489361702128\n",
      "MNB F1:  0.6716663242243681\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.58      0.69        19\n",
      "          1       0.90      0.97      0.94        75\n",
      "\n",
      "avg / total       0.89      0.89      0.89        94\n",
      "\n",
      "[11  8  2 73]\n",
      "svc Accuracy:  0.8936170212765957\n",
      "svc F1:  0.8116987179487181\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.37      0.54        19\n",
      "          1       0.86      1.00      0.93        75\n",
      "\n",
      "avg / total       0.89      0.87      0.85        94\n",
      "\n",
      "[ 7 12  0 75]\n",
      "LR Accuracy:  0.8723404255319149\n",
      "LR F1:  0.7321937321937322\n",
      "For name:  w_shi\n",
      "total sample size before apply threshold:  148\n",
      "Counter({'0000-0001-6130-1227': 45, '0000-0002-6336-3912': 40, '0000-0002-9155-613X': 36, '0000-0001-5453-1753': 12, '0000-0002-6458-4776': 6, '0000-0002-1320-2635': 5, '0000-0002-3886-7027': 3, '0000-0001-5683-3800': 1})\n",
      "['0000-0001-5453-1753', '0000-0002-6336-3912', '0000-0002-9155-613X', '0000-0001-6130-1227']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 58)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 16)\n",
      "2\n",
      "(133, 74)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.08      0.14        12\n",
      "          1       0.75      0.68      0.71        40\n",
      "          2       0.86      0.67      0.75        36\n",
      "          3       0.66      0.98      0.79        45\n",
      "\n",
      "avg / total       0.72      0.72      0.70       133\n",
      "\n",
      "[ 1  3  2  6  0 27  2 11  1  5 24  6  0  1  0 44]\n",
      "MNB Accuracy:  0.7218045112781954\n",
      "MNB F1:  0.5972744360902256\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.33      0.40        12\n",
      "          1       0.86      0.90      0.88        40\n",
      "          2       0.76      0.86      0.81        36\n",
      "          3       1.00      0.93      0.97        45\n",
      "\n",
      "avg / total       0.85      0.85      0.84       133\n",
      "\n",
      "[ 4  2  6  0  0 36  4  0  4  1 31  0  0  3  0 42]\n",
      "svc Accuracy:  0.849624060150376\n",
      "svc F1:  0.7621902067654801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29        12\n",
      "          1       0.75      0.82      0.79        40\n",
      "          2       0.76      0.89      0.82        36\n",
      "          3       0.93      0.93      0.93        45\n",
      "\n",
      "avg / total       0.84      0.82      0.80       133\n",
      "\n",
      "[ 2  4  5  1  0 33  5  2  0  4 32  0  0  3  0 42]\n",
      "LR Accuracy:  0.8195488721804511\n",
      "LR F1:  0.7063186813186813\n",
      "For name:  d_matthews\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0003-4611-8795': 36, '0000-0002-3579-3608': 11, '0000-0003-3562-9549': 9, '0000-0002-0516-7470': 1})\n",
      "['0000-0002-3579-3608', '0000-0003-4611-8795']\n",
      "Total sample size after apply threshold:  47\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 19)\n",
      "2\n",
      "(47, 49)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        11\n",
      "          1       0.84      1.00      0.91        36\n",
      "\n",
      "avg / total       0.88      0.85      0.82        47\n",
      "\n",
      "[ 4  7  0 36]\n",
      "MNB Accuracy:  0.851063829787234\n",
      "MNB F1:  0.7223628691983122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.18      0.29        11\n",
      "          1       0.80      0.97      0.88        36\n",
      "\n",
      "avg / total       0.77      0.79      0.74        47\n",
      "\n",
      "[ 2  9  1 35]\n",
      "svc Accuracy:  0.7872340425531915\n",
      "svc F1:  0.5803571428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17        11\n",
      "          1       0.78      1.00      0.88        36\n",
      "\n",
      "avg / total       0.83      0.79      0.71        47\n",
      "\n",
      "[ 1 10  0 36]\n",
      "LR Accuracy:  0.7872340425531915\n",
      "LR F1:  0.5223577235772359\n",
      "For name:  j_christensen\n",
      "total sample size before apply threshold:  203\n",
      "Counter({'0000-0002-4299-9479': 100, '0000-0003-1414-1886': 53, '0000-0002-7641-8302': 32, '0000-0002-6741-5839': 13, '0000-0002-2689-1169': 1, '0000-0002-9231-8029': 1, '0000-0003-4225-3359': 1, '0000-0003-2370-2702': 1, '0000-0002-2495-8905': 1})\n",
      "['0000-0002-7641-8302', '0000-0002-4299-9479', '0000-0002-6741-5839', '0000-0003-1414-1886']\n",
      "Total sample size after apply threshold:  198\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(198, 69)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(198, 24)\n",
      "2\n",
      "(198, 93)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.53      0.64        32\n",
      "          1       0.88      0.92      0.90       100\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.68      0.91      0.77        53\n",
      "\n",
      "avg / total       0.75      0.79      0.76       198\n",
      "\n",
      "[17  9  0  6  2 92  0  6  1  1  0 11  1  3  1 48]\n",
      "MNB Accuracy:  0.7929292929292929\n",
      "MNB F1:  0.5783159894897794\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.69      0.73        32\n",
      "          1       0.84      0.97      0.90       100\n",
      "          2       0.57      0.31      0.40        13\n",
      "          3       0.90      0.81      0.85        53\n",
      "\n",
      "avg / total       0.83      0.84      0.83       198\n",
      "\n",
      "[22 10  0  0  3 97  0  0  2  2  4  5  1  6  3 43]\n",
      "svc Accuracy:  0.8383838383838383\n",
      "svc F1:  0.7217860158108834\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.47      0.59        32\n",
      "          1       0.81      0.96      0.88       100\n",
      "          2       0.67      0.31      0.42        13\n",
      "          3       0.81      0.83      0.82        53\n",
      "\n",
      "avg / total       0.80      0.80      0.79       198\n",
      "\n",
      "[15 16  0  1  2 96  0  2  1  1  4  7  1  6  2 44]\n",
      "LR Accuracy:  0.803030303030303\n",
      "LR F1:  0.6771075402514435\n",
      "For name:  j_sampaio\n",
      "total sample size before apply threshold:  117\n",
      "Counter({'0000-0003-2335-9991': 61, '0000-0001-8145-5274': 48, '0000-0003-4359-493X': 5, '0000-0002-0460-3664': 3})\n",
      "['0000-0003-2335-9991', '0000-0001-8145-5274']\n",
      "Total sample size after apply threshold:  109\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 40)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 14)\n",
      "2\n",
      "(109, 54)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90        61\n",
      "          1       0.91      0.83      0.87        48\n",
      "\n",
      "avg / total       0.89      0.89      0.89       109\n",
      "\n",
      "[57  4  8 40]\n",
      "MNB Accuracy:  0.8899082568807339\n",
      "MNB F1:  0.8871635610766047\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.82      0.88        61\n",
      "          1       0.81      0.96      0.88        48\n",
      "\n",
      "avg / total       0.89      0.88      0.88       109\n",
      "\n",
      "[50 11  2 46]\n",
      "svc Accuracy:  0.8807339449541285\n",
      "svc F1:  0.8805731142014328\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90        61\n",
      "          1       0.89      0.83      0.86        48\n",
      "\n",
      "avg / total       0.88      0.88      0.88       109\n",
      "\n",
      "[56  5  8 40]\n",
      "LR Accuracy:  0.8807339449541285\n",
      "LR F1:  0.8781075268817203\n",
      "For name:  j_dias\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-7613-6241': 9, '0000-0002-1150-4357': 9, '0000-0003-3732-7122': 5, '0000-0003-2517-7905': 3, '0000-0002-0966-0537': 3, '0000-0003-4732-7230': 1, '0000-0002-6271-6501': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  p_nunes\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0002-4598-685X': 19, '0000-0003-4740-8268': 12, '0000-0002-4641-8846': 4, '0000-0003-1693-1267': 1})\n",
      "['0000-0002-4598-685X', '0000-0003-4740-8268']\n",
      "Total sample size after apply threshold:  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(31, 25)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(31, 10)\n",
      "2\n",
      "(31, 35)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.84      0.78        19\n",
      "          1       0.67      0.50      0.57        12\n",
      "\n",
      "avg / total       0.70      0.71      0.70        31\n",
      "\n",
      "[16  3  6  6]\n",
      "MNB Accuracy:  0.7096774193548387\n",
      "MNB F1:  0.6759581881533101\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.95      0.88        19\n",
      "          1       0.89      0.67      0.76        12\n",
      "\n",
      "avg / total       0.85      0.84      0.83        31\n",
      "\n",
      "[18  1  4  8]\n",
      "svc Accuracy:  0.8387096774193549\n",
      "svc F1:  0.8199767711962834\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.89      0.79        19\n",
      "          1       0.71      0.42      0.53        12\n",
      "\n",
      "avg / total       0.71      0.71      0.69        31\n",
      "\n",
      "[17  2  7  5]\n",
      "LR Accuracy:  0.7096774193548387\n",
      "LR F1:  0.6585067319461444\n",
      "For name:  c_bauer\n",
      "total sample size before apply threshold:  7\n",
      "Counter({'0000-0001-9511-2491': 4, '0000-0003-3466-7076': 1, '0000-0001-8288-8290': 1, '0000-0002-3368-6681': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_patel\n",
      "total sample size before apply threshold:  182\n",
      "Counter({'0000-0002-1526-4303': 128, '0000-0002-7444-5550': 16, '0000-0002-4712-1921': 9, '0000-0003-1586-5595': 8, '0000-0002-3851-8257': 8, '0000-0001-6344-4141': 4, '0000-0001-7667-5918': 3, '0000-0002-8442-0349': 2, '0000-0001-5330-1438': 2, '0000-0002-5398-2496': 1, '0000-0002-3418-0260': 1})\n",
      "['0000-0002-7444-5550', '0000-0002-1526-4303']\n",
      "Total sample size after apply threshold:  144\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(144, 68)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(144, 20)\n",
      "2\n",
      "(144, 88)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.31      0.45        16\n",
      "          1       0.92      0.99      0.95       128\n",
      "\n",
      "avg / total       0.91      0.92      0.90       144\n",
      "\n",
      "[  5  11   1 127]\n",
      "MNB Accuracy:  0.9166666666666666\n",
      "MNB F1:  0.7047163362952836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.44      0.58        16\n",
      "          1       0.93      0.99      0.96       128\n",
      "\n",
      "avg / total       0.93      0.93      0.92       144\n",
      "\n",
      "[  7   9   1 127]\n",
      "svc Accuracy:  0.9305555555555556\n",
      "svc F1:  0.7727272727272727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.19      0.32        16\n",
      "          1       0.91      1.00      0.95       128\n",
      "\n",
      "avg / total       0.92      0.91      0.88       144\n",
      "\n",
      "[  3  13   0 128]\n",
      "LR Accuracy:  0.9097222222222222\n",
      "LR F1:  0.6337311680688711\n",
      "For name:  a_das\n",
      "total sample size before apply threshold:  74\n",
      "Counter({'0000-0002-0883-1816': 14, '0000-0002-7033-1441': 10, '0000-0003-0740-8140': 8, '0000-0001-5924-4235': 6, '0000-0001-7383-9606': 5, '0000-0002-5196-9589': 5, '0000-0002-7510-1805': 5, '0000-0003-1801-7487': 4, '0000-0002-1733-626X': 3, '0000-0003-0616-9715': 3, '0000-0002-7473-6139': 2, '0000-0003-4305-6007': 2, '0000-0002-2101-9056': 2, '0000-0003-0921-8877': 2, '0000-0001-5884-0852': 1, '0000-0002-0445-0012': 1, '0000-0002-0141-0963': 1})\n",
      "['0000-0002-7033-1441', '0000-0002-0883-1816']\n",
      "Total sample size after apply threshold:  24\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 18)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 15)\n",
      "2\n",
      "(24, 33)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        10\n",
      "          1       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.96      0.96      0.96        24\n",
      "\n",
      "[10  0  1 13]\n",
      "MNB Accuracy:  0.9583333333333334\n",
      "MNB F1:  0.9576719576719577\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        10\n",
      "          1       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.96      0.96      0.96        24\n",
      "\n",
      "[10  0  1 13]\n",
      "svc Accuracy:  0.9583333333333334\n",
      "svc F1:  0.9576719576719577\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.80      0.84        10\n",
      "          1       0.87      0.93      0.90        14\n",
      "\n",
      "avg / total       0.88      0.88      0.87        24\n",
      "\n",
      "[ 8  2  1 13]\n",
      "LR Accuracy:  0.875\n",
      "LR F1:  0.8693284936479129\n",
      "For name:  c_becker\n",
      "total sample size before apply threshold:  110\n",
      "Counter({'0000-0002-1388-1041': 40, '0000-0002-1716-7208': 27, '0000-0002-6369-2185': 17, '0000-0002-7035-6083': 11, '0000-0002-9179-7996': 7, '0000-0003-3406-4670': 6, '0000-0002-8385-0785': 2})\n",
      "['0000-0002-6369-2185', '0000-0002-7035-6083', '0000-0002-1388-1041', '0000-0002-1716-7208']\n",
      "Total sample size after apply threshold:  95\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 58)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 22)\n",
      "2\n",
      "(95, 80)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.35      0.48        17\n",
      "          1       0.50      0.09      0.15        11\n",
      "          2       0.52      0.93      0.67        40\n",
      "          3       0.50      0.26      0.34        27\n",
      "\n",
      "avg / total       0.55      0.54      0.48        95\n",
      "\n",
      "[ 6  0  8  3  0  1  8  2  1  0 37  2  1  1 18  7]\n",
      "MNB Accuracy:  0.5368421052631579\n",
      "MNB F1:  0.4104940587867417\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.65      0.76        17\n",
      "          1       0.60      0.27      0.37        11\n",
      "          2       0.57      0.78      0.66        40\n",
      "          3       0.46      0.41      0.43        27\n",
      "\n",
      "avg / total       0.61      0.59      0.58        95\n",
      "\n",
      "[11  1  4  1  0  3  5  3  0  0 31  9  1  1 14 11]\n",
      "svc Accuracy:  0.5894736842105263\n",
      "svc F1:  0.5561419266899716\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        17\n",
      "          1       0.50      0.09      0.15        11\n",
      "          2       0.54      0.90      0.67        40\n",
      "          3       0.50      0.33      0.40        27\n",
      "\n",
      "avg / total       0.61      0.57      0.53        95\n",
      "\n",
      "[ 8  0  6  3  0  1  8  2  0  0 36  4  0  1 17  9]\n",
      "LR Accuracy:  0.5684210526315789\n",
      "LR F1:  0.466685837526959\n",
      "For name:  k_zhu\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0001-7664-7204': 3, '0000-0003-4361-1138': 1, '0000-0003-2784-3190': 1, '0000-0003-2293-3568': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  a_machado\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-8132-5610': 54, '0000-0002-5677-7332': 30, '0000-0003-4380-3711': 25, '0000-0001-6200-3686': 16, '0000-0003-0732-1571': 14, '0000-0003-1999-1206': 4, '0000-0003-1947-8605': 4, '0000-0001-8957-661X': 2, '0000-0001-9341-5827': 1})\n",
      "['0000-0002-8132-5610', '0000-0002-5677-7332', '0000-0003-4380-3711', '0000-0003-0732-1571', '0000-0001-6200-3686']\n",
      "Total sample size after apply threshold:  139\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 85)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 22)\n",
      "2\n",
      "(139, 107)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.91      0.64        54\n",
      "          1       0.73      0.27      0.39        30\n",
      "          2       0.95      0.84      0.89        25\n",
      "          3       1.00      0.14      0.25        14\n",
      "          4       0.20      0.06      0.10        16\n",
      "\n",
      "avg / total       0.64      0.58      0.53       139\n",
      "\n",
      "[49  2  1  0  2 21  8  0  0  1  4  0 21  0  0 10  1  0  2  1 15  0  0  0\n",
      "  1]\n",
      "MNB Accuracy:  0.5827338129496403\n",
      "MNB F1:  0.4539243789541418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.87      0.66        54\n",
      "          1       0.75      0.40      0.52        30\n",
      "          2       1.00      0.92      0.96        25\n",
      "          3       0.50      0.14      0.22        14\n",
      "          4       0.29      0.12      0.17        16\n",
      "\n",
      "avg / total       0.63      0.62      0.58       139\n",
      "\n",
      "[47  2  0  2  3 17 12  0  0  1  2  0 23  0  0 10  1  0  2  1 13  1  0  0\n",
      "  2]\n",
      "svc Accuracy:  0.6187050359712231\n",
      "svc F1:  0.5067100773622513\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.87      0.62        54\n",
      "          1       0.62      0.27      0.37        30\n",
      "          2       1.00      0.88      0.94        25\n",
      "          3       0.00      0.00      0.00        14\n",
      "          4       0.20      0.06      0.10        16\n",
      "\n",
      "avg / total       0.52      0.56      0.50       139\n",
      "\n",
      "[47  3  0  2  2 21  8  0  0  1  3  0 22  0  0 12  1  0  0  1 14  1  0  0\n",
      "  1]\n",
      "LR Accuracy:  0.5611510791366906\n",
      "LR F1:  0.4052035775102515\n",
      "For name:  j_alexander\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-6783-4382': 11, '0000-0003-2226-7913': 10, '0000-0002-2258-5738': 5, '0000-0001-9797-6322': 2, '0000-0002-6492-1621': 2, '0000-0001-7734-9428': 1})\n",
      "['0000-0001-6783-4382', '0000-0003-2226-7913']\n",
      "Total sample size after apply threshold:  21\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 18)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 8)\n",
      "2\n",
      "(21, 26)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.82      0.69        11\n",
      "          1       0.67      0.40      0.50        10\n",
      "\n",
      "avg / total       0.63      0.62      0.60        21\n",
      "\n",
      "[9 2 6 4]\n",
      "MNB Accuracy:  0.6190476190476191\n",
      "MNB F1:  0.5961538461538461\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.45      0.50        11\n",
      "          1       0.50      0.60      0.55        10\n",
      "\n",
      "avg / total       0.53      0.52      0.52        21\n",
      "\n",
      "[5 6 4 6]\n",
      "svc Accuracy:  0.5238095238095238\n",
      "svc F1:  0.5227272727272727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.73      0.67        11\n",
      "          1       0.62      0.50      0.56        10\n",
      "\n",
      "avg / total       0.62      0.62      0.61        21\n",
      "\n",
      "[8 3 5 5]\n",
      "LR Accuracy:  0.6190476190476191\n",
      "LR F1:  0.6111111111111112\n",
      "For name:  j_schneider\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0001-8016-8687': 13, '0000-0002-6028-9956': 7, '0000-0003-1114-618X': 5, '0000-0001-7169-3973': 5, '0000-0003-1176-8309': 3, '0000-0001-5187-6756': 3, '0000-0002-5863-7747': 1, '0000-0001-6093-5404': 1, '0000-0001-5556-0919': 1, '0000-0001-9610-6501': 1})\n",
      "['0000-0001-8016-8687']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  g_russo\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-8764-7389': 22, '0000-0002-2716-369X': 11, '0000-0003-1493-1087': 7, '0000-0001-9321-1613': 5, '0000-0003-4687-7353': 5, '0000-0001-5001-3027': 4, '0000-0002-4565-3131': 2, '0000-0003-4215-1926': 1, '0000-0002-7779-6225': 1})\n",
      "['0000-0002-8764-7389', '0000-0002-2716-369X']\n",
      "Total sample size after apply threshold:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 24)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 10)\n",
      "2\n",
      "(33, 34)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.91      0.85        22\n",
      "          1       0.75      0.55      0.63        11\n",
      "\n",
      "avg / total       0.78      0.79      0.78        33\n",
      "\n",
      "[20  2  5  6]\n",
      "MNB Accuracy:  0.7878787878787878\n",
      "MNB F1:  0.7413213885778276\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        22\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.90      0.88      0.87        33\n",
      "\n",
      "[22  0  4  7]\n",
      "svc Accuracy:  0.8787878787878788\n",
      "svc F1:  0.8472222222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.91      0.82        22\n",
      "          1       0.67      0.36      0.47        11\n",
      "\n",
      "avg / total       0.72      0.73      0.70        33\n",
      "\n",
      "[20  2  7  4]\n",
      "LR Accuracy:  0.7272727272727273\n",
      "LR F1:  0.6434573829531813\n",
      "For name:  j_carvalho\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-3015-7821': 49, '0000-0001-5256-1422': 33, '0000-0003-4495-057X': 22, '0000-0003-2362-0010': 15, '0000-0001-9743-438X': 9, '0000-0001-8091-5419': 3, '0000-0002-4235-1242': 2, '0000-0002-4027-735X': 2, '0000-0002-6263-344X': 1})\n",
      "['0000-0003-4495-057X', '0000-0001-5256-1422', '0000-0003-2362-0010', '0000-0002-3015-7821']\n",
      "Total sample size after apply threshold:  119\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(119, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(119, 18)\n",
      "2\n",
      "(119, 55)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        22\n",
      "          1       0.85      0.88      0.87        33\n",
      "          2       0.92      0.73      0.81        15\n",
      "          3       0.77      1.00      0.87        49\n",
      "\n",
      "avg / total       0.85      0.82      0.81       119\n",
      "\n",
      "[ 9  5  1  7  0 29  0  4  0  0 11  4  0  0  0 49]\n",
      "MNB Accuracy:  0.8235294117647058\n",
      "MNB F1:  0.7820970637660809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.77      0.83        22\n",
      "          1       0.79      0.94      0.86        33\n",
      "          2       1.00      0.80      0.89        15\n",
      "          3       1.00      1.00      1.00        49\n",
      "\n",
      "avg / total       0.92      0.92      0.92       119\n",
      "\n",
      "[17  5  0  0  2 31  0  0  0  3 12  0  0  0  0 49]\n",
      "svc Accuracy:  0.9159663865546218\n",
      "svc F1:  0.8948170731707318\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.64      0.74        22\n",
      "          1       0.76      0.94      0.84        33\n",
      "          2       0.85      0.73      0.79        15\n",
      "          3       1.00      1.00      1.00        49\n",
      "\n",
      "avg / total       0.89      0.88      0.88       119\n",
      "\n",
      "[14  7  1  0  1 31  1  0  1  3 11  0  0  0  0 49]\n",
      "LR Accuracy:  0.8823529411764706\n",
      "LR F1:  0.8400985572038203\n",
      "For name:  y_nishikawa\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0002-0739-8491': 10, '0000-0003-3313-1990': 8, '0000-0002-0088-8447': 2, '0000-0002-1113-6937': 1})\n",
      "['0000-0002-0739-8491']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  j_ward\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0001-9870-8936': 11, '0000-0002-4108-4330': 5, '0000-0002-4698-8857': 3, '0000-0002-4196-4653': 1, '0000-0003-0289-117X': 1, '0000-0002-4415-5544': 1})\n",
      "['0000-0001-9870-8936']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  m_singh\n",
      "total sample size before apply threshold:  133\n",
      "Counter({'0000-0002-8072-1769': 52, '0000-0003-3044-1010': 22, '0000-0002-2884-0074': 21, '0000-0002-8396-5451': 21, '0000-0001-8569-8599': 4, '0000-0002-9124-1859': 4, '0000-0001-8526-2955': 3, '0000-0002-9010-0990': 2, '0000-0002-5783-073X': 1, '0000-0003-0051-336X': 1, '0000-0001-9166-626X': 1, '0000-0002-0034-9726': 1})\n",
      "['0000-0003-3044-1010', '0000-0002-8072-1769', '0000-0002-2884-0074', '0000-0002-8396-5451']\n",
      "Total sample size after apply threshold:  116\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(116, 61)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(116, 20)\n",
      "2\n",
      "(116, 81)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.55      0.65        22\n",
      "          1       0.67      0.90      0.77        52\n",
      "          2       0.86      0.29      0.43        21\n",
      "          3       0.83      0.95      0.89        21\n",
      "\n",
      "avg / total       0.76      0.73      0.71       116\n",
      "\n",
      "[12  9  0  1  1 47  1  3  2 13  6  0  0  1  0 20]\n",
      "MNB Accuracy:  0.7327586206896551\n",
      "MNB F1:  0.6841501923469137\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        22\n",
      "          1       0.69      0.90      0.78        52\n",
      "          2       0.92      0.52      0.67        21\n",
      "          3       0.77      0.81      0.79        21\n",
      "\n",
      "avg / total       0.81      0.77      0.76       116\n",
      "\n",
      "[14  7  0  1  0 47  1  4  0 10 11  0  0  4  0 17]\n",
      "svc Accuracy:  0.7672413793103449\n",
      "svc F1:  0.7546188630490956\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        22\n",
      "          1       0.60      0.92      0.73        52\n",
      "          2       0.83      0.24      0.37        21\n",
      "          3       0.78      0.67      0.72        21\n",
      "\n",
      "avg / total       0.75      0.68      0.66       116\n",
      "\n",
      "[12  9  0  1  0 48  1  3  0 16  5  0  0  7  0 14]\n",
      "LR Accuracy:  0.6810344827586207\n",
      "LR F1:  0.630368542133248\n",
      "For name:  a_bhattacharyya\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-1646-709X': 8, '0000-0002-5948-3364': 3, '0000-0001-7011-2102': 2, '0000-0003-1077-2082': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  e_morris\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0001-7046-3623': 29, '0000-0003-1893-7515': 7, '0000-0002-5011-6744': 3, '0000-0002-9913-6041': 1})\n",
      "['0000-0001-7046-3623']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  m_lewis\n",
      "total sample size before apply threshold:  177\n",
      "Counter({'0000-0002-8430-4479': 63, '0000-0002-5735-5318': 35, '0000-0002-6709-9215': 30, '0000-0001-6042-0865': 13, '0000-0002-2062-6006': 11, '0000-0001-9365-5345': 9, '0000-0002-6241-3690': 8, '0000-0001-5918-3444': 3, '0000-0002-1154-9096': 2, '0000-0002-9703-8456': 1, '0000-0003-4410-5720': 1, '0000-0003-0897-1621': 1})\n",
      "['0000-0002-5735-5318', '0000-0002-8430-4479', '0000-0001-6042-0865', '0000-0002-2062-6006', '0000-0002-6709-9215']\n",
      "Total sample size after apply threshold:  152\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(152, 92)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(152, 20)\n",
      "2\n",
      "(152, 112)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.54      0.61        35\n",
      "          1       0.57      0.87      0.69        63\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       1.00      0.09      0.17        11\n",
      "          4       0.58      0.50      0.54        30\n",
      "\n",
      "avg / total       0.58      0.59      0.54       152\n",
      "\n",
      "[19 13  1  0  2  2 55  0  0  6  2  9  0  0  2  0  9  0  1  1  4 11  0  0\n",
      " 15]\n",
      "MNB Accuracy:  0.5921052631578947\n",
      "MNB F1:  0.4005568356374808\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.63      0.72        35\n",
      "          1       0.60      0.97      0.74        63\n",
      "          2       0.33      0.08      0.12        13\n",
      "          3       1.00      0.55      0.71        11\n",
      "          4       1.00      0.53      0.70        30\n",
      "\n",
      "avg / total       0.74      0.70      0.67       152\n",
      "\n",
      "[22 11  2  0  0  2 61  0  0  0  2 10  1  0  0  0  5  0  6  0  0 14  0  0\n",
      " 16]\n",
      "svc Accuracy:  0.6973684210526315\n",
      "svc F1:  0.5983496882576892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.51      0.63        35\n",
      "          1       0.53      0.97      0.69        63\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.43      0.60        30\n",
      "\n",
      "avg / total       0.61      0.61      0.55       152\n",
      "\n",
      "[18 15  2  0  0  2 61  0  0  0  2 11  0  0  0  0 11  0  0  0  0 17  0  0\n",
      " 13]\n",
      "LR Accuracy:  0.6052631578947368\n",
      "LR F1:  0.38432467371721696\n",
      "For name:  v_fernandes\n",
      "total sample size before apply threshold:  55\n",
      "Counter({'0000-0001-6060-9035': 17, '0000-0002-3873-2034': 16, '0000-0003-3979-7523': 15, '0000-0002-9671-3923': 6, '0000-0003-0568-2920': 1})\n",
      "['0000-0003-3979-7523', '0000-0002-3873-2034', '0000-0001-6060-9035']\n",
      "Total sample size after apply threshold:  48\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 9)\n",
      "2\n",
      "(48, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.60      0.58        15\n",
      "          1       0.71      0.62      0.67        16\n",
      "          2       0.56      0.59      0.57        17\n",
      "\n",
      "avg / total       0.61      0.60      0.61        48\n",
      "\n",
      "[ 9  1  5  3 10  3  4  3 10]\n",
      "MNB Accuracy:  0.6041666666666666\n",
      "MNB F1:  0.6062467997951869\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.73      0.65        15\n",
      "          1       0.79      0.69      0.73        16\n",
      "          2       0.67      0.59      0.62        17\n",
      "\n",
      "avg / total       0.68      0.67      0.67        48\n",
      "\n",
      "[11  1  3  3 11  2  5  2 10]\n",
      "svc Accuracy:  0.6666666666666666\n",
      "svc F1:  0.6684640522875817\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.53      0.53        15\n",
      "          1       0.73      0.69      0.71        16\n",
      "          2       0.61      0.65      0.63        17\n",
      "\n",
      "avg / total       0.63      0.62      0.63        48\n",
      "\n",
      "[ 8  2  5  3 11  2  4  2 11]\n",
      "LR Accuracy:  0.625\n",
      "LR F1:  0.6238607270865336\n",
      "For name:  m_pinheiro\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0001-8228-3435': 30, '0000-0002-6931-1355': 16, '0000-0002-5500-7408': 2, '0000-0003-0758-5526': 2, '0000-0003-2523-245X': 2, '0000-0001-5963-8947': 1, '0000-0001-8234-6790': 1})\n",
      "['0000-0001-8228-3435', '0000-0002-6931-1355']\n",
      "Total sample size after apply threshold:  46\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 10)\n",
      "2\n",
      "(46, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.93      0.89        30\n",
      "          1       0.85      0.69      0.76        16\n",
      "\n",
      "avg / total       0.85      0.85      0.84        46\n",
      "\n",
      "[28  2  5 11]\n",
      "MNB Accuracy:  0.8478260869565217\n",
      "MNB F1:  0.8237547892720307\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.93      0.89        30\n",
      "          1       0.85      0.69      0.76        16\n",
      "\n",
      "avg / total       0.85      0.85      0.84        46\n",
      "\n",
      "[28  2  5 11]\n",
      "svc Accuracy:  0.8478260869565217\n",
      "svc F1:  0.8237547892720307\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.93      0.86        30\n",
      "          1       0.82      0.56      0.67        16\n",
      "\n",
      "avg / total       0.81      0.80      0.79        46\n",
      "\n",
      "[28  2  7  9]\n",
      "LR Accuracy:  0.8043478260869565\n",
      "LR F1:  0.764102564102564\n",
      "For name:  j_petersen\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0001-9615-1310': 12, '0000-0001-6116-5114': 10, '0000-0001-8612-2508': 5, '0000-0003-0138-0693': 5, '0000-0002-4071-0416': 4, '0000-0002-7715-0088': 2, '0000-0001-6857-982X': 1, '0000-0003-2976-308X': 1, '0000-0003-4939-5149': 1})\n",
      "['0000-0001-6116-5114', '0000-0001-9615-1310']\n",
      "Total sample size after apply threshold:  22\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 12)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 12)\n",
      "2\n",
      "(22, 24)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.71      1.00      0.83        12\n",
      "\n",
      "avg / total       0.84      0.77      0.75        22\n",
      "\n",
      "[ 5  5  0 12]\n",
      "MNB Accuracy:  0.7727272727272727\n",
      "MNB F1:  0.7471264367816092\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        10\n",
      "          1       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.92      0.91      0.91        22\n",
      "\n",
      "[10  0  2 10]\n",
      "svc Accuracy:  0.9090909090909091\n",
      "svc F1:  0.9090909090909091\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.50      0.62        10\n",
      "          1       0.69      0.92      0.79        12\n",
      "\n",
      "avg / total       0.75      0.73      0.71        22\n",
      "\n",
      "[ 5  5  1 11]\n",
      "LR Accuracy:  0.7272727272727273\n",
      "LR F1:  0.7053571428571428\n",
      "For name:  k_shimizu\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0002-0229-6541': 44, '0000-0003-2454-1795': 37, '0000-0003-1574-5526': 10, '0000-0001-8261-8098': 8, '0000-0002-2796-8666': 4})\n",
      "['0000-0002-0229-6541', '0000-0003-1574-5526', '0000-0003-2454-1795']\n",
      "Total sample size after apply threshold:  91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 18)\n",
      "2\n",
      "(91, 49)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.80      0.84        44\n",
      "          1       1.00      0.30      0.46        10\n",
      "          2       0.71      0.95      0.81        37\n",
      "\n",
      "avg / total       0.83      0.80      0.79        91\n",
      "\n",
      "[35  0  9  2  3  5  2  0 35]\n",
      "MNB Accuracy:  0.8021978021978022\n",
      "MNB F1:  0.706288481295486\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.95      0.87        44\n",
      "          1       1.00      0.50      0.67        10\n",
      "          2       0.94      0.84      0.89        37\n",
      "\n",
      "avg / total       0.88      0.86      0.85        91\n",
      "\n",
      "[42  0  2  5  5  0  6  0 31]\n",
      "svc Accuracy:  0.8571428571428571\n",
      "svc F1:  0.8061201112747504\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.93      0.85        44\n",
      "          1       1.00      0.10      0.18        10\n",
      "          2       0.87      0.89      0.88        37\n",
      "\n",
      "avg / total       0.84      0.82      0.79        91\n",
      "\n",
      "[41  0  3  7  1  2  4  0 33]\n",
      "LR Accuracy:  0.8241758241758241\n",
      "LR F1:  0.6386616161616162\n",
      "For name:  p_shaw\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-8925-2567': 21, '0000-0003-1076-2669': 18, '0000-0003-3698-1608': 12, '0000-0002-3326-3670': 6})\n",
      "['0000-0002-8925-2567', '0000-0003-1076-2669', '0000-0003-3698-1608']\n",
      "Total sample size after apply threshold:  51\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 39)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 21)\n",
      "2\n",
      "(51, 60)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      1.00      0.71        21\n",
      "          1       0.55      0.33      0.41        18\n",
      "          2       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.42      0.53      0.44        51\n",
      "\n",
      "[21  0  0 10  6  2  7  5  0]\n",
      "MNB Accuracy:  0.5294117647058824\n",
      "MNB F1:  0.375219170075979\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93        21\n",
      "          1       0.61      0.78      0.68        18\n",
      "          2       0.25      0.08      0.12        12\n",
      "\n",
      "avg / total       0.63      0.71      0.65        51\n",
      "\n",
      "[21  0  0  1 14  3  2  9  1]\n",
      "svc Accuracy:  0.7058823529411765\n",
      "svc F1:  0.580420054200542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93        21\n",
      "          1       0.60      0.83      0.70        18\n",
      "          2       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.57      0.71      0.63        51\n",
      "\n",
      "[21  0  0  1 15  2  2 10  0]\n",
      "LR Accuracy:  0.7058823529411765\n",
      "LR F1:  0.5436692506459949\n",
      "For name:  g_coppola\n",
      "total sample size before apply threshold:  142\n",
      "Counter({'0000-0002-9574-0081': 61, '0000-0002-8510-6925': 57, '0000-0003-0147-6142': 16, '0000-0003-2675-783X': 7, '0000-0001-7139-3719': 1})\n",
      "['0000-0002-9574-0081', '0000-0002-8510-6925', '0000-0003-0147-6142']\n",
      "Total sample size after apply threshold:  134\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 60)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 11)\n",
      "2\n",
      "(134, 71)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.92      0.85        61\n",
      "          1       0.83      0.88      0.85        57\n",
      "          2       1.00      0.25      0.40        16\n",
      "\n",
      "avg / total       0.84      0.82      0.80       134\n",
      "\n",
      "[56  5  0  7 50  0  7  5  4]\n",
      "MNB Accuracy:  0.8208955223880597\n",
      "MNB F1:  0.7032208955873078\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.98      0.88        61\n",
      "          1       0.96      0.86      0.91        57\n",
      "          2       1.00      0.44      0.61        16\n",
      "\n",
      "avg / total       0.89      0.87      0.86       134\n",
      "\n",
      "[60  1  0  8 49  0  8  1  7]\n",
      "svc Accuracy:  0.8656716417910447\n",
      "svc F1:  0.7973384894468148\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.92      0.84        61\n",
      "          1       0.84      0.86      0.85        57\n",
      "          2       1.00      0.25      0.40        16\n",
      "\n",
      "avg / total       0.83      0.81      0.79       134\n",
      "\n",
      "[56  5  0  8 49  0  8  4  4]\n",
      "LR Accuracy:  0.8134328358208955\n",
      "LR F1:  0.6980930587337909\n",
      "For name:  a_sinclair\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0003-2741-7992': 64, '0000-0001-8510-8691': 31, '0000-0002-2628-1686': 9, '0000-0002-5602-5958': 5})\n",
      "['0000-0003-2741-7992', '0000-0001-8510-8691']\n",
      "Total sample size after apply threshold:  95\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 19)\n",
      "2\n",
      "(95, 63)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.92        64\n",
      "          1       0.89      0.77      0.83        31\n",
      "\n",
      "avg / total       0.89      0.89      0.89        95\n",
      "\n",
      "[61  3  7 24]\n",
      "MNB Accuracy:  0.8947368421052632\n",
      "MNB F1:  0.8759143155694881\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.89        64\n",
      "          1       0.90      0.58      0.71        31\n",
      "\n",
      "avg / total       0.85      0.84      0.83        95\n",
      "\n",
      "[62  2 13 18]\n",
      "svc Accuracy:  0.8421052631578947\n",
      "svc F1:  0.7989843419382141\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.95      0.85        64\n",
      "          1       0.80      0.39      0.52        31\n",
      "\n",
      "avg / total       0.77      0.77      0.74        95\n",
      "\n",
      "[61  3 19 12]\n",
      "LR Accuracy:  0.7684210526315789\n",
      "LR F1:  0.6844806763285025\n",
      "For name:  y_pan\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0001-7709-0508': 15, '0000-0002-6311-2945': 14, '0000-0002-8587-6065': 7, '0000-0002-5547-0849': 3, '0000-0002-1173-1074': 2, '0000-0001-5133-1342': 1, '0000-0002-3945-6377': 1, '0000-0002-0090-1285': 1, '0000-0002-6894-7271': 1, '0000-0002-9195-3776': 1})\n",
      "['0000-0002-6311-2945', '0000-0001-7709-0508']\n",
      "Total sample size after apply threshold:  29\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 10)\n",
      "2\n",
      "(29, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.50      0.58        14\n",
      "          1       0.63      0.80      0.71        15\n",
      "\n",
      "avg / total       0.66      0.66      0.65        29\n",
      "\n",
      "[ 7  7  3 12]\n",
      "MNB Accuracy:  0.6551724137931034\n",
      "MNB F1:  0.6446078431372549\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.93      0.87        14\n",
      "          1       0.92      0.80      0.86        15\n",
      "\n",
      "avg / total       0.87      0.86      0.86        29\n",
      "\n",
      "[13  1  3 12]\n",
      "svc Accuracy:  0.8620689655172413\n",
      "svc F1:  0.8619047619047618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.64      0.67        14\n",
      "          1       0.69      0.73      0.71        15\n",
      "\n",
      "avg / total       0.69      0.69      0.69        29\n",
      "\n",
      "[ 9  5  4 11]\n",
      "LR Accuracy:  0.6896551724137931\n",
      "LR F1:  0.6881720430107526\n",
      "For name:  m_ramos\n",
      "total sample size before apply threshold:  251\n",
      "Counter({'0000-0002-7554-8324': 187, '0000-0002-8950-2079': 22, '0000-0003-3230-8045': 13, '0000-0002-2157-9774': 8, '0000-0001-6176-5048': 7, '0000-0001-8849-6386': 3, '0000-0001-5224-5665': 3, '0000-0002-2582-7616': 2, '0000-0001-5832-0945': 1, '0000-0001-6594-6591': 1, '0000-0001-6821-3692': 1, '0000-0002-3117-4498': 1, '0000-0003-1133-4164': 1, '0000-0002-9480-782X': 1})\n",
      "['0000-0002-8950-2079', '0000-0003-3230-8045', '0000-0002-7554-8324']\n",
      "Total sample size after apply threshold:  222\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(222, 77)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(222, 20)\n",
      "2\n",
      "(222, 97)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.59      0.68        22\n",
      "          1       0.50      0.08      0.13        13\n",
      "          2       0.90      0.98      0.94       187\n",
      "\n",
      "avg / total       0.87      0.89      0.86       222\n",
      "\n",
      "[ 13   0   9   0   1  12   3   1 183]\n",
      "MNB Accuracy:  0.8873873873873874\n",
      "MNB F1:  0.5845350802410972\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.64      0.76        22\n",
      "          1       0.78      0.54      0.64        13\n",
      "          2       0.93      0.98      0.96       187\n",
      "\n",
      "avg / total       0.92      0.92      0.92       222\n",
      "\n",
      "[ 14   0   8   0   7   6   1   2 184]\n",
      "svc Accuracy:  0.9234234234234234\n",
      "svc F1:  0.782988182988183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        22\n",
      "          1       0.75      0.23      0.35        13\n",
      "          2       0.88      0.99      0.93       187\n",
      "\n",
      "avg / total       0.88      0.88      0.85       222\n",
      "\n",
      "[  6   0  16   0   3  10   0   1 186]\n",
      "LR Accuracy:  0.8783783783783784\n",
      "LR F1:  0.571281144036562\n",
      "For name:  j_tsai\n",
      "total sample size before apply threshold:  153\n",
      "Counter({'0000-0003-2723-6841': 83, '0000-0002-8657-3744': 38, '0000-0002-5227-8894': 16, '0000-0001-5202-722X': 7, '0000-0002-8666-2739': 5, '0000-0002-5332-2818': 2, '0000-0003-1693-9437': 1, '0000-0003-4921-3982': 1})\n",
      "['0000-0003-2723-6841', '0000-0002-8657-3744', '0000-0002-5227-8894']\n",
      "Total sample size after apply threshold:  137\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(137, 76)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(137, 28)\n",
      "2\n",
      "(137, 104)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.92      0.83        83\n",
      "          1       0.76      0.68      0.72        38\n",
      "          2       1.00      0.19      0.32        16\n",
      "\n",
      "avg / total       0.79      0.77      0.74       137\n",
      "\n",
      "[76  7  0 12 26  0 12  1  3]\n",
      "MNB Accuracy:  0.7664233576642335\n",
      "MNB F1:  0.6228709296008691\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.99      0.88        83\n",
      "          1       0.96      0.71      0.82        38\n",
      "          2       1.00      0.38      0.55        16\n",
      "\n",
      "avg / total       0.87      0.84      0.82       137\n",
      "\n",
      "[82  1  0 11 27  0 10  0  6]\n",
      "svc Accuracy:  0.8394160583941606\n",
      "svc F1:  0.7484522645812968\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.95      0.80        83\n",
      "          1       0.77      0.45      0.57        38\n",
      "          2       1.00      0.06      0.12        16\n",
      "\n",
      "avg / total       0.75      0.71      0.66       137\n",
      "\n",
      "[79  4  0 21 17  0 14  1  1]\n",
      "LR Accuracy:  0.708029197080292\n",
      "LR F1:  0.49544806078099596\n",
      "For name:  f_dai\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-7651-8549': 18, '0000-0003-0850-6906': 11, '0000-0002-9229-5576': 4, '0000-0002-2983-4880': 1})\n",
      "['0000-0003-0850-6906', '0000-0002-7651-8549']\n",
      "Total sample size after apply threshold:  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 10)\n",
      "2\n",
      "(29, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.90      1.00      0.95        18\n",
      "\n",
      "avg / total       0.94      0.93      0.93        29\n",
      "\n",
      "[ 9  2  0 18]\n",
      "MNB Accuracy:  0.9310344827586207\n",
      "MNB F1:  0.9236842105263159\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.82      0.86        11\n",
      "          1       0.89      0.94      0.92        18\n",
      "\n",
      "avg / total       0.90      0.90      0.90        29\n",
      "\n",
      "[ 9  2  1 17]\n",
      "svc Accuracy:  0.896551724137931\n",
      "svc F1:  0.888030888030888\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.86      1.00      0.92        18\n",
      "\n",
      "avg / total       0.91      0.90      0.89        29\n",
      "\n",
      "[ 8  3  0 18]\n",
      "LR Accuracy:  0.896551724137931\n",
      "LR F1:  0.8825910931174089\n",
      "For name:  t_martin\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0002-4028-4867': 43, '0000-0001-7165-9812': 28, '0000-0002-7872-4194': 7, '0000-0003-2800-5308': 2, '0000-0002-1609-078X': 1, '0000-0002-7302-1190': 1, '0000-0002-6242-6782': 1})\n",
      "['0000-0001-7165-9812', '0000-0002-4028-4867']\n",
      "Total sample size after apply threshold:  71\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 20)\n",
      "2\n",
      "(71, 39)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.64      0.64        28\n",
      "          1       0.77      0.77      0.77        43\n",
      "\n",
      "avg / total       0.72      0.72      0.72        71\n",
      "\n",
      "[18 10 10 33]\n",
      "MNB Accuracy:  0.7183098591549296\n",
      "MNB F1:  0.7051495016611296\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.61      0.60        28\n",
      "          1       0.74      0.72      0.73        43\n",
      "\n",
      "avg / total       0.68      0.68      0.68        71\n",
      "\n",
      "[17 11 12 31]\n",
      "svc Accuracy:  0.676056338028169\n",
      "svc F1:  0.662951496388029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.64      0.69        28\n",
      "          1       0.79      0.86      0.82        43\n",
      "\n",
      "avg / total       0.77      0.77      0.77        71\n",
      "\n",
      "[18 10  6 37]\n",
      "LR Accuracy:  0.7746478873239436\n",
      "LR F1:  0.7572649572649572\n",
      "For name:  t_o'brien\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  262\n",
      "Counter({'0000-0002-7198-8621': 202, '0000-0002-9161-8070': 39, '0000-0001-9028-5481': 20, '0000-0002-5031-736X': 1})\n",
      "['0000-0002-9161-8070', '0000-0002-7198-8621', '0000-0001-9028-5481']\n",
      "Total sample size after apply threshold:  261\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(261, 106)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(261, 22)\n",
      "2\n",
      "(261, 128)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.41      0.54        39\n",
      "          1       0.92      0.99      0.95       202\n",
      "          2       0.67      0.80      0.73        20\n",
      "\n",
      "avg / total       0.88      0.89      0.88       261\n",
      "\n",
      "[ 16  17   6   0 200   2   4   0  16]\n",
      "MNB Accuracy:  0.8888888888888888\n",
      "MNB F1:  0.741433182192051\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.44      0.54        39\n",
      "          1       0.93      0.97      0.95       202\n",
      "          2       0.59      0.80      0.68        20\n",
      "\n",
      "avg / total       0.87      0.87      0.87       261\n",
      "\n",
      "[ 17  15   7   3 195   4   4   0  16]\n",
      "svc Accuracy:  0.8735632183908046\n",
      "svc F1:  0.7223785150866333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        39\n",
      "          1       0.88      0.99      0.93       202\n",
      "          2       0.74      0.70      0.72        20\n",
      "\n",
      "avg / total       0.89      0.88      0.87       261\n",
      "\n",
      "[ 16  20   3   0 200   2   0   6  14]\n",
      "LR Accuracy:  0.8812260536398467\n",
      "LR F1:  0.7447821130064122\n",
      "For name:  s_may\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0003-1813-7745': 59, '0000-0001-5282-3250': 47, '0000-0002-7228-8440': 7, '0000-0001-6762-7500': 2})\n",
      "['0000-0003-1813-7745', '0000-0001-5282-3250']\n",
      "Total sample size after apply threshold:  106\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 41)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 25)\n",
      "2\n",
      "(106, 66)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.93      0.88        59\n",
      "          1       0.90      0.77      0.83        47\n",
      "\n",
      "avg / total       0.86      0.86      0.86       106\n",
      "\n",
      "[55  4 11 36]\n",
      "MNB Accuracy:  0.8584905660377359\n",
      "MNB F1:  0.8537931034482759\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96        59\n",
      "          1       0.96      0.94      0.95        47\n",
      "\n",
      "avg / total       0.95      0.95      0.95       106\n",
      "\n",
      "[57  2  3 44]\n",
      "svc Accuracy:  0.9528301886792453\n",
      "svc F1:  0.9521098762085479\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.92      0.90        59\n",
      "          1       0.89      0.85      0.87        47\n",
      "\n",
      "avg / total       0.89      0.89      0.89       106\n",
      "\n",
      "[54  5  7 40]\n",
      "LR Accuracy:  0.8867924528301887\n",
      "LR F1:  0.8847826086956523\n",
      "For name:  z_cai\n",
      "total sample size before apply threshold:  244\n",
      "Counter({'0000-0002-8724-7684': 200, '0000-0002-8937-4943': 27, '0000-0002-9180-675X': 11, '0000-0003-2884-1429': 6})\n",
      "['0000-0002-9180-675X', '0000-0002-8724-7684', '0000-0002-8937-4943']\n",
      "Total sample size after apply threshold:  238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(238, 79)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(238, 18)\n",
      "2\n",
      "(238, 97)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        11\n",
      "          1       0.87      0.99      0.93       200\n",
      "          2       0.83      0.19      0.30        27\n",
      "\n",
      "avg / total       0.87      0.87      0.83       238\n",
      "\n",
      "[  3   8   0   0 199   1   0  22   5]\n",
      "MNB Accuracy:  0.8697478991596639\n",
      "MNB F1:  0.5531135531135531\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.27      0.40        11\n",
      "          1       0.93      0.99      0.96       200\n",
      "          2       1.00      0.78      0.88        27\n",
      "\n",
      "avg / total       0.93      0.94      0.93       238\n",
      "\n",
      "[  3   8   0   1 199   0   0   6  21]\n",
      "svc Accuracy:  0.9369747899159664\n",
      "svc F1:  0.7462267958030671\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       0.85      1.00      0.92       200\n",
      "          2       1.00      0.07      0.14        27\n",
      "\n",
      "avg / total       0.88      0.86      0.80       238\n",
      "\n",
      "[  2   9   0   0 200   0   0  25   2]\n",
      "LR Accuracy:  0.8571428571428571\n",
      "LR F1:  0.4557607761167271\n",
      "For name:  a_pereira\n",
      "total sample size before apply threshold:  205\n",
      "Counter({'0000-0003-1378-4273': 47, '0000-0001-9980-441X': 19, '0000-0002-3478-4718': 15, '0000-0002-1053-8715': 14, '0000-0002-7392-2255': 9, '0000-0001-9430-9399': 7, '0000-0002-8587-262X': 7, '0000-0003-2351-1084': 7, '0000-0003-1587-4264': 7, '0000-0003-1344-2118': 7, '0000-0003-3097-7704': 5, '0000-0001-5062-1241': 5, '0000-0002-3897-2732': 5, '0000-0003-3665-7592': 5, '0000-0001-5206-4063': 4, '0000-0001-7616-4683': 4, '0000-0003-4532-6947': 3, '0000-0002-0131-3354': 3, '0000-0002-8573-7364': 3, '0000-0002-4788-0338': 3, '0000-0003-1698-3374': 3, '0000-0002-7616-0444': 3, '0000-0003-2534-1007': 2, '0000-0001-8335-7694': 2, '0000-0003-0824-1063': 2, '0000-0001-7066-1769': 2, '0000-0001-9479-5550': 2, '0000-0003-2291-1350': 2, '0000-0002-5834-9374': 1, '0000-0003-4203-6311': 1, '0000-0002-5468-0932': 1, '0000-0002-2563-6174': 1, '0000-0002-1068-2880': 1, '0000-0003-0038-2064': 1, '0000-0003-3803-2043': 1, '0000-0002-6733-5425': 1})\n",
      "['0000-0002-1053-8715', '0000-0003-1378-4273', '0000-0001-9980-441X', '0000-0002-3478-4718']\n",
      "Total sample size after apply threshold:  95\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 59)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 27)\n",
      "2\n",
      "(95, 86)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.14      0.24        14\n",
      "          1       0.74      0.91      0.82        47\n",
      "          2       0.54      0.74      0.62        19\n",
      "          3       0.62      0.33      0.43        15\n",
      "\n",
      "avg / total       0.67      0.67      0.63        95\n",
      "\n",
      "[ 2  7  5  0  0 43  2  2  1  3 14  1  0  5  5  5]\n",
      "MNB Accuracy:  0.6736842105263158\n",
      "MNB F1:  0.5278366419031381\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.14      0.21        14\n",
      "          1       0.82      0.89      0.86        47\n",
      "          2       0.52      0.74      0.61        19\n",
      "          3       0.50      0.40      0.44        15\n",
      "\n",
      "avg / total       0.65      0.67      0.65        95\n",
      "\n",
      "[ 2  5  5  2  1 42  2  2  2  1 14  2  0  3  6  6]\n",
      "svc Accuracy:  0.6736842105263158\n",
      "svc F1:  0.5302023173876721\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.14      0.24        14\n",
      "          1       0.63      0.98      0.77        47\n",
      "          2       0.86      0.63      0.73        19\n",
      "          3       0.80      0.27      0.40        15\n",
      "\n",
      "avg / total       0.71      0.67      0.62        95\n",
      "\n",
      "[ 2 11  1  0  0 46  0  1  1  6 12  0  0 10  1  4]\n",
      "LR Accuracy:  0.6736842105263158\n",
      "LR F1:  0.5323083778966132\n",
      "For name:  d_patel\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0002-1154-3444': 9, '0000-0002-5744-568X': 8, '0000-0002-2236-7757': 5, '0000-0002-1110-0125': 3, '0000-0002-7198-1163': 2, '0000-0002-3746-8171': 2, '0000-0002-0375-2318': 2, '0000-0002-9592-1990': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  a_james\n",
      "total sample size before apply threshold:  154\n",
      "Counter({'0000-0002-4125-4053': 64, '0000-0002-1411-9307': 37, '0000-0002-0873-3714': 29, '0000-0001-8523-0857': 9, '0000-0002-6174-6696': 4, '0000-0001-8454-6219': 3, '0000-0003-4573-932X': 2, '0000-0001-5655-1213': 2, '0000-0002-0023-4363': 2, '0000-0001-9274-7803': 1, '0000-0002-2002-622X': 1})\n",
      "['0000-0002-4125-4053', '0000-0002-0873-3714', '0000-0002-1411-9307']\n",
      "Total sample size after apply threshold:  130\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 68)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 15)\n",
      "2\n",
      "(130, 83)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.89      0.79        64\n",
      "          1       0.67      0.48      0.56        29\n",
      "          2       0.68      0.51      0.58        37\n",
      "\n",
      "avg / total       0.69      0.69      0.68       130\n",
      "\n",
      "[57  3  4 10 14  5 14  4 19]\n",
      "MNB Accuracy:  0.6923076923076923\n",
      "MNB F1:  0.643607427055703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.83      0.87        64\n",
      "          1       0.61      0.48      0.54        29\n",
      "          2       0.61      0.81      0.70        37\n",
      "\n",
      "avg / total       0.76      0.75      0.75       130\n",
      "\n",
      "[53  4  7  3 14 12  2  5 30]\n",
      "svc Accuracy:  0.7461538461538462\n",
      "svc F1:  0.701662805360861\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.89      0.78        64\n",
      "          1       0.70      0.48      0.57        29\n",
      "          2       0.67      0.49      0.56        37\n",
      "\n",
      "avg / total       0.68      0.68      0.67       130\n",
      "\n",
      "[57  3  4 10 14  5 16  3 18]\n",
      "LR Accuracy:  0.6846153846153846\n",
      "LR F1:  0.6364795918367346\n",
      "For name:  c_cao\n",
      "total sample size before apply threshold:  74\n",
      "Counter({'0000-0003-2139-1648': 25, '0000-0003-2830-4383': 20, '0000-0001-8621-8403': 19, '0000-0002-0320-1110': 5, '0000-0002-3407-7837': 4, '0000-0001-6909-5739': 1})\n",
      "['0000-0003-2830-4383', '0000-0003-2139-1648', '0000-0001-8621-8403']\n",
      "Total sample size after apply threshold:  64\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(64, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(64, 14)\n",
      "2\n",
      "(64, 42)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.40      0.47        20\n",
      "          1       0.61      0.88      0.72        25\n",
      "          2       0.71      0.53      0.61        19\n",
      "\n",
      "avg / total       0.63      0.62      0.61        64\n",
      "\n",
      "[ 8  9  3  2 22  1  4  5 10]\n",
      "MNB Accuracy:  0.625\n",
      "MNB F1:  0.5993201055881866\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.60      0.60        20\n",
      "          1       0.75      0.84      0.79        25\n",
      "          2       0.88      0.74      0.80        19\n",
      "\n",
      "avg / total       0.74      0.73      0.73        64\n",
      "\n",
      "[12  6  2  4 21  0  4  1 14]\n",
      "svc Accuracy:  0.734375\n",
      "svc F1:  0.730817610062893\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.45      0.51        20\n",
      "          1       0.67      0.88      0.76        25\n",
      "          2       0.75      0.63      0.69        19\n",
      "\n",
      "avg / total       0.67      0.67      0.66        64\n",
      "\n",
      "[ 9  8  3  2 22  1  4  3 12]\n",
      "LR Accuracy:  0.671875\n",
      "LR F1:  0.6528735632183909\n",
      "For name:  c_brown\n",
      "total sample size before apply threshold:  384\n",
      "Counter({'0000-0002-0294-2419': 85, '0000-0002-8959-0101': 60, '0000-0003-2305-846X': 49, '0000-0002-9637-9355': 44, '0000-0003-2506-4871': 33, '0000-0003-0079-7067': 28, '0000-0003-4776-3403': 13, '0000-0002-7271-4091': 12, '0000-0002-0210-1820': 11, '0000-0003-2057-3976': 8, '0000-0002-1559-3238': 8, '0000-0001-6001-2677': 8, '0000-0003-1602-9214': 7, '0000-0003-3060-5652': 6, '0000-0002-7758-6447': 4, '0000-0002-9905-6391': 3, '0000-0003-4780-6485': 2, '0000-0002-9616-2084': 2, '0000-0001-9979-1815': 1})\n",
      "['0000-0002-0294-2419', '0000-0002-0210-1820', '0000-0003-2305-846X', '0000-0002-9637-9355', '0000-0003-0079-7067', '0000-0003-4776-3403', '0000-0003-2506-4871', '0000-0002-8959-0101', '0000-0002-7271-4091']\n",
      "Total sample size after apply threshold:  335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(335, 176)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(335, 30)\n",
      "2\n",
      "(335, 206)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.87      0.57        85\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.79      0.67      0.73        49\n",
      "          3       0.76      0.57      0.65        44\n",
      "          4       0.78      0.25      0.38        28\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       0.63      0.58      0.60        33\n",
      "          7       0.53      0.42      0.47        60\n",
      "          8       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.55      0.55      0.51       335\n",
      "\n",
      "[74  0  1  2  0  0  2  6  0  8  0  2  0  0  0  1  0  0 10  0 33  1  0  0\n",
      "  1  4  0 14  0  0 25  0  0  1  4  0 12  0  3  0  7  0  0  6  0 11  0  1\n",
      "  0  0  0  1  0  0 14  0  0  0  0  0 19  0  0 24  0  2  3  2  0  4 25  0\n",
      "  7  0  0  2  0  0  1  2  0]\n",
      "MNB Accuracy:  0.5462686567164179\n",
      "MNB F1:  0.3772107385814551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.86      0.69        85\n",
      "          1       0.80      0.36      0.50        11\n",
      "          2       0.85      0.67      0.75        49\n",
      "          3       0.93      0.64      0.76        44\n",
      "          4       0.58      0.54      0.56        28\n",
      "          5       0.86      0.46      0.60        13\n",
      "          6       0.88      0.64      0.74        33\n",
      "          7       0.46      0.53      0.49        60\n",
      "          8       0.17      0.08      0.11        12\n",
      "\n",
      "avg / total       0.67      0.64      0.63       335\n",
      "\n",
      "[73  0  1  0  1  1  0  9  0  1  4  1  0  1  0  0  2  2  7  0 33  0  1  0\n",
      "  0  8  0  7  0  0 28  0  0  1  6  2  6  0  1  0 15  0  0  6  0  4  0  1\n",
      "  0  0  6  0  2  0 10  0  0  0  0  0 21  2  0 17  0  2  0  6  0  2 32  1\n",
      "  3  1  0  2  2  0  0  3  1]\n",
      "svc Accuracy:  0.6358208955223881\n",
      "svc F1:  0.5764465811537716\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.89      0.62        85\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.79      0.63      0.70        49\n",
      "          3       0.93      0.57      0.70        44\n",
      "          4       0.61      0.39      0.48        28\n",
      "          5       1.00      0.23      0.38        13\n",
      "          6       0.72      0.55      0.62        33\n",
      "          7       0.47      0.48      0.48        60\n",
      "          8       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.60      0.58      0.55       335\n",
      "\n",
      "[76  0  0  0  2  0  0  7  0  6  0  2  0  0  0  1  2  0  9  0 31  0  1  0\n",
      "  1  7  0 12  0  0 25  0  0  1  5  1  9  0  3  0 11  0  0  5  0  8  0  1\n",
      "  0  0  3  0  1  0 11  0  0  0  0  0 18  4  0 22  0  2  0  3  0  4 29  0\n",
      "  6  1  0  2  1  0  0  2  0]\n",
      "LR Accuracy:  0.5761194029850746\n",
      "LR F1:  0.44234244301482967\n",
      "For name:  y_liang\n",
      "total sample size before apply threshold:  30\n",
      "Counter({'0000-0002-4798-4882': 18, '0000-0002-7224-9687': 5, '0000-0002-7225-7062': 4, '0000-0002-6440-6144': 2, '0000-0001-7756-1621': 1})\n",
      "['0000-0002-4798-4882']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  y_fan\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0001-8477-8458': 18, '0000-0001-9677-3777': 11, '0000-0002-1865-4550': 8, '0000-0002-8897-9836': 3, '0000-0002-7919-4148': 3, '0000-0001-8914-4796': 3, '0000-0003-3743-3988': 2, '0000-0002-6551-9394': 1, '0000-0002-4010-9719': 1})\n",
      "['0000-0001-9677-3777', '0000-0001-8477-8458']\n",
      "Total sample size after apply threshold:  29\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 25)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 10)\n",
      "2\n",
      "(29, 35)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.18      0.24        11\n",
      "          1       0.61      0.78      0.68        18\n",
      "\n",
      "avg / total       0.50      0.55      0.51        29\n",
      "\n",
      "[ 2  9  4 14]\n",
      "MNB Accuracy:  0.5517241379310345\n",
      "MNB F1:  0.4591104734576758\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      0.18      0.22        11\n",
      "          1       0.59      0.72      0.65        18\n",
      "\n",
      "avg / total       0.48      0.52      0.49        29\n",
      "\n",
      "[ 2  9  5 13]\n",
      "svc Accuracy:  0.5172413793103449\n",
      "svc F1:  0.4361111111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.18      0.24        11\n",
      "          1       0.61      0.78      0.68        18\n",
      "\n",
      "avg / total       0.50      0.55      0.51        29\n",
      "\n",
      "[ 2  9  4 14]\n",
      "LR Accuracy:  0.5517241379310345\n",
      "LR F1:  0.4591104734576758\n",
      "For name:  j_simon\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0003-0214-3745': 54, '0000-0003-0858-0698': 36, '0000-0003-4824-5667': 1, '0000-0001-6081-4127': 1, '0000-0001-7513-9363': 1})\n",
      "['0000-0003-0214-3745', '0000-0003-0858-0698']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(90, 41)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(90, 19)\n",
      "2\n",
      "(90, 60)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.87      0.86        54\n",
      "          1       0.80      0.78      0.79        36\n",
      "\n",
      "avg / total       0.83      0.83      0.83        90\n",
      "\n",
      "[47  7  8 28]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.8255588577335573\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89        54\n",
      "          1       0.90      0.72      0.80        36\n",
      "\n",
      "avg / total       0.86      0.86      0.85        90\n",
      "\n",
      "[51  3 10 26]\n",
      "svc Accuracy:  0.8555555555555555\n",
      "svc F1:  0.8434782608695652\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.94      0.88        54\n",
      "          1       0.89      0.69      0.78        36\n",
      "\n",
      "avg / total       0.85      0.84      0.84        90\n",
      "\n",
      "[51  3 11 25]\n",
      "LR Accuracy:  0.8444444444444444\n",
      "LR F1:  0.8302801724137931\n",
      "For name:  m_jeong\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-7019-8089': 34, '0000-0003-0669-1386': 3, '0000-0003-2869-1475': 2, '0000-0003-4850-8121': 2})\n",
      "['0000-0002-7019-8089']\n",
      "Total sample size after apply threshold:  34\n",
      "For name:  j_barrett\n",
      "total sample size before apply threshold:  130\n",
      "Counter({'0000-0002-1720-7724': 116, '0000-0002-2222-0579': 9, '0000-0002-7524-6035': 1, '0000-0002-3316-5894': 1, '0000-0002-5573-0401': 1, '0000-0002-4048-1692': 1, '0000-0002-3736-0662': 1})\n",
      "['0000-0002-1720-7724']\n",
      "Total sample size after apply threshold:  116\n",
      "For name:  d_elliott\n",
      "total sample size before apply threshold:  216\n",
      "Counter({'0000-0001-9959-6841': 129, '0000-0002-6081-5442': 59, '0000-0003-1052-7407': 21, '0000-0001-9837-7890': 7})\n",
      "['0000-0002-6081-5442', '0000-0003-1052-7407', '0000-0001-9959-6841']\n",
      "Total sample size after apply threshold:  209\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(209, 63)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(209, 30)\n",
      "2\n",
      "(209, 93)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.83      0.80        59\n",
      "          1       0.00      0.00      0.00        21\n",
      "          2       0.86      0.97      0.91       129\n",
      "\n",
      "avg / total       0.75      0.83      0.79       209\n",
      "\n",
      "[ 49   0  10  11   0  10   4   0 125]\n",
      "MNB Accuracy:  0.8325358851674641\n",
      "MNB F1:  0.5697189088679208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.88      0.83        59\n",
      "          1       0.82      0.43      0.56        21\n",
      "          2       0.93      0.95      0.94       129\n",
      "\n",
      "avg / total       0.88      0.88      0.87       209\n",
      "\n",
      "[ 52   1   6   9   9   3   5   1 123]\n",
      "svc Accuracy:  0.8803827751196173\n",
      "svc F1:  0.7790095785440613\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.80      0.82        59\n",
      "          1       1.00      0.05      0.09        21\n",
      "          2       0.83      0.98      0.90       129\n",
      "\n",
      "avg / total       0.85      0.83      0.79       209\n",
      "\n",
      "[ 47   0  12   6   1  14   3   0 126]\n",
      "LR Accuracy:  0.8325358851674641\n",
      "LR F1:  0.6016991827606094\n",
      "For name:  p_antunes\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-3553-2678': 25, '0000-0003-3324-4151': 10, '0000-0001-9129-3539': 5, '0000-0003-1969-1860': 1})\n",
      "['0000-0002-3553-2678', '0000-0003-3324-4151']\n",
      "Total sample size after apply threshold:  35\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 15)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 13)\n",
      "2\n",
      "(35, 28)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.92        25\n",
      "          1       0.88      0.70      0.78        10\n",
      "\n",
      "avg / total       0.88      0.89      0.88        35\n",
      "\n",
      "[24  1  3  7]\n",
      "MNB Accuracy:  0.8857142857142857\n",
      "MNB F1:  0.8504273504273503\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        25\n",
      "          1       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.90      0.89      0.88        35\n",
      "\n",
      "[25  0  4  6]\n",
      "svc Accuracy:  0.8857142857142857\n",
      "svc F1:  0.8379629629629629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        25\n",
      "          1       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.90      0.89      0.88        35\n",
      "\n",
      "[25  0  4  6]\n",
      "LR Accuracy:  0.8857142857142857\n",
      "LR F1:  0.8379629629629629\n",
      "For name:  x_yuan\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0002-1632-8460': 38, '0000-0002-8063-9431': 13, '0000-0001-5395-9109': 11, '0000-0002-2891-1354': 5, '0000-0002-6900-6983': 2, '0000-0001-6983-7368': 1, '0000-0001-7280-7207': 1})\n",
      "['0000-0002-1632-8460', '0000-0001-5395-9109', '0000-0002-8063-9431']\n",
      "Total sample size after apply threshold:  62\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 44)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 14)\n",
      "2\n",
      "(62, 58)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.87      0.80        38\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.47      0.62      0.53        13\n",
      "\n",
      "avg / total       0.56      0.66      0.61        62\n",
      "\n",
      "[33  0  5  7  0  4  4  1  8]\n",
      "MNB Accuracy:  0.6612903225806451\n",
      "MNB F1:  0.4460704607046071\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.87      0.89        38\n",
      "          1       0.67      0.55      0.60        11\n",
      "          2       0.53      0.69      0.60        13\n",
      "\n",
      "avg / total       0.79      0.77      0.78        62\n",
      "\n",
      "[33  1  4  1  6  4  2  2  9]\n",
      "svc Accuracy:  0.7741935483870968\n",
      "svc F1:  0.6972972972972972\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.97      0.77        38\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.50      0.15      0.24        13\n",
      "\n",
      "avg / total       0.50      0.63      0.52        62\n",
      "\n",
      "[37  0  1 10  0  1 11  0  2]\n",
      "LR Accuracy:  0.6290322580645161\n",
      "LR F1:  0.33537581699346414\n",
      "For name:  t_kim\n",
      "total sample size before apply threshold:  568\n",
      "Counter({'0000-0003-4982-4441': 109, '0000-0001-5193-1428': 95, '0000-0003-4087-8021': 48, '0000-0003-0806-8969': 39, '0000-0001-6568-2469': 34, '0000-0002-9578-5722': 27, '0000-0001-9827-7531': 27, '0000-0003-2920-9038': 23, '0000-0002-7975-2437': 23, '0000-0001-9802-0568': 22, '0000-0003-3950-7557': 22, '0000-0002-4032-1285': 17, '0000-0001-5328-0913': 15, '0000-0002-2116-4579': 14, '0000-0002-4375-8095': 11, '0000-0001-7071-1455': 10, '0000-0002-5239-3833': 9, '0000-0002-5104-6565': 4, '0000-0002-0691-9072': 4, '0000-0002-9355-7574': 3, '0000-0003-4835-0707': 3, '0000-0002-7683-7259': 2, '0000-0002-6944-4385': 2, '0000-0002-2225-1199': 2, '0000-0002-3594-826X': 1, '0000-0002-6494-1868': 1, '0000-0001-5162-5420': 1})\n",
      "['0000-0001-9802-0568', '0000-0002-4032-1285', '0000-0003-3950-7557', '0000-0001-5328-0913', '0000-0001-6568-2469', '0000-0003-2920-9038', '0000-0002-2116-4579', '0000-0002-4375-8095', '0000-0002-9578-5722', '0000-0001-5193-1428', '0000-0003-4982-4441', '0000-0002-7975-2437', '0000-0003-4087-8021', '0000-0001-7071-1455', '0000-0001-9827-7531', '0000-0003-0806-8969']\n",
      "Total sample size after apply threshold:  536\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(536, 227)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(536, 22)\n",
      "2\n",
      "(536, 249)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        22\n",
      "          1       0.00      0.00      0.00        17\n",
      "          2       0.00      0.00      0.00        22\n",
      "          3       0.00      0.00      0.00        15\n",
      "          4       0.00      0.00      0.00        34\n",
      "          5       0.00      0.00      0.00        23\n",
      "          6       0.00      0.00      0.00        14\n",
      "          7       0.00      0.00      0.00        11\n",
      "          8       1.00      0.15      0.26        27\n",
      "          9       0.64      0.80      0.71        95\n",
      "         10       0.31      0.94      0.46       109\n",
      "         11       0.00      0.00      0.00        23\n",
      "         12       0.63      0.75      0.69        48\n",
      "         13       0.00      0.00      0.00        10\n",
      "         14       1.00      0.22      0.36        27\n",
      "         15       0.94      0.44      0.60        39\n",
      "\n",
      "avg / total       0.40      0.45      0.36       536\n",
      "\n",
      "[  0   0   0   0   0   0   0   0   0  13   9   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   2  13   0   1   0   0   1   0   0   0   0\n",
      "   0   0   0   0   0   7  15   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   1  12   0   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  30   0   4   0   0   0   0   0   0   0   1   0   0   0   0   3\n",
      "  17   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0  11   0\n",
      "   3   0   0   0   0   0   0   0   0   0   0   0   0   0  11   0   0   0\n",
      "   0   0   0   0   1   0   0   0   0   0   4   2  17   0   3   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  76  18   0   1   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   7 102   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   2  20   0   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   3   9   0  36   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  18   0   3   0   6   0   0   0   0   0   0   0   0   0   0   2  19   0\n",
      "   1   0   0  17]\n",
      "MNB Accuracy:  0.4496268656716418\n",
      "MNB F1:  0.19257236129127495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.45      0.59        22\n",
      "          1       0.67      0.24      0.35        17\n",
      "          2       0.28      0.23      0.25        22\n",
      "          3       0.73      0.53      0.62        15\n",
      "          4       0.08      0.12      0.10        34\n",
      "          5       0.50      0.09      0.15        23\n",
      "          6       0.75      0.21      0.33        14\n",
      "          7       0.60      0.27      0.37        11\n",
      "          8       0.89      0.59      0.71        27\n",
      "          9       0.76      0.78      0.77        95\n",
      "         10       0.45      0.90      0.60       109\n",
      "         11       0.50      0.09      0.15        23\n",
      "         12       1.00      0.85      0.92        48\n",
      "         13       1.00      0.30      0.46        10\n",
      "         14       0.76      0.59      0.67        27\n",
      "         15       0.96      0.59      0.73        39\n",
      "\n",
      "avg / total       0.65      0.58      0.57       536\n",
      "\n",
      "[10  0  3  0  2  0  0  0  0  3  4  0  0  0  0  0  0  4  0  0  1  1  0  0\n",
      "  0  3  7  0  0  0  0  1  1  0  5  1  5  0  0  0  0  1  8  1  0  0  0  0\n",
      "  0  0  1  8  1  0  0  0  1  0  1  0  0  0  3  0  0  0  1  0  4  0  0  0\n",
      "  0  0 28  1  0  0  0  0  0  0  1  0  6  2  0  1  0  5  8  0  0  0  0  0\n",
      "  0  0  1  0  4  0  3  0  0  1  4  0  0  0  1  0  0  0  0  0  3  0  0  3\n",
      "  0  1  4  0  0  0  0  0  0  0  1  1  1  0  0  0 16  1  7  0  0  0  0  0\n",
      "  0  1  2  0  3  1  0  1  0 74 13  0  0  0  0  0  1  0  2  0  2  0  0  0\n",
      "  0  6 98  0  0  0  0  0  0  0  1  0  4  0  0  0  0  2 14  2  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  1  5  0 41  0  1  0  0  0  0  0  2  0  0  0\n",
      "  0  0  5  0  0  3  0  0  0  0  0  1  4  0  1  0  1  0  4  0  0  0 16  0\n",
      "  0  1  0  0  6  0  0  0  0  0  9  0  0  0  0 23]\n",
      "svc Accuracy:  0.582089552238806\n",
      "svc F1:  0.4849287649767487\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        22\n",
      "          1       0.33      0.12      0.17        17\n",
      "          2       0.30      0.14      0.19        22\n",
      "          3       1.00      0.27      0.42        15\n",
      "          4       0.17      0.21      0.18        34\n",
      "          5       0.67      0.09      0.15        23\n",
      "          6       1.00      0.07      0.13        14\n",
      "          7       0.00      0.00      0.00        11\n",
      "          8       0.87      0.48      0.62        27\n",
      "          9       0.68      0.80      0.73        95\n",
      "         10       0.39      0.92      0.55       109\n",
      "         11       0.00      0.00      0.00        23\n",
      "         12       1.00      0.81      0.90        48\n",
      "         13       1.00      0.20      0.33        10\n",
      "         14       0.93      0.52      0.67        27\n",
      "         15       0.95      0.54      0.69        39\n",
      "\n",
      "avg / total       0.63      0.55      0.51       536\n",
      "\n",
      "[  9   0   1   0   1   0   0   0   0   6   5   0   0   0   0   0   0   2\n",
      "   0   0   2   0   0   0   0   2  10   0   0   0   0   1   0   0   3   0\n",
      "   1   0   0   0   1   6  10   1   0   0   0   0   0   0   0   4   2   0\n",
      "   0   0   0   1   7   0   0   0   1   0   0   0   1   0   7   1   0   0\n",
      "   0   0  24   1   0   0   0   0   0   1   2   0   4   2   0   0   0   4\n",
      "  10   0   0   0   0   0   0   0   0   0   4   0   1   0   0   1   8   0\n",
      "   0   0   0   0   0   0   0   0   4   0   0   0   0   0   7   0   0   0\n",
      "   0   0   0   0   1   0   2   0   0   0  13   2   9   0   0   0   0   0\n",
      "   0   1   1   0   3   0   0   0   0  76  14   0   0   0   0   0   0   1\n",
      "   1   0   0   0   0   0   1   6 100   0   0   0   0   0   0   0   0   0\n",
      "   4   0   0   0   0   3  16   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   1   8   0  39   0   0   0   0   0   0   0   1   0   0   0\n",
      "   0   1   6   0   0   2   0   0   0   0   0   0   5   0   0   0   0   0\n",
      "   8   0   0   0  14   0   0   1   0   0   2   0   0   0   0   3  12   0\n",
      "   0   0   0  21]\n",
      "LR Accuracy:  0.5466417910447762\n",
      "LR F1:  0.39524303046427056\n",
      "For name:  a_cruz\n",
      "total sample size before apply threshold:  80\n",
      "Counter({'0000-0002-0465-4111': 38, '0000-0002-8251-8422': 13, '0000-0002-1662-3072': 10, '0000-0003-0368-9731': 9, '0000-0003-4537-1318': 7, '0000-0002-4591-4362': 3})\n",
      "['0000-0002-8251-8422', '0000-0002-0465-4111', '0000-0002-1662-3072']\n",
      "Total sample size after apply threshold:  61\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 34)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 22)\n",
      "2\n",
      "(61, 56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.62      0.70        13\n",
      "          1       0.75      0.95      0.84        38\n",
      "          2       0.33      0.10      0.15        10\n",
      "\n",
      "avg / total       0.69      0.74      0.70        61\n",
      "\n",
      "[ 8  4  1  1 36  1  1  8  1]\n",
      "MNB Accuracy:  0.7377049180327869\n",
      "MNB F1:  0.5622358766949263\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.69      0.75        13\n",
      "          1       0.80      0.95      0.87        38\n",
      "          2       0.60      0.30      0.40        10\n",
      "\n",
      "avg / total       0.77      0.79      0.77        61\n",
      "\n",
      "[ 9  3  1  1 36  1  1  6  3]\n",
      "svc Accuracy:  0.7868852459016393\n",
      "svc F1:  0.6724899598393574\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        13\n",
      "          1       0.70      0.97      0.81        38\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.65      0.72      0.66        61\n",
      "\n",
      "[ 7  6  0  0 37  1  0 10  0]\n",
      "LR Accuracy:  0.7213114754098361\n",
      "LR F1:  0.5043956043956044\n",
      "For name:  a_mora\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0002-0785-5795': 54, '0000-0002-6397-4836': 20, '0000-0003-1344-1131': 5, '0000-0003-1354-4739': 3, '0000-0002-9132-5622': 2})\n",
      "['0000-0002-0785-5795', '0000-0002-6397-4836']\n",
      "Total sample size after apply threshold:  74\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(74, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(74, 20)\n",
      "2\n",
      "(74, 52)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94        54\n",
      "          1       0.93      0.70      0.80        20\n",
      "\n",
      "avg / total       0.91      0.91      0.90        74\n",
      "\n",
      "[53  1  6 14]\n",
      "MNB Accuracy:  0.9054054054054054\n",
      "MNB F1:  0.8690265486725663\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.96      0.92        54\n",
      "          1       0.87      0.65      0.74        20\n",
      "\n",
      "avg / total       0.88      0.88      0.87        74\n",
      "\n",
      "[52  2  7 13]\n",
      "svc Accuracy:  0.8783783783783784\n",
      "svc F1:  0.831605562579014\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        54\n",
      "          1       1.00      0.20      0.33        20\n",
      "\n",
      "avg / total       0.83      0.78      0.73        74\n",
      "\n",
      "[54  0 16  4]\n",
      "LR Accuracy:  0.7837837837837838\n",
      "LR F1:  0.6021505376344087\n",
      "For name:  j_walker\n",
      "total sample size before apply threshold:  253\n",
      "Counter({'0000-0002-8922-083X': 71, '0000-0002-5349-1689': 70, '0000-0002-2050-1641': 64, '0000-0002-2995-0398': 17, '0000-0002-8683-0026': 15, '0000-0001-6034-7514': 9, '0000-0002-9732-5738': 4, '0000-0001-5151-1693': 1, '0000-0003-1349-2633': 1, '0000-0002-8241-9424': 1})\n",
      "['0000-0002-2995-0398', '0000-0002-2050-1641', '0000-0002-8922-083X', '0000-0002-8683-0026', '0000-0002-5349-1689']\n",
      "Total sample size after apply threshold:  237\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(237, 125)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(237, 32)\n",
      "2\n",
      "(237, 157)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        17\n",
      "          1       0.74      0.66      0.69        64\n",
      "          2       0.64      0.68      0.66        71\n",
      "          3       0.77      0.67      0.71        15\n",
      "          4       0.59      0.73      0.65        70\n",
      "\n",
      "avg / total       0.68      0.66      0.65       237\n",
      "\n",
      "[ 5  0  1  1 10  0 42 11  0 11  0  9 48  1 13  0  1  2 10  2  0  5 13  1\n",
      " 51]\n",
      "MNB Accuracy:  0.6582278481012658\n",
      "MNB F1:  0.6340523640203979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.41      0.56        17\n",
      "          1       0.89      0.62      0.73        64\n",
      "          2       0.59      0.92      0.71        71\n",
      "          3       0.92      0.73      0.81        15\n",
      "          4       0.87      0.76      0.81        70\n",
      "\n",
      "avg / total       0.79      0.74      0.74       237\n",
      "\n",
      "[ 7  0  7  0  3  0 40 21  1  2  1  3 65  0  2  0  1  2 11  1  0  1 16  0\n",
      " 53]\n",
      "svc Accuracy:  0.7426160337552743\n",
      "svc F1:  0.7264411577144962\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        17\n",
      "          1       0.72      0.67      0.69        64\n",
      "          2       0.59      0.68      0.63        71\n",
      "          3       1.00      0.73      0.85        15\n",
      "          4       0.65      0.73      0.69        70\n",
      "\n",
      "avg / total       0.70      0.67      0.67       237\n",
      "\n",
      "[ 6  0  4  0  7  0 43 14  0  7  0 11 48  0 12  0  1  2 11  1  0  5 14  0\n",
      " 51]\n",
      "LR Accuracy:  0.6708860759493671\n",
      "LR F1:  0.6756163066533497\n",
      "For name:  j_alves\n",
      "total sample size before apply threshold:  53\n",
      "Counter({'0000-0001-5914-2087': 15, '0000-0001-7221-871X': 13, '0000-0001-7554-2419': 8, '0000-0001-7182-0936': 6, '0000-0002-5736-6519': 4, '0000-0003-3131-9834': 3, '0000-0002-9599-5463': 3, '0000-0002-4355-0921': 1})\n",
      "['0000-0001-5914-2087', '0000-0001-7221-871X']\n",
      "Total sample size after apply threshold:  28\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 14)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 8)\n",
      "2\n",
      "(28, 22)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        15\n",
      "          1       0.87      1.00      0.93        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        28\n",
      "\n",
      "[13  2  0 13]\n",
      "MNB Accuracy:  0.9285714285714286\n",
      "MNB F1:  0.9285714285714286\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        15\n",
      "          1       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.97      0.96      0.96        28\n",
      "\n",
      "[15  0  1 12]\n",
      "svc Accuracy:  0.9642857142857143\n",
      "svc F1:  0.9638709677419355\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        15\n",
      "          1       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.97      0.96      0.96        28\n",
      "\n",
      "[15  0  1 12]\n",
      "LR Accuracy:  0.9642857142857143\n",
      "LR F1:  0.9638709677419355\n",
      "For name:  j_seo\n",
      "total sample size before apply threshold:  146\n",
      "Counter({'0000-0002-1927-2618': 56, '0000-0003-0242-1805': 47, '0000-0002-5039-2503': 12, '0000-0001-8881-7952': 10, '0000-0001-5095-4046': 6, '0000-0003-3471-7803': 3, '0000-0001-5844-4585': 3, '0000-0002-6582-8162': 2, '0000-0001-5534-2508': 2, '0000-0002-3329-1540': 2, '0000-0002-2878-4551': 1, '0000-0003-2117-5750': 1, '0000-0001-9338-643X': 1})\n",
      "['0000-0003-0242-1805', '0000-0002-5039-2503', '0000-0001-8881-7952', '0000-0002-1927-2618']\n",
      "Total sample size after apply threshold:  125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(125, 84)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(125, 25)\n",
      "2\n",
      "(125, 109)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.62      0.67        47\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.60      0.93      0.73        56\n",
      "\n",
      "avg / total       0.55      0.65      0.58       125\n",
      "\n",
      "[29  0  0 18  3  0  0  9  3  0  0  7  4  0  0 52]\n",
      "MNB Accuracy:  0.648\n",
      "MNB F1:  0.3517032427120865\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.85      0.78        47\n",
      "          1       1.00      0.33      0.50        12\n",
      "          2       1.00      0.70      0.82        10\n",
      "          3       0.75      0.79      0.77        56\n",
      "\n",
      "avg / total       0.78      0.76      0.75       125\n",
      "\n",
      "[40  0  0  7  2  4  0  6  1  0  7  2 12  0  0 44]\n",
      "svc Accuracy:  0.76\n",
      "svc F1:  0.7182651321398124\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.83      0.75        47\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.66      0.80      0.73        56\n",
      "\n",
      "avg / total       0.55      0.67      0.61       125\n",
      "\n",
      "[39  0  0  8  4  0  0  8  3  0  0  7 11  0  0 45]\n",
      "LR Accuracy:  0.672\n",
      "LR F1:  0.36895161290322576\n",
      "For name:  y_tang\n",
      "total sample size before apply threshold:  66\n",
      "Counter({'0000-0003-4888-6771': 34, '0000-0003-2718-544X': 17, '0000-0001-9312-1378': 6, '0000-0002-2649-5270': 5, '0000-0002-8807-9264': 2, '0000-0001-7919-1409': 1, '0000-0003-1096-1764': 1})\n",
      "['0000-0003-4888-6771', '0000-0003-2718-544X']\n",
      "Total sample size after apply threshold:  51\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 27)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 8)\n",
      "2\n",
      "(51, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        34\n",
      "          1       1.00      0.59      0.74        17\n",
      "\n",
      "avg / total       0.89      0.86      0.85        51\n",
      "\n",
      "[34  0  7 10]\n",
      "MNB Accuracy:  0.8627450980392157\n",
      "MNB F1:  0.8237037037037037\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        34\n",
      "          1       1.00      0.65      0.79        17\n",
      "\n",
      "avg / total       0.90      0.88      0.87        51\n",
      "\n",
      "[34  0  6 11]\n",
      "svc Accuracy:  0.8823529411764706\n",
      "svc F1:  0.8523166023166023\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        34\n",
      "          1       1.00      0.59      0.74        17\n",
      "\n",
      "avg / total       0.89      0.86      0.85        51\n",
      "\n",
      "[34  0  7 10]\n",
      "LR Accuracy:  0.8627450980392157\n",
      "LR F1:  0.8237037037037037\n",
      "For name:  a_norman\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-1282-394X': 16, '0000-0002-4208-2708': 4, '0000-0002-9499-758X': 4, '0000-0002-4332-6049': 3, '0000-0001-6368-521X': 1})\n",
      "['0000-0002-1282-394X']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  s_tanaka\n",
      "total sample size before apply threshold:  80\n",
      "Counter({'0000-0002-3468-7694': 38, '0000-0001-5157-3317': 24, '0000-0002-1262-3876': 7, '0000-0003-2002-5582': 6, '0000-0002-7101-0690': 4, '0000-0002-2898-9557': 1})\n",
      "['0000-0001-5157-3317', '0000-0002-3468-7694']\n",
      "Total sample size after apply threshold:  62\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 33)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 16)\n",
      "2\n",
      "(62, 49)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.92      0.77        24\n",
      "          1       0.93      0.71      0.81        38\n",
      "\n",
      "avg / total       0.83      0.79      0.79        62\n",
      "\n",
      "[22  2 11 27]\n",
      "MNB Accuracy:  0.7903225806451613\n",
      "MNB F1:  0.7889499869075673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        24\n",
      "          1       0.93      1.00      0.96        38\n",
      "\n",
      "avg / total       0.96      0.95      0.95        62\n",
      "\n",
      "[21  3  0 38]\n",
      "svc Accuracy:  0.9516129032258065\n",
      "svc F1:  0.9476793248945148\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.71      0.81        24\n",
      "          1       0.84      0.97      0.90        38\n",
      "\n",
      "avg / total       0.88      0.87      0.87        62\n",
      "\n",
      "[17  7  1 37]\n",
      "LR Accuracy:  0.8709677419354839\n",
      "LR F1:  0.8559814169570268\n",
      "For name:  c_wen\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0002-5345-0756': 25, '0000-0002-1181-8786': 6, '0000-0002-7684-8820': 2, '0000-0002-5174-1576': 1, '0000-0002-4445-1589': 1, '0000-0002-2538-0439': 1})\n",
      "['0000-0002-5345-0756']\n",
      "Total sample size after apply threshold:  25\n",
      "For name:  c_myers\n",
      "total sample size before apply threshold:  100\n",
      "Counter({'0000-0002-2776-4823': 92, '0000-0003-1492-9008': 6, '0000-0001-7788-8595': 1, '0000-0001-9860-3931': 1})\n",
      "['0000-0002-2776-4823']\n",
      "Total sample size after apply threshold:  92\n",
      "For name:  v_santos\n",
      "total sample size before apply threshold:  30\n",
      "Counter({'0000-0003-0194-7397': 10, '0000-0002-5370-4867': 9, '0000-0001-8693-0759': 4, '0000-0003-3581-5595': 4, '0000-0002-8518-5408': 1, '0000-0003-1283-7388': 1, '0000-0002-9426-6197': 1})\n",
      "['0000-0003-0194-7397']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  j_brown\n",
      "total sample size before apply threshold:  290\n",
      "Counter({'0000-0002-2797-5428': 66, '0000-0001-5269-7661': 47, '0000-0002-6936-035X': 27, '0000-0001-8155-677X': 25, '0000-0002-6839-5948': 24, '0000-0002-1447-8633': 15, '0000-0002-0653-4615': 14, '0000-0001-8502-4252': 11, '0000-0002-3155-0334': 10, '0000-0002-2002-3010': 10, '0000-0002-7535-2874': 9, '0000-0002-4681-9586': 8, '0000-0002-4128-4359': 5, '0000-0002-9838-7201': 4, '0000-0001-6486-8667': 3, '0000-0003-3705-0290': 2, '0000-0002-1261-4574': 2, '0000-0002-1100-7457': 2, '0000-0001-6738-9653': 2, '0000-0001-5823-3083': 1, '0000-0002-9125-8474': 1, '0000-0002-2973-1021': 1, '0000-0003-2979-779X': 1})\n",
      "['0000-0002-3155-0334', '0000-0002-1447-8633', '0000-0001-5269-7661', '0000-0002-2797-5428', '0000-0001-8502-4252', '0000-0001-8155-677X', '0000-0002-0653-4615', '0000-0002-6936-035X', '0000-0002-2002-3010', '0000-0002-6839-5948']\n",
      "Total sample size after apply threshold:  249\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(249, 120)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(249, 19)\n",
      "2\n",
      "(249, 139)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.20      0.33        15\n",
      "          2       0.55      0.64      0.59        47\n",
      "          3       0.47      0.95      0.63        66\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       0.67      0.72      0.69        25\n",
      "          6       0.75      0.21      0.33        14\n",
      "          7       1.00      0.78      0.88        27\n",
      "          8       0.00      0.00      0.00        10\n",
      "          9       1.00      0.12      0.22        24\n",
      "\n",
      "avg / total       0.60      0.57      0.50       249\n",
      "\n",
      "[ 0  0  3  7  0  0  0  0  0  0  0  3  4  6  0  2  0  0  0  0  0  0 30 14\n",
      "  0  1  1  0  1  0  0  0  3 63  0  0  0  0  0  0  0  0  1 10  0  0  0  0\n",
      "  0  0  0  0  1  6  0 18  0  0  0  0  0  0  5  5  0  1  3  0  0  0  0  0\n",
      "  0  5  0  1  0 21  0  0  0  0  5  3  0  2  0  0  0  0  0  0  3 16  0  2\n",
      "  0  0  0  3]\n",
      "MNB Accuracy:  0.5662650602409639\n",
      "MNB F1:  0.367129754695602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       0.80      0.53      0.64        15\n",
      "          2       0.55      0.72      0.62        47\n",
      "          3       0.56      0.89      0.69        66\n",
      "          4       0.67      0.36      0.47        11\n",
      "          5       1.00      0.64      0.78        25\n",
      "          6       0.75      0.43      0.55        14\n",
      "          7       1.00      0.89      0.94        27\n",
      "          8       0.00      0.00      0.00        10\n",
      "          9       0.92      0.46      0.61        24\n",
      "\n",
      "avg / total       0.71      0.66      0.64       249\n",
      "\n",
      "[ 2  1  1  6  0  0  0  0  0  0  0  8  5  2  0  0  0  0  0  0  0  1 34  9\n",
      "  0  0  0  0  3  0  0  0  4 59  0  0  1  0  1  1  0  0  1  5  4  0  1  0\n",
      "  0  0  0  0  4  5  0 16  0  0  0  0  0  0  2  4  2  0  6  0  0  0  0  0\n",
      "  1  2  0  0  0 24  0  0  0  0  8  2  0  0  0  0  0  0  0  0  2 11  0  0\n",
      "  0  0  0 11]\n",
      "svc Accuracy:  0.6586345381526104\n",
      "svc F1:  0.5636063191200729\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.53      0.70        15\n",
      "          2       0.51      0.74      0.61        47\n",
      "          3       0.52      0.92      0.66        66\n",
      "          4       1.00      0.09      0.17        11\n",
      "          5       0.94      0.68      0.79        25\n",
      "          6       0.83      0.36      0.50        14\n",
      "          7       1.00      0.78      0.88        27\n",
      "          8       0.00      0.00      0.00        10\n",
      "          9       1.00      0.33      0.50        24\n",
      "\n",
      "avg / total       0.69      0.63      0.59       249\n",
      "\n",
      "[ 0  0  3  7  0  0  0  0  0  0  0  8  5  2  0  0  0  0  0  0  0  0 35 11\n",
      "  0  0  0  0  1  0  0  0  4 61  0  0  1  0  0  0  0  0  2  8  1  0  0  0\n",
      "  0  0  0  0  3  5  0 17  0  0  0  0  0  0  4  4  0  1  5  0  0  0  0  0\n",
      "  1  5  0  0  0 21  0  0  0  0  7  3  0  0  0  0  0  0  0  0  4 12  0  0\n",
      "  0  0  0  8]\n",
      "LR Accuracy:  0.6265060240963856\n",
      "LR F1:  0.47997556454330975\n",
      "For name:  b_pandey\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0001-6862-4424': 28, '0000-0002-8453-9665': 11, '0000-0001-7870-6060': 2, '0000-0002-3712-5961': 1})\n",
      "['0000-0001-6862-4424', '0000-0002-8453-9665']\n",
      "Total sample size after apply threshold:  39\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 12)\n",
      "2\n",
      "(39, 32)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.93      0.91        28\n",
      "          1       0.80      0.73      0.76        11\n",
      "\n",
      "avg / total       0.87      0.87      0.87        39\n",
      "\n",
      "[26  2  3  8]\n",
      "MNB Accuracy:  0.8717948717948718\n",
      "MNB F1:  0.837092731829574\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.90        28\n",
      "          1       0.86      0.55      0.67        11\n",
      "\n",
      "avg / total       0.85      0.85      0.83        39\n",
      "\n",
      "[27  1  5  6]\n",
      "svc Accuracy:  0.8461538461538461\n",
      "svc F1:  0.7833333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.90        28\n",
      "          1       0.86      0.55      0.67        11\n",
      "\n",
      "avg / total       0.85      0.85      0.83        39\n",
      "\n",
      "[27  1  5  6]\n",
      "LR Accuracy:  0.8461538461538461\n",
      "LR F1:  0.7833333333333332\n",
      "For name:  d_morgan\n",
      "total sample size before apply threshold:  86\n",
      "Counter({'0000-0002-2291-1740': 50, '0000-0002-7410-6591': 27, '0000-0001-8725-9477': 7, '0000-0001-7403-4586': 1, '0000-0002-4911-0046': 1})\n",
      "['0000-0002-2291-1740', '0000-0002-7410-6591']\n",
      "Total sample size after apply threshold:  77\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 43)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 24)\n",
      "2\n",
      "(77, 67)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.92      0.88        50\n",
      "          1       0.82      0.67      0.73        27\n",
      "\n",
      "avg / total       0.83      0.83      0.83        77\n",
      "\n",
      "[46  4  9 18]\n",
      "MNB Accuracy:  0.8311688311688312\n",
      "MNB F1:  0.8054421768707483\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        50\n",
      "          1       1.00      0.70      0.83        27\n",
      "\n",
      "avg / total       0.91      0.90      0.89        77\n",
      "\n",
      "[50  0  8 19]\n",
      "svc Accuracy:  0.8961038961038961\n",
      "svc F1:  0.8760064412238325\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89        50\n",
      "          1       1.00      0.56      0.71        27\n",
      "\n",
      "avg / total       0.87      0.84      0.83        77\n",
      "\n",
      "[50  0 12 15]\n",
      "LR Accuracy:  0.8441558441558441\n",
      "LR F1:  0.8035714285714286\n",
      "For name:  r_smith\n",
      "total sample size before apply threshold:  789\n",
      "Counter({'0000-0002-2381-2349': 587, '0000-0002-5252-9649': 43, '0000-0001-5645-8422': 31, '0000-0002-9174-7681': 19, '0000-0001-8483-6777': 19, '0000-0003-1599-9171': 13, '0000-0003-0245-2265': 13, '0000-0001-9746-1230': 10, '0000-0002-8343-794X': 8, '0000-0002-6881-5690': 8, '0000-0003-4000-2919': 6, '0000-0002-3540-1133': 6, '0000-0003-2502-5098': 6, '0000-0001-9634-2918': 4, '0000-0002-6825-888X': 4, '0000-0003-1209-9653': 3, '0000-0002-9044-9199': 3, '0000-0003-2340-0042': 2, '0000-0002-3794-3788': 2, '0000-0002-7413-4189': 1, '0000-0001-7479-7778': 1})\n",
      "['0000-0003-1599-9171', '0000-0002-9174-7681', '0000-0002-2381-2349', '0000-0001-9746-1230', '0000-0002-5252-9649', '0000-0003-0245-2265', '0000-0001-8483-6777', '0000-0001-5645-8422']\n",
      "Total sample size after apply threshold:  735\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(735, 181)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(735, 34)\n",
      "2\n",
      "(735, 215)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.15      0.21        13\n",
      "          1       0.00      0.00      0.00        19\n",
      "          2       0.83      1.00      0.90       587\n",
      "          3       0.75      0.60      0.67        10\n",
      "          4       0.79      0.26      0.39        43\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       0.00      0.00      0.00        19\n",
      "          7       0.00      0.00      0.00        31\n",
      "\n",
      "avg / total       0.72      0.82      0.76       735\n",
      "\n",
      "[  2   0  10   1   0   0   0   0   0   0  19   0   0   0   0   0   0   0\n",
      " 585   0   2   0   0   0   4   0   0   6   0   0   0   0   0   0  32   0\n",
      "  11   0   0   0   0   0  13   0   0   0   0   0   0   0  17   1   1   0\n",
      "   0   0   0   0  31   0   0   0   0   0]\n",
      "MNB Accuracy:  0.8217687074829932\n",
      "MNB F1:  0.2709163751728626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.31      0.42        13\n",
      "          1       0.86      0.63      0.73        19\n",
      "          2       0.87      0.97      0.92       587\n",
      "          3       0.83      1.00      0.91        10\n",
      "          4       0.74      0.67      0.71        43\n",
      "          5       1.00      0.15      0.27        13\n",
      "          6       1.00      0.21      0.35        19\n",
      "          7       0.60      0.10      0.17        31\n",
      "\n",
      "avg / total       0.86      0.86      0.84       735\n",
      "\n",
      "[  4   0   8   1   0   0   0   0   0  12   7   0   0   0   0   0   2   2\n",
      " 571   0  10   0   0   2   0   0   0  10   0   0   0   0   0   0  14   0\n",
      "  29   0   0   0   0   0  11   0   0   2   0   0   0   0  14   1   0   0\n",
      "   4   0   0   0  28   0   0   0   0   3]\n",
      "svc Accuracy:  0.8639455782312925\n",
      "svc F1:  0.5583575629173319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.23      0.38        13\n",
      "          1       1.00      0.26      0.42        19\n",
      "          2       0.83      0.99      0.90       587\n",
      "          3       0.50      0.20      0.29        10\n",
      "          4       0.80      0.37      0.51        43\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       1.00      0.05      0.10        19\n",
      "          7       0.00      0.00      0.00        31\n",
      "\n",
      "avg / total       0.79      0.83      0.78       735\n",
      "\n",
      "[  3   0   9   1   0   0   0   0   0   5  14   0   0   0   0   0   0   0\n",
      " 583   0   4   0   0   0   0   0   8   2   0   0   0   0   0   0  27   0\n",
      "  16   0   0   0   0   0  13   0   0   0   0   0   0   0  17   1   0   0\n",
      "   1   0   0   0  31   0   0   0   0   0]\n",
      "LR Accuracy:  0.8299319727891157\n",
      "LR F1:  0.32373683149235905\n",
      "For name:  a_guerrero\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0001-5474-1451': 28, '0000-0002-4389-5516': 12, '0000-0001-8602-1248': 9, '0000-0001-6050-8699': 6, '0000-0003-2550-6764': 2})\n",
      "['0000-0002-4389-5516', '0000-0001-5474-1451']\n",
      "Total sample size after apply threshold:  40\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 33)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 12)\n",
      "2\n",
      "(40, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.78      1.00      0.88        28\n",
      "\n",
      "avg / total       0.84      0.80      0.76        40\n",
      "\n",
      "[ 4  8  0 28]\n",
      "MNB Accuracy:  0.8\n",
      "MNB F1:  0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.78      1.00      0.88        28\n",
      "\n",
      "avg / total       0.84      0.80      0.76        40\n",
      "\n",
      "[ 4  8  0 28]\n",
      "svc Accuracy:  0.8\n",
      "svc F1:  0.6875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.70      1.00      0.82        28\n",
      "\n",
      "avg / total       0.49      0.70      0.58        40\n",
      "\n",
      "[ 0 12  0 28]\n",
      "LR Accuracy:  0.7\n",
      "LR F1:  0.4117647058823529\n",
      "For name:  a_grant\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0002-1147-2375': 22, '0000-0001-6146-101X': 9, '0000-0001-7205-5869': 7, '0000-0002-7032-3716': 4, '0000-0001-9746-2989': 2, '0000-0002-1553-596X': 1})\n",
      "['0000-0002-1147-2375']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  v_kumar\n",
      "total sample size before apply threshold:  98\n",
      "Counter({'0000-0003-3522-1121': 18, '0000-0001-6643-7465': 15, '0000-0002-9795-5967': 15, '0000-0001-6477-8274': 9, '0000-0001-5559-0624': 8, '0000-0003-4937-7442': 7, '0000-0003-0910-233X': 7, '0000-0002-7335-0824': 6, '0000-0003-2121-3964': 4, '0000-0002-1583-7749': 3, '0000-0003-1988-2536': 3, '0000-0002-3834-1906': 1, '0000-0002-1513-5835': 1, '0000-0002-3980-1345': 1})\n",
      "['0000-0001-6643-7465', '0000-0003-3522-1121', '0000-0002-9795-5967']\n",
      "Total sample size after apply threshold:  48\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 33)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 13)\n",
      "2\n",
      "(48, 46)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.40      0.48        15\n",
      "          1       0.43      0.67      0.52        18\n",
      "          2       0.80      0.53      0.64        15\n",
      "\n",
      "avg / total       0.60      0.54      0.55        48\n",
      "\n",
      "[ 6  9  0  4 12  2  0  7  8]\n",
      "MNB Accuracy:  0.5416666666666666\n",
      "MNB F1:  0.5472463768115943\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.67      0.71        15\n",
      "          1       0.58      0.78      0.67        18\n",
      "          2       0.82      0.60      0.69        15\n",
      "\n",
      "avg / total       0.71      0.69      0.69        48\n",
      "\n",
      "[10  5  0  2 14  2  1  5  9]\n",
      "svc Accuracy:  0.6875\n",
      "svc F1:  0.691086691086691\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.53      0.55        15\n",
      "          1       0.50      0.67      0.57        18\n",
      "          2       0.80      0.53      0.64        15\n",
      "\n",
      "avg / total       0.62      0.58      0.59        48\n",
      "\n",
      "[ 8  6  1  5 12  1  1  6  8]\n",
      "LR Accuracy:  0.5833333333333334\n",
      "LR F1:  0.5877175697865353\n",
      "For name:  p_shah\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0002-9052-4638': 48, '0000-0001-5497-4765': 12, '0000-0002-1255-9325': 11, '0000-0003-4755-1267': 8, '0000-0002-5839-1687': 3, '0000-0003-1929-9754': 2})\n",
      "['0000-0002-9052-4638', '0000-0001-5497-4765', '0000-0002-1255-9325']\n",
      "Total sample size after apply threshold:  71\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 20)\n",
      "2\n",
      "(71, 57)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84        48\n",
      "          1       0.56      0.42      0.48        12\n",
      "          2       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.77      0.76      0.74        71\n",
      "\n",
      "[44  4  0  7  5  0  6  0  5]\n",
      "MNB Accuracy:  0.7605633802816901\n",
      "MNB F1:  0.6464285714285715\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.96      0.85        48\n",
      "          1       0.75      0.50      0.60        12\n",
      "          2       1.00      0.27      0.43        11\n",
      "\n",
      "avg / total       0.80      0.77      0.74        71\n",
      "\n",
      "[46  2  0  6  6  0  8  0  3]\n",
      "svc Accuracy:  0.7746478873239436\n",
      "svc F1:  0.6268077601410934\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        48\n",
      "          1       1.00      0.33      0.50        12\n",
      "          2       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.82      0.76      0.71        71\n",
      "\n",
      "[48  0  0  8  4  0  9  0  2]\n",
      "LR Accuracy:  0.7605633802816901\n",
      "LR F1:  0.5524166099387339\n",
      "For name:  t_yu\n",
      "total sample size before apply threshold:  134\n",
      "Counter({'0000-0002-0113-2895': 59, '0000-0003-2988-7701': 28, '0000-0002-6737-0618': 17, '0000-0001-5012-9353': 17, '0000-0002-6874-989X': 10, '0000-0002-6724-6043': 1, '0000-0002-1029-6699': 1, '0000-0002-0273-9330': 1})\n",
      "['0000-0002-6874-989X', '0000-0002-0113-2895', '0000-0002-6737-0618', '0000-0003-2988-7701', '0000-0001-5012-9353']\n",
      "Total sample size after apply threshold:  131\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(131, 57)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(131, 16)\n",
      "2\n",
      "(131, 73)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.20      0.29        10\n",
      "          1       0.73      0.98      0.84        59\n",
      "          2       0.89      0.47      0.62        17\n",
      "          3       0.67      0.64      0.65        28\n",
      "          4       1.00      0.71      0.83        17\n",
      "\n",
      "avg / total       0.76      0.75      0.73       131\n",
      "\n",
      "[ 2  1  0  7  0  0 58  1  0  0  0  8  8  1  0  1  9  0 18  0  1  3  0  1\n",
      " 12]\n",
      "MNB Accuracy:  0.7480916030534351\n",
      "MNB F1:  0.6447620545371671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.60      0.71        10\n",
      "          1       0.82      1.00      0.90        59\n",
      "          2       1.00      0.71      0.83        17\n",
      "          3       0.75      0.64      0.69        28\n",
      "          4       1.00      0.94      0.97        17\n",
      "\n",
      "avg / total       0.85      0.85      0.84       131\n",
      "\n",
      "[ 6  0  0  4  0  0 59  0  0  0  0  4 12  1  0  1  9  0 18  0  0  0  0  1\n",
      " 16]\n",
      "svc Accuracy:  0.8473282442748091\n",
      "svc F1:  0.8192473161242033\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.20      0.29        10\n",
      "          1       0.74      0.98      0.85        59\n",
      "          2       0.90      0.53      0.67        17\n",
      "          3       0.64      0.57      0.60        28\n",
      "          4       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.76      0.76      0.74       131\n",
      "\n",
      "[ 2  1  0  7  0  0 58  1  0  0  0  7  9  1  0  1 11  0 16  0  1  1  0  1\n",
      " 14]\n",
      "LR Accuracy:  0.7557251908396947\n",
      "LR F1:  0.6612191344410758\n",
      "For name:  r_singh\n",
      "total sample size before apply threshold:  197\n",
      "Counter({'0000-0003-4261-7044': 83, '0000-0001-9933-4884': 16, '0000-0001-8094-4703': 15, '0000-0001-6298-8219': 11, '0000-0001-7269-6420': 10, '0000-0001-6358-489X': 8, '0000-0003-3642-0392': 6, '0000-0002-7887-2138': 6, '0000-0002-1195-8738': 6, '0000-0002-2944-2561': 6, '0000-0001-5647-3390': 4, '0000-0001-8068-7428': 4, '0000-0001-7128-5726': 4, '0000-0002-6608-7941': 3, '0000-0002-4842-1336': 3, '0000-0003-0283-3754': 2, '0000-0002-0938-9388': 2, '0000-0001-7049-5473': 2, '0000-0002-1514-5697': 2, '0000-0001-6452-1356': 2, '0000-0003-4022-9945': 1, '0000-0001-8493-4510': 1})\n",
      "['0000-0001-8094-4703', '0000-0001-6298-8219', '0000-0001-7269-6420', '0000-0001-9933-4884', '0000-0003-4261-7044']\n",
      "Total sample size after apply threshold:  135\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(135, 66)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(135, 15)\n",
      "2\n",
      "(135, 81)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.20      0.32        15\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       0.67      0.20      0.31        10\n",
      "          3       0.67      0.38      0.48        16\n",
      "          4       0.69      0.98      0.81        83\n",
      "\n",
      "avg / total       0.72      0.69      0.62       135\n",
      "\n",
      "[ 3  0  0  0 12  0  1  0  0 10  0  0  2  2  6  1  0  0  6  9  0  0  1  1\n",
      " 81]\n",
      "MNB Accuracy:  0.6888888888888889\n",
      "MNB F1:  0.4152237194593832\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        15\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       0.75      0.30      0.43        10\n",
      "          3       0.86      0.75      0.80        16\n",
      "          4       0.79      0.99      0.88        83\n",
      "\n",
      "avg / total       0.83      0.81      0.79       135\n",
      "\n",
      "[ 7  0  0  0  8  0  6  0  0  5  0  0  3  2  5  0  0  0 12  4  0  0  1  0\n",
      " 82]\n",
      "svc Accuracy:  0.8148148148148148\n",
      "svc F1:  0.6895645530939648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        15\n",
      "          1       1.00      0.27      0.43        11\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.67      0.25      0.36        16\n",
      "          4       0.67      0.99      0.80        83\n",
      "\n",
      "avg / total       0.68      0.68      0.61       135\n",
      "\n",
      "[ 3  0  0  0 12  0  3  0  0  8  0  0  0  2  8  0  0  0  4 12  0  0  1  0\n",
      " 82]\n",
      "LR Accuracy:  0.6814814814814815\n",
      "LR F1:  0.3851082251082251\n",
      "For name:  c_baker\n",
      "total sample size before apply threshold:  112\n",
      "Counter({'0000-0001-6861-8964': 49, '0000-0002-4434-3107': 36, '0000-0001-9134-2994': 10, '0000-0002-7622-1251': 6, '0000-0002-9391-2468': 5, '0000-0002-1171-563X': 3, '0000-0002-2675-1078': 2, '0000-0002-6274-0579': 1})\n",
      "['0000-0001-9134-2994', '0000-0001-6861-8964', '0000-0002-4434-3107']\n",
      "Total sample size after apply threshold:  95\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 43)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 19)\n",
      "2\n",
      "(95, 62)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.67      0.84      0.75        49\n",
      "          2       0.71      0.67      0.69        36\n",
      "\n",
      "avg / total       0.61      0.68      0.64        95\n",
      "\n",
      "[ 0  8  2  0 41  8  0 12 24]\n",
      "MNB Accuracy:  0.6842105263157895\n",
      "MNB F1:  0.477056277056277\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.69      0.96      0.80        49\n",
      "          2       0.92      0.61      0.73        36\n",
      "\n",
      "avg / total       0.81      0.76      0.74        95\n",
      "\n",
      "[ 3  7  0  0 47  2  0 14 22]\n",
      "svc Accuracy:  0.7578947368421053\n",
      "svc F1:  0.6660968660968661\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       0.68      0.94      0.79        49\n",
      "          2       0.88      0.61      0.72        36\n",
      "\n",
      "avg / total       0.79      0.74      0.71        95\n",
      "\n",
      "[ 2  8  0  0 46  3  0 14 22]\n",
      "LR Accuracy:  0.7368421052631579\n",
      "LR F1:  0.6136565316893186\n",
      "For name:  a_cattaneo\n",
      "total sample size before apply threshold:  196\n",
      "Counter({'0000-0002-6975-8923': 127, '0000-0002-9963-848X': 31, '0000-0002-2962-7259': 18, '0000-0002-4500-6540': 12, '0000-0001-5685-3684': 8})\n",
      "['0000-0002-6975-8923', '0000-0002-2962-7259', '0000-0002-4500-6540', '0000-0002-9963-848X']\n",
      "Total sample size after apply threshold:  188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(188, 98)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(188, 31)\n",
      "2\n",
      "(188, 129)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.98      0.84       127\n",
      "          1       0.67      0.22      0.33        18\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       0.80      0.26      0.39        31\n",
      "\n",
      "avg / total       0.69      0.73      0.66       188\n",
      "\n",
      "[125   1   0   1  14   4   0   0  11   0   0   1  22   1   0   8]\n",
      "MNB Accuracy:  0.7287234042553191\n",
      "MNB F1:  0.3899244092775376\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.95      0.88       127\n",
      "          1       0.92      0.61      0.73        18\n",
      "          2       0.50      0.08      0.14        12\n",
      "          3       0.56      0.48      0.52        31\n",
      "\n",
      "avg / total       0.77      0.79      0.76       188\n",
      "\n",
      "[121   0   1   5   4  11   0   3   7   0   1   4  15   1   0  15]\n",
      "svc Accuracy:  0.7872340425531915\n",
      "svc F1:  0.5691608835832345\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.99      0.83       127\n",
      "          1       1.00      0.22      0.36        18\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       0.88      0.23      0.36        31\n",
      "\n",
      "avg / total       0.72      0.73      0.66       188\n",
      "\n",
      "[126   0   0   1  14   4   0   0  12   0   0   0  24   0   0   7]\n",
      "LR Accuracy:  0.7287234042553191\n",
      "LR F1:  0.3885734727318886\n",
      "For name:  a_ferrari\n",
      "total sample size before apply threshold:  114\n",
      "Counter({'0000-0001-9536-3995': 49, '0000-0002-6166-1350': 18, '0000-0003-1465-2774': 17, '0000-0002-7022-9906': 17, '0000-0002-0387-9984': 9, '0000-0002-6265-4419': 3, '0000-0002-5939-8637': 1})\n",
      "['0000-0003-1465-2774', '0000-0002-7022-9906', '0000-0002-6166-1350', '0000-0001-9536-3995']\n",
      "Total sample size after apply threshold:  101\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 60)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 21)\n",
      "2\n",
      "(101, 81)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.24      0.35        17\n",
      "          1       0.56      0.29      0.38        17\n",
      "          2       0.10      0.06      0.07        18\n",
      "          3       0.61      0.94      0.74        49\n",
      "\n",
      "avg / total       0.52      0.55      0.49       101\n",
      "\n",
      "[ 4  0  1 12  1  5  7  4  0  3  1 14  1  1  1 46]\n",
      "MNB Accuracy:  0.5544554455445545\n",
      "MNB F1:  0.3849675107501194\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.53      0.64        17\n",
      "          1       0.69      0.53      0.60        17\n",
      "          2       0.41      0.50      0.45        18\n",
      "          3       0.82      0.92      0.87        49\n",
      "\n",
      "avg / total       0.72      0.71      0.71       101\n",
      "\n",
      "[ 9  0  4  4  0  9  7  1  0  4  9  5  2  0  2 45]\n",
      "svc Accuracy:  0.7128712871287128\n",
      "svc F1:  0.6395604395604395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        17\n",
      "          1       0.86      0.35      0.50        17\n",
      "          2       0.00      0.00      0.00        18\n",
      "          3       0.60      0.98      0.74        49\n",
      "\n",
      "avg / total       0.60      0.59      0.53       101\n",
      "\n",
      "[ 6  0  1 10  0  6  6  5  0  1  0 17  0  0  1 48]\n",
      "LR Accuracy:  0.594059405940594\n",
      "LR F1:  0.44148129423660265\n",
      "For name:  a_murphy\n",
      "total sample size before apply threshold:  178\n",
      "Counter({'0000-0003-4152-4081': 81, '0000-0002-5222-9902': 61, '0000-0002-2547-4750': 20, '0000-0003-4039-9063': 8, '0000-0002-2820-2304': 4, '0000-0002-9983-8641': 2, '0000-0003-2889-503X': 2})\n",
      "['0000-0003-4152-4081', '0000-0002-2547-4750', '0000-0002-5222-9902']\n",
      "Total sample size after apply threshold:  162\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(162, 88)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(162, 26)\n",
      "2\n",
      "(162, 114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.60      0.62        81\n",
      "          1       1.00      0.05      0.10        20\n",
      "          2       0.46      0.62      0.53        61\n",
      "\n",
      "avg / total       0.61      0.54      0.52       162\n",
      "\n",
      "[49  0 32  6  1 13 23  0 38]\n",
      "MNB Accuracy:  0.5432098765432098\n",
      "MNB F1:  0.41312269142457825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.77      0.69        81\n",
      "          1       1.00      0.40      0.57        20\n",
      "          2       0.60      0.54      0.57        61\n",
      "\n",
      "avg / total       0.66      0.64      0.63       162\n",
      "\n",
      "[62  0 19  9  8  3 28  0 33]\n",
      "svc Accuracy:  0.6358024691358025\n",
      "svc F1:  0.6097609925196132\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.79      0.68        81\n",
      "          1       0.00      0.00      0.00        20\n",
      "          2       0.54      0.48      0.50        61\n",
      "\n",
      "avg / total       0.50      0.57      0.53       162\n",
      "\n",
      "[64  0 17 12  0  8 32  0 29]\n",
      "LR Accuracy:  0.5740740740740741\n",
      "LR F1:  0.3938655011118779\n",
      "For name:  f_hong\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0003-1318-2635': 23, '0000-0001-5120-3519': 14, '0000-0003-0060-2063': 2, '0000-0002-4167-6037': 2})\n",
      "['0000-0003-1318-2635', '0000-0001-5120-3519']\n",
      "Total sample size after apply threshold:  37\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 15)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 13)\n",
      "2\n",
      "(37, 28)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.89        23\n",
      "          1       0.85      0.79      0.81        14\n",
      "\n",
      "avg / total       0.86      0.86      0.86        37\n",
      "\n",
      "[21  2  3 11]\n",
      "MNB Accuracy:  0.8648648648648649\n",
      "MNB F1:  0.8542159180457052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        23\n",
      "          1       0.86      0.86      0.86        14\n",
      "\n",
      "avg / total       0.89      0.89      0.89        37\n",
      "\n",
      "[21  2  2 12]\n",
      "svc Accuracy:  0.8918918918918919\n",
      "svc F1:  0.8850931677018633\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.91      0.87        23\n",
      "          1       0.83      0.71      0.77        14\n",
      "\n",
      "avg / total       0.84      0.84      0.83        37\n",
      "\n",
      "[21  2  4 10]\n",
      "LR Accuracy:  0.8378378378378378\n",
      "LR F1:  0.8221153846153846\n",
      "For name:  m_ferrari\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-3041-2917': 74, '0000-0002-7579-4031': 25, '0000-0002-2986-1272': 22, '0000-0001-6370-605X': 12, '0000-0003-3723-5957': 6, '0000-0001-8535-7348': 5, '0000-0002-7447-6146': 2, '0000-0003-0990-0403': 1, '0000-0003-0283-4263': 1, '0000-0001-7009-6552': 1, '0000-0002-3310-7715': 1})\n",
      "['0000-0002-2986-1272', '0000-0002-3041-2917', '0000-0001-6370-605X', '0000-0002-7579-4031']\n",
      "Total sample size after apply threshold:  133\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 83)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 27)\n",
      "2\n",
      "(133, 110)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.27      0.39        22\n",
      "          1       0.66      0.88      0.76        74\n",
      "          2       1.00      0.17      0.29        12\n",
      "          3       0.54      0.52      0.53        25\n",
      "\n",
      "avg / total       0.67      0.65      0.61       133\n",
      "\n",
      "[ 6 16  0  0  2 65  0  7  0  6  2  4  1 11  0 13]\n",
      "MNB Accuracy:  0.6466165413533834\n",
      "MNB F1:  0.4898093145735414\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.45      0.50        22\n",
      "          1       0.71      0.89      0.79        74\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       0.77      0.40      0.53        25\n",
      "\n",
      "avg / total       0.72      0.71      0.70       133\n",
      "\n",
      "[10 12  0  0  5 66  0  3  2  1  9  0  1 14  0 10]\n",
      "svc Accuracy:  0.7142857142857143\n",
      "svc F1:  0.668469452073297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        22\n",
      "          1       0.61      0.97      0.75        74\n",
      "          2       1.00      0.17      0.29        12\n",
      "          3       0.82      0.36      0.50        25\n",
      "\n",
      "avg / total       0.58      0.62      0.54       133\n",
      "\n",
      "[ 0 22  0  0  2 72  0  0  0  8  2  2  0 16  0  9]\n",
      "LR Accuracy:  0.6240601503759399\n",
      "LR F1:  0.38392857142857145\n",
      "For name:  j_paredes\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0002-1076-1343': 44, '0000-0002-7788-8939': 9, '0000-0002-0974-8109': 7, '0000-0002-1566-9044': 5, '0000-0002-0620-0770': 3})\n",
      "['0000-0002-1076-1343']\n",
      "Total sample size after apply threshold:  44\n",
      "For name:  z_zhao\n",
      "total sample size before apply threshold:  186\n",
      "Counter({'0000-0003-0654-1193': 79, '0000-0003-2743-9008': 28, '0000-0002-1279-2207': 15, '0000-0002-1876-1284': 15, '0000-0001-6079-1631': 14, '0000-0002-1701-3751': 7, '0000-0002-0862-8471': 6, '0000-0002-2901-5033': 6, '0000-0001-8978-8866': 5, '0000-0002-8679-3130': 4, '0000-0001-8979-844X': 3, '0000-0001-6529-5020': 3, '0000-0002-4577-5470': 1})\n",
      "['0000-0002-1279-2207', '0000-0003-2743-9008', '0000-0001-6079-1631', '0000-0003-0654-1193', '0000-0002-1876-1284']\n",
      "Total sample size after apply threshold:  151\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(151, 88)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(151, 17)\n",
      "2\n",
      "(151, 105)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.13      0.24        15\n",
      "          1       0.43      0.11      0.17        28\n",
      "          2       0.50      0.29      0.36        14\n",
      "          3       0.59      0.96      0.73        79\n",
      "          4       0.20      0.07      0.10        15\n",
      "\n",
      "avg / total       0.55      0.57      0.48       151\n",
      "\n",
      "[ 2  0  0 13  0  0  3  0 24  1  0  1  4  6  3  0  2  1 76  0  0  1  3 10\n",
      "  1]\n",
      "MNB Accuracy:  0.5695364238410596\n",
      "MNB F1:  0.320225656696245\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.53      0.70        15\n",
      "          1       0.50      0.36      0.42        28\n",
      "          2       0.44      0.29      0.35        14\n",
      "          3       0.68      0.95      0.79        79\n",
      "          4       0.25      0.07      0.11        15\n",
      "\n",
      "avg / total       0.61      0.65      0.60       151\n",
      "\n",
      "[ 8  0  0  7  0  0 10  2 16  0  0  3  4  4  3  0  4  0 75  0  0  3  3  8\n",
      "  1]\n",
      "svc Accuracy:  0.6490066225165563\n",
      "svc F1:  0.4718117758163524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        15\n",
      "          1       0.56      0.18      0.27        28\n",
      "          2       0.60      0.21      0.32        14\n",
      "          3       0.58      0.96      0.73        79\n",
      "          4       0.50      0.07      0.12        15\n",
      "\n",
      "avg / total       0.61      0.60      0.52       151\n",
      "\n",
      "[ 5  0  0 10  0  0  5  0 23  0  0  1  3  9  1  0  2  1 76  0  0  1  1 12\n",
      "  1]\n",
      "LR Accuracy:  0.5960264900662252\n",
      "LR F1:  0.3861959060101475\n",
      "For name:  j_cao\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-3586-2319': 11, '0000-0002-1544-7441': 10, '0000-0001-5938-6604': 8, '0000-0001-5196-8239': 5, '0000-0001-7414-7660': 4, '0000-0001-6171-1170': 1})\n",
      "['0000-0002-3586-2319', '0000-0002-1544-7441']\n",
      "Total sample size after apply threshold:  21\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 9)\n",
      "2\n",
      "(21, 12)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        21\n",
      "\n",
      "[11  0  0 10]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.96      0.95      0.95        21\n",
      "\n",
      "[10  1  0 10]\n",
      "svc Accuracy:  0.9523809523809523\n",
      "svc F1:  0.9523809523809523\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        21\n",
      "\n",
      "[11  0  0 10]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  d_kuo\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-6461-2562': 17, '0000-0002-3505-0169': 7, '0000-0001-9003-9993': 4, '0000-0001-9300-8551': 3, '0000-0002-7162-174X': 3})\n",
      "['0000-0002-6461-2562']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  a_andersen\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0003-0054-1897': 8, '0000-0002-3831-1707': 6, '0000-0001-8169-7273': 3, '0000-0001-9703-3180': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_longo\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0003-1117-1772': 33, '0000-0001-5062-6245': 5, '0000-0002-6364-8184': 3, '0000-0002-2450-4903': 2, '0000-0001-8325-4003': 1})\n",
      "['0000-0003-1117-1772']\n",
      "Total sample size after apply threshold:  33\n",
      "For name:  h_chiang\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-2979-6108': 18, '0000-0001-8781-5146': 14, '0000-0002-2333-9117': 7, '0000-0001-5041-9705': 5})\n",
      "['0000-0002-2979-6108', '0000-0001-8781-5146']\n",
      "Total sample size after apply threshold:  32\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 12)\n",
      "2\n",
      "(32, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.83      0.71        18\n",
      "          1       0.62      0.36      0.45        14\n",
      "\n",
      "avg / total       0.62      0.62      0.60        32\n",
      "\n",
      "[15  3  9  5]\n",
      "MNB Accuracy:  0.625\n",
      "MNB F1:  0.5844155844155844\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.72      0.74        18\n",
      "          1       0.67      0.71      0.69        14\n",
      "\n",
      "avg / total       0.72      0.72      0.72        32\n",
      "\n",
      "[13  5  4 10]\n",
      "svc Accuracy:  0.71875\n",
      "svc F1:  0.7162561576354679\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.78      0.72        18\n",
      "          1       0.64      0.50      0.56        14\n",
      "\n",
      "avg / total       0.65      0.66      0.65        32\n",
      "\n",
      "[14  4  7  7]\n",
      "LR Accuracy:  0.65625\n",
      "LR F1:  0.6389743589743591\n",
      "For name:  m_o'brien\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-8509-3650': 20, '0000-0002-1721-0464': 9, '0000-0003-1096-1991': 4, '0000-0003-4990-3289': 1})\n",
      "['0000-0002-8509-3650']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  s_ray\n",
      "total sample size before apply threshold:  123\n",
      "Counter({'0000-0002-1051-7260': 75, '0000-0001-5675-1258': 30, '0000-0001-8034-7706': 9, '0000-0002-2414-2930': 5, '0000-0002-4640-708X': 2, '0000-0003-2566-7146': 2})\n",
      "['0000-0002-1051-7260', '0000-0001-5675-1258']\n",
      "Total sample size after apply threshold:  105\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(105, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(105, 21)\n",
      "2\n",
      "(105, 58)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        75\n",
      "          1       0.77      0.77      0.77        30\n",
      "\n",
      "avg / total       0.87      0.87      0.87       105\n",
      "\n",
      "[68  7  7 23]\n",
      "MNB Accuracy:  0.8666666666666667\n",
      "MNB F1:  0.8366666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        75\n",
      "          1       1.00      0.80      0.89        30\n",
      "\n",
      "avg / total       0.95      0.94      0.94       105\n",
      "\n",
      "[75  0  6 24]\n",
      "svc Accuracy:  0.9428571428571428\n",
      "svc F1:  0.9252136752136753\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        75\n",
      "          1       1.00      0.70      0.82        30\n",
      "\n",
      "avg / total       0.92      0.91      0.91       105\n",
      "\n",
      "[75  0  9 21]\n",
      "LR Accuracy:  0.9142857142857143\n",
      "LR F1:  0.8834628190899001\n",
      "For name:  a_cheng\n",
      "total sample size before apply threshold:  636\n",
      "Counter({'0000-0002-9152-6512': 265, '0000-0003-3152-116X': 180, '0000-0003-2345-6951': 71, '0000-0002-1182-7375': 38, '0000-0001-7897-4751': 29, '0000-0003-3862-2967': 25, '0000-0003-2729-606X': 22, '0000-0001-5137-000X': 2, '0000-0002-0977-0381': 2, '0000-0001-5196-3307': 1, '0000-0002-8166-0806': 1})\n",
      "['0000-0003-3862-2967', '0000-0002-1182-7375', '0000-0003-2729-606X', '0000-0003-3152-116X', '0000-0002-9152-6512', '0000-0003-2345-6951', '0000-0001-7897-4751']\n",
      "Total sample size after apply threshold:  630\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(630, 240)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(630, 24)\n",
      "2\n",
      "(630, 264)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        25\n",
      "          1       1.00      0.08      0.15        38\n",
      "          2       0.00      0.00      0.00        22\n",
      "          3       0.62      0.78      0.69       180\n",
      "          4       0.61      0.89      0.72       265\n",
      "          5       0.62      0.11      0.19        71\n",
      "          6       0.00      0.00      0.00        29\n",
      "\n",
      "avg / total       0.60      0.62      0.54       630\n",
      "\n",
      "[  2   0   0   9  14   0   0   0   3   0  27   8   0   0   0   0   0   8\n",
      "  14   0   0   0   0   0 140  40   0   0   0   0   0  24 236   5   0   0\n",
      "   0   0  11  52   8   0   0   0   0   6  23   0   0]\n",
      "MNB Accuracy:  0.6174603174603175\n",
      "MNB F1:  0.2714643152997756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.48      0.62        25\n",
      "          1       0.82      0.37      0.51        38\n",
      "          2       1.00      0.59      0.74        22\n",
      "          3       0.78      0.75      0.76       180\n",
      "          4       0.64      0.91      0.75       265\n",
      "          5       0.54      0.20      0.29        71\n",
      "          6       0.43      0.10      0.17        29\n",
      "\n",
      "avg / total       0.69      0.69      0.66       630\n",
      "\n",
      "[ 12   0   0   0  12   0   1   0  14   0  19   5   0   0   0   0  13   1\n",
      "   8   0   0   0   3   0 135  41   0   1   0   0   0  11 242  11   1   0\n",
      "   0   0   6  50  14   1   2   0   0   2  21   1   3]\n",
      "svc Accuracy:  0.6873015873015873\n",
      "svc F1:  0.5481319696073716\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        25\n",
      "          1       0.71      0.13      0.22        38\n",
      "          2       1.00      0.50      0.67        22\n",
      "          3       0.70      0.71      0.70       180\n",
      "          4       0.60      0.91      0.72       265\n",
      "          5       0.42      0.11      0.18        71\n",
      "          6       0.00      0.00      0.00        29\n",
      "\n",
      "avg / total       0.62      0.63      0.58       630\n",
      "\n",
      "[  8   0   0   4  13   0   0   0   5   0  25   8   0   0   0   0  11   2\n",
      "   9   0   0   0   2   0 127  50   1   0   0   0   0  14 241  10   0   0\n",
      "   0   0   7  56   8   0   0   0   0   3  26   0   0]\n",
      "LR Accuracy:  0.6349206349206349\n",
      "LR F1:  0.42496135661517603\n",
      "For name:  j_savage\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-7756-7166': 6, '0000-0003-0599-0245': 6, '0000-0002-5123-3475': 3, '0000-0002-4737-5673': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  p_matthews\n",
      "total sample size before apply threshold:  329\n",
      "Counter({'0000-0002-1619-8328': 268, '0000-0002-4036-4269': 44, '0000-0002-1362-8003': 10, '0000-0002-2011-9303': 7})\n",
      "['0000-0002-1619-8328', '0000-0002-4036-4269', '0000-0002-1362-8003']\n",
      "Total sample size after apply threshold:  322\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(322, 136)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(322, 30)\n",
      "2\n",
      "(322, 166)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       268\n",
      "          1       0.63      0.39      0.48        44\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.83      0.87      0.84       322\n",
      "\n",
      "[262   6   0  27  17   0   6   4   0]\n",
      "MNB Accuracy:  0.8664596273291926\n",
      "MNB F1:  0.46986716033322495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94       268\n",
      "          1       0.81      0.50      0.62        44\n",
      "          2       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.89      0.89      0.88       322\n",
      "\n",
      "[264   4   0  22  22   0   7   1   2]\n",
      "svc Accuracy:  0.8944099378881988\n",
      "svc F1:  0.6314093712602412\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       268\n",
      "          1       1.00      0.30      0.46        44\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.86      0.87      0.84       322\n",
      "\n",
      "[268   0   0  31  13   0  10   0   0]\n",
      "LR Accuracy:  0.8726708074534162\n",
      "LR F1:  0.4616943861676143\n",
      "For name:  i_carvalho\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-2028-777X': 24, '0000-0002-7882-3555': 4, '0000-0002-7569-2019': 3, '0000-0001-7981-4442': 3, '0000-0001-5823-1520': 3, '0000-0002-1811-0588': 2})\n",
      "['0000-0002-2028-777X']\n",
      "Total sample size after apply threshold:  24\n",
      "For name:  j_parsons\n",
      "total sample size before apply threshold:  255\n",
      "Counter({'0000-0002-6875-7566': 212, '0000-0003-1785-3627': 36, '0000-0002-4184-343X': 5, '0000-0002-4856-8610': 1, '0000-0003-1022-6364': 1})\n",
      "['0000-0002-6875-7566', '0000-0003-1785-3627']\n",
      "Total sample size after apply threshold:  248\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(248, 74)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(248, 23)\n",
      "2\n",
      "(248, 97)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.95       212\n",
      "          1       0.89      0.47      0.62        36\n",
      "\n",
      "avg / total       0.91      0.92      0.90       248\n",
      "\n",
      "[210   2  19  17]\n",
      "MNB Accuracy:  0.9153225806451613\n",
      "MNB F1:  0.7852813852813854\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       212\n",
      "          1       1.00      0.75      0.86        36\n",
      "\n",
      "avg / total       0.97      0.96      0.96       248\n",
      "\n",
      "[212   0   9  27]\n",
      "svc Accuracy:  0.9637096774193549\n",
      "svc F1:  0.9181788188716595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       212\n",
      "          1       1.00      0.11      0.20        36\n",
      "\n",
      "avg / total       0.89      0.87      0.82       248\n",
      "\n",
      "[212   0  32   4]\n",
      "LR Accuracy:  0.8709677419354839\n",
      "LR F1:  0.5649122807017544\n",
      "For name:  s_oliveira\n",
      "total sample size before apply threshold:  143\n",
      "Counter({'0000-0003-4984-4805': 48, '0000-0002-6011-2122': 25, '0000-0001-7919-4191': 23, '0000-0001-8240-0013': 17, '0000-0002-6914-5529': 8, '0000-0002-7322-1184': 8, '0000-0003-0649-2694': 4, '0000-0002-7654-1909': 4, '0000-0002-3504-5749': 3, '0000-0002-8901-9757': 2, '0000-0002-3840-6781': 1})\n",
      "['0000-0003-4984-4805', '0000-0001-7919-4191', '0000-0002-6011-2122', '0000-0001-8240-0013']\n",
      "Total sample size after apply threshold:  113\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(113, 73)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(113, 19)\n",
      "2\n",
      "(113, 92)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.90      0.68        48\n",
      "          1       0.50      0.30      0.38        23\n",
      "          2       0.83      0.40      0.54        25\n",
      "          3       1.00      0.47      0.64        17\n",
      "\n",
      "avg / total       0.67      0.60      0.58       113\n",
      "\n",
      "[43  5  0  0 14  7  2  0 14  1 10  0  8  1  0  8]\n",
      "MNB Accuracy:  0.6017699115044248\n",
      "MNB F1:  0.5590210683124068\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.94      0.71        48\n",
      "          1       0.77      0.43      0.56        23\n",
      "          2       0.82      0.36      0.50        25\n",
      "          3       0.90      0.53      0.67        17\n",
      "\n",
      "avg / total       0.71      0.65      0.63       113\n",
      "\n",
      "[45  1  1  1 13 10  0  0 15  1  9  0  6  1  1  9]\n",
      "svc Accuracy:  0.6460176991150443\n",
      "svc F1:  0.6077209098862641\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.94      0.70        48\n",
      "          1       0.67      0.43      0.53        23\n",
      "          2       1.00      0.36      0.53        25\n",
      "          3       1.00      0.53      0.69        17\n",
      "\n",
      "avg / total       0.75      0.65      0.63       113\n",
      "\n",
      "[45  3  0  0 13 10  0  0 15  1  9  0  7  1  0  9]\n",
      "LR Accuracy:  0.6460176991150443\n",
      "LR F1:  0.6127900616218147\n",
      "For name:  h_kang\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0003-3431-0827': 25, '0000-0001-9671-0944': 6, '0000-0001-8697-4292': 6, '0000-0003-2844-5880': 2, '0000-0002-4952-5524': 1, '0000-0001-6876-4021': 1, '0000-0001-5550-241X': 1, '0000-0001-9073-5833': 1, '0000-0002-0309-7448': 1, '0000-0002-6771-2112': 1, '0000-0001-5036-5612': 1, '0000-0001-6293-0121': 1})\n",
      "['0000-0003-3431-0827']\n",
      "Total sample size after apply threshold:  25\n",
      "For name:  s_vogt\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-8034-5513': 68, '0000-0003-3466-9995': 9, '0000-0002-9009-5183': 8, '0000-0002-0393-5712': 8})\n",
      "['0000-0002-8034-5513']\n",
      "Total sample size after apply threshold:  68\n",
      "For name:  d_garcia\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0002-8552-1475': 32, '0000-0003-3356-4454': 24, '0000-0002-2820-9151': 2, '0000-0001-6669-9457': 1, '0000-0001-6777-9184': 1})\n",
      "['0000-0003-3356-4454', '0000-0002-8552-1475']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 29)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 15)\n",
      "2\n",
      "(56, 44)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.92      0.81        24\n",
      "          1       0.92      0.75      0.83        32\n",
      "\n",
      "avg / total       0.84      0.82      0.82        56\n",
      "\n",
      "[22  2  8 24]\n",
      "MNB Accuracy:  0.8214285714285714\n",
      "MNB F1:  0.8212005108556832\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83        24\n",
      "          1       0.88      0.88      0.88        32\n",
      "\n",
      "avg / total       0.86      0.86      0.86        56\n",
      "\n",
      "[20  4  4 28]\n",
      "svc Accuracy:  0.8571428571428571\n",
      "svc F1:  0.8541666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.79      0.81        24\n",
      "          1       0.85      0.88      0.86        32\n",
      "\n",
      "avg / total       0.84      0.84      0.84        56\n",
      "\n",
      "[19  5  4 28]\n",
      "LR Accuracy:  0.8392857142857143\n",
      "LR F1:  0.835024549918167\n",
      "For name:  w_xie\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0002-2768-3572': 44, '0000-0003-2410-2135': 17, '0000-0003-0493-062X': 15, '0000-0003-4655-6496': 10, '0000-0003-4504-8609': 7, '0000-0003-1762-7224': 6, '0000-0002-5500-8195': 6, '0000-0003-2546-2415': 5, '0000-0003-1501-896X': 2, '0000-0002-4887-3711': 1, '0000-0003-3856-9887': 1, '0000-0002-9983-7948': 1})\n",
      "['0000-0003-2410-2135', '0000-0003-4655-6496', '0000-0002-2768-3572', '0000-0003-0493-062X']\n",
      "Total sample size after apply threshold:  86\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 52)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 13)\n",
      "2\n",
      "(86, 65)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.24      0.31        17\n",
      "          1       0.80      0.40      0.53        10\n",
      "          2       0.62      0.95      0.75        44\n",
      "          3       1.00      0.27      0.42        15\n",
      "\n",
      "avg / total       0.67      0.63      0.58        86\n",
      "\n",
      "[ 4  1 12  0  1  4  5  0  2  0 42  0  2  0  9  4]\n",
      "MNB Accuracy:  0.627906976744186\n",
      "MNB F1:  0.5030195681511471\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.24      0.31        17\n",
      "          1       0.71      0.50      0.59        10\n",
      "          2       0.61      0.91      0.73        44\n",
      "          3       1.00      0.27      0.42        15\n",
      "\n",
      "avg / total       0.66      0.62      0.57        86\n",
      "\n",
      "[ 4  1 12  0  0  5  5  0  3  1 40  0  2  0  9  4]\n",
      "svc Accuracy:  0.6162790697674418\n",
      "svc F1:  0.5110632401654074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.18      0.24        17\n",
      "          1       0.80      0.40      0.53        10\n",
      "          2       0.61      0.95      0.74        44\n",
      "          3       1.00      0.27      0.42        15\n",
      "\n",
      "avg / total       0.65      0.62      0.56        86\n",
      "\n",
      "[ 3  1 13  0  1  4  5  0  2  0 42  0  2  0  9  4]\n",
      "LR Accuracy:  0.6162790697674418\n",
      "LR F1:  0.4844371991926719\n",
      "For name:  m_cruz\n",
      "total sample size before apply threshold:  141\n",
      "Counter({'0000-0001-9759-5466': 57, '0000-0001-9846-6754': 46, '0000-0003-1822-0514': 30, '0000-0002-4767-530X': 3, '0000-0001-8152-3054': 3, '0000-0003-3311-7582': 2})\n",
      "['0000-0001-9846-6754', '0000-0001-9759-5466', '0000-0003-1822-0514']\n",
      "Total sample size after apply threshold:  133\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 83)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 22)\n",
      "2\n",
      "(133, 105)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.43      0.51        46\n",
      "          1       0.57      0.89      0.69        57\n",
      "          2       0.82      0.30      0.44        30\n",
      "\n",
      "avg / total       0.64      0.60      0.57       133\n",
      "\n",
      "[20 24  2  6 51  0  6 15  9]\n",
      "MNB Accuracy:  0.6015037593984962\n",
      "MNB F1:  0.5485741513616078\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.67      0.63        46\n",
      "          1       0.68      0.79      0.73        57\n",
      "          2       0.93      0.43      0.59        30\n",
      "\n",
      "avg / total       0.70      0.67      0.66       133\n",
      "\n",
      "[31 14  1 12 45  0 10  7 13]\n",
      "svc Accuracy:  0.6691729323308271\n",
      "svc F1:  0.6496263447482961\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.46      0.51        46\n",
      "          1       0.60      0.88      0.71        57\n",
      "          2       0.86      0.40      0.55        30\n",
      "\n",
      "avg / total       0.65      0.62      0.61       133\n",
      "\n",
      "[21 23  2  7 50  0  8 10 12]\n",
      "LR Accuracy:  0.6240601503759399\n",
      "LR F1:  0.5906451272304931\n",
      "For name:  w_xu\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0002-2884-3101': 43, '0000-0002-7085-7814': 20, '0000-0003-4019-5140': 19, '0000-0001-8006-2399': 16, '0000-0002-5976-4991': 6, '0000-0002-3014-756X': 6, '0000-0002-2084-2630': 5, '0000-0003-3681-5052': 2, '0000-0003-0164-4652': 2, '0000-0001-7294-8229': 2, '0000-0001-7598-1489': 2, '0000-0002-5442-8569': 1, '0000-0003-0030-8606': 1, '0000-0001-5588-9300': 1})\n",
      "['0000-0002-2884-3101', '0000-0002-7085-7814', '0000-0001-8006-2399', '0000-0003-4019-5140']\n",
      "Total sample size after apply threshold:  98\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 53)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 25)\n",
      "2\n",
      "(98, 78)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.63      0.57        43\n",
      "          1       0.70      0.35      0.47        20\n",
      "          2       0.69      0.69      0.69        16\n",
      "          3       0.38      0.42      0.40        19\n",
      "\n",
      "avg / total       0.56      0.54      0.54        98\n",
      "\n",
      "[27  2  5  9 10  7  0  3  4  0 11  1 10  1  0  8]\n",
      "MNB Accuracy:  0.5408163265306123\n",
      "MNB F1:  0.5321586879432624\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.70      0.65        43\n",
      "          1       0.56      0.50      0.53        20\n",
      "          2       1.00      0.75      0.86        16\n",
      "          3       0.44      0.42      0.43        19\n",
      "\n",
      "avg / total       0.63      0.61      0.61        98\n",
      "\n",
      "[30  6  0  7  8 10  0  2  3  0 12  1  9  2  0  8]\n",
      "svc Accuracy:  0.6122448979591837\n",
      "svc F1:  0.6152630923428886\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.81      0.62        43\n",
      "          1       0.40      0.10      0.16        20\n",
      "          2       0.91      0.62      0.74        16\n",
      "          3       0.46      0.32      0.37        19\n",
      "\n",
      "avg / total       0.54      0.54      0.50        98\n",
      "\n",
      "[35  2  1  5 17  2  0  1  5  0 10  1 12  1  0  6]\n",
      "LR Accuracy:  0.5408163265306123\n",
      "LR F1:  0.47518518518518515\n",
      "For name:  k_roy\n",
      "total sample size before apply threshold:  131\n",
      "Counter({'0000-0003-4486-8074': 110, '0000-0001-9623-0617': 17, '0000-0002-3694-3663': 2, '0000-0001-7537-0792': 1, '0000-0001-8799-6207': 1})\n",
      "['0000-0003-4486-8074', '0000-0001-9623-0617']\n",
      "Total sample size after apply threshold:  127\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 37)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 14)\n",
      "2\n",
      "(127, 51)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       110\n",
      "          1       0.67      0.12      0.20        17\n",
      "\n",
      "avg / total       0.85      0.87      0.83       127\n",
      "\n",
      "[109   1  15   2]\n",
      "MNB Accuracy:  0.8740157480314961\n",
      "MNB F1:  0.5658119658119658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.93       110\n",
      "          1       0.50      0.29      0.37        17\n",
      "\n",
      "avg / total       0.84      0.87      0.85       127\n",
      "\n",
      "[105   5  12   5]\n",
      "svc Accuracy:  0.8661417322834646\n",
      "svc F1:  0.6477402512644803\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       110\n",
      "          1       1.00      0.12      0.21        17\n",
      "\n",
      "avg / total       0.90      0.88      0.84       127\n",
      "\n",
      "[110   0  15   2]\n",
      "LR Accuracy:  0.8818897637795275\n",
      "LR F1:  0.5733482642777156\n",
      "For name:  b_white\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0002-4293-6128': 29, '0000-0002-0684-5210': 7, '0000-0003-3365-939X': 7, '0000-0002-7477-9956': 3, '0000-0003-4191-3511': 1})\n",
      "['0000-0002-4293-6128']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  p_graham\n",
      "total sample size before apply threshold:  89\n",
      "Counter({'0000-0002-3745-0940': 33, '0000-0003-2890-2447': 27, '0000-0001-7133-1358': 26, '0000-0002-1600-1601': 3})\n",
      "['0000-0001-7133-1358', '0000-0002-3745-0940', '0000-0003-2890-2447']\n",
      "Total sample size after apply threshold:  86\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 50)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 22)\n",
      "2\n",
      "(86, 72)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.50      0.63        26\n",
      "          1       0.53      0.88      0.66        33\n",
      "          2       0.69      0.41      0.51        27\n",
      "\n",
      "avg / total       0.68      0.62      0.61        86\n",
      "\n",
      "[13 11  2  1 29  3  1 15 11]\n",
      "MNB Accuracy:  0.6162790697674418\n",
      "MNB F1:  0.6016217191770226\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.54      0.64        26\n",
      "          1       0.81      0.76      0.78        33\n",
      "          2       0.51      0.70      0.59        27\n",
      "\n",
      "avg / total       0.71      0.67      0.68        86\n",
      "\n",
      "[14  1 11  1 25  7  3  5 19]\n",
      "svc Accuracy:  0.6744186046511628\n",
      "svc F1:  0.6704545454545454\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.65      0.71        26\n",
      "          1       0.67      0.73      0.70        33\n",
      "          2       0.57      0.59      0.58        27\n",
      "\n",
      "avg / total       0.67      0.66      0.66        86\n",
      "\n",
      "[17  3  6  3 24  6  2  9 16]\n",
      "LR Accuracy:  0.6627906976744186\n",
      "LR F1:  0.6619345630215195\n",
      "For name:  d_rubin\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0002-6388-7724': 19, '0000-0002-0483-9458': 13, '0000-0003-1639-6989': 9, '0000-0001-5057-4369': 2})\n",
      "['0000-0002-0483-9458', '0000-0002-6388-7724']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 15)\n",
      "2\n",
      "(32, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.85      0.79        13\n",
      "          1       0.88      0.79      0.83        19\n",
      "\n",
      "avg / total       0.82      0.81      0.81        32\n",
      "\n",
      "[11  2  4 15]\n",
      "MNB Accuracy:  0.8125\n",
      "MNB F1:  0.8095238095238094\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.90      1.00      0.95        19\n",
      "\n",
      "avg / total       0.94      0.94      0.94        32\n",
      "\n",
      "[11  2  0 19]\n",
      "svc Accuracy:  0.9375\n",
      "svc F1:  0.9333333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.54      0.64        13\n",
      "          1       0.74      0.89      0.81        19\n",
      "\n",
      "avg / total       0.75      0.75      0.74        32\n",
      "\n",
      "[ 7  6  2 17]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.722943722943723\n",
      "For name:  b_ryan\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-6703-3718': 15, '0000-0001-7213-3273': 11, '0000-0002-5018-2952': 3, '0000-0003-3881-8556': 2})\n",
      "['0000-0001-7213-3273', '0000-0002-6703-3718']\n",
      "Total sample size after apply threshold:  26\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 21)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 9)\n",
      "2\n",
      "(26, 30)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82        11\n",
      "          1       0.87      0.87      0.87        15\n",
      "\n",
      "avg / total       0.85      0.85      0.85        26\n",
      "\n",
      "[ 9  2  2 13]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.8424242424242425\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[10  1  0 15]\n",
      "svc Accuracy:  0.9615384615384616\n",
      "svc F1:  0.9600614439324117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.82      0.86        11\n",
      "          1       0.88      0.93      0.90        15\n",
      "\n",
      "avg / total       0.89      0.88      0.88        26\n",
      "\n",
      "[ 9  2  1 14]\n",
      "LR Accuracy:  0.8846153846153846\n",
      "LR F1:  0.8801843317972351\n",
      "For name:  j_kim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  2116\n",
      "Counter({'0000-0003-1835-9436': 200, '0000-0003-3477-1172': 146, '0000-0003-1232-5307': 124, '0000-0001-6537-0350': 78, '0000-0003-0934-3344': 73, '0000-0001-7964-106X': 56, '0000-0003-2337-6935': 52, '0000-0003-2068-7287': 51, '0000-0002-3573-638X': 46, '0000-0003-4085-293X': 41, '0000-0002-6349-6950': 41, '0000-0002-6931-8581': 38, '0000-0002-4171-3803': 38, '0000-0003-0373-5080': 36, '0000-0002-1299-4300': 36, '0000-0002-8383-8524': 33, '0000-0002-0087-1151': 32, '0000-0002-3500-7494': 32, '0000-0002-4687-6732': 31, '0000-0001-5979-5774': 30, '0000-0001-9660-6303': 29, '0000-0002-1903-8354': 28, '0000-0002-5390-8763': 27, '0000-0003-0767-1918': 26, '0000-0002-4747-9763': 25, '0000-0003-0103-7457': 24, '0000-0003-4035-0438': 23, '0000-0003-2841-147X': 23, '0000-0003-0693-1415': 23, '0000-0002-3566-3379': 19, '0000-0003-4978-1867': 18, '0000-0002-9570-4216': 18, '0000-0001-5080-7097': 17, '0000-0002-1672-5730': 17, '0000-0002-9159-0733': 16, '0000-0001-8208-8568': 16, '0000-0002-5329-6605': 16, '0000-0003-0578-0635': 16, '0000-0001-5204-3369': 16, '0000-0002-3729-8774': 15, '0000-0002-6152-2924': 15, '0000-0001-6417-864X': 15, '0000-0001-6426-9074': 15, '0000-0002-0195-1460': 14, '0000-0001-5951-8013': 14, '0000-0002-8218-0062': 13, '0000-0003-1519-3274': 12, '0000-0001-9881-2784': 12, '0000-0003-0530-3425': 12, '0000-0002-1376-9498': 12, '0000-0001-5096-4068': 12, '0000-0003-4217-3228': 11, '0000-0003-4438-1872': 11, '0000-0001-9840-4780': 11, '0000-0001-7649-4244': 11, '0000-0001-7842-2172': 10, '0000-0001-9595-2765': 10, '0000-0003-4157-9365': 10, '0000-0003-4802-010X': 9, '0000-0001-6188-7571': 9, '0000-0002-0484-9189': 8, '0000-0003-0448-1684': 8, '0000-0002-8580-8134': 8, '0000-0002-0359-2887': 8, '0000-0002-7040-7397': 8, '0000-0001-6603-6768': 8, '0000-0002-7419-021X': 7, '0000-0002-4490-3610': 7, '0000-0001-7819-2784': 7, '0000-0002-3849-649X': 6, '0000-0001-8984-2914': 6, '0000-0002-6575-452X': 6, '0000-0003-0462-6521': 5, '0000-0002-2713-1006': 5, '0000-0002-1810-5383': 5, '0000-0002-0066-534X': 4, '0000-0002-1076-1095': 4, '0000-0003-0340-4169': 4, '0000-0002-8321-026X': 4, '0000-0001-7340-2770': 4, '0000-0001-5228-4939': 4, '0000-0001-6210-4540': 4, '0000-0003-1222-0054': 3, '0000-0002-7425-1828': 3, '0000-0003-1522-9038': 3, '0000-0001-7409-6306': 3, '0000-0002-5810-1512': 3, '0000-0002-3502-7604': 3, '0000-0001-8087-7977': 3, '0000-0001-9302-0040': 3, '0000-0002-3010-1641': 3, '0000-0001-6201-9602': 3, '0000-0003-3172-3212': 3, '0000-0002-3512-5837': 2, '0000-0003-3889-2289': 2, '0000-0002-2124-0818': 2, '0000-0002-5678-2019': 2, '0000-0001-7353-9259': 2, '0000-0001-5235-2612': 2, '0000-0003-4074-877X': 2, '0000-0002-3984-0686': 2, '0000-0002-2679-8802': 2, '0000-0002-9423-438X': 2, '0000-0002-8908-0902': 2, '0000-0001-6746-7447': 2, '0000-0001-5794-975X': 2, '0000-0001-5402-7725': 1, '0000-0002-1273-6096': 1, '0000-0002-3531-489X': 1, '0000-0002-5886-8545': 1, '0000-0003-1834-4867': 1, '0000-0001-8641-7904': 1, '0000-0002-7918-1072': 1, '0000-0001-8371-2852': 1, '0000-0001-7176-409X': 1, '0000-0002-5409-2743': 1, '0000-0001-8616-1654': 1, '0000-0001-6886-2449': 1, '0000-0002-5201-9841': 1, '0000-0002-4966-1980': 1, '0000-0002-0947-876X': 1, '0000-0001-5104-4634': 1, '0000-0002-8663-798X': 1, '0000-0001-7565-068X': 1, '0000-0003-3530-9342': 1, '0000-0003-4907-4716': 1, '0000-0002-7689-6822': 1, '0000-0001-8986-8436': 1, '0000-0002-6944-473X': 1, '0000-0002-8416-3872': 1, '0000-0001-5086-0277': 1, '0000-0002-1384-6799': 1, '0000-0003-0812-6663': 1, '0000-0002-2156-9875': 1, '0000-0002-1094-3761': 1, '0000-0001-7282-0559': 1, '0000-0003-4677-0513': 1, '0000-0002-1418-3309': 1, '0000-0002-3365-8007': 1, '0000-0002-6143-8810': 1, '0000-0003-2479-0548': 1, '0000-0002-2556-7404': 1, '0000-0001-5494-4582': 1, '0000-0002-1764-1045': 1, '0000-0002-0872-4906': 1, '0000-0002-1368-6684': 1, '0000-0002-8237-3956': 1, '0000-0003-4856-6305': 1, '0000-0002-3423-5401': 1, '0000-0002-6204-5170': 1, '0000-0003-3155-0569': 1, '0000-0002-0341-7085': 1, '0000-0002-2938-3995': 1, '0000-0001-6600-9647': 1, '0000-0003-4184-363X': 1, '0000-0002-9011-4209': 1, '0000-0003-0461-6438': 1, '0000-0002-5065-5916': 1, '0000-0001-9078-6892': 1, '0000-0003-2304-6549': 1, '0000-0003-4491-0308': 1, '0000-0001-5182-0242': 1, '0000-0002-0708-9242': 1, '0000-0002-1690-9396': 1, '0000-0002-0824-8532': 1, '0000-0001-9661-5015': 1, '0000-0001-9061-3350': 1, '0000-0002-6214-3889': 1, '0000-0002-4478-6127': 1})\n",
      "['0000-0003-1519-3274', '0000-0001-9660-6303', '0000-0002-5390-8763', '0000-0002-9159-0733', '0000-0001-7842-2172', '0000-0001-7964-106X', '0000-0002-0195-1460', '0000-0001-9881-2784', '0000-0001-5080-7097', '0000-0003-0103-7457', '0000-0003-1232-5307', '0000-0003-4217-3228', '0000-0002-4687-6732', '0000-0002-0087-1151', '0000-0003-0934-3344', '0000-0002-3500-7494', '0000-0003-4978-1867', '0000-0002-3573-638X', '0000-0003-4438-1872', '0000-0002-3729-8774', '0000-0002-6931-8581', '0000-0002-9570-4216', '0000-0001-5979-5774', '0000-0002-8218-0062', '0000-0003-0767-1918', '0000-0002-1903-8354', '0000-0002-6152-2924', '0000-0001-5951-8013', '0000-0001-8208-8568', '0000-0002-4171-3803', '0000-0001-6417-864X', '0000-0001-9595-2765', '0000-0003-2068-7287', '0000-0002-5329-6605', '0000-0003-4085-293X', '0000-0003-0373-5080', '0000-0003-4035-0438', '0000-0002-4747-9763', '0000-0001-6537-0350', '0000-0003-0530-3425', '0000-0002-1376-9498', '0000-0003-4157-9365', '0000-0002-8383-8524', '0000-0003-2841-147X', '0000-0002-3566-3379', '0000-0003-0693-1415', '0000-0001-9840-4780', '0000-0003-1835-9436', '0000-0001-7649-4244', '0000-0003-2337-6935', '0000-0003-0578-0635', '0000-0002-1672-5730', '0000-0002-6349-6950', '0000-0001-5204-3369', '0000-0002-1299-4300', '0000-0001-6426-9074', '0000-0001-5096-4068', '0000-0003-3477-1172']\n",
      "Total sample size after apply threshold:  1846\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(1846, 584)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(1846, 28)\n",
      "2\n",
      "(1846, 612)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.00      0.00      0.00        29\n",
      "          2       0.00      0.00      0.00        27\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.68      0.38      0.48        56\n",
      "          6       0.00      0.00      0.00        14\n",
      "          7       0.00      0.00      0.00        12\n",
      "          8       0.00      0.00      0.00        17\n",
      "          9       0.00      0.00      0.00        24\n",
      "         10       0.39      0.60      0.47       124\n",
      "         11       0.00      0.00      0.00        11\n",
      "         12       0.00      0.00      0.00        31\n",
      "         13       0.00      0.00      0.00        32\n",
      "         14       0.44      0.30      0.36        73\n",
      "         15       0.00      0.00      0.00        32\n",
      "         16       0.00      0.00      0.00        18\n",
      "         17       0.92      0.26      0.41        46\n",
      "         18       0.00      0.00      0.00        11\n",
      "         19       0.00      0.00      0.00        15\n",
      "         20       0.00      0.00      0.00        38\n",
      "         21       0.00      0.00      0.00        18\n",
      "         22       0.36      0.13      0.20        30\n",
      "         23       0.00      0.00      0.00        13\n",
      "         24       0.00      0.00      0.00        26\n",
      "         25       0.00      0.00      0.00        28\n",
      "         26       0.00      0.00      0.00        15\n",
      "         27       0.00      0.00      0.00        14\n",
      "         28       0.00      0.00      0.00        16\n",
      "         29       1.00      0.13      0.23        38\n",
      "         30       0.00      0.00      0.00        15\n",
      "         31       0.00      0.00      0.00        10\n",
      "         32       0.14      0.02      0.03        51\n",
      "         33       0.00      0.00      0.00        16\n",
      "         34       0.50      0.10      0.16        41\n",
      "         35       1.00      0.06      0.11        36\n",
      "         36       0.00      0.00      0.00        23\n",
      "         37       0.00      0.00      0.00        25\n",
      "         38       0.13      0.08      0.10        78\n",
      "         39       0.00      0.00      0.00        12\n",
      "         40       0.00      0.00      0.00        12\n",
      "         41       0.00      0.00      0.00        10\n",
      "         42       0.00      0.00      0.00        33\n",
      "         43       0.00      0.00      0.00        23\n",
      "         44       1.00      0.26      0.42        19\n",
      "         45       0.00      0.00      0.00        23\n",
      "         46       0.00      0.00      0.00        11\n",
      "         47       0.18      0.97      0.31       200\n",
      "         48       0.00      0.00      0.00        11\n",
      "         49       0.22      0.04      0.07        52\n",
      "         50       0.00      0.00      0.00        16\n",
      "         51       0.00      0.00      0.00        17\n",
      "         52       0.40      0.29      0.34        41\n",
      "         53       0.00      0.00      0.00        16\n",
      "         54       0.30      0.22      0.25        36\n",
      "         55       0.00      0.00      0.00        15\n",
      "         56       0.00      0.00      0.00        12\n",
      "         57       0.38      0.90      0.54       146\n",
      "\n",
      "avg / total       0.23      0.27      0.18      1846\n",
      "\n",
      "[  0   0   0 ...   0   0 131]\n",
      "MNB Accuracy:  0.27302275189599134\n",
      "MNB F1:  0.07700045991183978\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.11      0.07      0.08        29\n",
      "          2       0.20      0.30      0.24        27\n",
      "          3       0.12      0.06      0.08        16\n",
      "          4       1.00      0.20      0.33        10\n",
      "          5       0.44      0.43      0.43        56\n",
      "          6       0.17      0.07      0.10        14\n",
      "          7       1.00      0.58      0.74        12\n",
      "          8       1.00      0.76      0.87        17\n",
      "          9       0.30      0.25      0.27        24\n",
      "         10       0.22      0.83      0.35       124\n",
      "         11       0.00      0.00      0.00        11\n",
      "         12       0.39      0.23      0.29        31\n",
      "         13       0.65      0.53      0.59        32\n",
      "         14       0.43      0.42      0.43        73\n",
      "         15       0.44      0.25      0.32        32\n",
      "         16       1.00      0.67      0.80        18\n",
      "         17       0.97      0.61      0.75        46\n",
      "         18       0.00      0.00      0.00        11\n",
      "         19       0.17      0.07      0.10        15\n",
      "         20       0.32      0.21      0.25        38\n",
      "         21       0.91      0.56      0.69        18\n",
      "         22       0.71      0.90      0.79        30\n",
      "         23       0.22      0.15      0.18        13\n",
      "         24       0.38      0.23      0.29        26\n",
      "         25       0.53      0.29      0.37        28\n",
      "         26       0.17      0.07      0.10        15\n",
      "         27       0.50      0.29      0.36        14\n",
      "         28       0.00      0.00      0.00        16\n",
      "         29       0.77      0.61      0.68        38\n",
      "         30       0.40      0.27      0.32        15\n",
      "         31       0.00      0.00      0.00        10\n",
      "         32       0.38      0.25      0.31        51\n",
      "         33       1.00      0.50      0.67        16\n",
      "         34       0.57      0.41      0.48        41\n",
      "         35       0.46      0.17      0.24        36\n",
      "         36       0.50      0.39      0.44        23\n",
      "         37       0.70      0.28      0.40        25\n",
      "         38       0.27      0.32      0.29        78\n",
      "         39       0.86      0.50      0.63        12\n",
      "         40       0.00      0.00      0.00        12\n",
      "         41       1.00      0.50      0.67        10\n",
      "         42       0.43      0.27      0.33        33\n",
      "         43       0.20      0.04      0.07        23\n",
      "         44       0.94      0.84      0.89        19\n",
      "         45       0.20      0.09      0.12        23\n",
      "         46       0.14      0.09      0.11        11\n",
      "         47       0.68      0.84      0.75       200\n",
      "         48       0.67      0.18      0.29        11\n",
      "         49       0.42      0.35      0.38        52\n",
      "         50       0.75      0.19      0.30        16\n",
      "         51       0.75      0.18      0.29        17\n",
      "         52       0.34      0.49      0.40        41\n",
      "         53       0.89      0.50      0.64        16\n",
      "         54       0.43      0.28      0.34        36\n",
      "         55       0.80      0.27      0.40        15\n",
      "         56       0.00      0.00      0.00        12\n",
      "         57       0.72      0.86      0.79       146\n",
      "\n",
      "avg / total       0.50      0.46      0.45      1846\n",
      "\n",
      "[  0   0   0 ...   0   0 126]\n",
      "svc Accuracy:  0.46153846153846156\n",
      "svc F1:  0.36232337889972827\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.16      0.10      0.12        29\n",
      "          2       0.24      0.30      0.26        27\n",
      "          3       0.14      0.06      0.09        16\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.36      0.38      0.37        56\n",
      "          6       0.00      0.00      0.00        14\n",
      "          7       1.00      0.58      0.74        12\n",
      "          8       1.00      0.53      0.69        17\n",
      "          9       0.33      0.25      0.29        24\n",
      "         10       0.23      0.81      0.36       124\n",
      "         11       0.00      0.00      0.00        11\n",
      "         12       0.33      0.19      0.24        31\n",
      "         13       0.73      0.50      0.59        32\n",
      "         14       0.46      0.42      0.44        73\n",
      "         15       0.56      0.28      0.38        32\n",
      "         16       0.27      0.67      0.38        18\n",
      "         17       0.96      0.52      0.68        46\n",
      "         18       0.00      0.00      0.00        11\n",
      "         19       0.00      0.00      0.00        15\n",
      "         20       0.23      0.08      0.12        38\n",
      "         21       1.00      0.39      0.56        18\n",
      "         22       0.71      0.90      0.79        30\n",
      "         23       0.00      0.00      0.00        13\n",
      "         24       0.27      0.12      0.16        26\n",
      "         25       0.67      0.36      0.47        28\n",
      "         26       0.00      0.00      0.00        15\n",
      "         27       0.00      0.00      0.00        14\n",
      "         28       0.00      0.00      0.00        16\n",
      "         29       0.77      0.61      0.68        38\n",
      "         30       0.50      0.07      0.12        15\n",
      "         31       0.00      0.00      0.00        10\n",
      "         32       0.30      0.24      0.26        51\n",
      "         33       0.89      0.50      0.64        16\n",
      "         34       0.54      0.46      0.50        41\n",
      "         35       0.35      0.17      0.23        36\n",
      "         36       0.50      0.26      0.34        23\n",
      "         37       0.75      0.24      0.36        25\n",
      "         38       0.32      0.31      0.31        78\n",
      "         39       1.00      0.50      0.67        12\n",
      "         40       0.00      0.00      0.00        12\n",
      "         41       1.00      0.30      0.46        10\n",
      "         42       0.50      0.21      0.30        33\n",
      "         43       0.00      0.00      0.00        23\n",
      "         44       1.00      0.84      0.91        19\n",
      "         45       0.14      0.04      0.07        23\n",
      "         46       0.33      0.09      0.14        11\n",
      "         47       0.51      0.92      0.65       200\n",
      "         48       0.00      0.00      0.00        11\n",
      "         49       0.41      0.33      0.37        52\n",
      "         50       0.00      0.00      0.00        16\n",
      "         51       1.00      0.06      0.11        17\n",
      "         52       0.40      0.44      0.42        41\n",
      "         53       0.71      0.31      0.43        16\n",
      "         54       0.25      0.31      0.28        36\n",
      "         55       0.00      0.00      0.00        15\n",
      "         56       0.00      0.00      0.00        12\n",
      "         57       0.69      0.88      0.77       146\n",
      "\n",
      "avg / total       0.44      0.44      0.40      1846\n",
      "\n",
      "[  0   0   0 ...   0   0 129]\n",
      "LR Accuracy:  0.43661971830985913\n",
      "LR F1:  0.28877802304015987\n",
      "For name:  a_duarte\n",
      "total sample size before apply threshold:  373\n",
      "Counter({'0000-0002-4868-4099': 194, '0000-0002-0616-4650': 36, '0000-0002-9255-3635': 34, '0000-0002-0223-7867': 30, '0000-0003-0800-0112': 19, '0000-0003-2181-0187': 13, '0000-0003-4001-0871': 12, '0000-0003-3333-5977': 10, '0000-0001-9036-0170': 6, '0000-0001-6849-6004': 5, '0000-0001-5578-1586': 4, '0000-0003-0218-1952': 4, '0000-0002-6774-4886': 3, '0000-0002-5911-6521': 2, '0000-0001-8369-368X': 1})\n",
      "['0000-0003-4001-0871', '0000-0003-0800-0112', '0000-0003-2181-0187', '0000-0002-0223-7867', '0000-0002-0616-4650', '0000-0002-4868-4099', '0000-0002-9255-3635', '0000-0003-3333-5977']\n",
      "Total sample size after apply threshold:  348\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(348, 133)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(348, 23)\n",
      "2\n",
      "(348, 156)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       1.00      0.11      0.19        19\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.67      0.07      0.12        30\n",
      "          4       0.70      0.64      0.67        36\n",
      "          5       0.63      0.98      0.77       194\n",
      "          6       0.67      0.12      0.20        34\n",
      "          7       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.60      0.64      0.54       348\n",
      "\n",
      "[  0   0   0   0   1  11   0   0   0   2   0   0   0  17   0   0   0   0\n",
      "   0   1   0  12   0   0   0   0   0   2   4  24   0   0   0   0   0   0\n",
      "  23  12   1   0   0   0   0   0   2 191   1   0   0   0   0   0   3  27\n",
      "   4   0   0   0   0   0   0  10   0   0]\n",
      "MNB Accuracy:  0.6379310344827587\n",
      "MNB F1:  0.24317790643091847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.90      0.47      0.62        19\n",
      "          2       0.30      0.23      0.26        13\n",
      "          3       0.67      0.20      0.31        30\n",
      "          4       0.88      0.58      0.70        36\n",
      "          5       0.75      0.98      0.85       194\n",
      "          6       0.70      0.56      0.62        34\n",
      "          7       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.76      0.75      0.72       348\n",
      "\n",
      "[  7   0   0   0   0   5   0   0   0   9   1   0   0   9   0   0   0   1\n",
      "   3   2   0   5   2   0   0   0   4   6   1  16   3   0   0   0   1   0\n",
      "  21  13   1   0   0   0   0   0   2 191   1   0   0   0   1   1   0  13\n",
      "  19   0   0   0   0   0   0   4   1   5]\n",
      "svc Accuracy:  0.75\n",
      "svc F1:  0.5955750010716196\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       1.00      0.32      0.48        19\n",
      "          2       0.25      0.08      0.12        13\n",
      "          3       0.60      0.20      0.30        30\n",
      "          4       0.84      0.58      0.69        36\n",
      "          5       0.67      0.98      0.79       194\n",
      "          6       0.67      0.29      0.41        34\n",
      "          7       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.67      0.68      0.62       348\n",
      "\n",
      "[  0   0   0   0   1  11   0   0   0   6   0   0   0  13   0   0   0   0\n",
      "   1   4   0   8   0   0   0   0   3   6   1  17   3   0   0   0   0   0\n",
      "  21  15   0   0   0   0   0   0   2 191   1   0   0   0   0   0   0  24\n",
      "  10   0   0   0   0   0   0   8   1   1]\n",
      "LR Accuracy:  0.6781609195402298\n",
      "LR F1:  0.37129148628632025\n",
      "For name:  a_correia\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5115-1429': 81, '0000-0003-0408-6262': 26, '0000-0002-0119-9790': 11, '0000-0002-2831-025X': 7, '0000-0003-2414-0131': 4, '0000-0003-3000-9324': 4, '0000-0002-8946-8579': 2, '0000-0002-2172-6631': 1})\n",
      "['0000-0003-0408-6262', '0000-0002-5115-1429', '0000-0002-0119-9790']\n",
      "Total sample size after apply threshold:  118\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(118, 74)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(118, 18)\n",
      "2\n",
      "(118, 92)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.50      0.62        26\n",
      "          1       0.77      0.98      0.86        81\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.71      0.78      0.73       118\n",
      "\n",
      "[13 13  0  2 79  0  1 10  0]\n",
      "MNB Accuracy:  0.7796610169491526\n",
      "MNB F1:  0.4941451990632319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.62      0.70        26\n",
      "          1       0.81      0.96      0.88        81\n",
      "          2       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.83      0.81      0.79       118\n",
      "\n",
      "[16 10  0  3 78  0  1  8  2]\n",
      "svc Accuracy:  0.8135593220338984\n",
      "svc F1:  0.6282334712695803\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.35      0.50        26\n",
      "          1       0.75      1.00      0.86        81\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.71      0.76      0.70       118\n",
      "\n",
      "[ 9 17  0  0 81  0  1 10  0]\n",
      "LR Accuracy:  0.7627118644067796\n",
      "LR F1:  0.4523809523809524\n",
      "For name:  a_reynolds\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0002-0836-746X': 23, '0000-0001-9534-8699': 7, '0000-0002-6768-5716': 5, '0000-0002-9919-4161': 3, '0000-0003-0554-8107': 1, '0000-0002-6364-6250': 1})\n",
      "['0000-0002-0836-746X']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  g_qin\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0001-6770-1096': 7, '0000-0002-2212-1597': 6, '0000-0002-3524-2013': 1, '0000-0002-3437-3716': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_tang\n",
      "total sample size before apply threshold:  86\n",
      "Counter({'0000-0001-6460-8136': 36, '0000-0003-2861-682X': 19, '0000-0002-3483-0219': 10, '0000-0002-8756-8445': 6, '0000-0001-5858-5126': 4, '0000-0001-8117-9695': 3, '0000-0003-2876-9199': 3, '0000-0002-2416-4101': 2, '0000-0001-7479-6206': 1, '0000-0001-9726-9943': 1, '0000-0001-7321-6927': 1})\n",
      "['0000-0003-2861-682X', '0000-0001-6460-8136', '0000-0002-3483-0219']\n",
      "Total sample size after apply threshold:  65\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 33)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 14)\n",
      "2\n",
      "(65, 47)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.63      0.65        19\n",
      "          1       0.74      0.94      0.83        36\n",
      "          2       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.76      0.72      0.68        65\n",
      "\n",
      "[12  7  0  2 34  0  4  5  1]\n",
      "MNB Accuracy:  0.7230769230769231\n",
      "MNB F1:  0.5532450410499191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.74      0.70        19\n",
      "          1       0.85      0.94      0.89        36\n",
      "          2       0.75      0.30      0.43        10\n",
      "\n",
      "avg / total       0.78      0.78      0.77        65\n",
      "\n",
      "[14  4  1  2 34  0  5  2  3]\n",
      "svc Accuracy:  0.7846153846153846\n",
      "svc F1:  0.6744360902255638\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.58      0.65        19\n",
      "          1       0.73      1.00      0.85        36\n",
      "          2       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.78      0.74      0.69        65\n",
      "\n",
      "[11  8  0  0 36  0  4  5  1]\n",
      "LR Accuracy:  0.7384615384615385\n",
      "LR F1:  0.5586452762923352\n",
      "For name:  a_baranov\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-9976-8532': 20, '0000-0002-9112-0838': 14, '0000-0003-3987-8112': 7, '0000-0001-8810-9972': 1})\n",
      "['0000-0002-9112-0838', '0000-0002-9976-8532']\n",
      "Total sample size after apply threshold:  34\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 18)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 12)\n",
      "2\n",
      "(34, 30)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.86      0.83        14\n",
      "          1       0.89      0.85      0.87        20\n",
      "\n",
      "avg / total       0.86      0.85      0.85        34\n",
      "\n",
      "[12  2  3 17]\n",
      "MNB Accuracy:  0.8529411764705882\n",
      "MNB F1:  0.8496905393457118\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.86      0.83        14\n",
      "          1       0.89      0.85      0.87        20\n",
      "\n",
      "avg / total       0.86      0.85      0.85        34\n",
      "\n",
      "[12  2  3 17]\n",
      "svc Accuracy:  0.8529411764705882\n",
      "svc F1:  0.8496905393457118\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.71      0.74        14\n",
      "          1       0.81      0.85      0.83        20\n",
      "\n",
      "avg / total       0.79      0.79      0.79        34\n",
      "\n",
      "[10  4  3 17]\n",
      "LR Accuracy:  0.7941176470588235\n",
      "LR F1:  0.7850045167118338\n",
      "For name:  r_gray\n",
      "total sample size before apply threshold:  162\n",
      "Counter({'0000-0001-9694-4206': 83, '0000-0002-9858-0191': 48, '0000-0002-2203-2703': 19, '0000-0001-9668-6497': 6, '0000-0002-5890-1819': 6})\n",
      "['0000-0001-9694-4206', '0000-0002-2203-2703', '0000-0002-9858-0191']\n",
      "Total sample size after apply threshold:  150\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(150, 65)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(150, 18)\n",
      "2\n",
      "(150, 83)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.93      0.83        83\n",
      "          1       1.00      0.11      0.19        19\n",
      "          2       0.74      0.71      0.72        48\n",
      "\n",
      "avg / total       0.78      0.75      0.72       150\n",
      "\n",
      "[77  0  6 11  2  6 14  0 34]\n",
      "MNB Accuracy:  0.7533333333333333\n",
      "MNB F1:  0.5821042927425907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        83\n",
      "          1       1.00      0.42      0.59        19\n",
      "          2       0.97      0.75      0.85        48\n",
      "\n",
      "avg / total       0.88      0.85      0.83       150\n",
      "\n",
      "[83  0  0 10  8  1 12  0 36]\n",
      "svc Accuracy:  0.8466666666666667\n",
      "svc F1:  0.7742100465087532\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.99      0.82        83\n",
      "          1       1.00      0.05      0.10        19\n",
      "          2       0.94      0.62      0.75        48\n",
      "\n",
      "avg / total       0.81      0.75      0.71       150\n",
      "\n",
      "[82  0  1 17  1  1 18  0 30]\n",
      "LR Accuracy:  0.7533333333333333\n",
      "LR F1:  0.5566666666666666\n",
      "For name:  r_nunes\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0001-7425-5717': 28, '0000-0002-1377-9899': 13, '0000-0001-8633-4404': 3, '0000-0002-9014-0570': 2})\n",
      "['0000-0002-1377-9899', '0000-0001-7425-5717']\n",
      "Total sample size after apply threshold:  41\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 28)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 14)\n",
      "2\n",
      "(41, 42)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.46      0.55        13\n",
      "          1       0.78      0.89      0.83        28\n",
      "\n",
      "avg / total       0.74      0.76      0.74        41\n",
      "\n",
      "[ 6  7  3 25]\n",
      "MNB Accuracy:  0.7560975609756098\n",
      "MNB F1:  0.6893939393939394\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.69      0.75        13\n",
      "          1       0.87      0.93      0.90        28\n",
      "\n",
      "avg / total       0.85      0.85      0.85        41\n",
      "\n",
      "[ 9  4  2 26]\n",
      "svc Accuracy:  0.8536585365853658\n",
      "svc F1:  0.8232758620689655\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       0.80      1.00      0.89        28\n",
      "\n",
      "avg / total       0.86      0.83      0.81        41\n",
      "\n",
      "[ 6  7  0 28]\n",
      "LR Accuracy:  0.8292682926829268\n",
      "LR F1:  0.760233918128655\n",
      "For name:  s_huang\n",
      "total sample size before apply threshold:  441\n",
      "Counter({'0000-0002-0590-3474': 119, '0000-0002-3239-1072': 85, '0000-0001-5688-3410': 48, '0000-0001-9517-2515': 36, '0000-0001-8261-7079': 28, '0000-0001-6244-1555': 23, '0000-0001-8622-4838': 19, '0000-0003-4815-1863': 17, '0000-0001-7797-3626': 17, '0000-0003-2976-5798': 9, '0000-0002-2030-7574': 8, '0000-0003-1372-0480': 5, '0000-0001-5933-3115': 4, '0000-0002-8436-1991': 4, '0000-0003-1878-9348': 4, '0000-0003-1023-118X': 3, '0000-0001-9751-4523': 2, '0000-0003-4273-9682': 1, '0000-0001-7426-5181': 1, '0000-0002-8547-5309': 1, '0000-0002-1127-8898': 1, '0000-0002-6124-4178': 1, '0000-0002-7906-8467': 1, '0000-0002-8072-4388': 1, '0000-0002-4315-4494': 1, '0000-0003-3200-2206': 1, '0000-0003-3391-539X': 1})\n",
      "['0000-0001-8622-4838', '0000-0002-0590-3474', '0000-0001-5688-3410', '0000-0003-4815-1863', '0000-0001-7797-3626', '0000-0001-6244-1555', '0000-0002-3239-1072', '0000-0001-9517-2515', '0000-0001-8261-7079']\n",
      "Total sample size after apply threshold:  392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(392, 163)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(392, 20)\n",
      "2\n",
      "(392, 183)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        19\n",
      "          1       0.48      0.92      0.64       119\n",
      "          2       1.00      0.50      0.67        48\n",
      "          3       0.00      0.00      0.00        17\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.90      0.39      0.55        23\n",
      "          6       0.49      0.66      0.56        85\n",
      "          7       0.86      0.33      0.48        36\n",
      "          8       0.00      0.00      0.00        28\n",
      "\n",
      "avg / total       0.51      0.54      0.47       392\n",
      "\n",
      "[  0  13   0   0   1   0   5   0   0   0 110   0   0   0   0   9   0   0\n",
      "   0  10  24   0   0   0  14   0   0   0  14   0   0   0   1   2   0   0\n",
      "   0  10   0   0   0   0   5   2   0   0  10   0   0   0   9   4   0   0\n",
      "   0  28   0   0   1   0  56   0   0   0  11   0   0   0   0  13  12   0\n",
      "   0  21   0   0   0   0   7   0   0]\n",
      "MNB Accuracy:  0.5382653061224489\n",
      "MNB F1:  0.3208843736011366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.37      0.54        19\n",
      "          1       0.68      0.76      0.71       119\n",
      "          2       0.97      0.58      0.73        48\n",
      "          3       0.92      0.71      0.80        17\n",
      "          4       0.73      0.47      0.57        17\n",
      "          5       0.95      0.78      0.86        23\n",
      "          6       0.54      0.85      0.66        85\n",
      "          7       0.87      0.56      0.68        36\n",
      "          8       0.46      0.39      0.42        28\n",
      "\n",
      "avg / total       0.73      0.68      0.68       392\n",
      "\n",
      "[ 7  5  0  0  1  0  6  0  0  0 90  0  0  0  0 16  0 13  0  6 28  0  0  0\n",
      " 14  0  0  0  1  0 12  0  1  3  0  0  0  2  0  0  8  0  7  0  0  0  4  0\n",
      "  1  0 18  0  0  0  0  8  1  0  1  0 72  3  0  0  4  0  0  1  0 11 20  0\n",
      "  0 13  0  0  0  0  4  0 11]\n",
      "svc Accuracy:  0.6785714285714286\n",
      "svc F1:  0.6633538768976492\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.05      0.10        19\n",
      "          1       0.59      0.84      0.69       119\n",
      "          2       0.96      0.50      0.66        48\n",
      "          3       1.00      0.24      0.38        17\n",
      "          4       0.67      0.12      0.20        17\n",
      "          5       0.94      0.74      0.83        23\n",
      "          6       0.46      0.80      0.58        85\n",
      "          7       0.94      0.44      0.60        36\n",
      "          8       0.00      0.00      0.00        28\n",
      "\n",
      "avg / total       0.66      0.59      0.55       392\n",
      "\n",
      "[  1  10   0   0   0   0   8   0   0   0 100   0   0   0   0  14   0   5\n",
      "   0   5  24   0   0   0  19   0   0   0   8   0   4   0   1   4   0   0\n",
      "   0   7   0   0   2   0   8   0   0   0   4   0   0   0  17   2   0   0\n",
      "   0  14   1   0   1   0  68   1   0   0   4   0   0   0   0  16  16   0\n",
      "   0  18   0   0   0   0  10   0   0]\n",
      "LR Accuracy:  0.5918367346938775\n",
      "LR F1:  0.4494185120893602\n",
      "For name:  c_reid\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0002-1152-8551': 33, '0000-0003-2739-1585': 13, '0000-0001-8572-1162': 11, '0000-0001-5916-8172': 2, '0000-0001-8117-662X': 1})\n",
      "['0000-0001-8572-1162', '0000-0003-2739-1585', '0000-0002-1152-8551']\n",
      "Total sample size after apply threshold:  57\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 29)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 17)\n",
      "2\n",
      "(57, 46)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.91      0.83        11\n",
      "          1       0.91      0.77      0.83        13\n",
      "          2       0.88      0.88      0.88        33\n",
      "\n",
      "avg / total       0.86      0.86      0.86        57\n",
      "\n",
      "[10  0  1  0 10  3  3  1 29]\n",
      "MNB Accuracy:  0.8596491228070176\n",
      "MNB F1:  0.8484848484848485\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.64      0.74        11\n",
      "          1       0.79      0.85      0.81        13\n",
      "          2       0.86      0.91      0.88        33\n",
      "\n",
      "avg / total       0.84      0.84      0.84        57\n",
      "\n",
      "[ 7  1  3  0 11  2  1  2 30]\n",
      "svc Accuracy:  0.8421052631578947\n",
      "svc F1:  0.8113366204181478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.64      0.74        11\n",
      "          1       0.89      0.62      0.73        13\n",
      "          2       0.78      0.94      0.85        33\n",
      "\n",
      "avg / total       0.82      0.81      0.80        57\n",
      "\n",
      "[ 7  0  4  0  8  5  1  1 31]\n",
      "LR Accuracy:  0.8070175438596491\n",
      "LR F1:  0.771143300343012\n",
      "For name:  h_lu\n",
      "total sample size before apply threshold:  108\n",
      "Counter({'0000-0003-1720-6526': 20, '0000-0002-8340-2739': 19, '0000-0003-2180-3091': 17, '0000-0003-4025-3160': 9, '0000-0001-9732-0833': 6, '0000-0002-1440-9902': 6, '0000-0002-3940-3283': 5, '0000-0002-0017-4276': 5, '0000-0003-3604-7145': 5, '0000-0002-6708-0223': 5, '0000-0002-0349-2181': 4, '0000-0002-9090-258X': 3, '0000-0002-5177-3391': 2, '0000-0002-6881-660X': 1, '0000-0002-9443-4031': 1})\n",
      "['0000-0002-8340-2739', '0000-0003-1720-6526', '0000-0003-2180-3091']\n",
      "Total sample size after apply threshold:  56\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 25)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 11)\n",
      "2\n",
      "(56, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.58      0.56        19\n",
      "          1       0.48      0.60      0.53        20\n",
      "          2       0.64      0.41      0.50        17\n",
      "\n",
      "avg / total       0.55      0.54      0.53        56\n",
      "\n",
      "[11  6  2  6 12  2  3  7  7]\n",
      "MNB Accuracy:  0.5357142857142857\n",
      "MNB F1:  0.5324786324786325\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.53      0.53        19\n",
      "          1       0.59      0.50      0.54        20\n",
      "          2       0.50      0.59      0.54        17\n",
      "\n",
      "avg / total       0.54      0.54      0.54        56\n",
      "\n",
      "[10  3  6  6 10  4  3  4 10]\n",
      "svc Accuracy:  0.5357142857142857\n",
      "svc F1:  0.5357989568515884\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.58      0.56        19\n",
      "          1       0.45      0.50      0.48        20\n",
      "          2       0.50      0.41      0.45        17\n",
      "\n",
      "avg / total       0.50      0.50      0.50        56\n",
      "\n",
      "[11  5  3  6 10  4  3  7  7]\n",
      "LR Accuracy:  0.5\n",
      "LR F1:  0.4973019811729489\n",
      "For name:  j_cordeiro\n",
      "total sample size before apply threshold:  30\n",
      "Counter({'0000-0003-4656-6045': 14, '0000-0003-4605-1615': 9, '0000-0003-0902-9638': 5, '0000-0001-7876-0219': 1, '0000-0002-2118-1192': 1})\n",
      "['0000-0003-4656-6045']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  c_yu\n",
      "total sample size before apply threshold:  335\n",
      "Counter({'0000-0001-5664-9392': 252, '0000-0002-2136-2444': 26, '0000-0002-8648-8419': 16, '0000-0002-8453-5023': 11, '0000-0002-1742-2344': 10, '0000-0001-8062-9498': 6, '0000-0003-0084-6746': 5, '0000-0002-2934-2122': 3, '0000-0002-0635-3718': 2, '0000-0003-3712-5491': 2, '0000-0003-1555-8683': 1, '0000-0002-4304-2177': 1})\n",
      "['0000-0002-1742-2344', '0000-0001-5664-9392', '0000-0002-2136-2444', '0000-0002-8648-8419', '0000-0002-8453-5023']\n",
      "Total sample size after apply threshold:  315\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(315, 138)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(315, 21)\n",
      "2\n",
      "(315, 159)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.82      1.00      0.90       252\n",
      "          2       0.00      0.00      0.00        26\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.40      0.18      0.25        11\n",
      "\n",
      "avg / total       0.67      0.81      0.73       315\n",
      "\n",
      "[  0   9   0   0   1   0 252   0   0   0   0  24   0   0   2   0  16   0\n",
      "   0   0   0   6   3   0   2]\n",
      "MNB Accuracy:  0.8063492063492064\n",
      "MNB F1:  0.23032200357781757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.40      0.50        10\n",
      "          1       0.86      1.00      0.92       252\n",
      "          2       0.60      0.12      0.19        26\n",
      "          3       0.67      0.12      0.21        16\n",
      "          4       0.70      0.64      0.67        11\n",
      "\n",
      "avg / total       0.82      0.85      0.81       315\n",
      "\n",
      "[  4   3   2   0   1   0 251   0   1   0   2  19   3   0   2   0  14   0\n",
      "   2   0   0   4   0   0   7]\n",
      "svc Accuracy:  0.8476190476190476\n",
      "svc F1:  0.4990469847761446\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.81      1.00      0.89       252\n",
      "          2       0.00      0.00      0.00        26\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.64      0.80      0.71       315\n",
      "\n",
      "[  0  10   0   0   0   0 252   0   0   0   0  24   0   0   2   0  16   0\n",
      "   0   0   0  11   0   0   0]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.1784070796460177\n",
      "For name:  d_simpson\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0002-0500-9675': 11, '0000-0002-1189-0833': 11, '0000-0002-8105-2552': 2, '0000-0002-9768-7413': 2, '0000-0001-9538-3208': 1})\n",
      "['0000-0002-0500-9675', '0000-0002-1189-0833']\n",
      "Total sample size after apply threshold:  22\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 15)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 15)\n",
      "2\n",
      "(22, 30)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.73      0.64        11\n",
      "          1       0.62      0.45      0.53        11\n",
      "\n",
      "avg / total       0.60      0.59      0.58        22\n",
      "\n",
      "[8 3 6 5]\n",
      "MNB Accuracy:  0.5909090909090909\n",
      "MNB F1:  0.5831578947368421\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.64      0.70        11\n",
      "          1       0.69      0.82      0.75        11\n",
      "\n",
      "avg / total       0.74      0.73      0.73        22\n",
      "\n",
      "[7 4 2 9]\n",
      "svc Accuracy:  0.7272727272727273\n",
      "svc F1:  0.7250000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.64      0.67        11\n",
      "          1       0.67      0.73      0.70        11\n",
      "\n",
      "avg / total       0.68      0.68      0.68        22\n",
      "\n",
      "[7 4 3 8]\n",
      "LR Accuracy:  0.6818181818181818\n",
      "LR F1:  0.681159420289855\n",
      "For name:  c_pereira\n",
      "total sample size before apply threshold:  258\n",
      "Counter({'0000-0001-7874-1894': 55, '0000-0002-6630-5056': 31, '0000-0002-8392-9581': 29, '0000-0002-9724-1382': 26, '0000-0002-8167-6912': 25, '0000-0002-0804-9197': 14, '0000-0003-3421-8676': 11, '0000-0003-0093-771X': 9, '0000-0002-7133-0600': 8, '0000-0002-2146-1223': 8, '0000-0001-8050-5102': 7, '0000-0001-9224-1917': 7, '0000-0001-8111-1455': 6, '0000-0003-1389-9214': 5, '0000-0001-5514-4544': 4, '0000-0003-1788-4562': 4, '0000-0002-2899-9640': 3, '0000-0003-3406-3985': 3, '0000-0002-1805-7115': 2, '0000-0001-6153-7555': 1})\n",
      "['0000-0002-8167-6912', '0000-0001-7874-1894', '0000-0002-9724-1382', '0000-0002-8392-9581', '0000-0002-0804-9197', '0000-0003-3421-8676', '0000-0002-6630-5056']\n",
      "Total sample size after apply threshold:  191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 108)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 23)\n",
      "2\n",
      "(191, 131)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.40      0.48        25\n",
      "          1       0.50      0.87      0.64        55\n",
      "          2       0.47      0.31      0.37        26\n",
      "          3       0.62      0.69      0.66        29\n",
      "          4       1.00      0.21      0.35        14\n",
      "          5       1.00      0.36      0.53        11\n",
      "          6       0.59      0.42      0.49        31\n",
      "\n",
      "avg / total       0.61      0.55      0.53       191\n",
      "\n",
      "[10 11  2  2  0  0  0  2 48  1  3  0  0  1  1 13  8  1  0  0  3  1  6  1\n",
      " 20  0  0  1  1  1  3  2  3  0  4  0  4  0  3  0  4  0  2 13  2  1  0  0\n",
      " 13]\n",
      "MNB Accuracy:  0.5549738219895288\n",
      "MNB F1:  0.5023747630440096\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.48      0.56        25\n",
      "          1       0.54      0.80      0.64        55\n",
      "          2       0.38      0.38      0.38        26\n",
      "          3       0.95      0.62      0.75        29\n",
      "          4       1.00      0.50      0.67        14\n",
      "          5       0.75      0.55      0.63        11\n",
      "          6       0.58      0.58      0.58        31\n",
      "\n",
      "avg / total       0.65      0.60      0.60       191\n",
      "\n",
      "[12  7  3  0  0  1  2  2 44  4  0  0  1  4  3 10 10  0  0  0  3  1  7  2\n",
      " 18  0  0  1  0  1  3  0  7  0  3  0  3  1  1  0  6  0  0 10  3  0  0  0\n",
      " 18]\n",
      "svc Accuracy:  0.6020942408376964\n",
      "svc F1:  0.601997351606839\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.40      0.49        25\n",
      "          1       0.55      0.93      0.69        55\n",
      "          2       0.48      0.38      0.43        26\n",
      "          3       0.73      0.66      0.69        29\n",
      "          4       1.00      0.36      0.53        14\n",
      "          5       0.86      0.55      0.67        11\n",
      "          6       0.61      0.45      0.52        31\n",
      "\n",
      "avg / total       0.64      0.60      0.59       191\n",
      "\n",
      "[10  9  3  1  0  1  1  1 51  1  2  0  0  0  1 12 10  0  0  0  3  1  7  1\n",
      " 19  0  0  1  1  0  3  1  5  0  4  0  3  1  1  0  6  0  2 11  2  2  0  0\n",
      " 14]\n",
      "LR Accuracy:  0.6020942408376964\n",
      "LR F1:  0.5721337210999352\n",
      "For name:  h_wang\n",
      "total sample size before apply threshold:  848\n",
      "Counter({'0000-0002-0211-9000': 91, '0000-0003-0477-2908': 62, '0000-0002-5051-4929': 44, '0000-0002-7528-7494': 44, '0000-0002-9887-5555': 39, '0000-0001-5836-4120': 31, '0000-0002-8796-0367': 30, '0000-0002-7752-6217': 30, '0000-0003-1708-8734': 28, '0000-0002-6107-5095': 27, '0000-0001-8238-1641': 27, '0000-0003-4623-1878': 26, '0000-0001-9570-3611': 25, '0000-0001-9199-0721': 25, '0000-0002-7959-7377': 24, '0000-0003-2420-3147': 23, '0000-0002-8066-475X': 19, '0000-0003-1625-3400': 18, '0000-0002-1483-5135': 17, '0000-0001-6590-7736': 15, '0000-0002-9634-8778': 15, '0000-0001-7964-0809': 14, '0000-0001-6507-5503': 13, '0000-0003-4107-2062': 11, '0000-0002-3355-2448': 11, '0000-0002-6567-9144': 10, '0000-0003-4414-3372': 10, '0000-0002-6859-5683': 9, '0000-0002-2565-5543': 8, '0000-0003-0388-510X': 7, '0000-0003-1086-5318': 7, '0000-0002-4858-8195': 5, '0000-0002-2325-0120': 5, '0000-0003-4453-8059': 5, '0000-0001-9243-3935': 5, '0000-0002-9567-8249': 4, '0000-0003-4957-0509': 4, '0000-0002-0769-600X': 4, '0000-0002-1994-4402': 4, '0000-0002-3857-5737': 4, '0000-0001-7988-6120': 3, '0000-0002-0600-2555': 3, '0000-0003-1688-7948': 3, '0000-0001-9530-6587': 3, '0000-0002-9863-0144': 3, '0000-0002-9216-9342': 3, '0000-0002-6938-9507': 3, '0000-0001-9107-6120': 3, '0000-0003-4791-7994': 2, '0000-0001-6529-5629': 2, '0000-0001-5623-1148': 2, '0000-0002-5696-156X': 1, '0000-0002-8415-9793': 1, '0000-0002-3221-2820': 1, '0000-0001-6192-853X': 1, '0000-0002-7167-2483': 1, '0000-0002-0173-0545': 1, '0000-0001-8556-3504': 1, '0000-0001-7815-610X': 1, '0000-0002-7775-3268': 1, '0000-0002-3394-1531': 1, '0000-0002-9100-321X': 1, '0000-0001-9900-8528': 1, '0000-0002-8465-0996': 1, '0000-0001-5228-9270': 1, '0000-0001-9355-1319': 1, '0000-0002-2367-5591': 1, '0000-0001-5388-6691': 1, '0000-0002-2516-6774': 1})\n",
      "['0000-0002-0211-9000', '0000-0001-7964-0809', '0000-0003-2420-3147', '0000-0001-9570-3611', '0000-0001-9199-0721', '0000-0002-8066-475X', '0000-0002-8796-0367', '0000-0003-4107-2062', '0000-0002-3355-2448', '0000-0001-6590-7736', '0000-0002-6567-9144', '0000-0001-5836-4120', '0000-0002-7959-7377', '0000-0003-4623-1878', '0000-0003-1625-3400', '0000-0002-7752-6217', '0000-0003-4414-3372', '0000-0001-6507-5503', '0000-0003-0477-2908', '0000-0002-6107-5095', '0000-0003-1708-8734', '0000-0002-1483-5135', '0000-0002-9887-5555', '0000-0002-5051-4929', '0000-0002-9634-8778', '0000-0002-7528-7494', '0000-0001-8238-1641']\n",
      "Total sample size after apply threshold:  729\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(729, 342)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(729, 23)\n",
      "2\n",
      "(729, 365)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.76      0.31        91\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       1.00      0.17      0.30        23\n",
      "          3       0.20      0.04      0.07        25\n",
      "          4       0.00      0.00      0.00        25\n",
      "          5       0.00      0.00      0.00        19\n",
      "          6       0.25      0.07      0.11        30\n",
      "          7       0.00      0.00      0.00        11\n",
      "          8       0.00      0.00      0.00        11\n",
      "          9       1.00      0.67      0.80        15\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       0.60      0.10      0.17        31\n",
      "         12       0.89      0.33      0.48        24\n",
      "         13       0.00      0.00      0.00        26\n",
      "         14       0.00      0.00      0.00        18\n",
      "         15       1.00      0.20      0.33        30\n",
      "         16       0.00      0.00      0.00        10\n",
      "         17       1.00      0.08      0.14        13\n",
      "         18       0.22      0.73      0.34        62\n",
      "         19       0.86      0.22      0.35        27\n",
      "         20       0.00      0.00      0.00        28\n",
      "         21       1.00      0.06      0.11        17\n",
      "         22       0.27      0.31      0.29        39\n",
      "         23       0.27      0.16      0.20        44\n",
      "         24       0.00      0.00      0.00        15\n",
      "         25       0.45      0.23      0.30        44\n",
      "         26       0.80      0.44      0.57        27\n",
      "\n",
      "avg / total       0.37      0.27      0.22       729\n",
      "\n",
      "[69  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 19  0  0  0  0  2\n",
      "  0  0  0  6  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "  0  3  1  0  1  1 10  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  7  0  0  0  1  0  0  1  0 14  0  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  8  0  0  0  0  2  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  7  0  0  0  0  2  0  3  0  4  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  5  1  0  0  7  0  0  2  0  6  0  0  0  0  0\n",
      "  2  0  0  0  0  0  0  0  0  0  0  0  6  0  0  0 15  1  0  0  0  4  0  0\n",
      "  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  4  0  0  0  1  0  0  0  0\n",
      "  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  2\n",
      "  0  0  0  4  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  4  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  3  0  0  0\n",
      "  0  0  0  8  0  0  0  0  0  0  1  0  9  0  0  0  0  0  0  0  0  0  0  0\n",
      "  8  0  0  0  0  0  5  0  0  0  0  2  0  0  0 18  0  0  0  0  0  0  0  0\n",
      "  0  0  0  1  0  0  0  0  0  7  0  0  0  0  0  0  0  0 13  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  1  0  0  0  0 19  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0  4  0  0  0  0  0  0  1  0\n",
      "  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0\n",
      "  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  2  0  0\n",
      "  0  1  0  0  0  1 13  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 45  0  0  0  0  2  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  9  6  0  0  2  1  0  1  0 21  0  0  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  5  0  0  0  0  1  0  0  0  7  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  7  0  0  1  0  1  0  1  0 12  0  0  0  0  1\n",
      "  4  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0 12  0  0  1  1 27  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  7  0  0  0\n",
      "  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0\n",
      "  0  0  0 18  0  0  1  1  0  0  0  0  0  0  1  0  0  0  0  0  0 11  0  0\n",
      "  0  0  2  0 10  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  4  0  0  0  2  0  0  0 12]\n",
      "MNB Accuracy:  0.27023319615912206\n",
      "MNB F1:  0.18019524304775164\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.24      0.73      0.36        91\n",
      "          1       0.50      0.14      0.22        14\n",
      "          2       0.53      0.35      0.42        23\n",
      "          3       0.33      0.32      0.33        25\n",
      "          4       1.00      0.48      0.65        25\n",
      "          5       0.45      0.26      0.33        19\n",
      "          6       0.42      0.27      0.33        30\n",
      "          7       0.50      0.45      0.48        11\n",
      "          8       1.00      0.36      0.53        11\n",
      "          9       1.00      0.87      0.93        15\n",
      "         10       1.00      0.30      0.46        10\n",
      "         11       0.64      0.45      0.53        31\n",
      "         12       1.00      0.54      0.70        24\n",
      "         13       0.71      0.19      0.30        26\n",
      "         14       0.56      0.28      0.37        18\n",
      "         15       0.89      0.57      0.69        30\n",
      "         16       0.50      0.20      0.29        10\n",
      "         17       0.67      0.62      0.64        13\n",
      "         18       0.98      0.68      0.80        62\n",
      "         19       0.68      0.48      0.57        27\n",
      "         20       0.46      0.21      0.29        28\n",
      "         21       0.67      0.59      0.62        17\n",
      "         22       0.23      0.28      0.26        39\n",
      "         23       0.42      0.41      0.41        44\n",
      "         24       0.57      0.27      0.36        15\n",
      "         25       0.38      0.36      0.37        44\n",
      "         26       0.72      0.67      0.69        27\n",
      "\n",
      "avg / total       0.58      0.46      0.48       729\n",
      "\n",
      "[66  0  2  2  0  0  0  0  0  0  0  2  0  1  0  1  0  0  0  0  4  1  1  6\n",
      "  1  4  0  4  2  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  6  0  0  0  1  8  0  8  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  1  0  0  2  1  1  1  0 10  0  0  8  0  1  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  0  1  0  0  3  0  1  0 10  0  0  0 12  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  3  1  1  1  0  5  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  2  0  0  5  0  0  1  0  4  0  1  1  0  0\n",
      "  8  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 13  1  0  1  0  0  0  0\n",
      "  0  0  0  1  5  0  0  0  0  0  0  3  0  0  0  0  0  0  0  1  0  0  0  1\n",
      "  3  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  3  0  1\n",
      "  0  0  0  1  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  1  0  5  0  1  0  0  0  0  0  0  0  3  0  0  0  0  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0 12  0  0  1  0  0  0  0  0  0  0 14  0  0  0\n",
      "  0  1  0  0  0  0  0  0  0  0  3  0  8  0  0  0  0  0  0  0  0  0  0  1\n",
      " 13  0  0  0  0  0  0  0  0  0  0  1  0  1  0 17  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  5  0  0  1  0  0  0  1  0  0  1  0  1  0  6  0  0  0  0  0\n",
      "  0  5  0  0  0  0  0  0  5  0  0  0  0  0  0  0  2  0  0  0  0 11  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0  1  1  0  0  0\n",
      "  4  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  2  0  0  0  0  0  0  0\n",
      "  0  1  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0\n",
      "  0  0  0  0  0  3 13  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 42  0  0  1  0  2  0  2  0  5  0  0  1  0  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 13  0  0  3  1  0  3  0 16  0  0  3  0  0  0  0  0  0  0  0\n",
      "  0  1  0  0  0  0  0  0  6  0  0  0  1  1  0  5  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  1  0 10  0  1  0  0  0  7  1  1  0  0  4\n",
      "  9  0  0  0  0  0  0  0  0  0  0  1  0  2  0  0 11  1  0  0  2 21  0  1\n",
      "  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  1  0\n",
      "  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  2\n",
      "  4  1  0 22  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0\n",
      "  0  0  3  0 16  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3\n",
      "  0  0  0  0  2  0  0  0 18]\n",
      "svc Accuracy:  0.4609053497942387\n",
      "svc F1:  0.47941248701569417\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.24      0.82      0.37        91\n",
      "          1       0.67      0.14      0.24        14\n",
      "          2       0.54      0.30      0.39        23\n",
      "          3       0.26      0.20      0.23        25\n",
      "          4       0.85      0.44      0.58        25\n",
      "          5       0.62      0.26      0.37        19\n",
      "          6       0.35      0.20      0.26        30\n",
      "          7       0.56      0.45      0.50        11\n",
      "          8       1.00      0.27      0.43        11\n",
      "          9       1.00      0.87      0.93        15\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       0.63      0.39      0.48        31\n",
      "         12       0.86      0.50      0.63        24\n",
      "         13       1.00      0.12      0.21        26\n",
      "         14       0.40      0.11      0.17        18\n",
      "         15       0.94      0.53      0.68        30\n",
      "         16       0.00      0.00      0.00        10\n",
      "         17       0.60      0.46      0.52        13\n",
      "         18       0.81      0.68      0.74        62\n",
      "         19       0.60      0.33      0.43        27\n",
      "         20       0.25      0.04      0.06        28\n",
      "         21       0.71      0.59      0.65        17\n",
      "         22       0.31      0.31      0.31        39\n",
      "         23       0.31      0.41      0.35        44\n",
      "         24       0.00      0.00      0.00        15\n",
      "         25       0.34      0.34      0.34        44\n",
      "         26       0.65      0.56      0.60        27\n",
      "\n",
      "avg / total       0.52      0.42      0.41       729\n",
      "\n",
      "[75  0  2  2  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  1  0  6\n",
      "  0  3  0  5  2  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  4  1  0  0  1 12  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  1  1  0  0  0  1  0  1  0 13  0  0  5  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  0  1  0  0  4  0  1  0  9  0  0  0 11  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  2  0  3  0  3  1  0  1  0  5  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  4  0  0  4  0  0  1  0  8  0  1  0  0  0\n",
      "  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  1  0  1  0  1  0  0\n",
      "  0  0  0  1  5  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "  3  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  3  0  2\n",
      "  0  0  0  1  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  1  0  5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "  1  0  0  0  0  2  0  0  0 12  0  0  1  0  0  0  0  0  0  0 12  0  0  0\n",
      "  0  2  0  0  0  0  0  0  1  0  3  0  6  0  0  0  0  0  0  0  0  0  0  1\n",
      " 12  0  0  0  0  0  1  0  0  0  0  2  0  2  0 17  0  0  0  0  0  0  0  0\n",
      "  0  0  0  1  3  0  0  0  0  1  0  0  0  0  2  0  2  0 10  0  0  0  0  0\n",
      "  0  4  0  0  0  0  0  0  2  0  0  0  0  0  0  0  1  0  0  0  1 11  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  2  0  1  0\n",
      "  6  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  1  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0  0\n",
      "  0  0  0  0  0  3 14  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 42  0  0  0  0  2  0  2  0  8  0  0  1  0  0  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  1  9  0  0  3  1  0  3  0 22  0  0  3  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  1  0  0  1  0  1  0  5  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 10  1  1  0  0  0  8  0  1  0  0  3\n",
      "  8  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 12  3  0  1  2 21  0  1\n",
      "  3  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0 18  0  0  0\n",
      " 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  2\n",
      "  0  2  0 17  0  0  1  2  0  0  0  0  0  0  1  0  0  0  0  0  0  5  0  0\n",
      "  0  0  3  0 15  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4\n",
      "  0  0  0  0  1  1  0  0 15]\n",
      "LR Accuracy:  0.41838134430727025\n",
      "LR F1:  0.38722370560993463\n",
      "For name:  a_tan\n",
      "total sample size before apply threshold:  200\n",
      "Counter({'0000-0003-2955-8369': 97, '0000-0002-9158-7243': 60, '0000-0001-5313-8650': 18, '0000-0002-9225-0247': 18, '0000-0002-8484-7107': 3, '0000-0003-2902-4025': 3, '0000-0001-6459-6171': 1})\n",
      "['0000-0002-9158-7243', '0000-0001-5313-8650', '0000-0003-2955-8369', '0000-0002-9225-0247']\n",
      "Total sample size after apply threshold:  193\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(193, 89)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(193, 17)\n",
      "2\n",
      "(193, 106)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.80      0.81        60\n",
      "          1       1.00      0.44      0.62        18\n",
      "          2       0.73      0.93      0.81        97\n",
      "          3       1.00      0.17      0.29        18\n",
      "\n",
      "avg / total       0.81      0.77      0.75       193\n",
      "\n",
      "[48  0 12  0  3  8  7  0  7  0 90  0  0  0 15  3]\n",
      "MNB Accuracy:  0.772020725388601\n",
      "MNB F1:  0.6322844652854622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.83      0.89        60\n",
      "          1       1.00      0.89      0.94        18\n",
      "          2       0.82      0.98      0.89        97\n",
      "          3       1.00      0.50      0.67        18\n",
      "\n",
      "avg / total       0.90      0.88      0.88       193\n",
      "\n",
      "[50  0 10  0  0 16  2  0  2  0 95  0  0  0  9  9]\n",
      "svc Accuracy:  0.8808290155440415\n",
      "svc F1:  0.848179764863692\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.77      0.86        60\n",
      "          1       1.00      0.56      0.71        18\n",
      "          2       0.72      0.99      0.83        97\n",
      "          3       1.00      0.17      0.29        18\n",
      "\n",
      "avg / total       0.85      0.80      0.78       193\n",
      "\n",
      "[46  0 14  0  0 10  8  0  1  0 96  0  0  0 15  3]\n",
      "LR Accuracy:  0.8031088082901554\n",
      "LR F1:  0.6736489232019504\n",
      "For name:  m_aguilar\n",
      "total sample size before apply threshold:  108\n",
      "Counter({'0000-0002-1935-6619': 59, '0000-0001-7395-5754': 18, '0000-0002-2586-859X': 14, '0000-0002-8084-6991': 8, '0000-0002-5150-1871': 8, '0000-0002-9953-7400': 1})\n",
      "['0000-0002-1935-6619', '0000-0001-7395-5754', '0000-0002-2586-859X']\n",
      "Total sample size after apply threshold:  91\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 41)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 19)\n",
      "2\n",
      "(91, 60)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.93      0.87        59\n",
      "          1       0.64      0.50      0.56        18\n",
      "          2       1.00      0.64      0.78        14\n",
      "\n",
      "avg / total       0.81      0.80      0.79        91\n",
      "\n",
      "[55  4  0  9  9  0  4  1  9]\n",
      "MNB Accuracy:  0.8021978021978022\n",
      "MNB F1:  0.7370834759785462\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.95      0.90        59\n",
      "          1       0.71      0.56      0.63        18\n",
      "          2       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.85      0.85      0.84        91\n",
      "\n",
      "[56  3  0  8 10  0  2  1 11]\n",
      "svc Accuracy:  0.8461538461538461\n",
      "svc F1:  0.8003333333333335\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        59\n",
      "          1       1.00      0.33      0.50        18\n",
      "          2       1.00      0.57      0.73        14\n",
      "\n",
      "avg / total       0.85      0.80      0.77        91\n",
      "\n",
      "[59  0  0 12  6  0  6  0  8]\n",
      "LR Accuracy:  0.8021978021978022\n",
      "LR F1:  0.6983065953654188\n",
      "For name:  a_bianchi\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-1082-3911': 38, '0000-0001-6583-1671': 23, '0000-0001-9340-6971': 8, '0000-0002-4571-0511': 2, '0000-0003-4925-5269': 2})\n",
      "['0000-0001-6583-1671', '0000-0002-1082-3911']\n",
      "Total sample size after apply threshold:  61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 19)\n",
      "2\n",
      "(61, 41)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.83      0.88        23\n",
      "          1       0.90      0.97      0.94        38\n",
      "\n",
      "avg / total       0.92      0.92      0.92        61\n",
      "\n",
      "[19  4  1 37]\n",
      "MNB Accuracy:  0.9180327868852459\n",
      "MNB F1:  0.9102148954960261\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.91      0.93        23\n",
      "          1       0.95      0.97      0.96        38\n",
      "\n",
      "avg / total       0.95      0.95      0.95        61\n",
      "\n",
      "[21  2  1 37]\n",
      "svc Accuracy:  0.9508196721311475\n",
      "svc F1:  0.9471861471861471\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        23\n",
      "          1       0.88      1.00      0.94        38\n",
      "\n",
      "avg / total       0.93      0.92      0.92        61\n",
      "\n",
      "[18  5  0 38]\n",
      "LR Accuracy:  0.9180327868852459\n",
      "LR F1:  0.9081601927130383\n",
      "For name:  p_rossi\n",
      "total sample size before apply threshold:  200\n",
      "Counter({'0000-0003-2620-7918': 116, '0000-0003-4796-327X': 39, '0000-0002-6316-338X': 36, '0000-0002-3995-8836': 8, '0000-0002-6472-3588': 1})\n",
      "['0000-0002-6316-338X', '0000-0003-2620-7918', '0000-0003-4796-327X']\n",
      "Total sample size after apply threshold:  191\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 99)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 34)\n",
      "2\n",
      "(191, 133)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.83      0.81        36\n",
      "          1       0.77      0.90      0.83       116\n",
      "          2       0.67      0.31      0.42        39\n",
      "\n",
      "avg / total       0.75      0.76      0.74       191\n",
      "\n",
      "[ 30   6   0   6 104   6   2  25  12]\n",
      "MNB Accuracy:  0.7643979057591623\n",
      "MNB F1:  0.6868495671179673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        36\n",
      "          1       0.81      0.94      0.87       116\n",
      "          2       0.70      0.41      0.52        39\n",
      "\n",
      "avg / total       0.82      0.83      0.81       191\n",
      "\n",
      "[ 33   3   0   0 109   7   0  23  16]\n",
      "svc Accuracy:  0.8272251308900523\n",
      "svc F1:  0.7803922226009474\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        36\n",
      "          1       0.74      0.98      0.84       116\n",
      "          2       0.62      0.13      0.21        39\n",
      "\n",
      "avg / total       0.76      0.77      0.72       191\n",
      "\n",
      "[ 28   7   1   0 114   2   0  34   5]\n",
      "LR Accuracy:  0.7696335078534031\n",
      "LR F1:  0.6430314569103138\n",
      "For name:  y_yang\n",
      "total sample size before apply threshold:  665\n",
      "Counter({'0000-0002-8633-0873': 115, '0000-0002-6266-9864': 97, '0000-0003-1391-8040': 73, '0000-0001-8839-8161': 50, '0000-0002-6782-2813': 43, '0000-0001-7896-1184': 39, '0000-0002-3598-7218': 35, '0000-0003-4275-0515': 26, '0000-0002-0007-6481': 16, '0000-0003-3711-2842': 12, '0000-0003-0195-9478': 11, '0000-0001-8572-5155': 10, '0000-0001-8971-4648': 8, '0000-0003-2442-3713': 8, '0000-0002-0491-8295': 8, '0000-0002-7540-3301': 8, '0000-0002-2767-9354': 8, '0000-0002-5982-1706': 8, '0000-0001-7139-1254': 6, '0000-0001-6417-3654': 6, '0000-0001-5769-1795': 6, '0000-0003-0298-8641': 5, '0000-0002-5599-0975': 5, '0000-0002-1707-0633': 5, '0000-0003-1536-343X': 4, '0000-0002-8514-8228': 4, '0000-0001-9306-3227': 3, '0000-0002-5033-6210': 3, '0000-0003-3428-1587': 3, '0000-0002-7856-2009': 3, '0000-0002-5808-0109': 3, '0000-0002-8565-6214': 3, '0000-0002-1837-3628': 3, '0000-0002-6976-7416': 2, '0000-0002-3487-8730': 2, '0000-0001-8274-6196': 2, '0000-0002-2222-0202': 2, '0000-0002-7653-0601': 2, '0000-0003-0576-6032': 2, '0000-0003-1599-635X': 2, '0000-0002-6306-1324': 1, '0000-0001-9436-964X': 1, '0000-0001-5796-7990': 1, '0000-0002-3519-5472': 1, '0000-0002-8404-8305': 1, '0000-0002-7982-7988': 1, '0000-0003-2902-3989': 1, '0000-0001-5726-9420': 1, '0000-0002-0100-1078': 1, '0000-0002-1105-3824': 1, '0000-0002-6891-0655': 1, '0000-0002-1080-5086': 1, '0000-0003-4505-8954': 1, '0000-0002-1416-4925': 1})\n",
      "['0000-0001-8572-5155', '0000-0002-0007-6481', '0000-0002-3598-7218', '0000-0002-6782-2813', '0000-0003-0195-9478', '0000-0002-6266-9864', '0000-0001-7896-1184', '0000-0003-3711-2842', '0000-0002-8633-0873', '0000-0003-1391-8040', '0000-0001-8839-8161', '0000-0003-4275-0515']\n",
      "Total sample size after apply threshold:  527\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(527, 248)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(527, 23)\n",
      "2\n",
      "(527, 271)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.00      0.00      0.00        16\n",
      "          2       1.00      0.23      0.37        35\n",
      "          3       0.63      0.44      0.52        43\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       0.39      0.59      0.47        97\n",
      "          6       0.50      0.03      0.05        39\n",
      "          7       0.00      0.00      0.00        12\n",
      "          8       0.53      0.88      0.66       115\n",
      "          9       0.31      0.45      0.37        73\n",
      "         10       0.58      0.50      0.54        50\n",
      "         11       0.00      0.00      0.00        26\n",
      "\n",
      "avg / total       0.44      0.46      0.40       527\n",
      "\n",
      "[  0   0   0   0   0   0   0   0   1   8   1   0   0   0   0   4   0   4\n",
      "   0   0   2   4   2   0   0   0   8   1   0  13   0   0   7   5   1   0\n",
      "   0   0   0  19   0  10   0   0   5   6   3   0   0   0   0   0   0   2\n",
      "   0   0   5   4   0   0   0   0   0   2   0  57   0   0  24  11   3   0\n",
      "   0   0   0   2   0  16   1   0   9   7   3   1   0   0   0   0   0   3\n",
      "   0   0   3   4   2   0   0   0   0   0   0   8   0   0 101   6   0   0\n",
      "   0   0   0   0   0  18   0   0  19  33   3   0   0   0   0   0   0  11\n",
      "   0   0   5   9  25   0   0   0   0   2   0   6   1   0   9   8   0   0]\n",
      "MNB Accuracy:  0.4629981024667932\n",
      "MNB F1:  0.2481202988448706\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.40      0.42        10\n",
      "          1       0.75      0.38      0.50        16\n",
      "          2       0.79      0.43      0.56        35\n",
      "          3       0.68      0.53      0.60        43\n",
      "          4       1.00      0.64      0.78        11\n",
      "          5       0.44      0.73      0.55        97\n",
      "          6       0.50      0.21      0.29        39\n",
      "          7       0.25      0.17      0.20        12\n",
      "          8       0.83      0.79      0.81       115\n",
      "          9       0.41      0.60      0.49        73\n",
      "         10       0.85      0.56      0.67        50\n",
      "         11       0.75      0.46      0.57        26\n",
      "\n",
      "avg / total       0.64      0.59      0.59       527\n",
      "\n",
      "[ 4  0  0  0  0  1  0  5  0  0  0  0  0  6  0  4  0  3  0  0  0  3  0  0\n",
      "  0  0 15  1  0 10  0  0  2  7  0  0  0  1  0 23  0  9  3  0  0  6  0  1\n",
      "  0  0  0  0  7  2  0  0  0  2  0  0  0  0  3  2  0 71  0  0  7 14  0  0\n",
      "  0  0  0  3  0  9  8  1  3  9  4  2  5  0  0  0  0  2  0  2  0  1  1  1\n",
      "  0  0  1  0  0 12  0  0 91 11  0  0  0  0  0  0  0 22  0  0  7 44  0  0\n",
      "  0  1  0  0  0 12  4  0  0  5 28  0  0  0  0  1  0  7  1  0  0  5  0 12]\n",
      "svc Accuracy:  0.5901328273244781\n",
      "svc F1:  0.5365943317075348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.30      0.35        10\n",
      "          1       0.00      0.00      0.00        16\n",
      "          2       0.93      0.37      0.53        35\n",
      "          3       0.68      0.49      0.57        43\n",
      "          4       1.00      0.18      0.31        11\n",
      "          5       0.40      0.67      0.50        97\n",
      "          6       0.43      0.15      0.23        39\n",
      "          7       0.00      0.00      0.00        12\n",
      "          8       0.73      0.83      0.78       115\n",
      "          9       0.37      0.52      0.43        73\n",
      "         10       0.55      0.48      0.51        50\n",
      "         11       0.75      0.35      0.47        26\n",
      "\n",
      "avg / total       0.55      0.52      0.50       527\n",
      "\n",
      "[ 3  0  0  0  0  0  0  6  1  0  0  0  0  0  0  4  0  6  0  0  0  4  2  0\n",
      "  0  0 13  1  0 12  1  0  2  5  1  0  0  1  0 21  0  7  2  0  2  6  3  1\n",
      "  0  0  0  0  2  4  0  0  1  4  0  0  0  0  1  1  0 65  0  0 12 14  4  0\n",
      "  0  0  0  3  0 12  6  0  5  7  5  1  4  0  0  0  0  2  0  0  0  3  2  1\n",
      "  0  0  0  0  0 13  0  0 95  7  0  0  0  0  0  0  0 22  0  0 10 38  3  0\n",
      "  0  0  0  0  0 10  4  0  1 11 24  0  0  0  0  1  0  9  1  0  1  5  0  9]\n",
      "LR Accuracy:  0.523719165085389\n",
      "LR F1:  0.38969751137102354\n",
      "For name:  s_hsieh\n",
      "total sample size before apply threshold:  166\n",
      "Counter({'0000-0002-3188-8482': 88, '0000-0002-1879-4086': 65, '0000-0002-2716-4609': 9, '0000-0002-8475-7486': 3, '0000-0001-7617-8559': 1})\n",
      "['0000-0002-3188-8482', '0000-0002-1879-4086']\n",
      "Total sample size after apply threshold:  153\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(153, 81)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(153, 23)\n",
      "2\n",
      "(153, 104)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.81      0.84        88\n",
      "          1       0.76      0.83      0.79        65\n",
      "\n",
      "avg / total       0.82      0.82      0.82       153\n",
      "\n",
      "[71 17 11 54]\n",
      "MNB Accuracy:  0.8169934640522876\n",
      "MNB F1:  0.8147058823529412\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.92      0.87        88\n",
      "          1       0.87      0.72      0.79        65\n",
      "\n",
      "avg / total       0.84      0.84      0.83       153\n",
      "\n",
      "[81  7 18 47]\n",
      "svc Accuracy:  0.8366013071895425\n",
      "svc F1:  0.8281130634071809\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.91      0.85        88\n",
      "          1       0.85      0.68      0.75        65\n",
      "\n",
      "avg / total       0.82      0.81      0.81       153\n",
      "\n",
      "[80  8 21 44]\n",
      "LR Accuracy:  0.8104575163398693\n",
      "LR F1:  0.7993487993487993\n",
      "For name:  c_baptista\n",
      "total sample size before apply threshold:  19\n",
      "Counter({'0000-0002-1263-7880': 7, '0000-0002-8158-4743': 7, '0000-0003-4664-6766': 2, '0000-0002-7807-0995': 2, '0000-0002-9966-0708': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_kavanagh\n",
      "total sample size before apply threshold:  178\n",
      "Counter({'0000-0001-9072-8828': 113, '0000-0003-4718-0072': 58, '0000-0003-1531-6617': 4, '0000-0003-2854-7270': 3})\n",
      "['0000-0003-4718-0072', '0000-0001-9072-8828']\n",
      "Total sample size after apply threshold:  171\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(171, 87)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(171, 23)\n",
      "2\n",
      "(171, 110)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.52      0.61        58\n",
      "          1       0.78      0.90      0.84       113\n",
      "\n",
      "avg / total       0.77      0.77      0.76       171\n",
      "\n",
      "[ 30  28  11 102]\n",
      "MNB Accuracy:  0.7719298245614035\n",
      "MNB F1:  0.722783389450056\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.52      0.65        58\n",
      "          1       0.79      0.96      0.87       113\n",
      "\n",
      "avg / total       0.82      0.81      0.79       171\n",
      "\n",
      "[ 30  28   5 108]\n",
      "svc Accuracy:  0.8070175438596491\n",
      "svc F1:  0.7563155849203265\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.45      0.60        58\n",
      "          1       0.77      0.97      0.86       113\n",
      "\n",
      "avg / total       0.82      0.80      0.77       171\n",
      "\n",
      "[ 26  32   3 110]\n",
      "LR Accuracy:  0.7953216374269005\n",
      "LR F1:  0.7302231237322515\n",
      "For name:  l_wang\n",
      "total sample size before apply threshold:  828\n",
      "Counter({'0000-0001-9783-4383': 98, '0000-0003-3870-3388': 64, '0000-0002-5947-306X': 63, '0000-0002-5773-1627': 56, '0000-0002-5859-2526': 53, '0000-0002-5126-1046': 48, '0000-0002-4344-8791': 40, '0000-0001-8927-6772': 31, '0000-0001-5813-9505': 31, '0000-0002-1709-9401': 30, '0000-0003-3463-0740': 27, '0000-0003-1382-9195': 25, '0000-0003-3075-6872': 22, '0000-0001-9556-2361': 19, '0000-0002-4809-3109': 17, '0000-0002-1919-9107': 17, '0000-0002-4747-0419': 17, '0000-0002-6156-9028': 16, '0000-0001-7302-4714': 15, '0000-0001-7124-2718': 14, '0000-0001-8412-2985': 9, '0000-0002-8208-7079': 7, '0000-0003-4276-0051': 7, '0000-0002-4165-4022': 6, '0000-0002-7300-9271': 6, '0000-0002-0933-2808': 5, '0000-0001-9355-1167': 5, '0000-0002-4930-8618': 5, '0000-0001-7383-934X': 5, '0000-0001-7324-2682': 5, '0000-0003-1117-1326': 5, '0000-0002-7579-0233': 5, '0000-0002-2753-0947': 4, '0000-0002-1869-9871': 4, '0000-0002-0543-5519': 4, '0000-0002-5371-2138': 4, '0000-0001-5601-7539': 3, '0000-0003-0881-9689': 3, '0000-0001-6223-5962': 3, '0000-0003-0968-1247': 3, '0000-0001-8752-6635': 3, '0000-0001-8905-3456': 2, '0000-0001-6222-7807': 2, '0000-0002-1835-7601': 2, '0000-0001-5038-694X': 2, '0000-0002-2448-8149': 2, '0000-0001-8573-1213': 2, '0000-0003-2746-8992': 1, '0000-0001-7309-4325': 1, '0000-0002-8151-5182': 1, '0000-0002-9062-6183': 1, '0000-0002-5678-2369': 1, '0000-0001-5646-9746': 1, '0000-0001-7587-8924': 1, '0000-0002-0350-8534': 1, '0000-0002-8673-5221': 1, '0000-0003-2766-0845': 1, '0000-0002-5534-5466': 1, '0000-0002-9760-7436': 1})\n",
      "['0000-0002-6156-9028', '0000-0003-3463-0740', '0000-0001-9556-2361', '0000-0001-7302-4714', '0000-0002-4809-3109', '0000-0003-3075-6872', '0000-0002-1919-9107', '0000-0002-4344-8791', '0000-0002-5859-2526', '0000-0003-3870-3388', '0000-0003-1382-9195', '0000-0001-8927-6772', '0000-0002-5773-1627', '0000-0001-9783-4383', '0000-0002-4747-0419', '0000-0001-7124-2718', '0000-0002-1709-9401', '0000-0002-5947-306X', '0000-0001-5813-9505', '0000-0002-5126-1046']\n",
      "Total sample size after apply threshold:  703\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(703, 269)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(703, 21)\n",
      "2\n",
      "(703, 290)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.00      0.00      0.00        27\n",
      "          2       1.00      0.11      0.19        19\n",
      "          3       0.00      0.00      0.00        15\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       1.00      0.05      0.09        22\n",
      "          6       0.00      0.00      0.00        17\n",
      "          7       1.00      0.60      0.75        40\n",
      "          8       0.38      0.28      0.33        53\n",
      "          9       0.50      0.58      0.54        64\n",
      "         10       0.75      0.12      0.21        25\n",
      "         11       1.00      0.35      0.52        31\n",
      "         12       0.43      0.39      0.41        56\n",
      "         13       0.29      0.85      0.43        98\n",
      "         14       0.00      0.00      0.00        17\n",
      "         15       0.00      0.00      0.00        14\n",
      "         16       0.83      0.17      0.28        30\n",
      "         17       0.30      0.63      0.41        63\n",
      "         18       0.75      0.19      0.31        31\n",
      "         19       0.66      0.81      0.73        48\n",
      "\n",
      "avg / total       0.48      0.41      0.36       703\n",
      "\n",
      "[ 0  0  0  0  0  0  0  0  0  4  0  0  0  7  0  0  0  4  0  1  0  0  0  0\n",
      "  0  0  0  0  2  0  0  0  0 22  0  0  0  3  0  0  0  0  2  0  0  0  0  0\n",
      "  3  0  0  0  0  2  0  0  0  9  1  2  0  0  0  0  0  0  0  0  0  2  0  0\n",
      "  2  7  0  0  0  3  1  0  0  0  0  0  0  0  0  0  0  6  0  0  3  5  0  0\n",
      "  0  3  0  0  0  0  0  0  0  1  0  0  0  2  0  0  5  8  0  0  0  5  0  1\n",
      "  0  0  0  0  0  0  0  0  0  1  0  0  0 12  0  0  0  4  0  0  0  0  0  0\n",
      "  0  0  0 24  0  0  0  0  1 12  0  0  0  1  0  2  0  1  0  0  0  0  0  0\n",
      " 15  4  0  0  0 21  0  0  0  9  0  3  0  0  0  0  1  0  0  0  3 37  0  0\n",
      "  2 14  0  0  0  5  0  2  0  0  0  0  0  0  0  0  2  0  3  0  2 10  0  0\n",
      "  0  8  0  0  0  0  0  0  0  0  0  0  0  4  0 11  1 13  0  0  0  2  0  0\n",
      "  0  0  0  0  0  0  0  0  1  5  0  0 22 20  0  0  1  5  0  2  0  0  0  0\n",
      "  0  0  0  0  4  2  0  0  0 83  0  0  0  9  0  0  0  0  0  0  0  0  0  0\n",
      "  0  2  0  0  2  8  0  0  0  4  0  1  0  0  0  0  0  0  0  0  1  2  0  0\n",
      "  1  5  0  0  0  5  0  0  0  0  0  0  0  0  0  0  1  2  0  0  6 12  0  0\n",
      "  5  3  0  1  0  0  0  0  0  0  0  0  5  1  0  0  1 12  0  0  0 40  0  4\n",
      "  0  0  0  0  0  0  0  0  2  0  1  0  3  9  0  0  0  9  6  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  6  0  0  0  3  0 39]\n",
      "MNB Accuracy:  0.4096728307254623\n",
      "MNB F1:  0.2591128906858253\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.44      0.61        16\n",
      "          1       0.31      0.15      0.20        27\n",
      "          2       0.26      0.53      0.35        19\n",
      "          3       0.50      0.13      0.21        15\n",
      "          4       0.92      0.71      0.80        17\n",
      "          5       1.00      0.41      0.58        22\n",
      "          6       0.38      0.35      0.36        17\n",
      "          7       1.00      0.80      0.89        40\n",
      "          8       0.42      0.47      0.45        53\n",
      "          9       0.54      0.62      0.58        64\n",
      "         10       0.59      0.40      0.48        25\n",
      "         11       0.72      0.58      0.64        31\n",
      "         12       0.43      0.77      0.55        56\n",
      "         13       0.42      0.72      0.53        98\n",
      "         14       1.00      0.06      0.11        17\n",
      "         15       0.33      0.14      0.20        14\n",
      "         16       0.90      0.30      0.45        30\n",
      "         17       0.82      0.59      0.69        63\n",
      "         18       0.69      0.35      0.47        31\n",
      "         19       0.94      0.94      0.94        48\n",
      "\n",
      "avg / total       0.64      0.56      0.55       703\n",
      "\n",
      "[ 7  0  0  0  0  0  1  0  0  3  0  0  2  3  0  0  0  0  0  0  0  4  3  0\n",
      "  0  0  0  0  1  1  0  0  0 18  0  0  0  0  0  0  0  0 10  0  0  0  0  0\n",
      "  4  0  0  0  1  2  0  1  0  0  1  0  0  0  1  2  0  0  0  0  0  1  0  0\n",
      "  6  1  0  0  0  0  4  0  0  0  1  0 12  0  0  0  0  1  0  0  2  1  0  0\n",
      "  0  0  0  0  0  0  2  0  0  9  0  0  0  2  0  1  6  2  0  0  0  0  0  0\n",
      "  0  0  1  0  0  0  6  0  0  0  3  0  0  7  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 32  0  1  0  1  3  3  0  0  0  0  0  0  0  1  0  0  0  0  2  0\n",
      " 25  4  0  0  5 10  0  1  0  5  0  0  0  0  0  0  1  0  0  0  3 40  0  2\n",
      "  9  9  0  0  0  0  0  0  0  0  0  0  0  0  1  0  3  2 10  0  1  6  0  0\n",
      "  0  2  0  0  0  0  1  0  0  0  0  0  0  6  0 18  1  5  0  0  0  0  0  0\n",
      "  0  0  1  0  0  0  0  0  5  2  0  1 43  3  0  0  1  0  0  0  0  6  4  0\n",
      "  0  0  3  0  8  2  0  1  1 71  0  2  0  0  0  0  0  0  4  0  0  0  1  0\n",
      "  0  2  0  0  5  4  1  0  0  0  0  0  0  1  1  0  0  0  1  0  2  0  0  0\n",
      "  2  4  0  2  0  1  0  0  0  1  2  0  0  0  0  0  2  2  0  0  8  6  0  0\n",
      "  9  0  0  0  0  0  2  0  0  0  1  0  5  2  2  0  2  9  0  0  0 37  0  3\n",
      "  0  0  5  2  0  0  0  0  1  2  2  1  1  6  0  0  0  0 11  0  0  0  0  0\n",
      "  0  0  0  0  0  1  0  0  2  0  0  0  0  0  0 45]\n",
      "svc Accuracy:  0.5604551920341394\n",
      "svc F1:  0.5040735055197565\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        16\n",
      "          1       0.40      0.07      0.12        27\n",
      "          2       0.29      0.53      0.38        19\n",
      "          3       0.00      0.00      0.00        15\n",
      "          4       0.86      0.35      0.50        17\n",
      "          5       1.00      0.41      0.58        22\n",
      "          6       0.50      0.24      0.32        17\n",
      "          7       1.00      0.78      0.87        40\n",
      "          8       0.47      0.47      0.47        53\n",
      "          9       0.49      0.61      0.55        64\n",
      "         10       0.35      0.28      0.31        25\n",
      "         11       0.82      0.58      0.68        31\n",
      "         12       0.51      0.62      0.56        56\n",
      "         13       0.37      0.72      0.49        98\n",
      "         14       0.00      0.00      0.00        17\n",
      "         15       0.17      0.07      0.10        14\n",
      "         16       0.83      0.33      0.48        30\n",
      "         17       0.48      0.68      0.56        63\n",
      "         18       0.67      0.32      0.43        31\n",
      "         19       0.94      0.94      0.94        48\n",
      "\n",
      "avg / total       0.56      0.53      0.51       703\n",
      "\n",
      "[ 4  0  0  0  0  0  0  0  1  4  0  0  1  4  0  0  0  2  0  0  0  2  2  0\n",
      "  0  0  0  0  2  0  0  0  0 21  0  0  0  0  0  0  0  0 10  0  0  0  0  0\n",
      "  3  0  0  0  0  2  0  1  0  2  1  0  0  0  1  0  0  0  0  0  0  2  0  0\n",
      "  2  3  0  0  0  5  2  0  0  0  1  0  6  0  0  0  0  3  0  0  1  3  0  0\n",
      "  0  3  0  0  0  0  2  0  0  9  0  0  0  1  1  1  5  3  0  0  0  0  0  0\n",
      "  0  0  1  0  0  0  4  0  0  1  3  0  0  8  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 31  0  0  1  1  2  5  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n",
      " 25  5  0  0  4 11  0  0  0  6  1  0  0  0  0  0  1  0  0  0  3 39  3  0\n",
      "  2 13  0  0  0  3  0  0  0  0  0  0  0  0  1  0  3  1  7  0  2  6  0  0\n",
      "  0  4  1  0  0  0  1  0  0  0  0  0  0  5  0 18  0  5  0  0  0  2  0  0\n",
      "  0  0  1  0  0  0  0  0  2  5  1  1 35  6  0  0  2  3  0  0  0  1  3  0\n",
      "  0  0  2  0  4  4  0  0  2 71  0  4  0  7  0  0  0  0  4  0  0  0  0  0\n",
      "  0  3  0  0  4  6  0  0  0  0  0  0  0  1  1  0  0  0  1  0  1  2  0  0\n",
      "  0  5  0  1  0  2  0  0  0  0  2  0  0  0  0  0  1  1  0  0  5  7  0  0\n",
      " 10  4  0  0  0  0  2  0  0  0  0  0  7  0  2  0  1  5  0  0  0 43  0  3\n",
      "  0  0  3  1  0  0  0  0  1  2  2  1  3  5  0  0  0  3 10  0  0  0  0  0\n",
      "  0  0  0  0  0  1  0  0  0  1  0  0  0  1  0 45]\n",
      "LR Accuracy:  0.5263157894736842\n",
      "LR F1:  0.43736861424889034\n",
      "For name:  m_pinho\n",
      "total sample size before apply threshold:  97\n",
      "Counter({'0000-0002-7132-8842': 42, '0000-0001-8173-0379': 26, '0000-0002-4645-1638': 13, '0000-0002-4298-0014': 6, '0000-0003-4502-667X': 4, '0000-0003-3142-4351': 4, '0000-0002-8045-2546': 1, '0000-0002-7993-5161': 1})\n",
      "['0000-0001-8173-0379', '0000-0002-4645-1638', '0000-0002-7132-8842']\n",
      "Total sample size after apply threshold:  81\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 52)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 17)\n",
      "2\n",
      "(81, 69)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.42      0.51        26\n",
      "          1       0.71      0.38      0.50        13\n",
      "          2       0.61      0.83      0.71        42\n",
      "\n",
      "avg / total       0.64      0.63      0.61        81\n",
      "\n",
      "[11  0 15  1  5  7  5  2 35]\n",
      "MNB Accuracy:  0.6296296296296297\n",
      "MNB F1:  0.5728995380158172\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.54      0.60        26\n",
      "          1       0.71      0.38      0.50        13\n",
      "          2       0.68      0.86      0.76        42\n",
      "\n",
      "avg / total       0.68      0.68      0.66        81\n",
      "\n",
      "[14  0 12  3  5  5  4  2 36]\n",
      "svc Accuracy:  0.6790123456790124\n",
      "svc F1:  0.617879805897723\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.42      0.50        26\n",
      "          1       0.67      0.31      0.42        13\n",
      "          2       0.60      0.81      0.69        42\n",
      "\n",
      "avg / total       0.61      0.60      0.58        81\n",
      "\n",
      "[11  0 15  1  4  8  6  2 34]\n",
      "LR Accuracy:  0.6049382716049383\n",
      "LR F1:  0.5359737728158781\n",
      "For name:  m_bergman\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0003-2589-2976': 20, '0000-0002-4529-4925': 13, '0000-0002-7033-5362': 2, '0000-0002-7018-1578': 1})\n",
      "['0000-0002-4529-4925', '0000-0003-2589-2976']\n",
      "Total sample size after apply threshold:  33\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 15)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 18)\n",
      "2\n",
      "(33, 33)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.69      0.78        13\n",
      "          1       0.83      0.95      0.88        20\n",
      "\n",
      "avg / total       0.86      0.85      0.84        33\n",
      "\n",
      "[ 9  4  1 19]\n",
      "MNB Accuracy:  0.8484848484848485\n",
      "MNB F1:  0.8331648129423661\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.69      0.78        13\n",
      "          1       0.83      0.95      0.88        20\n",
      "\n",
      "avg / total       0.86      0.85      0.84        33\n",
      "\n",
      "[ 9  4  1 19]\n",
      "svc Accuracy:  0.8484848484848485\n",
      "svc F1:  0.8331648129423661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.69      0.78        13\n",
      "          1       0.83      0.95      0.88        20\n",
      "\n",
      "avg / total       0.86      0.85      0.84        33\n",
      "\n",
      "[ 9  4  1 19]\n",
      "LR Accuracy:  0.8484848484848485\n",
      "LR F1:  0.8331648129423661\n",
      "For name:  j_castro\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0001-6169-3822': 15, '0000-0002-0382-553X': 10, '0000-0001-8984-475X': 7, '0000-0003-0794-3178': 3, '0000-0002-1939-7859': 2, '0000-0002-7468-5220': 1, '0000-0003-0868-1894': 1})\n",
      "['0000-0001-6169-3822', '0000-0002-0382-553X']\n",
      "Total sample size after apply threshold:  25\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 11)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 14)\n",
      "2\n",
      "(25, 25)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        15\n",
      "          1       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.85      0.80      0.78        25\n",
      "\n",
      "[15  0  5  5]\n",
      "MNB Accuracy:  0.8\n",
      "MNB F1:  0.7619047619047619\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        15\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.96      0.96      0.96        25\n",
      "\n",
      "[15  0  1  9]\n",
      "svc Accuracy:  0.96\n",
      "svc F1:  0.9575551782682513\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        15\n",
      "          1       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.85      0.80      0.78        25\n",
      "\n",
      "[15  0  5  5]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.7619047619047619\n",
      "For name:  n_hall\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0003-2808-0009': 102, '0000-0003-0100-0291': 5, '0000-0003-1503-5989': 4, '0000-0001-7465-5470': 2, '0000-0001-7082-1523': 1, '0000-0002-0216-512X': 1})\n",
      "['0000-0003-2808-0009']\n",
      "Total sample size after apply threshold:  102\n",
      "For name:  d_schneider\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-2124-8385': 40, '0000-0001-9659-6731': 33, '0000-0002-2867-2613': 12, '0000-0002-0163-6137': 5, '0000-0002-5276-3304': 3})\n",
      "['0000-0002-2867-2613', '0000-0001-9659-6731', '0000-0002-2124-8385']\n",
      "Total sample size after apply threshold:  85\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 53)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 15)\n",
      "2\n",
      "(85, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29        12\n",
      "          1       0.75      0.64      0.69        33\n",
      "          2       0.65      0.90      0.76        40\n",
      "\n",
      "avg / total       0.74      0.69      0.66        85\n",
      "\n",
      "[ 2  3  7  0 21 12  0  4 36]\n",
      "MNB Accuracy:  0.6941176470588235\n",
      "MNB F1:  0.5773778709067751\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.33      0.42        12\n",
      "          1       0.69      0.67      0.68        33\n",
      "          2       0.67      0.78      0.72        40\n",
      "\n",
      "avg / total       0.66      0.67      0.66        85\n",
      "\n",
      "[ 4  3  5  1 22 10  2  7 31]\n",
      "svc Accuracy:  0.6705882352941176\n",
      "svc F1:  0.606301980353388\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29        12\n",
      "          1       0.74      0.61      0.67        33\n",
      "          2       0.64      0.90      0.75        40\n",
      "\n",
      "avg / total       0.73      0.68      0.65        85\n",
      "\n",
      "[ 2  3  7  0 20 13  0  4 36]\n",
      "LR Accuracy:  0.6823529411764706\n",
      "LR F1:  0.5674603174603174\n",
      "For name:  n_kumar\n",
      "total sample size before apply threshold:  156\n",
      "Counter({'0000-0002-9876-2884': 25, '0000-0002-4197-5133': 24, '0000-0003-4665-9401': 22, '0000-0003-0898-908X': 15, '0000-0001-6275-8501': 12, '0000-0003-0170-888X': 11, '0000-0003-4504-4704': 7, '0000-0003-2805-779X': 7, '0000-0002-1546-1921': 5, '0000-0003-4445-877X': 4, '0000-0003-2380-9489': 4, '0000-0001-7364-6601': 4, '0000-0002-1064-1659': 3, '0000-0003-3531-7414': 3, '0000-0002-7123-2111': 2, '0000-0003-3709-0823': 2, '0000-0002-6064-4161': 1, '0000-0002-2009-3158': 1, '0000-0002-3020-3947': 1, '0000-0002-6871-1840': 1, '0000-0001-5932-8500': 1, '0000-0002-2427-647X': 1})\n",
      "['0000-0002-4197-5133', '0000-0003-0898-908X', '0000-0001-6275-8501', '0000-0003-4665-9401', '0000-0003-0170-888X', '0000-0002-9876-2884']\n",
      "Total sample size after apply threshold:  109\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 61)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 10)\n",
      "2\n",
      "(109, 71)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.83      0.65        24\n",
      "          1       1.00      0.27      0.42        15\n",
      "          2       0.57      1.00      0.73        12\n",
      "          3       0.71      0.55      0.62        22\n",
      "          4       0.57      0.36      0.44        11\n",
      "          5       0.59      0.52      0.55        25\n",
      "\n",
      "avg / total       0.65      0.60      0.58       109\n",
      "\n",
      "[20  0  0  0  0  4  9  4  2  0  0  0  0  0 12  0  0  0  2  0  3 12  2  3\n",
      "  1  0  3  1  4  2  6  0  1  4  1 13]\n",
      "MNB Accuracy:  0.5963302752293578\n",
      "MNB F1:  0.5677511997275029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.96      0.70        24\n",
      "          1       0.83      0.33      0.48        15\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       0.58      0.64      0.61        22\n",
      "          4       1.00      0.64      0.78        11\n",
      "          5       0.70      0.56      0.62        25\n",
      "\n",
      "avg / total       0.72      0.67      0.66       109\n",
      "\n",
      "[23  1  0  0  0  0  8  5  0  2  0  0  0  0 10  1  0  1  4  0  0 14  0  4\n",
      "  2  0  0  1  7  1  5  0  0  6  0 14]\n",
      "svc Accuracy:  0.6697247706422018\n",
      "svc F1:  0.6818244557374992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.83      0.65        24\n",
      "          1       0.71      0.33      0.45        15\n",
      "          2       1.00      0.92      0.96        12\n",
      "          3       0.58      0.68      0.62        22\n",
      "          4       0.62      0.45      0.53        11\n",
      "          5       0.68      0.52      0.59        25\n",
      "\n",
      "avg / total       0.66      0.63      0.62       109\n",
      "\n",
      "[20  2  0  0  0  2  8  5  0  1  0  1  0  0 11  1  0  0  3  0  0 15  2  2\n",
      "  2  0  0  3  5  1  5  0  0  6  1 13]\n",
      "LR Accuracy:  0.6330275229357798\n",
      "LR F1:  0.6330755607302074\n",
      "For name:  i_martins\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-9284-8599': 12, '0000-0002-0136-1671': 11, '0000-0002-8521-2613': 8, '0000-0002-5362-9801': 7, '0000-0001-6797-2558': 7, '0000-0002-3412-9377': 6, '0000-0003-0897-8807': 1, '0000-0003-4328-7286': 1, '0000-0003-3291-0079': 1})\n",
      "['0000-0002-0136-1671', '0000-0002-9284-8599']\n",
      "Total sample size after apply threshold:  23\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 19)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 10)\n",
      "2\n",
      "(23, 29)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.55      0.52        11\n",
      "          1       0.55      0.50      0.52        12\n",
      "\n",
      "avg / total       0.52      0.52      0.52        23\n",
      "\n",
      "[6 5 6 6]\n",
      "MNB Accuracy:  0.5217391304347826\n",
      "MNB F1:  0.5217391304347826\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.55      0.63        11\n",
      "          1       0.67      0.83      0.74        12\n",
      "\n",
      "avg / total       0.71      0.70      0.69        23\n",
      "\n",
      "[ 6  5  2 10]\n",
      "svc Accuracy:  0.6956521739130435\n",
      "svc F1:  0.6861598440545809\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.55      0.55        11\n",
      "          1       0.58      0.58      0.58        12\n",
      "\n",
      "avg / total       0.57      0.57      0.57        23\n",
      "\n",
      "[6 5 5 7]\n",
      "LR Accuracy:  0.5652173913043478\n",
      "LR F1:  0.5643939393939394\n",
      "For name:  j_qiu\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-1541-9627': 41, '0000-0002-7633-6227': 8, '0000-0002-9886-3570': 3, '0000-0001-9220-4219': 2, '0000-0002-1059-627X': 1, '0000-0002-7628-5431': 1, '0000-0002-6155-8548': 1, '0000-0002-1275-4171': 1})\n",
      "['0000-0002-1541-9627']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  m_antunes\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0001-5545-2520': 7, '0000-0001-5888-2278': 6, '0000-0002-8913-6136': 6, '0000-0002-1257-2829': 5, '0000-0001-8216-8066': 3})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_andersen\n",
      "total sample size before apply threshold:  399\n",
      "Counter({'0000-0002-3894-4811': 222, '0000-0003-4694-486X': 58, '0000-0003-4794-6808': 39, '0000-0001-7029-2860': 21, '0000-0003-1125-1553': 14, '0000-0002-0234-0266': 11, '0000-0001-8275-9472': 11, '0000-0003-4977-3031': 8, '0000-0003-3845-4465': 7, '0000-0002-4833-1867': 3, '0000-0002-4654-3946': 2, '0000-0002-6803-0981': 2, '0000-0002-8164-278X': 1})\n",
      "['0000-0003-1125-1553', '0000-0002-0234-0266', '0000-0003-4794-6808', '0000-0001-7029-2860', '0000-0001-8275-9472', '0000-0003-4694-486X', '0000-0002-3894-4811']\n",
      "Total sample size after apply threshold:  376\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(376, 131)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(376, 31)\n",
      "2\n",
      "(376, 162)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       0.60      0.46      0.52        39\n",
      "          3       1.00      0.14      0.25        21\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       0.73      0.79      0.76        58\n",
      "          6       0.78      0.98      0.87       222\n",
      "\n",
      "avg / total       0.72      0.76      0.70       376\n",
      "\n",
      "[  0   0   3   0   0   3   8   0   1   2   0   0   2   6   0   0  18   0\n",
      "   0   4  17   0   0   4   3   0   3  11   0   0   0   0   0   1  10   0\n",
      "   0   3   0   0  46   9   0   0   0   0   0   4 218]\n",
      "MNB Accuracy:  0.7606382978723404\n",
      "MNB F1:  0.36699940809311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.21      0.33        14\n",
      "          1       0.88      0.64      0.74        11\n",
      "          2       0.76      0.64      0.69        39\n",
      "          3       1.00      0.52      0.69        21\n",
      "          4       0.88      0.64      0.74        11\n",
      "          5       0.98      0.78      0.87        58\n",
      "          6       0.82      0.99      0.90       222\n",
      "\n",
      "avg / total       0.85      0.84      0.83       376\n",
      "\n",
      "[  3   0   2   0   0   0   9   0   7   1   0   1   0   2   1   0  25   0\n",
      "   0   0  13   0   0   1  11   0   0   9   0   1   0   0   7   0   3   0\n",
      "   0   2   0   0  45  11   0   0   2   0   0   1 219]\n",
      "svc Accuracy:  0.8430851063829787\n",
      "svc F1:  0.7074125124707523\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       1.00      0.45      0.62        11\n",
      "          2       0.66      0.49      0.56        39\n",
      "          3       1.00      0.29      0.44        21\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       0.97      0.67      0.80        58\n",
      "          6       0.75      1.00      0.86       222\n",
      "\n",
      "avg / total       0.75      0.77      0.73       376\n",
      "\n",
      "[  0   0   3   0   0   0  11   0   5   1   0   0   0   5   0   0  19   0\n",
      "   0   0  20   0   0   4   6   0   0  11   0   0   0   0   0   1  10   0\n",
      "   0   2   0   0  39  17   0   0   0   0   0   0 222]\n",
      "LR Accuracy:  0.773936170212766\n",
      "LR F1:  0.46876131404942933\n",
      "For name:  l_xiao\n",
      "total sample size before apply threshold:  302\n",
      "Counter({'0000-0001-8532-2727': 267, '0000-0002-4631-2443': 24, '0000-0003-0178-9384': 5, '0000-0003-4088-6101': 5, '0000-0002-0391-6909': 1})\n",
      "['0000-0001-8532-2727', '0000-0002-4631-2443']\n",
      "Total sample size after apply threshold:  291\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(291, 77)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(291, 25)\n",
      "2\n",
      "(291, 102)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97       267\n",
      "          1       1.00      0.21      0.34        24\n",
      "\n",
      "avg / total       0.94      0.93      0.91       291\n",
      "\n",
      "[267   0  19   5]\n",
      "MNB Accuracy:  0.9347079037800687\n",
      "MNB F1:  0.6552347695953109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       267\n",
      "          1       1.00      0.58      0.74        24\n",
      "\n",
      "avg / total       0.97      0.97      0.96       291\n",
      "\n",
      "[267   0  10  14]\n",
      "svc Accuracy:  0.9656357388316151\n",
      "svc F1:  0.8592298761609907\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       267\n",
      "          1       1.00      0.04      0.08        24\n",
      "\n",
      "avg / total       0.93      0.92      0.89       291\n",
      "\n",
      "[267   0  23   1]\n",
      "LR Accuracy:  0.9209621993127147\n",
      "LR F1:  0.5193536804308797\n",
      "For name:  m_hartmann\n",
      "total sample size before apply threshold:  88\n",
      "Counter({'0000-0001-8069-5284': 28, '0000-0001-6937-5677': 25, '0000-0002-8207-3806': 21, '0000-0001-6046-0365': 10, '0000-0002-4774-2787': 4})\n",
      "['0000-0001-6937-5677', '0000-0001-8069-5284', '0000-0002-8207-3806', '0000-0001-6046-0365']\n",
      "Total sample size after apply threshold:  84\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(84, 35)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(84, 13)\n",
      "2\n",
      "(84, 48)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.68      0.63        25\n",
      "          1       0.65      0.61      0.63        28\n",
      "          2       0.74      0.95      0.83        21\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.58      0.64      0.61        84\n",
      "\n",
      "[17  6  1  1  7 17  3  1  0  1 20  0  5  2  3  0]\n",
      "MNB Accuracy:  0.6428571428571429\n",
      "MNB F1:  0.5231481481481481\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.72      0.65        25\n",
      "          1       0.68      0.68      0.68        28\n",
      "          2       0.86      0.90      0.88        21\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.62      0.67      0.64        84\n",
      "\n",
      "[18  6  0  1  8 19  0  1  0  0 19  2  4  3  3  0]\n",
      "svc Accuracy:  0.6666666666666666\n",
      "svc F1:  0.5542094533373603\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.72      0.67        25\n",
      "          1       0.61      0.71      0.66        28\n",
      "          2       0.90      0.90      0.90        21\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.61      0.68      0.64        84\n",
      "\n",
      "[18  7  0  0  8 20  0  0  0  1 19  1  3  5  2  0]\n",
      "LR Accuracy:  0.6785714285714286\n",
      "LR F1:  0.5567915690866511\n",
      "For name:  k_nielsen\n",
      "total sample size before apply threshold:  194\n",
      "Counter({'0000-0002-5848-0911': 89, '0000-0002-7217-2114': 59, '0000-0001-7956-1748': 20, '0000-0002-9155-2972': 12, '0000-0002-4643-5697': 11, '0000-0002-5510-7767': 2, '0000-0002-4944-9453': 1})\n",
      "['0000-0002-4643-5697', '0000-0002-9155-2972', '0000-0001-7956-1748', '0000-0002-5848-0911', '0000-0002-7217-2114']\n",
      "Total sample size after apply threshold:  191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 106)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 19)\n",
      "2\n",
      "(191, 125)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.08      0.15        12\n",
      "          2       1.00      0.05      0.10        20\n",
      "          3       0.65      0.90      0.75        89\n",
      "          4       0.55      0.61      0.58        59\n",
      "\n",
      "avg / total       0.64      0.62      0.55       191\n",
      "\n",
      "[ 0  0  0  8  3  0  1  0  4  7  0  0  1  9 10  0  0  0 80  9  0  0  0 23\n",
      " 36]\n",
      "MNB Accuracy:  0.6178010471204188\n",
      "MNB F1:  0.31618062385895196\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       0.60      0.25      0.35        12\n",
      "          2       0.64      0.35      0.45        20\n",
      "          3       0.71      0.87      0.78        89\n",
      "          4       0.62      0.64      0.63        59\n",
      "\n",
      "avg / total       0.68      0.68      0.66       191\n",
      "\n",
      "[ 5  0  0  4  2  0  3  1  3  5  0  0  7  8  5  0  1  0 77 11  0  1  3 17\n",
      " 38]\n",
      "svc Accuracy:  0.680628272251309\n",
      "svc F1:  0.5681330381615012\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.50      0.08      0.14        12\n",
      "          2       1.00      0.15      0.26        20\n",
      "          3       0.65      0.90      0.75        89\n",
      "          4       0.57      0.61      0.59        59\n",
      "\n",
      "avg / total       0.62      0.63      0.57       191\n",
      "\n",
      "[ 0  0  0  8  3  0  1  0  4  7  0  0  3  9  8  0  0  0 80  9  0  1  0 22\n",
      " 36]\n",
      "LR Accuracy:  0.6282722513089005\n",
      "LR F1:  0.34972152472656787\n",
      "For name:  m_sousa\n",
      "total sample size before apply threshold:  211\n",
      "Counter({'0000-0002-3009-3290': 117, '0000-0001-9424-4150': 28, '0000-0002-4524-2260': 28, '0000-0003-2305-4813': 9, '0000-0003-4957-7831': 8, '0000-0002-5269-3342': 5, '0000-0002-5397-4672': 4, '0000-0002-9946-4926': 4, '0000-0003-2238-1070': 4, '0000-0003-1687-942X': 2, '0000-0003-2575-3263': 1, '0000-0003-0012-7493': 1})\n",
      "['0000-0002-3009-3290', '0000-0001-9424-4150', '0000-0002-4524-2260']\n",
      "Total sample size after apply threshold:  173\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(173, 95)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(173, 22)\n",
      "2\n",
      "(173, 117)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82       117\n",
      "          1       0.80      0.14      0.24        28\n",
      "          2       1.00      0.04      0.07        28\n",
      "\n",
      "avg / total       0.77      0.71      0.61       173\n",
      "\n",
      "[117   0   0  24   4   0  26   1   1]\n",
      "MNB Accuracy:  0.7052023121387283\n",
      "MNB F1:  0.3784444738791508\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90       117\n",
      "          1       0.90      0.64      0.75        28\n",
      "          2       0.87      0.46      0.60        28\n",
      "\n",
      "avg / total       0.85      0.84      0.83       173\n",
      "\n",
      "[115   1   1   9  18   1  14   1  13]\n",
      "svc Accuracy:  0.8439306358381503\n",
      "svc F1:  0.7522039823681409\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      1.00      0.81       117\n",
      "          1       1.00      0.04      0.07        28\n",
      "          2       1.00      0.04      0.07        28\n",
      "\n",
      "avg / total       0.79      0.69      0.57       173\n",
      "\n",
      "[117   0   0  27   1   0  27   0   1]\n",
      "LR Accuracy:  0.6878612716763006\n",
      "LR F1:  0.31681034482758624\n",
      "For name:  a_coelho\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0002-6143-4203': 72, '0000-0003-2780-5821': 15, '0000-0002-7196-4179': 11, '0000-0002-3286-0262': 11, '0000-0003-3077-3859': 6, '0000-0002-7277-2267': 5, '0000-0002-2883-415X': 4, '0000-0003-3527-9091': 2, '0000-0002-9767-8891': 1, '0000-0002-2919-5468': 1})\n",
      "['0000-0003-2780-5821', '0000-0002-7196-4179', '0000-0002-6143-4203', '0000-0002-3286-0262']\n",
      "Total sample size after apply threshold:  109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 78)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 26)\n",
      "2\n",
      "(109, 104)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.42        15\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.72      0.99      0.83        72\n",
      "          3       0.83      0.45      0.59        11\n",
      "\n",
      "avg / total       0.70      0.73      0.67       109\n",
      "\n",
      "[ 4  0 11  0  0  0 11  0  0  0 71  1  0  0  6  5]\n",
      "MNB Accuracy:  0.7339449541284404\n",
      "MNB F1:  0.4599243206054352\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.27      0.38        15\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.74      0.96      0.84        72\n",
      "          3       0.89      0.73      0.80        11\n",
      "\n",
      "avg / total       0.67      0.74      0.69       109\n",
      "\n",
      "[ 4  0 11  0  0  0 11  0  1  1 69  1  1  0  2  8]\n",
      "svc Accuracy:  0.7431192660550459\n",
      "svc F1:  0.5043290043290043\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        15\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.68      0.99      0.81        72\n",
      "          3       1.00      0.36      0.53        11\n",
      "\n",
      "avg / total       0.55      0.69      0.59       109\n",
      "\n",
      "[ 0  0 15  0  0  0 11  0  0  1 71  0  0  0  7  4]\n",
      "LR Accuracy:  0.6880733944954128\n",
      "LR F1:  0.3350378787878788\n",
      "For name:  r_sanz\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0003-2830-0892': 30, '0000-0001-6626-4146': 8, '0000-0002-2381-933X': 3, '0000-0001-8211-7306': 1})\n",
      "['0000-0003-2830-0892']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  m_ferrara\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0003-2304-7576': 92, '0000-0002-4751-8478': 5, '0000-0001-5291-1373': 4, '0000-0002-1567-4281': 2})\n",
      "['0000-0003-2304-7576']\n",
      "Total sample size after apply threshold:  92\n",
      "For name:  c_hui\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-3660-8160': 34, '0000-0002-3698-5572': 5, '0000-0002-2886-4957': 4, '0000-0002-0260-193X': 1})\n",
      "['0000-0002-3660-8160']\n",
      "Total sample size after apply threshold:  34\n",
      "For name:  l_bruno\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0001-8260-4729': 22, '0000-0002-6745-0466': 10, '0000-0003-4703-2088': 7, '0000-0002-0875-7716': 2, '0000-0002-3054-2180': 1})\n",
      "['0000-0002-6745-0466', '0000-0001-8260-4729']\n",
      "Total sample size after apply threshold:  32\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 20)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 13)\n",
      "2\n",
      "(32, 33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70        10\n",
      "          1       0.86      0.86      0.86        22\n",
      "\n",
      "avg / total       0.81      0.81      0.81        32\n",
      "\n",
      "[ 7  3  3 19]\n",
      "MNB Accuracy:  0.8125\n",
      "MNB F1:  0.7818181818181817\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       0.88      1.00      0.94        22\n",
      "\n",
      "avg / total       0.92      0.91      0.90        32\n",
      "\n",
      "[ 7  3  0 22]\n",
      "svc Accuracy:  0.90625\n",
      "svc F1:  0.8798498122653317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.81      1.00      0.90        22\n",
      "\n",
      "avg / total       0.87      0.84      0.83        32\n",
      "\n",
      "[ 5  5  0 22]\n",
      "LR Accuracy:  0.84375\n",
      "LR F1:  0.782312925170068\n",
      "For name:  s_nielsen\n",
      "total sample size before apply threshold:  290\n",
      "Counter({'0000-0003-2417-0787': 108, '0000-0001-6391-7455': 72, '0000-0001-5341-1055': 44, '0000-0003-4175-3829': 21, '0000-0002-5777-6542': 13, '0000-0002-7780-7131': 11, '0000-0003-4309-5153': 7, '0000-0002-9754-0630': 4, '0000-0002-9214-2932': 4, '0000-0002-0458-3739': 3, '0000-0003-2770-9899': 1, '0000-0002-8449-476X': 1, '0000-0003-2064-8050': 1})\n",
      "['0000-0001-5341-1055', '0000-0003-4175-3829', '0000-0002-5777-6542', '0000-0002-7780-7131', '0000-0001-6391-7455', '0000-0003-2417-0787']\n",
      "Total sample size after apply threshold:  269\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(269, 105)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(269, 23)\n",
      "2\n",
      "(269, 128)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.66      0.71        44\n",
      "          1       1.00      0.76      0.86        21\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.76      0.78      0.77        72\n",
      "          5       0.68      0.89      0.77       108\n",
      "\n",
      "avg / total       0.68      0.73      0.70       269\n",
      "\n",
      "[29  0  0  0  3 12  0 16  0  0  1  4  1  0  0  0  3  9  3  0  0  0  2  6\n",
      "  2  0  0  0 56 14  3  0  0  0  9 96]\n",
      "MNB Accuracy:  0.7323420074349443\n",
      "MNB F1:  0.5183982605093711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.61      0.71        44\n",
      "          1       1.00      0.95      0.98        21\n",
      "          2       0.70      0.54      0.61        13\n",
      "          3       1.00      0.27      0.43        11\n",
      "          4       0.79      0.74      0.76        72\n",
      "          5       0.70      0.89      0.78       108\n",
      "\n",
      "avg / total       0.78      0.77      0.76       269\n",
      "\n",
      "[27  0  1  0  1 15  0 20  0  0  1  0  0  0  7  0  1  5  0  0  0  3  2  6\n",
      "  3  0  1  0 53 15  2  0  1  0  9 96]\n",
      "svc Accuracy:  0.7657992565055762\n",
      "svc F1:  0.7116110916796142\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.66      0.71        44\n",
      "          1       1.00      0.81      0.89        21\n",
      "          2       1.00      0.08      0.14        13\n",
      "          3       1.00      0.18      0.31        11\n",
      "          4       0.75      0.79      0.77        72\n",
      "          5       0.71      0.89      0.79       108\n",
      "\n",
      "avg / total       0.78      0.75      0.73       269\n",
      "\n",
      "[29  0  0  0  6  9  0 17  0  0  0  4  2  0  1  0  3  7  3  0  0  2  1  5\n",
      "  1  0  0  0 57 14  3  0  0  0  9 96]\n",
      "LR Accuracy:  0.7509293680297398\n",
      "LR F1:  0.6021661821476397\n",
      "For name:  b_russell\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0003-2333-4348': 61, '0000-0003-1282-9978': 20, '0000-0002-8740-6040': 1, '0000-0002-3345-8478': 1, '0000-0002-8848-4841': 1})\n",
      "['0000-0003-1282-9978', '0000-0003-2333-4348']\n",
      "Total sample size after apply threshold:  81\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 36)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 15)\n",
      "2\n",
      "(81, 51)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.25      0.31        20\n",
      "          1       0.78      0.89      0.83        61\n",
      "\n",
      "avg / total       0.69      0.73      0.70        81\n",
      "\n",
      "[ 5 15  7 54]\n",
      "MNB Accuracy:  0.7283950617283951\n",
      "MNB F1:  0.5716346153846155\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.30      0.40        20\n",
      "          1       0.80      0.93      0.86        61\n",
      "\n",
      "avg / total       0.75      0.78      0.75        81\n",
      "\n",
      "[ 6 14  4 57]\n",
      "svc Accuracy:  0.7777777777777778\n",
      "svc F1:  0.6318181818181818\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.05      0.09        20\n",
      "          1       0.76      0.97      0.85        61\n",
      "\n",
      "avg / total       0.65      0.74      0.66        81\n",
      "\n",
      "[ 1 19  2 59]\n",
      "LR Accuracy:  0.7407407407407407\n",
      "LR F1:  0.4679386925242415\n",
      "For name:  y_wu\n",
      "total sample size before apply threshold:  612\n",
      "Counter({'0000-0002-3611-0258': 120, '0000-0002-1720-7863': 65, '0000-0003-3456-3373': 43, '0000-0002-2573-8736': 39, '0000-0002-1751-461X': 35, '0000-0001-5579-2197': 33, '0000-0002-2985-219X': 23, '0000-0002-8621-4098': 23, '0000-0003-0365-5590': 23, '0000-0001-9359-1863': 23, '0000-0003-0253-1625': 17, '0000-0001-9142-456X': 14, '0000-0002-0833-1205': 12, '0000-0003-3191-3163': 11, '0000-0002-4459-087X': 10, '0000-0002-7919-1107': 10, '0000-0002-9460-3579': 9, '0000-0002-9289-1271': 9, '0000-0002-3612-7818': 8, '0000-0001-5035-4577': 8, '0000-0002-3805-6515': 7, '0000-0002-5163-0884': 6, '0000-0003-1028-1785': 6, '0000-0003-3511-4270': 5, '0000-0001-7857-0247': 5, '0000-0003-3970-3160': 5, '0000-0001-7247-7404': 5, '0000-0002-1457-3681': 4, '0000-0002-8937-4417': 4, '0000-0003-0878-7605': 4, '0000-0002-8858-1289': 4, '0000-0001-5083-8950': 4, '0000-0003-4542-1741': 3, '0000-0002-1509-1721': 3, '0000-0003-2874-8267': 2, '0000-0002-3269-7143': 2, '0000-0001-7876-261X': 2, '0000-0001-9263-5369': 1, '0000-0003-3357-3051': 1, '0000-0002-8966-1459': 1, '0000-0003-0118-2152': 1, '0000-0001-5480-1741': 1, '0000-0001-5466-2446': 1})\n",
      "['0000-0001-9142-456X', '0000-0001-5579-2197', '0000-0002-3611-0258', '0000-0003-3191-3163', '0000-0002-4459-087X', '0000-0002-2985-219X', '0000-0002-0833-1205', '0000-0002-8621-4098', '0000-0002-7919-1107', '0000-0003-3456-3373', '0000-0002-1751-461X', '0000-0002-1720-7863', '0000-0003-0365-5590', '0000-0001-9359-1863', '0000-0002-2573-8736', '0000-0003-0253-1625']\n",
      "Total sample size after apply threshold:  501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(501, 232)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(501, 18)\n",
      "2\n",
      "(501, 250)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.87      0.39      0.54        33\n",
      "          2       0.34      0.98      0.51       120\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       1.00      0.30      0.47        23\n",
      "          6       0.00      0.00      0.00        12\n",
      "          7       0.00      0.00      0.00        23\n",
      "          8       0.00      0.00      0.00        10\n",
      "          9       0.54      0.58      0.56        43\n",
      "         10       1.00      0.71      0.83        35\n",
      "         11       0.50      0.20      0.29        65\n",
      "         12       0.71      0.22      0.33        23\n",
      "         13       0.50      0.26      0.34        23\n",
      "         14       0.38      0.13      0.19        39\n",
      "         15       0.50      0.06      0.11        17\n",
      "\n",
      "avg / total       0.47      0.44      0.37       501\n",
      "\n",
      "[  0   0  11   0   0   0   0   0   0   0   0   3   0   0   0   0   0  13\n",
      "  17   0   0   0   0   0   0   1   0   2   0   0   0   0   0   0 118   0\n",
      "   0   0   0   0   0   2   0   0   0   0   0   0   0   0   9   0   0   0\n",
      "   0   0   0   2   0   0   0   0   0   0   0   0   7   0   0   0   0   0\n",
      "   0   3   0   0   0   0   0   0   0   0  15   0   0   7   0   0   0   0\n",
      "   0   1   0   0   0   0   0   0  11   0   0   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   0  15   0   0   0   0   0   0   1   0   1   2   3\n",
      "   1   0   0   0   9   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "   0   0  16   0   0   0   0   0   0  25   0   2   0   0   0   0   0   0\n",
      "  10   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0  45   0\n",
      "   0   0   0   0   0   7   0  13   0   0   0   0   0   2  14   0   0   0\n",
      "   0   1   0   1   0   0   5   0   0   0   0   0  11   0   0   0   0   0\n",
      "   0   0   0   2   0   6   3   1   0   0  27   0   0   0   0   0   0   3\n",
      "   0   2   0   2   5   0   0   0  12   0   0   0   0   0   0   0   0   0\n",
      "   0   1   3   1]\n",
      "MNB Accuracy:  0.4351297405189621\n",
      "MNB F1:  0.2605183344150414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.35        14\n",
      "          1       0.93      0.82      0.87        33\n",
      "          2       0.47      0.93      0.63       120\n",
      "          3       1.00      0.27      0.43        11\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       1.00      0.57      0.72        23\n",
      "          6       0.78      0.58      0.67        12\n",
      "          7       0.46      0.26      0.33        23\n",
      "          8       0.67      0.20      0.31        10\n",
      "          9       0.94      0.74      0.83        43\n",
      "         10       1.00      0.77      0.87        35\n",
      "         11       0.53      0.45      0.48        65\n",
      "         12       0.44      0.30      0.36        23\n",
      "         13       0.52      0.52      0.52        23\n",
      "         14       0.57      0.41      0.48        39\n",
      "         15       1.00      0.47      0.64        17\n",
      "\n",
      "avg / total       0.66      0.61      0.59       501\n",
      "\n",
      "[  3   0   8   0   0   0   0   0   0   0   0   3   0   0   0   0   0  27\n",
      "   5   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0 112   0\n",
      "   0   0   0   0   0   0   0   7   1   0   0   0   0   0   6   3   0   0\n",
      "   0   0   0   0   0   2   0   0   0   0   0   0   8   0   0   0   0   0\n",
      "   0   0   0   2   0   0   0   0   0   0   8   0   0  13   0   0   0   0\n",
      "   0   2   0   0   0   0   0   0   3   0   0   0   7   0   0   0   0   0\n",
      "   0   0   2   0   0   0  10   0   0   0   0   6   0   1   0   0   4   2\n",
      "   0   0   0   0   7   0   0   0   0   0   2   1   0   0   0   0   0   0\n",
      "   0   1   7   0   0   0   0   0   1  32   0   1   1   0   0   0   0   0\n",
      "   7   0   0   0   0   0   0   0  27   1   0   0   0   0   0   1  34   0\n",
      "   0   0   0   0   0   0   0  29   0   0   1   0   0   0   7   0   0   0\n",
      "   0   4   0   0   0   2   7   0   3   0   0   0   4   0   0   0   1   1\n",
      "   0   0   0   1   0  12   4   0   0   0   7   0   0   0   1   2   0   0\n",
      "   0   4   3   6  16   0   0   0   4   0   0   0   0   0   0   0   0   0\n",
      "   0   3   2   8]\n",
      "svc Accuracy:  0.6067864271457086\n",
      "svc F1:  0.5308525745893428\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.74      0.52      0.61        33\n",
      "          2       0.41      0.91      0.57       120\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       1.00      0.52      0.69        23\n",
      "          6       1.00      0.25      0.40        12\n",
      "          7       0.00      0.00      0.00        23\n",
      "          8       0.67      0.20      0.31        10\n",
      "          9       0.72      0.65      0.68        43\n",
      "         10       1.00      0.74      0.85        35\n",
      "         11       0.40      0.43      0.41        65\n",
      "         12       0.45      0.22      0.29        23\n",
      "         13       0.53      0.39      0.45        23\n",
      "         14       0.57      0.33      0.42        39\n",
      "         15       0.67      0.35      0.46        17\n",
      "\n",
      "avg / total       0.53      0.51      0.48       501\n",
      "\n",
      "[  0   0  11   0   0   0   0   0   0   0   0   3   0   0   0   0   0  17\n",
      "  11   0   0   0   0   0   0   1   0   4   0   0   0   0   0   1 109   0\n",
      "   0   0   0   0   0   1   0   9   0   0   0   0   0   0   7   0   0   0\n",
      "   0   0   0   1   0   3   0   0   0   0   0   0   6   0   0   0   0   0\n",
      "   0   2   0   2   0   0   0   0   0   0   9   0   0  12   0   0   0   0\n",
      "   0   2   0   0   0   0   0   0   8   0   0   0   3   0   0   0   0   0\n",
      "   0   0   1   0   0   0  14   0   0   0   0   0   0   1   0   2   3   2\n",
      "   1   0   0   0   7   0   0   0   0   0   2   1   0   0   0   0   0   0\n",
      "   0   1   9   0   0   0   0   0   1  28   0   3   0   0   1   0   0   0\n",
      "   9   0   0   0   0   0   0   0  26   0   0   0   0   0   0   1  32   0\n",
      "   0   0   0   1   0   3   0  28   0   0   0   0   0   1   9   0   0   0\n",
      "   0   1   0   0   0   4   5   0   3   0   0   0   6   0   0   0   0   0\n",
      "   0   0   0   2   0   9   3   3   0   1  11   0   0   0   0   0   0   1\n",
      "   0   7   3   3  13   0   0   1   5   0   0   0   0   0   0   0   0   1\n",
      "   0   3   1   6]\n",
      "LR Accuracy:  0.5149700598802395\n",
      "LR F1:  0.3840594786784473\n",
      "For name:  j_soto\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0003-0234-9188': 39, '0000-0001-6702-2878': 21, '0000-0001-5521-0900': 3, '0000-0001-8961-9106': 1})\n",
      "['0000-0001-6702-2878', '0000-0003-0234-9188']\n",
      "Total sample size after apply threshold:  60\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 36)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 17)\n",
      "2\n",
      "(60, 53)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.71      0.77        21\n",
      "          1       0.86      0.92      0.89        39\n",
      "\n",
      "avg / total       0.85      0.85      0.85        60\n",
      "\n",
      "[15  6  3 36]\n",
      "MNB Accuracy:  0.85\n",
      "MNB F1:  0.829059829059829\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        21\n",
      "          1       0.93      1.00      0.96        39\n",
      "\n",
      "avg / total       0.95      0.95      0.95        60\n",
      "\n",
      "[18  3  0 39]\n",
      "svc Accuracy:  0.95\n",
      "svc F1:  0.9430199430199431\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        21\n",
      "          1       0.85      1.00      0.92        39\n",
      "\n",
      "avg / total       0.90      0.88      0.88        60\n",
      "\n",
      "[14  7  0 39]\n",
      "LR Accuracy:  0.8833333333333333\n",
      "LR F1:  0.8588235294117648\n",
      "For name:  r_mckay\n",
      "total sample size before apply threshold:  53\n",
      "Counter({'0000-0001-7781-1539': 31, '0000-0003-2723-5371': 17, '0000-0002-5602-6985': 4, '0000-0001-8042-2462': 1})\n",
      "['0000-0001-7781-1539', '0000-0003-2723-5371']\n",
      "Total sample size after apply threshold:  48\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 30)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 17)\n",
      "2\n",
      "(48, 47)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.97      0.87        31\n",
      "          1       0.90      0.53      0.67        17\n",
      "\n",
      "avg / total       0.83      0.81      0.80        48\n",
      "\n",
      "[30  1  8  9]\n",
      "MNB Accuracy:  0.8125\n",
      "MNB F1:  0.7681159420289856\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.97      0.87        31\n",
      "          1       0.90      0.53      0.67        17\n",
      "\n",
      "avg / total       0.83      0.81      0.80        48\n",
      "\n",
      "[30  1  8  9]\n",
      "svc Accuracy:  0.8125\n",
      "svc F1:  0.7681159420289856\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84        31\n",
      "          1       1.00      0.29      0.45        17\n",
      "\n",
      "avg / total       0.82      0.75      0.70        48\n",
      "\n",
      "[31  0 12  5]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.6461916461916462\n",
      "For name:  d_sharma\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0001-7612-3486': 32, '0000-0002-0082-1285': 16, '0000-0003-4463-1480': 4, '0000-0001-7379-4233': 4, '0000-0001-5818-025X': 2, '0000-0002-2971-5013': 1, '0000-0001-5557-9388': 1})\n",
      "['0000-0001-7612-3486', '0000-0002-0082-1285']\n",
      "Total sample size after apply threshold:  48\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 23)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 13)\n",
      "2\n",
      "(48, 36)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94        32\n",
      "          1       0.93      0.81      0.87        16\n",
      "\n",
      "avg / total       0.92      0.92      0.92        48\n",
      "\n",
      "[31  1  3 13]\n",
      "MNB Accuracy:  0.9166666666666666\n",
      "MNB F1:  0.9030303030303031\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.94      0.92        32\n",
      "          1       0.87      0.81      0.84        16\n",
      "\n",
      "avg / total       0.89      0.90      0.89        48\n",
      "\n",
      "[30  2  3 13]\n",
      "svc Accuracy:  0.8958333333333334\n",
      "svc F1:  0.8808933002481389\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94        32\n",
      "          1       0.93      0.81      0.87        16\n",
      "\n",
      "avg / total       0.92      0.92      0.92        48\n",
      "\n",
      "[31  1  3 13]\n",
      "LR Accuracy:  0.9166666666666666\n",
      "LR F1:  0.9030303030303031\n",
      "For name:  a_wilson\n",
      "total sample size before apply threshold:  252\n",
      "Counter({'0000-0002-5045-2051': 61, '0000-0003-3679-9232': 48, '0000-0002-5016-4164': 36, '0000-0003-1098-8457': 35, '0000-0002-2000-2914': 27, '0000-0002-7696-1671': 10, '0000-0003-1325-8513': 9, '0000-0003-2352-5232': 7, '0000-0001-5865-6537': 7, '0000-0003-3362-7806': 4, '0000-0001-5775-6085': 3, '0000-0002-6473-7234': 2, '0000-0003-1461-6212': 2, '0000-0002-1015-3786': 1})\n",
      "['0000-0003-3679-9232', '0000-0002-5045-2051', '0000-0002-7696-1671', '0000-0002-5016-4164', '0000-0003-1098-8457', '0000-0002-2000-2914']\n",
      "Total sample size after apply threshold:  217\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(217, 104)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(217, 21)\n",
      "2\n",
      "(217, 125)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.75      0.64        48\n",
      "          1       0.54      0.85      0.66        61\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.81      0.61      0.70        36\n",
      "          4       0.84      0.46      0.59        35\n",
      "          5       0.50      0.15      0.23        27\n",
      "\n",
      "avg / total       0.61      0.60      0.57       217\n",
      "\n",
      "[36 12  0  0  0  0  4 52  1  1  1  2  1  7  0  0  0  2  5  7  0 22  2  0\n",
      " 10  6  0  3 16  0  8 13  1  1  0  4]\n",
      "MNB Accuracy:  0.5990783410138248\n",
      "MNB F1:  0.470110285089188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.88      0.70        48\n",
      "          1       0.70      0.79      0.74        61\n",
      "          2       0.20      0.20      0.20        10\n",
      "          3       0.78      0.58      0.67        36\n",
      "          4       0.86      0.51      0.64        35\n",
      "          5       0.72      0.48      0.58        27\n",
      "\n",
      "avg / total       0.69      0.66      0.66       217\n",
      "\n",
      "[42  5  1  0  0  0  5 48  4  2  0  2  0  6  2  0  0  2  6  5  0 21  3  1\n",
      " 10  2  2  3 18  0  9  3  1  1  0 13]\n",
      "svc Accuracy:  0.663594470046083\n",
      "svc F1:  0.5876271876271876\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.79      0.70        48\n",
      "          1       0.60      0.84      0.70        61\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.81      0.61      0.70        36\n",
      "          4       0.80      0.57      0.67        35\n",
      "          5       0.62      0.37      0.47        27\n",
      "\n",
      "avg / total       0.65      0.65      0.63       217\n",
      "\n",
      "[38  8  0  0  1  1  3 51  2  1  1  3  1  7  0  0  0  2  5  6  0 22  3  0\n",
      "  9  3  0  3 20  0  5 10  1  1  0 10]\n",
      "LR Accuracy:  0.6497695852534562\n",
      "LR F1:  0.5376789145929087\n",
      "For name:  f_marini\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0001-8266-1117': 37, '0000-0002-9495-2349': 12, '0000-0003-0747-5060': 12, '0000-0003-3252-7758': 4})\n",
      "['0000-0002-9495-2349', '0000-0003-0747-5060', '0000-0001-8266-1117']\n",
      "Total sample size after apply threshold:  61\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 32)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 18)\n",
      "2\n",
      "(61, 50)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.50      0.63        12\n",
      "          1       1.00      0.50      0.67        12\n",
      "          2       0.77      1.00      0.87        37\n",
      "\n",
      "avg / total       0.83      0.80      0.78        61\n",
      "\n",
      "[ 6  0  6  1  6  5  0  0 37]\n",
      "MNB Accuracy:  0.8032786885245902\n",
      "MNB F1:  0.7229446164430685\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.67      0.76        12\n",
      "          1       1.00      0.58      0.74        12\n",
      "          2       0.80      0.97      0.88        37\n",
      "\n",
      "avg / total       0.86      0.84      0.83        61\n",
      "\n",
      "[ 8  0  4  0  7  5  1  0 36]\n",
      "svc Accuracy:  0.8360655737704918\n",
      "svc F1:  0.7922652158852416\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.17      0.27        12\n",
      "          1       1.00      0.25      0.40        12\n",
      "          2       0.67      1.00      0.80        37\n",
      "\n",
      "avg / total       0.74      0.69      0.62        61\n",
      "\n",
      "[ 2  0 10  1  3  8  0  0 37]\n",
      "LR Accuracy:  0.6885245901639344\n",
      "LR F1:  0.4903381642512077\n",
      "For name:  h_tsai\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-9393-7155': 36, '0000-0003-1310-9980': 15, '0000-0002-4070-0058': 14, '0000-0002-9661-5848': 8, '0000-0002-7395-1603': 7, '0000-0003-2097-0170': 6, '0000-0003-1174-5473': 1, '0000-0001-8242-4939': 1, '0000-0001-6444-8814': 1, '0000-0002-4480-0240': 1, '0000-0001-8972-7174': 1, '0000-0003-3467-0507': 1, '0000-0003-3840-7853': 1})\n",
      "['0000-0002-4070-0058', '0000-0003-1310-9980', '0000-0002-9393-7155']\n",
      "Total sample size after apply threshold:  65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 36)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 20)\n",
      "2\n",
      "(65, 56)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.79      0.85        14\n",
      "          1       1.00      0.33      0.50        15\n",
      "          2       0.75      1.00      0.86        36\n",
      "\n",
      "avg / total       0.84      0.80      0.77        65\n",
      "\n",
      "[11  0  3  1  5  9  0  0 36]\n",
      "MNB Accuracy:  0.8\n",
      "MNB F1:  0.7344322344322345\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        14\n",
      "          1       1.00      0.40      0.57        15\n",
      "          2       0.75      1.00      0.86        36\n",
      "\n",
      "avg / total       0.86      0.82      0.80        65\n",
      "\n",
      "[11  0  3  0  6  9  0  0 36]\n",
      "svc Accuracy:  0.8153846153846154\n",
      "svc F1:  0.7695238095238096\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        14\n",
      "          1       0.67      0.13      0.22        15\n",
      "          2       0.67      1.00      0.80        36\n",
      "\n",
      "avg / total       0.74      0.71      0.65        65\n",
      "\n",
      "[ 8  1  5  0  2 13  0  0 36]\n",
      "LR Accuracy:  0.7076923076923077\n",
      "LR F1:  0.5831649831649832\n",
      "For name:  s_o'brien\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0001-7353-8301': 27, '0000-0003-3133-8920': 2, '0000-0001-8965-178X': 2, '0000-0002-2052-0762': 1})\n",
      "['0000-0001-7353-8301']\n",
      "Total sample size after apply threshold:  27\n",
      "For name:  c_webb\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0003-1031-3249': 16, '0000-0002-4094-2524': 15, '0000-0002-2538-6953': 3, '0000-0003-4164-9634': 1})\n",
      "['0000-0002-4094-2524', '0000-0003-1031-3249']\n",
      "Total sample size after apply threshold:  31\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(31, 22)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(31, 15)\n",
      "2\n",
      "(31, 37)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.60      0.58        15\n",
      "          1       0.60      0.56      0.58        16\n",
      "\n",
      "avg / total       0.58      0.58      0.58        31\n",
      "\n",
      "[9 6 7 9]\n",
      "MNB Accuracy:  0.5806451612903226\n",
      "MNB F1:  0.5806451612903225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.60      0.58        15\n",
      "          1       0.60      0.56      0.58        16\n",
      "\n",
      "avg / total       0.58      0.58      0.58        31\n",
      "\n",
      "[9 6 7 9]\n",
      "svc Accuracy:  0.5806451612903226\n",
      "svc F1:  0.5806451612903225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.60      0.60        15\n",
      "          1       0.62      0.62      0.62        16\n",
      "\n",
      "avg / total       0.61      0.61      0.61        31\n",
      "\n",
      "[ 9  6  6 10]\n",
      "LR Accuracy:  0.6129032258064516\n",
      "LR F1:  0.6125\n",
      "For name:  c_adams\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0003-2100-4417': 43, '0000-0001-5602-2741': 20, '0000-0002-7333-9908': 4, '0000-0003-1628-4020': 1, '0000-0002-0667-8088': 1})\n",
      "['0000-0003-2100-4417', '0000-0001-5602-2741']\n",
      "Total sample size after apply threshold:  63\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 31)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 18)\n",
      "2\n",
      "(63, 49)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.91      0.92        43\n",
      "          1       0.81      0.85      0.83        20\n",
      "\n",
      "avg / total       0.89      0.89      0.89        63\n",
      "\n",
      "[39  4  3 17]\n",
      "MNB Accuracy:  0.8888888888888888\n",
      "MNB F1:  0.8734576757532282\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        43\n",
      "          1       1.00      0.85      0.92        20\n",
      "\n",
      "avg / total       0.96      0.95      0.95        63\n",
      "\n",
      "[43  0  3 17]\n",
      "svc Accuracy:  0.9523809523809523\n",
      "svc F1:  0.9426055268751897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        43\n",
      "          1       1.00      0.75      0.86        20\n",
      "\n",
      "avg / total       0.93      0.92      0.92        63\n",
      "\n",
      "[43  0  5 15]\n",
      "LR Accuracy:  0.9206349206349206\n",
      "LR F1:  0.901098901098901\n",
      "For name:  c_peng\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0003-3666-9833': 79, '0000-0003-3332-184X': 10, '0000-0001-7943-9873': 7, '0000-0001-6090-2944': 5, '0000-0002-0800-1417': 2})\n",
      "['0000-0003-3666-9833', '0000-0003-3332-184X']\n",
      "Total sample size after apply threshold:  89\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 46)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 22)\n",
      "2\n",
      "(89, 68)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        79\n",
      "          1       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.98      0.98      0.98        89\n",
      "\n",
      "[79  0  2  8]\n",
      "MNB Accuracy:  0.9775280898876404\n",
      "MNB F1:  0.9381944444444446\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        79\n",
      "          1       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.98      0.98      0.98        89\n",
      "\n",
      "[79  0  2  8]\n",
      "svc Accuracy:  0.9775280898876404\n",
      "svc F1:  0.9381944444444446\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        79\n",
      "          1       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.94      0.93      0.92        89\n",
      "\n",
      "[79  0  6  4]\n",
      "LR Accuracy:  0.9325842696629213\n",
      "LR F1:  0.7674216027874565\n",
      "For name:  k_kobayashi\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0003-2951-1341': 17, '0000-0002-9475-6807': 8, '0000-0002-4642-1690': 7, '0000-0002-4163-9498': 2, '0000-0001-8842-469X': 1})\n",
      "['0000-0003-2951-1341']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  s_larsen\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0002-5170-4337': 31, '0000-0002-0838-9378': 11, '0000-0003-4570-9489': 10, '0000-0001-9522-7678': 9, '0000-0002-5134-3332': 4, '0000-0002-9056-6061': 2, '0000-0001-5836-370X': 1})\n",
      "['0000-0002-0838-9378', '0000-0002-5170-4337', '0000-0003-4570-9489']\n",
      "Total sample size after apply threshold:  52\n",
      "(0, 0)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 33)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 12)\n",
      "2\n",
      "(52, 45)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.73      0.64        11\n",
      "          1       0.69      0.77      0.73        31\n",
      "          2       0.67      0.20      0.31        10\n",
      "\n",
      "avg / total       0.66      0.65      0.63        52\n",
      "\n",
      "[ 8  3  0  6 24  1  0  8  2]\n",
      "MNB Accuracy:  0.6538461538461539\n",
      "MNB F1:  0.5583216783216783\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.64      0.74        11\n",
      "          1       0.77      0.97      0.86        31\n",
      "          2       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.84      0.81      0.80        52\n",
      "\n",
      "[ 7  4  0  1 30  0  0  5  5]\n",
      "svc Accuracy:  0.8076923076923077\n",
      "svc F1:  0.7535505430242272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.64      0.74        11\n",
      "          1       0.70      0.97      0.81        31\n",
      "          2       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.79      0.73      0.67        52\n",
      "\n",
      "[ 7  4  0  1 30  0  0  9  1]\n",
      "LR Accuracy:  0.7307692307692307\n",
      "LR F1:  0.5764903659640502\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# load the file\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "fileDir = \"../Data/\"+Dataset+\"/canopies_labeled/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "# collect statistic to output\n",
    "allname = []\n",
    "num_class = []\n",
    "per_class_count = []\n",
    "average_textual_size = []\n",
    "\n",
    "all_mnb_accuracy = []\n",
    "all_mnb_f1 = []\n",
    "all_svcLinear_accuracy = []\n",
    "all_svcLinear_f1 = []\n",
    "all_LR_accuracy = []\n",
    "all_LR_f1 = []\n",
    "\n",
    "# read all file in labeled group\n",
    "for file in listfiles:\n",
    "    # group name\n",
    "    temp = file.split(\"_\")\n",
    "    name = temp[1]+\"_\"+temp[-1]\n",
    "    print(\"For name: \",name)\n",
    "    allname.append(name)\n",
    "    # read needed content in labeled file\n",
    "    labeled_data = read_labeled_file(fileDir+file)\n",
    "    print(\"total sample size before apply threshold: \",len(labeled_data))\n",
    "    # count number of paper each author write based on author ID\n",
    "    paperCounter = collections.Counter(labeled_data[\"authorID\"])\n",
    "    print(paperCounter)\n",
    "    # collect per class statistic\n",
    "    for k in list(paperCounter):\n",
    "        if paperCounter[k] < threshold:\n",
    "            del paperCounter[k]\n",
    "    temp =list(paperCounter.keys())\n",
    "    print(temp)\n",
    "    per_class_count.append(paperCounter)\n",
    "    num_class.append(len(paperCounter))\n",
    "    # remove samples that are smaller than threshold\n",
    "    labeled_data = labeled_data[labeled_data.authorID.isin(temp)]\n",
    "    print(\"Total sample size after apply threshold: \",len(labeled_data))\n",
    "    # if only have one class or no class pass the threshold, not applicable\n",
    "    if(len(paperCounter)==0) or (len(paperCounter)==1):\n",
    "        average_textual_size.append(\"Not applicable\")\n",
    "        all_mnb_accuracy.append(\"Not applicable\")\n",
    "        all_mnb_f1.append(\"Not applicable\")\n",
    "        all_svcLinear_accuracy.append(\"Not applicable\")\n",
    "        all_svcLinear_f1.append(\"Not applicable\")\n",
    "        all_LR_accuracy.append(\"Not applicable\")\n",
    "        all_LR_f1.append(\"Not applicable\")\n",
    "    else:\n",
    "        # convert author id to label\n",
    "        gather_label = []\n",
    "        for index, record in labeled_data.iterrows():\n",
    "            gather_label.append(temp.index(record[\"authorID\"]))\n",
    "        labeled_data[\"label\"] = gather_label\n",
    "        # shuffle the data\n",
    "        labeled_data = labeled_data.sample(frac=1).reset_index(drop=True)\n",
    "        # extract true label and pid\n",
    "        label = labeled_data[\"label\"]\n",
    "        pid = labeled_data[\"paperID\"]\n",
    "        # list of different data field\n",
    "        part_collection = []\n",
    "        # data part 1, co-author matrix\n",
    "        data_part_co_author = co_author_to_vector(labeled_data[\"co-author\"], emb_type=coauthor_emb_type)\n",
    "        print(data_part_co_author.shape)\n",
    "        part_collection.append(data_part_co_author)\n",
    "        # data part 2.1, venue_id that author attend\n",
    "        data_part_venue = venue_to_vector(labeled_data[\"venue_id\"], emb_type=venue_emb_type)\n",
    "        print(data_part_venue.shape)\n",
    "        part_collection.append(data_part_venue)\n",
    "        # data part 2.2 year that author attend\n",
    "        data_part_year = year_to_vector(labeled_data[\"publish_year\"], emb_type=year_emb_type)\n",
    "        print(data_part_year.shape)\n",
    "        part_collection.append(data_part_year)\n",
    "        # merge different part of data data together by concatenate it all together\n",
    "        # remove empty emb (when emb set off)\n",
    "        part_collection = [part for part in part_collection if len(part)!=0]\n",
    "        print(len(part_collection))\n",
    "        if len(part_collection)>1:\n",
    "            combinedata = np.concatenate(part_collection,axis=1)\n",
    "        elif len(part_collection)==1:\n",
    "            if isinstance(part_collection[0], pd.DataFrame):\n",
    "                combinedata = part_collection[0].values\n",
    "            else:\n",
    "                combinedata = part_collection[0]\n",
    "        else:\n",
    "            print(\"No data available\")\n",
    "            break\n",
    "        print(combinedata.shape)\n",
    "        # using converted feature vector to train classifier\n",
    "        # using Multinomial naive bayes\n",
    "        clf = MultinomialNB()\n",
    "        # use 10 fold cv\n",
    "        mnbaccuracy, mnbmarcof1 = k_fold_cv(combinedata, label, clf, k=10)\n",
    "        print(\"MNB Accuracy: \",mnbaccuracy)\n",
    "        print(\"MNB F1: \", mnbmarcof1)\n",
    "        all_mnb_accuracy.append(mnbaccuracy)\n",
    "        all_mnb_f1.append(mnbmarcof1)\n",
    "        # using SVM with linear kernal\n",
    "        clf = SVC(decision_function_shape='ovr', kernel='linear')\n",
    "        svcaccuracy, svcmarcof1 = k_fold_cv(combinedata, label, clf, k=10)\n",
    "        print(\"svc Accuracy: \",svcaccuracy)\n",
    "        print(\"svc F1: \", svcmarcof1)\n",
    "        all_svcLinear_accuracy.append(svcaccuracy)\n",
    "        all_svcLinear_f1.append(svcmarcof1)\n",
    "        # using logistic regression\n",
    "        clf = LogisticRegression(multi_class='ovr')\n",
    "        LRaccuracy, LRmarcof1 = k_fold_cv(combinedata, label, clf, k=10)\n",
    "        print(\"LR Accuracy: \",LRaccuracy)\n",
    "        print(\"LR F1: \", LRmarcof1)\n",
    "        all_LR_accuracy.append(LRaccuracy)\n",
    "        all_LR_f1.append(LRmarcof1)\n",
    "    \n",
    "# write evaluation result to excel\n",
    "output = pd.DataFrame({'Name Group':allname,\"Class number\":num_class,\"per_class_size\":per_class_count, \n",
    "                       \"svc(linear) accuracy\":all_svcLinear_accuracy, \"svc(linear) macro f1\": all_svcLinear_f1, \n",
    "                       \"mnb accuracy\":all_mnb_accuracy, \"mnb macro f1\": all_mnb_f1,\n",
    "                       \"logistic regression accuracy\":all_LR_accuracy, \"logistic regression macro f1\": all_LR_f1})\n",
    "\n",
    "savePath = \"../result/\"+Dataset+\"/year_venue_only/\"\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "filename = \"2004_meta_\"+venue_emb_type+\"_threshold=\"+str(threshold)+\".csv\"\n",
    "output.to_csv(savePath+filename, encoding='utf-8',index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:38:01.216454Z",
     "start_time": "2018-12-02T02:38:01.173047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "784\n",
      "784\n",
      "0.7192512241904999\n",
      "0.77393245727873\n",
      "0.7259381668203747\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "from statistics import mean \n",
    "cleaned_mnb_accuracy = [x for x in all_mnb_accuracy if isinstance(x, float)]\n",
    "cleaned_svcLinear_accuracy = [x for x in all_svcLinear_accuracy if isinstance(x, float)]\n",
    "cleaned_lr_accuracy = [x for x in all_LR_accuracy if isinstance(x, float)]\n",
    "print(len(cleaned_mnb_accuracy))\n",
    "print(len(cleaned_svcLinear_accuracy))\n",
    "print(len(cleaned_lr_accuracy))\n",
    "print(mean(cleaned_mnb_accuracy))\n",
    "print(mean(cleaned_svcLinear_accuracy))\n",
    "print(mean(cleaned_lr_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:38:01.279775Z",
     "start_time": "2018-12-02T02:38:01.221355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "784\n",
      "784\n",
      "0.598677461782394\n",
      "0.7096296153254906\n",
      "0.5971807362010636\n"
     ]
    }
   ],
   "source": [
    "# f1\n",
    "from statistics import mean \n",
    "# remove string from result\n",
    "cleaned_mnb_f1 = [x for x in all_mnb_f1 if isinstance(x, float)]\n",
    "cleaned_svcLinear_f1 = [x for x in all_svcLinear_f1 if isinstance(x, float)]\n",
    "cleaned_lr_f1 = [x for x in all_LR_f1 if isinstance(x, float)]\n",
    "print(len(cleaned_mnb_f1))\n",
    "print(len(cleaned_svcLinear_f1))\n",
    "print(len(cleaned_lr_f1))\n",
    "print(mean(cleaned_mnb_f1))\n",
    "print(mean(cleaned_svcLinear_f1))\n",
    "print(mean(cleaned_lr_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-29T21:26:31.930Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%who"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
