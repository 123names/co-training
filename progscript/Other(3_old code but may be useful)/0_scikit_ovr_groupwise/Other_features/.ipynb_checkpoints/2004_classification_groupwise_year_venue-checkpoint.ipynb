{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:23.963072Z",
     "start_time": "2018-12-02T02:12:15.855457Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import com_func\n",
    "\n",
    "Dataset = \"pubmed\"\n",
    "\n",
    "# parameters\n",
    "threshold = 10\n",
    "cutoff = 3\n",
    "\n",
    "coauthor_emb_type = \"tf_idf\"\n",
    "venue_emb_type = \"off\"\n",
    "year_emb_type = \"off\"\n",
    "pp_textual_emb_type = \"off\"\n",
    "citation_emb_type = \"off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:19:24.632920Z",
     "start_time": "2018-12-02T02:19:24.583746Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy(doc):\n",
    "    return doc\n",
    "def read_labeled_file(infile):\n",
    "    LabeledRecords_original = []\n",
    "    with open(infile, 'r', encoding = 'utf8') as f:\n",
    "        for line in f:\n",
    "            read_data = line.split(\"\\t\")\n",
    "            # get ride of bad formated lines\n",
    "            if(len(read_data)==13 or len(read_data)==12):\n",
    "                paper_detail = {\"paperID\": read_data[0], \"authorID\":read_data[1], \n",
    "                                \"co-author\": read_data[5], \"venue_id\": read_data[7],\n",
    "                                \"publish_year\": read_data[10]}\n",
    "                LabeledRecords_original.append(paper_detail)\n",
    "            else:\n",
    "                print(len(read_data))\n",
    "        f.close()\n",
    "    return pd.DataFrame(LabeledRecords_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:24.057943Z",
     "start_time": "2018-12-02T02:12:24.020201Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSA(cleaned_token, dim=100):\n",
    "    # Tf-idf Transformation\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True, tokenizer=dummy,\n",
    "                                               preprocessor=dummy, stop_words = None,min_df=cutoff)\n",
    "    tfidfMatrix = tfidf_vectorizer.fit_transform(cleaned_token).toarray()\n",
    "    if(tfidfMatrix.shape[1]<dim):\n",
    "        dim = tfidfMatrix.shape[1] -1\n",
    "    # tf-idf + svd\n",
    "    svd = TruncatedSVD(n_components=dim)\n",
    "    final_lsa_Matrix = svd.fit_transform(tfidfMatrix)\n",
    "    print(svd.explained_variance_ratio_.sum())\n",
    "    return final_lsa_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:24.127563Z",
     "start_time": "2018-12-02T02:12:24.062441Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# co-author relation to frequence count\n",
    "def co_author_to_vector(raw_co_author_data, emb_type=\"off\"):\n",
    "    while True:\n",
    "        if emb_type == \"tf\":\n",
    "            co_author_vectorizer = CountVectorizer()\n",
    "            print(co_author_vectorizer)\n",
    "            result_vector = co_author_vectorizer.fit_transform(raw_co_author_data).toarray()\n",
    "            #print(co_author_vectorizer.get_feature_names())\n",
    "            #print(len(co_author_vectorizer.vocabulary_))\n",
    "            break\n",
    "        elif emb_type == \"tf_idf\":\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
    "                                               stop_words = None)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(raw_co_author_data).toarray()\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:24.195364Z",
     "start_time": "2018-12-02T02:12:24.132239Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# venue relation with author\n",
    "def venue_to_vector(raw_venue_id, emb_type=\"off\"):\n",
    "    while True:\n",
    "        if emb_type == \"tf\":\n",
    "            venue_count_vectorizer = CountVectorizer()\n",
    "            print(venue_count_vectorizer)\n",
    "            result_vector = venue_count_vectorizer.fit_transform(raw_venue_id).toarray()\n",
    "            #print(len(venue_count_vectorizer.vocabulary_))\n",
    "            break\n",
    "        elif emb_type == \"tf_idf\":\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
    "                                               stop_words = None)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(raw_co_author_data).toarray()\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:24.257723Z",
     "start_time": "2018-12-02T02:12:24.199938Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# author-year relation to emb\n",
    "def year_to_vector(raw_year, emb_type=\"off\"):\n",
    "    while True:\n",
    "        if emb_type == \"tf\":\n",
    "            count_vectorizer = CountVectorizer()\n",
    "            result_vector = count_vectorizer.fit_transform(raw_year).toarray()\n",
    "            #print(len(count_vectorizer.vocabulary_))\n",
    "            break\n",
    "        elif emb_type == \"tf_idf\":\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
    "                                               stop_words = None)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(raw_co_author_data).toarray()\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"tf\"\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:27.634494Z",
     "start_time": "2018-12-02T02:12:27.487428Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# document relation wrt textual content\n",
    "# convert raw text to numerical feature vectors\n",
    "# bow(Bags of words) are used with uni-gram setting\n",
    "def raw_text_to_vector(raw_textual_content, emb_type=\"off\", stopword=True):\n",
    "    cleaned_token, sample_size= com_func.clean_batch_of_raw(raw_textual_content, stopword=stopword)\n",
    "    average_sample_size = sum(sample_size)/len(sample_size)\n",
    "    print(\"Minimal sample size: \", min(sample_size))\n",
    "    print(\"maximal sample size: \", max(sample_size))\n",
    "    while True:\n",
    "        if emb_type == \"tf_idf\":\n",
    "            # using tf-idf\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True, tokenizer=dummy,\n",
    "                                               preprocessor=dummy, stop_words = None,min_df=cutoff)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(cleaned_token).toarray()\n",
    "            #print(len(tfidf_vectorizer.vocabulary_))\n",
    "            #print(tfidf_vectorizer.get_feature_names())\n",
    "            break\n",
    "        elif emb_type == \"tf\":\n",
    "            # Document-Term frequence Matrix\n",
    "            count_vectorizer = CountVectorizer(tokenizer=dummy,preprocessor=dummy, min_df=cutoff)\n",
    "            result_vector = count_vectorizer.fit_transform(cleaned_token).toarray()\n",
    "            break\n",
    "        elif emb_type == \"lsa\":\n",
    "            # use lsa\n",
    "            result_vector = LSA(cleaned_token, dim=100)\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return result_vector, average_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:30.672868Z",
     "start_time": "2018-12-02T02:12:30.555139Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "# cross validation\n",
    "def k_fold_cv(data, label, clf, k=10):\n",
    "    kf = KFold(n_splits=k, shuffle=False)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data[train_index], data[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        # fit data to clf\n",
    "        clf.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = clf.predict(data_test)\n",
    "        allTrueLabel.extend(label_test)\n",
    "        allPredLabel.extend(label_pred)\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "\n",
    "    accuracy = accuracy_score(allTrueLabel, allPredLabel)\n",
    "    f1 = f1_score(allTrueLabel, allPredLabel,average='macro')\n",
    "    \n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel).ravel())\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-02T02:25:03.748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For name:  j_read\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5159-1192': 57, '0000-0002-9029-5185': 39, '0000-0002-9697-0962': 31, '0000-0002-4739-9245': 3, '0000-0003-0605-5259': 3, '0000-0003-4316-7006': 1, '0000-0002-0784-0091': 1, '0000-0002-3888-6631': 1})\n",
      "['0000-0002-9697-0962', '0000-0002-9029-5185', '0000-0002-5159-1192']\n",
      "Total sample size after apply threshold:  127\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 263)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        31\n",
      "          1       0.90      0.69      0.78        39\n",
      "          2       0.77      0.98      0.86        57\n",
      "\n",
      "avg / total       0.86      0.84      0.84       127\n",
      "\n",
      "[24  2  5  0 27 12  0  1 56]\n",
      "MNB Accuracy:  0.84251968503937\n",
      "MNB F1:  0.8389581433059693\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        31\n",
      "          1       1.00      0.64      0.78        39\n",
      "          2       0.70      1.00      0.83        57\n",
      "\n",
      "avg / total       0.87      0.81      0.81       127\n",
      "\n",
      "[21  0 10  0 25 14  0  0 57]\n",
      "svc Accuracy:  0.8110236220472441\n",
      "svc F1:  0.8050097547380157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        31\n",
      "          1       1.00      0.54      0.70        39\n",
      "          2       0.64      1.00      0.78        57\n",
      "\n",
      "avg / total       0.84      0.75      0.74       127\n",
      "\n",
      "[17  0 14  0 21 18  0  0 57]\n",
      "LR Accuracy:  0.7480314960629921\n",
      "LR F1:  0.7297184170471841\n",
      "For name:  f_esteves\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-3046-1313': 18, '0000-0002-5403-0091': 12, '0000-0003-0589-0746': 3, '0000-0003-3172-6253': 1})\n",
      "['0000-0002-5403-0091', '0000-0002-3046-1313']\n",
      "Total sample size after apply threshold:  30\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(30, 63)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "30\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.89      0.87      0.86        30\n",
      "\n",
      "[ 8  4  0 18]\n",
      "MNB Accuracy:  0.8666666666666667\n",
      "MNB F1:  0.8500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.95      1.00      0.97        18\n",
      "\n",
      "avg / total       0.97      0.97      0.97        30\n",
      "\n",
      "[11  1  0 18]\n",
      "svc Accuracy:  0.9666666666666667\n",
      "svc F1:  0.9647473560517039\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.78      1.00      0.88        18\n",
      "\n",
      "avg / total       0.87      0.83      0.82        30\n",
      "\n",
      "[ 7  5  0 18]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.8074454428754814\n",
      "For name:  c_miller\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  252\n",
      "Counter({'0000-0003-4341-1283': 51, '0000-0002-3989-7973': 40, '0000-0002-3813-1706': 39, '0000-0003-2772-9531': 27, '0000-0001-6082-9273': 22, '0000-0002-2601-4422': 22, '0000-0002-9448-8144': 19, '0000-0001-8628-4902': 15, '0000-0002-2936-7717': 6, '0000-0003-3898-9734': 6, '0000-0002-5074-6914': 2, '0000-0003-4266-6700': 1, '0000-0002-9286-9787': 1, '0000-0002-0821-0892': 1})\n",
      "['0000-0003-4341-1283', '0000-0002-9448-8144', '0000-0003-2772-9531', '0000-0001-6082-9273', '0000-0002-3813-1706', '0000-0001-8628-4902', '0000-0002-3989-7973', '0000-0002-2601-4422']\n",
      "Total sample size after apply threshold:  235\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(235, 683)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      1.00      0.65        51\n",
      "          1       1.00      0.42      0.59        19\n",
      "          2       1.00      0.70      0.83        27\n",
      "          3       0.91      0.45      0.61        22\n",
      "          4       0.86      0.95      0.90        39\n",
      "          5       1.00      0.33      0.50        15\n",
      "          6       0.97      0.78      0.86        40\n",
      "          7       1.00      0.45      0.62        22\n",
      "\n",
      "avg / total       0.85      0.73      0.73       235\n",
      "\n",
      "[51  0  0  0  0  0  0  0  9  8  0  1  1  0  0  0  8  0 19  0  0  0  0  0\n",
      " 12  0  0 10  0  0  0  0  1  0  0  0 37  0  1  0  7  0  0  0  3  5  0  0\n",
      "  7  0  0  0  2  0 31  0 12  0  0  0  0  0  0 10]\n",
      "MNB Accuracy:  0.7276595744680852\n",
      "MNB F1:  0.6948574888661821\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      1.00      0.70        51\n",
      "          1       1.00      0.63      0.77        19\n",
      "          2       1.00      0.67      0.80        27\n",
      "          3       0.94      0.68      0.79        22\n",
      "          4       1.00      0.90      0.95        39\n",
      "          5       1.00      0.80      0.89        15\n",
      "          6       0.97      0.78      0.86        40\n",
      "          7       1.00      0.68      0.81        22\n",
      "\n",
      "avg / total       0.89      0.80      0.82       235\n",
      "\n",
      "[51  0  0  0  0  0  0  0  6 12  0  1  0  0  0  0  9  0 18  0  0  0  0  0\n",
      "  7  0  0 15  0  0  0  0  3  0  0  0 35  0  1  0  3  0  0  0  0 12  0  0\n",
      "  9  0  0  0  0  0 31  0  7  0  0  0  0  0  0 15]\n",
      "svc Accuracy:  0.8042553191489362\n",
      "svc F1:  0.8211317657925852\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      1.00      0.60        51\n",
      "          1       1.00      0.42      0.59        19\n",
      "          2       1.00      0.59      0.74        27\n",
      "          3       1.00      0.45      0.62        22\n",
      "          4       1.00      0.92      0.96        39\n",
      "          5       1.00      0.47      0.64        15\n",
      "          6       1.00      0.72      0.84        40\n",
      "          7       1.00      0.50      0.67        22\n",
      "\n",
      "avg / total       0.88      0.71      0.73       235\n",
      "\n",
      "[51  0  0  0  0  0  0  0 11  8  0  0  0  0  0  0 11  0 16  0  0  0  0  0\n",
      " 12  0  0 10  0  0  0  0  3  0  0  0 36  0  0  0  8  0  0  0  0  7  0  0\n",
      " 11  0  0  0  0  0 29  0 11  0  0  0  0  0  0 11]\n",
      "LR Accuracy:  0.7148936170212766\n",
      "LR F1:  0.7086173685171799\n",
      "For name:  r_jha\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0002-2891-8353': 6, '0000-0003-0332-2542': 3, '0000-0003-1877-1973': 1, '0000-0002-7755-7443': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  a_lowe\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0002-4691-8162': 69, '0000-0001-6650-7486': 22, '0000-0002-0558-3597': 10, '0000-0003-1139-2516': 1})\n",
      "['0000-0002-0558-3597', '0000-0002-4691-8162', '0000-0001-6650-7486']\n",
      "Total sample size after apply threshold:  101\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 262)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "101\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.83      1.00      0.91        69\n",
      "          2       1.00      0.82      0.90        22\n",
      "\n",
      "avg / total       0.79      0.86      0.82       101\n",
      "\n",
      "[ 0 10  0  0 69  0  0  4 18]\n",
      "MNB Accuracy:  0.8613861386138614\n",
      "MNB F1:  0.6026315789473684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.90      1.00      0.95        69\n",
      "          2       1.00      0.91      0.95        22\n",
      "\n",
      "avg / total       0.93      0.92      0.91       101\n",
      "\n",
      "[ 4  6  0  0 69  0  0  2 20]\n",
      "svc Accuracy:  0.9207920792079208\n",
      "svc F1:  0.8230050010871928\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.79      1.00      0.88        69\n",
      "          2       1.00      0.50      0.67        22\n",
      "\n",
      "avg / total       0.86      0.82      0.80       101\n",
      "\n",
      "[ 3  7  0  0 69  0  0 11 11]\n",
      "LR Accuracy:  0.8217821782178217\n",
      "LR F1:  0.6709401709401709\n",
      "For name:  a_vega\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-8207-9925': 10, '0000-0002-2178-2780': 8, '0000-0002-8148-5702': 1, '0000-0003-1082-0961': 1})\n",
      "['0000-0002-8207-9925']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  k_smith\n",
      "total sample size before apply threshold:  338\n",
      "Counter({'0000-0002-6736-4779': 133, '0000-0001-8088-566X': 75, '0000-0002-1323-627X': 29, '0000-0002-8914-6457': 23, '0000-0001-6828-7480': 19, '0000-0001-8150-5702': 15, '0000-0003-2793-3460': 14, '0000-0002-4530-6914': 13, '0000-0003-2802-4939': 8, '0000-0002-0932-1412': 4, '0000-0002-2424-6254': 1, '0000-0001-6957-5361': 1, '0000-0002-7807-2472': 1, '0000-0002-0346-2820': 1, '0000-0003-2060-9369': 1})\n",
      "['0000-0001-8150-5702', '0000-0002-1323-627X', '0000-0002-4530-6914', '0000-0002-6736-4779', '0000-0003-2793-3460', '0000-0002-8914-6457', '0000-0001-8088-566X', '0000-0001-6828-7480']\n",
      "Total sample size after apply threshold:  321\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(321, 719)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "321\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        15\n",
      "          1       1.00      0.93      0.96        29\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.71      0.98      0.83       133\n",
      "          4       1.00      0.50      0.67        14\n",
      "          5       1.00      0.61      0.76        23\n",
      "          6       0.91      0.84      0.87        75\n",
      "          7       1.00      0.68      0.81        19\n",
      "\n",
      "avg / total       0.82      0.82      0.80       321\n",
      "\n",
      "[  7   0   0   5   0   0   3   0   0  27   0   2   0   0   0   0   0   0\n",
      "   0  13   0   0   0   0   0   0   0 131   0   0   2   0   0   0   0   7\n",
      "   7   0   0   0   0   0   0   8   0  14   1   0   0   0   0  12   0   0\n",
      "  63   0   0   0   0   6   0   0   0  13]\n",
      "MNB Accuracy:  0.8161993769470405\n",
      "MNB F1:  0.6922588995982135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        15\n",
      "          1       1.00      0.93      0.96        29\n",
      "          2       1.00      0.38      0.56        13\n",
      "          3       0.80      0.99      0.89       133\n",
      "          4       1.00      0.64      0.78        14\n",
      "          5       1.00      0.96      0.98        23\n",
      "          6       0.98      0.87      0.92        75\n",
      "          7       1.00      0.79      0.88        19\n",
      "\n",
      "avg / total       0.92      0.90      0.89       321\n",
      "\n",
      "[ 13   0   0   2   0   0   0   0   0  27   0   2   0   0   0   0   0   0\n",
      "   5   8   0   0   0   0   0   0   0 132   0   0   1   0   0   0   0   5\n",
      "   9   0   0   0   0   0   0   1   0  22   0   0   0   0   0  10   0   0\n",
      "  65   0   0   0   0   4   0   0   0  15]\n",
      "svc Accuracy:  0.897196261682243\n",
      "svc F1:  0.8627533521888557\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        15\n",
      "          1       1.00      0.93      0.96        29\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.64      0.98      0.77       133\n",
      "          4       1.00      0.50      0.67        14\n",
      "          5       1.00      0.70      0.82        23\n",
      "          6       0.96      0.60      0.74        75\n",
      "          7       1.00      0.47      0.64        19\n",
      "\n",
      "avg / total       0.80      0.76      0.74       321\n",
      "\n",
      "[  9   0   0   6   0   0   0   0   0  27   0   2   0   0   0   0   0   0\n",
      "   0  13   0   0   0   0   0   0   0 131   0   0   2   0   0   0   0   7\n",
      "   7   0   0   0   0   0   0   7   0  16   0   0   0   0   0  30   0   0\n",
      "  45   0   0   0   0  10   0   0   0   9]\n",
      "LR Accuracy:  0.7601246105919003\n",
      "LR F1:  0.6693610774109106\n",
      "For name:  j_gordon\n",
      "total sample size before apply threshold:  19\n",
      "Counter({'0000-0002-0061-2168': 12, '0000-0001-9494-0586': 4, '0000-0001-7811-9245': 2, '0000-0002-5911-4219': 1})\n",
      "['0000-0002-0061-2168']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  s_liao\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0003-4129-0879': 46, '0000-0002-4312-5351': 43, '0000-0003-0943-0667': 10, '0000-0002-3122-8249': 2, '0000-0002-2372-9502': 1, '0000-0002-8872-2117': 1, '0000-0002-7339-2768': 1})\n",
      "['0000-0003-0943-0667', '0000-0003-4129-0879', '0000-0002-4312-5351']\n",
      "Total sample size after apply threshold:  99\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(99, 88)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.65      0.87      0.74        46\n",
      "          2       0.81      0.70      0.75        43\n",
      "\n",
      "avg / total       0.65      0.71      0.67        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  9  1  0 40  6  0 13 30]\n",
      "MNB Accuracy:  0.7070707070707071\n",
      "MNB F1:  0.49691358024691357\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.75      0.85      0.80        46\n",
      "          2       0.81      0.88      0.84        43\n",
      "\n",
      "avg / total       0.70      0.78      0.74        99\n",
      "\n",
      "[ 0  8  2  0 39  7  0  5 38]\n",
      "svc Accuracy:  0.7777777777777778\n",
      "svc F1:  0.5467876039304611\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.71      0.85      0.77        46\n",
      "          2       0.82      0.84      0.83        43\n",
      "\n",
      "avg / total       0.68      0.76      0.72        99\n",
      "\n",
      "[ 0  9  1  0 39  7  0  7 36]\n",
      "LR Accuracy:  0.7575757575757576\n",
      "LR F1:  0.5332878115397747\n",
      "For name:  j_qian\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-8793-9330': 6, '0000-0001-6145-045X': 6, '0000-0003-3162-2913': 1, '0000-0002-9522-6445': 1, '0000-0002-1325-6975': 1, '0000-0002-5438-0833': 1, '0000-0001-5043-020X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_bernardi\n",
      "total sample size before apply threshold:  91\n",
      "Counter({'0000-0001-5672-0881': 38, '0000-0002-7429-3075': 30, '0000-0002-1050-3096': 17, '0000-0001-6130-8533': 6})\n",
      "['0000-0002-7429-3075', '0000-0001-5672-0881', '0000-0002-1050-3096']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 403)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        30\n",
      "          1       0.90      1.00      0.95        38\n",
      "          2       1.00      0.65      0.79        17\n",
      "\n",
      "avg / total       0.94      0.93      0.92        85\n",
      "\n",
      "[30  0  0  0 38  0  2  4 11]\n",
      "MNB Accuracy:  0.9294117647058824\n",
      "MNB F1:  0.9011520737327189\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        30\n",
      "          1       0.90      1.00      0.95        38\n",
      "          2       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.96      0.95      0.95        85\n",
      "\n",
      "[30  0  0  0 38  0  0  4 13]\n",
      "svc Accuracy:  0.9529411764705882\n",
      "svc F1:  0.938888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        30\n",
      "          1       0.72      1.00      0.84        38\n",
      "          2       1.00      0.29      0.45        17\n",
      "\n",
      "avg / total       0.87      0.82      0.80        85\n",
      "\n",
      "[27  3  0  0 38  0  0 12  5]\n",
      "LR Accuracy:  0.8235294117647058\n",
      "LR F1:  0.7456929035876404\n",
      "For name:  t_hill\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0003-4159-9104': 7, '0000-0001-6996-9475': 3, '0000-0002-4125-7895': 2, '0000-0003-2980-4099': 2, '0000-0002-7995-9315': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_schindler\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-9991-9513': 26, '0000-0002-7054-5431': 13, '0000-0003-1028-3115': 6, '0000-0003-1378-0053': 5, '0000-0002-1755-4304': 1})\n",
      "['0000-0002-7054-5431', '0000-0002-9991-9513']\n",
      "Total sample size after apply threshold:  39\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 129)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.96      1.00      0.98        26\n",
      "\n",
      "avg / total       0.98      0.97      0.97        39\n",
      "\n",
      "[12  1  0 26]\n",
      "MNB Accuracy:  0.9743589743589743\n",
      "MNB F1:  0.9705660377358492\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.93      1.00      0.96        26\n",
      "\n",
      "avg / total       0.95      0.95      0.95        39\n",
      "\n",
      "[11  2  0 26]\n",
      "svc Accuracy:  0.9487179487179487\n",
      "svc F1:  0.9398148148148149\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.84      1.00      0.91        26\n",
      "\n",
      "avg / total       0.89      0.87      0.86        39\n",
      "\n",
      "[ 8  5  0 26]\n",
      "LR Accuracy:  0.8717948717948718\n",
      "LR F1:  0.837092731829574\n",
      "For name:  j_williams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  625\n",
      "Counter({'0000-0001-5188-7957': 141, '0000-0002-6063-7615': 82, '0000-0001-6665-6596': 79, '0000-0002-4688-3000': 66, '0000-0001-7152-765X': 51, '0000-0001-8251-4176': 28, '0000-0003-1235-5186': 26, '0000-0002-8883-7838': 25, '0000-0001-8331-3181': 20, '0000-0001-8377-5175': 15, '0000-0002-8861-0596': 14, '0000-0002-3804-2594': 14, '0000-0003-3815-0891': 14, '0000-0002-4497-4961': 10, '0000-0002-9801-9580': 9, '0000-0003-4400-5180': 5, '0000-0002-3500-914X': 5, '0000-0002-0195-6771': 4, '0000-0001-6105-0296': 3, '0000-0002-4681-3360': 3, '0000-0003-0161-0532': 3, '0000-0002-6511-1284': 3, '0000-0002-0195-5509': 2, '0000-0003-0500-1961': 2, '0000-0002-5355-3210': 1})\n",
      "['0000-0003-1235-5186', '0000-0002-8861-0596', '0000-0001-7152-765X', '0000-0001-6665-6596', '0000-0002-4497-4961', '0000-0002-6063-7615', '0000-0001-5188-7957', '0000-0002-3804-2594', '0000-0002-8883-7838', '0000-0001-8251-4176', '0000-0003-3815-0891', '0000-0001-8331-3181', '0000-0002-4688-3000', '0000-0001-8377-5175']\n",
      "Total sample size after apply threshold:  585\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(585, 1669)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        26\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       0.96      0.84      0.90        51\n",
      "          3       0.99      0.89      0.93        79\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.88      0.73      0.80        82\n",
      "          6       0.44      0.99      0.61       141\n",
      "          7       0.00      0.00      0.00        14\n",
      "          8       1.00      0.12      0.21        25\n",
      "          9       1.00      0.18      0.30        28\n",
      "         10       0.00      0.00      0.00        14\n",
      "         11       1.00      0.25      0.40        20\n",
      "         12       0.98      0.79      0.87        66\n",
      "         13       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.75      0.68      0.64       585\n",
      "\n",
      "[  8   0   0   0   0   1  17   0   0   0   0   0   0   0   0  12   0   0\n",
      "   0   0   2   0   0   0   0   0   0   0   0   0  43   0   0   0   8   0\n",
      "   0   0   0   0   0   0   0   0   1  70   0   0   8   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0\n",
      "   0   1   0  60  21   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      " 140   0   0   0   0   0   0   0   0   0   1   0   0   0  13   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1  20   0   3   0   0   0   1   0\n",
      "   0   0   0   0   0   0  23   0   0   5   0   0   0   0   0   0   0   0\n",
      "   0   1  13   0   0   0   0   0   0   0   0   0   0   0   0   2  13   0\n",
      "   0   0   0   5   0   0   0   0   0   0   0   0  14   0   0   0   0   0\n",
      "  52   0   0   0   0   0   0   2  13   0   0   0   0   0   0   0]\n",
      "MNB Accuracy:  0.6803418803418804\n",
      "MNB F1:  0.4591523221360682\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.85      0.90        26\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       1.00      0.82      0.90        51\n",
      "          3       1.00      0.84      0.91        79\n",
      "          4       1.00      0.40      0.57        10\n",
      "          5       0.85      0.77      0.81        82\n",
      "          6       0.61      1.00      0.76       141\n",
      "          7       1.00      0.43      0.60        14\n",
      "          8       1.00      0.80      0.89        25\n",
      "          9       0.95      0.64      0.77        28\n",
      "         10       1.00      0.50      0.67        14\n",
      "         11       1.00      0.80      0.89        20\n",
      "         12       0.98      0.88      0.93        66\n",
      "         13       1.00      0.33      0.50        15\n",
      "\n",
      "avg / total       0.88      0.82      0.82       585\n",
      "\n",
      "[ 22   0   0   0   0   0   3   0   0   0   0   0   1   0   0  12   0   0\n",
      "   0   0   2   0   0   0   0   0   0   0   0   0  42   0   0   0   9   0\n",
      "   0   0   0   0   0   0   1   0   0  66   0   1  11   0   0   0   0   0\n",
      "   0   0   0   0   0   0   4   0   5   0   0   1   0   0   0   0   0   0\n",
      "   0   0   0  63  19   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 141   0   0   0   0   0   0   0   0   0   0   0   0   2   6   6   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   5   0  20   0   0   0   0   0\n",
      "   0   0   0   0   0   2   8   0   0  18   0   0   0   0   0   0   0   0\n",
      "   0   2   5   0   0   0   7   0   0   0   0   0   0   0   0   1   3   0\n",
      "   0   0   0  16   0   0   0   0   0   0   0   0   8   0   0   0   0   0\n",
      "  58   0   0   0   0   0   0   3   7   0   0   0   0   0   0   5]\n",
      "svc Accuracy:  0.8205128205128205\n",
      "svc F1:  0.7862972630531296\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        26\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       0.98      0.82      0.89        51\n",
      "          3       1.00      0.85      0.92        79\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       1.00      0.70      0.82        82\n",
      "          6       0.45      1.00      0.62       141\n",
      "          7       1.00      0.07      0.13        14\n",
      "          8       1.00      0.44      0.61        25\n",
      "          9       1.00      0.25      0.40        28\n",
      "         10       0.00      0.00      0.00        14\n",
      "         11       1.00      0.65      0.79        20\n",
      "         12       0.98      0.71      0.82        66\n",
      "         13       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.80      0.70      0.69       585\n",
      "\n",
      "[ 14   0   0   0   0   0  12   0   0   0   0   0   0   0   0  12   0   0\n",
      "   0   0   2   0   0   0   0   0   0   0   0   0  42   0   0   0   9   0\n",
      "   0   0   0   0   0   0   0   0   0  67   0   0  12   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  57  25   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 141   0   0   0   0   0   0   0   0   0   1   0   0   0  12   1   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  13   0  11   0   0   0   1   0\n",
      "   0   0   0   0   0   0  21   0   0   7   0   0   0   0   0   0   0   0\n",
      "   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   7   0\n",
      "   0   0   0  13   0   0   0   0   0   0   0   0  19   0   0   0   0   0\n",
      "  47   0   0   0   0   0   0   0  15   0   0   0   0   0   0   0]\n",
      "LR Accuracy:  0.7042735042735043\n",
      "LR F1:  0.5452890886105058\n",
      "For name:  s_jacobson\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-9042-8750': 20, '0000-0002-3955-5746': 4, '0000-0002-4952-9007': 3, '0000-0001-9937-419X': 1})\n",
      "['0000-0002-9042-8750']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  e_andrade\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-1941-580X': 7, '0000-0001-7080-7035': 5, '0000-0003-2016-8305': 4, '0000-0002-5030-1675': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_santos\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0002-5365-4863': 18, '0000-0003-3765-5863': 14, '0000-0001-9072-5010': 3, '0000-0001-9947-6022': 2, '0000-0002-7694-306X': 2, '0000-0003-4171-5806': 1, '0000-0002-9744-0410': 1, '0000-0002-5325-3090': 1, '0000-0003-4620-0174': 1, '0000-0002-5738-4995': 1, '0000-0001-6892-0354': 1})\n",
      "['0000-0003-3765-5863', '0000-0002-5365-4863']\n",
      "Total sample size after apply threshold:  32\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 83)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        14\n",
      "          1       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.90      0.88      0.87        32\n",
      "\n",
      "[10  4  0 18]\n",
      "MNB Accuracy:  0.875\n",
      "MNB F1:  0.8666666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       1.00      1.00      1.00        18\n",
      "\n",
      "avg / total       1.00      1.00      1.00        32\n",
      "\n",
      "[14  0  0 18]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        14\n",
      "          1       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.90      0.88      0.87        32\n",
      "\n",
      "[10  4  0 18]\n",
      "LR Accuracy:  0.875\n",
      "LR F1:  0.8666666666666667\n",
      "For name:  k_kim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  1111\n",
      "Counter({'0000-0002-6929-5359': 211, '0000-0001-9498-284X': 154, '0000-0002-5878-8895': 139, '0000-0002-1864-3392': 92, '0000-0002-7045-8004': 57, '0000-0001-7896-6751': 57, '0000-0002-7991-9428': 55, '0000-0002-4010-1063': 45, '0000-0002-2186-3484': 28, '0000-0002-4899-1929': 25, '0000-0003-0487-4242': 24, '0000-0002-3642-1486': 22, '0000-0001-9965-3535': 17, '0000-0002-4168-757X': 17, '0000-0001-6525-3744': 14, '0000-0002-3897-0278': 14, '0000-0002-1181-5112': 12, '0000-0003-1447-9385': 11, '0000-0002-7305-8786': 11, '0000-0002-2655-7806': 10, '0000-0003-3466-5353': 9, '0000-0002-7359-663X': 8, '0000-0003-4600-8668': 6, '0000-0002-1382-7088': 5, '0000-0002-9505-4882': 5, '0000-0003-3667-9900': 4, '0000-0001-9714-6038': 4, '0000-0002-4760-0228': 3, '0000-0003-4188-7915': 3, '0000-0001-9454-0427': 3, '0000-0002-0333-6808': 3, '0000-0003-2134-4964': 3, '0000-0002-6658-047X': 3, '0000-0003-1273-379X': 3, '0000-0002-7047-3183': 3, '0000-0002-1814-9546': 3, '0000-0003-4812-6297': 2, '0000-0001-6597-578X': 2, '0000-0002-5285-9138': 2, '0000-0002-6796-7844': 2, '0000-0002-1130-8698': 2, '0000-0001-8518-8150': 2, '0000-0002-7103-924X': 2, '0000-0002-5407-0202': 1, '0000-0001-6220-8411': 1, '0000-0002-7440-6703': 1, '0000-0002-1603-7559': 1, '0000-0003-0257-1707': 1, '0000-0001-8532-6517': 1, '0000-0001-6626-316X': 1, '0000-0002-3246-9861': 1, '0000-0002-7207-4389': 1, '0000-0001-9682-9654': 1, '0000-0002-0196-3832': 1, '0000-0001-8063-6081': 1, '0000-0003-2037-3333': 1, '0000-0001-8872-6751': 1})\n",
      "['0000-0003-1447-9385', '0000-0001-6525-3744', '0000-0001-9498-284X', '0000-0002-3642-1486', '0000-0001-9965-3535', '0000-0002-7305-8786', '0000-0002-4899-1929', '0000-0002-6929-5359', '0000-0002-7045-8004', '0000-0002-2186-3484', '0000-0002-5878-8895', '0000-0002-4010-1063', '0000-0003-0487-4242', '0000-0001-7896-6751', '0000-0002-3897-0278', '0000-0002-7991-9428', '0000-0002-1864-3392', '0000-0002-4168-757X', '0000-0002-2655-7806', '0000-0002-1181-5112']\n",
      "Total sample size after apply threshold:  1015\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(1015, 674)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.39      0.84      0.53       154\n",
      "          3       0.00      0.00      0.00        22\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00        11\n",
      "          6       0.00      0.00      0.00        25\n",
      "          7       0.51      0.88      0.64       211\n",
      "          8       0.00      0.00      0.00        57\n",
      "          9       0.00      0.00      0.00        28\n",
      "         10       0.53      0.88      0.66       139\n",
      "         11       1.00      0.16      0.27        45\n",
      "         12       0.00      0.00      0.00        24\n",
      "         13       0.00      0.00      0.00        57\n",
      "         14       0.00      0.00      0.00        14\n",
      "         15       0.76      0.45      0.57        55\n",
      "         16       0.81      0.32      0.45        92\n",
      "         17       1.00      0.12      0.21        17\n",
      "         18       0.00      0.00      0.00        10\n",
      "         19       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.41      0.49      0.39      1015\n",
      "\n",
      "[  0   0   6   0   0   0   0   1   0   0   4   0   0   0   0   0   0   0\n",
      "   0   0   0   0   7   0   0   0   0   7   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 130   0   0   0   0  12   0   0  12   0   0   0\n",
      "   0   0   0   0   0   0   0   0  11   0   0   0   0   9   0   0   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   8   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   7\n",
      "   0   0   2   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0\n",
      "   0   2   0   0   2   0   0   0   0   0   0   0   0   0   0   0  17   0\n",
      "   0   0   0 186   0   0   8   0   0   0   0   0   0   0   0   0   0   0\n",
      "  13   0   0   0   0  23   0   0  21   0   0   0   0   0   0   0   0   0\n",
      "   0   0  10   0   0   0   0  15   0   0   3   0   0   0   0   0   0   0\n",
      "   0   0   0   0  11   0   0   0   0   3   0   0 123   0   0   0   0   0\n",
      "   2   0   0   0   0   0   9   0   0   0   0  27   0   0   1   7   0   1\n",
      "   0   0   0   0   0   0   0   0   7   0   0   0   0  17   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  24   0   0   0   0  13   0   0\n",
      "  18   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   7   0   0   0   0   7   0   0   0   0   0   0  18   0   0   0\n",
      "   0   2   0   0  10   0   0   0   0  25   0   0   0   0   0   0  30   0\n",
      "   0   0   0  17   0   0  16   0   0   0   0   0  29   0   0   0   0   0\n",
      "   0   0   0   0   0  11   0   0   0   0   0   0   0   0   4   2   0   0\n",
      "   0   0   7   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   4   0   0   0   0   5   0   0   3   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "MNB Accuracy:  0.4945812807881773\n",
      "MNB F1:  0.16686179855062339\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.82      0.75        11\n",
      "          1       1.00      0.64      0.78        14\n",
      "          2       0.70      0.80      0.75       154\n",
      "          3       0.75      0.27      0.40        22\n",
      "          4       1.00      0.47      0.64        17\n",
      "          5       0.50      0.09      0.15        11\n",
      "          6       0.83      0.80      0.82        25\n",
      "          7       0.58      0.89      0.70       211\n",
      "          8       0.59      0.33      0.43        57\n",
      "          9       0.64      0.32      0.43        28\n",
      "         10       0.77      0.79      0.78       139\n",
      "         11       0.85      0.51      0.64        45\n",
      "         12       1.00      0.33      0.50        24\n",
      "         13       0.70      0.53      0.60        57\n",
      "         14       0.67      0.29      0.40        14\n",
      "         15       0.73      0.75      0.74        55\n",
      "         16       0.59      0.66      0.62        92\n",
      "         17       1.00      0.53      0.69        17\n",
      "         18       1.00      0.80      0.89        10\n",
      "         19       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.71      0.68      0.66      1015\n",
      "\n",
      "[  9   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "   0   0   0   9   3   0   0   0   0   1   0   1   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 123   0   0   0   0  15   0   0   8   0   0   3\n",
      "   0   1   4   0   0   0   0   0   3   6   0   0   0   6   0   2   1   1\n",
      "   0   0   0   1   2   0   0   0   0   0   1   0   8   0   0   5   0   0\n",
      "   0   0   0   0   0   0   3   0   0   0   0   0   2   0   0   1   0   5\n",
      "   0   1   2   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0\n",
      "  20   0   2   0   0   0   0   0   0   0   1   0   0   0   0   0   7   0\n",
      "   0   0   0 188   2   1   1   0   0   2   0   1   9   0   0   0   1   0\n",
      "   6   0   0   0   1  16  19   0   5   0   0   2   0   0   7   0   0   0\n",
      "   0   0   1   1   0   0   1  14   0   9   0   2   0   0   0   0   0   0\n",
      "   0   0   0   0  10   0   0   0   0  14   1   0 110   0   0   0   0   1\n",
      "   3   0   0   0   0   0   7   0   0   0   0  10   1   0   0  23   0   3\n",
      "   0   0   1   0   0   0   0   0   0   0   0   0   0  10   0   0   0   1\n",
      "   8   0   0   0   5   0   0   0   3   0   2   0   0   0   0   8   4   0\n",
      "   4   0   0  30   0   1   5   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   4  10   0   0   0   0   0   0   3   0   0   0\n",
      "   0   4   0   0   3   0   0   1   2  41   1   0   0   0   0   0   3   1\n",
      "   0   0   2  14   3   0   6   0   0   2   0   0  61   0   0   0   0   0\n",
      "   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   9   0   0\n",
      "   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0\n",
      "   8   0   0   0   1   0   0   1   0   3   0   0   2   0   0   0   0   0\n",
      "   1   0   0   4]\n",
      "svc Accuracy:  0.6798029556650246\n",
      "svc F1:  0.6107175326813988\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82        11\n",
      "          1       1.00      0.50      0.67        14\n",
      "          2       0.67      0.78      0.72       154\n",
      "          3       1.00      0.09      0.17        22\n",
      "          4       1.00      0.24      0.38        17\n",
      "          5       0.00      0.00      0.00        11\n",
      "          6       0.90      0.72      0.80        25\n",
      "          7       0.50      0.91      0.65       211\n",
      "          8       0.65      0.26      0.38        57\n",
      "          9       0.62      0.29      0.39        28\n",
      "         10       0.69      0.85      0.76       139\n",
      "         11       0.86      0.40      0.55        45\n",
      "         12       1.00      0.29      0.45        24\n",
      "         13       0.71      0.39      0.50        57\n",
      "         14       0.60      0.21      0.32        14\n",
      "         15       0.74      0.67      0.70        55\n",
      "         16       0.65      0.58      0.61        92\n",
      "         17       1.00      0.06      0.11        17\n",
      "         18       1.00      0.60      0.75        10\n",
      "         19       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.67      0.63      0.60      1015\n",
      "\n",
      "[  9   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   7   3   0   0   0   0   4   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 120   0   0   0   0  16   0   0  13   0   0   2\n",
      "   0   1   2   0   0   0   0   0   2   2   0   0   0  11   0   2   3   0\n",
      "   0   0   0   1   1   0   0   0   0   0   2   0   4   0   0   9   0   0\n",
      "   0   0   0   0   0   0   2   0   0   0   0   0   1   0   0   0   0   6\n",
      "   0   1   2   0   0   0   0   0   1   0   0   0   0   0   4   0   0   0\n",
      "  18   2   1   0   0   0   0   0   0   0   0   0   0   0   0   0   7   0\n",
      "   0   0   0 192   0   1   2   0   0   2   0   0   7   0   0   0   0   0\n",
      "   6   0   0   0   0  18  15   1  10   0   0   2   0   0   5   0   0   0\n",
      "   0   0   2   0   0   0   0  16   1   8   0   0   0   1   0   0   0   0\n",
      "   0   0   0   0   6   0   0   0   0  13   0   0 118   0   0   0   0   0\n",
      "   2   0   0   0   0   0   4   0   0   0   0  20   0   0   0  18   0   2\n",
      "   0   0   1   0   0   0   0   0   1   0   0   0   0  12   0   0   0   1\n",
      "   7   0   0   0   3   0   0   0   2   0   6   0   0   0   0  11   3   0\n",
      "   8   1   0  22   0   2   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   2   0   0   0   3   9   0   0   0   0   0   0   5   0   0   0\n",
      "   0   8   0   0   2   0   0   0   2  37   1   0   0   0   0   0   4   0\n",
      "   0   0   2  22   3   0   8   0   0   0   0   0  53   0   0   0   0   0\n",
      "   0   0   0   0   0  16   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "   0   0   2   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0\n",
      "   6   0   0   0   1   0   0   0   0   6   0   0   2   1   0   0   0   0\n",
      "   2   0   0   0]\n",
      "LR Accuracy:  0.6305418719211823\n",
      "LR F1:  0.48588302691379964\n",
      "For name:  d_ricci\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0003-0015-6374': 26, '0000-0003-2853-4816': 12, '0000-0001-9678-904X': 1, '0000-0002-9790-0552': 1})\n",
      "['0000-0003-0015-6374', '0000-0003-2853-4816']\n",
      "Total sample size after apply threshold:  38\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 139)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        26\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        38\n",
      "\n",
      "[26  0  0 12]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        26\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97        38\n",
      "\n",
      "[26  0  1 11]\n",
      "svc Accuracy:  0.9736842105263158\n",
      "svc F1:  0.9688269073010665\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        26\n",
      "          1       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.91      0.89      0.89        38\n",
      "\n",
      "[26  0  4  8]\n",
      "LR Accuracy:  0.8947368421052632\n",
      "LR F1:  0.8642857142857143\n",
      "For name:  s_cameron\n",
      "total sample size before apply threshold:  66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'0000-0002-6694-4130': 41, '0000-0002-3050-7262': 16, '0000-0001-9570-135X': 7, '0000-0001-5680-2641': 2})\n",
      "['0000-0002-6694-4130', '0000-0002-3050-7262']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 173)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        41\n",
      "          1       0.94      1.00      0.97        16\n",
      "\n",
      "avg / total       0.98      0.98      0.98        57\n",
      "\n",
      "[40  1  0 16]\n",
      "MNB Accuracy:  0.9824561403508771\n",
      "MNB F1:  0.978675645342312\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        41\n",
      "          1       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00        57\n",
      "\n",
      "[41  0  0 16]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        41\n",
      "          1       1.00      0.62      0.77        16\n",
      "\n",
      "avg / total       0.91      0.89      0.89        57\n",
      "\n",
      "[41  0  6 10]\n",
      "LR Accuracy:  0.8947368421052632\n",
      "LR F1:  0.8505244755244756\n",
      "For name:  t_wright\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-5071-9978': 19, '0000-0002-5813-9991': 6, '0000-0001-8338-5935': 5, '0000-0001-7836-6705': 1})\n",
      "['0000-0001-5071-9978']\n",
      "Total sample size after apply threshold:  19\n",
      "For name:  r_cunha\n",
      "total sample size before apply threshold:  209\n",
      "Counter({'0000-0003-2550-6422': 151, '0000-0002-0203-3143': 24, '0000-0002-0849-3247': 12, '0000-0002-6622-7043': 12, '0000-0003-2228-5492': 8, '0000-0002-2382-7479': 2})\n",
      "['0000-0002-0849-3247', '0000-0002-6622-7043', '0000-0003-2550-6422', '0000-0002-0203-3143']\n",
      "Total sample size after apply threshold:  199\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(199, 473)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.76      1.00      0.87       151\n",
      "          3       1.00      0.04      0.08        24\n",
      "\n",
      "avg / total       0.70      0.76      0.67       199\n",
      "\n",
      "[  0   0  12   0   0   0  12   0   0   0 151   0   0   0  23   1]\n",
      "MNB Accuracy:  0.7638190954773869\n",
      "MNB F1:  0.2363323782234957\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29        12\n",
      "          1       1.00      0.33      0.50        12\n",
      "          2       0.83      1.00      0.91       151\n",
      "          3       1.00      0.46      0.63        24\n",
      "\n",
      "avg / total       0.87      0.84      0.81       199\n",
      "\n",
      "[  2   0  10   0   0   4   8   0   0   0 151   0   0   0  13  11]\n",
      "svc Accuracy:  0.8442211055276382\n",
      "svc F1:  0.5802981552981553\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.76      1.00      0.86       151\n",
      "          3       0.00      0.00      0.00        24\n",
      "\n",
      "avg / total       0.58      0.76      0.65       199\n",
      "\n",
      "[  0   0  12   0   0   0  12   0   0   0 151   0   0   0  24   0]\n",
      "LR Accuracy:  0.7587939698492462\n",
      "LR F1:  0.21571428571428572\n",
      "For name:  s_fuchs\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0002-1338-2699': 18, '0000-0001-9191-7970': 11, '0000-0002-0644-2876': 2, '0000-0001-7261-9214': 1})\n",
      "['0000-0001-9191-7970', '0000-0002-1338-2699']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 271)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.89      0.86      0.85        29\n",
      "\n",
      "[ 7  4  0 18]\n",
      "MNB Accuracy:  0.8620689655172413\n",
      "MNB F1:  0.8388888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.90      1.00      0.95        18\n",
      "\n",
      "avg / total       0.94      0.93      0.93        29\n",
      "\n",
      "[ 9  2  0 18]\n",
      "svc Accuracy:  0.9310344827586207\n",
      "svc F1:  0.9236842105263159\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.78      1.00      0.88        18\n",
      "\n",
      "avg / total       0.87      0.83      0.81        29\n",
      "\n",
      "[ 6  5  0 18]\n",
      "LR Accuracy:  0.8275862068965517\n",
      "LR F1:  0.7919655667144907\n",
      "For name:  m_nawaz\n",
      "total sample size before apply threshold:  9\n",
      "Counter({'0000-0002-0792-8296': 4, '0000-0001-9016-9229': 3, '0000-0003-4249-4259': 1, '0000-0003-3387-484X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  k_harris\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0001-8486-1219': 15, '0000-0002-5930-6456': 10, '0000-0003-1769-2587': 8, '0000-0002-1199-2856': 7, '0000-0003-2162-9652': 3, '0000-0003-0302-2523': 2, '0000-0001-5190-4219': 1, '0000-0003-2806-1262': 1})\n",
      "['0000-0002-5930-6456', '0000-0001-8486-1219']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  25\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 42)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.50      0.62        10\n",
      "          1       0.74      0.93      0.82        15\n",
      "\n",
      "avg / total       0.78      0.76      0.74        25\n",
      "\n",
      "[ 5  5  1 14]\n",
      "MNB Accuracy:  0.76\n",
      "MNB F1:  0.7242647058823529\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        10\n",
      "          1       1.00      0.93      0.97        15\n",
      "\n",
      "avg / total       0.96      0.96      0.96        25\n",
      "\n",
      "[10  0  1 14]\n",
      "svc Accuracy:  0.96\n",
      "svc F1:  0.9589490968801313\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.40      0.53        10\n",
      "          1       0.70      0.93      0.80        15\n",
      "\n",
      "avg / total       0.74      0.72      0.69        25\n",
      "\n",
      "[ 4  6  1 14]\n",
      "LR Accuracy:  0.72\n",
      "LR F1:  0.6666666666666667\n",
      "For name:  r_daniel\n",
      "total sample size before apply threshold:  173\n",
      "Counter({'0000-0002-8646-7925': 123, '0000-0002-6483-5897': 37, '0000-0001-8835-8047': 8, '0000-0002-1753-6683': 5})\n",
      "['0000-0002-8646-7925', '0000-0002-6483-5897']\n",
      "Total sample size after apply threshold:  160\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(160, 787)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "160\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       123\n",
      "          1       1.00      0.68      0.81        37\n",
      "\n",
      "avg / total       0.93      0.93      0.92       160\n",
      "\n",
      "[123   0  12  25]\n",
      "MNB Accuracy:  0.925\n",
      "MNB F1:  0.8799699924981246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96       123\n",
      "          1       1.00      0.76      0.86        37\n",
      "\n",
      "avg / total       0.95      0.94      0.94       160\n",
      "\n",
      "[123   0   9  28]\n",
      "svc Accuracy:  0.94375\n",
      "svc F1:  0.9131221719457014\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       123\n",
      "          1       1.00      0.38      0.55        37\n",
      "\n",
      "avg / total       0.88      0.86      0.83       160\n",
      "\n",
      "[123   0  23  14]\n",
      "LR Accuracy:  0.85625\n",
      "LR F1:  0.7317588745535388\n",
      "For name:  k_xu\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0002-2788-194X': 19, '0000-0003-2036-3469': 14, '0000-0002-3985-739X': 3, '0000-0001-7851-2629': 1})\n",
      "['0000-0003-2036-3469', '0000-0002-2788-194X']\n",
      "Total sample size after apply threshold:  33\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 76)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.90      1.00      0.95        19\n",
      "\n",
      "avg / total       0.95      0.94      0.94        33\n",
      "\n",
      "[12  2  0 19]\n",
      "MNB Accuracy:  0.9393939393939394\n",
      "MNB F1:  0.9365384615384615\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.90      1.00      0.95        19\n",
      "\n",
      "avg / total       0.95      0.94      0.94        33\n",
      "\n",
      "[12  2  0 19]\n",
      "svc Accuracy:  0.9393939393939394\n",
      "svc F1:  0.9365384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.90      1.00      0.95        19\n",
      "\n",
      "avg / total       0.95      0.94      0.94        33\n",
      "\n",
      "[12  2  0 19]\n",
      "LR Accuracy:  0.9393939393939394\n",
      "LR F1:  0.9365384615384615\n",
      "For name:  s_antunes\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-6686-9919': 35, '0000-0002-5512-9093': 12, '0000-0003-3218-3924': 4, '0000-0002-2264-3774': 3})\n",
      "['0000-0002-5512-9093', '0000-0002-6686-9919']\n",
      "Total sample size after apply threshold:  47\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 95)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.88      1.00      0.93        35\n",
      "\n",
      "avg / total       0.91      0.89      0.88        47\n",
      "\n",
      "[ 7  5  0 35]\n",
      "MNB Accuracy:  0.8936170212765957\n",
      "MNB F1:  0.8350877192982455\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        12\n",
      "          1       0.95      1.00      0.97        35\n",
      "\n",
      "avg / total       0.96      0.96      0.96        47\n",
      "\n",
      "[10  2  0 35]\n",
      "svc Accuracy:  0.9574468085106383\n",
      "svc F1:  0.9406565656565656\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.81      1.00      0.90        35\n",
      "\n",
      "avg / total       0.86      0.83      0.80        47\n",
      "\n",
      "[ 4  8  0 35]\n",
      "LR Accuracy:  0.8297872340425532\n",
      "LR F1:  0.6987179487179487\n",
      "For name:  k_cho\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0002-7751-0469': 55, '0000-0001-6586-983X': 47, '0000-0002-5782-6028': 15, '0000-0003-2555-5048': 6, '0000-0003-3818-9403': 1, '0000-0003-1154-4065': 1, '0000-0003-2926-3958': 1})\n",
      "['0000-0001-6586-983X', '0000-0002-7751-0469', '0000-0002-5782-6028']\n",
      "Total sample size after apply threshold:  117\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 148)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        47\n",
      "          1       0.82      1.00      0.90        55\n",
      "          2       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.76      0.87      0.81       117\n",
      "\n",
      "[47  0  0  0 55  0  3 12  0]\n",
      "MNB Accuracy:  0.8717948717948718\n",
      "MNB F1:  0.6235705030702495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        47\n",
      "          1       0.92      0.98      0.95        55\n",
      "          2       0.88      0.47      0.61        15\n",
      "\n",
      "avg / total       0.92      0.92      0.91       117\n",
      "\n",
      "[47  0  0  0 54  1  3  5  7]\n",
      "svc Accuracy:  0.9230769230769231\n",
      "svc F1:  0.841712079391666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        47\n",
      "          1       0.85      1.00      0.92        55\n",
      "          2       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.76      0.87      0.81       117\n",
      "\n",
      "[47  0  0  0 55  0  5 10  0]\n",
      "LR Accuracy:  0.8717948717948718\n",
      "LR F1:  0.6220538720538721\n",
      "For name:  j_sanderson\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-7023-8442': 24, '0000-0003-3326-9842': 3, '0000-0002-1206-8833': 2, '0000-0003-1000-2897': 1, '0000-0002-4726-4885': 1})\n",
      "['0000-0001-7023-8442']\n",
      "Total sample size after apply threshold:  24\n",
      "For name:  s_uddin\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0003-4698-2225': 13, '0000-0003-1886-6710': 8, '0000-0003-0091-6919': 8, '0000-0001-6045-6059': 8, '0000-0002-7285-4262': 2})\n",
      "['0000-0003-4698-2225']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  a_batista\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-6652-3988': 14, '0000-0003-1904-0531': 9, '0000-0003-1593-0174': 8, '0000-0002-5672-8266': 6, '0000-0001-7366-1254': 5, '0000-0002-7788-1753': 3, '0000-0002-9617-8094': 2, '0000-0002-2287-4265': 1})\n",
      "['0000-0001-6652-3988']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  h_pereira\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0003-1043-1675': 16, '0000-0002-5393-4443': 16, '0000-0002-1369-2099': 10, '0000-0003-4373-7005': 9, '0000-0002-7933-6097': 6, '0000-0002-0104-8714': 6, '0000-0002-1423-3038': 4, '0000-0001-9448-682X': 2, '0000-0002-3561-4980': 1})\n",
      "['0000-0003-1043-1675', '0000-0002-5393-4443', '0000-0002-1369-2099']\n",
      "Total sample size after apply threshold:  42\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 220)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.12        16\n",
      "          1       0.52      1.00      0.68        16\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.82      0.64      0.54        42\n",
      "\n",
      "[ 1 15  0  0 16  0  0  0 10]\n",
      "MNB Accuracy:  0.6428571428571429\n",
      "MNB F1:  0.5994993742177722\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.94      0.88        16\n",
      "          1       1.00      0.81      0.90        16\n",
      "          2       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.91      0.90      0.90        42\n",
      "\n",
      "[15  0  1  3 13  0  0  0 10]\n",
      "svc Accuracy:  0.9047619047619048\n",
      "svc F1:  0.9104285392317847\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.94      0.86        16\n",
      "          1       0.93      0.81      0.87        16\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.89      0.88      0.88        42\n",
      "\n",
      "[15  1  0  3 13  0  1  0  9]\n",
      "LR Accuracy:  0.8809523809523809\n",
      "LR F1:  0.8903926482873853\n",
      "For name:  a_patel\n",
      "total sample size before apply threshold:  262\n",
      "Counter({'0000-0003-1984-1400': 61, '0000-0001-7621-6463': 32, '0000-0002-6570-8582': 27, '0000-0003-1751-0421': 25, '0000-0002-3840-2473': 20, '0000-0002-5549-9166': 19, '0000-0001-7214-5901': 18, '0000-0003-0075-3304': 13, '0000-0003-3874-3216': 11, '0000-0002-7129-7548': 10, '0000-0002-4914-5062': 9, '0000-0002-3632-4977': 8, '0000-0001-8915-8995': 3, '0000-0003-3423-5134': 2, '0000-0002-2344-4179': 1, '0000-0001-7857-8724': 1, '0000-0003-4213-7454': 1, '0000-0002-9245-731X': 1})\n",
      "['0000-0002-6570-8582', '0000-0003-1751-0421', '0000-0002-5549-9166', '0000-0002-7129-7548', '0000-0003-3874-3216', '0000-0002-3840-2473', '0000-0001-7214-5901', '0000-0003-0075-3304', '0000-0003-1984-1400', '0000-0001-7621-6463']\n",
      "Total sample size after apply threshold:  236\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(236, 760)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        27\n",
      "          1       1.00      0.72      0.84        25\n",
      "          2       0.95      1.00      0.97        19\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.09      0.17        11\n",
      "          5       1.00      0.60      0.75        20\n",
      "          6       1.00      0.78      0.88        18\n",
      "          7       0.00      0.00      0.00        13\n",
      "          8       0.48      1.00      0.65        61\n",
      "          9       1.00      0.78      0.88        32\n",
      "\n",
      "avg / total       0.77      0.72      0.69       236\n",
      "\n",
      "[20  0  1  0  0  0  0  0  6  0  0 18  0  0  0  0  0  0  7  0  0  0 19  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  1  0  0  0\n",
      " 10  0  0  0  0  0  0 12  0  0  8  0  0  0  0  0  0  0 14  0  4  0  0  0\n",
      "  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0 61  0  0  0  0  0  0  0\n",
      "  0  0  7 25]\n",
      "MNB Accuracy:  0.7203389830508474\n",
      "MNB F1:  0.5983898172706896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        27\n",
      "          1       1.00      0.80      0.89        25\n",
      "          2       0.95      1.00      0.97        19\n",
      "          3       1.00      0.50      0.67        10\n",
      "          4       1.00      0.73      0.84        11\n",
      "          5       1.00      0.95      0.97        20\n",
      "          6       1.00      0.94      0.97        18\n",
      "          7       0.86      0.46      0.60        13\n",
      "          8       0.66      1.00      0.80        61\n",
      "          9       1.00      0.84      0.92        32\n",
      "\n",
      "avg / total       0.90      0.86      0.86       236\n",
      "\n",
      "[21  0  1  0  0  0  0  0  5  0  0 20  0  0  0  0  0  0  5  0  0  0 19  0\n",
      "  0  0  0  0  0  0  0  0  0  5  0  0  0  0  5  0  0  0  0  0  8  0  0  0\n",
      "  3  0  0  0  0  0  0 19  0  0  1  0  0  0  0  0  0  0 17  0  1  0  0  0\n",
      "  0  0  0  0  0  6  7  0  0  0  0  0  0  0  0  0 61  0  0  0  0  0  0  0\n",
      "  0  1  4 27]\n",
      "svc Accuracy:  0.8601694915254238\n",
      "svc F1:  0.8505447197063137\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        27\n",
      "          1       1.00      0.76      0.86        25\n",
      "          2       0.95      1.00      0.97        19\n",
      "          3       1.00      0.10      0.18        10\n",
      "          4       1.00      0.55      0.71        11\n",
      "          5       1.00      0.80      0.89        20\n",
      "          6       1.00      0.94      0.97        18\n",
      "          7       1.00      0.23      0.38        13\n",
      "          8       0.56      1.00      0.72        61\n",
      "          9       1.00      0.78      0.88        32\n",
      "\n",
      "avg / total       0.88      0.79      0.78       236\n",
      "\n",
      "[20  0  1  0  0  0  0  0  6  0  0 19  0  0  0  0  0  0  6  0  0  0 19  0\n",
      "  0  0  0  0  0  0  0  0  0  1  0  0  0  0  9  0  0  0  0  0  6  0  0  0\n",
      "  5  0  0  0  0  0  0 16  0  0  4  0  0  0  0  0  0  0 17  0  1  0  0  0\n",
      "  0  0  0  0  0  3 10  0  0  0  0  0  0  0  0  0 61  0  0  0  0  0  0  0\n",
      "  0  0  7 25]\n",
      "LR Accuracy:  0.7923728813559322\n",
      "LR F1:  0.7406917204139061\n",
      "For name:  r_graham\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0002-8686-4867': 41, '0000-0002-5530-8120': 9, '0000-0003-3082-8784': 1, '0000-0003-0103-2971': 1})\n",
      "['0000-0002-8686-4867']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  a_nilsson\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0001-5885-7101': 29, '0000-0002-5609-4988': 5, '0000-0002-1217-2163': 4, '0000-0002-9476-4516': 2, '0000-0001-5774-7189': 1, '0000-0003-1968-8696': 1})\n",
      "['0000-0001-5885-7101']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  m_soto\n",
      "total sample size before apply threshold:  97\n",
      "Counter({'0000-0002-4541-8182': 40, '0000-0003-2045-7238': 30, '0000-0002-4843-556X': 14, '0000-0002-2140-2012': 13})\n",
      "['0000-0002-4541-8182', '0000-0002-2140-2012', '0000-0002-4843-556X', '0000-0003-2045-7238']\n",
      "Total sample size after apply threshold:  97\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(97, 226)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        40\n",
      "          1       1.00      0.77      0.87        13\n",
      "          2       1.00      0.43      0.60        14\n",
      "          3       1.00      0.93      0.97        30\n",
      "\n",
      "avg / total       0.90      0.87      0.86        97\n",
      "\n",
      "[40  0  0  0  3 10  0  0  8  0  6  0  2  0  0 28]\n",
      "MNB Accuracy:  0.865979381443299\n",
      "MNB F1:  0.823824378133514\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        40\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       1.00      0.50      0.67        14\n",
      "          3       0.96      0.90      0.93        30\n",
      "\n",
      "avg / total       0.91      0.89      0.88        97\n",
      "\n",
      "[40  0  0  0  1 12  0  0  6  0  7  1  3  0  0 27]\n",
      "svc Accuracy:  0.8865979381443299\n",
      "svc F1:  0.8616475095785441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      1.00      0.82        40\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       1.00      0.36      0.53        14\n",
      "          3       1.00      0.87      0.93        30\n",
      "\n",
      "avg / total       0.87      0.81      0.80        97\n",
      "\n",
      "[40  0  0  0  5  8  0  0  9  0  5  0  4  0  0 26]\n",
      "LR Accuracy:  0.8144329896907216\n",
      "LR F1:  0.7582796276405299\n",
      "For name:  g_guidi\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0002-3061-9870': 15, '0000-0003-3199-6624': 11, '0000-0001-9535-9152': 5, '0000-0002-1393-326X': 4, '0000-0002-8857-0096': 2})\n",
      "['0000-0003-3199-6624', '0000-0002-3061-9870']\n",
      "Total sample size after apply threshold:  26\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 1492)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        11\n",
      "          1       0.93      0.93      0.93        15\n",
      "\n",
      "avg / total       0.92      0.92      0.92        26\n",
      "\n",
      "[10  1  1 14]\n",
      "MNB Accuracy:  0.9230769230769231\n",
      "MNB F1:  0.9212121212121211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        26\n",
      "\n",
      "[11  0  0 15]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        26\n",
      "\n",
      "[11  0  0 15]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  e_andersson\n",
      "total sample size before apply threshold:  138\n",
      "Counter({'0000-0002-7864-1014': 36, '0000-0003-0088-8719': 33, '0000-0002-2854-0354': 29, '0000-0003-3095-465X': 26, '0000-0001-5856-6806': 10, '0000-0002-8608-625X': 2, '0000-0001-8453-2079': 1, '0000-0003-3398-0132': 1})\n",
      "['0000-0001-5856-6806', '0000-0003-3095-465X', '0000-0002-2854-0354', '0000-0003-0088-8719', '0000-0002-7864-1014']\n",
      "Total sample size after apply threshold:  134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 375)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "134\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        10\n",
      "          1       1.00      0.81      0.89        26\n",
      "          2       0.88      1.00      0.94        29\n",
      "          3       0.97      1.00      0.99        33\n",
      "          4       0.80      1.00      0.89        36\n",
      "\n",
      "avg / total       0.91      0.90      0.87       134\n",
      "\n",
      "[ 1  0  1  1  7  0 21  3  0  2  0  0 29  0  0  0  0  0 33  0  0  0  0  0\n",
      " 36]\n",
      "MNB Accuracy:  0.8955223880597015\n",
      "MNB F1:  0.776976517963416\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.80      0.92      0.86        26\n",
      "          2       1.00      0.97      0.98        29\n",
      "          3       1.00      0.94      0.97        33\n",
      "          4       0.85      0.97      0.91        36\n",
      "\n",
      "avg / total       0.92      0.91      0.90       134\n",
      "\n",
      "[ 4  3  0  0  3  0 24  0  0  2  0  0 28  0  1  0  2  0 31  0  0  1  0  0\n",
      " 35]\n",
      "svc Accuracy:  0.9104477611940298\n",
      "svc F1:  0.8577736956026429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        10\n",
      "          1       1.00      0.85      0.92        26\n",
      "          2       1.00      0.93      0.96        29\n",
      "          3       1.00      0.97      0.98        33\n",
      "          4       0.69      1.00      0.82        36\n",
      "\n",
      "avg / total       0.92      0.88      0.86       134\n",
      "\n",
      "[ 1  0  0  0  9  0 22  0  0  4  0  0 27  0  2  0  0  0 32  1  0  0  0  0\n",
      " 36]\n",
      "LR Accuracy:  0.8805970149253731\n",
      "LR F1:  0.773113553113553\n",
      "For name:  s_reid\n",
      "total sample size before apply threshold:  132\n",
      "Counter({'0000-0001-9916-7414': 43, '0000-0002-6103-4429': 42, '0000-0001-7779-4820': 34, '0000-0002-8068-6529': 12, '0000-0001-9415-5246': 1})\n",
      "['0000-0001-7779-4820', '0000-0001-9916-7414', '0000-0002-8068-6529', '0000-0002-6103-4429']\n",
      "Total sample size after apply threshold:  131\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(131, 396)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        34\n",
      "          1       0.87      0.95      0.91        43\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       0.89      0.93      0.91        42\n",
      "\n",
      "avg / total       0.92      0.92      0.92       131\n",
      "\n",
      "[31  1  0  2  0 41  0  2  0  2  9  1  0  3  0 39]\n",
      "MNB Accuracy:  0.916030534351145\n",
      "MNB F1:  0.9072692165715421\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        34\n",
      "          1       1.00      0.91      0.95        43\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       0.81      1.00      0.89        42\n",
      "\n",
      "avg / total       0.94      0.92      0.93       131\n",
      "\n",
      "[30  0  0  4  0 39  0  4  0  0 10  2  0  0  0 42]\n",
      "svc Accuracy:  0.9236641221374046\n",
      "svc F1:  0.9228568606406566\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        34\n",
      "          1       1.00      0.91      0.95        43\n",
      "          2       1.00      0.67      0.80        12\n",
      "          3       0.78      1.00      0.88        42\n",
      "\n",
      "avg / total       0.93      0.91      0.91       131\n",
      "\n",
      "[30  0  0  4  0 39  0  4  0  0  8  4  0  0  0 42]\n",
      "LR Accuracy:  0.9083969465648855\n",
      "LR F1:  0.8909298780487804\n",
      "For name:  a_maleki\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0001-5490-3350': 15, '0000-0001-8261-8717': 5, '0000-0003-3203-7492': 4, '0000-0001-7888-1985': 1})\n",
      "['0000-0001-5490-3350']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  j_moon\n",
      "total sample size before apply threshold:  203\n",
      "Counter({'0000-0001-8071-1491': 96, '0000-0001-6327-0575': 23, '0000-0001-7776-6889': 19, '0000-0002-9182-5475': 17, '0000-0001-9760-297X': 13, '0000-0002-9274-4554': 12, '0000-0002-8625-6562': 8, '0000-0003-1282-4528': 7, '0000-0003-1569-3068': 2, '0000-0003-1428-414X': 2, '0000-0002-7049-892X': 1, '0000-0001-8246-931X': 1, '0000-0003-4742-8744': 1, '0000-0002-4630-3301': 1})\n",
      "['0000-0001-7776-6889', '0000-0002-9274-4554', '0000-0001-8071-1491', '0000-0001-9760-297X', '0000-0002-9182-5475', '0000-0001-6327-0575']\n",
      "Total sample size after apply threshold:  180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(180, 623)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "180\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.53      0.69        19\n",
      "          1       1.00      0.08      0.15        12\n",
      "          2       0.73      0.94      0.82        96\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       1.00      0.82      0.90        17\n",
      "          5       0.74      1.00      0.85        23\n",
      "\n",
      "avg / total       0.75      0.77      0.71       180\n",
      "\n",
      "[10  0  9  0  0  0  0  1 11  0  0  0  0  0 90  0  0  6  0  0 11  0  0  2\n",
      "  0  0  3  0 14  0  0  0  0  0  0 23]\n",
      "MNB Accuracy:  0.7666666666666667\n",
      "MNB F1:  0.5694601337908717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        19\n",
      "          1       1.00      0.42      0.59        12\n",
      "          2       0.81      0.94      0.87        96\n",
      "          3       0.83      0.38      0.53        13\n",
      "          4       1.00      0.88      0.94        17\n",
      "          5       0.79      1.00      0.88        23\n",
      "\n",
      "avg / total       0.86      0.84      0.83       180\n",
      "\n",
      "[14  0  5  0  0  0  0  5  7  0  0  0  0  0 90  1  0  5  0  0  7  5  0  1\n",
      "  0  0  2  0 15  0  0  0  0  0  0 23]\n",
      "svc Accuracy:  0.8444444444444444\n",
      "svc F1:  0.7757860890138114\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        19\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.71      0.96      0.81        96\n",
      "          3       1.00      0.08      0.14        13\n",
      "          4       1.00      0.88      0.94        17\n",
      "          5       0.81      0.91      0.86        23\n",
      "\n",
      "avg / total       0.75      0.76      0.71       180\n",
      "\n",
      "[ 8  0 11  0  0  0  0  0 12  0  0  0  0  0 92  0  0  4  0  0 11  1  0  1\n",
      "  0  0  2  0 15  0  0  0  2  0  0 21]\n",
      "LR Accuracy:  0.7611111111111111\n",
      "LR F1:  0.5573753141046651\n",
      "For name:  t_abe\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0003-3496-1953': 19, '0000-0002-4185-5254': 17, '0000-0001-5298-082X': 12, '0000-0003-1251-7448': 2})\n",
      "['0000-0002-4185-5254', '0000-0001-5298-082X', '0000-0003-3496-1953']\n",
      "Total sample size after apply threshold:  48\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 117)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        17\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       0.90      1.00      0.95        19\n",
      "\n",
      "avg / total       0.96      0.96      0.96        48\n",
      "\n",
      "[16  0  1  0 11  1  0  0 19]\n",
      "MNB Accuracy:  0.9583333333333334\n",
      "MNB F1:  0.9587395696091349\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        17\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       0.98      0.98      0.98        48\n",
      "\n",
      "[17  0  0  1 11  0  0  0 19]\n",
      "svc Accuracy:  0.9791666666666666\n",
      "svc F1:  0.975983436853002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        17\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       0.98      0.98      0.98        48\n",
      "\n",
      "[17  0  0  1 11  0  0  0 19]\n",
      "LR Accuracy:  0.9791666666666666\n",
      "LR F1:  0.975983436853002\n",
      "For name:  x_fu\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-6928-4396': 8, '0000-0001-9295-6314': 6, '0000-0002-8012-4753': 1, '0000-0002-4305-6624': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  f_ortega\n",
      "total sample size before apply threshold:  368\n",
      "Counter({'0000-0003-2001-1121': 205, '0000-0003-2111-769X': 86, '0000-0002-4730-9270': 38, '0000-0002-3172-2095': 22, '0000-0002-7431-354X': 9, '0000-0001-7850-2105': 7, '0000-0003-0231-2051': 1})\n",
      "['0000-0002-3172-2095', '0000-0003-2001-1121', '0000-0002-4730-9270', '0000-0003-2111-769X']\n",
      "Total sample size after apply threshold:  351\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(351, 723)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "351\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        22\n",
      "          1       0.93      0.99      0.96       205\n",
      "          2       1.00      0.92      0.96        38\n",
      "          3       0.97      1.00      0.98        86\n",
      "\n",
      "avg / total       0.95      0.95      0.94       351\n",
      "\n",
      "[  9  13   0   0   0 203   0   2   0   2  35   1   0   0   0  86]\n",
      "MNB Accuracy:  0.9487179487179487\n",
      "MNB F1:  0.8705543221102495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        22\n",
      "          1       0.94      1.00      0.97       205\n",
      "          2       1.00      0.92      0.96        38\n",
      "          3       1.00      0.95      0.98        86\n",
      "\n",
      "avg / total       0.97      0.97      0.97       351\n",
      "\n",
      "[ 17   5   0   0   0 205   0   0   0   3  35   0   0   4   0  82]\n",
      "svc Accuracy:  0.9658119658119658\n",
      "svc F1:  0.9446133596542607\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        22\n",
      "          1       0.88      1.00      0.93       205\n",
      "          2       1.00      0.87      0.93        38\n",
      "          3       1.00      0.90      0.94        86\n",
      "\n",
      "avg / total       0.93      0.92      0.91       351\n",
      "\n",
      "[  7  15   0   0   0 205   0   0   0   5  33   0   0   9   0  77]\n",
      "LR Accuracy:  0.9173789173789174\n",
      "LR F1:  0.8227655340098696\n",
      "For name:  r_morris\n",
      "total sample size before apply threshold:  409\n",
      "Counter({'0000-0001-7240-4563': 107, '0000-0001-7809-0315': 73, '0000-0001-8661-1520': 59, '0000-0002-7574-9388': 51, '0000-0003-3080-2613': 44, '0000-0002-5018-1239': 21, '0000-0001-7431-6401': 20, '0000-0001-7450-5923': 14, '0000-0001-5511-3457': 10, '0000-0003-4764-3639': 7, '0000-0001-7443-7406': 2, '0000-0002-9193-3417': 1})\n",
      "['0000-0003-3080-2613', '0000-0002-5018-1239', '0000-0001-7809-0315', '0000-0001-5511-3457', '0000-0001-7240-4563', '0000-0001-7431-6401', '0000-0002-7574-9388', '0000-0001-8661-1520', '0000-0001-7450-5923']\n",
      "Total sample size after apply threshold:  399\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(399, 1936)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "399\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.66      0.79        44\n",
      "          1       1.00      0.14      0.25        21\n",
      "          2       0.90      0.88      0.89        73\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.50      0.97      0.66       107\n",
      "          5       1.00      0.25      0.40        20\n",
      "          6       1.00      0.80      0.89        51\n",
      "          7       0.97      0.64      0.78        59\n",
      "          8       1.00      0.29      0.44        14\n",
      "\n",
      "avg / total       0.82      0.72      0.71       399\n",
      "\n",
      "[ 29   0   1   0  14   0   0   0   0   0   3   0   0  18   0   0   0   0\n",
      "   0   0  64   0   9   0   0   0   0   0   0   0   0  10   0   0   0   0\n",
      "   0   0   2   0 104   0   0   1   0   0   0   1   0  14   5   0   0   0\n",
      "   0   0   1   0   9   0  41   0   0   0   0   2   0  19   0   0  38   0\n",
      "   0   0   0   0  10   0   0   0   4]\n",
      "MNB Accuracy:  0.7218045112781954\n",
      "MNB F1:  0.5674543128168738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        44\n",
      "          1       1.00      0.86      0.92        21\n",
      "          2       0.94      0.88      0.91        73\n",
      "          3       1.00      0.80      0.89        10\n",
      "          4       0.82      0.95      0.88       107\n",
      "          5       1.00      0.70      0.82        20\n",
      "          6       1.00      0.76      0.87        51\n",
      "          7       0.66      0.92      0.77        59\n",
      "          8       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.89      0.86      0.87       399\n",
      "\n",
      "[ 34   0   0   0   5   0   0   5   0   0  18   0   0   1   0   0   2   0\n",
      "   0   0  64   0   3   0   0   6   0   0   0   0   8   2   0   0   0   0\n",
      "   0   0   2   0 102   0   0   3   0   0   0   1   0   4  14   0   1   0\n",
      "   0   0   0   0   3   0  39   9   0   0   0   1   0   4   0   0  54   0\n",
      "   0   0   0   0   1   0   0   2  11]\n",
      "svc Accuracy:  0.8621553884711779\n",
      "svc F1:  0.8674473302519855\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        44\n",
      "          1       1.00      0.52      0.69        21\n",
      "          2       0.95      0.86      0.91        73\n",
      "          3       1.00      0.30      0.46        10\n",
      "          4       0.57      0.98      0.72       107\n",
      "          5       1.00      0.55      0.71        20\n",
      "          6       1.00      0.78      0.88        51\n",
      "          7       1.00      0.68      0.81        59\n",
      "          8       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.88      0.79      0.80       399\n",
      "\n",
      "[ 32   0   0   0  12   0   0   0   0   0  11   0   0  10   0   0   0   0\n",
      "   0   0  63   0  10   0   0   0   0   0   0   0   3   7   0   0   0   0\n",
      "   0   0   2   0 105   0   0   0   0   0   0   0   0   9  11   0   0   0\n",
      "   0   0   0   0  11   0  40   0   0   0   0   1   0  18   0   0  40   0\n",
      "   0   0   0   0   3   0   0   0  11]\n",
      "LR Accuracy:  0.7919799498746867\n",
      "LR F1:  0.7659639703987275\n",
      "For name:  w_fang\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0002-8431-8256': 31, '0000-0002-9580-3716': 6, '0000-0002-2449-3749': 3, '0000-0002-9724-898X': 3})\n",
      "['0000-0002-8431-8256']\n",
      "Total sample size after apply threshold:  31\n",
      "For name:  m_amaral\n",
      "total sample size before apply threshold:  134\n",
      "Counter({'0000-0002-0828-8630': 101, '0000-0002-3209-3366': 21, '0000-0003-4966-2614': 6, '0000-0002-4301-2760': 4, '0000-0001-5607-6475': 1, '0000-0001-9686-1312': 1})\n",
      "['0000-0002-0828-8630', '0000-0002-3209-3366']\n",
      "Total sample size after apply threshold:  122\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(122, 442)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       101\n",
      "          1       1.00      0.43      0.60        21\n",
      "\n",
      "avg / total       0.91      0.90      0.88       122\n",
      "\n",
      "[101   0  12   9]\n",
      "MNB Accuracy:  0.9016393442622951\n",
      "MNB F1:  0.7719626168224298\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       101\n",
      "          1       0.95      0.86      0.90        21\n",
      "\n",
      "avg / total       0.97      0.97      0.97       122\n",
      "\n",
      "[100   1   3  18]\n",
      "svc Accuracy:  0.9672131147540983\n",
      "svc F1:  0.9401960784313725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       101\n",
      "          1       1.00      0.05      0.09        21\n",
      "\n",
      "avg / total       0.86      0.84      0.77       122\n",
      "\n",
      "[101   0  20   1]\n",
      "LR Accuracy:  0.8360655737704918\n",
      "LR F1:  0.5004095004095004\n",
      "For name:  h_song\n",
      "total sample size before apply threshold:  210\n",
      "Counter({'0000-0001-5684-4059': 88, '0000-0001-5553-2539': 30, '0000-0002-3134-782X': 29, '0000-0003-3845-8079': 20, '0000-0002-7844-2293': 14, '0000-0001-5486-2560': 8, '0000-0002-8720-6436': 6, '0000-0002-2721-3626': 2, '0000-0002-3563-9504': 2, '0000-0003-2197-1562': 2, '0000-0002-9849-8091': 2, '0000-0002-2164-8813': 2, '0000-0001-6000-1572': 1, '0000-0001-5747-8847': 1, '0000-0002-2791-1723': 1, '0000-0002-4204-6459': 1, '0000-0003-2631-9223': 1})\n",
      "['0000-0002-3134-782X', '0000-0002-7844-2293', '0000-0001-5684-4059', '0000-0001-5553-2539', '0000-0003-3845-8079']\n",
      "Total sample size after apply threshold:  181\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 1094)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "181\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        29\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.69      1.00      0.82        88\n",
      "          3       0.85      0.57      0.68        30\n",
      "          4       1.00      0.40      0.57        20\n",
      "\n",
      "avg / total       0.75      0.77      0.73       181\n",
      "\n",
      "[26  0  1  2  0  0  0 14  0  0  0  0 88  0  0  0  0 13 17  0  0  0 11  1\n",
      "  8]\n",
      "MNB Accuracy:  0.7679558011049724\n",
      "MNB F1:  0.6030975536091816\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        29\n",
      "          1       1.00      0.36      0.53        14\n",
      "          2       0.88      1.00      0.94        88\n",
      "          3       0.87      0.90      0.89        30\n",
      "          4       0.94      0.80      0.86        20\n",
      "\n",
      "avg / total       0.91      0.91      0.90       181\n",
      "\n",
      "[28  0  0  1  0  0  5  9  0  0  0  0 88  0  0  0  0  2 27  1  0  0  1  3\n",
      " 16]\n",
      "svc Accuracy:  0.9060773480662984\n",
      "svc F1:  0.8390105818189456\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        29\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.73      1.00      0.85        88\n",
      "          3       0.96      0.77      0.85        30\n",
      "          4       1.00      0.45      0.62        20\n",
      "\n",
      "avg / total       0.79      0.82      0.78       181\n",
      "\n",
      "[28  0  1  0  0  0  0 14  0  0  0  0 88  0  0  0  0  7 23  0  0  0 10  1\n",
      "  9]\n",
      "LR Accuracy:  0.8176795580110497\n",
      "LR F1:  0.6602302987057977\n",
      "For name:  h_dai\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0003-1395-7904': 2, '0000-0002-1516-7255': 2, '0000-0003-3807-4585': 1, '0000-0001-6165-4196': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  y_nakajima\n",
      "total sample size before apply threshold:  12\n",
      "Counter({'0000-0001-6558-5378': 8, '0000-0001-9759-3487': 2, '0000-0002-7153-6238': 1, '0000-0002-7357-2910': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_warner\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0003-3988-4408': 56, '0000-0003-0604-0110': 6, '0000-0003-1809-102X': 3, '0000-0001-8397-6030': 3})\n",
      "['0000-0003-3988-4408']\n",
      "Total sample size after apply threshold:  56\n",
      "For name:  s_saha\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0001-9433-8894': 24, '0000-0001-6610-4820': 23, '0000-0002-0087-8652': 14, '0000-0001-8780-9117': 12, '0000-0001-6631-0464': 8, '0000-0003-3029-7995': 5, '0000-0003-1060-9402': 5, '0000-0003-1534-7130': 4, '0000-0002-5791-8635': 3, '0000-0002-8312-6711': 3, '0000-0003-1742-2974': 2, '0000-0003-2366-8620': 2, '0000-0002-7184-6906': 2, '0000-0002-7487-9885': 1, '0000-0001-6844-2516': 1, '0000-0002-6655-4001': 1, '0000-0001-9742-3306': 1})\n",
      "['0000-0002-0087-8652', '0000-0001-8780-9117', '0000-0001-9433-8894', '0000-0001-6610-4820']\n",
      "Total sample size after apply threshold:  73\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 210)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        14\n",
      "          1       1.00      0.25      0.40        12\n",
      "          2       0.67      1.00      0.80        24\n",
      "          3       0.92      1.00      0.96        23\n",
      "\n",
      "avg / total       0.87      0.81      0.78        73\n",
      "\n",
      "[ 9  0  4  1  0  3  8  1  0  0 24  0  0  0  0 23]\n",
      "MNB Accuracy:  0.8082191780821918\n",
      "MNB F1:  0.7352355072463769\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.79      0.85        14\n",
      "          1       0.91      0.83      0.87        12\n",
      "          2       0.82      0.96      0.88        24\n",
      "          3       1.00      0.96      0.98        23\n",
      "\n",
      "avg / total       0.91      0.90      0.90        73\n",
      "\n",
      "[11  1  2  0  0 10  2  0  1  0 23  0  0  0  1 22]\n",
      "svc Accuracy:  0.9041095890410958\n",
      "svc F1:  0.8945280564845782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        14\n",
      "          1       1.00      0.33      0.50        12\n",
      "          2       0.63      1.00      0.77        24\n",
      "          3       0.95      0.91      0.93        23\n",
      "\n",
      "avg / total       0.86      0.79      0.78        73\n",
      "\n",
      "[ 9  0  5  0  0  4  7  1  0  0 24  0  0  0  2 21]\n",
      "LR Accuracy:  0.7945205479452054\n",
      "LR F1:  0.747533894343151\n",
      "For name:  j_fernandez\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0003-2222-3355': 7, '0000-0002-4190-7341': 5, '0000-0003-2969-8150': 5, '0000-0003-4756-6645': 5, '0000-0002-8533-1858': 1, '0000-0003-4427-3935': 1, '0000-0002-7315-2326': 1, '0000-0002-7629-6106': 1, '0000-0001-5894-9866': 1, '0000-0002-9528-6173': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_pan\n",
      "total sample size before apply threshold:  146\n",
      "Counter({'0000-0002-5188-7030': 128, '0000-0001-5535-2714': 10, '0000-0001-5697-6086': 6, '0000-0003-1485-3154': 1, '0000-0003-3350-8719': 1})\n",
      "['0000-0001-5535-2714', '0000-0002-5188-7030']\n",
      "Total sample size after apply threshold:  138\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(138, 119)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "138\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.93      1.00      0.96       128\n",
      "\n",
      "avg / total       0.86      0.93      0.89       138\n",
      "\n",
      "[  0  10   0 128]\n",
      "MNB Accuracy:  0.927536231884058\n",
      "MNB F1:  0.48120300751879697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.30      0.43        10\n",
      "          1       0.95      0.99      0.97       128\n",
      "\n",
      "avg / total       0.93      0.94      0.93       138\n",
      "\n",
      "[  3   7   1 127]\n",
      "svc Accuracy:  0.9420289855072463\n",
      "svc F1:  0.6990185387131951\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.93      1.00      0.96       128\n",
      "\n",
      "avg / total       0.86      0.93      0.89       138\n",
      "\n",
      "[  0  10   0 128]\n",
      "LR Accuracy:  0.927536231884058\n",
      "LR F1:  0.48120300751879697\n",
      "For name:  a_simon\n",
      "total sample size before apply threshold:  117\n",
      "Counter({'0000-0002-6141-7921': 60, '0000-0002-0151-0120': 19, '0000-0002-6509-4541': 14, '0000-0001-6023-6427': 14, '0000-0002-1879-5628': 5, '0000-0002-3286-5776': 4, '0000-0003-4641-6186': 1})\n",
      "['0000-0002-6141-7921', '0000-0002-6509-4541', '0000-0002-0151-0120', '0000-0001-6023-6427']\n",
      "Total sample size after apply threshold:  107\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 437)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "107\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        60\n",
      "          1       1.00      0.14      0.25        14\n",
      "          2       1.00      0.84      0.91        19\n",
      "          3       1.00      0.71      0.83        14\n",
      "\n",
      "avg / total       0.87      0.82      0.79       107\n",
      "\n",
      "[60  0  0  0 12  2  0  0  3  0 16  0  4  0  0 10]\n",
      "MNB Accuracy:  0.822429906542056\n",
      "MNB F1:  0.7152321000342583\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90        60\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       1.00      0.84      0.91        19\n",
      "          3       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.89      0.87      0.86       107\n",
      "\n",
      "[60  0  0  0  8  6  0  0  3  0 16  0  3  0  0 11]\n",
      "svc Accuracy:  0.8691588785046729\n",
      "svc F1:  0.8224520255863539\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82        60\n",
      "          1       1.00      0.07      0.13        14\n",
      "          2       1.00      0.63      0.77        19\n",
      "          3       1.00      0.57      0.73        14\n",
      "\n",
      "avg / total       0.83      0.76      0.71       107\n",
      "\n",
      "[60  0  0  0 13  1  0  0  7  0 12  0  6  0  0  8]\n",
      "LR Accuracy:  0.7570093457943925\n",
      "LR F1:  0.6141793543030838\n",
      "For name:  r_freitas\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0003-4900-3897': 48, '0000-0001-8605-2925': 6, '0000-0002-0123-7232': 6, '0000-0002-4448-6458': 5, '0000-0001-5811-5255': 5, '0000-0002-1645-4125': 2, '0000-0001-8836-1422': 1})\n",
      "['0000-0003-4900-3897']\n",
      "Total sample size after apply threshold:  48\n",
      "For name:  c_yun\n",
      "total sample size before apply threshold:  284\n",
      "Counter({'0000-0002-9466-4531': 149, '0000-0002-0041-2887': 98, '0000-0003-2204-8067': 36, '0000-0002-6747-4628': 1})\n",
      "['0000-0002-9466-4531', '0000-0002-0041-2887', '0000-0003-2204-8067']\n",
      "Total sample size after apply threshold:  283\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(283, 1324)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.97      0.86       149\n",
      "          1       0.88      0.84      0.86        98\n",
      "          2       0.00      0.00      0.00        36\n",
      "\n",
      "avg / total       0.71      0.80      0.75       283\n",
      "\n",
      "[145   4   0  15  82   1  29   7   0]\n",
      "MNB Accuracy:  0.8021201413427562\n",
      "MNB F1:  0.5722089697119902\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.93      0.89       149\n",
      "          1       0.86      0.93      0.89        98\n",
      "          2       0.79      0.31      0.44        36\n",
      "\n",
      "avg / total       0.85      0.85      0.83       283\n",
      "\n",
      "[139   8   2   6  91   1  18   7  11]\n",
      "svc Accuracy:  0.8515901060070671\n",
      "svc F1:  0.7410608345902464\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.95      0.86       149\n",
      "          1       0.89      0.86      0.88        98\n",
      "          2       0.83      0.14      0.24        36\n",
      "\n",
      "avg / total       0.82      0.82      0.78       283\n",
      "\n",
      "[142   6   1  14  84   0  27   4   5]\n",
      "LR Accuracy:  0.8162544169611308\n",
      "LR F1:  0.656172308280742\n",
      "For name:  j_huang\n",
      "total sample size before apply threshold:  443\n",
      "Counter({'0000-0001-8011-2317': 69, '0000-0001-9207-8953': 68, '0000-0001-5495-3577': 68, '0000-0002-2742-5557': 32, '0000-0001-8993-2506': 25, '0000-0002-7027-3042': 22, '0000-0003-3282-8892': 21, '0000-0003-0996-9451': 18, '0000-0002-7163-5156': 17, '0000-0002-4452-4557': 15, '0000-0001-7281-663X': 14, '0000-0002-4569-0629': 12, '0000-0002-5761-2177': 12, '0000-0002-9570-4101': 10, '0000-0001-9069-5739': 8, '0000-0001-9639-2907': 6, '0000-0002-0901-9635': 5, '0000-0003-4435-7274': 4, '0000-0002-4051-4482': 4, '0000-0002-5153-506X': 3, '0000-0001-7288-9724': 2, '0000-0003-1776-9863': 1, '0000-0003-2314-7104': 1, '0000-0002-7531-4691': 1, '0000-0001-8111-0583': 1, '0000-0001-6589-4963': 1, '0000-0002-6135-1256': 1, '0000-0002-5736-6148': 1, '0000-0002-4189-3779': 1})\n",
      "['0000-0003-3282-8892', '0000-0001-9207-8953', '0000-0001-8011-2317', '0000-0002-7163-5156', '0000-0001-7281-663X', '0000-0001-8993-2506', '0000-0002-9570-4101', '0000-0002-2742-5557', '0000-0002-4569-0629', '0000-0002-4452-4557', '0000-0002-7027-3042', '0000-0003-0996-9451', '0000-0002-5761-2177', '0000-0001-5495-3577']\n",
      "Total sample size after apply threshold:  403\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(403, 752)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "403\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        21\n",
      "          1       0.44      1.00      0.61        68\n",
      "          2       0.50      1.00      0.66        69\n",
      "          3       0.00      0.00      0.00        17\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       1.00      0.68      0.81        25\n",
      "          6       0.00      0.00      0.00        10\n",
      "          7       1.00      0.38      0.55        32\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.00      0.00      0.00        15\n",
      "         10       1.00      0.23      0.37        22\n",
      "         11       1.00      0.22      0.36        18\n",
      "         12       0.00      0.00      0.00        12\n",
      "         13       0.92      0.85      0.89        68\n",
      "\n",
      "avg / total       0.61      0.60      0.53       403\n",
      "\n",
      "[ 9 10  2  0  0  0  0  0  0  0  0  0  0  0  0 68  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 69  0  0  0  0  0  0  0  0  0  0  0  0 14  3  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  9  4  0  0  0  0  0  0  0  0  0  0  1  0  7\n",
      "  1  0  0 17  0  0  0  0  0  0  0  0  0  7  3  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 11  9  0  0  0  0 12  0  0  0  0  0  0  0  4  5  0  0  0  0  0\n",
      "  0  0  0  0  0  3  0  2 13  0  0  0  0  0  0  0  0  0  0  0  0  3 14  0\n",
      "  0  0  0  0  0  0  5  0  0  0  0 13  0  0  0  0  0  0  0  0  0  4  0  1\n",
      "  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  6  4  0  0  0  0  0  0  0\n",
      "  0  0  0 58]\n",
      "MNB Accuracy:  0.6004962779156328\n",
      "MNB F1:  0.3464682445189533\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        21\n",
      "          1       0.96      1.00      0.98        68\n",
      "          2       0.79      0.97      0.87        69\n",
      "          3       0.64      0.53      0.58        17\n",
      "          4       0.88      0.50      0.64        14\n",
      "          5       1.00      0.88      0.94        25\n",
      "          6       1.00      0.90      0.95        10\n",
      "          7       0.89      0.75      0.81        32\n",
      "          8       1.00      0.58      0.74        12\n",
      "          9       1.00      0.60      0.75        15\n",
      "         10       0.79      0.68      0.73        22\n",
      "         11       1.00      0.78      0.88        18\n",
      "         12       1.00      0.67      0.80        12\n",
      "         13       0.71      1.00      0.83        68\n",
      "\n",
      "avg / total       0.87      0.85      0.84       403\n",
      "\n",
      "[14  0  0  3  0  0  0  0  0  0  1  0  0  3  0 68  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 67  0  0  0  0  0  0  0  1  0  0  1  0  0  1  9  1  0\n",
      "  0  0  0  0  0  0  0  6  0  2  0  1  7  0  0  0  0  0  0  0  0  4  0  0\n",
      "  0  1  0 22  0  1  0  0  0  0  0  1  0  0  0  0  0  0  9  1  0  0  0  0\n",
      "  0  0  0  1  0  0  0  0  0 24  0  0  0  0  0  7  0  0  3  0  0  0  0  0\n",
      "  7  0  0  0  0  2  0  0  5  0  0  0  0  0  0  9  1  0  0  0  0  0  7  0\n",
      "  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  4\n",
      "  0  0  2  0  0  0  0  1  0  0  1  0  8  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 68]\n",
      "svc Accuracy:  0.8461538461538461\n",
      "svc F1:  0.8061051146316159\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.62      0.74        21\n",
      "          1       0.85      1.00      0.92        68\n",
      "          2       0.72      0.99      0.83        69\n",
      "          3       0.62      0.29      0.40        17\n",
      "          4       1.00      0.21      0.35        14\n",
      "          5       1.00      0.84      0.91        25\n",
      "          6       1.00      0.80      0.89        10\n",
      "          7       1.00      0.47      0.64        32\n",
      "          8       1.00      0.42      0.59        12\n",
      "          9       1.00      0.20      0.33        15\n",
      "         10       1.00      0.50      0.67        22\n",
      "         11       1.00      0.39      0.56        18\n",
      "         12       1.00      0.42      0.59        12\n",
      "         13       0.53      1.00      0.69        68\n",
      "\n",
      "avg / total       0.83      0.74      0.72       403\n",
      "\n",
      "[13  2  0  2  0  0  0  0  0  0  0  0  0  4  0 68  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 68  0  0  0  0  0  0  0  0  0  0  1  0  2  1  5  0  0\n",
      "  0  0  0  0  0  0  0  9  1  4  0  1  3  0  0  0  0  0  0  0  0  5  0  1\n",
      "  0  0  0 21  0  0  0  0  0  0  0  3  0  0  0  0  0  0  8  0  0  0  0  0\n",
      "  0  2  0  1  0  0  0  0  0 15  0  0  0  0  0 16  0  0  3  0  0  0  0  0\n",
      "  5  0  0  0  0  4  0  2  8  0  0  0  0  0  0  3  0  0  0  2  0  0  8  0\n",
      "  0  0  0  0  0  0 11  0  0  3  0  0  0  0  0  0  0  0  0  0  0  7  0 11\n",
      "  0  0  6  0  0  0  0  0  0  0  0  0  5  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 68]\n",
      "LR Accuracy:  0.7444168734491315\n",
      "LR F1:  0.6511520874387304\n",
      "For name:  p_santos\n",
      "total sample size before apply threshold:  92\n",
      "Counter({'0000-0003-3234-4265': 24, '0000-0002-2225-455X': 17, '0000-0003-3548-700X': 16, '0000-0001-9669-9837': 9, '0000-0002-8723-4373': 8, '0000-0002-2362-5527': 4, '0000-0002-3363-0098': 3, '0000-0003-3045-4591': 3, '0000-0001-7907-5133': 2, '0000-0002-4188-7766': 1, '0000-0002-0257-592X': 1, '0000-0003-2505-8420': 1, '0000-0002-2537-5904': 1, '0000-0003-1179-3096': 1, '0000-0001-9785-0180': 1})\n",
      "['0000-0003-3548-700X', '0000-0003-3234-4265', '0000-0002-2225-455X']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 158)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91        16\n",
      "          1       1.00      0.83      0.91        24\n",
      "          2       0.85      1.00      0.92        17\n",
      "\n",
      "avg / total       0.92      0.91      0.91        57\n",
      "\n",
      "[15  0  1  2 20  2  0  0 17]\n",
      "MNB Accuracy:  0.9122807017543859\n",
      "MNB F1:  0.9123669123669123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        16\n",
      "          1       0.96      0.92      0.94        24\n",
      "          2       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.95      0.95      0.95        57\n",
      "\n",
      "[15  1  0  1 22  1  0  0 17]\n",
      "svc Accuracy:  0.9473684210526315\n",
      "svc F1:  0.9483662613981764\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        16\n",
      "          1       0.96      0.96      0.96        24\n",
      "          2       0.94      0.94      0.94        17\n",
      "\n",
      "avg / total       0.95      0.95      0.95        57\n",
      "\n",
      "[15  0  1  1 23  0  0  1 16]\n",
      "LR Accuracy:  0.9473684210526315\n",
      "LR F1:  0.9456699346405228\n",
      "For name:  n_young\n",
      "total sample size before apply threshold:  182\n",
      "Counter({'0000-0002-1739-3299': 72, '0000-0001-8756-229X': 66, '0000-0002-3323-2815': 30, '0000-0002-3263-4847': 8, '0000-0002-9323-9437': 6})\n",
      "['0000-0001-8756-229X', '0000-0002-3323-2815', '0000-0002-1739-3299']\n",
      "Total sample size after apply threshold:  168\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(168, 615)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97        66\n",
      "          1       1.00      0.57      0.72        30\n",
      "          2       0.87      1.00      0.93        72\n",
      "\n",
      "avg / total       0.93      0.92      0.91       168\n",
      "\n",
      "[65  0  1  3 17 10  0  0 72]\n",
      "MNB Accuracy:  0.9166666666666666\n",
      "MNB F1:  0.8741952557050027\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98        66\n",
      "          1       1.00      0.70      0.82        30\n",
      "          2       0.89      1.00      0.94        72\n",
      "\n",
      "avg / total       0.95      0.94      0.94       168\n",
      "\n",
      "[65  0  1  1 21  8  0  0 72]\n",
      "svc Accuracy:  0.9404761904761905\n",
      "svc F1:  0.9165181224004754\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        66\n",
      "          1       1.00      0.43      0.60        30\n",
      "          2       0.73      1.00      0.84        72\n",
      "\n",
      "avg / total       0.88      0.84      0.83       168\n",
      "\n",
      "[56  0 10  0 13 17  0  0 72]\n",
      "LR Accuracy:  0.8392857142857143\n",
      "LR F1:  0.7882630709446127\n",
      "For name:  d_ross\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-8272-1877': 8, '0000-0002-8659-3833': 7, '0000-0001-7426-9561': 7, '0000-0002-5480-9978': 2, '0000-0001-6353-6951': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  q_wang\n",
      "total sample size before apply threshold:  348\n",
      "Counter({'0000-0002-2149-384X': 85, '0000-0001-7929-7692': 54, '0000-0001-9409-0251': 31, '0000-0002-7982-7275': 22, '0000-0001-5988-1293': 18, '0000-0002-5125-3724': 16, '0000-0002-6514-3470': 15, '0000-0002-1355-1616': 12, '0000-0001-7309-9580': 12, '0000-0002-2359-3262': 11, '0000-0002-0645-6514': 8, '0000-0002-9808-5035': 7, '0000-0002-4036-1818': 7, '0000-0001-7692-6721': 7, '0000-0001-8566-1120': 6, '0000-0002-6010-2178': 6, '0000-0002-9706-2421': 5, '0000-0003-2645-5807': 5, '0000-0002-6411-984X': 4, '0000-0003-3525-3422': 4, '0000-0002-8460-6821': 3, '0000-0003-3514-455X': 3, '0000-0002-0757-5208': 2, '0000-0001-7952-7101': 1, '0000-0001-5483-0243': 1, '0000-0002-6858-2778': 1, '0000-0003-3484-4810': 1, '0000-0003-3715-9106': 1})\n",
      "['0000-0002-2149-384X', '0000-0002-7982-7275', '0000-0002-2359-3262', '0000-0002-1355-1616', '0000-0001-5988-1293', '0000-0001-7309-9580', '0000-0001-9409-0251', '0000-0002-5125-3724', '0000-0001-7929-7692', '0000-0002-6514-3470']\n",
      "Total sample size after apply threshold:  276\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(276, 541)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.92      0.74        85\n",
      "          1       1.00      0.73      0.84        22\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       1.00      0.44      0.62        18\n",
      "          5       0.00      0.00      0.00        12\n",
      "          6       1.00      0.84      0.91        31\n",
      "          7       1.00      0.25      0.40        16\n",
      "          8       0.59      0.98      0.74        54\n",
      "          9       1.00      0.40      0.57        15\n",
      "\n",
      "avg / total       0.68      0.69      0.64       276\n",
      "\n",
      "[78  0  0  0  0  0  0  0  7  0  6 16  0  0  0  0  0  0  0  0 10  0  0  0\n",
      "  0  0  0  0  1  0 12  0  0  0  0  0  0  0  0  0  3  0  0  0  8  0  0  0\n",
      "  7  0  2  0  0  0  0  0  0  0 10  0  3  0  0  0  0  0 26  0  2  0  2  0\n",
      "  0  0  0  0  0  4 10  0  1  0  0  0  0  0  0  0 53  0  9  0  0  0  0  0\n",
      "  0  0  0  6]\n",
      "MNB Accuracy:  0.6920289855072463\n",
      "MNB F1:  0.48166467557275733\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.95      0.84        85\n",
      "          1       1.00      0.86      0.93        22\n",
      "          2       0.86      0.55      0.67        11\n",
      "          3       1.00      0.83      0.91        12\n",
      "          4       1.00      0.78      0.88        18\n",
      "          5       1.00      0.50      0.67        12\n",
      "          6       1.00      0.94      0.97        31\n",
      "          7       0.92      0.75      0.83        16\n",
      "          8       0.84      0.91      0.88        54\n",
      "          9       1.00      0.87      0.93        15\n",
      "\n",
      "avg / total       0.88      0.87      0.86       276\n",
      "\n",
      "[81  0  1  0  0  0  0  0  3  0  3 19  0  0  0  0  0  0  0  0  5  0  6  0\n",
      "  0  0  0  0  0  0  2  0  0 10  0  0  0  0  0  0  2  0  0  0 14  0  0  0\n",
      "  2  0  3  0  0  0  0  6  0  0  3  0  1  0  0  0  0  0 29  0  1  0  4  0\n",
      "  0  0  0  0  0 12  0  0  4  0  0  0  0  0  0  1 49  0  2  0  0  0  0  0\n",
      "  0  0  0 13]\n",
      "svc Accuracy:  0.8659420289855072\n",
      "svc F1:  0.8485827812851573\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.96      0.74        85\n",
      "          1       1.00      0.64      0.78        22\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.58      0.74        12\n",
      "          4       1.00      0.67      0.80        18\n",
      "          5       1.00      0.08      0.15        12\n",
      "          6       1.00      0.87      0.93        31\n",
      "          7       0.92      0.69      0.79        16\n",
      "          8       0.82      0.91      0.86        54\n",
      "          9       1.00      0.33      0.50        15\n",
      "\n",
      "avg / total       0.79      0.75      0.72       276\n",
      "\n",
      "[82  0  0  0  0  0  0  0  3  0  8 14  0  0  0  0  0  0  0  0 11  0  0  0\n",
      "  0  0  0  0  0  0  5  0  0  7  0  0  0  0  0  0  3  0  0  0 12  0  0  0\n",
      "  3  0  7  0  0  0  0  1  0  0  4  0  3  0  0  0  0  0 27  0  1  0  5  0\n",
      "  0  0  0  0  0 11  0  0  4  0  0  0  0  0  0  1 49  0 10  0  0  0  0  0\n",
      "  0  0  0  5]\n",
      "LR Accuracy:  0.7536231884057971\n",
      "LR F1:  0.6280289937135622\n",
      "For name:  c_cardoso\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-6239-6651': 15, '0000-0003-3645-5368': 12, '0000-0001-7273-0676': 10, '0000-0002-9339-8075': 8, '0000-0003-3323-4447': 4, '0000-0002-7527-3973': 2, '0000-0003-1914-9553': 1})\n",
      "['0000-0001-6239-6651', '0000-0001-7273-0676', '0000-0003-3645-5368']\n",
      "Total sample size after apply threshold:  37\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 101)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        15\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       0.92      0.92      0.92        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        37\n",
      "\n",
      "[14  0  1  0 10  0  1  0 11]\n",
      "MNB Accuracy:  0.9459459459459459\n",
      "MNB F1:  0.9500000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        15\n",
      "          1       1.00      0.90      0.95        10\n",
      "          2       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        37\n",
      "\n",
      "[15  0  0  1  9  0  1  0 11]\n",
      "svc Accuracy:  0.9459459459459459\n",
      "svc F1:  0.9471300533943555\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.91      0.89      0.89        37\n",
      "\n",
      "[15  0  0  3  7  0  1  0 11]\n",
      "LR Accuracy:  0.8918918918918919\n",
      "LR F1:  0.887468030690537\n",
      "For name:  j_matthews\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0002-9815-8636': 46, '0000-0001-6184-1813': 7, '0000-0002-5993-7610': 5, '0000-0002-1832-4420': 4, '0000-0002-7282-8929': 1, '0000-0002-6888-9438': 1, '0000-0002-3968-8282': 1})\n",
      "['0000-0002-9815-8636']\n",
      "Total sample size after apply threshold:  46\n",
      "For name:  g_lee\n",
      "total sample size before apply threshold:  202\n",
      "Counter({'0000-0001-6910-9133': 102, '0000-0002-8441-0802': 27, '0000-0001-7895-5112': 18, '0000-0002-3028-867X': 15, '0000-0001-6250-8852': 13, '0000-0002-7619-8979': 5, '0000-0002-4521-8957': 4, '0000-0003-0932-4418': 4, '0000-0003-4122-7976': 3, '0000-0002-4676-4554': 3, '0000-0002-3488-8963': 2, '0000-0002-8705-9210': 2, '0000-0002-8492-650X': 1, '0000-0002-8206-1151': 1, '0000-0002-2587-2775': 1, '0000-0002-6412-9482': 1})\n",
      "['0000-0001-6250-8852', '0000-0001-6910-9133', '0000-0002-3028-867X', '0000-0002-8441-0802', '0000-0001-7895-5112']\n",
      "Total sample size after apply threshold:  175\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 175)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.15      0.25        13\n",
      "          1       0.89      0.98      0.93       102\n",
      "          2       1.00      0.47      0.64        15\n",
      "          3       0.61      0.81      0.70        27\n",
      "          4       0.82      0.78      0.80        18\n",
      "\n",
      "avg / total       0.83      0.83      0.81       175\n",
      "\n",
      "[  2   1   0   8   2   0 100   0   2   0   0   7   7   1   0   1   3   0\n",
      "  22   1   0   1   0   3  14]\n",
      "MNB Accuracy:  0.8285714285714286\n",
      "MNB F1:  0.6638711548057342\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.93      0.98      0.96       102\n",
      "          2       1.00      0.80      0.89        15\n",
      "          3       0.79      0.85      0.82        27\n",
      "          4       1.00      0.83      0.91        18\n",
      "\n",
      "avg / total       0.93      0.93      0.93       175\n",
      "\n",
      "[ 12   0   0   1   0   0 100   0   2   0   0   3  12   0   0   0   4   0\n",
      "  23   0   0   0   0   3  15]\n",
      "svc Accuracy:  0.9257142857142857\n",
      "svc F1:  0.9072692336902863\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        13\n",
      "          1       0.79      0.98      0.88       102\n",
      "          2       1.00      0.20      0.33        15\n",
      "          3       0.84      0.78      0.81        27\n",
      "          4       1.00      0.78      0.88        18\n",
      "\n",
      "avg / total       0.86      0.83      0.81       175\n",
      "\n",
      "[  7   5   0   1   0   0 100   0   2   0   0  12   3   0   0   0   6   0\n",
      "  21   0   0   3   0   1  14]\n",
      "LR Accuracy:  0.8285714285714286\n",
      "LR F1:  0.7186437246963562\n",
      "For name:  m_salem\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-4955-0479': 12, '0000-0003-3214-3711': 9, '0000-0002-3961-7935': 3, '0000-0002-4189-857X': 1})\n",
      "['0000-0003-4955-0479']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  h_lai\n",
      "total sample size before apply threshold:  165\n",
      "Counter({'0000-0002-7958-2183': 146, '0000-0003-4334-0243': 10, '0000-0003-1834-4154': 6, '0000-0003-2521-0509': 2, '0000-0001-6044-8470': 1})\n",
      "['0000-0002-7958-2183', '0000-0003-4334-0243']\n",
      "Total sample size after apply threshold:  156\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(156, 151)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "156\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97       146\n",
      "          1       0.50      0.10      0.17        10\n",
      "\n",
      "avg / total       0.91      0.94      0.92       156\n",
      "\n",
      "[145   1   9   1]\n",
      "MNB Accuracy:  0.9358974358974359\n",
      "MNB F1:  0.5666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98       146\n",
      "          1       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.96      0.96      0.94       156\n",
      "\n",
      "[146   0   7   3]\n",
      "svc Accuracy:  0.9551282051282052\n",
      "svc F1:  0.7190635451505016\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       146\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.88      0.94      0.90       156\n",
      "\n",
      "[146   0  10   0]\n",
      "LR Accuracy:  0.9358974358974359\n",
      "LR F1:  0.48344370860927155\n",
      "For name:  r_harris\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0002-4377-5063': 26, '0000-0002-7943-5650': 8, '0000-0002-2636-1520': 6, '0000-0003-1787-7784': 3, '0000-0002-9247-0768': 3, '0000-0003-0954-1981': 2, '0000-0003-3322-1371': 2})\n",
      "['0000-0002-4377-5063']\n",
      "Total sample size after apply threshold:  26\n",
      "For name:  c_vaughan\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0003-4314-7689': 73, '0000-0003-3988-8222': 7, '0000-0001-8714-4442': 2, '0000-0001-9147-8648': 1})\n",
      "['0000-0003-4314-7689']\n",
      "Total sample size after apply threshold:  73\n",
      "For name:  e_thompson\n",
      "total sample size before apply threshold:  181\n",
      "Counter({'0000-0002-9723-4924': 163, '0000-0001-8633-2417': 9, '0000-0002-6434-9290': 4, '0000-0003-3506-0401': 2, '0000-0002-5615-2893': 2, '0000-0002-7115-0001': 1})\n",
      "['0000-0002-9723-4924']\n",
      "Total sample size after apply threshold:  163\n",
      "For name:  r_gomes\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-7155-0059': 15, '0000-0002-9197-8279': 10, '0000-0003-0278-4876': 10, '0000-0002-7242-6540': 6, '0000-0002-9012-3287': 6, '0000-0002-5984-0712': 4, '0000-0002-6375-7014': 1})\n",
      "['0000-0001-7155-0059', '0000-0002-9197-8279', '0000-0003-0278-4876']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 462)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        15\n",
      "          1       1.00      0.60      0.75        10\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.89      0.86      0.85        35\n",
      "\n",
      "[15  0  0  4  6  0  1  0  9]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.8515037593984962\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        15\n",
      "          1       0.82      0.90      0.86        10\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.92      0.91      0.92        35\n",
      "\n",
      "[14  1  0  1  9  0  0  1  9]\n",
      "svc Accuracy:  0.9142857142857143\n",
      "svc F1:  0.9126148705096074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.91      0.89      0.88        35\n",
      "\n",
      "[15  0  0  3  7  0  1  0  9]\n",
      "LR Accuracy:  0.8857142857142857\n",
      "LR F1:  0.8844169246646026\n",
      "For name:  r_bennett\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-7526-3425': 74, '0000-0002-7227-4831': 11, '0000-0002-5780-8786': 3, '0000-0002-3746-367X': 3, '0000-0002-5210-1386': 1, '0000-0002-1200-2068': 1})\n",
      "['0000-0002-7526-3425', '0000-0002-7227-4831']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 310)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        74\n",
      "          1       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.91      0.89      0.86        85\n",
      "\n",
      "[74  0  9  2]\n",
      "MNB Accuracy:  0.8941176470588236\n",
      "MNB F1:  0.6251837334639883\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99        74\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.99      0.99      0.99        85\n",
      "\n",
      "[74  0  1 10]\n",
      "svc Accuracy:  0.9882352941176471\n",
      "svc F1:  0.9728347714924896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        74\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.76      0.87      0.81        85\n",
      "\n",
      "[74  0 11  0]\n",
      "LR Accuracy:  0.8705882352941177\n",
      "LR F1:  0.46540880503144655\n",
      "For name:  m_collins\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-7656-4975': 20, '0000-0003-3785-6008': 14, '0000-0003-3969-5797': 9, '0000-0002-2312-3172': 6, '0000-0003-2536-4508': 6, '0000-0003-1641-848X': 2})\n",
      "['0000-0002-7656-4975', '0000-0003-3785-6008']\n",
      "Total sample size after apply threshold:  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 160)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        20\n",
      "          1       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.85      0.79      0.78        34\n",
      "\n",
      "[20  0  7  7]\n",
      "MNB Accuracy:  0.7941176470588235\n",
      "MNB F1:  0.7588652482269503\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        20\n",
      "          1       0.88      1.00      0.93        14\n",
      "\n",
      "avg / total       0.95      0.94      0.94        34\n",
      "\n",
      "[18  2  0 14]\n",
      "svc Accuracy:  0.9411764705882353\n",
      "svc F1:  0.9403508771929825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        20\n",
      "          1       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.85      0.79      0.78        34\n",
      "\n",
      "[20  0  7  7]\n",
      "LR Accuracy:  0.7941176470588235\n",
      "LR F1:  0.7588652482269503\n",
      "For name:  m_cowley\n",
      "total sample size before apply threshold:  132\n",
      "Counter({'0000-0001-7811-134X': 57, '0000-0002-9519-5714': 49, '0000-0003-0664-2891': 17, '0000-0001-8564-4224': 9})\n",
      "['0000-0003-0664-2891', '0000-0002-9519-5714', '0000-0001-7811-134X']\n",
      "Total sample size after apply threshold:  123\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(123, 775)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        17\n",
      "          1       0.95      0.82      0.88        49\n",
      "          2       0.74      0.96      0.84        57\n",
      "\n",
      "avg / total       0.86      0.83      0.82       123\n",
      "\n",
      "[ 7  0 10  0 40  9  0  2 55]\n",
      "MNB Accuracy:  0.8292682926829268\n",
      "MNB F1:  0.767382956314254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        17\n",
      "          1       0.96      0.88      0.91        49\n",
      "          2       0.90      0.96      0.93        57\n",
      "\n",
      "avg / total       0.94      0.93      0.93       123\n",
      "\n",
      "[17  0  0  0 43  6  0  2 55]\n",
      "svc Accuracy:  0.9349593495934959\n",
      "svc F1:  0.9490323356172617\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.38        17\n",
      "          1       0.95      0.84      0.89        49\n",
      "          2       0.72      0.96      0.83        57\n",
      "\n",
      "avg / total       0.85      0.81      0.79       123\n",
      "\n",
      "[ 4  0 13  0 41  8  0  2 55]\n",
      "LR Accuracy:  0.8130081300813008\n",
      "LR F1:  0.6997747993171334\n",
      "For name:  p_teixeira\n",
      "total sample size before apply threshold:  213\n",
      "Counter({'0000-0002-7258-7977': 60, '0000-0002-6296-5137': 55, '0000-0001-7202-0527': 48, '0000-0003-2315-2261': 26, '0000-0003-2735-6608': 22, '0000-0002-7596-9735': 1, '0000-0002-1593-8064': 1})\n",
      "['0000-0001-7202-0527', '0000-0002-7258-7977', '0000-0003-2315-2261', '0000-0003-2735-6608', '0000-0002-6296-5137']\n",
      "Total sample size after apply threshold:  211\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(211, 378)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        48\n",
      "          1       0.94      1.00      0.97        60\n",
      "          2       1.00      0.62      0.76        26\n",
      "          3       1.00      0.86      0.93        22\n",
      "          4       0.76      1.00      0.87        55\n",
      "\n",
      "avg / total       0.92      0.90      0.90       211\n",
      "\n",
      "[40  0  0  0  8  0 60  0  0  0  0  4 16  0  6  0  0  0 19  3  0  0  0  0\n",
      " 55]\n",
      "MNB Accuracy:  0.9004739336492891\n",
      "MNB F1:  0.886341721411138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        48\n",
      "          1       1.00      0.98      0.99        60\n",
      "          2       0.95      0.73      0.83        26\n",
      "          3       1.00      0.86      0.93        22\n",
      "          4       1.00      1.00      1.00        55\n",
      "\n",
      "avg / total       0.95      0.95      0.95       211\n",
      "\n",
      "[48  0  0  0  0  1 59  0  0  0  7  0 19  0  0  2  0  1 19  0  0  0  0  0\n",
      " 55]\n",
      "svc Accuracy:  0.9478672985781991\n",
      "svc F1:  0.9300346481656749\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        48\n",
      "          1       1.00      1.00      1.00        60\n",
      "          2       1.00      0.62      0.76        26\n",
      "          3       1.00      0.91      0.95        22\n",
      "          4       0.73      1.00      0.85        55\n",
      "\n",
      "avg / total       0.93      0.91      0.90       211\n",
      "\n",
      "[40  0  0  0  8  0 60  0  0  0  0  0 16  0 10  0  0  0 20  2  0  0  0  0\n",
      " 55]\n",
      "LR Accuracy:  0.9052132701421801\n",
      "LR F1:  0.8939060939060939\n",
      "For name:  c_cox\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0002-4927-979X': 24, '0000-0003-0625-328X': 21, '0000-0003-1074-3839': 2, '0000-0002-4486-0681': 1})\n",
      "['0000-0003-0625-328X', '0000-0002-4927-979X']\n",
      "Total sample size after apply threshold:  45\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 210)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        21\n",
      "          1       0.92      1.00      0.96        24\n",
      "\n",
      "avg / total       0.96      0.96      0.96        45\n",
      "\n",
      "[19  2  0 24]\n",
      "MNB Accuracy:  0.9555555555555556\n",
      "MNB F1:  0.9550000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        21\n",
      "          1       0.92      1.00      0.96        24\n",
      "\n",
      "avg / total       0.96      0.96      0.96        45\n",
      "\n",
      "[19  2  0 24]\n",
      "svc Accuracy:  0.9555555555555556\n",
      "svc F1:  0.9550000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        21\n",
      "          1       0.86      1.00      0.92        24\n",
      "\n",
      "avg / total       0.92      0.91      0.91        45\n",
      "\n",
      "[17  4  0 24]\n",
      "LR Accuracy:  0.9111111111111111\n",
      "LR F1:  0.9089068825910931\n",
      "For name:  s_hsu\n",
      "total sample size before apply threshold:  204\n",
      "Counter({'0000-0003-3399-055X': 124, '0000-0002-7231-0185': 65, '0000-0002-8214-1696': 12, '0000-0002-8830-5305': 1, '0000-0002-6666-4665': 1, '0000-0002-7232-9839': 1})"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['0000-0002-8214-1696', '0000-0002-7231-0185', '0000-0003-3399-055X']\n",
      "Total sample size after apply threshold:  201\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(201, 228)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "201\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       1.00      0.62      0.76        65\n",
      "          2       0.77      1.00      0.87       124\n",
      "\n",
      "avg / total       0.80      0.82      0.78       201\n",
      "\n",
      "[  0   0  12   0  40  25   0   0 124]\n",
      "MNB Accuracy:  0.8159203980099502\n",
      "MNB F1:  0.5440267335004177\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.90      0.80      0.85        65\n",
      "          2       0.83      0.95      0.89       124\n",
      "\n",
      "avg / total       0.86      0.85      0.83       201\n",
      "\n",
      "[  1   0  11   0  52  13   0   6 118]\n",
      "svc Accuracy:  0.8507462686567164\n",
      "svc F1:  0.6288642180811629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.93      0.60      0.73        65\n",
      "          2       0.76      0.98      0.86       124\n",
      "\n",
      "avg / total       0.77      0.80      0.76       201\n",
      "\n",
      "[  0   0  12   0  39  26   0   3 121]\n",
      "LR Accuracy:  0.7960199004975125\n",
      "LR F1:  0.5280318791761611\n",
      "For name:  f_williams\n",
      "total sample size before apply threshold:  149\n",
      "Counter({'0000-0002-2998-2744': 84, '0000-0002-6194-2734': 33, '0000-0002-3046-9235': 29, '0000-0003-4144-1411': 2, '0000-0001-7507-4870': 1})\n",
      "['0000-0002-2998-2744', '0000-0002-6194-2734', '0000-0002-3046-9235']\n",
      "Total sample size after apply threshold:  146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(146, 1028)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "146\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90        84\n",
      "          1       1.00      0.79      0.88        33\n",
      "          2       0.95      0.66      0.78        29\n",
      "\n",
      "avg / total       0.89      0.88      0.87       146\n",
      "\n",
      "[83  0  1  7 26  0 10  0 19]\n",
      "MNB Accuracy:  0.8767123287671232\n",
      "MNB F1:  0.8530133497761669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        84\n",
      "          1       1.00      0.85      0.92        33\n",
      "          2       1.00      0.83      0.91        29\n",
      "\n",
      "avg / total       0.94      0.93      0.93       146\n",
      "\n",
      "[84  0  0  5 28  0  5  0 24]\n",
      "svc Accuracy:  0.9315068493150684\n",
      "svc F1:  0.9225044629876124\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        84\n",
      "          1       1.00      0.70      0.82        33\n",
      "          2       1.00      0.52      0.68        29\n",
      "\n",
      "avg / total       0.87      0.84      0.82       146\n",
      "\n",
      "[84  0  0 10 23  0 14  0 15]\n",
      "LR Accuracy:  0.8356164383561644\n",
      "LR F1:  0.7927489177489179\n",
      "For name:  d_parsons\n",
      "total sample size before apply threshold:  30\n",
      "Counter({'0000-0002-3956-6031': 26, '0000-0002-1393-8431': 2, '0000-0002-9121-7859': 1, '0000-0002-5142-4466': 1})\n",
      "['0000-0002-3956-6031']\n",
      "Total sample size after apply threshold:  26\n",
      "For name:  a_choudhury\n",
      "total sample size before apply threshold:  56\n",
      "Counter({'0000-0002-3561-6580': 28, '0000-0001-5496-7346': 24, '0000-0002-7042-8139': 3, '0000-0002-8990-879X': 1})\n",
      "['0000-0001-5496-7346', '0000-0002-3561-6580']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 306)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.92      0.86        24\n",
      "          1       0.92      0.82      0.87        28\n",
      "\n",
      "avg / total       0.87      0.87      0.87        52\n",
      "\n",
      "[22  2  5 23]\n",
      "MNB Accuracy:  0.8653846153846154\n",
      "MNB F1:  0.8653348131705512\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        24\n",
      "          1       0.82      1.00      0.90        28\n",
      "\n",
      "avg / total       0.90      0.88      0.88        52\n",
      "\n",
      "[18  6  0 28]\n",
      "svc Accuracy:  0.8846153846153846\n",
      "svc F1:  0.880184331797235\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        24\n",
      "          1       0.82      1.00      0.90        28\n",
      "\n",
      "avg / total       0.90      0.88      0.88        52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[18  6  0 28]\n",
      "LR Accuracy:  0.8846153846153846\n",
      "LR F1:  0.880184331797235\n",
      "For name:  c_richter\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0002-5658-6173': 4, '0000-0002-6591-1118': 4, '0000-0001-6017-1520': 2, '0000-0002-6839-7994': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_hossain\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0003-1408-2273': 26, '0000-0002-1878-8145': 17, '0000-0003-3967-2544': 10, '0000-0003-3399-581X': 9, '0000-0003-3303-5755': 7, '0000-0003-1271-1515': 7, '0000-0003-4733-0018': 6, '0000-0002-9953-586X': 5, '0000-0001-8019-843X': 4, '0000-0001-7996-9233': 3, '0000-0002-1917-8701': 1, '0000-0002-0984-984X': 1, '0000-0002-7673-8410': 1, '0000-0002-0977-4593': 1, '0000-0003-2970-2324': 1, '0000-0001-6753-4216': 1, '0000-0002-3929-6211': 1, '0000-0002-6621-8737': 1})\n",
      "['0000-0003-3967-2544', '0000-0003-1408-2273', '0000-0002-1878-8145']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 127)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.81      0.96      0.88        26\n",
      "          2       0.94      0.94      0.94        17\n",
      "\n",
      "avg / total       0.89      0.87      0.86        53\n",
      "\n",
      "[ 5  5  0  0 25  1  0  1 16]\n",
      "MNB Accuracy:  0.8679245283018868\n",
      "MNB F1:  0.828345373237014\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.93      0.96      0.94        26\n",
      "          2       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.95      0.94      0.94        53\n",
      "\n",
      "[ 8  2  0  0 25  1  0  0 17]\n",
      "svc Accuracy:  0.9433962264150944\n",
      "svc F1:  0.9345712289108516\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.74      1.00      0.85        26\n",
      "          2       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.87      0.83      0.82        53\n",
      "\n",
      "[ 5  5  0  0 26  0  0  4 13]\n",
      "LR Accuracy:  0.8301886792452831\n",
      "LR F1:  0.7952641165755919\n",
      "For name:  v_alves\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-8430-4380': 13, '0000-0002-6182-1748': 5, '0000-0003-1819-7051': 4, '0000-0002-1485-6032': 2})\n",
      "['0000-0002-8430-4380']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  j_becker\n",
      "total sample size before apply threshold:  177\n",
      "Counter({'0000-0003-4425-4726': 122, '0000-0002-6845-6122': 45, '0000-0003-4564-3192': 4, '0000-0001-5668-1544': 3, '0000-0002-5041-5488': 2, '0000-0002-7733-4522': 1})\n",
      "['0000-0002-6845-6122', '0000-0003-4425-4726']\n",
      "Total sample size after apply threshold:  167\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(167, 678)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "167\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.71      0.82        45\n",
      "          1       0.90      0.99      0.95       122\n",
      "\n",
      "avg / total       0.92      0.92      0.91       167\n",
      "\n",
      "[ 32  13   1 121]\n",
      "MNB Accuracy:  0.9161676646706587\n",
      "MNB F1:  0.8829126602564102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        45\n",
      "          1       0.93      1.00      0.96       122\n",
      "\n",
      "avg / total       0.95      0.95      0.94       167\n",
      "\n",
      "[ 36   9   0 122]\n",
      "svc Accuracy:  0.9461077844311377\n",
      "svc F1:  0.9266578831796224\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.42        45\n",
      "          1       0.79      1.00      0.88       122\n",
      "\n",
      "avg / total       0.84      0.80      0.76       167\n",
      "\n",
      "[ 12  33   0 122]\n",
      "LR Accuracy:  0.8023952095808383\n",
      "LR F1:  0.6509595287858636\n",
      "For name:  m_soares\n",
      "total sample size before apply threshold:  247\n",
      "Counter({'0000-0001-9701-836X': 75, '0000-0002-9314-4833': 68, '0000-0001-6071-0272': 44, '0000-0003-1579-8513': 32, '0000-0002-5213-2377': 10, '0000-0001-8860-0470': 7, '0000-0003-4227-4141': 4, '0000-0002-7181-1906': 3, '0000-0002-4614-8209': 2, '0000-0002-8059-7067': 1, '0000-0002-9013-2570': 1})\n",
      "['0000-0002-5213-2377', '0000-0001-6071-0272', '0000-0003-1579-8513', '0000-0002-9314-4833', '0000-0001-9701-836X']\n",
      "Total sample size after apply threshold:  229\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(229, 634)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "229\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.98      0.95      0.97        44\n",
      "          2       1.00      0.72      0.84        32\n",
      "          3       0.97      0.90      0.93        68\n",
      "          4       0.74      0.99      0.85        75\n",
      "\n",
      "avg / total       0.86      0.87      0.86       229\n",
      "\n",
      "[ 0  0  0  0 10  0 42  0  0  2  0  1 23  1  7  0  0  0 61  7  0  0  0  1\n",
      " 74]\n",
      "MNB Accuracy:  0.8733624454148472\n",
      "MNB F1:  0.7157785746761793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       1.00      0.91      0.95        44\n",
      "          2       1.00      0.75      0.86        32\n",
      "          3       0.89      0.93      0.91        68\n",
      "          4       0.83      0.96      0.89        75\n",
      "\n",
      "avg / total       0.91      0.90      0.90       229\n",
      "\n",
      "[ 7  0  0  0  3  0 40  0  2  2  0  0 24  3  5  0  0  0 63  5  0  0  0  3\n",
      " 72]\n",
      "svc Accuracy:  0.8995633187772926\n",
      "svc F1:  0.8856833860642579\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       1.00      0.86      0.93        44\n",
      "          2       1.00      0.62      0.77        32\n",
      "          3       0.95      0.91      0.93        68\n",
      "          4       0.73      0.99      0.84        75\n",
      "\n",
      "avg / total       0.90      0.86      0.86       229\n",
      "\n",
      "[ 4  0  0  0  6  0 38  0  1  5  0  0 20  1 11  0  0  0 62  6  0  0  0  1\n",
      " 74]\n",
      "LR Accuracy:  0.8646288209606987\n",
      "LR F1:  0.8071955256220177\n",
      "For name:  j_yi\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0001-5299-9897': 18, '0000-0002-9296-8443': 9, '0000-0002-1025-865X': 1, '0000-0003-1718-6326': 1})\n",
      "['0000-0001-5299-9897']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  s_khan\n",
      "total sample size before apply threshold:  193\n",
      "Counter({'0000-0001-5147-145X': 61, '0000-0001-5654-2835': 42, '0000-0003-4185-8882': 29, '0000-0002-6792-3577': 7, '0000-0003-0910-4095': 7, '0000-0002-0310-0424': 6, '0000-0002-0763-2583': 6, '0000-0002-9564-5092': 5, '0000-0003-0273-1248': 5, '0000-0002-2689-8563': 4, '0000-0002-0948-5003': 4, '0000-0003-0772-6122': 4, '0000-0002-3845-541X': 3, '0000-0001-6732-768X': 2, '0000-0002-9643-6858': 2, '0000-0002-1894-7839': 1, '0000-0002-1589-6634': 1, '0000-0001-9377-6382': 1, '0000-0002-6307-2023': 1, '0000-0002-0823-4042': 1, '0000-0001-8678-2872': 1})\n",
      "['0000-0003-4185-8882', '0000-0001-5147-145X', '0000-0001-5654-2835']\n",
      "Total sample size after apply threshold:  132\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(132, 942)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "132\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        29\n",
      "          1       0.71      0.98      0.82        61\n",
      "          2       0.88      0.50      0.64        42\n",
      "\n",
      "avg / total       0.82      0.79      0.78       132\n",
      "\n",
      "[23  4  2  0 60  1  0 21 21]\n",
      "MNB Accuracy:  0.7878787878787878\n",
      "MNB F1:  0.780965609732733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        29\n",
      "          1       1.00      0.92      0.96        61\n",
      "          2       0.81      1.00      0.89        42\n",
      "\n",
      "avg / total       0.94      0.92      0.93       132\n",
      "\n",
      "[24  0  5  0 56  5  0  0 42]\n",
      "svc Accuracy:  0.9242424242424242\n",
      "svc F1:  0.918847451966681\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93        29\n",
      "          1       0.75      0.95      0.84        61\n",
      "          2       0.87      0.62      0.72        42\n",
      "\n",
      "avg / total       0.84      0.83      0.82       132\n",
      "\n",
      "[25  3  1  0 58  3  0 16 26]\n",
      "LR Accuracy:  0.8257575757575758\n",
      "LR F1:  0.8295759527643586\n",
      "For name:  a_rao\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-2676-2762': 36, '0000-0003-0320-2962': 20, '0000-0002-2550-6097': 11, '0000-0001-6440-1274': 8, '0000-0003-2319-6539': 5, '0000-0002-2474-5010': 5, '0000-0003-4480-3190': 3, '0000-0003-4879-1123': 2, '0000-0002-7983-0773': 1, '0000-0002-0220-7131': 1, '0000-0002-6531-8728': 1})\n",
      "['0000-0002-2550-6097', '0000-0003-0320-2962', '0000-0002-2676-2762']\n",
      "Total sample size after apply threshold:  67\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 184)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       1.00      0.90      0.95        20\n",
      "          2       0.77      1.00      0.87        36\n",
      "\n",
      "avg / total       0.87      0.84      0.80        67\n",
      "\n",
      "[ 2  0  9  0 18  2  0  0 36]\n",
      "MNB Accuracy:  0.835820895522388\n",
      "MNB F1:  0.7075102027543373\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        11\n",
      "          1       1.00      0.95      0.97        20\n",
      "          2       0.80      1.00      0.89        36\n",
      "\n",
      "avg / total       0.89      0.87      0.84        67\n",
      "\n",
      "[ 3  0  8  0 19  1  0  0 36]\n",
      "svc Accuracy:  0.8656716417910447\n",
      "svc F1:  0.7639397639397639\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.75      0.86        20\n",
      "          2       0.69      1.00      0.82        36\n",
      "\n",
      "avg / total       0.67      0.76      0.70        67\n",
      "\n",
      "[ 0  0 11  0 15  5  0  0 36]\n",
      "LR Accuracy:  0.7611940298507462\n",
      "LR F1:  0.5584415584415584\n",
      "For name:  d_cameron\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0002-5439-6544': 29, '0000-0001-6274-2913': 17, '0000-0001-7520-7741': 2, '0000-0003-2567-0564': 1})\n",
      "['0000-0002-5439-6544', '0000-0001-6274-2913']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 154)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        29\n",
      "          1       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.94      0.93      0.93        46\n",
      "\n",
      "[29  0  3 14]\n",
      "MNB Accuracy:  0.9347826086956522\n",
      "MNB F1:  0.9270227392913801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        29\n",
      "          1       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.94      0.93      0.93        46\n",
      "\n",
      "[29  0  3 14]\n",
      "svc Accuracy:  0.9347826086956522\n",
      "svc F1:  0.9270227392913801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        29\n",
      "          1       1.00      0.53      0.69        17\n",
      "\n",
      "avg / total       0.86      0.83      0.81        46\n",
      "\n",
      "[29  0  8  9]\n",
      "LR Accuracy:  0.8260869565217391\n",
      "LR F1:  0.7855477855477856\n",
      "For name:  c_morgan\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0003-3131-9906': 15, '0000-0003-0931-5474': 11, '0000-0002-7511-0488': 11, '0000-0002-0118-1056': 3, '0000-0002-1508-2614': 2, '0000-0002-8191-3738': 1})\n",
      "['0000-0003-3131-9906', '0000-0003-0931-5474', '0000-0002-7511-0488']\n",
      "Total sample size after apply threshold:  37"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 170)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      1.00      0.71        15\n",
      "          1       1.00      0.45      0.62        11\n",
      "          2       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.82      0.68      0.66        37\n",
      "\n",
      "[15  0  0  6  5  0  6  0  5]\n",
      "MNB Accuracy:  0.6756756756756757\n",
      "MNB F1:  0.6547619047619048\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.80      0.69        15\n",
      "          1       0.88      0.64      0.74        11\n",
      "          2       0.78      0.64      0.70        11\n",
      "\n",
      "avg / total       0.73      0.70      0.71        37\n",
      "\n",
      "[12  1  2  4  7  0  4  0  7]\n",
      "svc Accuracy:  0.7027027027027027\n",
      "svc F1:  0.7075187969924812\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.93      0.67        15\n",
      "          1       1.00      0.36      0.53        11\n",
      "          2       0.83      0.45      0.59        11\n",
      "\n",
      "avg / total       0.76      0.62      0.60        37\n",
      "\n",
      "[14  0  1  7  4  0  6  0  5]\n",
      "LR Accuracy:  0.6216216216216216\n",
      "LR F1:  0.5960784313725491\n",
      "For name:  h_cui\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0001-6394-4808': 11, '0000-0003-3358-8958': 10, '0000-0002-9870-748X': 9, '0000-0002-6343-1014': 9, '0000-0002-8627-8534': 1})\n",
      "['0000-0001-6394-4808', '0000-0003-3358-8958']\n",
      "Total sample size after apply threshold:  21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 55)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "21\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        11\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.96      0.95      0.95        21\n",
      "\n",
      "[11  0  1  9]\n",
      "MNB Accuracy:  0.9523809523809523\n",
      "MNB F1:  0.9519450800915332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.96      0.95      0.95        21\n",
      "\n",
      "[10  1  0 10]\n",
      "svc Accuracy:  0.9523809523809523\n",
      "svc F1:  0.9523809523809523\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.96      0.95      0.95        21\n",
      "\n",
      "[10  1  0 10]\n",
      "LR Accuracy:  0.9523809523809523\n",
      "LR F1:  0.9523809523809523\n",
      "For name:  p_zhang\n",
      "total sample size before apply threshold:  137\n",
      "Counter({'0000-0002-1765-5965': 26, '0000-0003-3603-0175': 25, '0000-0003-2228-3569': 20, '0000-0002-2774-5534': 17, '0000-0002-5409-7480': 16, '0000-0001-5574-0899': 8, '0000-0002-6218-1885': 6, '0000-0002-1806-4200': 5, '0000-0001-9539-1136': 5, '0000-0003-0606-6855': 3, '0000-0001-6953-800X': 3, '0000-0002-8462-0340': 1, '0000-0001-7331-6020': 1, '0000-0003-3344-4823': 1})\n",
      "['0000-0002-5409-7480', '0000-0002-2774-5534', '0000-0003-3603-0175', '0000-0003-2228-3569', '0000-0002-1765-5965']\n",
      "Total sample size after apply threshold:  104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(104, 161)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "104\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.75      0.80        16\n",
      "          1       0.94      0.88      0.91        17\n",
      "          2       0.96      0.92      0.94        25\n",
      "          3       0.77      1.00      0.87        20\n",
      "          4       0.96      0.88      0.92        26\n",
      "\n",
      "avg / total       0.90      0.89      0.89       104\n",
      "\n",
      "[12  1  0  3  0  0 15  0  2  0  1  0 23  0  1  0  0  0 20  0  1  0  1  1\n",
      " 23]\n",
      "MNB Accuracy:  0.8942307692307693\n",
      "MNB F1:  0.887486327337259\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91        16\n",
      "          1       0.94      0.94      0.94        17\n",
      "          2       0.88      0.92      0.90        25\n",
      "          3       0.95      0.95      0.95        20\n",
      "          4       0.92      0.85      0.88        26\n",
      "\n",
      "avg / total       0.91      0.91      0.91       104\n",
      "\n",
      "[15  1  0  0  0  0 16  1  0  0  1  0 23  0  1  0  0  0 19  1  1  0  2  1\n",
      " 22]\n",
      "svc Accuracy:  0.9134615384615384\n",
      "svc F1:  0.9164456327985739\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88        16\n",
      "          1       0.94      0.94      0.94        17\n",
      "          2       0.85      0.92      0.88        25\n",
      "          3       0.95      0.95      0.95        20\n",
      "          4       0.92      0.85      0.88        26\n",
      "\n",
      "avg / total       0.91      0.90      0.90       104\n",
      "\n",
      "[14  1  1  0  0  0 16  1  0  0  1  0 23  0  1  0  0  0 19  1  1  0  2  1\n",
      " 22]\n",
      "LR Accuracy:  0.9038461538461539\n",
      "LR F1:  0.9061583710407239\n",
      "For name:  j_fernandes\n",
      "total sample size before apply threshold:  208\n",
      "Counter({'0000-0002-2550-1640': 63, '0000-0003-1556-1698': 38, '0000-0001-5512-4092': 33, '0000-0002-8565-2942': 27, '0000-0002-6726-5324': 22, '0000-0002-9089-273X': 6, '0000-0001-8205-5870': 4, '0000-0001-6387-2939': 3, '0000-0002-4505-4809': 3, '0000-0001-6616-3513': 3, '0000-0003-0337-7084': 3, '0000-0003-1519-8032': 2, '0000-0003-0934-9244': 1})\n",
      "['0000-0002-2550-1640', '0000-0003-1556-1698', '0000-0002-8565-2942', '0000-0001-5512-4092', '0000-0002-6726-5324']\n",
      "Total sample size after apply threshold:  183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(183, 329)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "183\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93        63\n",
      "          1       0.92      0.95      0.94        38\n",
      "          2       0.92      0.85      0.88        27\n",
      "          3       0.97      0.97      0.97        33\n",
      "          4       1.00      0.64      0.78        22\n",
      "\n",
      "avg / total       0.92      0.92      0.91       183\n",
      "\n",
      "[63  0  0  0  0  1 36  1  0  0  1  2 23  1  0  0  1  0 32  0  7  0  1  0\n",
      " 14]\n",
      "MNB Accuracy:  0.9180327868852459\n",
      "MNB F1:  0.9000976800976801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        63\n",
      "          1       0.94      0.89      0.92        38\n",
      "          2       0.95      0.78      0.86        27\n",
      "          3       1.00      0.97      0.98        33\n",
      "          4       1.00      0.73      0.84        22\n",
      "\n",
      "avg / total       0.92      0.91      0.91       183\n",
      "\n",
      "[63  0  0  0  0  3 34  1  0  0  4  2 21  0  0  1  0  0 32  0  6  0  0  0\n",
      " 16]\n",
      "svc Accuracy:  0.907103825136612\n",
      "svc F1:  0.9005564847670111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        63\n",
      "          1       0.94      0.87      0.90        38\n",
      "          2       1.00      0.74      0.85        27\n",
      "          3       1.00      0.97      0.98        33\n",
      "          4       1.00      0.55      0.71        22\n",
      "\n",
      "avg / total       0.90      0.87      0.87       183\n",
      "\n",
      "[63  0  0  0  0  5 33  0  0  0  5  2 20  0  0  1  0  0 32  0 10  0  0  0\n",
      " 12]\n",
      "LR Accuracy:  0.8743169398907104\n",
      "LR F1:  0.8605628027055496\n",
      "For name:  a_jain\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0001-7808-6180': 15, '0000-0003-0250-3608': 11, '0000-0001-5320-0880': 9, '0000-0003-2235-5139': 7, '0000-0003-4032-1442': 6, '0000-0002-3281-9729': 5, '0000-0003-2827-6263': 4, '0000-0001-9415-0883': 4, '0000-0001-5658-367X': 3, '0000-0002-2457-8144': 1, '0000-0002-8481-7119': 1, '0000-0002-3950-2601': 1})\n",
      "['0000-0003-0250-3608', '0000-0001-7808-6180']\n",
      "Total sample size after apply threshold:  26\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 63)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.79      1.00      0.88        15\n",
      "\n",
      "avg / total       0.88      0.85      0.84        26\n",
      "\n",
      "[ 7  4  0 15]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.8300653594771241\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        26\n",
      "\n",
      "[11  0  0 15]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.75      1.00      0.86        15\n",
      "\n",
      "avg / total       0.86      0.81      0.79        26\n",
      "\n",
      "[ 6  5  0 15]\n",
      "LR Accuracy:  0.8076923076923077\n",
      "LR F1:  0.7815126050420167\n",
      "For name:  d_zhang\n",
      "total sample size before apply threshold:  94\n",
      "Counter({'0000-0002-4175-5982': 17, '0000-0002-7665-2182': 12, '0000-0003-0779-6438': 11, '0000-0003-4280-0068': 8, '0000-0001-9295-4992': 7, '0000-0001-9508-8209': 7, '0000-0001-6930-5994': 6, '0000-0001-9478-5344': 6, '0000-0001-5809-0027': 5, '0000-0002-4149-4938': 4, '0000-0002-1581-2357': 4, '0000-0001-5956-4618': 2, '0000-0001-7063-7742': 2, '0000-0002-2541-837X': 1, '0000-0001-6259-7082': 1, '0000-0002-4515-2070': 1})\n",
      "['0000-0002-4175-5982', '0000-0002-7665-2182', '0000-0003-0779-6438']\n",
      "Total sample size after apply threshold:  40\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 77)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "40\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        17\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.90      0.88      0.88        40\n",
      "\n",
      "[17  0  0  3  9  0  2  0  9]\n",
      "MNB Accuracy:  0.875\n",
      "MNB F1:  0.8763125763125763\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.91        17\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.93      0.93      0.92        40\n",
      "\n",
      "[16  0  1  2 10  0  0  0 11]\n",
      "svc Accuracy:  0.925\n",
      "svc F1:  0.9266327875023528\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.94      0.78        17\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       0.86      0.55      0.67        11\n",
      "\n",
      "avg / total       0.82      0.78      0.77        40\n",
      "\n",
      "[16  0  1  3  9  0  5  0  6]\n",
      "LR Accuracy:  0.775\n",
      "LR F1:  0.7680991095625241\n",
      "For name:  b_huang\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-9082-2216': 16, '0000-0002-1981-5838': 12, '0000-0002-1246-7447': 9, '0000-0001-6189-814X': 5, '0000-0001-5009-3928': 3, '0000-0003-2838-6315': 3})\n",
      "['0000-0001-9082-2216', '0000-0002-1981-5838']\n",
      "Total sample size after apply threshold:  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 145)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.84        16\n",
      "          1       1.00      0.50      0.67        12\n",
      "\n",
      "avg / total       0.84      0.79      0.77        28\n",
      "\n",
      "[16  0  6  6]\n",
      "MNB Accuracy:  0.7857142857142857\n",
      "MNB F1:  0.7543859649122807\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.86      1.00      0.92        12\n",
      "\n",
      "avg / total       0.94      0.93      0.93        28\n",
      "\n",
      "[14  2  0 12]\n",
      "svc Accuracy:  0.9285714285714286\n",
      "svc F1:  0.9282051282051282\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.94      0.83        16\n",
      "          1       0.88      0.58      0.70        12\n",
      "\n",
      "avg / total       0.80      0.79      0.78        28\n",
      "\n",
      "[15  1  5  7]\n",
      "LR Accuracy:  0.7857142857142857\n",
      "LR F1:  0.7666666666666667\n",
      "For name:  m_chong\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0001-9324-5901': 20, '0000-0002-9586-6303': 20, '0000-0003-0587-2505': 1, '0000-0002-5507-1987': 1, '0000-0002-7324-1660': 1})\n",
      "['0000-0001-9324-5901', '0000-0002-9586-6303']\n",
      "Total sample size after apply threshold:  40\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 90)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "40\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.85      0.87        20\n",
      "          1       0.86      0.90      0.88        20\n",
      "\n",
      "avg / total       0.88      0.88      0.87        40\n",
      "\n",
      "[17  3  2 18]\n",
      "MNB Accuracy:  0.875\n",
      "MNB F1:  0.8749218261413383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.90      0.88        20\n",
      "          1       0.89      0.85      0.87        20\n",
      "\n",
      "avg / total       0.88      0.88      0.87        40\n",
      "\n",
      "[18  2  3 17]\n",
      "svc Accuracy:  0.875\n",
      "svc F1:  0.8749218261413383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.85      0.87        20\n",
      "          1       0.86      0.90      0.88        20\n",
      "\n",
      "avg / total       0.88      0.88      0.87        40\n",
      "\n",
      "[17  3  2 18]\n",
      "LR Accuracy:  0.875\n",
      "LR F1:  0.8749218261413383\n",
      "For name:  m_cerqueira\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-8342-2967': 12, '0000-0002-2430-7758': 12, '0000-0001-6614-3942': 11, '0000-0002-3505-6982': 4, '0000-0001-7237-5053': 2})\n",
      "['0000-0002-8342-2967', '0000-0002-2430-7758', '0000-0001-6614-3942']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 81)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.75      0.82        12\n",
      "          1       0.86      1.00      0.92        12\n",
      "          2       0.91      0.91      0.91        11\n",
      "\n",
      "avg / total       0.89      0.89      0.88        35\n",
      "\n",
      "[ 9  2  1  0 12  0  1  0 10]\n",
      "MNB Accuracy:  0.8857142857142857\n",
      "MNB F1:  0.8834498834498835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        12\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.95      0.94      0.94        35\n",
      "\n",
      "[12  0  0  1 11  0  1  0 10]\n",
      "svc Accuracy:  0.9428571428571428\n",
      "svc F1:  0.9439932048627702\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        12\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.93      0.91      0.92        35\n",
      "\n",
      "[12  0  0  1 11  0  2  0  9]\n",
      "LR Accuracy:  0.9142857142857143\n",
      "LR F1:  0.9151368760064412\n",
      "For name:  p_yang\n",
      "total sample size before apply threshold:  227\n",
      "Counter({'0000-0001-6330-6048': 102, '0000-0003-3473-4611': 46, '0000-0003-1098-3138': 17, '0000-0002-4004-2518': 17, '0000-0002-0463-1024': 14, '0000-0002-2334-5664': 10, '0000-0002-4635-1215': 6, '0000-0001-7554-5281': 5, '0000-0001-9227-3919': 4, '0000-0002-6610-1758': 3, '0000-0001-5247-1953': 1, '0000-0003-1840-6204': 1, '0000-0001-8472-0205': 1})\n",
      "['0000-0001-6330-6048', '0000-0003-3473-4611', '0000-0002-0463-1024', '0000-0003-1098-3138', '0000-0002-4004-2518', '0000-0002-2334-5664']\n",
      "Total sample size after apply threshold:  206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(206, 440)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "206\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.99      0.73       102\n",
      "          1       0.93      0.54      0.68        46\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       1.00      0.18      0.30        17\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.58      0.63      0.54       206\n",
      "\n",
      "[101   0   0   0   1   0  21  25   0   0   0   0  14   0   0   0   0   0\n",
      "  13   1   0   3   0   0  17   0   0   0   0   0   9   1   0   0   0   0]\n",
      "MNB Accuracy:  0.6262135922330098\n",
      "MNB F1:  0.2856955640176055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.97      0.87       102\n",
      "          1       0.90      0.80      0.85        46\n",
      "          2       0.88      0.50      0.64        14\n",
      "          3       1.00      0.82      0.90        17\n",
      "          4       1.00      0.35      0.52        17\n",
      "          5       0.83      1.00      0.91        10\n",
      "\n",
      "avg / total       0.86      0.84      0.83       206\n",
      "\n",
      "[99  3  0  0  0  0  9 37  0  0  0  0  5  0  7  0  0  2  2  0  1 14  0  0\n",
      " 10  1  0  0  6  0  0  0  0  0  0 10]\n",
      "svc Accuracy:  0.8398058252427184\n",
      "svc F1:  0.7822068151699769\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.99      0.79       102\n",
      "          1       0.94      0.70      0.80        46\n",
      "          2       1.00      0.14      0.25        14\n",
      "          3       1.00      0.29      0.45        17\n",
      "          4       1.00      0.18      0.30        17\n",
      "          5       0.89      0.80      0.84        10\n",
      "\n",
      "avg / total       0.81      0.73      0.69       206\n",
      "\n",
      "[101   1   0   0   0   0  14  32   0   0   0   0  11   0   2   0   0   1\n",
      "  12   0   0   5   0   0  13   1   0   0   3   0   2   0   0   0   0   8]\n",
      "LR Accuracy:  0.7330097087378641\n",
      "LR F1:  0.5731345967414079\n",
      "For name:  j_marques\n",
      "total sample size before apply threshold:  183\n",
      "Counter({'0000-0001-8865-8189': 30, '0000-0001-8157-8864': 28, '0000-0002-3800-7756': 27, '0000-0001-8910-4735': 18, '0000-0002-3457-3320': 14, '0000-0002-8124-3156': 12, '0000-0001-9436-1613': 11, '0000-0002-7234-9477': 8, '0000-0002-3724-5664': 8, '0000-0002-7333-9158': 6, '0000-0002-1014-0483': 5, '0000-0003-2199-9362': 4, '0000-0002-8740-642X': 4, '0000-0003-3429-0774': 2, '0000-0002-1644-7195': 2, '0000-0002-2523-6365': 1, '0000-0003-0972-1149': 1, '0000-0002-2354-433X': 1, '0000-0001-9834-1361': 1})\n",
      "['0000-0002-3457-3320', '0000-0002-8124-3156', '0000-0002-3800-7756', '0000-0001-8910-4735', '0000-0001-8865-8189', '0000-0001-9436-1613', '0000-0001-8157-8864']\n",
      "Total sample size after apply threshold:  140\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 285)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "140\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25        14\n",
      "          1       1.00      0.58      0.74        12\n",
      "          2       0.63      0.96      0.76        27\n",
      "          3       1.00      0.83      0.91        18\n",
      "          4       0.74      0.93      0.82        30\n",
      "          5       1.00      0.27      0.43        11\n",
      "          6       0.79      0.96      0.87        28\n",
      "\n",
      "avg / total       0.83      0.77      0.74       140\n",
      "\n",
      "[ 2  0  9  0  1  0  2  0  7  0  0  5  0  0  0  0 26  0  0  0  1  0  0  2\n",
      " 15  1  0  0  0  0  1  0 28  0  1  0  0  3  0  2  3  3  0  0  0  0  1  0\n",
      " 27]\n",
      "MNB Accuracy:  0.7714285714285715\n",
      "MNB F1:  0.6833867827112323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        14\n",
      "          1       0.91      0.83      0.87        12\n",
      "          2       1.00      0.93      0.96        27\n",
      "          3       1.00      0.89      0.94        18\n",
      "          4       0.63      0.97      0.76        30\n",
      "          5       1.00      0.36      0.53        11\n",
      "          6       1.00      0.96      0.98        28\n",
      "\n",
      "avg / total       0.91      0.87      0.87       140\n",
      "\n",
      "[11  0  0  0  3  0  0  0 10  0  0  2  0  0  0  0 25  0  2  0  0  0  0  0\n",
      " 16  2  0  0  0  1  0  0 29  0  0  0  0  0  0  7  4  0  0  0  0  0  1  0\n",
      " 27]\n",
      "svc Accuracy:  0.8714285714285714\n",
      "svc F1:  0.847227079915194\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.35        14\n",
      "          1       1.00      0.67      0.80        12\n",
      "          2       1.00      0.96      0.98        27\n",
      "          3       1.00      0.89      0.94        18\n",
      "          4       0.54      1.00      0.70        30\n",
      "          5       1.00      0.36      0.53        11\n",
      "          6       1.00      0.96      0.98        28\n",
      "\n",
      "avg / total       0.90      0.81      0.80       140\n",
      "\n",
      "[ 3  0  0  0 11  0  0  0  8  0  0  4  0  0  0  0 26  0  1  0  0  0  0  0\n",
      " 16  2  0  0  0  0  0  0 30  0  0  0  0  0  0  7  4  0  0  0  0  0  1  0\n",
      " 27]\n",
      "LR Accuracy:  0.8142857142857143\n",
      "LR F1:  0.7554393794695269\n",
      "For name:  n_ali\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0001-8121-0939': 6, '0000-0003-2063-2745': 3, '0000-0003-1245-4299': 2, '0000-0002-8292-0091': 1, '0000-0003-0858-7849': 1, '0000-0003-2924-6429': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_ng\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0002-9210-5349': 53, '0000-0001-6352-8417': 41, '0000-0002-4055-8151': 13, '0000-0001-6519-1942': 1, '0000-0003-2397-840X': 1})\n",
      "['0000-0001-6352-8417', '0000-0002-9210-5349', '0000-0002-4055-8151']\n",
      "Total sample size after apply threshold:  107\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 235)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "107\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.66      0.78        41\n",
      "          1       0.78      0.98      0.87        53\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.88      0.85      0.85       107\n",
      "\n",
      "[27 14  0  1 52  0  0  1 12]\n",
      "MNB Accuracy:  0.8504672897196262\n",
      "MNB F1:  0.8697584541062802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86        41\n",
      "          1       0.92      0.87      0.89        53\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.89      0.89      0.89       107\n",
      "\n",
      "[37  4  0  7 46  0  1  0 12]\n",
      "svc Accuracy:  0.8878504672897196\n",
      "svc F1:  0.9045563332580718\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.76      0.83        41\n",
      "          1       0.82      0.94      0.88        53\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.88      0.87      0.87       107\n",
      "\n",
      "[31 10  0  3 50  0  0  1 12]\n",
      "LR Accuracy:  0.8691588785046729\n",
      "LR F1:  0.887953216374269\n",
      "For name:  m_viana\n",
      "total sample size before apply threshold:  139\n",
      "Counter({'0000-0002-0464-4845': 34, '0000-0003-4356-8109': 31, '0000-0002-4073-3802': 29, '0000-0001-9665-2115': 26, '0000-0001-9288-2108': 13, '0000-0002-3074-767X': 5, '0000-0002-5657-5570': 1})\n",
      "['0000-0001-9665-2115', '0000-0003-4356-8109', '0000-0002-4073-3802', '0000-0001-9288-2108', '0000-0002-0464-4845']\n",
      "Total sample size after apply threshold:  133\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 440)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.92      0.87        26\n",
      "          1       0.86      0.97      0.91        31\n",
      "          2       0.97      0.97      0.97        29\n",
      "          3       0.83      0.38      0.53        13\n",
      "          4       0.97      0.97      0.97        34\n",
      "\n",
      "avg / total       0.90      0.90      0.89       133\n",
      "\n",
      "[24  1  0  1  0  0 30  0  0  1  0  1 28  0  0  4  3  1  5  0  1  0  0  0\n",
      " 33]\n",
      "MNB Accuracy:  0.9022556390977443\n",
      "MNB F1:  0.8488478895930587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.96      0.85        26\n",
      "          1       1.00      0.94      0.97        31\n",
      "          2       1.00      0.93      0.96        29\n",
      "          3       0.91      0.77      0.83        13\n",
      "          4       1.00      0.97      0.99        34\n",
      "\n",
      "avg / total       0.94      0.93      0.93       133\n",
      "\n",
      "[25  0  0  1  0  2 29  0  0  0  2  0 27  0  0  3  0  0 10  0  1  0  0  0\n",
      " 33]\n",
      "svc Accuracy:  0.9323308270676691\n",
      "svc F1:  0.919363593654006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.92      0.86        26\n",
      "          1       0.91      0.94      0.92        31\n",
      "          2       0.93      0.97      0.95        29\n",
      "          3       0.88      0.54      0.67        13\n",
      "          4       1.00      0.97      0.99        34\n",
      "\n",
      "avg / total       0.91      0.91      0.91       133\n",
      "\n",
      "[24  1  0  1  0  1 29  1  0  0  0  1 28  0  0  4  1  1  7  0  1  0  0  0\n",
      " 33]\n",
      "LR Accuracy:  0.9097744360902256\n",
      "LR F1:  0.8757343227365995\n",
      "For name:  t_inoue\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0002-2728-0060': 52, '0000-0003-3289-4478': 9, '0000-0002-7710-1526': 8, '0000-0003-0582-0908': 1})\n",
      "['0000-0002-2728-0060']\n",
      "Total sample size after apply threshold:  52\n",
      "For name:  b_meyer\n",
      "total sample size before apply threshold:  92\n",
      "Counter({'0000-0002-0388-9568': 60, '0000-0003-1100-0260': 25, '0000-0002-2549-1825': 3, '0000-0002-7903-5710': 2, '0000-0001-9321-1277': 1, '0000-0002-6530-4588': 1})\n",
      "['0000-0002-0388-9568', '0000-0003-1100-0260']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 518)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.98      0.89        60\n",
      "          1       0.92      0.44      0.59        25\n",
      "\n",
      "avg / total       0.84      0.82      0.80        85\n",
      "\n",
      "[59  1 14 11]\n",
      "MNB Accuracy:  0.8235294117647058\n",
      "MNB F1:  0.7409063198536883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.95        60\n",
      "          1       0.91      0.84      0.87        25\n",
      "\n",
      "avg / total       0.93      0.93      0.93        85\n",
      "\n",
      "[58  2  4 21]\n",
      "svc Accuracy:  0.9294117647058824\n",
      "svc F1:  0.9129098360655737\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        60\n",
      "          1       1.00      0.28      0.44        25\n",
      "\n",
      "avg / total       0.84      0.79      0.74        85\n",
      "\n",
      "[60  0 18  7]\n",
      "LR Accuracy:  0.788235294117647\n",
      "LR F1:  0.6535326086956522\n",
      "For name:  c_liao\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-1324-9644': 11, '0000-0001-5168-6493': 11, '0000-0001-9777-3701': 6, '0000-0003-3459-1913': 6, '0000-0003-4156-0912': 1})\n",
      "['0000-0002-1324-9644', '0000-0001-5168-6493']\n",
      "Total sample size after apply threshold:  22\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 50)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "22\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        22\n",
      "\n",
      "[11  0  0 11]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "[10  1  0 11]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.9544513457556936\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        22\n",
      "\n",
      "[11  0  0 11]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  k_wheeler\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0003-3728-8928': 18, '0000-0001-6752-7542': 6, '0000-0002-6806-4233': 2, '0000-0003-2056-9977': 2})\n",
      "['0000-0003-3728-8928']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  m_rizzo\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0002-9549-8504': 68, '0000-0002-3856-5010': 53, '0000-0001-5924-8615': 18, '0000-0002-1023-4260': 9, '0000-0003-4343-8937': 4})\n",
      "['0000-0002-9549-8504', '0000-0001-5924-8615', '0000-0002-3856-5010']\n",
      "Total sample size after apply threshold:  139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 378)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        68\n",
      "          1       1.00      0.67      0.80        18\n",
      "          2       0.83      1.00      0.91        53\n",
      "\n",
      "avg / total       0.93      0.92      0.92       139\n",
      "\n",
      "[63  0  5  0 12  6  0  0 53]\n",
      "MNB Accuracy:  0.920863309352518\n",
      "MNB F1:  0.8892716556838695\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        68\n",
      "          1       1.00      0.83      0.91        18\n",
      "          2       1.00      1.00      1.00        53\n",
      "\n",
      "avg / total       0.98      0.98      0.98       139\n",
      "\n",
      "[68  0  0  3 15  0  0  0 53]\n",
      "svc Accuracy:  0.9784172661870504\n",
      "svc F1:  0.9625027250926531\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        68\n",
      "          1       1.00      0.50      0.67        18\n",
      "          2       1.00      1.00      1.00        53\n",
      "\n",
      "avg / total       0.94      0.94      0.93       139\n",
      "\n",
      "[68  0  0  9  9  0  0  0 53]\n",
      "LR Accuracy:  0.935251798561151\n",
      "LR F1:  0.8681992337164751\n",
      "For name:  y_shi\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0001-6933-4971': 17, '0000-0003-4530-2056': 10, '0000-0003-2943-5465': 7, '0000-0001-6029-6526': 5, '0000-0001-7421-3306': 5, '0000-0001-7713-0813': 4, '0000-0003-4273-8663': 3, '0000-0001-9406-7967': 3, '0000-0003-1804-6990': 3, '0000-0002-6715-7681': 2, '0000-0002-7887-3050': 2, '0000-0001-7256-3628': 2, '0000-0001-6085-7880': 1, '0000-0003-0965-5751': 1, '0000-0001-7502-9201': 1, '0000-0002-3284-4449': 1})\n",
      "['0000-0001-6933-4971', '0000-0003-4530-2056']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 93)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        17\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.97      0.96      0.96        27\n",
      "\n",
      "[17  0  1  9]\n",
      "MNB Accuracy:  0.9629629629629629\n",
      "MNB F1:  0.9593984962406015\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        17\n",
      "          1       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.93      0.93      0.93        27\n",
      "\n",
      "[16  1  1  9]\n",
      "svc Accuracy:  0.9259259259259259\n",
      "svc F1:  0.9205882352941177\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        17\n",
      "          1       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.93      0.93      0.92        27\n",
      "\n",
      "[17  0  2  8]\n",
      "LR Accuracy:  0.9259259259259259\n",
      "LR F1:  0.9166666666666667\n",
      "For name:  c_luo\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0003-0524-5886': 36, '0000-0002-6453-7435': 18, '0000-0003-2193-3670': 15, '0000-0002-3477-5969': 5, '0000-0001-5876-5266': 1, '0000-0002-0879-3127': 1, '0000-0003-1152-0557': 1, '0000-0001-8806-1139': 1})\n",
      "['0000-0003-0524-5886', '0000-0002-6453-7435', '0000-0003-2193-3670']\n",
      "Total sample size after apply threshold:  69\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 134)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        36\n",
      "          1       1.00      0.89      0.94        18\n",
      "          2       1.00      0.87      0.93        15\n",
      "\n",
      "avg / total       0.95      0.94      0.94        69\n",
      "\n",
      "[36  0  0  2 16  0  2  0 13]\n",
      "MNB Accuracy:  0.9420289855072463\n",
      "MNB F1:  0.9390387734040985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        36\n",
      "          1       1.00      1.00      1.00        18\n",
      "          2       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        69\n",
      "\n",
      "[36  0  0  0 18  0  0  0 15]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        36\n",
      "          1       1.00      0.89      0.94        18\n",
      "          2       1.00      0.87      0.93        15\n",
      "\n",
      "avg / total       0.95      0.94      0.94        69\n",
      "\n",
      "[36  0  0  2 16  0  2  0 13]\n",
      "LR Accuracy:  0.9420289855072463\n",
      "LR F1:  0.9390387734040985\n",
      "For name:  j_arthur\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-4796-0207': 24, '0000-0002-9185-6108': 11, '0000-0003-4540-4511': 6, '0000-0003-0344-4478': 1})\n",
      "['0000-0002-4796-0207', '0000-0002-9185-6108']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 184)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        24\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        35\n",
      "\n",
      "[24  0  0 11]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        24\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        35\n",
      "\n",
      "[24  0  0 11]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        24\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.90      0.89      0.88        35\n",
      "\n",
      "[24  0  4  7]\n",
      "LR Accuracy:  0.8857142857142857\n",
      "LR F1:  0.8504273504273504\n",
      "For name:  m_ansari\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0001-6365-7104': 9, '0000-0002-8718-3078': 8, '0000-0001-7678-4639': 7, '0000-0003-2790-8353': 5, '0000-0002-9106-0978': 3, '0000-0002-0112-238X': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  g_anderson\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0001-5087-7837': 65, '0000-0001-7545-9893': 35, '0000-0002-5768-6360': 1, '0000-0001-6544-8007': 1, '0000-0003-2046-3152': 1})\n",
      "['0000-0001-7545-9893', '0000-0001-5087-7837']\n",
      "Total sample size after apply threshold:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 351)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "100\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        35\n",
      "          1       0.98      0.98      0.98        65\n",
      "\n",
      "avg / total       0.98      0.98      0.98       100\n",
      "\n",
      "[34  1  1 64]\n",
      "MNB Accuracy:  0.98\n",
      "MNB F1:  0.9780219780219781\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        35\n",
      "          1       0.97      1.00      0.98        65\n",
      "\n",
      "avg / total       0.98      0.98      0.98       100\n",
      "\n",
      "[33  2  0 65]\n",
      "svc Accuracy:  0.98\n",
      "svc F1:  0.9777183600713013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        35\n",
      "          1       0.89      1.00      0.94        65\n",
      "\n",
      "avg / total       0.93      0.92      0.92       100\n",
      "\n",
      "[27  8  0 65]\n",
      "LR Accuracy:  0.92\n",
      "LR F1:  0.9064983637213652\n",
      "For name:  m_hidalgo\n",
      "total sample size before apply threshold:  279\n",
      "Counter({'0000-0002-3765-3318': 238, '0000-0002-4450-3772': 31, '0000-0001-9862-6578': 5, '0000-0002-3494-9658': 3, '0000-0003-0684-0740': 2})\n",
      "['0000-0002-3765-3318', '0000-0002-4450-3772']\n",
      "Total sample size after apply threshold:  269\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(269, 1109)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "269\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       238\n",
      "          1       1.00      0.35      0.52        31\n",
      "\n",
      "avg / total       0.93      0.93      0.91       269\n",
      "\n",
      "[238   0  20  11]\n",
      "MNB Accuracy:  0.9256505576208178\n",
      "MNB F1:  0.7417434715821813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       238\n",
      "          1       1.00      0.81      0.89        31\n",
      "\n",
      "avg / total       0.98      0.98      0.98       269\n",
      "\n",
      "[238   0   6  25]\n",
      "svc Accuracy:  0.9776951672862454\n",
      "svc F1:  0.9402045050385299\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       238\n",
      "          1       1.00      0.13      0.23        31\n",
      "\n",
      "avg / total       0.91      0.90      0.86       269\n",
      "\n",
      "[238   0  27   4]\n",
      "LR Accuracy:  0.8996282527881041\n",
      "LR F1:  0.587446748082931\n",
      "For name:  k_jacobsen\n",
      "total sample size before apply threshold:  113\n",
      "Counter({'0000-0002-4198-6246': 93, '0000-0002-1121-2979': 17, '0000-0002-3450-0850': 2, '0000-0003-0135-0988': 1})\n",
      "['0000-0002-4198-6246', '0000-0002-1121-2979']\n",
      "Total sample size after apply threshold:  110\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(110, 1386)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "110\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        93\n",
      "          1       1.00      0.18      0.30        17\n",
      "\n",
      "avg / total       0.89      0.87      0.83       110\n",
      "\n",
      "[93  0 14  3]\n",
      "MNB Accuracy:  0.8727272727272727\n",
      "MNB F1:  0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        93\n",
      "          1       1.00      0.59      0.74        17\n",
      "\n",
      "avg / total       0.94      0.94      0.93       110\n",
      "\n",
      "[93  0  7 10]\n",
      "svc Accuracy:  0.9363636363636364\n",
      "svc F1:  0.8522356553444637\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        93\n",
      "          1       1.00      0.12      0.21        17\n",
      "\n",
      "avg / total       0.88      0.86      0.81       110\n",
      "\n",
      "[93  0 15  2]\n",
      "LR Accuracy:  0.8636363636363636\n",
      "LR F1:  0.5679497250589159\n",
      "For name:  s_kelly\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0003-4002-048X': 31, '0000-0001-8583-5362': 26, '0000-0002-8245-0181': 20, '0000-0003-3533-5268': 12, '0000-0002-0375-1040': 11, '0000-0002-3078-8404': 2})\n",
      "['0000-0002-8245-0181', '0000-0001-8583-5362', '0000-0003-3533-5268', '0000-0002-0375-1040', '0000-0003-4002-048X']\n",
      "Total sample size after apply threshold:  100\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 304)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "100\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        20\n",
      "          1       1.00      0.69      0.82        26\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       1.00      0.18      0.31        11\n",
      "          4       0.61      1.00      0.76        31\n",
      "\n",
      "avg / total       0.88      0.80      0.78       100\n",
      "\n",
      "[20  0  0  0  0  0 18  0  0  8  0  0  9  0  3  0  0  0  2  9  0  0  0  0\n",
      " 31]\n",
      "MNB Accuracy:  0.8\n",
      "MNB F1:  0.7478229087985184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        20\n",
      "          1       0.81      0.85      0.83        26\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       1.00      0.55      0.71        11\n",
      "          4       0.74      0.90      0.81        31\n",
      "\n",
      "avg / total       0.87      0.85      0.85       100\n",
      "\n",
      "[20  0  0  0  0  0 22  0  0  4  0  1  9  0  2  0  1  0  6  4  0  3  0  0\n",
      " 28]\n",
      "svc Accuracy:  0.85\n",
      "svc F1:  0.8409616184455734\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        20\n",
      "          1       1.00      0.54      0.70        26\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       1.00      0.18      0.31        11\n",
      "          4       0.56      1.00      0.72        31\n",
      "\n",
      "avg / total       0.86      0.76      0.74       100\n",
      "\n",
      "[20  0  0  0  0  0 14  0  0 12  0  0  9  0  3  0  0  0  2  9  0  0  0  0\n",
      " 31]\n",
      "LR Accuracy:  0.76\n",
      "LR F1:  0.7171530794786609\n",
      "For name:  s_james\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0001-9369-3288': 29, '0000-0003-0651-9842': 13, '0000-0001-7955-0491': 8, '0000-0001-6758-5726': 7, '0000-0003-1150-0628': 1, '0000-0002-8128-2139': 1})\n",
      "['0000-0003-0651-9842', '0000-0001-9369-3288']\n",
      "Total sample size after apply threshold:  42\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 162)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       1.00      1.00      1.00        42\n",
      "\n",
      "[13  0  0 29]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.97      1.00      0.98        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        42\n",
      "\n",
      "[12  1  0 29]\n",
      "svc Accuracy:  0.9761904761904762\n",
      "svc F1:  0.9715254237288136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       0.81      1.00      0.89        29\n",
      "\n",
      "avg / total       0.87      0.83      0.81        42\n",
      "\n",
      "[ 6  7  0 29]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.7619433198380567\n",
      "For name:  p_persson\n",
      "total sample size before apply threshold:  80\n",
      "Counter({'0000-0001-9172-3068': 39, '0000-0001-7600-3230': 26, '0000-0001-9140-6724': 8, '0000-0003-4468-032X': 7})\n",
      "['0000-0001-7600-3230', '0000-0001-9172-3068']\n",
      "Total sample size after apply threshold:  65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 172)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        26\n",
      "          1       0.87      1.00      0.93        39\n",
      "\n",
      "avg / total       0.92      0.91      0.90        65\n",
      "\n",
      "[20  6  0 39]\n",
      "MNB Accuracy:  0.9076923076923077\n",
      "MNB F1:  0.8990683229813665\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        26\n",
      "          1       0.89      1.00      0.94        39\n",
      "\n",
      "avg / total       0.93      0.92      0.92        65\n",
      "\n",
      "[21  5  0 39]\n",
      "svc Accuracy:  0.9230769230769231\n",
      "svc F1:  0.916688028710587\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.73        26\n",
      "          1       0.78      1.00      0.88        39\n",
      "\n",
      "avg / total       0.87      0.83      0.82        65\n",
      "\n",
      "[15 11  0 39]\n",
      "LR Accuracy:  0.8307692307692308\n",
      "LR F1:  0.8040559057275967\n",
      "For name:  y_tanaka\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-0674-660X': 12, '0000-0002-6190-4586': 5, '0000-0001-9598-5583': 2, '0000-0002-5163-7752': 1})\n",
      "['0000-0002-0674-660X']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  c_gao\n",
      "total sample size before apply threshold:  189\n",
      "Counter({'0000-0001-5084-7208': 144, '0000-0003-3429-3473': 17, '0000-0001-7386-692X': 13, '0000-0002-1445-7939': 11, '0000-0003-2792-5022': 2, '0000-0003-2736-3920': 1, '0000-0002-5456-451X': 1})\n",
      "['0000-0003-3429-3473', '0000-0002-1445-7939', '0000-0001-7386-692X', '0000-0001-5084-7208']\n",
      "Total sample size after apply threshold:  185\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(185, 131)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        17\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       0.84      1.00      0.91       144\n",
      "\n",
      "avg / total       0.81      0.85      0.80       185\n",
      "\n",
      "[  5   0   0  12   0   0   0  11   0   0   8   5   0   0   0 144]\n",
      "MNB Accuracy:  0.8486486486486486\n",
      "MNB F1:  0.5319606553783769\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.88      0.91        17\n",
      "          1       0.88      0.64      0.74        11\n",
      "          2       1.00      0.77      0.87        13\n",
      "          3       0.94      0.99      0.96       144\n",
      "\n",
      "avg / total       0.94      0.94      0.94       185\n",
      "\n",
      "[ 15   0   0   2   0   7   0   4   0   0  10   3   1   1   0 142]\n",
      "svc Accuracy:  0.9405405405405406\n",
      "svc F1:  0.8695525240380377\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        17\n",
      "          1       1.00      0.18      0.31        11\n",
      "          2       1.00      0.54      0.70        13\n",
      "          3       0.84      1.00      0.91       144\n",
      "\n",
      "avg / total       0.88      0.85      0.82       185\n",
      "\n",
      "[  5   0   0  12   0   2   0   9   0   0   7   6   0   0   0 144]\n",
      "LR Accuracy:  0.8540540540540541\n",
      "LR F1:  0.5941308691308691\n",
      "For name:  w_jung\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0002-8697-9584': 17, '0000-0002-6853-2885': 8, '0000-0001-5266-3795': 4, '0000-0001-9590-3859': 2, '0000-0002-1615-750X': 2})\n",
      "['0000-0002-8697-9584']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  s_lewis\n",
      "total sample size before apply threshold:  306\n",
      "Counter({'0000-0003-1861-4652': 112, '0000-0002-8343-612X': 69, '0000-0002-2049-1586': 35, '0000-0003-1210-2314': 27, '0000-0003-4555-4907': 20, '0000-0001-9537-5822': 19, '0000-0002-6929-6626': 15, '0000-0001-7262-3168': 7, '0000-0003-4557-4123': 1, '0000-0002-5250-7415': 1})\n",
      "['0000-0003-4555-4907', '0000-0001-9537-5822', '0000-0002-2049-1586', '0000-0002-8343-612X', '0000-0003-1861-4652', '0000-0002-6929-6626', '0000-0003-1210-2314']\n",
      "Total sample size after apply threshold:  297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(297, 1721)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "297\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        20\n",
      "          1       1.00      0.05      0.10        19\n",
      "          2       1.00      0.54      0.70        35\n",
      "          3       1.00      0.77      0.87        69\n",
      "          4       0.54      1.00      0.70       112\n",
      "          5       1.00      0.20      0.33        15\n",
      "          6       1.00      0.37      0.54        27\n",
      "\n",
      "avg / total       0.82      0.67      0.63       297\n",
      "\n",
      "[  2   0   0   0  18   0   0   0   1   0   0  18   0   0   0   0  19   0\n",
      "  16   0   0   0   0   0  53  16   0   0   0   0   0   0 112   0   0   0\n",
      "   0   0   0  12   3   0   0   0   0   0  17   0  10]\n",
      "MNB Accuracy:  0.6734006734006734\n",
      "MNB F1:  0.4894382190076997\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        20\n",
      "          1       1.00      0.63      0.77        19\n",
      "          2       1.00      0.74      0.85        35\n",
      "          3       0.97      0.94      0.96        69\n",
      "          4       0.74      1.00      0.85       112\n",
      "          5       1.00      0.80      0.89        15\n",
      "          6       1.00      0.63      0.77        27\n",
      "\n",
      "avg / total       0.90      0.86      0.86       297\n",
      "\n",
      "[ 12   0   0   0   8   0   0   0  12   0   0   7   0   0   0   0  26   0\n",
      "   9   0   0   0   0   0  65   4   0   0   0   0   0   0 112   0   0   0\n",
      "   0   0   0   3  12   0   0   0   0   2   8   0  17]\n",
      "svc Accuracy:  0.8619528619528619\n",
      "svc F1:  0.8351231579934068\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        20\n",
      "          1       1.00      0.32      0.48        19\n",
      "          2       1.00      0.57      0.73        35\n",
      "          3       1.00      0.86      0.92        69\n",
      "          4       0.61      1.00      0.75       112\n",
      "          5       1.00      0.40      0.57        15\n",
      "          6       1.00      0.48      0.65        27\n",
      "\n",
      "avg / total       0.85      0.75      0.74       297\n",
      "\n",
      "[  8   0   0   0  12   0   0   0   6   0   0  13   0   0   0   0  20   0\n",
      "  15   0   0   0   0   0  59  10   0   0   0   0   0   0 112   0   0   0\n",
      "   0   0   0   9   6   0   0   0   0   0  14   0  13]\n",
      "LR Accuracy:  0.7542087542087542\n",
      "LR F1:  0.6680305177626608\n",
      "For name:  w_han\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0001-9702-0523': 18, '0000-0001-8678-7147': 9, '0000-0003-2252-9311': 3, '0000-0002-4544-2908': 3, '0000-0002-7567-1883': 1})\n",
      "['0000-0001-9702-0523']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  m_shah\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0003-0299-8903': 10, '0000-0001-6126-7102': 2, '0000-0001-6599-7233': 2, '0000-0003-2191-7611': 1, '0000-0002-4354-9760': 1, '0000-0002-9740-8429': 1})\n",
      "['0000-0003-0299-8903']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  c_arango\n",
      "total sample size before apply threshold:  185\n",
      "Counter({'0000-0003-3382-4754': 177, '0000-0003-1098-830X': 6, '0000-0001-5920-5340': 1, '0000-0002-2970-4074': 1})\n",
      "['0000-0003-3382-4754']\n",
      "Total sample size after apply threshold:  177\n",
      "For name:  r_young\n",
      "total sample size before apply threshold:  361\n",
      "Counter({'0000-0002-6806-6503': 117, '0000-0001-8001-2914': 87, '0000-0002-6380-6314': 70, '0000-0001-7003-3017': 38, '0000-0001-6073-9489': 24, '0000-0002-1062-5691': 10, '0000-0002-5719-2205': 9, '0000-0001-7485-0604': 6})\n",
      "['0000-0001-8001-2914', '0000-0002-6806-6503', '0000-0001-7003-3017', '0000-0002-1062-5691', '0000-0001-6073-9489', '0000-0002-6380-6314']\n",
      "Total sample size after apply threshold:  346\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(346, 701)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "346\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.89      0.90        87\n",
      "          1       0.67      0.99      0.80       117\n",
      "          2       1.00      0.76      0.87        38\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.25      0.40        24\n",
      "          5       1.00      0.76      0.86        70\n",
      "\n",
      "avg / total       0.84      0.81      0.79       346\n",
      "\n",
      "[ 77  10   0   0   0   0   1 116   0   0   0   0   2   7  29   0   0   0\n",
      "   0  10   0   0   0   0   4  14   0   0   6   0   0  17   0   0   0  53]\n",
      "MNB Accuracy:  0.8121387283236994\n",
      "MNB F1:  0.6375493190175651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.94      0.77        87\n",
      "          1       0.98      0.95      0.97       117\n",
      "          2       0.97      0.79      0.87        38\n",
      "          3       1.00      0.40      0.57        10\n",
      "          4       1.00      0.58      0.74        24\n",
      "          5       0.90      0.76      0.82        70\n",
      "\n",
      "avg / total       0.88      0.85      0.85       346\n",
      "\n",
      "[ 82   0   1   0   0   4   5 111   0   0   0   1   8   0  30   0   0   0\n",
      "   4   2   0   4   0   0   9   0   0   0  14   1  17   0   0   0   0  53]\n",
      "svc Accuracy:  0.8497109826589595\n",
      "svc F1:  0.7897239362340579\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.93      0.76        87\n",
      "          1       0.85      0.97      0.90       117\n",
      "          2       0.96      0.71      0.82        38\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.25      0.40        24\n",
      "          5       1.00      0.77      0.87        70\n",
      "\n",
      "avg / total       0.83      0.81      0.79       346\n",
      "\n",
      "[ 81   5   1   0   0   0   4 113   0   0   0   0   9   2  27   0   0   0\n",
      "   4   6   0   0   0   0  15   3   0   0   6   0  12   4   0   0   0  54]\n",
      "LR Accuracy:  0.8121387283236994\n",
      "LR F1:  0.6262167505855881\n",
      "For name:  r_coleman\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0003-4136-5914': 15, '0000-0002-5194-8550': 13, '0000-0001-7118-524X': 3, '0000-0002-9731-7498': 3})\n",
      "['0000-0003-4136-5914', '0000-0002-5194-8550']\n",
      "Total sample size after apply threshold:  28\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 179)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90        15\n",
      "          1       0.92      0.85      0.88        13\n",
      "\n",
      "avg / total       0.89      0.89      0.89        28\n",
      "\n",
      "[14  1  2 11]\n",
      "MNB Accuracy:  0.8928571428571429\n",
      "MNB F1:  0.8916129032258064\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.89      0.86      0.85        28\n",
      "\n",
      "[15  0  4  9]\n",
      "svc Accuracy:  0.8571428571428571\n",
      "svc F1:  0.8502673796791443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        15\n",
      "          1       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.87      0.82      0.81        28\n",
      "\n",
      "[15  0  5  8]\n",
      "LR Accuracy:  0.8214285714285714\n",
      "LR F1:  0.8095238095238095\n",
      "For name:  b_kang\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0001-5902-0549': 10, '0000-0001-6946-2279': 5, '0000-0003-2637-4695': 2, '0000-0003-0901-4903': 1, '0000-0002-4299-2170': 1, '0000-0002-1690-7753': 1})\n",
      "['0000-0001-5902-0549']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  s_carter\n",
      "total sample size before apply threshold:  205\n",
      "Counter({'0000-0002-3585-9400': 124, '0000-0003-2617-8694': 44, '0000-0002-9080-519X': 15, '0000-0002-4670-0884': 12, '0000-0002-9817-0029': 5, '0000-0002-3619-8640': 2, '0000-0002-8169-4483': 2, '0000-0002-2907-9651': 1})\n",
      "['0000-0002-3585-9400', '0000-0002-4670-0884', '0000-0003-2617-8694', '0000-0002-9080-519X']\n",
      "Total sample size after apply threshold:  195\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(195, 439)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "195\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90       124\n",
      "          1       1.00      0.50      0.67        12\n",
      "          2       0.91      0.70      0.79        44\n",
      "          3       1.00      0.40      0.57        15\n",
      "\n",
      "avg / total       0.87      0.85      0.84       195\n",
      "\n",
      "[123   0   1   0   6   6   0   0  13   0  31   0   7   0   2   6]\n",
      "MNB Accuracy:  0.8512820512820513\n",
      "MNB F1:  0.7335164835164836\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       124\n",
      "          1       1.00      0.58      0.74        12\n",
      "          2       1.00      0.75      0.86        44\n",
      "          3       1.00      0.67      0.80        15\n",
      "\n",
      "avg / total       0.91      0.89      0.89       195\n",
      "\n",
      "[124   0   0   0   5   7   0   0  11   0  33   0   5   0   0  10]\n",
      "svc Accuracy:  0.8923076923076924\n",
      "svc F1:  0.8289795119769685\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85       124\n",
      "          1       1.00      0.50      0.67        12\n",
      "          2       1.00      0.45      0.62        44\n",
      "          3       1.00      0.13      0.24        15\n",
      "\n",
      "avg / total       0.84      0.78      0.74       195\n",
      "\n",
      "[124   0   0   0   6   6   0   0  24   0  20   0  13   0   0   2]\n",
      "LR Accuracy:  0.7794871794871795\n",
      "LR F1:  0.5947986153224176\n",
      "For name:  c_thomas\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0003-2822-1334': 56, '0000-0001-5855-1196': 15, '0000-0003-0316-6391': 15, '0000-0001-8704-3262': 8, '0000-0003-3091-5757': 2, '0000-0002-0351-0466': 2, '0000-0001-6662-6362': 2, '0000-0001-5706-3940': 1, '0000-0001-6536-4591': 1})\n",
      "['0000-0001-5855-1196', '0000-0003-2822-1334', '0000-0003-0316-6391']\n",
      "Total sample size after apply threshold:  86\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 280)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        15\n",
      "          1       0.70      1.00      0.82        56\n",
      "          2       1.00      0.07      0.12        15\n",
      "\n",
      "avg / total       0.80      0.72      0.65        86\n",
      "\n",
      "[ 5 10  0  0 56  0  0 14  1]\n",
      "MNB Accuracy:  0.7209302325581395\n",
      "MNB F1:  0.48284313725490197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        15\n",
      "          1       0.74      1.00      0.85        56\n",
      "          2       1.00      0.27      0.42        15\n",
      "\n",
      "avg / total       0.83      0.77      0.73        86\n",
      "\n",
      "[ 6  9  0  0 56  0  0 11  4]\n",
      "svc Accuracy:  0.7674418604651163\n",
      "svc F1:  0.6136553504974557\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.12        15\n",
      "          1       0.66      1.00      0.79        56\n",
      "          2       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.60      0.66      0.54        86\n",
      "\n",
      "[ 1 14  0  0 56  0  0 15  0]\n",
      "LR Accuracy:  0.6627906976744186\n",
      "LR F1:  0.3064420803782506\n",
      "For name:  m_gutierrez\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0003-3199-0337': 30, '0000-0003-0964-6222': 2})\n",
      "['0000-0003-3199-0337']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  s_moon\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0001-6248-9049': 30, '0000-0002-7513-4404': 20, '0000-0001-7282-2888': 16, '0000-0002-3803-6354': 16, '0000-0002-2249-7500': 1, '0000-0002-4662-7859': 1, '0000-0002-4989-0150': 1})\n",
      "['0000-0001-6248-9049', '0000-0001-7282-2888', '0000-0002-3803-6354', '0000-0002-7513-4404']\n",
      "Total sample size after apply threshold:  82\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 93)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.97      0.77        30\n",
      "          1       0.91      0.62      0.74        16\n",
      "          2       0.62      0.31      0.42        16\n",
      "          3       0.72      0.65      0.68        20\n",
      "\n",
      "avg / total       0.71      0.70      0.68        82\n",
      "\n",
      "[29  0  0  1  4 10  2  0  6  1  5  4  6  0  1 13]\n",
      "MNB Accuracy:  0.6951219512195121\n",
      "MNB F1:  0.6537378167641326\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        30\n",
      "          1       0.88      0.88      0.88        16\n",
      "          2       0.79      0.69      0.73        16\n",
      "          3       0.82      0.90      0.86        20\n",
      "\n",
      "avg / total       0.87      0.87      0.86        82\n",
      "\n",
      "[28  0  1  1  0 14  2  0  1  1 11  3  1  1  0 18]\n",
      "svc Accuracy:  0.8658536585365854\n",
      "svc F1:  0.849702380952381\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.93      0.84        30\n",
      "          1       0.92      0.75      0.83        16\n",
      "          2       0.69      0.56      0.62        16\n",
      "          3       0.79      0.75      0.77        20\n",
      "\n",
      "avg / total       0.78      0.78      0.78        82\n",
      "\n",
      "[28  0  1  1  1 12  2  1  4  1  9  2  4  0  1 15]\n",
      "LR Accuracy:  0.7804878048780488\n",
      "LR F1:  0.7633318817055307\n",
      "For name:  r_pereira\n",
      "total sample size before apply threshold:  202\n",
      "Counter({'0000-0001-6857-5968': 74, '0000-0003-3704-2848': 39, '0000-0002-3889-798X': 29, '0000-0002-8076-4822': 14, '0000-0002-7514-6130': 14, '0000-0003-1800-1450': 8, '0000-0001-7279-5728': 6, '0000-0003-2767-8535': 5, '0000-0003-1146-7506': 3, '0000-0003-1553-9693': 3, '0000-0001-8500-7364': 2, '0000-0002-3834-3709': 2, '0000-0002-5618-7690': 1, '0000-0002-9841-4775': 1, '0000-0002-2176-016X': 1})\n",
      "['0000-0002-8076-4822', '0000-0002-7514-6130', '0000-0002-3889-798X', '0000-0001-6857-5968', '0000-0003-3704-2848']\n",
      "Total sample size after apply threshold:  170\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(170, 377)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "170\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       1.00      0.57      0.73        14\n",
      "          2       1.00      0.76      0.86        29\n",
      "          3       0.65      1.00      0.79        74\n",
      "          4       0.89      0.62      0.73        39\n",
      "\n",
      "avg / total       0.74      0.75      0.72       170\n",
      "\n",
      "[ 0  0  0 12  2  0  8  0  6  0  0  0 22  6  1  0  0  0 74  0  0  0  0 15\n",
      " 24]\n",
      "MNB Accuracy:  0.7529411764705882\n",
      "MNB F1:  0.62174688057041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        14\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       0.96      0.86      0.91        29\n",
      "          3       0.95      0.95      0.95        74\n",
      "          4       0.73      0.95      0.82        39\n",
      "\n",
      "avg / total       0.91      0.89      0.89       170\n",
      "\n",
      "[ 7  0  0  1  6  0 12  0  1  1  0  0 25  1  3  0  0  0 70  4  0  0  1  1\n",
      " 37]\n",
      "svc Accuracy:  0.888235294117647\n",
      "svc F1:  0.8534005334005335\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        14\n",
      "          1       1.00      0.79      0.88        14\n",
      "          2       0.96      0.83      0.89        29\n",
      "          3       0.83      0.96      0.89        74\n",
      "          4       0.76      0.79      0.77        39\n",
      "\n",
      "avg / total       0.86      0.85      0.84       170\n",
      "\n",
      "[ 7  0  0  3  4  0 11  0  2  1  0  0 24  3  2  0  0  0 71  3  0  0  1  7\n",
      " 31]\n",
      "LR Accuracy:  0.8470588235294118\n",
      "LR F1:  0.8196111111111112\n",
      "For name:  a_nielsen\n",
      "total sample size before apply threshold:  132\n",
      "Counter({'0000-0003-4372-9961': 70, '0000-0001-6616-0187': 27, '0000-0003-4464-8549': 17, '0000-0002-6469-4473': 7, '0000-0002-4837-9449': 3, '0000-0001-9842-5303': 2, '0000-0002-4741-7992': 2, '0000-0002-8955-9374': 2, '0000-0003-2199-2857': 1, '0000-0002-7130-6432': 1})\n",
      "['0000-0001-6616-0187', '0000-0003-4372-9961', '0000-0003-4464-8549']\n",
      "Total sample size after apply threshold:  114\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 270)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "114\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        27\n",
      "          1       0.78      1.00      0.88        70\n",
      "          2       1.00      0.94      0.97        17\n",
      "\n",
      "avg / total       0.86      0.82      0.79       114\n",
      "\n",
      "[ 8 19  0  0 70  0  0  1 16]\n",
      "MNB Accuracy:  0.8245614035087719\n",
      "MNB F1:  0.7672799422799423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.83        27\n",
      "          1       0.89      1.00      0.94        70\n",
      "          2       1.00      0.94      0.97        17\n",
      "\n",
      "avg / total       0.93      0.92      0.92       114\n",
      "\n",
      "[19  8  0  0 70  0  0  1 16]\n",
      "svc Accuracy:  0.9210526315789473\n",
      "svc F1:  0.9117937472183169\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.14        27\n",
      "          1       0.72      1.00      0.84        70\n",
      "          2       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.83      0.76      0.69       114\n",
      "\n",
      "[ 2 25  0  0 70  0  0  2 15]\n",
      "LR Accuracy:  0.7631578947368421\n",
      "LR F1:  0.6379181292587239\n",
      "For name:  j_conde\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0001-8422-6792': 35, '0000-0002-2187-479X': 29, '0000-0002-5677-3024': 19, '0000-0001-8739-6893': 1})\n",
      "['0000-0001-8422-6792', '0000-0002-5677-3024', '0000-0002-2187-479X']\n",
      "Total sample size after apply threshold:  83\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(83, 131)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        35\n",
      "          1       0.95      0.95      0.95        19\n",
      "          2       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        83\n",
      "\n",
      "[34  1  0  1 18  0  0  0 29]\n",
      "MNB Accuracy:  0.9759036144578314\n",
      "MNB F1:  0.9729323308270676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        35\n",
      "          1       1.00      0.89      0.94        19\n",
      "          2       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        83\n",
      "\n",
      "[35  0  0  2 17  0  0  0 29]\n",
      "svc Accuracy:  0.9759036144578314\n",
      "svc F1:  0.9722222222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        35\n",
      "          1       1.00      0.89      0.94        19\n",
      "          2       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        83\n",
      "\n",
      "[35  0  0  2 17  0  0  0 29]\n",
      "LR Accuracy:  0.9759036144578314\n",
      "LR F1:  0.9722222222222222\n",
      "For name:  k_wright\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0003-0040-9247': 18, '0000-0002-9020-1572': 15, '0000-0003-3865-9743': 12, '0000-0002-0387-3048': 7, '0000-0001-6202-1737': 6, '0000-0003-0700-6010': 1})\n",
      "['0000-0003-0040-9247', '0000-0002-9020-1572', '0000-0003-3865-9743']\n",
      "Total sample size after apply threshold:  45\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 2167)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        18\n",
      "          1       0.93      0.93      0.93        15\n",
      "          2       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.89      0.87      0.86        45\n",
      "\n",
      "[18  0  0  1 14  0  4  1  7]\n",
      "MNB Accuracy:  0.8666666666666667\n",
      "MNB F1:  0.8494080730280987\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        18\n",
      "          1       1.00      0.87      0.93        15\n",
      "          2       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.90      0.87      0.87        45\n",
      "\n",
      "[18  0  0  2 13  0  4  0  8]\n",
      "svc Accuracy:  0.8666666666666667\n",
      "svc F1:  0.8619047619047618\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80        18\n",
      "          1       1.00      0.73      0.85        15\n",
      "          2       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.87      0.80      0.80        45\n",
      "\n",
      "[18  0  0  4 11  0  5  0  7]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.794331983805668\n",
      "For name:  m_parker\n",
      "total sample size before apply threshold:  280\n",
      "Counter({'0000-0002-3101-1138': 232, '0000-0002-7172-5231': 13, '0000-0003-1007-4612': 11, '0000-0002-3772-3742': 10, '0000-0002-1052-9296': 6, '0000-0002-3170-3505': 4, '0000-0002-1597-4858': 3, '0000-0001-9845-9108': 1})\n",
      "['0000-0002-3101-1138', '0000-0003-1007-4612', '0000-0002-7172-5231', '0000-0002-3772-3742']\n",
      "Total sample size after apply threshold:  266\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(266, 873)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "266\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93       232\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.80      0.88      0.82       266\n",
      "\n",
      "[232   0   0   0  10   1   0   0  13   0   0   0  10   0   0   0]\n",
      "MNB Accuracy:  0.8759398496240601\n",
      "MNB F1:  0.2750670690811536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96       232\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.94      0.94      0.93       266\n",
      "\n",
      "[232   0   0   0   5   6   0   0   5   0   8   0   7   0   0   3]\n",
      "svc Accuracy:  0.9360902255639098\n",
      "svc F1:  0.7234956352603412\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       232\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.76      0.87      0.81       266\n",
      "\n",
      "[232   0   0   0  11   0   0   0  13   0   0   0  10   0   0   0]\n",
      "LR Accuracy:  0.8721804511278195\n",
      "LR F1:  0.2329317269076305\n",
      "For name:  h_huang\n",
      "total sample size before apply threshold:  224\n",
      "Counter({'0000-0002-3386-0934': 87, '0000-0002-3382-305X': 24, '0000-0001-7640-7702': 18, '0000-0003-2657-3635': 16, '0000-0003-1461-5762': 16, '0000-0001-5497-0158': 14, '0000-0002-3778-4457': 9, '0000-0002-5647-7049': 6, '0000-0002-0919-4644': 5, '0000-0003-1743-7850': 5, '0000-0002-4564-7604': 5, '0000-0002-9665-2489': 4, '0000-0002-0534-2718': 4, '0000-0002-5948-317X': 3, '0000-0002-4104-9471': 2, '0000-0001-8346-1571': 1, '0000-0002-2650-3736': 1, '0000-0001-8237-0168': 1, '0000-0002-1188-9760': 1, '0000-0001-6455-676X': 1, '0000-0003-4184-3744': 1})\n",
      "['0000-0001-7640-7702', '0000-0002-3382-305X', '0000-0001-5497-0158', '0000-0003-2657-3635', '0000-0002-3386-0934', '0000-0003-1461-5762']\n",
      "Total sample size after apply threshold:  175\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 906)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.28      0.43        18\n",
      "          1       0.45      0.21      0.29        24\n",
      "          2       1.00      0.29      0.44        14\n",
      "          3       1.00      0.38      0.55        16\n",
      "          4       0.60      1.00      0.75        87\n",
      "          5       1.00      0.25      0.40        16\n",
      "\n",
      "avg / total       0.73      0.63      0.58       175\n",
      "\n",
      "[ 5  0  0  0 13  0  0  5  0  0 19  0  0  0  4  0 10  0  0  1  0  6  9  0\n",
      "  0  0  0  0 87  0  0  5  0  0  7  4]\n",
      "MNB Accuracy:  0.6342857142857142\n",
      "MNB F1:  0.47673264738482124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.78      0.82        18\n",
      "          1       0.80      0.83      0.82        24\n",
      "          2       1.00      0.79      0.88        14\n",
      "          3       1.00      0.88      0.93        16\n",
      "          4       0.89      0.98      0.93        87\n",
      "          5       0.85      0.69      0.76        16\n",
      "\n",
      "avg / total       0.89      0.89      0.88       175\n",
      "\n",
      "[14  3  0  0  1  0  2 20  0  0  2  0  0  1 11  0  2  0  0  0  0 14  1  1\n",
      "  0  1  0  0 85  1  0  0  0  0  5 11]\n",
      "svc Accuracy:  0.8857142857142857\n",
      "svc F1:  0.856795285666556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.67      0.77        18\n",
      "          1       1.00      0.42      0.59        24\n",
      "          2       1.00      0.57      0.73        14\n",
      "          3       1.00      0.56      0.72        16\n",
      "          4       0.67      1.00      0.81        87\n",
      "          5       1.00      0.38      0.55        16\n",
      "\n",
      "avg / total       0.83      0.75      0.73       175\n",
      "\n",
      "[12  0  0  0  6  0  1 10  0  0 13  0  0  0  8  0  6  0  0  0  0  9  7  0\n",
      "  0  0  0  0 87  0  0  0  0  0 10  6]\n",
      "LR Accuracy:  0.7542857142857143\n",
      "LR F1:  0.6934519451312621\n",
      "For name:  j_terry\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-6829-5736': 35, '0000-0001-5464-8679': 20, '0000-0003-4255-5509': 1, '0000-0002-6314-1412': 1})\n",
      "['0000-0001-5464-8679', '0000-0002-6829-5736']\n",
      "Total sample size after apply threshold:  55\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 207)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.26        20\n",
      "          1       0.67      1.00      0.80        35\n",
      "\n",
      "avg / total       0.79      0.69      0.61        55\n",
      "\n",
      "[ 3 17  0 35]\n",
      "MNB Accuracy:  0.6909090909090909\n",
      "MNB F1:  0.5327336331834083\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86        20\n",
      "          1       0.94      0.89      0.91        35\n",
      "\n",
      "avg / total       0.90      0.89      0.89        55\n",
      "\n",
      "[18  2  4 31]\n",
      "svc Accuracy:  0.8909090909090909\n",
      "svc F1:  0.884453781512605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        20\n",
      "          1       0.66      1.00      0.80        35\n",
      "\n",
      "avg / total       0.78      0.67      0.57        55\n",
      "\n",
      "[ 2 18  0 35]\n",
      "LR Accuracy:  0.6727272727272727\n",
      "LR F1:  0.48863636363636365\n",
      "For name:  y_xu\n",
      "total sample size before apply threshold:  137\n",
      "Counter({'0000-0002-2195-1695': 47, '0000-0002-6689-7768': 19, '0000-0002-6406-7832': 17, '0000-0001-6643-3173': 9, '0000-0002-0763-9953': 8, '0000-0002-4479-6157': 8, '0000-0001-7429-4724': 5, '0000-0002-5578-4960': 4, '0000-0002-1887-0632': 4, '0000-0002-9834-3006': 3, '0000-0002-9945-3514': 3, '0000-0001-8488-0399': 2, '0000-0001-9106-0049': 1, '0000-0003-4549-6110': 1, '0000-0002-2341-7971': 1, '0000-0003-4420-6353': 1, '0000-0002-7963-6890': 1, '0000-0002-7962-6668': 1, '0000-0003-1355-0055': 1, '0000-0002-1563-8811': 1})\n",
      "['0000-0002-6406-7832', '0000-0002-2195-1695', '0000-0002-6689-7768']\n",
      "Total sample size after apply threshold:  83\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(83, 154)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.38        17\n",
      "          1       0.67      1.00      0.80        47\n",
      "          2       1.00      0.47      0.64        19\n",
      "\n",
      "avg / total       0.81      0.72      0.68        83\n",
      "\n",
      "[ 4 13  0  0 47  0  0 10  9]\n",
      "MNB Accuracy:  0.7228915662650602\n",
      "MNB F1:  0.6090761090761091\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.87        17\n",
      "          1       0.84      1.00      0.91        47\n",
      "          2       0.86      0.63      0.73        19\n",
      "\n",
      "avg / total       0.88      0.87      0.86        83\n",
      "\n",
      "[13  2  2  0 47  0  0  7 12]\n",
      "svc Accuracy:  0.8674698795180723\n",
      "svc F1:  0.8355202510542316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        17\n",
      "          1       0.70      1.00      0.82        47\n",
      "          2       1.00      0.47      0.64        19\n",
      "\n",
      "avg / total       0.83      0.76      0.73        83\n",
      "\n",
      "[ 7 10  0  0 47  0  0 10  9]\n",
      "LR Accuracy:  0.7590361445783133\n",
      "LR F1:  0.6835839598997494\n",
      "For name:  a_melo\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-6455-7834': 26, '0000-0002-9153-0773': 11, '0000-0002-4606-7791': 7, '0000-0001-5682-2116': 4})\n",
      "['0000-0001-6455-7834', '0000-0002-9153-0773']\n",
      "Total sample size after apply threshold:  37\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 84)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        26\n",
      "          1       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.95      0.95      0.94        37\n",
      "\n",
      "[26  0  2  9]\n",
      "MNB Accuracy:  0.9459459459459459\n",
      "MNB F1:  0.9314814814814816\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        26\n",
      "          1       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.95      0.95      0.94        37\n",
      "\n",
      "[26  0  2  9]\n",
      "svc Accuracy:  0.9459459459459459\n",
      "svc F1:  0.9314814814814816\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        26\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.91      0.89      0.88        37\n",
      "\n",
      "[26  0  4  7]\n",
      "LR Accuracy:  0.8918918918918919\n",
      "LR F1:  0.8531746031746033\n",
      "For name:  r_doyle\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0001-6229-4700': 5, '0000-0001-5001-1945': 4, '0000-0003-1019-6783': 1, '0000-0002-4704-7178': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_bernardo\n",
      "total sample size before apply threshold:  250\n",
      "Counter({'0000-0001-8748-6717': 216, '0000-0002-9204-7230': 22, '0000-0002-5823-6636': 11, '0000-0003-2661-5380': 1})\n",
      "['0000-0002-9204-7230', '0000-0001-8748-6717', '0000-0002-5823-6636']\n",
      "Total sample size after apply threshold:  249\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(249, 586)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.98        22\n",
      "          1       0.97      1.00      0.99       216\n",
      "          2       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.98      0.98      0.97       249\n",
      "\n",
      "[ 21   1   0   0 216   0   0   5   6]\n",
      "MNB Accuracy:  0.9759036144578314\n",
      "MNB F1:  0.8896426362835673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93        22\n",
      "          1       0.99      1.00      0.99       216\n",
      "          2       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       0.99      0.99      0.99       249\n",
      "\n",
      "[ 19   3   0   0 216   0   0   0  11]\n",
      "svc Accuracy:  0.9879518072289156\n",
      "svc F1:  0.9733109055228484\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        22\n",
      "          1       0.90      1.00      0.95       216\n",
      "          2       1.00      0.27      0.43        11\n",
      "\n",
      "avg / total       0.92      0.91      0.89       249\n",
      "\n",
      "[  7  15   0   0 216   0   0   8   3]\n",
      "LR Accuracy:  0.9076305220883534\n",
      "LR F1:  0.6202601995705445\n",
      "For name:  j_soares\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0001-6558-4973': 17, '0000-0002-2775-131X': 8, '0000-0002-7105-2815': 6, '0000-0003-3464-6208': 5, '0000-0002-7241-8719': 5, '0000-0001-8496-156X': 3, '0000-0003-3908-0741': 2, '0000-0001-5277-4575': 2, '0000-0001-6534-1824': 1})\n",
      "['0000-0001-6558-4973']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  j_richard\n",
      "total sample size before apply threshold:  179\n",
      "Counter({'0000-0002-0440-2387': 110, '0000-0003-1503-3035': 57, '0000-0001-5750-0418': 10, '0000-0003-2514-8282': 2})\n",
      "['0000-0002-0440-2387', '0000-0003-1503-3035', '0000-0001-5750-0418']\n",
      "Total sample size after apply threshold:  177\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(177, 307)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "177\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       110\n",
      "          1       1.00      0.89      0.94        57\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.86      0.91      0.88       177\n",
      "\n",
      "[110   0   0   6  51   0  10   0   0]\n",
      "MNB Accuracy:  0.9096045197740112\n",
      "MNB F1:  0.625549278091651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       110\n",
      "          1       1.00      0.89      0.94        57\n",
      "          2       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.95      0.94      0.94       177\n",
      "\n",
      "[110   0   0   6  51   0   4   0   6]\n",
      "svc Accuracy:  0.943502824858757\n",
      "svc F1:  0.8836553945249598\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       110\n",
      "          1       1.00      0.82      0.90        57\n",
      "          2       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.92      0.90      0.89       177\n",
      "\n",
      "[110   0   0  10  47   0   7   0   3]\n",
      "LR Accuracy:  0.903954802259887\n",
      "LR F1:  0.7645515525262362\n",
      "For name:  p_robinson\n",
      "total sample size before apply threshold:  275\n",
      "Counter({'0000-0002-7878-0313': 133, '0000-0002-0736-9199': 119, '0000-0002-3156-3418': 19, '0000-0002-0577-3147': 4})\n",
      "['0000-0002-0736-9199', '0000-0002-7878-0313', '0000-0002-3156-3418']\n",
      "Total sample size after apply threshold:  271\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(271, 1067)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "271\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.94      0.97       119\n",
      "          1       0.84      1.00      0.91       133\n",
      "          2       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.85      0.90      0.87       271\n",
      "\n",
      "[112   7   0   0 133   0   1  18   0]\n",
      "MNB Accuracy:  0.9040590405904059\n",
      "MNB F1:  0.626535529486116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97       119\n",
      "          1       0.90      1.00      0.95       133\n",
      "          2       1.00      0.53      0.69        19\n",
      "\n",
      "avg / total       0.95      0.94      0.94       271\n",
      "\n",
      "[113   6   0   0 133   0   0   9  10]\n",
      "svc Accuracy:  0.9446494464944649\n",
      "svc F1:  0.8701374401767089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95       119\n",
      "          1       0.83      1.00      0.91       133\n",
      "          2       1.00      0.16      0.27        19\n",
      "\n",
      "avg / total       0.92      0.90      0.88       271\n",
      "\n",
      "[108  11   0   0 133   0   0  16   3]\n",
      "LR Accuracy:  0.9003690036900369\n",
      "LR F1:  0.7107063174330243\n",
      "For name:  c_zou\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0003-2484-7292': 22, '0000-0001-8569-3747': 8, '0000-0003-4305-5055': 1, '0000-0002-9712-4282': 1})\n",
      "['0000-0003-2484-7292']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  s_rana\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-8039-1149': 30, '0000-0001-9197-8378': 9, '0000-0003-0628-7076': 2, '0000-0002-6604-997X': 1})\n",
      "['0000-0002-8039-1149']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  a_nunes\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0003-2760-3277': 18, '0000-0001-9102-3600': 11, '0000-0001-8893-9247': 9, '0000-0001-8844-8333': 5, '0000-0002-3296-0183': 5, '0000-0002-0595-5821': 4, '0000-0002-5001-3534': 2, '0000-0002-4789-0253': 2, '0000-0003-4440-0391': 2, '0000-0001-6847-5764': 2, '0000-0001-8665-4459': 1})\n",
      "['0000-0001-9102-3600', '0000-0003-2760-3277']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 79)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       0.75      1.00      0.86        18\n",
      "\n",
      "avg / total       0.84      0.79      0.77        29\n",
      "\n",
      "[ 5  6  0 18]\n",
      "MNB Accuracy:  0.7931034482758621\n",
      "MNB F1:  0.7410714285714286\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.64      0.74        11\n",
      "          1       0.81      0.94      0.87        18\n",
      "\n",
      "avg / total       0.83      0.83      0.82        29\n",
      "\n",
      "[ 7  4  1 17]\n",
      "svc Accuracy:  0.8275862068965517\n",
      "svc F1:  0.8043184885290149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       0.75      1.00      0.86        18\n",
      "\n",
      "avg / total       0.84      0.79      0.77        29\n",
      "\n",
      "[ 5  6  0 18]\n",
      "LR Accuracy:  0.7931034482758621\n",
      "LR F1:  0.7410714285714286\n",
      "For name:  s_jeong\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0001-6178-8338': 33, '0000-0002-1958-8436': 21, '0000-0002-6376-7001': 13, '0000-0002-6480-7685': 7, '0000-0002-9084-5183': 6, '0000-0001-8995-3497': 5, '0000-0002-8370-3566': 1, '0000-0002-4004-3510': 1, '0000-0001-9175-9642': 1, '0000-0001-9197-1184': 1, '0000-0002-9868-621X': 1, '0000-0002-3309-0693': 1, '0000-0001-9575-0354': 1, '0000-0001-9588-1928': 1})\n",
      "['0000-0002-6376-7001', '0000-0002-1958-8436', '0000-0001-6178-8338']\n",
      "Total sample size after apply threshold:  67\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 138)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.75      0.57      0.65        21\n",
      "          2       0.68      0.97      0.80        33\n",
      "\n",
      "avg / total       0.76      0.72      0.69        67\n",
      "\n",
      "[ 4  3  6  0 12  9  0  1 32]\n",
      "MNB Accuracy:  0.7164179104477612\n",
      "MNB F1:  0.639745627980922\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.84      0.76      0.80        21\n",
      "          2       0.86      0.94      0.90        33\n",
      "\n",
      "avg / total       0.88      0.88      0.88        67\n",
      "\n",
      "[12  1  0  0 16  5  0  2 31]\n",
      "svc Accuracy:  0.8805970149253731\n",
      "svc F1:  0.8861835748792272\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        13\n",
      "          1       0.84      0.76      0.80        21\n",
      "          2       0.84      0.97      0.90        33\n",
      "\n",
      "avg / total       0.87      0.87      0.86        67\n",
      "\n",
      "[10  2  1  0 16  5  0  1 32]\n",
      "LR Accuracy:  0.8656716417910447\n",
      "LR F1:  0.85699122269851\n",
      "For name:  b_olsen\n",
      "total sample size before apply threshold:  213\n",
      "Counter({'0000-0002-4646-691X': 167, '0000-0002-7272-7140': 35, '0000-0001-9758-3641': 6, '0000-0001-5608-2779': 3, '0000-0002-6551-6812': 2})\n",
      "['0000-0002-7272-7140', '0000-0002-4646-691X']\n",
      "Total sample size after apply threshold:  202\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(202, 442)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "202\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        35\n",
      "          1       0.92      1.00      0.96       167\n",
      "\n",
      "avg / total       0.94      0.93      0.92       202\n",
      "\n",
      "[ 21  14   0 167]\n",
      "MNB Accuracy:  0.9306930693069307\n",
      "MNB F1:  0.8548850574712643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        35\n",
      "          1       0.95      1.00      0.97       167\n",
      "\n",
      "avg / total       0.96      0.96      0.95       202\n",
      "\n",
      "[ 26   9   0 167]\n",
      "svc Accuracy:  0.9554455445544554\n",
      "svc F1:  0.9131099746690245\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.11      0.21        35\n",
      "          1       0.84      1.00      0.92       167\n",
      "\n",
      "avg / total       0.87      0.85      0.79       202\n",
      "\n",
      "[  4  31   0 167]\n",
      "LR Accuracy:  0.8465346534653465\n",
      "LR F1:  0.560098349139445\n",
      "For name:  m_reilly\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0001-8029-0084': 17, '0000-0002-5526-8245': 1, '0000-0001-8746-3224': 1, '0000-0003-2506-3190': 1})\n",
      "['0000-0001-8029-0084']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  d_nguyen\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-4997-555X': 8, '0000-0002-3283-3504': 7, '0000-0001-6420-7308': 3, '0000-0002-6811-5897': 2, '0000-0001-6432-4467': 2, '0000-0002-1694-0617': 1, '0000-0001-7720-3592': 1, '0000-0002-9680-5772': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_santos\n",
      "total sample size before apply threshold:  184\n",
      "Counter({'0000-0003-3737-8296': 33, '0000-0002-1577-1663': 29, '0000-0001-5071-443X': 20, '0000-0002-3085-5128': 16, '0000-0001-7720-6806': 13, '0000-0002-7394-7604': 13, '0000-0002-4830-0470': 11, '0000-0001-6182-1708': 8, '0000-0002-7604-5753': 7, '0000-0001-5240-6799': 6, '0000-0003-0126-7420': 6, '0000-0002-8368-8618': 4, '0000-0001-8183-9649': 4, '0000-0001-6071-8100': 4, '0000-0002-0070-5735': 2, '0000-0003-4395-8078': 2, '0000-0001-7922-5357': 1, '0000-0002-9133-2187': 1, '0000-0002-7861-4366': 1, '0000-0002-5431-4756': 1, '0000-0001-6328-8097': 1, '0000-0001-5845-5698': 1})\n",
      "['0000-0003-3737-8296', '0000-0002-4830-0470', '0000-0001-7720-6806', '0000-0001-5071-443X', '0000-0002-1577-1663', '0000-0002-3085-5128', '0000-0002-7394-7604']\n",
      "Total sample size after apply threshold:  135\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(135, 235)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        33\n",
      "          1       1.00      0.45      0.62        11\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       1.00      0.80      0.89        20\n",
      "          4       0.64      0.93      0.76        29\n",
      "          5       1.00      0.81      0.90        16\n",
      "          6       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.88      0.83      0.83       135\n",
      "\n",
      "[33  0  0  0  0  0  0  2  5  0  0  4  0  0  0  0  8  0  5  0  0  2  0  0\n",
      " 16  2  0  0  2  0  0  0 27  0  0  1  0  0  0  2 13  0  1  0  0  0  2  0\n",
      " 10]\n",
      "MNB Accuracy:  0.8296296296296296\n",
      "MNB F1:  0.8134808377852097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        33\n",
      "          1       0.88      0.64      0.74        11\n",
      "          2       0.92      0.85      0.88        13\n",
      "          3       0.95      0.90      0.92        20\n",
      "          4       0.74      1.00      0.85        29\n",
      "          5       1.00      0.81      0.90        16\n",
      "          6       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.92      0.90      0.90       135\n",
      "\n",
      "[33  0  0  0  0  0  0  0  7  1  1  2  0  0  0  0 11  0  2  0  0  0  1  0\n",
      " 18  1  0  0  0  0  0  0 29  0  0  0  0  0  0  3 13  0  0  0  0  0  2  0\n",
      " 11]\n",
      "svc Accuracy:  0.9037037037037037\n",
      "svc F1:  0.8865826565164666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        33\n",
      "          1       1.00      0.64      0.78        11\n",
      "          2       0.89      0.62      0.73        13\n",
      "          3       1.00      0.90      0.95        20\n",
      "          4       0.64      0.97      0.77        29\n",
      "          5       1.00      0.81      0.90        16\n",
      "          6       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.90      0.87      0.87       135\n",
      "\n",
      "[33  0  0  0  0  0  0  0  7  1  0  3  0  0  0  0  8  0  5  0  0  0  0  0\n",
      " 18  2  0  0  1  0  0  0 28  0  0  0  0  0  0  3 13  0  0  0  0  0  3  0\n",
      " 10]\n",
      "LR Accuracy:  0.8666666666666667\n",
      "LR F1:  0.8529619688813251\n",
      "For name:  f_ferreira\n",
      "total sample size before apply threshold:  224\n",
      "Counter({'0000-0003-0989-2335': 125, '0000-0002-7571-1830': 18, '0000-0002-9160-7355': 18, '0000-0001-5765-576X': 16, '0000-0003-1516-1221': 15, '0000-0003-3326-1250': 12, '0000-0001-9616-295X': 5, '0000-0001-8714-2615': 5, '0000-0001-5177-6237': 4, '0000-0002-8857-2438': 3, '0000-0001-5815-2136': 2, '0000-0001-8818-6521': 1})\n",
      "['0000-0003-0989-2335', '0000-0003-1516-1221', '0000-0002-7571-1830', '0000-0003-3326-1250', '0000-0001-5765-576X', '0000-0002-9160-7355']\n",
      "Total sample size after apply threshold:  204\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(204, 649)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "204\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84       125\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       1.00      0.89      0.94        18\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       1.00      0.19      0.32        16\n",
      "          5       1.00      0.28      0.43        18\n",
      "\n",
      "avg / total       0.75      0.76      0.70       204\n",
      "\n",
      "[125   0   0   0   0   0  15   0   0   0   0   0   2   0  16   0   0   0\n",
      "   6   0   0   6   0   0  13   0   0   0   3   0  13   0   0   0   0   5]\n",
      "MNB Accuracy:  0.7598039215686274\n",
      "MNB F1:  0.5324226034954262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       125\n",
      "          1       1.00      0.20      0.33        15\n",
      "          2       1.00      0.94      0.97        18\n",
      "          3       1.00      0.92      0.96        12\n",
      "          4       0.86      0.75      0.80        16\n",
      "          5       1.00      0.61      0.76        18\n",
      "\n",
      "avg / total       0.89      0.88      0.86       204\n",
      "\n",
      "[125   0   0   0   0   0  12   3   0   0   0   0   1   0  17   0   0   0\n",
      "   1   0   0  11   0   0   4   0   0   0  12   0   5   0   0   0   2  11]\n",
      "svc Accuracy:  0.8774509803921569\n",
      "svc F1:  0.7892758748830713\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83       125\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       1.00      0.72      0.84        18\n",
      "          3       1.00      0.58      0.74        12\n",
      "          4       1.00      0.31      0.48        16\n",
      "          5       1.00      0.22      0.36        18\n",
      "\n",
      "avg / total       0.75      0.75      0.70       204\n",
      "\n",
      "[125   0   0   0   0   0  15   0   0   0   0   0   5   0  13   0   0   0\n",
      "   5   0   0   7   0   0  11   0   0   0   5   0  14   0   0   0   0   4]\n",
      "LR Accuracy:  0.7549019607843137\n",
      "LR F1:  0.5414519926404476\n",
      "For name:  y_ng\n",
      "total sample size before apply threshold:  19\n",
      "Counter({'0000-0003-4598-1829': 11, '0000-0001-9142-2126': 4, '0000-0002-7140-1616': 2, '0000-0002-4590-3364': 1, '0000-0002-7213-5030': 1})\n",
      "['0000-0003-4598-1829']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  j_madsen\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0001-7625-9498': 28, '0000-0003-1664-7645': 24, '0000-0003-1411-9080': 8, '0000-0003-3246-0215': 8, '0000-0002-6874-2970': 1})\n",
      "['0000-0001-7625-9498', '0000-0003-1664-7645']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 211)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        28\n",
      "          1       1.00      0.92      0.96        24\n",
      "\n",
      "avg / total       0.96      0.96      0.96        52\n",
      "\n",
      "[28  0  2 22]\n",
      "MNB Accuracy:  0.9615384615384616\n",
      "MNB F1:  0.9610194902548725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        28\n",
      "          1       0.96      1.00      0.98        24\n",
      "\n",
      "avg / total       0.98      0.98      0.98        52\n",
      "\n",
      "[27  1  0 24]\n",
      "svc Accuracy:  0.9807692307692307\n",
      "svc F1:  0.9807050092764378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        28\n",
      "          1       0.96      1.00      0.98        24\n",
      "\n",
      "avg / total       0.98      0.98      0.98        52\n",
      "\n",
      "[27  1  0 24]\n",
      "LR Accuracy:  0.9807692307692307\n",
      "LR F1:  0.9807050092764378\n",
      "For name:  d_collins\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-6754-9290': 8, '0000-0002-6248-9644': 7, '0000-0002-3283-0733': 6, '0000-0003-2274-0889': 5, '0000-0003-2484-1640': 2, '0000-0002-8432-7021': 1, '0000-0001-8891-1893': 1, '0000-0002-7981-3586': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  l_davies\n",
      "total sample size before apply threshold:  96\n",
      "Counter({'0000-0001-8801-3559': 62, '0000-0002-0451-8670': 19, '0000-0002-4876-6270': 11, '0000-0002-2986-705X': 4})\n",
      "['0000-0001-8801-3559', '0000-0002-4876-6270', '0000-0002-0451-8670']\n",
      "Total sample size after apply threshold:  92\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(92, 444)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "92\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        62\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       1.00      0.89      0.94        19\n",
      "\n",
      "avg / total       0.89      0.87      0.83        92\n",
      "\n",
      "[62  0  0 10  1  0  2  0 17]\n",
      "MNB Accuracy:  0.8695652173913043\n",
      "MNB F1:  0.6742919389978214\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        62\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       1.00      0.84      0.91        19\n",
      "\n",
      "avg / total       0.94      0.93      0.93        92\n",
      "\n",
      "[62  0  0  3  8  0  3  0 16]\n",
      "svc Accuracy:  0.9347826086956522\n",
      "svc F1:  0.9034123770965876\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        62\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.58      0.73        19\n",
      "\n",
      "avg / total       0.72      0.79      0.74        92\n",
      "\n",
      "[62  0  0 11  0  0  8  0 11]\n",
      "LR Accuracy:  0.7934782608695652\n",
      "LR F1:  0.5334887334887335\n",
      "For name:  m_mora\n",
      "total sample size before apply threshold:  131\n",
      "Counter({'0000-0002-5765-2320': 104, '0000-0002-8393-0216': 22, '0000-0002-2979-3601': 4, '0000-0003-0627-6764': 1})\n",
      "['0000-0002-8393-0216', '0000-0002-5765-2320']\n",
      "Total sample size after apply threshold:  126\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(126, 654)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "126\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        22\n",
      "          1       0.85      1.00      0.92       104\n",
      "\n",
      "avg / total       0.88      0.86      0.81       126\n",
      "\n",
      "[  4  18   0 104]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.6140231449965963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        22\n",
      "          1       0.88      1.00      0.94       104\n",
      "\n",
      "avg / total       0.90      0.89      0.87       126\n",
      "\n",
      "[  8  14   0 104]\n",
      "svc Accuracy:  0.8888888888888888\n",
      "svc F1:  0.7351351351351352\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        22\n",
      "          1       0.83      1.00      0.90       104\n",
      "\n",
      "avg / total       0.68      0.83      0.75       126\n",
      "\n",
      "[  0  22   0 104]\n",
      "LR Accuracy:  0.8253968253968254\n",
      "LR F1:  0.45217391304347826\n",
      "For name:  a_fontana\n",
      "total sample size before apply threshold:  203\n",
      "Counter({'0000-0002-6660-5315': 65, '0000-0002-5453-461X': 59, '0000-0002-5391-7520': 44, '0000-0002-8481-1219': 16, '0000-0002-4791-8746': 14, '0000-0003-3820-2823': 3, '0000-0003-1556-2770': 2})\n",
      "['0000-0002-5391-7520', '0000-0002-5453-461X', '0000-0002-4791-8746', '0000-0002-6660-5315', '0000-0002-8481-1219']\n",
      "Total sample size after apply threshold:  198\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(198, 702)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "198\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        44\n",
      "          1       0.80      0.97      0.88        59\n",
      "          2       1.00      0.50      0.67        14\n",
      "          3       0.94      0.97      0.95        65\n",
      "          4       1.00      0.62      0.77        16\n",
      "\n",
      "avg / total       0.92      0.91      0.90       198\n",
      "\n",
      "[43  1  0  0  0  0 57  0  2  0  0  5  7  2  0  0  2  0 63  0  0  6  0  0\n",
      " 10]\n",
      "MNB Accuracy:  0.9090909090909091\n",
      "MNB F1:  0.8511743428984809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.98        44\n",
      "          1       0.88      0.98      0.93        59\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       0.98      0.98      0.98        65\n",
      "          4       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       0.96      0.95      0.95       198\n",
      "\n",
      "[42  2  0  0  0  0 58  0  1  0  0  5  9  0  0  0  1  0 64  0  0  0  0  0\n",
      " 16]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.934393653262814\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.89      0.93        44\n",
      "          1       0.91      0.85      0.88        59\n",
      "          2       1.00      0.50      0.67        14\n",
      "          3       0.77      1.00      0.87        65\n",
      "          4       1.00      0.75      0.86        16\n",
      "\n",
      "avg / total       0.89      0.87      0.87       198\n",
      "\n",
      "[39  1  0  4  0  1 50  0  8  0  0  3  7  4  0  0  0  0 65  0  0  1  0  3\n",
      " 12]\n",
      "LR Accuracy:  0.8737373737373737\n",
      "LR F1:  0.8404114312627204\n",
      "For name:  r_chen\n",
      "total sample size before apply threshold:  367\n",
      "Counter({'0000-0002-8371-8629': 179, '0000-0001-6344-1442': 34, '0000-0003-0291-006X': 32, '0000-0001-6892-0602': 32, '0000-0003-3987-033X': 24, '0000-0002-7505-5415': 21, '0000-0003-1455-5093': 20, '0000-0001-9186-6747': 11, '0000-0002-5340-248X': 4, '0000-0002-8237-6612': 3, '0000-0001-6968-4955': 2, '0000-0003-1919-3335': 1, '0000-0003-4581-8204': 1, '0000-0001-8395-4392': 1, '0000-0001-9750-6670': 1, '0000-0003-1298-9381': 1})\n",
      "['0000-0003-0291-006X', '0000-0001-9186-6747', '0000-0001-6892-0602', '0000-0002-8371-8629', '0000-0003-1455-5093', '0000-0003-3987-033X', '0000-0002-7505-5415', '0000-0001-6344-1442']\n",
      "Total sample size after apply threshold:  353\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(353, 645)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.84      0.75        32\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.63      0.84      0.72        32\n",
      "          3       0.83      1.00      0.91       179\n",
      "          4       1.00      0.45      0.62        20\n",
      "          5       1.00      0.21      0.34        24\n",
      "          6       0.90      0.43      0.58        21\n",
      "          7       0.90      0.82      0.86        34\n",
      "\n",
      "avg / total       0.81      0.80      0.77       353\n",
      "\n",
      "[ 27   0   3   1   0   0   1   0   0   0   1  10   0   0   0   0   3   0\n",
      "  27   2   0   0   0   0   0   0   0 179   0   0   0   0   0   0   0   8\n",
      "   9   0   0   3   4   0   6   9   0   5   0   0   5   0   5   2   0   0\n",
      "   9   0   1   0   1   4   0   0   0  28]\n",
      "MNB Accuracy:  0.8045325779036827\n",
      "MNB F1:  0.5982912882290575\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85        32\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       0.79      0.84      0.82        32\n",
      "          3       0.93      0.99      0.96       179\n",
      "          4       0.88      0.75      0.81        20\n",
      "          5       0.64      0.58      0.61        24\n",
      "          6       0.71      0.48      0.57        21\n",
      "          7       0.83      0.85      0.84        34\n",
      "\n",
      "avg / total       0.87      0.87      0.86       353\n",
      "\n",
      "[ 28   0   1   0   0   2   1   0   0   6   0   5   0   0   0   0   2   0\n",
      "  27   2   0   1   0   0   0   0   1 178   0   0   0   0   0   0   0   1\n",
      "  15   0   0   4   1   0   3   2   0  14   3   1   3   0   2   1   0   4\n",
      "  10   1   0   0   0   2   2   1   0  29]\n",
      "svc Accuracy:  0.8696883852691218\n",
      "svc F1:  0.7707782407910284\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.88      0.84        32\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.79      0.81      0.80        32\n",
      "          3       0.72      1.00      0.84       179\n",
      "          4       1.00      0.55      0.71        20\n",
      "          5       0.67      0.08      0.15        24\n",
      "          6       0.78      0.33      0.47        21\n",
      "          7       0.92      0.35      0.51        34\n",
      "\n",
      "avg / total       0.75      0.75      0.70       353\n",
      "\n",
      "[ 28   0   1   2   0   0   1   0   0   0   0  11   0   0   0   0   2   0\n",
      "  26   4   0   0   0   0   0   0   0 179   0   0   0   0   0   0   0   8\n",
      "  11   0   0   1   3   0   2  16   0   2   1   0   2   0   4   7   0   1\n",
      "   7   0   0   0   0  22   0   0   0  12]\n",
      "LR Accuracy:  0.7507082152974505\n",
      "LR F1:  0.5384250032119029\n",
      "For name:  s_krause\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0002-5259-4651': 43, '0000-0003-1943-2703': 11, '0000-0002-8532-4244': 11, '0000-0002-7062-8472': 5})\n",
      "['0000-0003-1943-2703', '0000-0002-5259-4651', '0000-0002-8532-4244']\n",
      "Total sample size after apply threshold:  65\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 330)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        11\n",
      "          1       0.70      1.00      0.83        43\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.64      0.72      0.64        65\n",
      "\n",
      "[ 4  7  0  0 43  0  0 11  0]\n",
      "MNB Accuracy:  0.7230769230769231\n",
      "MNB F1:  0.4534188034188034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.80      1.00      0.89        43\n",
      "          2       1.00      0.36      0.53        11\n",
      "\n",
      "avg / total       0.87      0.83      0.81        65\n",
      "\n",
      "[ 7  4  0  0 43  0  0  7  4]\n",
      "svc Accuracy:  0.8307692307692308\n",
      "svc F1:  0.7325696830851469\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        11\n",
      "          1       0.70      1.00      0.83        43\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.64      0.72      0.64        65\n",
      "\n",
      "[ 4  7  0  0 43  0  0 11  0]\n",
      "LR Accuracy:  0.7230769230769231\n",
      "LR F1:  0.4534188034188034\n",
      "For name:  t_smith\n",
      "total sample size before apply threshold:  603\n",
      "Counter({'0000-0002-3650-9381': 154, '0000-0003-1673-2954': 113, '0000-0002-2120-2766': 85, '0000-0002-6279-9685': 84, '0000-0003-3528-6793': 65, '0000-0003-4453-9713': 32, '0000-0002-5197-5030': 26, '0000-0002-3945-630X': 10, '0000-0001-7894-6814': 9, '0000-0002-5750-0706': 6, '0000-0002-5495-8906': 4, '0000-0003-3762-6253': 4, '0000-0002-0479-4261': 3, '0000-0003-2389-461X': 2, '0000-0001-6272-8871': 2, '0000-0001-7683-2653': 1, '0000-0002-2104-2264': 1, '0000-0001-9068-4642': 1, '0000-0002-1881-2766': 1})\n",
      "['0000-0002-3945-630X', '0000-0003-4453-9713', '0000-0003-3528-6793', '0000-0002-6279-9685', '0000-0003-1673-2954', '0000-0002-3650-9381', '0000-0002-2120-2766', '0000-0002-5197-5030']\n",
      "Total sample size after apply threshold:  569\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(569, 1071)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.09      0.17        32\n",
      "          2       0.92      0.71      0.80        65\n",
      "          3       0.93      0.68      0.79        84\n",
      "          4       0.88      0.93      0.90       113\n",
      "          5       0.66      1.00      0.79       154\n",
      "          6       0.96      0.92      0.94        85\n",
      "          7       1.00      0.73      0.84        26\n",
      "\n",
      "avg / total       0.84      0.81      0.79       569\n",
      "\n",
      "[  0   0   0   1   2   7   0   0   0   3   2   1   9  17   0   0   0   0\n",
      "  46   1   2  13   3   0   0   0   2  57   2  23   0   0   0   0   0   0\n",
      " 105   8   0   0   0   0   0   0   0 154   0   0   0   0   0   0   0   7\n",
      "  78   0   0   0   0   1   0   6   0  19]\n",
      "MNB Accuracy:  0.81195079086116\n",
      "MNB F1:  0.654362535142212\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.50      0.67        32\n",
      "          2       0.95      0.80      0.87        65\n",
      "          3       0.88      0.80      0.84        84\n",
      "          4       0.96      0.92      0.94       113\n",
      "          5       0.71      0.99      0.83       154\n",
      "          6       0.99      0.92      0.95        85\n",
      "          7       1.00      0.81      0.89        26\n",
      "\n",
      "avg / total       0.87      0.86      0.86       569\n",
      "\n",
      "[  0   0   0   1   2   7   0   0   0  16   2   3   2   9   0   0   0   0\n",
      "  52   3   0   9   1   0   0   0   0  67   0  17   0   0   0   0   1   0\n",
      " 104   8   0   0   0   0   0   1   0 153   0   0   0   0   0   1   0   6\n",
      "  78   0   0   0   0   0   0   5   0  21]\n",
      "svc Accuracy:  0.8629173989455184\n",
      "svc F1:  0.748546009565465\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.22      0.36        32\n",
      "          2       0.94      0.68      0.79        65\n",
      "          3       0.95      0.68      0.79        84\n",
      "          4       0.98      0.88      0.93       113\n",
      "          5       0.59      1.00      0.74       154\n",
      "          6       0.99      0.84      0.90        85\n",
      "          7       1.00      0.77      0.87        26\n",
      "\n",
      "avg / total       0.85      0.79      0.79       569\n",
      "\n",
      "[  0   0   0   1   1   8   0   0   0   7   2   0   0  23   0   0   0   0\n",
      "  44   1   1  18   1   0   0   0   1  57   0  26   0   0   0   0   0   0\n",
      "  99  14   0   0   0   0   0   0   0 154   0   0   0   0   0   0   0  14\n",
      "  71   0   0   0   0   1   0   5   0  20]\n",
      "LR Accuracy:  0.7943760984182777\n",
      "LR F1:  0.671999673464645\n",
      "For name:  a_biswas\n",
      "total sample size before apply threshold:  10\n",
      "Counter({'0000-0003-2010-9524': 3, '0000-0002-5828-7230': 3, '0000-0002-0393-6280': 2, '0000-0002-7446-4639': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_day\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-9520-3465': 5, '0000-0003-1686-4885': 2, '0000-0001-8681-9831': 2, '0000-0001-6274-9197': 2, '0000-0001-6803-5865': 1, '0000-0003-4324-3486': 1, '0000-0003-1035-2117': 1, '0000-0003-4277-4816': 1, '0000-0003-3133-943X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_truong\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0003-4946-8969': 7, '0000-0002-1720-1744': 4, '0000-0003-3200-1297': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_pan\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0003-3154-6690': 34, '0000-0002-8247-2110': 12, '0000-0002-1189-4199': 11, '0000-0003-2082-4077': 10, '0000-0001-6451-4666': 10, '0000-0002-7581-1831': 9, '0000-0003-2620-7272': 6, '0000-0001-6565-3836': 5, '0000-0003-0794-527X': 4})\n",
      "['0000-0003-2082-4077', '0000-0001-6451-4666', '0000-0002-1189-4199', '0000-0002-8247-2110', '0000-0003-3154-6690']\n",
      "Total sample size after apply threshold:  77\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 211)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.75      0.25      0.38        12\n",
      "          4       0.47      1.00      0.64        34\n",
      "\n",
      "avg / total       0.32      0.48      0.34        77\n",
      "\n",
      "[ 0  0  0  0 10  0  0  0  0 10  0  0  0  1 10  0  0  0  3  9  0  0  0  0\n",
      " 34]\n",
      "MNB Accuracy:  0.4805194805194805\n",
      "MNB F1:  0.20210280373831777\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       0.67      0.55      0.60        11\n",
      "          3       0.91      0.83      0.87        12\n",
      "          4       0.80      0.97      0.88        34\n",
      "\n",
      "avg / total       0.85      0.84      0.84        77\n",
      "\n",
      "[ 9  0  0  0  1  0  7  0  0  3  0  0  6  1  4  0  0  2 10  0  0  0  1  0\n",
      " 33]\n",
      "svc Accuracy:  0.8441558441558441\n",
      "svc F1:  0.8240926100417283\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       1.00      0.40      0.57        10\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       0.55      1.00      0.71        34\n",
      "\n",
      "avg / total       0.66      0.64      0.58        77\n",
      "\n",
      "[ 5  0  0  0  5  0  4  0  0  6  0  0  0  0 11  0  0  0  6  6  0  0  0  0\n",
      " 34]\n",
      "LR Accuracy:  0.6363636363636364\n",
      "LR F1:  0.5226190476190476\n",
      "For name:  a_andrade\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-9569-6503': 18, '0000-0002-5689-6606': 13, '0000-0003-4902-8728': 10, '0000-0002-8107-7338': 9, '0000-0002-3540-6858': 1, '0000-0001-7128-3472': 1})\n",
      "['0000-0002-5689-6606', '0000-0003-4902-8728', '0000-0001-9569-6503']\n",
      "Total sample size after apply threshold:  41\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 142)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       0.72      1.00      0.84        18\n",
      "\n",
      "avg / total       0.88      0.83      0.81        41\n",
      "\n",
      "[ 6  0  7  0 10  0  0  0 18]\n",
      "MNB Accuracy:  0.8292682926829268\n",
      "MNB F1:  0.8229294165646674\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       0.95      1.00      0.97        18\n",
      "\n",
      "avg / total       0.98      0.98      0.98        41\n",
      "\n",
      "[12  0  1  0 10  0  0  0 18]\n",
      "svc Accuracy:  0.975609756097561\n",
      "svc F1:  0.9776576576576576\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       0.72      1.00      0.84        18\n",
      "\n",
      "avg / total       0.88      0.83      0.81        41\n",
      "\n",
      "[ 6  0  7  0 10  0  0  0 18]\n",
      "LR Accuracy:  0.8292682926829268\n",
      "LR F1:  0.8229294165646674\n",
      "For name:  t_oliveira\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-2654-0879': 17, '0000-0003-0843-7541': 11, '0000-0003-0509-0562': 9, '0000-0001-7040-7189': 1, '0000-0003-3947-1881': 1, '0000-0002-9200-3625': 1, '0000-0001-6055-058X': 1})\n",
      "['0000-0003-0843-7541', '0000-0002-2654-0879']\n",
      "Total sample size after apply threshold:  28\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 156)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.97      0.96      0.96        28\n",
      "\n",
      "[10  1  0 17]\n",
      "MNB Accuracy:  0.9642857142857143\n",
      "MNB F1:  0.9619047619047618\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.97      0.96      0.96        28\n",
      "\n",
      "[10  1  0 17]\n",
      "svc Accuracy:  0.9642857142857143\n",
      "svc F1:  0.9619047619047618\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.85      1.00      0.92        17\n",
      "\n",
      "avg / total       0.91      0.89      0.89        28\n",
      "\n",
      "[ 8  3  0 17]\n",
      "LR Accuracy:  0.8928571428571429\n",
      "LR F1:  0.8805120910384068\n",
      "For name:  n_romano\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0003-2765-4912': 7, '0000-0002-9541-8885': 2, '0000-0002-6105-1827': 1, '0000-0001-7276-6994': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_hara\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0003-2668-6218': 15, '0000-0003-0450-6829': 6, '0000-0002-6565-0720': 1, '0000-0002-0235-238X': 1})\n",
      "['0000-0003-2668-6218']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  t_wong\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-1045-2698': 9, '0000-0002-5752-7917': 2, '0000-0001-9234-4529': 1, '0000-0001-6187-8851': 1, '0000-0001-8611-4911': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_ross\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-2302-8415': 17, '0000-0001-7305-3451': 3, '0000-0002-3094-3769': 2, '0000-0003-3512-9579': 1, '0000-0001-5676-4489': 1, '0000-0001-5523-2376': 1})\n",
      "['0000-0002-2302-8415']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  d_richardson\n",
      "total sample size before apply threshold:  456\n",
      "Counter({'0000-0003-0960-6415': 231, '0000-0002-7751-1058': 167, '0000-0002-3992-8610': 22, '0000-0003-0247-9118': 17, '0000-0002-3189-2190': 12, '0000-0002-0054-6850': 7})\n",
      "['0000-0002-3189-2190', '0000-0003-0960-6415', '0000-0002-7751-1058', '0000-0002-3992-8610', '0000-0003-0247-9118']\n",
      "Total sample size after apply threshold:  449\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(449, 1208)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.86      1.00      0.93       231\n",
      "          2       0.98      0.95      0.96       167\n",
      "          3       0.92      0.50      0.65        22\n",
      "          4       1.00      0.47      0.64        17\n",
      "\n",
      "avg / total       0.89      0.91      0.89       449\n",
      "\n",
      "[  0  11   1   0   0   0 230   1   0   0   0   8 159   0   0   0  11   0\n",
      "  11   0   0   6   2   1   8]\n",
      "MNB Accuracy:  0.9086859688195991\n",
      "MNB F1:  0.6352497014170584\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.89      1.00      0.94       231\n",
      "          2       0.99      0.95      0.97       167\n",
      "          3       1.00      0.73      0.84        22\n",
      "          4       1.00      0.53      0.69        17\n",
      "\n",
      "avg / total       0.94      0.94      0.93       449\n",
      "\n",
      "[  6   6   0   0   0   0 231   0   0   0   0   9 158   0   0   0   6   0\n",
      "  16   0   0   7   1   0   9]\n",
      "svc Accuracy:  0.9354120267260579\n",
      "svc F1:  0.822652383672726\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.80      1.00      0.89       231\n",
      "          2       0.99      0.87      0.92       167\n",
      "          3       1.00      0.50      0.67        22\n",
      "          4       1.00      0.18      0.30        17\n",
      "\n",
      "avg / total       0.89      0.87      0.85       449\n",
      "\n",
      "[  1  10   1   0   0   0 231   0   0   0   0  22 145   0   0   0  11   0\n",
      "  11   0   0  13   1   0   3]\n",
      "LR Accuracy:  0.8708240534521158\n",
      "LR F1:  0.5871943182771208\n",
      "For name:  j_moraes\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0002-5766-6802': 13, '0000-0002-8563-6432': 7, '0000-0002-4490-8307': 4, '0000-0002-3067-5194': 2})\n",
      "['0000-0002-5766-6802']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  e_moreno\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0002-2309-4826': 26, '0000-0001-5040-452X': 21, '0000-0001-9490-7030': 14, '0000-0002-8434-2483': 8, '0000-0003-0491-7951': 5, '0000-0002-2301-4558': 4, '0000-0002-7197-5679': 3, '0000-0001-8520-8086': 1, '0000-0002-2733-0267': 1})\n",
      "['0000-0002-2309-4826', '0000-0001-9490-7030', '0000-0001-5040-452X']\n",
      "Total sample size after apply threshold:  61\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 143)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        26\n",
      "          1       1.00      0.79      0.88        14\n",
      "          2       0.85      0.81      0.83        21\n",
      "\n",
      "avg / total       0.89      0.89      0.88        61\n",
      "\n",
      "[26  0  0  0 11  3  4  0 17]\n",
      "MNB Accuracy:  0.8852459016393442\n",
      "MNB F1:  0.8792799070847851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        26\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       0.86      0.86      0.86        21\n",
      "\n",
      "avg / total       0.89      0.89      0.88        61\n",
      "\n",
      "[26  0  0  1 10  3  3  0 18]\n",
      "svc Accuracy:  0.8852459016393442\n",
      "svc F1:  0.873015873015873\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        26\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       1.00      0.76      0.86        21\n",
      "\n",
      "avg / total       0.89      0.85      0.85        61\n",
      "\n",
      "[26  0  0  4 10  0  5  0 16]\n",
      "LR Accuracy:  0.8524590163934426\n",
      "LR F1:  0.8502190715305469\n",
      "For name:  r_little\n",
      "total sample size before apply threshold:  4\n",
      "Counter({'0000-0002-4000-946X': 2, '0000-0002-7732-157X': 1, '0000-0003-1870-3241': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_kobayashi\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-4008-454X': 85, '0000-0002-0237-3623': 22, '0000-0002-2738-373X': 10, '0000-0002-7650-1763': 10, '0000-0002-0903-6259': 6, '0000-0002-9202-7643': 5, '0000-0001-7297-8524': 5, '0000-0002-6952-8669': 4, '0000-0003-0963-2525': 2, '0000-0003-4264-5117': 1})\n",
      "['0000-0002-4008-454X', '0000-0002-2738-373X', '0000-0002-0237-3623', '0000-0002-7650-1763']\n",
      "Total sample size after apply threshold:  127\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 325)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.99      0.81        85\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.75      0.14      0.23        22\n",
      "          3       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.67      0.69      0.60       127\n",
      "\n",
      "[84  0  1  0 10  0  0  0 19  0  3  0  9  0  0  1]\n",
      "MNB Accuracy:  0.6929133858267716\n",
      "MNB F1:  0.3060454038714909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        85\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.68      0.81        22\n",
      "          3       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.89      0.87      0.86       127\n",
      "\n",
      "[85  0  0  0  3  7  0  0  7  0 15  0  6  0  0  4]\n",
      "svc Accuracy:  0.8740157480314961\n",
      "svc F1:  0.779936822156936\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        85\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.36      0.53        22\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.65      0.73      0.65       127\n",
      "\n",
      "[85  0  0  0 10  0  0  0 14  0  8  0 10  0  0  0]\n",
      "LR Accuracy:  0.7322834645669292\n",
      "LR F1:  0.3416666666666667\n",
      "For name:  a_lin\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0003-4236-7233': 27, '0000-0001-6310-9765': 10, '0000-0001-9783-1270': 5, '0000-0003-0072-612X': 3, '0000-0001-8545-2222': 1})\n",
      "['0000-0003-4236-7233', '0000-0001-6310-9765']\n",
      "Total sample size after apply threshold:  37\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 55)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        27\n",
      "          1       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.87      0.84      0.81        37\n",
      "\n",
      "[27  0  6  4]\n",
      "MNB Accuracy:  0.8378378378378378\n",
      "MNB F1:  0.7357142857142858\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        27\n",
      "          1       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.91      0.89      0.88        37\n",
      "\n",
      "[27  0  4  6]\n",
      "svc Accuracy:  0.8918918918918919\n",
      "svc F1:  0.8405172413793103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.89        27\n",
      "          1       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.85      0.81      0.77        37\n",
      "\n",
      "[27  0  7  3]\n",
      "LR Accuracy:  0.8108108108108109\n",
      "LR F1:  0.6733921815889029\n",
      "For name:  a_miranda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0001-6998-5686': 48, '0000-0001-5807-5820': 11, '0000-0003-3957-6288': 4, '0000-0003-4964-2197': 2, '0000-0002-9066-6935': 2, '0000-0003-4872-0632': 2, '0000-0002-7297-9639': 1})\n",
      "['0000-0001-5807-5820', '0000-0001-6998-5686']\n",
      "Total sample size after apply threshold:  59\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 586)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.73      0.80        11\n",
      "          1       0.94      0.98      0.96        48\n",
      "\n",
      "avg / total       0.93      0.93      0.93        59\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  3  1 47]\n",
      "MNB Accuracy:  0.9322033898305084\n",
      "MNB F1:  0.8795918367346938\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        48\n",
      "\n",
      "avg / total       1.00      1.00      1.00        59\n",
      "\n",
      "[11  0  0 48]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       0.84      1.00      0.91        48\n",
      "\n",
      "avg / total       0.87      0.85      0.80        59\n",
      "\n",
      "[ 2  9  0 48]\n",
      "LR Accuracy:  0.847457627118644\n",
      "LR F1:  0.610989010989011\n",
      "For name:  h_vogel\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0001-9821-7731': 5, '0000-0002-9902-8120': 4, '0000-0003-2404-9485': 4, '0000-0003-0072-4239': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_campos\n",
      "total sample size before apply threshold:  148\n",
      "Counter({'0000-0001-7738-9892': 107, '0000-0003-3217-9001': 12, '0000-0003-4313-7069': 8, '0000-0003-1012-6240': 6, '0000-0002-0883-0610': 5, '0000-0002-5233-3769': 5, '0000-0003-4683-0176': 3, '0000-0002-9516-6526': 2})\n",
      "['0000-0001-7738-9892', '0000-0003-3217-9001']\n",
      "Total sample size after apply threshold:  119\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(119, 260)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "119\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       107\n",
      "          1       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.96      0.96      0.95       119\n",
      "\n",
      "[107   0   5   7]\n",
      "MNB Accuracy:  0.957983193277311\n",
      "MNB F1:  0.8570055275174238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       107\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.99      0.99      0.99       119\n",
      "\n",
      "[107   0   1  11]\n",
      "svc Accuracy:  0.9915966386554622\n",
      "svc F1:  0.9759352881698686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       107\n",
      "          1       1.00      0.42      0.59        12\n",
      "\n",
      "avg / total       0.94      0.94      0.93       119\n",
      "\n",
      "[107   0   7   5]\n",
      "LR Accuracy:  0.9411764705882353\n",
      "LR F1:  0.7782805429864253\n",
      "For name:  d_stewart\n",
      "total sample size before apply threshold:  294\n",
      "Counter({'0000-0002-8157-7746': 210, '0000-0001-7360-8592': 77, '0000-0002-6764-4842': 3, '0000-0002-8499-7105': 1, '0000-0002-4087-5544': 1, '0000-0001-5144-1234': 1, '0000-0002-3690-9844': 1})\n",
      "['0000-0001-7360-8592', '0000-0002-8157-7746']\n",
      "Total sample size after apply threshold:  287\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 519)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "287\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.92      0.95        77\n",
      "          1       0.97      0.99      0.98       210\n",
      "\n",
      "avg / total       0.97      0.97      0.97       287\n",
      "\n",
      "[ 71   6   2 208]\n",
      "MNB Accuracy:  0.9721254355400697\n",
      "MNB F1:  0.9638993710691823\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        77\n",
      "          1       0.96      1.00      0.98       210\n",
      "\n",
      "avg / total       0.97      0.97      0.97       287\n",
      "\n",
      "[ 69   8   0 210]\n",
      "svc Accuracy:  0.9721254355400697\n",
      "svc F1:  0.963256945333504\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        77\n",
      "          1       0.86      1.00      0.93       210\n",
      "\n",
      "avg / total       0.90      0.89      0.87       287\n",
      "\n",
      "[ 44  33   0 210]\n",
      "LR Accuracy:  0.8850174216027874\n",
      "LR F1:  0.827212522576761\n",
      "For name:  j_abrantes\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-8391-7134': 42, '0000-0003-1902-9017': 11, '0000-0003-4585-9831': 4})\n",
      "['0000-0003-1902-9017', '0000-0002-8391-7134']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 118)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.91      1.00      0.95        42\n",
      "\n",
      "avg / total       0.93      0.92      0.92        53\n",
      "\n",
      "[ 7  4  0 42]\n",
      "MNB Accuracy:  0.9245283018867925\n",
      "MNB F1:  0.8661616161616161\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.98      1.00      0.99        42\n",
      "\n",
      "avg / total       0.98      0.98      0.98        53\n",
      "\n",
      "[10  1  0 42]\n",
      "svc Accuracy:  0.9811320754716981\n",
      "svc F1:  0.9703081232492996\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.89      1.00      0.94        42\n",
      "\n",
      "avg / total       0.92      0.91      0.89        53\n",
      "\n",
      "[ 6  5  0 42]\n",
      "LR Accuracy:  0.9056603773584906\n",
      "LR F1:  0.8248512888301387\n",
      "For name:  j_arroyo\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0002-1971-1721': 65, '0000-0003-4749-2519': 18, '0000-0002-5992-5011': 10, '0000-0002-5674-6739': 10, '0000-0001-7658-8750': 6})\n",
      "['0000-0003-4749-2519', '0000-0002-5992-5011', '0000-0002-5674-6739', '0000-0002-1971-1721']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  103\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 412)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.22      0.35        18\n",
      "          1       1.00      0.10      0.18        10\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.66      0.98      0.79        65\n",
      "\n",
      "avg / total       0.65      0.67      0.58       103\n",
      "\n",
      "[ 4  0  0 14  0  1  0  9  0  0  0 10  1  0  0 64]\n",
      "MNB Accuracy:  0.6699029126213593\n",
      "MNB F1:  0.32994193139120676\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        18\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.60      0.75        10\n",
      "          3       0.83      1.00      0.91        65\n",
      "\n",
      "avg / total       0.89      0.87      0.87       103\n",
      "\n",
      "[12  0  0  6  0  7  0  3  0  0  6  4  0  0  0 65]\n",
      "svc Accuracy:  0.8737864077669902\n",
      "svc F1:  0.8206550802139038\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.11      0.20        18\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.64      1.00      0.78        65\n",
      "\n",
      "avg / total       0.58      0.65      0.53       103\n",
      "\n",
      "[ 2  0  0 16  0  0  0 10  0  0  0 10  0  0  0 65]\n",
      "LR Accuracy:  0.6504854368932039\n",
      "LR F1:  0.24578313253012046\n",
      "For name:  a_giuliani\n",
      "total sample size before apply threshold:  196\n",
      "Counter({'0000-0002-4640-804X': 155, '0000-0003-1710-4933': 36, '0000-0002-4315-1699': 4, '0000-0002-6823-2807': 1})\n",
      "['0000-0003-1710-4933', '0000-0002-4640-804X']\n",
      "Total sample size after apply threshold:  191\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 513)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        36\n",
      "          1       0.96      1.00      0.98       155\n",
      "\n",
      "avg / total       0.96      0.96      0.96       191\n",
      "\n",
      "[ 29   7   0 155]\n",
      "MNB Accuracy:  0.9633507853403142\n",
      "MNB F1:  0.9351128366901238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        36\n",
      "          1       0.95      1.00      0.97       155\n",
      "\n",
      "avg / total       0.96      0.95      0.95       191\n",
      "\n",
      "[ 27   9   0 155]\n",
      "svc Accuracy:  0.9528795811518325\n",
      "svc F1:  0.9144648454993283\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        36\n",
      "          1       0.86      1.00      0.93       155\n",
      "\n",
      "avg / total       0.89      0.87      0.84       191\n",
      "\n",
      "[ 11  25   0 155]\n",
      "LR Accuracy:  0.8691099476439791\n",
      "LR F1:  0.6967291203556685\n",
      "For name:  f_campos\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0001-8376-0977': 14, '0000-0002-5948-472X': 12, '0000-0002-1132-3257': 10, '0000-0001-8332-5043': 9, '0000-0001-9826-751X': 2, '0000-0001-5828-2862': 2})\n",
      "['0000-0001-8376-0977', '0000-0002-5948-472X', '0000-0002-1132-3257']\n",
      "Total sample size after apply threshold:  36\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 129)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       1.00      1.00      1.00        12\n",
      "          2       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[13  0  1  0 12  0  0  0 10]\n",
      "MNB Accuracy:  0.9722222222222222\n",
      "MNB F1:  0.9717813051146384\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.86      0.89        14\n",
      "          1       0.92      1.00      0.96        12\n",
      "          2       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.92      0.92      0.92        36\n",
      "\n",
      "[12  1  1  0 12  0  1  0  9]\n",
      "svc Accuracy:  0.9166666666666666\n",
      "svc F1:  0.9162962962962964\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.79      0.85        14\n",
      "          1       0.86      1.00      0.92        12\n",
      "          2       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.89      0.89      0.89        36\n",
      "\n",
      "[11  2  1  0 12  0  1  0  9]\n",
      "LR Accuracy:  0.8888888888888888\n",
      "LR F1:  0.8897435897435897\n",
      "For name:  a_mitchell\n",
      "total sample size before apply threshold:  436\n",
      "Counter({'0000-0001-6014-598X': 188, '0000-0002-0868-4000': 98, '0000-0002-2463-2956': 65, '0000-0001-8996-1067': 24, '0000-0001-8655-7966': 23, '0000-0002-9946-183X': 20, '0000-0003-1062-0716': 6, '0000-0001-5022-5898': 4, '0000-0003-2001-1738': 4, '0000-0003-0969-1680': 3, '0000-0003-3352-3046': 1})\n",
      "['0000-0002-9946-183X', '0000-0001-6014-598X', '0000-0001-8655-7966', '0000-0002-2463-2956', '0000-0002-0868-4000', '0000-0001-8996-1067']\n",
      "Total sample size after apply threshold:  418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(418, 1043)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "418\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        20\n",
      "          1       0.73      1.00      0.84       188\n",
      "          2       1.00      0.30      0.47        23\n",
      "          3       1.00      0.91      0.95        65\n",
      "          4       1.00      0.85      0.92        98\n",
      "          5       1.00      0.33      0.50        24\n",
      "\n",
      "avg / total       0.88      0.83      0.80       418\n",
      "\n",
      "[  2  18   0   0   0   0   0 188   0   0   0   0   0  16   7   0   0   0\n",
      "   0   6   0  59   0   0   0  15   0   0  83   0   0  16   0   0   0   8]\n",
      "MNB Accuracy:  0.8301435406698564\n",
      "MNB F1:  0.643064689082638\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        20\n",
      "          1       0.75      1.00      0.85       188\n",
      "          2       1.00      0.43      0.61        23\n",
      "          3       1.00      0.82      0.90        65\n",
      "          4       1.00      0.72      0.84        98\n",
      "          5       1.00      0.71      0.83        24\n",
      "\n",
      "avg / total       0.89      0.85      0.84       418\n",
      "\n",
      "[ 15   5   0   0   0   0   0 188   0   0   0   0   0  13  10   0   0   0\n",
      "   0  12   0  53   0   0   0  27   0   0  71   0   0   7   0   0   0  17]\n",
      "svc Accuracy:  0.84688995215311\n",
      "svc F1:  0.8142598302613567\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        20\n",
      "          1       0.65      1.00      0.79       188\n",
      "          2       1.00      0.17      0.30        23\n",
      "          3       1.00      0.66      0.80        65\n",
      "          4       1.00      0.68      0.81        98\n",
      "          5       1.00      0.38      0.55        24\n",
      "\n",
      "avg / total       0.84      0.76      0.74       418\n",
      "\n",
      "[  6  14   0   0   0   0   0 188   0   0   0   0   0  19   4   0   0   0\n",
      "   0  22   0  43   0   0   0  31   0   0  67   0   0  15   0   0   0   9]\n",
      "LR Accuracy:  0.7583732057416268\n",
      "LR F1:  0.6166611282963484\n",
      "For name:  c_murray\n",
      "total sample size before apply threshold:  112\n",
      "Counter({'0000-0002-0951-5700': 41, '0000-0001-6736-1546': 28, '0000-0002-2398-3914': 23, '0000-0002-5499-6857': 15, '0000-0003-4471-0509': 4, '0000-0002-4713-8475': 1})\n",
      "['0000-0001-6736-1546', '0000-0002-2398-3914', '0000-0002-5499-6857', '0000-0002-0951-5700']\n",
      "Total sample size after apply threshold:  107\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 296)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.50      0.65        28\n",
      "          1       1.00      0.78      0.88        23\n",
      "          2       1.00      0.20      0.33        15\n",
      "          3       0.56      0.98      0.71        41\n",
      "\n",
      "avg / total       0.82      0.70      0.68       107\n",
      "\n",
      "[14  0  0 14  0 18  0  5  0  0  3 12  1  0  0 40]\n",
      "MNB Accuracy:  0.7009345794392523\n",
      "MNB F1:  0.6442076547011317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.75      0.84        28\n",
      "          1       1.00      0.91      0.95        23\n",
      "          2       1.00      0.27      0.42        15\n",
      "          3       0.67      0.98      0.79        41\n",
      "\n",
      "avg / total       0.86      0.80      0.79       107\n",
      "\n",
      "[21  0  0  7  0 21  0  2  0  0  4 11  1  0  0 40]\n",
      "svc Accuracy:  0.8037383177570093\n",
      "svc F1:  0.7519193235112984\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        28\n",
      "          1       1.00      0.74      0.85        23\n",
      "          2       1.00      0.13      0.24        15\n",
      "          3       0.55      1.00      0.71        41\n",
      "\n",
      "avg / total       0.83      0.68      0.65       107\n",
      "\n",
      "[13  0  0 15  0 17  0  6  0  0  2 13  0  0  0 41]\n",
      "LR Accuracy:  0.6822429906542056\n",
      "LR F1:  0.6065842527086529\n",
      "For name:  m_grant\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-1380-2104': 28, '0000-0002-7838-8725': 9, '0000-0003-1003-4071': 1, '0000-0002-0377-2036': 1})\n",
      "['0000-0002-1380-2104']\n",
      "Total sample size after apply threshold:  28\n",
      "For name:  d_scott\n",
      "total sample size before apply threshold:  145\n",
      "Counter({'0000-0001-5226-1972': 65, '0000-0002-6726-2078': 64, '0000-0002-6878-9840': 10, '0000-0003-2230-0090': 2, '0000-0003-4918-2610': 2, '0000-0001-8560-0248': 1, '0000-0002-2592-1522': 1})\n",
      "['0000-0002-6726-2078', '0000-0001-5226-1972', '0000-0002-6878-9840']\n",
      "Total sample size after apply threshold:  139\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(139, 750)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.89      0.90        64\n",
      "          1       0.84      1.00      0.92        65\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.82      0.88      0.84       139\n",
      "\n",
      "[57  7  0  0 65  0  5  5  0]\n",
      "MNB Accuracy:  0.8776978417266187\n",
      "MNB F1:  0.6067516208361279\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        64\n",
      "          1       1.00      0.97      0.98        65\n",
      "          2       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.93      0.92      0.90       139\n",
      "\n",
      "[64  0  0  2 63  0  9  0  1]\n",
      "svc Accuracy:  0.920863309352518\n",
      "svc F1:  0.6956854970568999\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        64\n",
      "          1       1.00      0.97      0.98        65\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.86      0.91      0.88       139\n",
      "\n",
      "[64  0  0  2 63  0 10  0  0]\n",
      "LR Accuracy:  0.9136690647482014\n",
      "LR F1:  0.6328869047619047\n",
      "For name:  s_mohan\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0002-5305-9685': 43, '0000-0002-4797-9565': 4, '0000-0001-5628-2631': 2, '0000-0001-8980-0730': 1})\n",
      "['0000-0002-5305-9685']\n",
      "Total sample size after apply threshold:  43\n",
      "For name:  n_wong\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0003-3788-8114': 13, '0000-0002-7003-6020': 9, '0000-0003-4393-7541': 1, '0000-0002-5932-1015': 1})\n",
      "['0000-0003-3788-8114']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  k_anderson\n",
      "total sample size before apply threshold:  171\n",
      "Counter({'0000-0003-1657-2161': 78, '0000-0002-9324-9598': 44, '0000-0001-9843-404X': 22, '0000-0001-5613-5893': 14, '0000-0002-3289-2598': 6, '0000-0003-3927-8117': 4, '0000-0002-1472-3352': 2, '0000-0002-5458-6735': 1})\n",
      "['0000-0001-9843-404X', '0000-0002-9324-9598', '0000-0001-5613-5893', '0000-0003-1657-2161']\n",
      "Total sample size after apply threshold:  158\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(158, 453)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "158\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        22\n",
      "          1       1.00      0.70      0.83        44\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.67      1.00      0.80        78\n",
      "\n",
      "avg / total       0.75      0.75      0.71       158\n",
      "\n",
      "[10  0  0 12  0 31  0 13  0  0  0 14  0  0  0 78]\n",
      "MNB Accuracy:  0.7531645569620253\n",
      "MNB F1:  0.5629166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        22\n",
      "          1       1.00      0.68      0.81        44\n",
      "          2       1.00      0.71      0.83        14\n",
      "          3       0.76      1.00      0.86        78\n",
      "\n",
      "avg / total       0.88      0.84      0.84       158\n",
      "\n",
      "[15  0  0  7  0 30  0 14  0  0 10  4  0  0  0 78]\n",
      "svc Accuracy:  0.8417721518987342\n",
      "svc F1:  0.8292083519984073\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        22\n",
      "          1       1.00      0.55      0.71        44\n",
      "          2       1.00      0.07      0.13        14\n",
      "          3       0.62      1.00      0.76        78\n",
      "\n",
      "avg / total       0.81      0.70      0.65       158\n",
      "\n",
      "[ 7  0  0 15  0 24  0 20  0  0  1 13  0  0  0 78]\n",
      "LR Accuracy:  0.6962025316455697\n",
      "LR F1:  0.5216700473292766\n",
      "For name:  m_king\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-2587-9117': 26, '0000-0001-6030-5154': 13, '0000-0001-9895-7297': 9, '0000-0001-5611-9498': 7, '0000-0002-9558-8622': 2, '0000-0001-7993-8808': 1})\n",
      "['0000-0001-6030-5154', '0000-0002-2587-9117']\n",
      "Total sample size after apply threshold:  39\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 62)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       0.79      1.00      0.88        26\n",
      "\n",
      "avg / total       0.86      0.82      0.80        39\n",
      "\n",
      "[ 6  7  0 26]\n",
      "MNB Accuracy:  0.8205128205128205\n",
      "MNB F1:  0.7564674397859055\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        13\n",
      "          1       0.96      0.96      0.96        26\n",
      "\n",
      "avg / total       0.95      0.95      0.95        39\n",
      "\n",
      "[12  1  1 25]\n",
      "svc Accuracy:  0.9487179487179487\n",
      "svc F1:  0.9423076923076923\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       0.79      1.00      0.88        26\n",
      "\n",
      "avg / total       0.86      0.82      0.80        39\n",
      "\n",
      "[ 6  7  0 26]\n",
      "LR Accuracy:  0.8205128205128205\n",
      "LR F1:  0.7564674397859055\n",
      "For name:  a_srivastava\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0002-2031-4643': 14, '0000-0002-0211-7814': 13, '0000-0001-9866-8145': 6, '0000-0001-7042-4317': 5, '0000-0001-8340-856X': 3, '0000-0001-9871-5781': 3, '0000-0001-5345-6405': 2, '0000-0002-7046-405X': 1, '0000-0002-4590-7947': 1, '0000-0002-5295-7176': 1})\n",
      "['0000-0002-2031-4643', '0000-0002-0211-7814']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 105)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.87      1.00      0.93        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        27\n",
      "\n",
      "[12  2  0 13]\n",
      "MNB Accuracy:  0.9259259259259259\n",
      "MNB F1:  0.9258241758241759\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        14\n",
      "          1       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.97      0.96      0.96        27\n",
      "\n",
      "[14  0  1 12]\n",
      "svc Accuracy:  0.9629629629629629\n",
      "svc F1:  0.9627586206896552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        14\n",
      "          1       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.91      0.89      0.89        27\n",
      "\n",
      "[14  0  3 10]\n",
      "LR Accuracy:  0.8888888888888888\n",
      "LR F1:  0.8863955119214586\n",
      "For name:  m_scholz\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0001-8440-6785': 31, '0000-0002-4300-3020': 9, '0000-0001-9887-9831': 2})\n",
      "['0000-0001-8440-6785']\n",
      "Total sample size after apply threshold:  31\n",
      "For name:  y_ju\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0002-5120-6960': 14, '0000-0001-8325-1494': 9, '0000-0003-0103-1207': 3, '0000-0002-5514-4189': 1})\n",
      "['0000-0002-5120-6960']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  d_stanley\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0001-9806-5694': 4, '0000-0001-5992-8901': 1, '0000-0001-8948-8409': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_nogueira\n",
      "total sample size before apply threshold:  303\n",
      "Counter({'0000-0003-2950-3632': 279, '0000-0002-0853-5304': 16, '0000-0001-8464-0045': 4, '0000-0002-9152-754X': 4})\n",
      "['0000-0002-0853-5304', '0000-0003-2950-3632']\n",
      "Total sample size after apply threshold:  295\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 392)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.48        16\n",
      "          1       0.96      1.00      0.98       279\n",
      "\n",
      "avg / total       0.96      0.96      0.95       295\n",
      "\n",
      "[  5  11   0 279]\n",
      "MNB Accuracy:  0.9627118644067797\n",
      "MNB F1:  0.7284291572516528\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.48        16\n",
      "          1       0.96      1.00      0.98       279\n",
      "\n",
      "avg / total       0.96      0.96      0.95       295\n",
      "\n",
      "[  5  11   0 279]\n",
      "svc Accuracy:  0.9627118644067797\n",
      "svc F1:  0.7284291572516528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.95      1.00      0.97       279\n",
      "\n",
      "avg / total       0.89      0.95      0.92       295\n",
      "\n",
      "[  0  16   0 279]\n",
      "LR Accuracy:  0.9457627118644067\n",
      "LR F1:  0.48606271777003485\n",
      "For name:  j_cooper\n",
      "total sample size before apply threshold:  147\n",
      "Counter({'0000-0003-1339-4750': 85, '0000-0001-6009-3542': 24, '0000-0001-8163-2306': 19, '0000-0002-9014-4395': 14, '0000-0002-8626-7827': 4, '0000-0002-4932-1740': 1})\n",
      "['0000-0002-9014-4395', '0000-0001-6009-3542', '0000-0001-8163-2306', '0000-0003-1339-4750']\n",
      "Total sample size after apply threshold:  142\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 549)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "142\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       1.00      0.50      0.67        24\n",
      "          2       1.00      0.37      0.54        19\n",
      "          3       0.69      1.00      0.82        85\n",
      "\n",
      "avg / total       0.72      0.73      0.67       142\n",
      "\n",
      "[ 0  0  0 14  0 12  0 12  0  0  7 12  0  0  0 85]\n",
      "MNB Accuracy:  0.7323943661971831\n",
      "MNB F1:  0.5056089743589743\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        14\n",
      "          1       1.00      0.75      0.86        24\n",
      "          2       1.00      0.63      0.77        19\n",
      "          3       0.79      1.00      0.89        85\n",
      "\n",
      "avg / total       0.88      0.85      0.83       142\n",
      "\n",
      "[ 5  0  0  9  0 18  0  6  0  0 12  7  0  0  0 85]\n",
      "svc Accuracy:  0.8450704225352113\n",
      "svc F1:  0.7607672154175761\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       1.00      0.33      0.50        24\n",
      "          2       1.00      0.21      0.35        19\n",
      "          3       0.65      1.00      0.79        85\n",
      "\n",
      "avg / total       0.69      0.68      0.60       142\n",
      "\n",
      "[ 0  0  0 14  0  8  0 16  0  0  4 15  0  0  0 85]\n",
      "LR Accuracy:  0.6830985915492958\n",
      "LR F1:  0.4096309403437816\n",
      "For name:  k_lau\n",
      "total sample size before apply threshold:  121\n",
      "Counter({'0000-0003-2125-6841': 81, '0000-0003-3676-9228': 18, '0000-0001-8438-0319': 17, '0000-0002-7713-1928': 4, '0000-0003-2197-5539': 1})\n",
      "['0000-0001-8438-0319', '0000-0003-2125-6841', '0000-0003-3676-9228']\n",
      "Total sample size after apply threshold:  116\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(116, 242)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.38        17\n",
      "          1       0.76      1.00      0.86        81\n",
      "          2       1.00      0.28      0.43        18\n",
      "\n",
      "avg / total       0.83      0.78      0.73       116\n",
      "\n",
      "[ 4 13  0  0 81  0  0 13  5]\n",
      "MNB Accuracy:  0.7758620689655172\n",
      "MNB F1:  0.5591457057692025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        17\n",
      "          1       0.91      1.00      0.95        81\n",
      "          2       1.00      0.83      0.91        18\n",
      "\n",
      "avg / total       0.94      0.93      0.93       116\n",
      "\n",
      "[12  5  0  0 81  0  0  3 15]\n",
      "svc Accuracy:  0.9310344827586207\n",
      "svc F1:  0.8965394308193497\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.11        17\n",
      "          1       0.72      1.00      0.84        81\n",
      "          2       1.00      0.17      0.29        18\n",
      "\n",
      "avg / total       0.81      0.73      0.65       116\n",
      "\n",
      "[ 1 16  0  0 81  0  0 15  3]\n",
      "LR Accuracy:  0.7327586206896551\n",
      "LR F1:  0.412067878389122\n",
      "For name:  s_hussein\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0002-7946-0717': 18, '0000-0002-6305-508X': 9, '0000-0003-3657-7410': 4, '0000-0002-5394-4385': 1, '0000-0002-0139-1483': 1})\n",
      "['0000-0002-7946-0717']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  z_luo\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-3074-046X': 15, '0000-0002-2719-1025': 5, '0000-0002-8129-333X': 3, '0000-0003-0164-4492': 2})\n",
      "['0000-0002-3074-046X']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  c_pimentel\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0002-5158-6414': 16, '0000-0002-1106-8962': 3, '0000-0002-8364-8990': 2, '0000-0002-4932-0174': 1})\n",
      "['0000-0002-5158-6414']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  s_ito\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0003-1776-4608': 22, '0000-0001-9310-1852': 18, '0000-0003-1108-1371': 14, '0000-0002-0268-013X': 4, '0000-0002-3635-2580': 1})\n",
      "['0000-0001-9310-1852', '0000-0003-1108-1371', '0000-0003-1776-4608']\n",
      "Total sample size after apply threshold:  54\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 134)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       1.00      1.00      1.00        54\n",
      "\n",
      "[18  0  0  0 14  0  0  0 22]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       1.00      1.00      1.00        54\n",
      "\n",
      "[18  0  0  0 14  0  0  0 22]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       1.00      1.00      1.00        54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[18  0  0  0 14  0  0  0 22]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  f_zhang\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0001-6035-4829': 27, '0000-0001-7434-7339': 23, '0000-0002-0480-7501': 11, '0000-0001-9542-6634': 10, '0000-0003-1298-9795': 9, '0000-0002-1371-266X': 7, '0000-0002-1957-0543': 5, '0000-0002-2822-2049': 4, '0000-0002-9309-9577': 2, '0000-0003-1709-7788': 2, '0000-0001-7550-9483': 1, '0000-0002-8438-7155': 1, '0000-0003-2829-0735': 1})\n",
      "['0000-0001-7434-7339', '0000-0002-0480-7501', '0000-0001-6035-4829', '0000-0001-9542-6634']\n",
      "Total sample size after apply threshold:  71\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 158)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        23\n",
      "          1       1.00      0.64      0.78        11\n",
      "          2       0.80      0.89      0.84        27\n",
      "          3       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.85      0.82      0.80        71\n",
      "\n",
      "[23  0  0  0  3  7  1  0  3  0 24  0  1  0  5  4]\n",
      "MNB Accuracy:  0.8169014084507042\n",
      "MNB F1:  0.7648090351665328\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        23\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       0.90      0.96      0.93        27\n",
      "          3       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.95      0.94      0.94        71\n",
      "\n",
      "[23  0  0  0  0 11  0  0  1  0 26  0  0  0  3  7]\n",
      "svc Accuracy:  0.9436619718309859\n",
      "svc F1:  0.9327060611478633\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        23\n",
      "          1       1.00      0.91      0.95        11\n",
      "          2       0.79      0.96      0.87        27\n",
      "          3       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.91      0.89      0.87        71\n",
      "\n",
      "[23  0  0  0  0 10  1  0  1  0 26  0  0  0  6  4]\n",
      "LR Accuracy:  0.8873239436619719\n",
      "LR F1:  0.8422998986828775\n",
      "For name:  s_chapman\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0003-3347-6024': 23, '0000-0003-0053-1584': 23, '0000-0002-4314-9193': 15, '0000-0003-0778-084X': 7, '0000-0003-2342-3383': 3})\n",
      "['0000-0003-3347-6024', '0000-0003-0053-1584', '0000-0002-4314-9193']\n",
      "Total sample size after apply threshold:  61\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 128)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.91      0.93        23\n",
      "          1       0.85      1.00      0.92        23\n",
      "          2       1.00      0.80      0.89        15\n",
      "\n",
      "avg / total       0.93      0.92      0.92        61\n",
      "\n",
      "[21  2  0  0 23  0  1  2 12]\n",
      "MNB Accuracy:  0.9180327868852459\n",
      "MNB F1:  0.9140740740740741\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        23\n",
      "          1       0.88      1.00      0.94        23\n",
      "          2       1.00      0.80      0.89        15\n",
      "\n",
      "avg / total       0.92      0.92      0.92        61\n",
      "\n",
      "[21  2  0  0 23  0  2  1 12]\n",
      "svc Accuracy:  0.9180327868852459\n",
      "svc F1:  0.9135692924512799\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.89        23\n",
      "          1       0.85      1.00      0.92        23\n",
      "          2       1.00      0.67      0.80        15\n",
      "\n",
      "avg / total       0.90      0.89      0.88        61\n",
      "\n",
      "[21  2  0  0 23  0  3  2 10]\n",
      "LR Accuracy:  0.8852459016393442\n",
      "LR F1:  0.8712056737588654\n",
      "For name:  j_rosa\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0003-0857-3746': 15, '0000-0001-7770-5381': 7, '0000-0002-7154-2494': 4, '0000-0001-7947-2681': 2, '0000-0002-0015-6254': 1})\n",
      "['0000-0003-0857-3746']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  y_yin\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0003-0218-3042': 127, '0000-0003-1077-810X': 8, '0000-0003-3514-5712': 5, '0000-0003-0963-2672': 5, '0000-0003-0965-4951': 4, '0000-0002-8685-4378': 2, '0000-0001-5821-7497': 1})\n",
      "['0000-0003-0218-3042']\n",
      "Total sample size after apply threshold:  127\n",
      "For name:  p_tavares\n",
      "total sample size before apply threshold:  53\n",
      "Counter({'0000-0002-7398-2661': 29, '0000-0001-7589-1299': 13, '0000-0002-2287-2446': 8, '0000-0001-7832-4134': 3})\n",
      "['0000-0001-7589-1299', '0000-0002-7398-2661']\n",
      "Total sample size after apply threshold:  42\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 144)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.56        13\n",
      "          1       0.78      1.00      0.88        29\n",
      "\n",
      "avg / total       0.85      0.81      0.78        42\n",
      "\n",
      "[ 5  8  0 29]\n",
      "MNB Accuracy:  0.8095238095238095\n",
      "MNB F1:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7171717171717171\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.97      1.00      0.98        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        42\n",
      "\n",
      "[12  1  0 29]\n",
      "svc Accuracy:  0.9761904761904762\n",
      "svc F1:  0.9715254237288136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.14        13\n",
      "          1       0.71      1.00      0.83        29\n",
      "\n",
      "avg / total       0.80      0.71      0.62        42\n",
      "\n",
      "[ 1 12  0 29]\n",
      "LR Accuracy:  0.7142857142857143\n",
      "LR F1:  0.4857142857142857\n",
      "For name:  a_palma\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0003-2099-1297': 34, '0000-0002-8530-4913': 13, '0000-0002-5971-3676': 8, '0000-0003-0420-1785': 3, '0000-0002-1682-7032': 2, '0000-0002-7263-4868': 1})\n",
      "['0000-0002-8530-4913', '0000-0003-2099-1297']\n",
      "Total sample size after apply threshold:  47\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 71)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        34\n",
      "\n",
      "avg / total       1.00      1.00      1.00        47\n",
      "\n",
      "[13  0  0 34]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        34\n",
      "\n",
      "avg / total       1.00      1.00      1.00        47\n",
      "\n",
      "[13  0  0 34]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.97      1.00      0.99        34\n",
      "\n",
      "avg / total       0.98      0.98      0.98        47\n",
      "\n",
      "[12  1  0 34]\n",
      "LR Accuracy:  0.9787234042553191\n",
      "LR F1:  0.9727536231884057\n",
      "For name:  e_shaw\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0003-1424-7568': 9, '0000-0002-5653-0145': 4, '0000-0002-4148-3526': 2, '0000-0002-4334-1900': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_cameron\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0001-5788-8790': 17, '0000-0002-2277-7035': 9, '0000-0001-9464-8796': 1, '0000-0002-2508-7718': 1})\n",
      "['0000-0001-5788-8790']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  a_reid\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-0523-926X': 18, '0000-0003-1752-3302': 18, '0000-0003-4713-2951': 6, '0000-0002-2500-2980': 2})\n",
      "['0000-0002-0523-926X', '0000-0003-1752-3302']\n",
      "Total sample size after apply threshold:  36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 101)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        18\n",
      "          1       1.00      0.94      0.97        18\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[18  0  1 17]\n",
      "MNB Accuracy:  0.9722222222222222\n",
      "MNB F1:  0.9722007722007722\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.94      0.89        18\n",
      "          1       0.94      0.83      0.88        18\n",
      "\n",
      "avg / total       0.89      0.89      0.89        36\n",
      "\n",
      "[17  1  3 15]\n",
      "svc Accuracy:  0.8888888888888888\n",
      "svc F1:  0.8885448916408669\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        18\n",
      "          1       1.00      0.78      0.88        18\n",
      "\n",
      "avg / total       0.91      0.89      0.89        36\n",
      "\n",
      "[18  0  4 14]\n",
      "LR Accuracy:  0.8888888888888888\n",
      "LR F1:  0.8875000000000001\n",
      "For name:  d_gil\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0003-3179-1987': 23, '0000-0002-2770-4767': 16, '0000-0003-4241-1302': 16, '0000-0001-8910-2780': 4, '0000-0003-0791-8298': 1})\n",
      "['0000-0002-2770-4767', '0000-0003-3179-1987', '0000-0003-4241-1302']\n",
      "Total sample size after apply threshold:  55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 176)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.79      1.00      0.88        23\n",
      "          2       1.00      0.81      0.90        16\n",
      "\n",
      "avg / total       0.91      0.89      0.89        55\n",
      "\n",
      "[13  3  0  0 23  0  0  3 13]\n",
      "MNB Accuracy:  0.8909090909090909\n",
      "MNB F1:  0.8925729442970822\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.85      1.00      0.92        23\n",
      "          2       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.94      0.93      0.93        55\n",
      "\n",
      "[13  3  0  0 23  0  0  1 15]\n",
      "svc Accuracy:  0.9272727272727272\n",
      "svc F1:  0.9280978865406007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.77      1.00      0.87        23\n",
      "          2       1.00      0.75      0.86        16\n",
      "\n",
      "avg / total       0.90      0.87      0.87        55\n",
      "\n",
      "[13  3  0  0 23  0  0  4 12]\n",
      "LR Accuracy:  0.8727272727272727\n",
      "LR F1:  0.8738730365275584\n",
      "For name:  s_morgan\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0003-4069-3801': 38, '0000-0001-5091-3148': 28, '0000-0002-5340-0652': 7, '0000-0001-9528-8323': 4, '0000-0002-1734-4710': 2, '0000-0002-7529-0028': 2, '0000-0001-7601-3551': 1, '0000-0001-7610-4496': 1})\n",
      "['0000-0003-4069-3801', '0000-0001-5091-3148']\n",
      "Total sample size after apply threshold:  66\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 136)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        38\n",
      "          1       1.00      0.96      0.98        28\n",
      "\n",
      "avg / total       0.99      0.98      0.98        66\n",
      "\n",
      "[38  0  1 27]\n",
      "MNB Accuracy:  0.9848484848484849\n",
      "MNB F1:  0.9844155844155844\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        38\n",
      "          1       1.00      0.96      0.98        28\n",
      "\n",
      "avg / total       0.99      0.98      0.98        66\n",
      "\n",
      "[38  0  1 27]\n",
      "svc Accuracy:  0.9848484848484849\n",
      "svc F1:  0.9844155844155844\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        38\n",
      "          1       1.00      0.79      0.88        28\n",
      "\n",
      "avg / total       0.92      0.91      0.91        66\n",
      "\n",
      "[38  0  6 22]\n",
      "LR Accuracy:  0.9090909090909091\n",
      "LR F1:  0.9034146341463414\n",
      "For name:  p_ross\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0001-7105-7117': 14, '0000-0002-5051-5382': 10, '0000-0001-7984-6452': 2, '0000-0001-7645-7523': 1})\n",
      "['0000-0002-5051-5382', '0000-0001-7105-7117']\n",
      "Total sample size after apply threshold:  24\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 92)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.60      0.71        10\n",
      "          1       0.76      0.93      0.84        14\n",
      "\n",
      "avg / total       0.80      0.79      0.78        24\n",
      "\n",
      "[ 6  4  1 13]\n",
      "MNB Accuracy:  0.7916666666666666\n",
      "MNB F1:  0.7722960151802656\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.78      1.00      0.88        14\n",
      "\n",
      "avg / total       0.87      0.83      0.82        24\n",
      "\n",
      "[ 6  4  0 14]\n",
      "svc Accuracy:  0.8333333333333334\n",
      "svc F1:  0.8125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.74      1.00      0.85        14\n",
      "\n",
      "avg / total       0.85      0.79      0.77        24\n",
      "\n",
      "[ 5  5  0 14]\n",
      "LR Accuracy:  0.7916666666666666\n",
      "LR F1:  0.7575757575757576\n",
      "For name:  l_simon\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0003-4321-8539': 7, '0000-0003-4870-1052': 4, '0000-0002-5010-4778': 2, '0000-0002-0148-4217': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  k_thomas\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0003-3436-2184': 23, '0000-0003-3355-9583': 23, '0000-0001-8152-9974': 6, '0000-0003-2980-2384': 5, '0000-0001-8836-4631': 3})\n",
      "['0000-0003-3436-2184', '0000-0003-3355-9583']\n",
      "Total sample size after apply threshold:  46\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 66)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        23\n",
      "          1       0.96      0.96      0.96        23\n",
      "\n",
      "avg / total       0.96      0.96      0.96        46\n",
      "\n",
      "[22  1  1 22]\n",
      "MNB Accuracy:  0.9565217391304348\n",
      "MNB F1:  0.9565217391304348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        23\n",
      "          1       0.92      1.00      0.96        23\n",
      "\n",
      "avg / total       0.96      0.96      0.96        46\n",
      "\n",
      "[21  2  0 23]\n",
      "svc Accuracy:  0.9565217391304348\n",
      "svc F1:  0.9564393939393939\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        23\n",
      "          1       0.92      1.00      0.96        23\n",
      "\n",
      "avg / total       0.96      0.96      0.96        46\n",
      "\n",
      "[21  2  0 23]\n",
      "LR Accuracy:  0.9565217391304348\n",
      "LR F1:  0.9564393939393939\n",
      "For name:  l_torres\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0002-0194-7875': 56, '0000-0002-4598-1899': 7, '0000-0002-2512-1074': 1, '0000-0001-9945-7331': 1})\n",
      "['0000-0002-0194-7875']\n",
      "Total sample size after apply threshold:  56\n",
      "For name:  p_ding\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-3535-6053': 8, '0000-0003-2559-4696': 8, '0000-0002-2613-2496': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  g_morris\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0003-1731-8405': 50, '0000-0003-2588-6349': 23, '0000-0002-1097-4453': 19, '0000-0001-9893-6648': 16, '0000-0002-3067-3359': 15, '0000-0003-2892-8428': 5})\n",
      "['0000-0001-9893-6648', '0000-0003-2588-6349', '0000-0002-1097-4453', '0000-0002-3067-3359', '0000-0003-1731-8405']\n",
      "Total sample size after apply threshold:  123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(123, 377)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.56      0.72        16\n",
      "          1       1.00      0.57      0.72        23\n",
      "          2       1.00      0.47      0.64        19\n",
      "          3       1.00      0.27      0.42        15\n",
      "          4       0.57      1.00      0.72        50\n",
      "\n",
      "avg / total       0.82      0.69      0.67       123\n",
      "\n",
      "[ 9  0  0  0  7  0 13  0  0 10  0  0  9  0 10  0  0  0  4 11  0  0  0  0\n",
      " 50]\n",
      "MNB Accuracy:  0.6910569105691057\n",
      "MNB F1:  0.6461539355635465\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        16\n",
      "          1       1.00      0.61      0.76        23\n",
      "          2       1.00      0.74      0.85        19\n",
      "          3       1.00      0.53      0.70        15\n",
      "          4       0.65      1.00      0.79        50\n",
      "\n",
      "avg / total       0.86      0.78      0.78       123\n",
      "\n",
      "[10  0  0  0  6  0 14  0  0  9  0  0 14  0  5  0  0  0  8  7  0  0  0  0\n",
      " 50]\n",
      "svc Accuracy:  0.7804878048780488\n",
      "svc F1:  0.7715052246377135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.44      0.61        16\n",
      "          1       1.00      0.48      0.65        23\n",
      "          2       1.00      0.47      0.64        19\n",
      "          3       1.00      0.27      0.42        15\n",
      "          4       0.54      1.00      0.70        50\n",
      "\n",
      "avg / total       0.81      0.66      0.64       123\n",
      "\n",
      "[ 7  0  0  0  9  0 11  0  0 12  0  0  9  0 10  0  0  0  4 11  0  0  0  0\n",
      " 50]\n",
      "LR Accuracy:  0.6585365853658537\n",
      "LR F1:  0.6047779204504182\n",
      "For name:  s_andrews\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0003-4295-2686': 46, '0000-0002-2103-7748': 6, '0000-0002-3851-2197': 3, '0000-0003-0878-1182': 2, '0000-0002-5499-5125': 1, '0000-0003-2174-6728': 1, '0000-0003-4997-3906': 1})\n",
      "['0000-0003-4295-2686']\n",
      "Total sample size after apply threshold:  46\n",
      "For name:  b_yan\n",
      "total sample size before apply threshold:  129\n",
      "Counter({'0000-0001-8802-9606': 93, '0000-0003-4268-4757': 21, '0000-0003-3509-0686': 10, '0000-0001-7235-5554': 4, '0000-0003-2258-2817': 1})\n",
      "['0000-0003-4268-4757', '0000-0001-8802-9606', '0000-0003-3509-0686']\n",
      "Total sample size after apply threshold:  124\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(124, 363)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "124\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        21\n",
      "          1       0.88      1.00      0.93        93\n",
      "          2       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.91      0.90      0.87       124\n",
      "\n",
      "[17  4  0  0 93  0  0  9  1]\n",
      "MNB Accuracy:  0.8951612903225806\n",
      "MNB F1:  0.6704094635858718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        21\n",
      "          1       1.00      1.00      1.00        93\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00       124\n",
      "\n",
      "[21  0  0  0 93  0  0  0 10]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        21\n",
      "          1       0.82      1.00      0.90        93\n",
      "          2       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.87      0.84      0.81       124\n",
      "\n",
      "[ 9 12  0  0 93  0  0  8  2]\n",
      "LR Accuracy:  0.8387096774193549\n",
      "LR F1:  0.6120819848975189\n",
      "For name:  r_hu\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0001-6709-031X': 93, '0000-0001-7412-8451': 27, '0000-0001-6893-529X': 4, '0000-0001-5549-3082': 2, '0000-0002-7126-4076': 1, '0000-0001-5921-6891': 1})\n",
      "['0000-0001-6709-031X', '0000-0001-7412-8451']\n",
      "Total sample size after apply threshold:  120\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(120, 106)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "120\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99        93\n",
      "          1       1.00      0.96      0.98        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99       120\n",
      "\n",
      "[93  0  1 26]\n",
      "MNB Accuracy:  0.9916666666666667\n",
      "MNB F1:  0.9878922409444052\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        93\n",
      "          1       1.00      1.00      1.00        27\n",
      "\n",
      "avg / total       1.00      1.00      1.00       120\n",
      "\n",
      "[93  0  0 27]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        93\n",
      "          1       1.00      0.81      0.90        27\n",
      "\n",
      "avg / total       0.96      0.96      0.96       120\n",
      "\n",
      "[93  0  5 22]\n",
      "LR Accuracy:  0.9583333333333334\n",
      "LR F1:  0.9358905866011326\n",
      "For name:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j_braun\n",
      "total sample size before apply threshold:  72\n",
      "Counter({'0000-0002-8886-078X': 37, '0000-0002-4504-6235': 25, '0000-0002-8309-6401': 5, '0000-0002-2491-5788': 5})\n",
      "['0000-0002-8886-078X', '0000-0002-4504-6235']\n",
      "Total sample size after apply threshold:  62\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 157)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        37\n",
      "          1       1.00      0.80      0.89        25\n",
      "\n",
      "avg / total       0.93      0.92      0.92        62\n",
      "\n",
      "[37  0  5 20]\n",
      "MNB Accuracy:  0.9193548387096774\n",
      "MNB F1:  0.9127988748241913\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        37\n",
      "          1       1.00      0.84      0.91        25\n",
      "\n",
      "avg / total       0.94      0.94      0.93        62\n",
      "\n",
      "[37  0  4 21]\n",
      "svc Accuracy:  0.9354838709677419\n",
      "svc F1:  0.9308807134894093\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        37\n",
      "          1       1.00      0.64      0.78        25\n",
      "\n",
      "avg / total       0.88      0.85      0.85        62\n",
      "\n",
      "[37  0  9 16]\n",
      "LR Accuracy:  0.8548387096774194\n",
      "LR F1:  0.8360270349691448\n",
      "For name:  c_he\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0002-4868-331X': 20, '0000-0002-1918-5186': 13, '0000-0002-0663-275X': 7, '0000-0001-7869-7627': 5, '0000-0001-5426-769X': 2, '0000-0001-9867-9629': 1, '0000-0001-5842-9617': 1})\n",
      "['0000-0002-4868-331X', '0000-0002-1918-5186']\n",
      "Total sample size after apply threshold:  33\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 163)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        20\n",
      "          1       0.92      0.92      0.92        13\n",
      "\n",
      "avg / total       0.94      0.94      0.94        33\n",
      "\n",
      "[19  1  1 12]\n",
      "MNB Accuracy:  0.9393939393939394\n",
      "MNB F1:  0.9365384615384615\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        20\n",
      "          1       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.94      0.94      0.94        33\n",
      "\n",
      "[20  0  2 11]\n",
      "svc Accuracy:  0.9393939393939394\n",
      "svc F1:  0.9345238095238095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        20\n",
      "          1       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.90      0.88      0.87        33\n",
      "\n",
      "[20  0  4  9]\n",
      "LR Accuracy:  0.8787878787878788\n",
      "LR F1:  0.8636363636363635\n",
      "For name:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_lu\n",
      "total sample size before apply threshold:  138\n",
      "Counter({'0000-0003-4731-1976': 38, '0000-0001-6722-1527': 33, '0000-0001-5358-305X': 30, '0000-0001-7421-347X': 13, '0000-0002-1405-4806': 6, '0000-0001-9798-8964': 4, '0000-0003-4334-5722': 3, '0000-0002-6570-3044': 3, '0000-0002-5243-5554': 2, '0000-0001-5508-342X': 2, '0000-0002-1398-9933': 1, '0000-0001-6214-4024': 1, '0000-0002-5101-9778': 1, '0000-0002-4528-2246': 1})\n",
      "['0000-0001-5358-305X', '0000-0003-4731-1976', '0000-0001-7421-347X', '0000-0001-6722-1527']\n",
      "Total sample size after apply threshold:  114\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 152)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "114\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94        30\n",
      "          1       0.94      0.89      0.92        38\n",
      "          2       1.00      0.46      0.63        13\n",
      "          3       0.80      0.97      0.88        33\n",
      "\n",
      "avg / total       0.90      0.89      0.88       114\n",
      "\n",
      "[29  0  0  1  3 34  0  1  0  1  6  6  0  1  0 32]\n",
      "MNB Accuracy:  0.8859649122807017\n",
      "MNB F1:  0.8406735165055512\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        30\n",
      "          1       0.88      1.00      0.94        38\n",
      "          2       0.92      0.85      0.88        13\n",
      "          3       1.00      0.97      0.98        33\n",
      "\n",
      "avg / total       0.95      0.95      0.95       114\n",
      "\n",
      "[27  2  1  0  0 38  0  0  0  2 11  0  0  1  0 32]\n",
      "svc Accuracy:  0.9473684210526315\n",
      "svc F1:  0.9375638526515719\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.90      0.93        30\n",
      "          1       0.86      0.95      0.90        38\n",
      "          2       1.00      0.85      0.92        13\n",
      "          3       0.94      0.94      0.94        33\n",
      "\n",
      "avg / total       0.93      0.92      0.92       114\n",
      "\n",
      "[27  2  0  1  1 36  0  1  0  2 11  0  0  2  0 31]\n",
      "LR Accuracy:  0.9210526315789473\n",
      "LR F1:  0.9217737722048067\n",
      "For name:  r_radhakrishnan\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0003-0088-4777': 35, '0000-0002-8220-655X': 14, '0000-0001-6616-8525': 7, '0000-0001-7170-699X': 5, '0000-0002-3560-1020': 1})\n",
      "['0000-0003-0088-4777', '0000-0002-8220-655X']\n",
      "Total sample size after apply threshold:  49\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 119)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90        35\n",
      "          1       1.00      0.43      0.60        14\n",
      "\n",
      "avg / total       0.87      0.84      0.81        49\n",
      "\n",
      "[35  0  8  6]\n",
      "MNB Accuracy:  0.8367346938775511\n",
      "MNB F1:  0.7487179487179487\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93        35\n",
      "          1       1.00      0.64      0.78        14\n",
      "\n",
      "avg / total       0.91      0.90      0.89        49\n",
      "\n",
      "[35  0  5  9]\n",
      "svc Accuracy:  0.8979591836734694\n",
      "svc F1:  0.8579710144927537\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        35\n",
      "          1       1.00      0.29      0.44        14\n",
      "\n",
      "avg / total       0.84      0.80      0.75        49\n",
      "\n",
      "[35  0 10  4]\n",
      "LR Accuracy:  0.7959183673469388\n",
      "LR F1:  0.6597222222222223\n",
      "For name:  k_saito\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0003-4663-1134': 26, '0000-0002-2151-6204': 16, '0000-0002-5726-8775': 11, '0000-0003-2557-1726': 7, '0000-0001-6310-5342': 1})\n",
      "['0000-0002-2151-6204', '0000-0003-4663-1134', '0000-0002-5726-8775']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 189)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.70      1.00      0.83        26\n",
      "          2       1.00      0.27      0.43        11\n",
      "\n",
      "avg / total       0.85      0.79      0.76        53\n",
      "\n",
      "[13  3  0  0 26  0  0  8  3]\n",
      "MNB Accuracy:  0.7924528301886793\n",
      "MNB F1:  0.7168399927020617\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.81      1.00      0.90        26\n",
      "          2       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.91      0.89      0.88        53\n",
      "\n",
      "[14  2  0  0 26  0  0  4  7]\n",
      "svc Accuracy:  0.8867924528301887\n",
      "svc F1:  0.8692209450830141\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        16\n",
      "          1       0.62      1.00      0.76        26\n",
      "          2       1.00      0.09      0.17        11\n",
      "\n",
      "avg / total       0.81      0.70      0.64        53\n",
      "\n",
      "[10  6  0  0 26  0  0 10  1]\n",
      "LR Accuracy:  0.6981132075471698\n",
      "LR F1:  0.5668677727501258\n",
      "For name:  y_wang\n",
      "total sample size before apply threshold:  1689\n",
      "Counter({'0000-0001-8592-0698': 121, '0000-0003-0852-0767': 117, '0000-0002-6227-6112': 69, '0000-0001-5803-5343': 60, '0000-0002-1211-2822': 57, '0000-0002-3063-3066': 55, '0000-0003-2067-382X': 54, '0000-0003-0773-1212': 42, '0000-0002-6574-6706': 40, '0000-0001-9574-2194': 37, '0000-0001-5764-6740': 35, '0000-0001-6046-2934': 31, '0000-0001-8043-5757': 31, '0000-0003-2533-865X': 31, '0000-0001-8619-0455': 30, '0000-0003-0764-2279': 30, '0000-0002-9893-8296': 29, '0000-0001-7076-8312': 29, '0000-0001-5291-9826': 28, '0000-0002-0921-0122': 27, '0000-0003-3557-5085': 26, '0000-0002-0474-4790': 25, '0000-0003-2540-2199': 24, '0000-0003-0513-9039': 22, '0000-0003-3011-1919': 18, '0000-0002-1241-6252': 17, '0000-0002-5845-5150': 17, '0000-0001-9753-5535': 16, '0000-0003-0961-1716': 16, '0000-0001-6321-9542': 15, '0000-0002-0768-1676': 15, '0000-0002-7851-1623': 14, '0000-0003-1360-8931': 14, '0000-0001-7042-9804': 14, '0000-0002-5985-5244': 13, '0000-0001-5716-3183': 13, '0000-0002-7243-441X': 13, '0000-0002-0363-926X': 13, '0000-0001-6790-1311': 12, '0000-0003-0266-0224': 12, '0000-0001-8440-9388': 12, '0000-0002-2110-623X': 11, '0000-0002-2626-478X': 11, '0000-0001-8021-5180': 11, '0000-0001-8697-9165': 11, '0000-0002-1786-5970': 11, '0000-0003-0144-1388': 11, '0000-0002-3002-8069': 10, '0000-0002-6822-4778': 9, '0000-0002-9659-977X': 9, '0000-0002-8601-8302': 9, '0000-0001-9032-9990': 9, '0000-0002-1851-3483': 9, '0000-0002-1255-0937': 9, '0000-0002-7209-585X': 9, '0000-0002-5111-1443': 9, '0000-0002-6295-6492': 8, '0000-0002-4847-6273': 8, '0000-0002-0002-2467': 8, '0000-0002-7389-5066': 8, '0000-0003-2561-1855': 7, '0000-0003-1286-2401': 7, '0000-0002-2900-5126': 7, '0000-0003-3594-2658': 7, '0000-0003-4816-9182': 6, '0000-0001-5580-7766': 6, '0000-0002-0582-0855': 6, '0000-0002-3034-7377': 6, '0000-0002-2188-383X': 6, '0000-0003-1567-3358': 6, '0000-0001-5020-2020': 6, '0000-0001-9997-7636': 5, '0000-0002-6401-7464': 5, '0000-0003-3620-8455': 5, '0000-0002-2532-4832': 5, '0000-0002-3823-2136': 5, '0000-0002-5300-7121': 4, '0000-0002-7986-4500': 4, '0000-0003-3430-2210': 4, '0000-0002-3769-0020': 4, '0000-0001-8925-5277': 4, '0000-0001-6232-0382': 4, '0000-0003-2763-1008': 3, '0000-0001-5231-6283': 3, '0000-0003-3222-0211': 3, '0000-0002-5590-5881': 3, '0000-0002-3729-2743': 3, '0000-0002-1769-1966': 3, '0000-0003-1786-5767': 3, '0000-0003-0708-1950': 2, '0000-0002-1609-2523': 2, '0000-0001-8518-6745': 2, '0000-0001-5495-5839': 2, '0000-0003-1681-9566': 2, '0000-0001-9474-6396': 2, '0000-0001-6108-5157': 2, '0000-0001-5500-1228': 2, '0000-0002-8648-2172': 2, '0000-0002-3184-4201': 2, '0000-0003-3432-0603': 2, '0000-0002-8937-3000': 2, '0000-0002-0676-5886': 2, '0000-0003-1154-820X': 2, '0000-0002-5223-4074': 2, '0000-0001-6264-650X': 2, '0000-0002-6066-2634': 2, '0000-0003-1404-8526': 2, '0000-0003-3928-6926': 2, '0000-0002-5399-2803': 2, '0000-0002-1288-8997': 2, '0000-0001-6085-5615': 2, '0000-0002-3656-4284': 2, '0000-0002-5187-3755': 2, '0000-0002-9628-1382': 2, '0000-0002-2244-1742': 2, '0000-0003-1009-2087': 1, '0000-0001-6823-1225': 1, '0000-0002-5692-3117': 1, '0000-0001-6981-7797': 1, '0000-0001-7956-3102': 1, '0000-0002-2657-7057': 1, '0000-0002-2665-0365': 1, '0000-0002-4336-0474': 1, '0000-0002-7629-4178': 1, '0000-0001-5918-7525': 1, '0000-0002-0891-1517': 1, '0000-0002-9684-1730': 1, '0000-0002-2932-6042': 1, '0000-0001-8538-5998': 1, '0000-0002-4506-4230': 1, '0000-0003-3120-827X': 1, '0000-0002-9640-0871': 1, '0000-0003-3511-0288': 1, '0000-0001-9156-0377': 1, '0000-0002-7281-1908': 1, '0000-0003-2540-5824': 1, '0000-0002-9365-1851': 1, '0000-0002-2333-157X': 1})\n",
      "['0000-0002-0474-4790', '0000-0001-6790-1311', '0000-0002-2110-623X', '0000-0001-5291-9826', '0000-0002-7851-1623', '0000-0002-1241-6252', '0000-0001-5764-6740', '0000-0001-6046-2934', '0000-0002-0921-0122', '0000-0003-0266-0224', '0000-0002-5985-5244', '0000-0003-1360-8931', '0000-0002-9893-8296', '0000-0002-2626-478X', '0000-0001-8021-5180', '0000-0002-5845-5150', '0000-0003-2540-2199', '0000-0001-8619-0455', '0000-0001-6321-9542', '0000-0003-0513-9039', '0000-0002-1211-2822', '0000-0001-8697-9165', '0000-0002-3063-3066', '0000-0001-5716-3183', '0000-0001-8043-5757', '0000-0002-3002-8069', '0000-0001-7076-8312', '0000-0001-9753-5535', '0000-0003-0961-1716', '0000-0001-8592-0698', '0000-0003-0852-0767', '0000-0002-1786-5970', '0000-0003-0764-2279', '0000-0001-5803-5343', '0000-0002-7243-441X', '0000-0003-2067-382X', '0000-0001-7042-9804', '0000-0002-0768-1676', '0000-0002-0363-926X', '0000-0001-9574-2194', '0000-0003-3557-5085', '0000-0002-6574-6706', '0000-0003-0773-1212', '0000-0003-2533-865X', '0000-0003-3011-1919', '0000-0002-6227-6112', '0000-0003-0144-1388', '0000-0001-8440-9388']\n",
      "Total sample size after apply threshold:  1370\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(1370, 1958)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "1370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.39        25\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.11      0.19        28\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       1.00      0.41      0.58        17\n",
      "          6       1.00      0.83      0.91        35\n",
      "          7       1.00      0.10      0.18        31\n",
      "          8       1.00      0.19      0.31        27\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       0.00      0.00      0.00        13\n",
      "         11       1.00      0.07      0.13        14\n",
      "         12       1.00      0.41      0.59        29\n",
      "         13       0.00      0.00      0.00        11\n",
      "         14       0.00      0.00      0.00        11\n",
      "         15       1.00      0.18      0.30        17\n",
      "         16       1.00      0.71      0.83        24\n",
      "         17       0.75      0.10      0.18        30\n",
      "         18       0.00      0.00      0.00        15\n",
      "         19       1.00      0.95      0.98        22\n",
      "         20       0.92      0.40      0.56        57\n",
      "         21       0.00      0.00      0.00        11\n",
      "         22       1.00      0.96      0.98        55\n",
      "         23       0.00      0.00      0.00        13\n",
      "         24       1.00      0.29      0.45        31\n",
      "         25       0.00      0.00      0.00        10\n",
      "         26       1.00      0.72      0.84        29\n",
      "         27       0.00      0.00      0.00        16\n",
      "         28       1.00      0.38      0.55        16\n",
      "         29       0.28      0.93      0.43       121\n",
      "         30       0.41      0.84      0.55       117\n",
      "         31       0.00      0.00      0.00        11\n",
      "         32       0.67      0.07      0.12        30\n",
      "         33       0.52      0.92      0.67        60\n",
      "         34       0.00      0.00      0.00        13\n",
      "         35       1.00      0.54      0.70        54\n",
      "         36       0.00      0.00      0.00        14\n",
      "         37       0.00      0.00      0.00        15\n",
      "         38       0.00      0.00      0.00        13\n",
      "         39       0.79      0.92      0.85        37\n",
      "         40       1.00      0.92      0.96        26\n",
      "         41       0.67      0.30      0.41        40\n",
      "         42       1.00      0.21      0.35        42\n",
      "         43       0.78      0.94      0.85        31\n",
      "         44       1.00      0.17      0.29        18\n",
      "         45       0.28      0.96      0.44        69\n",
      "         46       0.00      0.00      0.00        11\n",
      "         47       1.00      0.50      0.67        12\n",
      "\n",
      "avg / total       0.63      0.51      0.46      1370\n",
      "\n",
      "[6 0 0 ... 0 0 6]\n",
      "MNB Accuracy:  0.5116788321167883\n",
      "MNB F1:  0.3381250646669425\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        25\n",
      "          1       0.80      0.67      0.73        12\n",
      "          2       0.90      0.82      0.86        11\n",
      "          3       0.72      0.64      0.68        28\n",
      "          4       1.00      0.93      0.96        14\n",
      "          5       1.00      0.94      0.97        17\n",
      "          6       0.91      0.89      0.90        35\n",
      "          7       0.89      0.77      0.83        31\n",
      "          8       0.90      0.70      0.79        27\n",
      "          9       1.00      0.08      0.15        12\n",
      "         10       0.89      0.62      0.73        13\n",
      "         11       1.00      1.00      1.00        14\n",
      "         12       0.83      0.83      0.83        29\n",
      "         13       1.00      0.64      0.78        11\n",
      "         14       0.60      0.55      0.57        11\n",
      "         15       1.00      0.94      0.97        17\n",
      "         16       1.00      0.83      0.91        24\n",
      "         17       0.88      0.77      0.82        30\n",
      "         18       0.91      0.67      0.77        15\n",
      "         19       1.00      0.95      0.98        22\n",
      "         20       0.81      0.67      0.73        57\n",
      "         21       0.89      0.73      0.80        11\n",
      "         22       1.00      0.91      0.95        55\n",
      "         23       1.00      0.23      0.38        13\n",
      "         24       0.62      0.77      0.69        31\n",
      "         25       1.00      0.40      0.57        10\n",
      "         26       1.00      0.83      0.91        29\n",
      "         27       1.00      0.62      0.77        16\n",
      "         28       1.00      0.94      0.97        16\n",
      "         29       0.64      0.90      0.75       121\n",
      "         30       0.47      0.86      0.61       117\n",
      "         31       1.00      0.64      0.78        11\n",
      "         32       0.78      0.93      0.85        30\n",
      "         33       0.89      0.80      0.84        60\n",
      "         34       1.00      0.62      0.76        13\n",
      "         35       0.92      0.83      0.87        54\n",
      "         36       1.00      0.71      0.83        14\n",
      "         37       1.00      0.60      0.75        15\n",
      "         38       0.57      0.31      0.40        13\n",
      "         39       0.94      0.92      0.93        37\n",
      "         40       1.00      0.92      0.96        26\n",
      "         41       0.57      0.68      0.62        40\n",
      "         42       0.96      0.57      0.72        42\n",
      "         43       0.94      0.94      0.94        31\n",
      "         44       0.89      0.89      0.89        18\n",
      "         45       0.79      0.84      0.82        69\n",
      "         46       0.83      0.45      0.59        11\n",
      "         47       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.83      0.79      0.79      1370\n",
      "\n",
      "[15  0  0 ...  0  0 11]\n",
      "svc Accuracy:  0.7854014598540145\n",
      "svc F1:  0.783113614122609\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        25\n",
      "          1       1.00      0.67      0.80        12\n",
      "          2       1.00      0.45      0.62        11\n",
      "          3       1.00      0.43      0.60        28\n",
      "          4       1.00      0.86      0.92        14\n",
      "          5       1.00      0.76      0.87        17\n",
      "          6       0.86      0.89      0.87        35\n",
      "          7       0.92      0.71      0.80        31\n",
      "          8       0.93      0.48      0.63        27\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       1.00      0.38      0.56        13\n",
      "         11       1.00      1.00      1.00        14\n",
      "         12       0.79      0.79      0.79        29\n",
      "         13       1.00      0.36      0.53        11\n",
      "         14       0.80      0.36      0.50        11\n",
      "         15       1.00      0.76      0.87        17\n",
      "         16       1.00      0.75      0.86        24\n",
      "         17       0.80      0.67      0.73        30\n",
      "         18       1.00      0.33      0.50        15\n",
      "         19       1.00      0.95      0.98        22\n",
      "         20       0.64      0.47      0.55        57\n",
      "         21       1.00      0.55      0.71        11\n",
      "         22       1.00      0.93      0.96        55\n",
      "         23       0.00      0.00      0.00        13\n",
      "         24       0.71      0.81      0.76        31\n",
      "         25       1.00      0.10      0.18        10\n",
      "         26       1.00      0.72      0.84        29\n",
      "         27       1.00      0.25      0.40        16\n",
      "         28       1.00      0.81      0.90        16\n",
      "         29       0.56      0.90      0.69       121\n",
      "         30       0.37      0.90      0.52       117\n",
      "         31       1.00      0.36      0.53        11\n",
      "         32       0.68      0.90      0.77        30\n",
      "         33       0.80      0.85      0.82        60\n",
      "         34       1.00      0.08      0.14        13\n",
      "         35       0.85      0.65      0.74        54\n",
      "         36       1.00      0.50      0.67        14\n",
      "         37       1.00      0.13      0.24        15\n",
      "         38       0.00      0.00      0.00        13\n",
      "         39       0.87      0.92      0.89        37\n",
      "         40       1.00      0.92      0.96        26\n",
      "         41       0.59      0.68      0.63        40\n",
      "         42       1.00      0.38      0.55        42\n",
      "         43       0.88      0.94      0.91        31\n",
      "         44       0.88      0.78      0.82        18\n",
      "         45       0.65      0.93      0.77        69\n",
      "         46       1.00      0.36      0.53        11\n",
      "         47       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.78      0.70      0.69      1370\n",
      "\n",
      "[ 8  0  0 ...  0  0 11]\n",
      "LR Accuracy:  0.7029197080291971\n",
      "LR F1:  0.6530849355520242\n",
      "For name:  j_gao\n",
      "total sample size before apply threshold:  222\n",
      "Counter({'0000-0003-3215-7013': 44, '0000-0001-9341-1287': 36, '0000-0001-9778-4312': 26, '0000-0002-6200-4141': 24, '0000-0001-9803-0256': 20, '0000-0001-5732-9905': 14, '0000-0002-4545-1126': 12, '0000-0002-9943-4786': 12, '0000-0002-5739-1781': 11, '0000-0002-3952-208X': 8, '0000-0003-2059-0290': 7, '0000-0002-9959-5600': 2, '0000-0001-6659-5770': 1, '0000-0002-1181-4531': 1, '0000-0003-1160-6553': 1, '0000-0003-2668-6672': 1, '0000-0003-4024-4694': 1, '0000-0002-5977-0021': 1})\n",
      "['0000-0002-6200-4141', '0000-0001-5732-9905', '0000-0001-9341-1287', '0000-0003-3215-7013', '0000-0001-9778-4312', '0000-0002-5739-1781', '0000-0002-4545-1126', '0000-0002-9943-4786', '0000-0001-9803-0256']\n",
      "Total sample size after apply threshold:  199\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(199, 272)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "199\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        24\n",
      "          1       1.00      0.29      0.44        14\n",
      "          2       0.82      0.89      0.85        36\n",
      "          3       0.39      1.00      0.56        44\n",
      "          4       0.85      0.65      0.74        26\n",
      "          5       1.00      0.18      0.31        11\n",
      "          6       0.00      0.00      0.00        12\n",
      "          7       1.00      0.17      0.29        12\n",
      "          8       1.00      0.30      0.46        20\n",
      "\n",
      "avg / total       0.75      0.60      0.57       199\n",
      "\n",
      "[12  0  1 11  0  0  0  0  0  0  4  0 10  0  0  0  0  0  0  0 32  4  0  0\n",
      "  0  0  0  0  0  0 44  0  0  0  0  0  0  0  0  9 17  0  0  0  0  0  0  2\n",
      "  7  0  2  0  0  0  0  0  0 10  2  0  0  0  0  0  0  2  7  1  0  0  2  0\n",
      "  0  0  2 12  0  0  0  0  6]\n",
      "MNB Accuracy:  0.5979899497487438\n",
      "MNB F1:  0.4794979954987293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        24\n",
      "          1       0.91      0.71      0.80        14\n",
      "          2       0.85      0.92      0.88        36\n",
      "          3       0.77      0.93      0.85        44\n",
      "          4       0.85      0.88      0.87        26\n",
      "          5       1.00      0.64      0.78        11\n",
      "          6       0.90      0.75      0.82        12\n",
      "          7       1.00      0.92      0.96        12\n",
      "          8       0.82      0.70      0.76        20\n",
      "\n",
      "avg / total       0.87      0.86      0.86       199\n",
      "\n",
      "[23  0  0  1  0  0  0  0  0  0 10  2  2  0  0  0  0  0  0  1 33  1  0  0\n",
      "  1  0  0  0  0  0 41  2  0  0  0  1  0  0  0  2 23  0  0  0  1  0  0  2\n",
      "  2  0  7  0  0  0  0  0  1  0  2  0  9  0  0  0  0  0  0  0  0  0 11  1\n",
      "  1  0  1  4  0  0  0  0 14]\n",
      "svc Accuracy:  0.8592964824120602\n",
      "svc F1:  0.8512063086915862\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        24\n",
      "          1       0.78      0.50      0.61        14\n",
      "          2       0.70      0.92      0.80        36\n",
      "          3       0.63      0.95      0.76        44\n",
      "          4       0.79      0.88      0.84        26\n",
      "          5       1.00      0.27      0.43        11\n",
      "          6       0.75      0.25      0.38        12\n",
      "          7       1.00      0.75      0.86        12\n",
      "          8       0.90      0.45      0.60        20\n",
      "\n",
      "avg / total       0.80      0.75      0.73       199\n",
      "\n",
      "[21  1  1  1  0  0  0  0  0  0  7  3  3  1  0  0  0  0  0  1 33  1  0  0\n",
      "  1  0  0  0  0  0 42  2  0  0  0  0  0  0  0  2 23  0  0  0  1  0  0  4\n",
      "  4  0  3  0  0  0  0  0  3  4  2  0  3  0  0  0  0  0  2  1  0  0  9  0\n",
      "  0  0  3  8  0  0  0  0  9]\n",
      "LR Accuracy:  0.7537688442211056\n",
      "LR F1:  0.6878938208037213\n",
      "For name:  d_fernandes\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0003-0599-3200': 20, '0000-0002-5056-5734': 9, '0000-0001-5263-2737': 5, '0000-0001-6155-6246': 4, '0000-0002-2208-6349': 1, '0000-0003-3466-9450': 1})\n",
      "['0000-0003-0599-3200']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  c_silva\n",
      "total sample size before apply threshold:  148\n",
      "Counter({'0000-0003-4521-6377': 23, '0000-0001-6348-0505': 16, '0000-0001-6252-8693': 13, '0000-0002-7870-8848': 9, '0000-0002-9310-2457': 9, '0000-0002-1015-5095': 8, '0000-0002-0495-3955': 8, '0000-0002-2357-3405': 7, '0000-0003-1413-8038': 7, '0000-0002-1399-6674': 4, '0000-0002-1439-9214': 3, '0000-0002-9413-4573': 3, '0000-0003-0104-8412': 3, '0000-0003-4331-3755': 3, '0000-0002-5831-2993': 3, '0000-0001-7590-9639': 2, '0000-0002-1196-306X': 2, '0000-0002-1549-6833': 2, '0000-0002-7103-9100': 2, '0000-0002-7092-1169': 2, '0000-0001-6827-8939': 2, '0000-0002-7238-546X': 2, '0000-0002-1771-1517': 2, '0000-0003-1731-7883': 2, '0000-0003-4327-5744': 1, '0000-0002-5656-0061': 1, '0000-0001-6475-6622': 1, '0000-0003-2701-179X': 1, '0000-0001-8172-5860': 1, '0000-0001-9777-8406': 1, '0000-0002-4327-6272': 1, '0000-0002-5077-5176': 1, '0000-0002-7477-1495': 1, '0000-0003-2506-1435': 1, '0000-0002-9148-5458': 1})\n",
      "['0000-0001-6348-0505', '0000-0003-4521-6377', '0000-0001-6252-8693']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 197)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.88      1.00      0.94        23\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.95      0.94      0.94        52\n",
      "\n",
      "[14  2  0  0 23  0  0  1 12]\n",
      "MNB Accuracy:  0.9423076923076923\n",
      "MNB F1:  0.9440362811791383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        16\n",
      "          1       0.79      1.00      0.88        23\n",
      "          2       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.91      0.88      0.88        52\n",
      "\n",
      "[12  4  0  0 23  0  0  2 11]\n",
      "svc Accuracy:  0.8846153846153846\n",
      "svc F1:  0.8861416361416361\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        16\n",
      "          1       0.72      1.00      0.84        23\n",
      "          2       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.88      0.83      0.82        52\n",
      "\n",
      "[10  6  0  0 23  0  0  3 10]\n",
      "LR Accuracy:  0.8269230769230769\n",
      "LR F1:  0.8250532076619033\n",
      "For name:  t_fitzgerald\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-3855-1591': 31, '0000-0002-2370-8496': 21, '0000-0001-9898-1166': 1, '0000-0002-1532-517X': 1})\n",
      "['0000-0002-3855-1591', '0000-0002-2370-8496']\n",
      "Total sample size after apply threshold:  52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 300)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.89        31\n",
      "          1       1.00      0.62      0.76        21\n",
      "\n",
      "avg / total       0.88      0.85      0.84        52\n",
      "\n",
      "[31  0  8 13]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.8252100840336135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.94      0.95        31\n",
      "          1       0.91      0.95      0.93        21\n",
      "\n",
      "avg / total       0.94      0.94      0.94        52\n",
      "\n",
      "[29  2  1 20]\n",
      "svc Accuracy:  0.9423076923076923\n",
      "svc F1:  0.9405261151353412\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.95        31\n",
      "          1       0.95      0.90      0.93        21\n",
      "\n",
      "avg / total       0.94      0.94      0.94        52\n",
      "\n",
      "[30  1  2 19]\n",
      "LR Accuracy:  0.9423076923076923\n",
      "LR F1:  0.9396051103368176\n",
      "For name:  j_mitchell\n",
      "total sample size before apply threshold:  143\n",
      "Counter({'0000-0002-0379-6097': 57, '0000-0002-8445-0935': 32, '0000-0002-7147-4604': 16, '0000-0002-2361-9805': 14, '0000-0003-4956-1530': 11, '0000-0002-2520-8428': 6, '0000-0001-6785-9352': 3, '0000-0002-0710-5580': 3, '0000-0002-8624-5070': 1})\n",
      "['0000-0002-0379-6097', '0000-0002-8445-0935', '0000-0002-7147-4604', '0000-0003-4956-1530', '0000-0002-2361-9805']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 130\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 274)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "130\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.98      0.74        57\n",
      "          1       0.96      0.72      0.82        32\n",
      "          2       1.00      0.50      0.67        16\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.21      0.35        14\n",
      "\n",
      "avg / total       0.73      0.69      0.65       130\n",
      "\n",
      "[56  1  0  0  0  9 23  0  0  0  8  0  8  0  0 11  0  0  0  0 11  0  0  0\n",
      "  3]\n",
      "MNB Accuracy:  0.6923076923076923\n",
      "MNB F1:  0.5155757039657968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.98      0.81        57\n",
      "          1       0.96      0.81      0.88        32\n",
      "          2       1.00      0.75      0.86        16\n",
      "          3       1.00      0.27      0.43        11\n",
      "          4       1.00      0.43      0.60        14\n",
      "\n",
      "avg / total       0.85      0.79      0.78       130\n",
      "\n",
      "[56  1  0  0  0  6 26  0  0  0  4  0 12  0  0  8  0  0  3  0  8  0  0  0\n",
      "  6]\n",
      "svc Accuracy:  0.7923076923076923\n",
      "svc F1:  0.7145651227202257\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.98      0.70        57\n",
      "          1       0.94      0.53      0.68        32\n",
      "          2       1.00      0.38      0.55        16\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.14      0.25        14\n",
      "\n",
      "avg / total       0.70      0.62      0.57       130\n",
      "\n",
      "[56  1  0  0  0 15 17  0  0  0 10  0  6  0  0 11  0  0  0  0 12  0  0  0\n",
      "  2]\n",
      "LR Accuracy:  0.6230769230769231\n",
      "LR F1:  0.4342213438735178\n",
      "For name:  a_gomes\n",
      "total sample size before apply threshold:  244\n",
      "Counter({'0000-0002-9819-3036': 44, '0000-0002-0567-064X': 42, '0000-0002-5940-9893': 32, '0000-0001-7883-2446': 20, '0000-0002-8221-6985': 19, '0000-0003-1052-8004': 18, '0000-0002-3348-0448': 16, '0000-0001-9598-1275': 13, '0000-0002-4989-6026': 7, '0000-0003-3976-238X': 6, '0000-0002-6390-9866': 6, '0000-0001-9565-8814': 5, '0000-0003-1998-0291': 5, '0000-0002-1707-9208': 3, '0000-0001-8702-4360': 2, '0000-0002-9793-4816': 1, '0000-0003-0010-2608': 1, '0000-0002-3498-7734': 1, '0000-0001-5466-0272': 1, '0000-0002-3332-834X': 1, '0000-0002-3201-0081': 1})\n",
      "['0000-0002-9819-3036', '0000-0002-5940-9893', '0000-0003-1052-8004', '0000-0002-8221-6985', '0000-0001-9598-1275', '0000-0001-7883-2446', '0000-0002-3348-0448', '0000-0002-0567-064X']\n",
      "Total sample size after apply threshold:  204\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(204, 3913)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.95        44\n",
      "          1       1.00      1.00      1.00        32\n",
      "          2       1.00      0.11      0.20        18\n",
      "          3       0.95      0.95      0.95        19\n",
      "          4       1.00      0.54      0.70        13\n",
      "          5       1.00      0.95      0.97        20\n",
      "          6       0.00      0.00      0.00        16\n",
      "          7       0.51      0.95      0.67        42\n",
      "\n",
      "avg / total       0.80      0.79      0.74       204\n",
      "\n",
      "[43  0  0  0  0  0  0  1  0 32  0  0  0  0  0  0  0  0  2  0  0  0  0 16\n",
      "  0  0  0 18  0  0  0  1  0  0  0  0  7  0  0  6  0  0  0  0  0 19  0  1\n",
      "  3  0  0  0  0  0  0 13  1  0  0  1  0  0  0 40]\n",
      "MNB Accuracy:  0.7892156862745098\n",
      "MNB F1:  0.6791811258916522\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.85        44\n",
      "          1       1.00      1.00      1.00        32\n",
      "          2       0.83      0.56      0.67        18\n",
      "          3       1.00      0.89      0.94        19\n",
      "          4       1.00      1.00      1.00        13\n",
      "          5       1.00      0.95      0.97        20\n",
      "          6       1.00      0.62      0.77        16\n",
      "          7       0.93      0.90      0.92        42\n",
      "\n",
      "avg / total       0.91      0.90      0.89       204\n",
      "\n",
      "[44  0  0  0  0  0  0  0  0 32  0  0  0  0  0  0  6  0 10  0  0  0  0  2\n",
      "  1  0  1 17  0  0  0  0  0  0  0  0 13  0  0  0  1  0  0  0  0 19  0  0\n",
      "  5  0  0  0  0  0 10  1  3  0  1  0  0  0  0 38]\n",
      "svc Accuracy:  0.8970588235294118\n",
      "svc F1:  0.8895646689321388\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      1.00      0.75        44\n",
      "          1       1.00      1.00      1.00        32\n",
      "          2       0.89      0.44      0.59        18\n",
      "          3       1.00      0.89      0.94        19\n",
      "          4       1.00      0.92      0.96        13\n",
      "          5       1.00      0.95      0.97        20\n",
      "          6       1.00      0.12      0.22        16\n",
      "          7       0.85      0.81      0.83        42\n",
      "\n",
      "avg / total       0.87      0.82      0.80       204\n",
      "\n",
      "[44  0  0  0  0  0  0  0  0 32  0  0  0  0  0  0  7  0  8  0  0  0  0  3\n",
      "  2  0  0 17  0  0  0  0  0  0  0  0 12  0  0  1  1  0  0  0  0 19  0  0\n",
      " 11  0  1  0  0  0  2  2  8  0  0  0  0  0  0 34]\n",
      "LR Accuracy:  0.8235294117647058\n",
      "LR F1:  0.7843779098047391\n",
      "For name:  t_weber\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0002-0494-0484': 29, '0000-0001-8994-1285': 13, '0000-0002-8260-5120': 12, '0000-0003-2931-8963': 10, '0000-0001-8320-361X': 7})\n",
      "['0000-0002-0494-0484', '0000-0001-8994-1285', '0000-0003-2931-8963', '0000-0002-8260-5120']\n",
      "Total sample size after apply threshold:  64\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(64, 421)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      1.00      0.76        29\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       1.00      0.70      0.82        10\n",
      "          3       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.83      0.72      0.70        64\n",
      "\n",
      "[29  0  0  0  7  6  0  0  3  0  7  0  8  0  0  4]\n",
      "MNB Accuracy:  0.71875\n",
      "MNB F1:  0.6795665634674922\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84        29\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       1.00      0.70      0.82        10\n",
      "          3       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.88      0.83      0.83        64\n",
      "\n",
      "[29  0  0  0  5  8  0  0  3  0  7  0  3  0  0  9]\n",
      "svc Accuracy:  0.828125\n",
      "svc F1:  0.8207891852393131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      1.00      0.72        29\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       1.00      0.50      0.67        10\n",
      "          3       1.00      0.17      0.29        12\n",
      "\n",
      "avg / total       0.80      0.66      0.61        64\n",
      "\n",
      "[29  0  0  0  7  6  0  0  5  0  5  0 10  0  0  2]\n",
      "LR Accuracy:  0.65625\n",
      "LR F1:  0.5772399749373432\n",
      "For name:  j_shim\n",
      "total sample size before apply threshold:  188\n",
      "Counter({'0000-0002-5361-2903': 91, '0000-0003-0167-7307': 36, '0000-0003-1881-8436': 30, '0000-0003-4088-2557': 12, '0000-0002-3974-1290': 6, '0000-0003-4577-1952': 6, '0000-0001-5485-160X': 3, '0000-0003-0101-3076': 2, '0000-0001-9367-2233': 1, '0000-0002-1909-5412': 1})\n",
      "['0000-0003-4088-2557', '0000-0002-5361-2903', '0000-0003-0167-7307', '0000-0003-1881-8436']\n",
      "Total sample size after apply threshold:  169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 220)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "169\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.79      1.00      0.88        91\n",
      "          2       0.96      0.61      0.75        36\n",
      "          3       0.90      0.90      0.90        30\n",
      "\n",
      "avg / total       0.86      0.83      0.81       169\n",
      "\n",
      "[ 1  9  0  2  0 91  0  0  0 13 22  1  0  2  1 27]\n",
      "MNB Accuracy:  0.834319526627219\n",
      "MNB F1:  0.6707760028354072\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.75      0.82        12\n",
      "          1       0.96      0.98      0.97        91\n",
      "          2       0.87      0.94      0.91        36\n",
      "          3       1.00      0.90      0.95        30\n",
      "\n",
      "avg / total       0.94      0.94      0.94       169\n",
      "\n",
      "[ 9  0  3  0  1 89  1  0  0  2 34  0  0  2  1 27]\n",
      "svc Accuracy:  0.9408284023668639\n",
      "svc F1:  0.9099020525622357\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.90      0.99      0.94        91\n",
      "          2       0.91      0.89      0.90        36\n",
      "          3       0.96      0.87      0.91        30\n",
      "\n",
      "avg / total       0.92      0.92      0.91       169\n",
      "\n",
      "[ 7  4  1  0  0 90  0  1  0  4 32  0  0  2  2 26]\n",
      "LR Accuracy:  0.9171597633136095\n",
      "LR F1:  0.8732349086712801\n",
      "For name:  k_kang\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0003-2622-9017': 53, '0000-0003-0446-469X': 22, '0000-0002-0457-842X': 12, '0000-0002-8790-9350': 11, '0000-0002-4465-0617': 9, '0000-0001-6374-8356': 8, '0000-0003-3290-1017': 3, '0000-0002-6529-4543': 3, '0000-0002-8428-8288': 3, '0000-0003-1230-3626': 2, '0000-0003-0611-9320': 1, '0000-0001-9135-1890': 1})\n",
      "['0000-0002-0457-842X', '0000-0002-8790-9350', '0000-0003-2622-9017', '0000-0003-0446-469X']\n",
      "Total sample size after apply threshold:  98\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 178)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       1.00      0.36      0.53        11\n",
      "          2       0.60      1.00      0.75        53\n",
      "          3       0.75      0.14      0.23        22\n",
      "\n",
      "avg / total       0.73      0.62      0.53        98\n",
      "\n",
      "[ 1  0 10  1  0  4  7  0  0  0 53  0  0  0 19  3]\n",
      "MNB Accuracy:  0.6224489795918368\n",
      "MNB F1:  0.4161068977970387\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       0.85      0.98      0.91        53\n",
      "          3       0.71      0.68      0.70        22\n",
      "\n",
      "avg / total       0.86      0.85      0.84        98\n",
      "\n",
      "[ 8  0  2  2  0  8  0  3  0  0 52  1  0  0  7 15]\n",
      "svc Accuracy:  0.8469387755102041\n",
      "svc F1:  0.813015095879233\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       0.68      0.98      0.80        53\n",
      "          3       0.86      0.27      0.41        22\n",
      "\n",
      "avg / total       0.79      0.73      0.70        98\n",
      "\n",
      "[ 6  0  6  0  0  8  3  0  0  0 52  1  0  0 16  6]\n",
      "LR Accuracy:  0.7346938775510204\n",
      "LR F1:  0.6806412583182093\n",
      "For name:  i_ferreira\n",
      "total sample size before apply threshold:  344\n",
      "Counter({'0000-0003-4910-4882': 166, '0000-0003-1434-0607': 90, '0000-0001-8424-1431': 44, '0000-0001-6552-4479': 19, '0000-0002-8838-0364': 13, '0000-0002-4934-917X': 7, '0000-0002-3164-8227': 3, '0000-0002-5368-9505': 2})\n",
      "['0000-0003-1434-0607', '0000-0001-6552-4479', '0000-0003-4910-4882', '0000-0002-8838-0364', '0000-0001-8424-1431']\n",
      "Total sample size after apply threshold:  332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(332, 492)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        90\n",
      "          1       0.00      0.00      0.00        19\n",
      "          2       0.76      1.00      0.86       166\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       1.00      0.57      0.72        44\n",
      "\n",
      "avg / total       0.78      0.84      0.80       332\n",
      "\n",
      "[ 88   0   2   0   0   0   0  19   0   0   0   0 166   0   0   0   0  13\n",
      "   0   0   0   0  19   0  25]\n",
      "MNB Accuracy:  0.8403614457831325\n",
      "MNB F1:  0.5151478776881806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        90\n",
      "          1       1.00      0.95      0.97        19\n",
      "          2       0.93      0.99      0.96       166\n",
      "          3       1.00      0.85      0.92        13\n",
      "          4       0.97      0.82      0.89        44\n",
      "\n",
      "avg / total       0.96      0.96      0.96       332\n",
      "\n",
      "[ 88   0   2   0   0   0  18   1   0   0   0   0 165   0   1   0   0   2\n",
      "  11   0   0   0   8   0  36]\n",
      "svc Accuracy:  0.9578313253012049\n",
      "svc F1:  0.9453189798107487\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        90\n",
      "          1       1.00      0.37      0.54        19\n",
      "          2       0.78      1.00      0.88       166\n",
      "          3       1.00      0.08      0.14        13\n",
      "          4       1.00      0.59      0.74        44\n",
      "\n",
      "avg / total       0.89      0.86      0.84       332\n",
      "\n",
      "[ 85   0   5   0   0   0   7  12   0   0   0   0 166   0   0   0   0  12\n",
      "   1   0   0   0  18   0  26]\n",
      "LR Accuracy:  0.858433734939759\n",
      "LR F1:  0.6543187683029371\n",
      "For name:  y_jia\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0002-2784-1905': 24, '0000-0003-3852-7302': 10, '0000-0002-8852-7557': 3, '0000-0001-9657-0806': 3, '0000-0001-7978-9312': 3, '0000-0001-9395-2139': 2, '0000-0003-4972-1004': 1})\n",
      "['0000-0003-3852-7302', '0000-0002-2784-1905']\n",
      "Total sample size after apply threshold:  34\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 73)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      1.00      1.00        24\n",
      "\n",
      "avg / total       1.00      1.00      1.00        34\n",
      "\n",
      "[10  0  0 24]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      1.00      1.00        24\n",
      "\n",
      "avg / total       1.00      1.00      1.00        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  0  0 24]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       0.89      1.00      0.94        24\n",
      "\n",
      "avg / total       0.92      0.91      0.91        34\n",
      "\n",
      "[ 7  3  0 24]\n",
      "LR Accuracy:  0.9117647058823529\n",
      "LR F1:  0.8823529411764706\n",
      "For name:  p_gaspar\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0003-4217-5717': 87, '0000-0001-5967-0584': 3, '0000-0002-4832-8537': 2, '0000-0003-3388-1724': 1})\n",
      "['0000-0003-4217-5717']\n",
      "Total sample size after apply threshold:  87\n",
      "For name:  r_o'connor\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0003-4426-2507': 36, '0000-0002-4643-9794': 27, '0000-0002-6869-7954': 13, '0000-0002-3916-3101': 6})\n",
      "['0000-0002-6869-7954', '0000-0003-4426-2507', '0000-0002-4643-9794']\n",
      "Total sample size after apply threshold:  76\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(76, 215)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "76\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        13\n",
      "          1       0.86      1.00      0.92        36\n",
      "          2       0.88      0.78      0.82        27\n",
      "\n",
      "avg / total       0.89      0.88      0.88        76\n",
      "\n",
      "[10  0  3  0 36  0  0  6 21]\n",
      "MNB Accuracy:  0.881578947368421\n",
      "MNB F1:  0.8720571840776445\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.92      0.94      0.93        36\n",
      "          2       0.86      0.89      0.87        27\n",
      "\n",
      "avg / total       0.91      0.91      0.91        76\n",
      "\n",
      "[11  0  2  0 34  2  0  3 24]\n",
      "svc Accuracy:  0.9078947368421053\n",
      "svc F1:  0.9069669295696693\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.69      1.00      0.82        36\n",
      "          2       1.00      0.59      0.74        27\n",
      "\n",
      "avg / total       0.85      0.79      0.78        76\n",
      "\n",
      "[ 8  5  0  0 36  0  0 11 16]\n",
      "LR Accuracy:  0.7894736842105263\n",
      "LR F1:  0.7747575421994027\n",
      "For name:  k_larsen\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0003-2172-7519': 35, '0000-0002-3918-6645': 6, '0000-0002-1421-6182': 4, '0000-0002-6473-7285': 1, '0000-0003-1182-7727': 1})\n",
      "['0000-0003-2172-7519']\n",
      "Total sample size after apply threshold:  35\n",
      "For name:  s_das\n",
      "total sample size before apply threshold:  197\n",
      "Counter({'0000-0002-1659-2499': 50, '0000-0002-2424-2851': 21, '0000-0002-8394-5303': 17, '0000-0002-5353-0422': 15, '0000-0002-0539-5174': 14, '0000-0003-1185-9366': 13, '0000-0002-2384-3903': 9, '0000-0001-6256-5646': 9, '0000-0002-7066-2128': 6, '0000-0002-8097-6542': 6, '0000-0002-4217-9972': 5, '0000-0001-6470-7302': 4, '0000-0002-5974-7649': 4, '0000-0001-9380-2907': 3, '0000-0002-8628-5128': 2, '0000-0003-0467-0872': 2, '0000-0002-4852-1396': 2, '0000-0003-0745-469X': 2, '0000-0002-9302-7645': 2, '0000-0002-3428-1862': 1, '0000-0001-5339-7708': 1, '0000-0002-0994-8960': 1, '0000-0003-2889-8644': 1, '0000-0003-2161-4784': 1, '0000-0002-0285-8970': 1, '0000-0002-4464-3417': 1, '0000-0002-7336-9568': 1, '0000-0002-3010-6469': 1, '0000-0001-7329-8264': 1, '0000-0002-9896-3520': 1})\n",
      "['0000-0002-0539-5174', '0000-0002-5353-0422', '0000-0002-2424-2851', '0000-0003-1185-9366', '0000-0002-8394-5303', '0000-0002-1659-2499']\n",
      "Total sample size after apply threshold:  130\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 271)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "130\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        14\n",
      "          1       1.00      0.60      0.75        15\n",
      "          2       1.00      0.90      0.95        21\n",
      "          3       1.00      0.77      0.87        13\n",
      "          4       1.00      0.65      0.79        17\n",
      "          5       0.68      1.00      0.81        50\n",
      "\n",
      "avg / total       0.88      0.82      0.81       130\n",
      "\n",
      "[ 7  0  0  0  0  7  0  9  0  0  0  6  0  0 19  0  0  2  0  0  0 10  0  3\n",
      "  0  0  0  0 11  6  0  0  0  0  0 50]\n",
      "MNB Accuracy:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8153846153846154\n",
      "MNB F1:  0.8047329637792471\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       1.00      0.93      0.97        15\n",
      "          2       1.00      0.86      0.92        21\n",
      "          3       1.00      1.00      1.00        13\n",
      "          4       1.00      0.71      0.83        17\n",
      "          5       0.82      1.00      0.90        50\n",
      "\n",
      "avg / total       0.93      0.92      0.91       130\n",
      "\n",
      "[12  0  0  0  0  2  0 14  0  0  0  1  0  0 18  0  0  3  0  0  0 13  0  0\n",
      "  0  0  0  0 12  5  0  0  0  0  0 50]\n",
      "svc Accuracy:  0.9153846153846154\n",
      "svc F1:  0.9233596992217681\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        14\n",
      "          1       1.00      0.67      0.80        15\n",
      "          2       1.00      0.86      0.92        21\n",
      "          3       1.00      0.62      0.76        13\n",
      "          4       1.00      0.65      0.79        17\n",
      "          5       0.64      1.00      0.78        50\n",
      "\n",
      "avg / total       0.86      0.78      0.78       130\n",
      "\n",
      "[ 5  0  0  0  0  9  0 10  0  0  0  5  0  0 18  0  0  3  0  0  0  8  0  5\n",
      "  0  0  0  0 11  6  0  0  0  0  0 50]\n",
      "LR Accuracy:  0.7846153846153846\n",
      "LR F1:  0.7630436266949424\n",
      "For name:  f_rodriguez\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0003-4044-8734': 3, '0000-0003-1213-0999': 2, '0000-0003-4053-099X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  w_peng\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0001-5093-7115': 14, '0000-0002-4506-0942': 13, '0000-0001-9747-2466': 8, '0000-0003-4917-6851': 3})\n",
      "['0000-0002-4506-0942', '0000-0001-5093-7115']\n",
      "Total sample size after apply threshold:  27\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 101)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.97      0.96      0.96        27\n",
      "\n",
      "[13  0  1 13]\n",
      "MNB Accuracy:  0.9629629629629629\n",
      "MNB F1:  0.962962962962963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        27\n",
      "\n",
      "[13  0  0 14]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        27\n",
      "\n",
      "[13  0  0 14]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  c_torres\n",
      "total sample size before apply threshold:  300\n",
      "Counter({'0000-0003-3709-1690': 237, '0000-0001-8573-0990': 20, '0000-0001-6303-4417': 16, '0000-0001-6786-8769': 15, '0000-0003-3991-0573': 9, '0000-0001-6322-5862': 2, '0000-0002-7908-6884': 1})\n",
      "['0000-0001-8573-0990', '0000-0001-6786-8769', '0000-0003-3709-1690', '0000-0001-6303-4417']\n",
      "Total sample size after apply threshold:  288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(288, 528)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "288\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        20\n",
      "          1       1.00      0.20      0.33        15\n",
      "          2       0.89      1.00      0.94       237\n",
      "          3       1.00      0.19      0.32        16\n",
      "\n",
      "avg / total       0.91      0.90      0.87       288\n",
      "\n",
      "[ 16   0   4   0   0   3  12   0   0   0 237   0   0   0  13   3]\n",
      "MNB Accuracy:  0.8993055555555556\n",
      "MNB F1:  0.6200894050899284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        20\n",
      "          1       1.00      0.53      0.70        15\n",
      "          2       0.94      1.00      0.97       237\n",
      "          3       1.00      0.75      0.86        16\n",
      "\n",
      "avg / total       0.95      0.95      0.94       288\n",
      "\n",
      "[ 16   0   4   0   0   8   7   0   0   0 237   0   0   0   4  12]\n",
      "svc Accuracy:  0.9479166666666666\n",
      "svc F1:  0.8527522683297557\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        20\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.85      1.00      0.92       237\n",
      "          3       1.00      0.12      0.22        16\n",
      "\n",
      "avg / total       0.82      0.85      0.80       288\n",
      "\n",
      "[  7   0  13   0   0   0  15   0   0   0 237   0   0   0  14   2]\n",
      "LR Accuracy:  0.8541666666666666\n",
      "LR F1:  0.41483634797588287\n",
      "For name:  s_rossi\n",
      "total sample size before apply threshold:  199\n",
      "Counter({'0000-0003-3257-8248': 86, '0000-0002-9963-8121': 34, '0000-0002-9919-0494': 25, '0000-0002-8854-7072': 14, '0000-0003-0346-8410': 13, '0000-0002-3278-8993': 10, '0000-0002-2694-9535': 8, '0000-0001-5134-8398': 5, '0000-0001-7048-7158': 1, '0000-0001-8853-0775': 1, '0000-0001-9511-3857': 1, '0000-0001-7479-5756': 1})\n",
      "['0000-0002-8854-7072', '0000-0002-9919-0494', '0000-0003-0346-8410', '0000-0002-9963-8121', '0000-0002-3278-8993', '0000-0003-3257-8248']\n",
      "Total sample size after apply threshold:  182\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(182, 538)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "182\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        14\n",
      "          1       1.00      0.76      0.86        25\n",
      "          2       1.00      0.77      0.87        13\n",
      "          3       1.00      0.85      0.92        34\n",
      "          4       1.00      0.20      0.33        10\n",
      "          5       0.75      1.00      0.86        86\n",
      "\n",
      "avg / total       0.88      0.85      0.83       182\n",
      "\n",
      "[ 8  0  0  0  0  6  0 19  0  0  0  6  0  0 10  0  0  3  0  0  0 29  0  5\n",
      "  0  0  0  0  2  8  0  0  0  0  0 86]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.7624070937114417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       1.00      0.88      0.94        25\n",
      "          2       1.00      0.92      0.96        13\n",
      "          3       0.94      0.91      0.93        34\n",
      "          4       1.00      0.80      0.89        10\n",
      "          5       0.91      1.00      0.95        86\n",
      "\n",
      "avg / total       0.94      0.94      0.94       182\n",
      "\n",
      "[12  0  0  1  0  1  0 22  0  1  0  2  0  0 12  0  0  1  0  0  0 31  0  3\n",
      "  0  0  0  0  8  2  0  0  0  0  0 86]\n",
      "svc Accuracy:  0.9395604395604396\n",
      "svc F1:  0.9306309003590084\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        14\n",
      "          1       1.00      0.84      0.91        25\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       1.00      0.79      0.89        34\n",
      "          4       1.00      0.40      0.57        10\n",
      "          5       0.74      1.00      0.85        86\n",
      "\n",
      "avg / total       0.88      0.84      0.83       182\n",
      "\n",
      "[ 6  0  0  0  0  8  0 21  0  0  0  4  0  0  8  0  0  5  0  0  0 27  0  7\n",
      "  0  0  0  0  4  6  0  0  0  0  0 86]\n",
      "LR Accuracy:  0.8351648351648352\n",
      "LR F1:  0.7638513102913999\n",
      "For name:  s_alavi\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0003-4328-4747': 23, '0000-0003-4009-4921': 14, '0000-0003-1130-3165': 1})\n",
      "['0000-0003-4328-4747', '0000-0003-4009-4921']\n",
      "Total sample size after apply threshold:  37\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 80)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        23\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        37\n",
      "\n",
      "[23  0  0 14]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        23\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        37\n",
      "\n",
      "[23  0  0 14]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        23\n",
      "          1       1.00      0.71      0.83        14\n",
      "\n",
      "avg / total       0.91      0.89      0.89        37\n",
      "\n",
      "[23  0  4 10]\n",
      "LR Accuracy:  0.8918918918918919\n",
      "LR F1:  0.8766666666666667\n",
      "For name:  r_marques\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-6949-0947': 11, '0000-0002-4749-7523': 11, '0000-0002-3125-3911': 8, '0000-0001-6239-5456': 3, '0000-0002-9416-1299': 2, '0000-0001-8261-4409': 1, '0000-0001-6925-041X': 1, '0000-0002-9197-9845': 1, '0000-0002-0672-9260': 1, '0000-0001-8622-9786': 1, '0000-0003-0314-3675': 1})\n",
      "['0000-0002-6949-0947', '0000-0002-4749-7523']\n",
      "Total sample size after apply threshold:  22"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 89)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "22\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.85      1.00      0.92        11\n",
      "\n",
      "avg / total       0.92      0.91      0.91        22\n",
      "\n",
      "[ 9  2  0 11]\n",
      "MNB Accuracy:  0.9090909090909091\n",
      "MNB F1:  0.9083333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        11\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "[11  0  1 10]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.9544513457556936\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        11\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "[11  0  1 10]\n",
      "LR Accuracy:  0.9545454545454546\n",
      "LR F1:  0.9544513457556936\n",
      "For name:  m_wheeler\n",
      "total sample size before apply threshold:  163\n",
      "Counter({'0000-0002-7480-7267': 112, '0000-0001-5589-357X': 47, '0000-0002-0319-1987': 3, '0000-0002-7404-7069': 1})\n",
      "['0000-0002-7480-7267', '0000-0001-5589-357X']\n",
      "Total sample size after apply threshold:  159\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 507)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "159\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       112\n",
      "          1       1.00      0.68      0.81        47\n",
      "\n",
      "avg / total       0.92      0.91      0.90       159\n",
      "\n",
      "[112   0  15  32]\n",
      "MNB Accuracy:  0.9056603773584906\n",
      "MNB F1:  0.8736825380011652\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       112\n",
      "          1       1.00      0.72      0.84        47\n",
      "\n",
      "avg / total       0.93      0.92      0.91       159\n",
      "\n",
      "[112   0  13  34]\n",
      "svc Accuracy:  0.9182389937106918\n",
      "svc F1:  0.8923269260822004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89       112\n",
      "          1       1.00      0.43      0.60        47\n",
      "\n",
      "avg / total       0.86      0.83      0.81       159\n",
      "\n",
      "[112   0  27  20]\n",
      "LR Accuracy:  0.8301886792452831\n",
      "LR F1:  0.7447226021287983\n",
      "For name:  l_rasmussen\n",
      "total sample size before apply threshold:  249\n",
      "Counter({'0000-0002-7480-3004': 214, '0000-0002-4497-8049': 24, '0000-0001-6613-2469': 5, '0000-0001-5962-6647': 4, '0000-0001-5795-4794': 1, '0000-0002-7301-3182': 1})\n",
      "['0000-0002-4497-8049', '0000-0002-7480-3004']\n",
      "Total sample size after apply threshold:  238\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(238, 523)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        24\n",
      "          1       0.98      1.00      0.99       214\n",
      "\n",
      "avg / total       0.98      0.98      0.98       238\n",
      "\n",
      "[ 19   5   0 214]\n",
      "MNB Accuracy:  0.9789915966386554\n",
      "MNB F1:  0.9360867930608519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        24\n",
      "          1       0.97      1.00      0.98       214\n",
      "\n",
      "avg / total       0.97      0.97      0.97       238\n",
      "\n",
      "[ 17   7   0 214]\n",
      "svc Accuracy:  0.9705882352941176\n",
      "svc F1:  0.9065881693299691\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        24\n",
      "          1       0.92      1.00      0.96       214\n",
      "\n",
      "avg / total       0.93      0.92      0.90       238\n",
      "\n",
      "[  6  18   0 214]\n",
      "LR Accuracy:  0.9243697478991597\n",
      "LR F1:  0.6798206278026906\n",
      "For name:  m_saad\n",
      "total sample size before apply threshold:  4\n",
      "Counter({'0000-0003-0458-5942': 1, '0000-0002-8071-2328': 1, '0000-0002-5655-8674': 1, '0000-0003-1291-366X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_carr\n",
      "total sample size before apply threshold:  271\n",
      "Counter({'0000-0002-4398-8237': 179, '0000-0002-6445-2992': 42, '0000-0002-5028-2160': 40, '0000-0002-2729-0920': 6, '0000-0002-9164-4156': 2, '0000-0002-2324-8944': 1, '0000-0002-1080-1472': 1})\n",
      "['0000-0002-6445-2992', '0000-0002-5028-2160', '0000-0002-4398-8237']\n",
      "Total sample size after apply threshold:  261\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(261, 791)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "261\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.50      0.66        42\n",
      "          1       1.00      0.40      0.57        40\n",
      "          2       0.80      0.99      0.89       179\n",
      "\n",
      "avg / total       0.85      0.82      0.80       261\n",
      "\n",
      "[ 21   0  21   0  16  24   1   0 178]\n",
      "MNB Accuracy:  0.8237547892720306\n",
      "MNB F1:  0.7044169035773513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        42\n",
      "          1       1.00      0.68      0.81        40\n",
      "          2       0.88      1.00      0.93       179\n",
      "\n",
      "avg / total       0.92      0.90      0.90       261\n",
      "\n",
      "[ 30   0  12   0  27  13   0   0 179]\n",
      "svc Accuracy:  0.9042145593869731\n",
      "svc F1:  0.8580097770503444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.35        42\n",
      "          1       1.00      0.25      0.40        40\n",
      "          2       0.74      1.00      0.85       179\n",
      "\n",
      "avg / total       0.82      0.76      0.70       261\n",
      "\n",
      "[  9   0  33   0  10  30   0   0 179]\n",
      "LR Accuracy:  0.7586206896551724\n",
      "LR F1:  0.5344324903358019\n",
      "For name:  j_fraser\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0002-5080-2859': 38, '0000-0002-6505-1883': 36, '0000-0002-5980-3989': 9, '0000-0003-0111-9137': 6, '0000-0002-8020-2985': 6, '0000-0001-9697-3795': 3, '0000-0003-4941-1997': 3})\n",
      "['0000-0002-6505-1883', '0000-0002-5080-2859']\n",
      "Total sample size after apply threshold:  74\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(74, 258)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "74\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91        36\n",
      "          1       0.97      0.84      0.90        38\n",
      "\n",
      "avg / total       0.91      0.91      0.91        74\n",
      "\n",
      "[35  1  6 32]\n",
      "MNB Accuracy:  0.9054054054054054\n",
      "MNB F1:  0.9052496798975672\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        36\n",
      "          1       0.93      1.00      0.96        38\n",
      "\n",
      "avg / total       0.96      0.96      0.96        74\n",
      "\n",
      "[33  3  0 38]\n",
      "svc Accuracy:  0.9594594594594594\n",
      "svc F1:  0.9592735277930655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        36\n",
      "          1       0.93      1.00      0.96        38\n",
      "\n",
      "avg / total       0.96      0.96      0.96        74\n",
      "\n",
      "[33  3  0 38]\n",
      "LR Accuracy:  0.9594594594594594\n",
      "LR F1:  0.9592735277930655\n",
      "For name:  s_woo\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-3692-7169': 22, '0000-0001-8788-2875': 1, '0000-0001-6765-4322': 1, '0000-0001-6902-0315': 1})\n",
      "['0000-0003-3692-7169']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  s_bartlett\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0001-9755-2490': 80, '0000-0003-4387-670X': 18, '0000-0002-7044-4454': 3, '0000-0003-0699-2250': 3})\n",
      "['0000-0003-4387-670X', '0000-0001-9755-2490']\n",
      "Total sample size after apply threshold:  98\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 486)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.06      0.10        18\n",
      "          1       0.82      0.99      0.90        80\n",
      "\n",
      "avg / total       0.76      0.82      0.75        98\n",
      "\n",
      "[ 1 17  1 79]\n",
      "MNB Accuracy:  0.8163265306122449\n",
      "MNB F1:  0.49886363636363634\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        18\n",
      "          1       0.87      1.00      0.93        80\n",
      "\n",
      "avg / total       0.89      0.88      0.85        98\n",
      "\n",
      "[ 6 12  0 80]\n",
      "svc Accuracy:  0.8775510204081632\n",
      "svc F1:  0.7151162790697674\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        18\n",
      "          1       0.82      1.00      0.90        80\n",
      "\n",
      "avg / total       0.67      0.82      0.73        98\n",
      "\n",
      "[ 0 18  0 80]\n",
      "LR Accuracy:  0.8163265306122449\n",
      "LR F1:  0.449438202247191\n",
      "For name:  m_lucas\n",
      "total sample size before apply threshold:  75\n",
      "Counter({'0000-0002-3252-0145': 25, '0000-0002-3625-9714': 19, '0000-0001-8672-9940': 15, '0000-0002-5463-0505': 14, '0000-0002-1646-4139': 2})\n",
      "['0000-0002-5463-0505', '0000-0001-8672-9940', '0000-0002-3625-9714', '0000-0002-3252-0145']\n",
      "Total sample size after apply threshold:  73\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 201)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "73\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       1.00      1.00      1.00        15\n",
      "          2       0.83      0.79      0.81        19\n",
      "          3       0.85      0.92      0.88        25\n",
      "\n",
      "avg / total       0.91      0.90      0.90        73\n",
      "\n",
      "[13  0  1  0  0 15  0  0  0  0 15  4  0  0  2 23]\n",
      "MNB Accuracy:  0.9041095890410958\n",
      "MNB F1:  0.9145972895972896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       1.00      0.93      0.97        15\n",
      "          2       1.00      0.79      0.88        19\n",
      "          3       0.78      1.00      0.88        25\n",
      "\n",
      "avg / total       0.93      0.90      0.91        73\n",
      "\n",
      "[12  0  0  2  0 14  0  1  0  0 15  4  0  0  0 25]\n",
      "svc Accuracy:  0.9041095890410958\n",
      "svc F1:  0.9120350220222111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        14\n",
      "          1       1.00      0.93      0.97        15\n",
      "          2       1.00      0.74      0.85        19\n",
      "          3       0.74      1.00      0.85        25\n",
      "\n",
      "avg / total       0.91      0.88      0.88        73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11  0  0  3  0 14  0  1  0  0 14  5  0  0  0 25]\n",
      "LR Accuracy:  0.8767123287671232\n",
      "LR F1:  0.8853649292457008\n",
      "For name:  w_lee\n",
      "total sample size before apply threshold:  590\n",
      "Counter({'0000-0003-3171-7672': 108, '0000-0001-5833-989X': 100, '0000-0003-3231-9764': 82, '0000-0002-1082-7592': 62, '0000-0003-3267-4811': 40, '0000-0001-7805-869X': 36, '0000-0003-2883-0391': 21, '0000-0002-0607-038X': 21, '0000-0002-5461-6770': 16, '0000-0002-3912-6095': 11, '0000-0001-6757-885X': 11, '0000-0001-6408-7668': 10, '0000-0002-9873-1033': 9, '0000-0001-7801-083X': 8, '0000-0001-8430-4797': 7, '0000-0002-2572-7287': 5, '0000-0002-6766-8481': 5, '0000-0001-8706-6026': 4, '0000-0002-0036-2859': 4, '0000-0002-9624-0505': 3, '0000-0002-3413-4029': 3, '0000-0003-1817-8395': 3, '0000-0003-1744-8525': 3, '0000-0001-8052-2420': 2, '0000-0003-0853-8561': 2, '0000-0001-7285-4054': 2, '0000-0001-9645-8179': 2, '0000-0002-4383-756X': 2, '0000-0003-1911-3454': 2, '0000-0003-4333-5444': 1, '0000-0002-7324-5792': 1, '0000-0002-2152-7210': 1, '0000-0003-4040-1100': 1, '0000-0003-0133-9076': 1, '0000-0002-7696-5517': 1})\n",
      "['0000-0001-7805-869X', '0000-0002-3912-6095', '0000-0003-2883-0391', '0000-0001-6408-7668', '0000-0003-3267-4811', '0000-0003-3171-7672', '0000-0003-3231-9764', '0000-0001-5833-989X', '0000-0002-0607-038X', '0000-0002-1082-7592', '0000-0001-6757-885X', '0000-0002-5461-6770']\n",
      "Total sample size after apply threshold:  518\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(518, 550)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "518\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.19      0.33        36\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.10      0.17        21\n",
      "          3       1.00      0.40      0.57        10\n",
      "          4       0.83      0.12      0.22        40\n",
      "          5       0.46      0.91      0.61       108\n",
      "          6       0.86      0.68      0.76        82\n",
      "          7       0.66      0.99      0.79       100\n",
      "          8       1.00      0.67      0.80        21\n",
      "          9       0.91      0.85      0.88        62\n",
      "         10       0.00      0.00      0.00        11\n",
      "         11       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.70      0.65      0.60       518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 7  0  0  0  0 13  0 15  0  1  0  0  0  0  0  0  0 10  0  1  0  0  0  0\n",
      "  0  0  2  0  0 18  1  0  0  0  0  0  0  0  0  4  0  0  0  5  0  1  0  0\n",
      "  0  0  0  0  5 34  1  0  0  0  0  0  0  0  0  0  1 98  7  2  0  0  0  0\n",
      "  0  0  0  0  0 26 56  0  0  0  0  0  0  0  0  0  0  0  0 99  0  1  0  0\n",
      "  0  0  0  0  0  7  0  0 14  0  0  0  0  0  0  0  0  2  0  7  0 53  0  0\n",
      "  0  0  0  0  0  2  0  8  0  1  0  0  0  0  0  0  0  1  0 14  0  1  0  0]\n",
      "MNB Accuracy:  0.6525096525096525\n",
      "MNB F1:  0.42806809117095507\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.67      0.79        36\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       1.00      0.43      0.60        21\n",
      "          3       1.00      0.70      0.82        10\n",
      "          4       0.71      0.68      0.69        40\n",
      "          5       0.56      0.88      0.68       108\n",
      "          6       0.87      0.71      0.78        82\n",
      "          7       0.89      0.98      0.93       100\n",
      "          8       1.00      0.71      0.83        21\n",
      "          9       0.91      0.94      0.92        62\n",
      "         10       0.00      0.00      0.00        11\n",
      "         11       1.00      0.69      0.81        16\n",
      "\n",
      "avg / total       0.81      0.78      0.77       518\n",
      "\n",
      "[24  0  0  0  0  8  0  2  0  2  0  0  0  1  0  0  0  9  0  1  0  0  0  0\n",
      "  0  0  9  0  0 12  0  0  0  0  0  0  0  0  0  7  0  0  0  3  0  0  0  0\n",
      "  0  0  0  0 27 10  3  0  0  0  0  0  0  0  0  0  7 95  6  0  0  0  0  0\n",
      "  0  0  0  0  4 20 58  0  0  0  0  0  0  0  0  0  0  0  0 98  0  2  0  0\n",
      "  0  0  0  0  0  6  0  0 15  0  0  0  1  0  0  0  0  3  0  0  0 58  0  0\n",
      "  0  0  0  0  0  5  0  5  0  1  0  0  0  0  0  0  0  3  0  1  0  1  0 11]\n",
      "svc Accuracy:  0.777992277992278\n",
      "svc F1:  0.6692527077432818\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        36\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.29      0.44        21\n",
      "          3       1.00      0.70      0.82        10\n",
      "          4       0.71      0.50      0.59        40\n",
      "          5       0.50      0.88      0.64       108\n",
      "          6       0.82      0.67      0.74        82\n",
      "          7       0.86      0.98      0.92       100\n",
      "          8       1.00      0.71      0.83        21\n",
      "          9       0.88      0.90      0.89        62\n",
      "         10       0.00      0.00      0.00        11\n",
      "         11       1.00      0.56      0.72        16\n",
      "\n",
      "avg / total       0.76      0.73      0.71       518\n",
      "\n",
      "[17  0  0  0  0 14  1  3  0  1  0  0  0  0  0  0  0 10  0  1  0  0  0  0\n",
      "  0  0  6  0  0 15  0  0  0  0  0  0  0  0  0  7  0  0  0  2  0  1  0  0\n",
      "  0  0  0  0 20 16  4  0  0  0  0  0  0  0  0  0  6 95  7  0  0  0  0  0\n",
      "  0  0  0  0  2 25 55  0  0  0  0  0  0  0  0  0  0  0  0 98  0  2  0  0\n",
      "  0  0  0  0  0  6  0  0 15  0  0  0  0  0  0  0  0  3  0  3  0 56  0  0\n",
      "  0  0  0  0  0  4  0  5  0  2  0  0  0  0  0  0  0  3  0  2  0  2  0  9]\n",
      "LR Accuracy:  0.7297297297297297\n",
      "LR F1:  0.6024612662960285\n",
      "For name:  j_cheng\n",
      "total sample size before apply threshold:  66\n",
      "Counter({'0000-0003-1786-6188': 19, '0000-0001-8285-3207': 16, '0000-0001-5318-5668': 8, '0000-0002-7004-5138': 6, '0000-0003-3928-1770': 6, '0000-0002-1881-012X': 5, '0000-0002-4364-9657': 3, '0000-0002-1722-2617': 1, '0000-0002-5434-1201': 1, '0000-0001-6065-2682': 1})\n",
      "['0000-0003-1786-6188', '0000-0001-8285-3207']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 76)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00        35\n",
      "\n",
      "[19  0  0 16]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        19\n",
      "          1       0.94      1.00      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        35\n",
      "\n",
      "[18  1  0 16]\n",
      "svc Accuracy:  0.9714285714285714\n",
      "svc F1:  0.9713349713349714\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        19\n",
      "          1       0.94      0.94      0.94        16\n",
      "\n",
      "avg / total       0.94      0.94      0.94        35\n",
      "\n",
      "[18  1  1 15]\n",
      "LR Accuracy:  0.9428571428571428\n",
      "LR F1:  0.9424342105263157\n",
      "For name:  g_lewis\n",
      "total sample size before apply threshold:  367\n",
      "Counter({'0000-0001-5205-8245': 343, '0000-0002-2548-8423': 12, '0000-0003-3081-9319': 7, '0000-0003-4112-5048': 5})\n",
      "['0000-0002-2548-8423', '0000-0001-5205-8245']\n",
      "Total sample size after apply threshold:  355\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(355, 707)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.97      1.00      0.98       343\n",
      "\n",
      "avg / total       0.93      0.96      0.95       355\n",
      "\n",
      "[  0  12   1 342]\n",
      "MNB Accuracy:  0.9633802816901409\n",
      "MNB F1:  0.49067431850789095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       1.00      1.00      1.00       343\n",
      "\n",
      "avg / total       1.00      1.00      1.00       355\n",
      "\n",
      "[ 11   1   0 343]\n",
      "svc Accuracy:  0.9971830985915493\n",
      "svc F1:  0.9775330675273717\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.97      1.00      0.98       343\n",
      "\n",
      "avg / total       0.93      0.97      0.95       355\n",
      "\n",
      "[  0  12   0 343]\n",
      "LR Accuracy:  0.9661971830985916\n",
      "LR F1:  0.49140401146131807\n",
      "For name:  j_albert\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0002-3420-7371': 40, '0000-0001-6538-9801': 19, '0000-0001-5330-1892': 13, '0000-0002-8256-2650': 6})\n",
      "['0000-0002-3420-7371', '0000-0001-6538-9801', '0000-0001-5330-1892']\n",
      "Total sample size after apply threshold:  72\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 249)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        40\n",
      "          1       1.00      0.95      0.97        19\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.97      0.97      0.97        72\n",
      "\n",
      "[40  0  0  1 18  0  1  0 12]\n",
      "MNB Accuracy:  0.9722222222222222\n",
      "MNB F1:  0.9695275763568447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        40\n",
      "          1       1.00      0.95      0.97        19\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.97      0.97      0.97        72\n",
      "\n",
      "[40  0  0  1 18  0  1  0 12]\n",
      "svc Accuracy:  0.9722222222222222\n",
      "svc F1:  0.9695275763568447\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        40\n",
      "          1       1.00      0.84      0.91        19\n",
      "          2       1.00      0.38      0.56        13\n",
      "\n",
      "avg / total       0.88      0.85      0.83        72\n",
      "\n",
      "[40  0  0  3 16  0  8  0  5]\n",
      "LR Accuracy:  0.8472222222222222\n",
      "LR F1:  0.782987382987383\n",
      "For name:  k_goh\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-2839-8722': 22, '0000-0002-3623-4891': 5, '0000-0003-0599-9696': 5, '0000-0001-5499-5187': 4, '0000-0002-2367-8303': 3, '0000-0001-5416-9627': 2, '0000-0002-8265-3421': 1})\n",
      "['0000-0002-2839-8722']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  n_harris\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-1320-282X': 5, '0000-0003-1256-3006': 4, '0000-0002-3443-3643': 2, '0000-0002-1965-6750': 2, '0000-0001-9664-2769': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_hill\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0002-4424-239X': 118, '0000-0002-6474-0214': 12, '0000-0003-3010-8998': 7, '0000-0002-5909-692X': 5, '0000-0002-2995-2596': 4, '0000-0001-8055-860X': 3, '0000-0001-6742-3620': 2, '0000-0002-3305-6954': 1})\n",
      "['0000-0002-4424-239X', '0000-0002-6474-0214']\n",
      "Total sample size after apply threshold:  130\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 182)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "130\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       118\n",
      "          1       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.82      0.91      0.86       130\n",
      "\n",
      "[118   0  12   0]\n",
      "MNB Accuracy:  0.9076923076923077\n",
      "MNB F1:  0.47580645161290325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98       118\n",
      "          1       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97       130\n",
      "\n",
      "[118   0   4   8]\n",
      "svc Accuracy:  0.9692307692307692\n",
      "svc F1:  0.8916666666666666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       118\n",
      "          1       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.82      0.91      0.86       130\n",
      "\n",
      "[118   0  12   0]\n",
      "LR Accuracy:  0.9076923076923077\n",
      "LR F1:  0.47580645161290325\n",
      "For name:  p_pathak\n",
      "total sample size before apply threshold:  9\n",
      "Counter({'0000-0003-0118-3235': 4, '0000-0002-1157-5550': 3, '0000-0002-9771-6624': 1, '0000-0003-2152-3938': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_zeng\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0002-8246-2000': 42, '0000-0002-0260-1059': 21, '0000-0002-9909-7732': 6, '0000-0002-9150-214X': 6, '0000-0003-0293-7692': 4, '0000-0002-7657-6714': 3})\n",
      "['0000-0002-0260-1059', '0000-0002-8246-2000']\n",
      "Total sample size after apply threshold:  63\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 118)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.81      0.87        21\n",
      "          1       0.91      0.98      0.94        42\n",
      "\n",
      "avg / total       0.92      0.92      0.92        63\n",
      "\n",
      "[17  4  1 41]\n",
      "MNB Accuracy:  0.9206349206349206\n",
      "MNB F1:  0.9071618037135278\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        21\n",
      "          1       0.88      1.00      0.93        42\n",
      "\n",
      "avg / total       0.92      0.90      0.90        63\n",
      "\n",
      "[15  6  0 42]\n",
      "svc Accuracy:  0.9047619047619048\n",
      "svc F1:  0.8833333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.52      0.69        21\n",
      "          1       0.81      1.00      0.89        42\n",
      "\n",
      "avg / total       0.87      0.84      0.82        63\n",
      "\n",
      "[11 10  0 42]\n",
      "LR Accuracy:  0.8412698412698413\n",
      "LR F1:  0.790558510638298\n",
      "For name:  h_liu\n",
      "total sample size before apply threshold:  439\n",
      "Counter({'0000-0001-6715-6366': 100, '0000-0002-0253-647X': 45, '0000-0002-1006-6666': 39, '0000-0001-7639-0904': 39, '0000-0002-7233-1509': 31, '0000-0001-9366-6204': 26, '0000-0002-4723-845X': 18, '0000-0003-3326-2640': 17, '0000-0002-3745-7202': 13, '0000-0003-4837-5373': 11, '0000-0003-3103-6949': 10, '0000-0002-4548-2002': 9, '0000-0003-0266-9472': 9, '0000-0001-7984-6305': 8, '0000-0002-7645-0855': 8, '0000-0003-2394-5421': 7, '0000-0001-5451-6828': 6, '0000-0002-1852-4537': 5, '0000-0003-2183-9609': 3, '0000-0003-1837-1435': 3, '0000-0002-2781-2637': 3, '0000-0001-8959-0315': 3, '0000-0003-1313-4000': 3, '0000-0003-1724-4418': 2, '0000-0003-0345-6647': 2, '0000-0001-8519-3240': 2, '0000-0002-3292-9303': 2, '0000-0003-1679-6560': 2, '0000-0003-4341-672X': 2, '0000-0001-8806-6204': 1, '0000-0003-3125-4399': 1, '0000-0002-5450-5958': 1, '0000-0003-0658-4425': 1, '0000-0002-6370-0704': 1, '0000-0001-6604-5509': 1, '0000-0002-6009-8797': 1, '0000-0003-4566-2107': 1, '0000-0003-3055-5528': 1, '0000-0002-5437-4695': 1, '0000-0003-3607-7176': 1})\n",
      "['0000-0003-4837-5373', '0000-0002-1006-6666', '0000-0003-3326-2640', '0000-0002-3745-7202', '0000-0001-6715-6366', '0000-0001-9366-6204', '0000-0002-0253-647X', '0000-0002-4723-845X', '0000-0001-7639-0904', '0000-0003-3103-6949', '0000-0002-7233-1509']\n",
      "Total sample size after apply threshold:  349\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(349, 633)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "349\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.44      0.61        39\n",
      "          2       0.00      0.00      0.00        17\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.49      1.00      0.66       100\n",
      "          5       1.00      0.77      0.87        26\n",
      "          6       0.83      0.76      0.79        45\n",
      "          7       1.00      0.39      0.56        18\n",
      "          8       0.77      0.85      0.80        39\n",
      "          9       0.00      0.00      0.00        10\n",
      "         10       1.00      0.58      0.73        31\n",
      "\n",
      "avg / total       0.66      0.66      0.61       349\n",
      "\n",
      "[  0   0   0   0  11   0   0   0   0   0   0   0  17   0   0  19   0   2\n",
      "   0   1   0   0   0   0   0   0  17   0   0   0   0   0   0   0   0   0\n",
      "   0  11   0   2   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "   0   0   0   0   0   6  20   0   0   0   0   0   0   0   0   0  10   0\n",
      "  34   0   1   0   0   0   0   0   0   4   0   1   7   6   0   0   0   0\n",
      "   0   0   6   0   0   0  33   0   0   0   0   0   0  10   0   0   0   0\n",
      "   0   0   0   0   0   0   9   0   2   0   2   0  18]\n",
      "MNB Accuracy:  0.6561604584527221\n",
      "MNB F1:  0.45700397108044866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.78      0.90      0.83        39\n",
      "          2       1.00      0.76      0.87        17\n",
      "          3       1.00      0.54      0.70        13\n",
      "          4       0.80      1.00      0.89       100\n",
      "          5       1.00      0.92      0.96        26\n",
      "          6       0.98      0.91      0.94        45\n",
      "          7       0.88      0.78      0.82        18\n",
      "          8       0.92      0.92      0.92        39\n",
      "          9       1.00      0.30      0.46        10\n",
      "         10       0.96      0.87      0.92        31\n",
      "\n",
      "avg / total       0.90      0.88      0.87       349\n",
      "\n",
      "[  7   0   0   0   4   0   0   0   0   0   0   0  35   0   0   2   0   0\n",
      "   1   1   0   0   0   0  13   0   3   0   0   1   0   0   0   0   0   0\n",
      "   7   6   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "   0   0   0   0   0   2  24   0   0   0   0   0   0   1   0   0   2   0\n",
      "  41   0   1   0   0   0   2   0   0   0   0   0  14   1   0   1   0   2\n",
      "   0   0   1   0   0   0  36   0   0   0   2   0   0   5   0   0   0   0\n",
      "   3   0   0   3   0   0   0   0   1   0   0   0  27]\n",
      "svc Accuracy:  0.8796561604584527\n",
      "svc F1:  0.8265994941788251\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       0.83      0.64      0.72        39\n",
      "          2       1.00      0.53      0.69        17\n",
      "          3       1.00      0.15      0.27        13\n",
      "          4       0.64      1.00      0.78       100\n",
      "          5       1.00      0.85      0.92        26\n",
      "          6       0.91      0.89      0.90        45\n",
      "          7       0.92      0.67      0.77        18\n",
      "          8       0.77      0.87      0.82        39\n",
      "          9       0.00      0.00      0.00        10\n",
      "         10       0.96      0.81      0.88        31\n",
      "\n",
      "avg / total       0.80      0.78      0.75       349\n",
      "\n",
      "[  2   0   0   0   9   0   0   0   0   0   0   0  25   0   0   8   0   0\n",
      "   1   5   0   0   0   0   9   0   8   0   0   0   0   0   0   0   2   0\n",
      "   2   9   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "   0   0   0   0   0   4  22   0   0   0   0   0   0   1   0   0   3   0\n",
      "  40   0   1   0   0   0   0   0   0   1   0   1  12   3   0   1   0   1\n",
      "   0   0   3   0   1   0  34   0   0   0   0   0   0  10   0   0   0   0\n",
      "   0   0   0   1   0   0   2   0   2   0   1   0  25]\n",
      "LR Accuracy:  0.7765042979942693\n",
      "LR F1:  0.641429197726875\n",
      "For name:  s_bae\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0003-0551-7618': 19, '0000-0002-3019-0584': 17, '0000-0002-4995-6543': 17, '0000-0002-8993-8884': 9, '0000-0003-0098-8816': 8, '0000-0003-1926-5466': 6, '0000-0001-7603-7676': 6, '0000-0003-0637-4110': 1})\n",
      "['0000-0003-0551-7618', '0000-0002-3019-0584', '0000-0002-4995-6543']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 92)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        19\n",
      "          1       0.86      0.35      0.50        17\n",
      "          2       0.64      0.94      0.76        17\n",
      "\n",
      "avg / total       0.80      0.77      0.75        53\n",
      "\n",
      "[19  0  0  2  6  9  0  1 16]\n",
      "MNB Accuracy:  0.7735849056603774\n",
      "MNB F1:  0.7373015873015873\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       0.93      0.82      0.87        17\n",
      "          2       0.84      0.94      0.89        17\n",
      "\n",
      "avg / total       0.93      0.92      0.92        53\n",
      "\n",
      "[19  0  0  0 14  3  0  1 16]\n",
      "svc Accuracy:  0.9245283018867925\n",
      "svc F1:  0.9212962962962963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        19\n",
      "          1       0.88      0.82      0.85        17\n",
      "          2       0.88      0.88      0.88        17\n",
      "\n",
      "avg / total       0.90      0.91      0.90        53\n",
      "\n",
      "[19  0  0  1 14  2  0  2 15]\n",
      "LR Accuracy:  0.9056603773584906\n",
      "LR F1:  0.9017322546734311\n",
      "For name:  s_fernandes\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0003-1128-833X': 20, '0000-0002-1295-5010': 6, '0000-0002-9035-793X': 5, '0000-0002-7871-6717': 5, '0000-0002-0790-303X': 2})\n",
      "['0000-0003-1128-833X']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  a_miller\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0002-7056-8502': 33, '0000-0001-8474-5090': 28, '0000-0002-7293-764X': 22, '0000-0002-0553-8470': 15, '0000-0001-9735-6609': 5, '0000-0001-8527-1595': 1, '0000-0002-1761-4143': 1, '0000-0002-3099-1648': 1, '0000-0002-0941-1717': 1, '0000-0001-9739-8462': 1, '0000-0003-0924-8443': 1})\n",
      "['0000-0001-8474-5090', '0000-0002-0553-8470', '0000-0002-7056-8502', '0000-0002-7293-764X']\n",
      "Total sample size after apply threshold:  98\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 283)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.79      0.79        28\n",
      "          1       1.00      0.80      0.89        15\n",
      "          2       0.72      0.88      0.79        33\n",
      "          3       0.94      0.77      0.85        22\n",
      "\n",
      "avg / total       0.83      0.82      0.82        98\n",
      "\n",
      "[22  0  6  0  2 12  0  1  4  0 29  0  0  0  5 17]\n",
      "MNB Accuracy:  0.8163265306122449\n",
      "MNB F1:  0.829780930637095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        28\n",
      "          1       1.00      0.87      0.93        15\n",
      "          2       0.72      1.00      0.84        33\n",
      "          3       0.94      0.73      0.82        22\n",
      "\n",
      "avg / total       0.89      0.86      0.86        98\n",
      "\n",
      "[22  0  6  0  0 13  1  1  0  0 33  0  0  0  6 16]\n",
      "svc Accuracy:  0.8571428571428571\n",
      "svc F1:  0.8661318217647331\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.64      0.71        28\n",
      "          1       1.00      0.80      0.89        15\n",
      "          2       0.62      0.91      0.74        33\n",
      "          3       1.00      0.68      0.81        22\n",
      "\n",
      "avg / total       0.81      0.77      0.77        98\n",
      "\n",
      "[18  0 10  0  2 12  1  0  3  0 30  0  0  0  7 15]\n",
      "LR Accuracy:  0.7653061224489796\n",
      "LR F1:  0.7865806983454042\n",
      "For name:  a_eklund\n",
      "total sample size before apply threshold:  118\n",
      "Counter({'0000-0002-2031-722X': 73, '0000-0003-0861-1001': 40, '0000-0003-1271-1814': 4, '0000-0002-2162-7537': 1})\n",
      "['0000-0003-0861-1001', '0000-0002-2031-722X']\n",
      "Total sample size after apply threshold:  113\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(113, 438)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "113\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        40\n",
      "          1       0.90      1.00      0.95        73\n",
      "\n",
      "avg / total       0.94      0.93      0.93       113\n",
      "\n",
      "[32  8  0 73]\n",
      "MNB Accuracy:  0.9292035398230089\n",
      "MNB F1:  0.9184704184704184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        40\n",
      "          1       1.00      1.00      1.00        73\n",
      "\n",
      "avg / total       1.00      1.00      1.00       113\n",
      "\n",
      "[40  0  0 73]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        40\n",
      "          1       0.94      1.00      0.97        73\n",
      "\n",
      "avg / total       0.96      0.96      0.96       113\n",
      "\n",
      "[35  5  0 73]\n",
      "LR Accuracy:  0.9557522123893806\n",
      "LR F1:  0.9501103752759382\n",
      "For name:  r_moore\n",
      "total sample size before apply threshold:  221\n",
      "Counter({'0000-0002-0776-5861': 75, '0000-0001-7221-6693': 51, '0000-0003-1072-2755': 45, '0000-0003-2027-2428': 44, '0000-0003-4196-1804': 6})\n",
      "['0000-0003-2027-2428', '0000-0003-1072-2755', '0000-0001-7221-6693', '0000-0002-0776-5861']\n",
      "Total sample size after apply threshold:  215\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(215, 579)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "215\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        44\n",
      "          1       1.00      0.87      0.93        45\n",
      "          2       0.96      0.96      0.96        51\n",
      "          3       0.80      0.99      0.88        75\n",
      "\n",
      "avg / total       0.92      0.90      0.90       215\n",
      "\n",
      "[32  0  0 12  0 39  1  5  0  0 49  2  0  0  1 74]\n",
      "MNB Accuracy:  0.9023255813953488\n",
      "MNB F1:  0.9031033466017987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        44\n",
      "          1       1.00      0.82      0.90        45\n",
      "          2       1.00      0.96      0.98        51\n",
      "          3       0.81      1.00      0.89        75\n",
      "\n",
      "avg / total       0.93      0.92      0.92       215\n",
      "\n",
      "[36  0  0  8  0 37  0  8  0  0 49  2  0  0  0 75]\n",
      "svc Accuracy:  0.9162790697674419\n",
      "svc F1:  0.9188240418118466\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        44\n",
      "          1       1.00      0.78      0.88        45\n",
      "          2       1.00      0.96      0.98        51\n",
      "          3       0.70      1.00      0.82        75\n",
      "\n",
      "avg / total       0.90      0.85      0.85       215\n",
      "\n",
      "[24  0  0 20  0 35  0 10  0  0 49  2  0  0  0 75]\n",
      "LR Accuracy:  0.8511627906976744\n",
      "LR F1:  0.8462645442792502\n",
      "For name:  m_thomsen\n",
      "total sample size before apply threshold:  98\n",
      "Counter({'0000-0002-2469-6458': 37, '0000-0003-2453-5141': 32, '0000-0001-6805-7247': 17, '0000-0003-3081-9220': 7, '0000-0003-3814-1709': 3, '0000-0003-1208-5497': 2})\n",
      "['0000-0003-2453-5141', '0000-0002-2469-6458', '0000-0001-6805-7247']\n",
      "Total sample size after apply threshold:  86\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 213)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94        32\n",
      "          1       0.87      0.92      0.89        37\n",
      "          2       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.91      0.91      0.91        86\n",
      "\n",
      "[31  1  0  3 34  0  0  4 13]\n",
      "MNB Accuracy:  0.9069767441860465\n",
      "MNB F1:  0.9002658160552898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.91      0.94        32\n",
      "          1       0.82      0.97      0.89        37\n",
      "          2       1.00      0.71      0.83        17\n",
      "\n",
      "avg / total       0.91      0.90      0.89        86\n",
      "\n",
      "[29  3  0  1 36  0  0  5 12]\n",
      "svc Accuracy:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8953488372093024\n",
      "svc F1:  0.8839863222510608\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        32\n",
      "          1       0.74      0.95      0.83        37\n",
      "          2       1.00      0.41      0.58        17\n",
      "\n",
      "avg / total       0.87      0.84      0.82        86\n",
      "\n",
      "[30  2  0  2 35  0  0 10  7]\n",
      "LR Accuracy:  0.8372093023255814\n",
      "LR F1:  0.7847222222222223\n",
      "For name:  l_ng\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0003-1905-3586': 37, '0000-0002-6973-9466': 3, '0000-0001-7500-9403': 1, '0000-0001-5988-008X': 1, '0000-0003-3135-244X': 1, '0000-0002-7189-1272': 1})\n",
      "['0000-0003-1905-3586']\n",
      "Total sample size after apply threshold:  37\n",
      "For name:  a_phillips\n",
      "total sample size before apply threshold:  170\n",
      "Counter({'0000-0002-5461-0598': 98, '0000-0001-6367-9784': 24, '0000-0001-5599-6499': 24, '0000-0003-4883-0022': 9, '0000-0003-4225-0158': 7, '0000-0003-4473-5108': 4, '0000-0001-6618-0145': 3, '0000-0001-6335-9430': 1})\n",
      "['0000-0001-6367-9784', '0000-0001-5599-6499', '0000-0002-5461-0598']\n",
      "Total sample size after apply threshold:  146\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(146, 333)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "146\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        24\n",
      "          1       1.00      0.58      0.74        24\n",
      "          2       0.82      1.00      0.90        98\n",
      "\n",
      "avg / total       0.88      0.85      0.83       146\n",
      "\n",
      "[12  0 12  0 14 10  0  0 98]\n",
      "MNB Accuracy:  0.8493150684931506\n",
      "MNB F1:  0.7675304469123879\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        24\n",
      "          1       1.00      0.83      0.91        24\n",
      "          2       0.92      1.00      0.96        98\n",
      "\n",
      "avg / total       0.94      0.94      0.94       146\n",
      "\n",
      "[19  0  5  0 20  4  0  0 98]\n",
      "svc Accuracy:  0.9383561643835616\n",
      "svc F1:  0.9163031334330256\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.55        24\n",
      "          1       1.00      0.54      0.70        24\n",
      "          2       0.79      1.00      0.88        98\n",
      "\n",
      "avg / total       0.86      0.82      0.80       146\n",
      "\n",
      "[ 9  0 15  0 13 11  0  0 98]\n",
      "LR Accuracy:  0.821917808219178\n",
      "LR F1:  0.7103467103467103\n",
      "For name:  y_ye\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0002-7517-1715': 75, '0000-0002-2029-4558': 8, '0000-0003-3962-8463': 1, '0000-0002-9172-6514': 1})\n",
      "['0000-0002-7517-1715']\n",
      "Total sample size after apply threshold:  75\n",
      "For name:  m_guerreiro\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0002-1948-1516': 23, '0000-0002-5133-8779': 6, '0000-0002-2863-887X': 6, '0000-0001-6774-9348': 1})\n",
      "['0000-0002-1948-1516']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  g_alves\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0002-4213-0714': 40, '0000-0003-0630-2870': 12, '0000-0003-3945-9962': 7, '0000-0003-4985-5555': 1})\n",
      "['0000-0003-0630-2870', '0000-0002-4213-0714']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 99)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        40\n",
      "\n",
      "avg / total       1.00      1.00      1.00        52\n",
      "\n",
      "[12  0  0 40]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        40\n",
      "\n",
      "avg / total       1.00      1.00      1.00        52\n",
      "\n",
      "[12  0  0 40]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.87      1.00      0.93        40\n",
      "\n",
      "avg / total       0.90      0.88      0.87        52\n",
      "\n",
      "[ 6  6  0 40]\n",
      "LR Accuracy:  0.8846153846153846\n",
      "LR F1:  0.7984496124031008\n",
      "For name:  m_mohammed\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0003-3423-0085': 2, '0000-0002-1795-579X': 2, '0000-0002-9695-396X': 1, '0000-0002-7103-0165': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_mohammadi\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0003-1311-9636': 42, '0000-0003-0650-6654': 13, '0000-0003-3450-6424': 1, '0000-0003-1658-9756': 1, '0000-0002-6656-025X': 1, '0000-0002-9209-3034': 1})\n",
      "['0000-0003-0650-6654', '0000-0003-1311-9636']\n",
      "Total sample size after apply threshold:  55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 148)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.95      1.00      0.98        42\n",
      "\n",
      "avg / total       0.97      0.96      0.96        55\n",
      "\n",
      "[11  2  0 42]\n",
      "MNB Accuracy:  0.9636363636363636\n",
      "MNB F1:  0.9467054263565892\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.95      1.00      0.98        42\n",
      "\n",
      "avg / total       0.97      0.96      0.96        55\n",
      "\n",
      "[11  2  0 42]\n",
      "svc Accuracy:  0.9636363636363636\n",
      "svc F1:  0.9467054263565892\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.56        13\n",
      "          1       0.84      1.00      0.91        42\n",
      "\n",
      "avg / total       0.88      0.85      0.83        55\n",
      "\n",
      "[ 5  8  0 42]\n",
      "LR Accuracy:  0.8545454545454545\n",
      "LR F1:  0.7342995169082126\n",
      "For name:  c_chao\n",
      "total sample size before apply threshold:  155\n",
      "Counter({'0000-0003-2892-7986': 86, '0000-0002-2804-7447': 34, '0000-0001-6499-5789': 19, '0000-0002-8789-7732': 7, '0000-0001-7769-9305': 7, '0000-0003-1215-8588': 1, '0000-0003-4108-2658': 1})\n",
      "['0000-0002-2804-7447', '0000-0003-2892-7986', '0000-0001-6499-5789']\n",
      "Total sample size after apply threshold:  139\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 106)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.56      0.72        34\n",
      "          1       0.79      1.00      0.88        86\n",
      "          2       1.00      0.58      0.73        19\n",
      "\n",
      "avg / total       0.87      0.83      0.82       139\n",
      "\n",
      "[19 15  0  0 86  0  0  8 11]\n",
      "MNB Accuracy:  0.8345323741007195\n",
      "MNB F1:  0.7774552491533623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.79      0.84        34\n",
      "          1       0.90      0.98      0.94        86\n",
      "          2       1.00      0.84      0.91        19\n",
      "\n",
      "avg / total       0.92      0.91      0.91       139\n",
      "\n",
      "[27  7  0  2 84  0  1  2 16]\n",
      "svc Accuracy:  0.9136690647482014\n",
      "svc F1:  0.8988610667730779\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.59      0.70        34\n",
      "          1       0.80      0.98      0.88        86\n",
      "          2       1.00      0.58      0.73        19\n",
      "\n",
      "avg / total       0.84      0.83      0.82       139\n",
      "\n",
      "[20 14  0  2 84  0  1  7 11]\n",
      "LR Accuracy:  0.8273381294964028\n",
      "LR F1:  0.7715562903769021\n",
      "For name:  s_teixeira\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0003-0419-2348': 12, '0000-0001-5845-058X': 11, '0000-0002-2462-8535': 3, '0000-0002-9473-0113': 3, '0000-0002-7464-3944': 3, '0000-0002-6603-7936': 3, '0000-0003-3664-2577': 1})\n",
      "['0000-0003-0419-2348', '0000-0001-5845-058X']\n",
      "Total sample size after apply threshold:  23\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 99)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "23\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        12\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.87      0.83      0.82        23\n",
      "\n",
      "[12  0  4  7]\n",
      "MNB Accuracy:  0.8260869565217391\n",
      "MNB F1:  0.8174603174603174\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        23\n",
      "\n",
      "[12  0  0 11]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        23\n",
      "\n",
      "[12  0  0 11]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  l_almeida\n",
      "total sample size before apply threshold:  133\n",
      "Counter({'0000-0002-4861-8649': 57, '0000-0002-7769-4712': 43, '0000-0003-1370-961X': 12, '0000-0003-0370-214X': 8, '0000-0002-0651-7014': 5, '0000-0001-9346-7520': 4, '0000-0002-1324-0068': 1, '0000-0002-9544-3028': 1, '0000-0003-4711-4454': 1, '0000-0002-0921-887X': 1})\n",
      "['0000-0003-1370-961X', '0000-0002-4861-8649', '0000-0002-7769-4712']\n",
      "Total sample size after apply threshold:  112\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(112, 197)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "112\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.97      0.98      0.97        57\n",
      "          2       0.90      1.00      0.95        43\n",
      "\n",
      "avg / total       0.94      0.94      0.93       112\n",
      "\n",
      "[ 6  2  4  0 56  1  0  0 43]\n",
      "MNB Accuracy:  0.9375\n",
      "MNB F1:  0.8618782183999576\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        12\n",
      "          1       0.98      0.98      0.98        57\n",
      "          2       1.00      1.00      1.00        43\n",
      "\n",
      "avg / total       0.98      0.98      0.98       112\n",
      "\n",
      "[11  1  0  1 56  0  0  0 43]\n",
      "svc Accuracy:  0.9821428571428571\n",
      "svc F1:  0.9663742690058479\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        12\n",
      "          1       0.97      1.00      0.98        57\n",
      "          2       0.90      1.00      0.95        43\n",
      "\n",
      "avg / total       0.94      0.94      0.93       112\n",
      "\n",
      "[ 5  2  5  0 57  0  0  0 43]\n",
      "LR Accuracy:  0.9375\n",
      "LR F1:  0.8386829532874157\n",
      "For name:  y_tseng\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-8461-6181': 45, '0000-0002-2354-5906': 9, '0000-0001-6917-893X': 2, '0000-0002-3803-7410': 2, '0000-0002-1814-5553': 2, '0000-0002-3511-7191': 1})\n",
      "['0000-0002-8461-6181']\n",
      "Total sample size after apply threshold:  45\n",
      "For name:  a_ferro\n",
      "total sample size before apply threshold:  125\n",
      "Counter({'0000-0002-5486-9145': 91, '0000-0003-2399-3626': 11, '0000-0001-6042-4591': 10, '0000-0003-4470-079X': 7, '0000-0001-8403-9823': 4, '0000-0002-9431-5788': 2})\n",
      "['0000-0001-6042-4591', '0000-0002-5486-9145', '0000-0003-2399-3626']\n",
      "Total sample size after apply threshold:  112\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(112, 289)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.88      1.00      0.94        91\n",
      "          2       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.91      0.89      0.87       112\n",
      "\n",
      "[ 3  7  0  0 91  0  0  5  6]\n",
      "MNB Accuracy:  0.8928571428571429\n",
      "MNB F1:  0.7018550481255149\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.93      1.00      0.96        91\n",
      "          2       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.94      0.94      0.93       112\n",
      "\n",
      "[ 8  2  0  0 91  0  0  5  6]\n",
      "svc Accuracy:  0.9375\n",
      "svc F1:  0.8525780682643429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.81      1.00      0.90        91\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.66      0.81      0.73       112\n",
      "\n",
      "[ 0 10  0  0 91  0  0 11  0]\n",
      "LR Accuracy:  0.8125\n",
      "LR F1:  0.2988505747126437\n",
      "For name:  d_he\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0003-3253-654X': 17, '0000-0003-2212-1973': 4, '0000-0002-9947-6177': 3, '0000-0002-2446-7436': 2, '0000-0002-4001-826X': 2, '0000-0002-3360-9352': 1})\n",
      "['0000-0003-3253-654X']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  k_ko\n",
      "total sample size before apply threshold:  168\n",
      "Counter({'0000-0002-0978-1937': 153, '0000-0003-3649-4594': 11, '0000-0002-6412-1026': 2, '0000-0002-0192-0269': 1, '0000-0002-0515-5904': 1})\n",
      "['0000-0003-3649-4594', '0000-0002-0978-1937']\n",
      "Total sample size after apply threshold:  164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(164, 224)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "164\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.93      0.99      0.96       153\n",
      "\n",
      "avg / total       0.87      0.92      0.89       164\n",
      "\n",
      "[  0  11   2 151]\n",
      "MNB Accuracy:  0.9207317073170732\n",
      "MNB F1:  0.4793650793650794\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       0.94      1.00      0.97       153\n",
      "\n",
      "avg / total       0.95      0.95      0.93       164\n",
      "\n",
      "[  2   9   0 153]\n",
      "svc Accuracy:  0.9451219512195121\n",
      "svc F1:  0.6395604395604395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.93      1.00      0.97       153\n",
      "\n",
      "avg / total       0.87      0.93      0.90       164\n",
      "\n",
      "[  0  11   0 153]\n",
      "LR Accuracy:  0.9329268292682927\n",
      "LR F1:  0.48264984227129337\n",
      "For name:  t_mori\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0003-3918-0873': 92, '0000-0002-0370-1924': 10, '0000-0001-5340-3282': 1, '0000-0001-7096-4161': 1})\n",
      "['0000-0002-0370-1924', '0000-0003-3918-0873']\n",
      "Total sample size after apply threshold:  102\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(102, 157)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.99      1.00      0.99        92\n",
      "\n",
      "avg / total       0.99      0.99      0.99       102\n",
      "\n",
      "[ 9  1  0 92]\n",
      "MNB Accuracy:  0.9901960784313726\n",
      "MNB F1:  0.9709815078236131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.99      1.00      0.99        92\n",
      "\n",
      "avg / total       0.99      0.99      0.99       102\n",
      "\n",
      "[ 9  1  0 92]\n",
      "svc Accuracy:  0.9901960784313726\n",
      "svc F1:  0.9709815078236131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.94      1.00      0.97        92\n",
      "\n",
      "avg / total       0.94      0.94      0.93       102\n",
      "\n",
      "[ 4  6  0 92]\n",
      "LR Accuracy:  0.9411764705882353\n",
      "LR F1:  0.7699248120300752\n",
      "For name:  p_lima\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-1252-2565': 8, '0000-0002-9739-0783': 8, '0000-0002-4323-3918': 4, '0000-0003-2081-571X': 2, '0000-0002-8962-8050': 1, '0000-0003-2937-9520': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_ferguson\n",
      "total sample size before apply threshold:  217\n",
      "Counter({'0000-0001-5045-819X': 174, '0000-0001-9302-5992': 35, '0000-0001-6448-8701': 4, '0000-0003-0612-6512': 3, '0000-0002-7400-7892': 1})\n",
      "['0000-0001-5045-819X', '0000-0001-9302-5992']\n",
      "Total sample size after apply threshold:  209\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(209, 856)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       174\n",
      "          1       1.00      0.66      0.79        35\n",
      "\n",
      "avg / total       0.95      0.94      0.94       209\n",
      "\n",
      "[174   0  12  23]\n",
      "MNB Accuracy:  0.9425837320574163\n",
      "MNB F1:  0.8798850574712643\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       174\n",
      "          1       1.00      0.77      0.87        35\n",
      "\n",
      "avg / total       0.96      0.96      0.96       209\n",
      "\n",
      "[174   0   8  27]\n",
      "svc Accuracy:  0.9617224880382775\n",
      "svc F1:  0.9242479159115622\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       174\n",
      "          1       1.00      0.26      0.41        35\n",
      "\n",
      "avg / total       0.89      0.88      0.84       209\n",
      "\n",
      "[174   0  26   9]\n",
      "LR Accuracy:  0.8755980861244019\n",
      "LR F1:  0.6697860962566844\n",
      "For name:  h_moreira\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-1487-0539': 13, '0000-0002-5481-0688': 10, '0000-0002-4674-5417': 3, '0000-0002-4556-5027': 1, '0000-0002-5588-374X': 1})\n",
      "['0000-0002-1487-0539', '0000-0002-5481-0688']\n",
      "Total sample size after apply threshold:  23\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 29)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "23\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.96      0.96      0.96        23\n",
      "\n",
      "[13  0  1  9]\n",
      "MNB Accuracy:  0.9565217391304348\n",
      "MNB F1:  0.9551656920077973\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.96      0.96      0.96        23\n",
      "\n",
      "[13  0  1  9]\n",
      "svc Accuracy:  0.9565217391304348\n",
      "svc F1:  0.9551656920077973\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.96      0.96      0.96        23\n",
      "\n",
      "[13  0  1  9]\n",
      "LR Accuracy:  0.9565217391304348\n",
      "LR F1:  0.9551656920077973\n",
      "For name:  s_yi\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0002-6656-6205': 29, '0000-0001-6333-4399': 19, '0000-0003-2689-8595': 11, '0000-0003-2804-7161': 3, '0000-0003-4932-8237': 3, '0000-0002-9190-5643': 2})\n",
      "['0000-0002-6656-6205', '0000-0003-2689-8595', '0000-0001-6333-4399']\n",
      "Total sample size after apply threshold:  59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 52)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.97      0.88        29\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       0.89      0.84      0.86        19\n",
      "\n",
      "avg / total       0.87      0.85      0.84        59\n",
      "\n",
      "[28  0  1  4  6  1  3  0 16]\n",
      "MNB Accuracy:  0.847457627118644\n",
      "MNB F1:  0.8152490726020138\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93        29\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       0.68      1.00      0.81        19\n",
      "\n",
      "avg / total       0.90      0.85      0.85        59\n",
      "\n",
      "[25  0  4  0  6  5  0  0 19]\n",
      "svc Accuracy:  0.847457627118644\n",
      "svc F1:  0.8134396390549915\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93        29\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       0.86      1.00      0.93        19\n",
      "\n",
      "avg / total       0.91      0.90      0.89        59\n",
      "\n",
      "[28  0  1  3  6  2  0  0 19]\n",
      "LR Accuracy:  0.8983050847457628\n",
      "LR F1:  0.8553483181890642\n",
      "For name:  q_liu\n",
      "total sample size before apply threshold:  264\n",
      "Counter({'0000-0001-8477-6452': 62, '0000-0001-8525-7961': 62, '0000-0002-1179-290X': 47, '0000-0002-8402-029X': 26, '0000-0001-5286-4423': 24, '0000-0003-3533-7140': 18, '0000-0003-4114-5540': 8, '0000-0002-3616-351X': 6, '0000-0002-2199-2999': 2, '0000-0003-1508-7172': 2, '0000-0003-0769-4642': 1, '0000-0001-9746-2938': 1, '0000-0002-6286-941X': 1, '0000-0002-7574-3752': 1, '0000-0002-4678-3333': 1, '0000-0002-8398-1021': 1, '0000-0002-7285-5425': 1})\n",
      "['0000-0002-1179-290X', '0000-0003-3533-7140', '0000-0001-8477-6452', '0000-0001-5286-4423', '0000-0002-8402-029X', '0000-0001-8525-7961']\n",
      "Total sample size after apply threshold:  239\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(239, 352)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.87      0.88        47\n",
      "          1       1.00      0.17      0.29        18\n",
      "          2       0.84      0.84      0.84        62\n",
      "          3       1.00      0.08      0.15        24\n",
      "          4       1.00      0.77      0.87        26\n",
      "          5       0.58      1.00      0.74        62\n",
      "\n",
      "avg / total       0.83      0.75      0.71       239\n",
      "\n",
      "[41  0  0  0  0  6  1  3  1  0  0 13  0  0 52  0  0 10  3  0  7  2  0 12\n",
      "  1  0  2  0 20  3  0  0  0  0  0 62]\n",
      "MNB Accuracy:  0.7531380753138075\n",
      "MNB F1:  0.6279418337623106\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.91      0.93        47\n",
      "          1       0.85      0.61      0.71        18\n",
      "          2       0.85      1.00      0.92        62\n",
      "          3       0.79      0.79      0.79        24\n",
      "          4       1.00      0.92      0.96        26\n",
      "          5       0.98      0.95      0.97        62\n",
      "\n",
      "avg / total       0.92      0.91      0.91       239\n",
      "\n",
      "[43  0  4  0  0  0  1 11  3  2  0  1  0  0 62  0  0  0  1  0  4 19  0  0\n",
      "  0  0  0  2 24  0  0  2  0  1  0 59]\n",
      "svc Accuracy:  0.9121338912133892\n",
      "svc F1:  0.880309721331629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.89      0.91        47\n",
      "          1       1.00      0.44      0.62        18\n",
      "          2       0.74      0.98      0.85        62\n",
      "          3       0.87      0.54      0.67        24\n",
      "          4       1.00      0.85      0.92        26\n",
      "          5       0.93      1.00      0.96        62\n",
      "\n",
      "avg / total       0.89      0.87      0.86       239\n",
      "\n",
      "[42  0  4  0  0  1  1  8  6  0  0  3  0  0 61  0  0  1  2  0  9 13  0  0\n",
      "  0  0  2  2 22  0  0  0  0  0  0 62]\n",
      "LR Accuracy:  0.8702928870292888\n",
      "LR F1:  0.8200373265464266\n",
      "For name:  m_ibrahim\n",
      "total sample size before apply threshold:  146\n",
      "Counter({'0000-0002-5756-5198': 20, '0000-0002-9698-0837': 19, '0000-0001-6509-2979': 17, '0000-0003-4614-7182': 15, '0000-0003-0257-860X': 14, '0000-0001-6019-5055': 9, '0000-0001-8657-3368': 9, '0000-0002-0116-597X': 6, '0000-0003-1412-2132': 6, '0000-0002-2603-8280': 5, '0000-0002-7762-1580': 5, '0000-0003-0623-5225': 4, '0000-0003-0468-617X': 3, '0000-0002-8854-8198': 3, '0000-0002-7925-4585': 2, '0000-0002-0021-5971': 2, '0000-0002-9288-2359': 2, '0000-0002-5121-7256': 1, '0000-0001-8433-7409': 1, '0000-0003-3407-4983': 1, '0000-0002-3425-600X': 1, '0000-0002-2953-2305': 1})\n",
      "['0000-0001-6509-2979', '0000-0003-4614-7182', '0000-0003-0257-860X', '0000-0002-9698-0837', '0000-0002-5756-5198']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 253)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89        17\n",
      "          1       1.00      0.33      0.50        15\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       0.60      0.95      0.73        19\n",
      "          4       0.91      1.00      0.95        20\n",
      "\n",
      "avg / total       0.86      0.80      0.78        85\n",
      "\n",
      "[16  0  0  1  0  1  5  0  8  1  2  0  9  3  0  0  0  0 18  1  0  0  0  0\n",
      " 20]\n",
      "MNB Accuracy:  0.8\n",
      "MNB F1:  0.771714482894607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        17\n",
      "          1       0.75      0.60      0.67        15\n",
      "          2       1.00      0.93      0.96        14\n",
      "          3       0.72      0.95      0.82        19\n",
      "          4       1.00      1.00      1.00        20\n",
      "\n",
      "avg / total       0.89      0.88      0.88        85\n",
      "\n",
      "[15  1  0  1  0  0  9  0  6  0  0  1 13  0  0  0  1  0 18  0  0  0  0  0\n",
      " 20]\n",
      "svc Accuracy:  0.8823529411764706\n",
      "svc F1:  0.8770622895622896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        17\n",
      "          1       1.00      0.40      0.57        15\n",
      "          2       1.00      0.79      0.88        14\n",
      "          3       0.62      0.95      0.75        19\n",
      "          4       0.87      1.00      0.93        20\n",
      "\n",
      "avg / total       0.88      0.84      0.83        85\n",
      "\n",
      "[16  0  0  1  0  0  6  0  8  1  0  0 11  2  1  0  0  0 18  1  0  0  0  0\n",
      " 20]\n",
      "LR Accuracy:  0.8352941176470589\n",
      "LR F1:  0.8202716198530153\n",
      "For name:  s_collins\n",
      "total sample size before apply threshold:  163\n",
      "Counter({'0000-0002-0193-2892': 43, '0000-0002-4276-5840': 38, '0000-0002-0648-7433': 24, '0000-0003-0204-5109': 15, '0000-0001-9989-8794': 13, '0000-0002-5245-6611': 10, '0000-0003-1571-7410': 9, '0000-0002-3110-1037': 7, '0000-0001-5503-7386': 2, '0000-0003-4721-0040': 2})\n",
      "['0000-0002-0193-2892', '0000-0002-4276-5840', '0000-0002-5245-6611', '0000-0003-0204-5109', '0000-0002-0648-7433', '0000-0001-9989-8794']\n",
      "Total sample size after apply threshold:  143\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(143, 693)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.98      0.73        43\n",
      "          1       0.93      1.00      0.96        38\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       1.00      0.47      0.64        15\n",
      "          4       1.00      0.71      0.83        24\n",
      "          5       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.79      0.77      0.74       143\n",
      "\n",
      "[42  1  0  0  0  0  0 38  0  0  0  0 10  0  0  0  0  0  8  0  0  7  0  0\n",
      "  6  1  0  0 17  0  6  1  0  0  0  6]\n",
      "MNB Accuracy:  0.7692307692307693\n",
      "MNB F1:  0.6316118292465626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.98      0.72        43\n",
      "          1       1.00      0.95      0.97        38\n",
      "          2       1.00      0.20      0.33        10\n",
      "          3       0.89      0.53      0.67        15\n",
      "          4       1.00      0.62      0.77        24\n",
      "          5       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.86      0.78      0.77       143\n",
      "\n",
      "[42  0  0  1  0  0  2 36  0  0  0  0  8  0  2  0  0  0  7  0  0  8  0  0\n",
      "  9  0  0  0 15  0  5  0  0  0  0  8]\n",
      "svc Accuracy:  0.7762237762237763\n",
      "svc F1:  0.7047077391904978\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.98      0.70        43\n",
      "          1       1.00      0.97      0.99        38\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.88      0.47      0.61        15\n",
      "          4       1.00      0.62      0.77        24\n",
      "          5       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.78      0.75      0.72       143\n",
      "\n",
      "[42  0  0  1  0  0  1 37  0  0  0  0 10  0  0  0  0  0  8  0  0  7  0  0\n",
      "  9  0  0  0 15  0  7  0  0  0  0  6]\n",
      "LR Accuracy:  0.7482517482517482\n",
      "LR F1:  0.616028672573295\n",
      "For name:  d_franco\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0002-5669-7164': 58, '0000-0002-0093-7042': 40, '0000-0003-3849-4272': 8, '0000-0001-5604-2531': 6, '0000-0002-8653-0488': 2, '0000-0002-2050-7883': 1})\n",
      "['0000-0002-0093-7042', '0000-0002-5669-7164']\n",
      "Total sample size after apply threshold:  98\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 228)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95        40\n",
      "          1       0.98      0.95      0.96        58\n",
      "\n",
      "avg / total       0.96      0.96      0.96        98\n",
      "\n",
      "[39  1  3 55]\n",
      "MNB Accuracy:  0.9591836734693877\n",
      "MNB F1:  0.9580658964484382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        40\n",
      "          1       0.95      1.00      0.97        58\n",
      "\n",
      "avg / total       0.97      0.97      0.97        98\n",
      "\n",
      "[37  3  0 58]\n",
      "svc Accuracy:  0.9693877551020408\n",
      "svc F1:  0.9679144385026738\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        40\n",
      "          1       0.91      1.00      0.95        58\n",
      "\n",
      "avg / total       0.94      0.94      0.94        98\n",
      "\n",
      "[34  6  0 58]\n",
      "LR Accuracy:  0.9387755102040817\n",
      "LR F1:  0.9348692955250332\n",
      "For name:  h_brown\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-8578-5510': 17, '0000-0002-0067-991X': 9, '0000-0003-4870-8369': 8, '0000-0001-7418-5536': 6, '0000-0001-6227-5147': 3, '0000-0001-9404-9515': 3, '0000-0003-2292-7766': 2})\n",
      "['0000-0001-8578-5510']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  s_martins\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0002-9396-5957': 18, '0000-0002-3720-2920': 15, '0000-0001-7217-6273': 15, '0000-0003-0237-6370': 12, '0000-0002-1812-8913': 8, '0000-0002-1874-0192': 7, '0000-0002-7733-4485': 5, '0000-0003-2122-0670': 3, '0000-0002-3526-3199': 1})\n",
      "['0000-0002-3720-2920', '0000-0003-0237-6370', '0000-0001-7217-6273', '0000-0002-9396-5957']\n",
      "Total sample size after apply threshold:  60\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 159)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "60\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        15\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       1.00      1.00      1.00        15\n",
      "          3       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.95      0.93      0.93        60\n",
      "\n",
      "[13  0  0  2  0 10  0  2  0  0 15  0  0  0  0 18]\n",
      "MNB Accuracy:  0.9333333333333333\n",
      "MNB F1:  0.9344155844155844\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       1.00      1.00      1.00        15\n",
      "          3       1.00      0.94      0.97        18\n",
      "\n",
      "avg / total       0.95      0.93      0.93        60\n",
      "\n",
      "[15  0  0  0  3  9  0  0  0  0 15  0  1  0  0 17]\n",
      "svc Accuracy:  0.9333333333333333\n",
      "svc F1:  0.9277310924369748\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        15\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       1.00      1.00      1.00        15\n",
      "          3       0.86      1.00      0.92        18\n",
      "\n",
      "avg / total       0.94      0.93      0.93        60\n",
      "\n",
      "[14  0  0  1  1  9  0  2  0  0 15  0  0  0  0 18]\n",
      "LR Accuracy:  0.9333333333333333\n",
      "LR F1:  0.9283882783882783\n",
      "For name:  m_ruiz\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0003-4174-6688': 40, '0000-0002-2734-2196': 32, '0000-0002-1530-9508': 9, '0000-0002-1337-0110': 5, '0000-0001-8617-667X': 4, '0000-0001-7492-9873': 3, '0000-0003-4419-1649': 3, '0000-0002-2926-702X': 3, '0000-0003-1437-5578': 2, '0000-0002-4670-9037': 2, '0000-0002-4917-1252': 2, '0000-0002-1286-6624': 2, '0000-0002-6799-1537': 1, '0000-0002-1116-206X': 1, '0000-0003-0118-668X': 1, '0000-0002-8527-4734': 1})\n",
      "['0000-0003-4174-6688', '0000-0002-2734-2196']\n",
      "Total sample size after apply threshold:  72\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 157)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        40\n",
      "          1       1.00      0.84      0.92        32\n",
      "\n",
      "avg / total       0.94      0.93      0.93        72\n",
      "\n",
      "[40  0  5 27]\n",
      "MNB Accuracy:  0.9305555555555556\n",
      "MNB F1:  0.9282153539381854\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        40\n",
      "          1       0.94      1.00      0.97        32\n",
      "\n",
      "avg / total       0.97      0.97      0.97        72\n",
      "\n",
      "[38  2  0 32]\n",
      "svc Accuracy:  0.9722222222222222\n",
      "svc F1:  0.9720279720279721\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        40\n",
      "          1       0.97      1.00      0.98        32\n",
      "\n",
      "avg / total       0.99      0.99      0.99        72\n",
      "\n",
      "[39  1  0 32]\n",
      "LR Accuracy:  0.9861111111111112\n",
      "LR F1:  0.9859785783836417\n",
      "For name:  a_levy\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0003-4770-1886': 13, '0000-0002-6709-4190': 6, '0000-0002-5856-8294': 3, '0000-0002-1521-658X': 1})\n",
      "['0000-0003-4770-1886']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  j_murray\n",
      "total sample size before apply threshold:  213\n",
      "Counter({'0000-0002-2282-3839': 78, '0000-0002-8897-0161': 32, '0000-0002-8992-7317': 23, '0000-0002-6928-2347': 23, '0000-0001-9314-2283': 18, '0000-0001-8224-679X': 13, '0000-0003-1941-9090': 11, '0000-0002-8577-7964': 8, '0000-0003-2994-4155': 3, '0000-0002-8741-4964': 1, '0000-0003-4390-1039': 1, '0000-0001-9721-992X': 1, '0000-0003-3000-9199': 1})\n",
      "['0000-0002-2282-3839', '0000-0001-9314-2283', '0000-0002-8992-7317', '0000-0003-1941-9090', '0000-0002-8897-0161', '0000-0001-8224-679X', '0000-0002-6928-2347']\n",
      "Total sample size after apply threshold:  198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(198, 651)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "198\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67        78\n",
      "          1       1.00      0.22      0.36        18\n",
      "          2       1.00      0.87      0.93        23\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.59      0.75        32\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.57      0.61      0.53       198\n",
      "\n",
      "[78  0  0  0  0  0  0 14  4  0  0  0  0  0  3  0 20  0  0  0  0 11  0  0\n",
      "  0  0  0  0 13  0  0  0 19  0  0 13  0  0  0  0  0  0 23  0  0  0  0  0\n",
      "  0]\n",
      "MNB Accuracy:  0.6111111111111112\n",
      "MNB F1:  0.38692783685532756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      1.00      0.78        78\n",
      "          1       1.00      0.56      0.71        18\n",
      "          2       1.00      0.91      0.95        23\n",
      "          3       1.00      0.45      0.62        11\n",
      "          4       1.00      0.69      0.81        32\n",
      "          5       1.00      0.46      0.63        13\n",
      "          6       0.92      0.52      0.67        23\n",
      "\n",
      "avg / total       0.85      0.78      0.77       198\n",
      "\n",
      "[78  0  0  0  0  0  0  8 10  0  0  0  0  0  2  0 21  0  0  0  0  6  0  0\n",
      "  5  0  0  0 10  0  0  0 22  0  0  6  0  0  0  0  6  1 11  0  0  0  0  0\n",
      " 12]\n",
      "svc Accuracy:  0.7777777777777778\n",
      "svc F1:  0.7415444565244317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      1.00      0.65        78\n",
      "          1       1.00      0.17      0.29        18\n",
      "          2       1.00      0.83      0.90        23\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.44      0.61        32\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.56      0.58      0.49       198\n",
      "\n",
      "[78  0  0  0  0  0  0 15  3  0  0  0  0  0  4  0 19  0  0  0  0 11  0  0\n",
      "  0  0  0  0 18  0  0  0 14  0  0 13  0  0  0  0  0  0 23  0  0  0  0  0\n",
      "  0]\n",
      "LR Accuracy:  0.5757575757575758\n",
      "LR F1:  0.3498816918071576\n",
      "For name:  y_hou\n",
      "total sample size before apply threshold:  162\n",
      "Counter({'0000-0001-6546-2597': 97, '0000-0002-3995-7219': 29, '0000-0002-0420-0726': 14, '0000-0002-8114-166X': 12, '0000-0002-7360-5751': 5, '0000-0002-4978-9829': 4, '0000-0003-3195-7430': 1})\n",
      "['0000-0002-3995-7219', '0000-0002-8114-166X', '0000-0001-6546-2597', '0000-0002-0420-0726']\n",
      "Total sample size after apply threshold:  152\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(152, 320)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "152\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        29\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.92      1.00      0.96        97\n",
      "          3       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.95      0.94      0.93       152\n",
      "\n",
      "[29  0  0  0  1 10  1  0  0  0 97  0  0  0  7  7]\n",
      "MNB Accuracy:  0.9407894736842105\n",
      "MNB F1:  0.8798011157047908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        29\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.95      1.00      0.97        97\n",
      "          3       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97       152\n",
      "\n",
      "[29  0  0  0  0 10  2  0  0  0 97  0  0  0  3 11]\n",
      "svc Accuracy:  0.9671052631578947\n",
      "svc F1:  0.9409913202375514\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        29\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.87      1.00      0.93        97\n",
      "          3       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.91      0.90      0.89       152\n",
      "\n",
      "[23  0  6  0  0 10  2  0  0  0 97  0  0  0  7  7]\n",
      "LR Accuracy:  0.9013157894736842\n",
      "LR F1:  0.8471506563611827\n",
      "For name:  m_sahin\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-7044-2953': 41, '0000-0002-3490-6009': 3, '0000-0001-6502-2209': 2, '0000-0001-7677-8423': 2})\n",
      "['0000-0001-7044-2953']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  c_feng\n",
      "total sample size before apply threshold:  88\n",
      "Counter({'0000-0002-1854-356X': 30, '0000-0002-2130-8851': 26, '0000-0003-3267-0968': 12, '0000-0002-7031-4211': 12, '0000-0002-3278-9451': 7, '0000-0003-1085-4395': 1})\n",
      "['0000-0002-1854-356X', '0000-0002-2130-8851', '0000-0003-3267-0968', '0000-0002-7031-4211']\n",
      "Total sample size after apply threshold:  80\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(80, 86)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "80\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        30\n",
      "          1       0.81      1.00      0.90        26\n",
      "          2       1.00      0.58      0.74        12\n",
      "          3       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.92      0.90      0.89        80\n",
      "\n",
      "[30  0  0  0  0 26  0  0  2  3  7  0  0  3  0  9]\n",
      "MNB Accuracy:  0.9\n",
      "MNB F1:  0.8645696555069543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        30\n",
      "          1       0.90      1.00      0.95        26\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.97      0.96      0.96        80\n",
      "\n",
      "[29  1  0  0  0 26  0  0  0  2 10  0  0  0  0 12]\n",
      "svc Accuracy:  0.9625\n",
      "svc F1:  0.9593990755007704\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        30\n",
      "          1       0.93      1.00      0.96        26\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.98      0.97      0.97        80\n",
      "\n",
      "[30  0  0  0  0 26  0  0  0  2 10  0  0  0  0 12]\n",
      "LR Accuracy:  0.975\n",
      "LR F1:  0.968013468013468\n",
      "For name:  j_coutinho\n",
      "total sample size before apply threshold:  129\n",
      "Counter({'0000-0002-3841-743X': 105, '0000-0002-6303-9549': 13, '0000-0002-1562-0099': 8, '0000-0003-0280-366X': 3})\n",
      "['0000-0002-6303-9549', '0000-0002-3841-743X']\n",
      "Total sample size after apply threshold:  118\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(118, 181)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "118\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.92      1.00      0.96       105\n",
      "\n",
      "avg / total       0.93      0.92      0.91       118\n",
      "\n",
      "[  4   9   0 105]\n",
      "MNB Accuracy:  0.923728813559322\n",
      "MNB F1:  0.7147461724415793\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.95      1.00      0.98       105\n",
      "\n",
      "avg / total       0.96      0.96      0.95       118\n",
      "\n",
      "[  8   5   0 105]\n",
      "svc Accuracy:  0.9576271186440678\n",
      "svc F1:  0.8693244739756368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.89      1.00      0.94       105\n",
      "\n",
      "avg / total       0.79      0.89      0.84       118\n",
      "\n",
      "[  0  13   0 105]\n",
      "LR Accuracy:  0.8898305084745762\n",
      "LR F1:  0.47085201793721976\n",
      "For name:  s_huber\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-4125-159X': 26, '0000-0003-3558-351X': 12, '0000-0002-8271-7835': 3, '0000-0002-5842-5859': 2, '0000-0001-6303-5188': 1})\n",
      "['0000-0003-3558-351X', '0000-0002-4125-159X']\n",
      "Total sample size after apply threshold:  38\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 93)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.84      1.00      0.91        26\n",
      "\n",
      "avg / total       0.89      0.87      0.86        38\n",
      "\n",
      "[ 7  5  0 26]\n",
      "MNB Accuracy:  0.868421052631579\n",
      "MNB F1:  0.8245614035087718\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.84      1.00      0.91        26\n",
      "\n",
      "avg / total       0.89      0.87      0.86        38\n",
      "\n",
      "[ 7  5  0 26]\n",
      "svc Accuracy:  0.868421052631579\n",
      "svc F1:  0.8245614035087718\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.70      1.00      0.83        26\n",
      "\n",
      "avg / total       0.80      0.71      0.61        38\n",
      "\n",
      "[ 1 11  0 26]\n",
      "LR Accuracy:  0.7105263157894737\n",
      "LR F1:  0.48962148962148966\n",
      "For name:  a_rocha\n",
      "total sample size before apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "Counter({'0000-0003-3218-7001': 26, '0000-0001-9710-9835': 21, '0000-0003-2165-5519': 12, '0000-0002-4094-7982': 3, '0000-0002-5637-1041': 3, '0000-0001-6528-9034': 3, '0000-0003-4940-6522': 2, '0000-0003-0298-8246': 2, '0000-0001-8679-2886': 1})\n",
      "['0000-0001-9710-9835', '0000-0003-2165-5519', '0000-0003-3218-7001']\n",
      "Total sample size after apply threshold:  59\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 108)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        21\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       0.87      1.00      0.93        26\n",
      "\n",
      "avg / total       0.94      0.93      0.93        59\n",
      "\n",
      "[18  0  3  0 11  1  0  0 26]\n",
      "MNB Accuracy:  0.9322033898305084\n",
      "MNB F1:  0.9360566969262623\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.86      0.88        21\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.90      1.00      0.95        26\n",
      "\n",
      "avg / total       0.92      0.92      0.91        59\n",
      "\n",
      "[18  0  3  2 10  0  0  0 26]\n",
      "svc Accuracy:  0.9152542372881356\n",
      "svc F1:  0.9108647450110864\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        21\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.81      1.00      0.90        26\n",
      "\n",
      "avg / total       0.92      0.90      0.90        59\n",
      "\n",
      "[17  0  4  0 10  2  0  0 26]\n",
      "LR Accuracy:  0.8983050847457628\n",
      "LR F1:  0.9001264917780345\n",
      "For name:  a_white\n",
      "total sample size before apply threshold:  386\n",
      "Counter({'0000-0002-9668-4632': 108, '0000-0003-1802-9891': 87, '0000-0002-7686-2884': 85, '0000-0001-9639-5200': 41, '0000-0002-5442-6985': 16, '0000-0002-9859-0947': 13, '0000-0002-1539-0158': 9, '0000-0001-5530-742X': 9, '0000-0001-7499-7390': 4, '0000-0002-3904-2019': 4, '0000-0002-7771-3899': 3, '0000-0002-9708-2406': 2, '0000-0002-2783-895X': 2, '0000-0002-7268-5163': 1, '0000-0002-4837-7128': 1, '0000-0002-7106-6440': 1})\n",
      "['0000-0002-7686-2884', '0000-0002-5442-6985', '0000-0002-9668-4632', '0000-0002-9859-0947', '0000-0001-9639-5200', '0000-0003-1802-9891']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 350\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(350, 1067)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "350\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.91        85\n",
      "          1       1.00      0.19      0.32        16\n",
      "          2       0.76      0.99      0.86       108\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       1.00      0.73      0.85        41\n",
      "          5       0.98      0.98      0.98        87\n",
      "\n",
      "avg / total       0.86      0.87      0.84       350\n",
      "\n",
      "[ 80   0   4   0   0   1   5   3   8   0   0   0   0   0 107   0   0   1\n",
      "   2   0  11   0   0   0   3   0   8   0  30   0   0   0   2   0   0  85]\n",
      "MNB Accuracy:  0.8714285714285714\n",
      "MNB F1:  0.6525100550940768\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.89      0.93        85\n",
      "          1       1.00      0.69      0.81        16\n",
      "          2       0.74      1.00      0.85       108\n",
      "          3       1.00      0.31      0.47        13\n",
      "          4       1.00      0.73      0.85        41\n",
      "          5       1.00      0.92      0.96        87\n",
      "\n",
      "avg / total       0.91      0.88      0.88       350\n",
      "\n",
      "[ 76   0   9   0   0   0   1  11   4   0   0   0   0   0 108   0   0   0\n",
      "   0   0   9   4   0   0   2   0   9   0  30   0   0   0   7   0   0  80]\n",
      "svc Accuracy:  0.8828571428571429\n",
      "svc F1:  0.8109633790099263\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.88      0.91        85\n",
      "          1       1.00      0.25      0.40        16\n",
      "          2       0.68      1.00      0.81       108\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       1.00      0.68      0.81        41\n",
      "          5       1.00      0.92      0.96        87\n",
      "\n",
      "avg / total       0.85      0.84      0.82       350\n",
      "\n",
      "[ 75   0  10   0   0   0   2   4  10   0   0   0   0   0 108   0   0   0\n",
      "   0   0  13   0   0   0   2   0  11   0  28   0   0   0   7   0   0  80]\n",
      "LR Accuracy:  0.8428571428571429\n",
      "LR F1:  0.6488834909367146\n",
      "For name:  j_scott\n",
      "total sample size before apply threshold:  342\n",
      "Counter({'0000-0002-7203-8601': 155, '0000-0002-0744-0688': 60, '0000-0003-0765-9054': 44, '0000-0002-9116-948X': 36, '0000-0002-7513-6768': 21, '0000-0002-9916-6523': 8, '0000-0001-7782-3601': 7, '0000-0002-5073-0832': 6, '0000-0003-2368-8218': 1, '0000-0003-2971-7673': 1, '0000-0002-5616-2688': 1, '0000-0002-4900-0891': 1, '0000-0001-8408-5176': 1})\n",
      "['0000-0002-7203-8601', '0000-0003-0765-9054', '0000-0002-0744-0688', '0000-0002-9116-948X', '0000-0002-7513-6768']\n",
      "Total sample size after apply threshold:  316\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(316, 1124)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      1.00      0.78       155\n",
      "          1       1.00      0.41      0.58        44\n",
      "          2       1.00      0.65      0.79        60\n",
      "          3       1.00      0.44      0.62        36\n",
      "          4       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.76      0.72      0.68       316\n",
      "\n",
      "[155   0   0   0   0  26  18   0   0   0  21   0  39   0   0  20   0   0\n",
      "  16   0  21   0   0   0   0]\n",
      "MNB Accuracy:  0.7215189873417721\n",
      "MNB F1:  0.552560607383107\n"
     ]
    }
   ],
   "source": [
    "# load the file\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "fileDir = \"../Data/\"+Dataset+\"/canopies_labeled/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "# collect statistic to output\n",
    "allname = []\n",
    "num_class = []\n",
    "per_class_count = []\n",
    "average_textual_size = []\n",
    "\n",
    "all_mnb_accuracy = []\n",
    "all_mnb_f1 = []\n",
    "all_svcLinear_accuracy = []\n",
    "all_svcLinear_f1 = []\n",
    "all_LR_accuracy = []\n",
    "all_LR_f1 = []\n",
    "\n",
    "# read all file in labeled group\n",
    "for file in listfiles:\n",
    "    # group name\n",
    "    temp = file.split(\"_\")\n",
    "    name = temp[1]+\"_\"+temp[-1]\n",
    "    print(\"For name: \",name)\n",
    "    allname.append(name)\n",
    "    # read needed content in labeled file\n",
    "    labeled_data = read_labeled_file(fileDir+file)\n",
    "    print(\"total sample size before apply threshold: \",len(labeled_data))\n",
    "    # count number of paper each author write based on author ID\n",
    "    paperCounter = collections.Counter(labeled_data[\"authorID\"])\n",
    "    print(paperCounter)\n",
    "    # collect per class statistic\n",
    "    for k in list(paperCounter):\n",
    "        if paperCounter[k] < threshold:\n",
    "            del paperCounter[k]\n",
    "    temp =list(paperCounter.keys())\n",
    "    print(temp)\n",
    "    per_class_count.append(paperCounter)\n",
    "    num_class.append(len(paperCounter))\n",
    "    # remove samples that are smaller than threshold\n",
    "    labeled_data = labeled_data[labeled_data.authorID.isin(temp)]\n",
    "    print(\"Total sample size after apply threshold: \",len(labeled_data))\n",
    "    # if only have one class or no class pass the threshold, not applicable\n",
    "    if(len(paperCounter)==0) or (len(paperCounter)==1):\n",
    "        average_textual_size.append(\"Not applicable\")\n",
    "        all_mnb_accuracy.append(\"Not applicable\")\n",
    "        all_mnb_f1.append(\"Not applicable\")\n",
    "        all_svcLinear_accuracy.append(\"Not applicable\")\n",
    "        all_svcLinear_f1.append(\"Not applicable\")\n",
    "        all_LR_accuracy.append(\"Not applicable\")\n",
    "        all_LR_f1.append(\"Not applicable\")\n",
    "    else:\n",
    "        # convert author id to label\n",
    "        gather_label = []\n",
    "        for index, record in labeled_data.iterrows():\n",
    "            gather_label.append(temp.index(record[\"authorID\"]))\n",
    "        labeled_data[\"label\"] = gather_label\n",
    "        # shuffle the data\n",
    "        labeled_data = labeled_data.sample(frac=1).reset_index(drop=True)\n",
    "        # extract true label and pid\n",
    "        label = labeled_data[\"label\"]\n",
    "        pid = labeled_data[\"paperID\"]\n",
    "        # list of different data field\n",
    "        part_collection = []\n",
    "        # data part 1, co-author matrix\n",
    "        data_part_co_author = co_author_to_vector(labeled_data[\"co-author\"], emb_type=coauthor_emb_type)\n",
    "        print(data_part_co_author.shape)\n",
    "        part_collection.append(data_part_co_author)\n",
    "        # data part 2.1, venue_id that author attend\n",
    "        data_part_venue = venue_to_vector(labeled_data[\"venue_id\"], emb_type=venue_emb_type)\n",
    "        print(data_part_venue.shape)\n",
    "        part_collection.append(data_part_venue)\n",
    "        # data part 2.2 year that author attend\n",
    "        data_part_year = year_to_vector(labeled_data[\"publish_year\"], emb_type=year_emb_type)\n",
    "        print(data_part_year.shape)\n",
    "        part_collection.append(data_part_year)\n",
    "        # merge different part of data data together by concatenate it all together\n",
    "        # remove empty emb (when emb set off)\n",
    "        part_collection = [part for part in part_collection if len(part)!=0]\n",
    "        print(len(part_collection))\n",
    "        if len(part_collection)>1:\n",
    "            combinedata = np.concatenate(part_collection,axis=1)\n",
    "        elif len(part_collection)==1:\n",
    "            if isinstance(part_collection[0], pd.DataFrame):\n",
    "                combinedata = part_collection[0].values\n",
    "            else:\n",
    "                combinedata = part_collection[0]\n",
    "        else:\n",
    "            print(\"No data available\")\n",
    "            break\n",
    "        print(len(combinedata))\n",
    "        # using converted feature vector to train classifier\n",
    "        # using Multinomial naive bayes\n",
    "        clf = MultinomialNB()\n",
    "        # use 10 fold cv\n",
    "        mnbaccuracy, mnbmarcof1 = k_fold_cv(combinedata, label, clf, k=10)\n",
    "        print(\"MNB Accuracy: \",mnbaccuracy)\n",
    "        print(\"MNB F1: \", mnbmarcof1)\n",
    "        all_mnb_accuracy.append(mnbaccuracy)\n",
    "        all_mnb_f1.append(mnbmarcof1)\n",
    "        # using SVM with linear kernal\n",
    "        clf = SVC(decision_function_shape='ovr', kernel='linear')\n",
    "        svcaccuracy, svcmarcof1 = k_fold_cv(combinedata, label, clf, k=10)\n",
    "        print(\"svc Accuracy: \",svcaccuracy)\n",
    "        print(\"svc F1: \", svcmarcof1)\n",
    "        all_svcLinear_accuracy.append(svcaccuracy)\n",
    "        all_svcLinear_f1.append(svcmarcof1)\n",
    "        # using logistic regression\n",
    "        clf = LogisticRegression(multi_class='ovr')\n",
    "        LRaccuracy, LRmarcof1 = k_fold_cv(combinedata, label, clf, k=10)\n",
    "        print(\"LR Accuracy: \",LRaccuracy)\n",
    "        print(\"LR F1: \", LRmarcof1)\n",
    "        all_LR_accuracy.append(LRaccuracy)\n",
    "        all_LR_f1.append(LRmarcof1)\n",
    "# write evaluation result to excel\n",
    "output = pd.DataFrame({'Name Group':allname,\"Class number\":num_class,\"per_class_size\":per_class_count, \n",
    "                       \"svc(linear) accuracy\":all_svcLinear_accuracy, \"svc(linear) macro f1\": all_svcLinear_f1, \n",
    "                       \"mnb accuracy\":all_mnb_accuracy, \"mnb macro f1\": all_mnb_f1,\n",
    "                       \"logistic regression accuracy\":all_LR_accuracy, \"logistic regression macro f1\": all_LR_f1})\n",
    "\n",
    "savePath = \"../result/\"+Dataset+\"/coauthor_only/\"\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "filename = \"2004_coauthor_only_\"+coauthor_emb_type+\"_threshold=\"+str(threshold)+\".csv\"\n",
    "output.to_csv(savePath+filename, encoding='utf-8',index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-02T02:25:09.386Z"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "from statistics import mean \n",
    "cleaned_mnb_accuracy = [x for x in all_mnb_accuracy if isinstance(x, float)]\n",
    "cleaned_svcLinear_accuracy = [x for x in all_svcLinear_accuracy if isinstance(x, float)]\n",
    "cleaned_lr_accuracy = [x for x in all_LR_accuracy if isinstance(x, float)]\n",
    "print(len(cleaned_mnb_accuracy))\n",
    "print(len(cleaned_svcLinear_accuracy))\n",
    "print(len(cleaned_lr_accuracy))\n",
    "print(mean(cleaned_mnb_accuracy))\n",
    "print(mean(cleaned_svcLinear_accuracy))\n",
    "print(mean(cleaned_lr_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-02T02:25:09.643Z"
    }
   },
   "outputs": [],
   "source": [
    "# f1\n",
    "from statistics import mean \n",
    "# remove string from result\n",
    "cleaned_mnb_f1 = [x for x in all_mnb_f1 if isinstance(x, float)]\n",
    "cleaned_svcLinear_f1 = [x for x in all_svcLinear_f1 if isinstance(x, float)]\n",
    "cleaned_lr_f1 = [x for x in all_LR_f1 if isinstance(x, float)]\n",
    "print(len(cleaned_mnb_f1))\n",
    "print(len(cleaned_svcLinear_f1))\n",
    "print(len(cleaned_lr_f1))\n",
    "print(mean(cleaned_mnb_f1))\n",
    "print(mean(cleaned_svcLinear_f1))\n",
    "print(mean(cleaned_lr_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-29T21:26:31.930Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%who"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
