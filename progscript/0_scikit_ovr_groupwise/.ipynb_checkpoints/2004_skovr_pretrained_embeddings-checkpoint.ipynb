{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T14:42:02.142788Z",
     "start_time": "2018-12-18T14:42:02.119399Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "threshold = 100\n",
    "cutoff = 3\n",
    "Dataset = \"pubmed\"\n",
    "\n",
    "pp_textual = \"pv_dbow\"\n",
    "citation_emb = \"n2v\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T14:42:02.820313Z",
     "start_time": "2018-12-18T14:42:02.675645Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read trained rec to rec textual graph\n",
    "def read_textual_embedding(Dataset = \"pubmed\", emb_type = \"off\"):\n",
    "    textual_emb = []\n",
    "    while True:\n",
    "        if emb_type == \"pv_dm\":\n",
    "            loadDir = \"../../Data/\"+Dataset+\"/vectors/d2v/textual_sample=3m/extracted_labeled_pv_dm.txt\"\n",
    "            with open(loadDir, 'r', encoding = 'utf8') as f:\n",
    "                for line in f:\n",
    "                    read_data = line.split(\" \")\n",
    "                    paper_Vectors = read_data\n",
    "                    textual_emb.append(paper_Vectors)\n",
    "            f.close()\n",
    "\n",
    "            print(\"Total textual vector records:\",len(textual_emb))\n",
    "            print(textual_emb[0])\n",
    "            break\n",
    "        elif emb_type == \"pv_dbow\":\n",
    "            loadDir = \"../../Data/\"+Dataset+\"/vectors/d2v/textual_sample=3m/extracted_labeled_pv_dbow.txt\"\n",
    "            with open(loadDir, 'r', encoding = 'utf8') as f:\n",
    "                for line in f:\n",
    "                    read_data = line.split(\" \")\n",
    "                    paper_Vectors = read_data\n",
    "                    textual_emb.append(paper_Vectors)\n",
    "            f.close()\n",
    "            \n",
    "            print(\"Total textual vector records:\",len(textual_emb))\n",
    "            print(textual_emb[0])\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return textual_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T14:42:03.303987Z",
     "start_time": "2018-12-18T14:42:03.230700Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read trained rec to rec node2vec citation graph\n",
    "def read_citation_embedding(Dataset = \"pubmed\", emb_type = \"off\"):\n",
    "    citation_emb = []\n",
    "    while True:\n",
    "        if emb_type == \"n2v\":\n",
    "            citation_emb_dir = \"../../Data/\"+Dataset+\"/vectors/\"+emb_type+\"/extracted_labeled_n2v.txt\"\n",
    "            with open(citation_emb_dir, 'r', encoding = 'utf8') as f:\n",
    "                for line in f:\n",
    "                    read_data = line.split(\" \")\n",
    "                    if(len(read_data)==101):\n",
    "                        paper_Vectors = read_data\n",
    "                        citation_emb.append(paper_Vectors)\n",
    "            f.close()\n",
    "            print(\"Total citation vector records:\",len(citation_emb))\n",
    "            print(citation_emb[:3])\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return citation_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T14:42:03.823953Z",
     "start_time": "2018-12-18T14:42:03.783907Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_labeled_file(infile):\n",
    "    LabeledRecords_original = []\n",
    "    with open(infile, 'r', encoding = 'utf8') as f:\n",
    "        for line in f:\n",
    "            read_data = line.split(\"\\t\")\n",
    "            # get ride of bad formated lines\n",
    "            if(len(read_data)==13 or len(read_data)==12):\n",
    "                paper_detail = {\"paperID\": read_data[0], \"authorID\":read_data[1], \n",
    "                                \"co-author\": read_data[5], \"venue_id\": read_data[7]}\n",
    "                LabeledRecords_original.append(paper_detail)\n",
    "            else:\n",
    "                print(len(read_data))\n",
    "        f.close()\n",
    "    return pd.DataFrame(LabeledRecords_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T14:42:04.407279Z",
     "start_time": "2018-12-18T14:42:04.352383Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_embedding(all_embedding, pid):\n",
    "    extracted_emb = []\n",
    "    wanted_pid = pid.values.tolist()\n",
    "    # only if embedding exist\n",
    "    if len(all_embedding)>0:\n",
    "        for paper_embedding in all_embedding:\n",
    "            if paper_embedding[0] in wanted_pid:\n",
    "                extracted_emb.append(paper_embedding)\n",
    "    \n",
    "    extracted_emb = pd.DataFrame(extracted_emb)\n",
    "    # only if embedding exist\n",
    "    if len(all_embedding)>0:\n",
    "        # reorder embedding with pid and fill empty record with 0\n",
    "        extracted_emb = pd.merge(pid.to_frame(), extracted_emb, left_on='paperID', right_on=0, how='outer')\n",
    "        # fill missing value with 0\n",
    "        extracted_emb.fillna(0, inplace = True)\n",
    "        # remove index\n",
    "        extracted_emb.drop(['paperID', 0], axis=1, inplace=True)\n",
    "    return extracted_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T14:42:06.026635Z",
     "start_time": "2018-12-18T14:42:04.922777Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "def normal_group_predict(X_train, y_train, X_test, y_test, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    # get predicted label\n",
    "    label_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,label_pred)\n",
    "    f1 = f1_score(y_test, label_pred,average='macro')\n",
    "    \n",
    "    print(metrics.classification_report(y_test, label_pred))\n",
    "    print(metrics.confusion_matrix(y_test, label_pred).ravel())\n",
    "    \n",
    "    # accumulate statistic for entire model f1\n",
    "    cnf_matrix = confusion_matrix(y_test, label_pred)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "#     print(cnf_matrix)\n",
    "#     print(\"TP: \",TP, \"TN: \",TN, \"FP: \",FP,\"FN: \",FN)\n",
    "    return accuracy, f1, TP.sum(), TN.sum(), FP.sum(), FN.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T14:42:07.392886Z",
     "start_time": "2018-12-18T14:42:07.182735Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "# cross validation\n",
    "def k_fold_cv(data, label, clf, k=10):\n",
    "    kf = KFold(n_splits=k, shuffle=False)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data[train_index], data[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        # fit data to clf\n",
    "        clf.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = clf.predict(data_test)\n",
    "        allTrueLabel.extend(label_test)\n",
    "        allPredLabel.extend(label_pred)\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "\n",
    "    accuracy = accuracy_score(allTrueLabel, allPredLabel)\n",
    "    f1 = f1_score(allTrueLabel, allPredLabel,average='macro')\n",
    "    \n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel).ravel())\n",
    "    \n",
    "    # accumulate statistic for entire model f1\n",
    "    cnf_matrix = confusion_matrix(allTrueLabel, allPredLabel)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "#     print(cnf_matrix)\n",
    "#     print(\"TP: \",TP, \"TN: \",TN, \"FP: \",FP,\"FN: \",FN)\n",
    "\n",
    "    return accuracy, f1, TP.sum(), TN.sum(), FP.sum(), FN.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T14:42:08.311718Z",
     "start_time": "2018-12-18T14:42:08.247620Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_csv_df(savePath, filename, df):\n",
    "    if not os.path.exists(savePath):\n",
    "        os.makedirs(savePath)\n",
    "    # Give the filename you wish to save the file to\n",
    "    pathfile = os.path.normpath(os.path.join(savePath,filename))\n",
    "\n",
    "    # Use this function to search for any files which match your filename\n",
    "    files_present = os.path.isfile(pathfile) \n",
    "    # if no matching files, write to csv, if there are matching files, print statement\n",
    "    if not files_present:\n",
    "        df.to_csv(pathfile, encoding='utf-8',index=False)\n",
    "    else:\n",
    "        overwrite = input(\"WARNING: \" + pathfile + \" already exists! Do you want to overwrite <y/n>? \\n \")\n",
    "        if overwrite == 'y':\n",
    "            df.to_csv(pathfile, encoding='utf-8',index=False)\n",
    "        elif overwrite == 'n':\n",
    "            new_filename = input(\"Type new filename: \\n \")\n",
    "            write_csv_df(savePath,new_filename,df)\n",
    "        else:\n",
    "            print(\"Not a valid input. Data is NOT saved!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T14:42:09.485507Z",
     "start_time": "2018-12-18T14:42:09.149530Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Data/pubmed/vectors/d2v/extracted_labeled_pv_dbow.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8367074d0d9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read pretrained embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_textual_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_textual_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp_textual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mall_citation_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_citation_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcitation_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-079ab7379ca8>\u001b[0m in \u001b[0;36mread_textual_embedding\u001b[0;34m(Dataset, emb_type)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0memb_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pv_dbow\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloadDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../../Data/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/vectors/d2v/extracted_labeled_pv_dbow.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloadDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mread_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Data/pubmed/vectors/d2v/extracted_labeled_pv_dbow.txt'"
     ]
    }
   ],
   "source": [
    "# read pretrained embeddings\n",
    "all_textual_embedding = read_textual_embedding(emb_type = pp_textual)\n",
    "all_citation_embedding = read_citation_embedding(emb_type = citation_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T14:42:16.413201Z",
     "start_time": "2018-12-18T14:42:14.022929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For name:  j_read\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5159-1192': 57, '0000-0002-9029-5185': 39, '0000-0002-9697-0962': 31, '0000-0002-4739-9245': 3, '0000-0003-0605-5259': 3, '0000-0003-4316-7006': 1, '0000-0002-0784-0091': 1, '0000-0002-3888-6631': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "j_read  pass\n",
      "For name:  f_esteves\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-3046-1313': 18, '0000-0002-5403-0091': 12, '0000-0003-0589-0746': 3, '0000-0003-3172-6253': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "f_esteves  pass\n",
      "For name:  c_miller\n",
      "total sample size before apply threshold:  252\n",
      "Counter({'0000-0003-4341-1283': 51, '0000-0002-3989-7973': 40, '0000-0002-3813-1706': 39, '0000-0003-2772-9531': 27, '0000-0001-6082-9273': 22, '0000-0002-2601-4422': 22, '0000-0002-9448-8144': 19, '0000-0001-8628-4902': 15, '0000-0002-2936-7717': 6, '0000-0003-3898-9734': 6, '0000-0002-5074-6914': 2, '0000-0003-4266-6700': 1, '0000-0002-9286-9787': 1, '0000-0002-0821-0892': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "c_miller  pass\n",
      "For name:  r_jha\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0002-2891-8353': 6, '0000-0003-0332-2542': 3, '0000-0003-1877-1973': 1, '0000-0002-7755-7443': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "r_jha  pass\n",
      "For name:  a_lowe\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0002-4691-8162': 69, '0000-0001-6650-7486': 22, '0000-0002-0558-3597': 10, '0000-0003-1139-2516': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "a_lowe  pass\n",
      "For name:  a_vega\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-8207-9925': 10, '0000-0002-2178-2780': 8, '0000-0002-8148-5702': 1, '0000-0003-1082-0961': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "a_vega  pass\n",
      "For name:  k_smith\n",
      "total sample size before apply threshold:  338\n",
      "Counter({'0000-0002-6736-4779': 133, '0000-0001-8088-566X': 75, '0000-0002-1323-627X': 29, '0000-0002-8914-6457': 23, '0000-0001-6828-7480': 19, '0000-0001-8150-5702': 15, '0000-0003-2793-3460': 14, '0000-0002-4530-6914': 13, '0000-0003-2802-4939': 8, '0000-0002-0932-1412': 4, '0000-0002-2424-6254': 1, '0000-0001-6957-5361': 1, '0000-0002-7807-2472': 1, '0000-0002-0346-2820': 1, '0000-0003-2060-9369': 1})\n",
      "['0000-0002-6736-4779']\n",
      "Total sample size after apply threshold:  133\n",
      "k_smith  pass\n",
      "For name:  j_gordon\n",
      "total sample size before apply threshold:  19\n",
      "Counter({'0000-0002-0061-2168': 12, '0000-0001-9494-0586': 4, '0000-0001-7811-9245': 2, '0000-0002-5911-4219': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "j_gordon  pass\n",
      "For name:  s_liao\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0003-4129-0879': 46, '0000-0002-4312-5351': 43, '0000-0003-0943-0667': 10, '0000-0002-3122-8249': 2, '0000-0002-2372-9502': 1, '0000-0002-8872-2117': 1, '0000-0002-7339-2768': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "s_liao  pass\n",
      "For name:  j_qian\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-8793-9330': 6, '0000-0001-6145-045X': 6, '0000-0003-3162-2913': 1, '0000-0002-9522-6445': 1, '0000-0002-1325-6975': 1, '0000-0002-5438-0833': 1, '0000-0001-5043-020X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "j_qian  pass\n",
      "For name:  s_bernardi\n",
      "total sample size before apply threshold:  91\n",
      "Counter({'0000-0001-5672-0881': 38, '0000-0002-7429-3075': 30, '0000-0002-1050-3096': 17, '0000-0001-6130-8533': 6})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "s_bernardi  pass\n",
      "For name:  t_hill\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0003-4159-9104': 7, '0000-0001-6996-9475': 3, '0000-0002-4125-7895': 2, '0000-0003-2980-4099': 2, '0000-0002-7995-9315': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "t_hill  pass\n",
      "For name:  s_schindler\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-9991-9513': 26, '0000-0002-7054-5431': 13, '0000-0003-1028-3115': 6, '0000-0003-1378-0053': 5, '0000-0002-1755-4304': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "s_schindler  pass\n",
      "For name:  j_williams\n",
      "total sample size before apply threshold:  625\n",
      "Counter({'0000-0001-5188-7957': 141, '0000-0002-6063-7615': 82, '0000-0001-6665-6596': 79, '0000-0002-4688-3000': 66, '0000-0001-7152-765X': 51, '0000-0001-8251-4176': 28, '0000-0003-1235-5186': 26, '0000-0002-8883-7838': 25, '0000-0001-8331-3181': 20, '0000-0001-8377-5175': 15, '0000-0002-8861-0596': 14, '0000-0002-3804-2594': 14, '0000-0003-3815-0891': 14, '0000-0002-4497-4961': 10, '0000-0002-9801-9580': 9, '0000-0003-4400-5180': 5, '0000-0002-3500-914X': 5, '0000-0002-0195-6771': 4, '0000-0001-6105-0296': 3, '0000-0002-4681-3360': 3, '0000-0003-0161-0532': 3, '0000-0002-6511-1284': 3, '0000-0002-0195-5509': 2, '0000-0003-0500-1961': 2, '0000-0002-5355-3210': 1})\n",
      "['0000-0001-5188-7957']\n",
      "Total sample size after apply threshold:  141\n",
      "j_williams  pass\n",
      "For name:  s_jacobson\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-9042-8750': 20, '0000-0002-3955-5746': 4, '0000-0002-4952-9007': 3, '0000-0001-9937-419X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "s_jacobson  pass\n",
      "For name:  e_andrade\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-1941-580X': 7, '0000-0001-7080-7035': 5, '0000-0003-2016-8305': 4, '0000-0002-5030-1675': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "e_andrade  pass\n",
      "For name:  t_santos\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0002-5365-4863': 18, '0000-0003-3765-5863': 14, '0000-0001-9072-5010': 3, '0000-0001-9947-6022': 2, '0000-0002-7694-306X': 2, '0000-0003-4171-5806': 1, '0000-0002-9744-0410': 1, '0000-0002-5325-3090': 1, '0000-0003-4620-0174': 1, '0000-0002-5738-4995': 1, '0000-0001-6892-0354': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "t_santos  pass\n",
      "For name:  k_kim\n",
      "total sample size before apply threshold:  1111\n",
      "Counter({'0000-0002-6929-5359': 211, '0000-0001-9498-284X': 154, '0000-0002-5878-8895': 139, '0000-0002-1864-3392': 92, '0000-0002-7045-8004': 57, '0000-0001-7896-6751': 57, '0000-0002-7991-9428': 55, '0000-0002-4010-1063': 45, '0000-0002-2186-3484': 28, '0000-0002-4899-1929': 25, '0000-0003-0487-4242': 24, '0000-0002-3642-1486': 22, '0000-0001-9965-3535': 17, '0000-0002-4168-757X': 17, '0000-0001-6525-3744': 14, '0000-0002-3897-0278': 14, '0000-0002-1181-5112': 12, '0000-0003-1447-9385': 11, '0000-0002-7305-8786': 11, '0000-0002-2655-7806': 10, '0000-0003-3466-5353': 9, '0000-0002-7359-663X': 8, '0000-0003-4600-8668': 6, '0000-0002-1382-7088': 5, '0000-0002-9505-4882': 5, '0000-0003-3667-9900': 4, '0000-0001-9714-6038': 4, '0000-0002-4760-0228': 3, '0000-0003-4188-7915': 3, '0000-0001-9454-0427': 3, '0000-0002-0333-6808': 3, '0000-0003-2134-4964': 3, '0000-0002-6658-047X': 3, '0000-0003-1273-379X': 3, '0000-0002-7047-3183': 3, '0000-0002-1814-9546': 3, '0000-0003-4812-6297': 2, '0000-0001-6597-578X': 2, '0000-0002-5285-9138': 2, '0000-0002-6796-7844': 2, '0000-0002-1130-8698': 2, '0000-0001-8518-8150': 2, '0000-0002-7103-924X': 2, '0000-0002-5407-0202': 1, '0000-0001-6220-8411': 1, '0000-0002-7440-6703': 1, '0000-0002-1603-7559': 1, '0000-0003-0257-1707': 1, '0000-0001-8532-6517': 1, '0000-0001-6626-316X': 1, '0000-0002-3246-9861': 1, '0000-0002-7207-4389': 1, '0000-0001-9682-9654': 1, '0000-0002-0196-3832': 1, '0000-0001-8063-6081': 1, '0000-0003-2037-3333': 1, '0000-0001-8872-6751': 1})\n",
      "['0000-0001-9498-284X', '0000-0002-6929-5359', '0000-0002-5878-8895']\n",
      "Total sample size after apply threshold:  504\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_textual_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b299a9fa6755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# select feature wanted to fit to clustering/classification algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# data part extract textual embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mdata_part_textual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_textual_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_part_textual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mpart_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_part_textual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_textual_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "# load the file\n",
    "import io\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "fileDir = \"../../Data/\"+Dataset+\"/canopies_labeled/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# collect statistic to output\n",
    "allname, num_class, per_class_count = ([] for i in range(3))\n",
    "\n",
    "all_svcLinear_accuracy, all_svcLinear_f1, all_LR_accuracy, all_LR_f1 = ([] for i in range(4))\n",
    "\n",
    "# collect overall tp, tn, fp, fn\n",
    "svcTP=svcTN=svcFP=svcFN = 0\n",
    "lrTP=lrTN=lrFP=lrFN = 0\n",
    "\n",
    "# read all file in labeled group\n",
    "for file in listfiles:\n",
    "    # group name\n",
    "    temp = file.split(\"_\")\n",
    "    name = temp[1]+\"_\"+temp[-1]\n",
    "    print(\"For name: \",name)\n",
    "    # read needed content in labeled file\n",
    "    labeled_data = read_labeled_file(fileDir+file)\n",
    "    print(\"total sample size before apply threshold: \",len(labeled_data))\n",
    "    # count number of paper each author write based on author ID\n",
    "    paperCounter = collections.Counter(labeled_data[\"authorID\"])\n",
    "    print(paperCounter)\n",
    "    # collect per class statistic\n",
    "    for k in list(paperCounter):\n",
    "        if paperCounter[k] < threshold:\n",
    "            del paperCounter[k]\n",
    "    temp =list(paperCounter.keys())\n",
    "    print(temp)\n",
    "    # remove samples that are smaller than threshold\n",
    "    labeled_data = labeled_data[labeled_data.authorID.isin(temp)]\n",
    "    print(\"Total sample size after apply threshold: \",len(labeled_data))\n",
    "    # if only have one class or no class pass the threshold, not applicable\n",
    "    if(len(paperCounter)<2):\n",
    "        print(name, \" pass\")\n",
    "    else:\n",
    "        allname.append(name)\n",
    "        num_class.append(len(paperCounter))\n",
    "        per_class_count.append(paperCounter)\n",
    "        # extract true label and pid\n",
    "        label = labeled_data[\"authorID\"]\n",
    "        pid = labeled_data[\"paperID\"]\n",
    "        # list of different data field\n",
    "        part_collection = []\n",
    "        # select feature wanted to fit to clustering/classification algorithm\n",
    "        # data part extract textual embedding\n",
    "        data_part_textual = extract_embedding(all_textual_embedding, pid)\n",
    "        print(data_part_textual.shape)\n",
    "        part_collection.append(data_part_textual)\n",
    "        # data part read citation embedding \n",
    "        data_part_citation = extract_embedding(all_citation_embedding, pid)\n",
    "        print(data_part_citation.shape)\n",
    "        part_collection.append(data_part_citation)\n",
    "        # merge different part of data data together by concatenate it all together\n",
    "        # remove empty emb (when emb set off)\n",
    "        part_collection = [part for part in part_collection if len(part)!=0]\n",
    "        print(len(part_collection))\n",
    "        if len(part_collection)>1:\n",
    "            combinedata = np.concatenate(part_collection,axis=1)\n",
    "        elif len(part_collection)==1:\n",
    "            if isinstance(part_collection[0], pd.DataFrame):\n",
    "                combinedata = part_collection[0].values\n",
    "            else:\n",
    "                combinedata = part_collection[0]\n",
    "        else:\n",
    "            print(\"No data available\")\n",
    "            break\n",
    "        print(combinedata.shape)\n",
    "        # shuffle split train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(combinedata, label,\n",
    "                                                            stratify=label, \n",
    "                                                            test_size=0.20)\n",
    "        print(X_train.shape)\n",
    "        print(y_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(y_test.shape)\n",
    "        # using converted feature vector to train classifier\n",
    "        # using SVM with linear kernal\n",
    "        clf = SVC(decision_function_shape='ovr', kernel='linear')\n",
    "        # normal predict\n",
    "        svcaccuracy, svcmarcof1, tp, tn, fp, fn = normal_group_predict(X_train, y_train, X_test, y_test, clf)\n",
    "#         # use 10 fold cv\n",
    "#         svcaccuracy, svcmarcof1, tp, tn, fp, fn = k_fold_cv(combinedata, label, clf, k=10)\n",
    "        svcTP+=tp\n",
    "        svcTN+=tn\n",
    "        svcFP+=fp\n",
    "        svcFN+=fn\n",
    "        print(name, \" in group svc Accuracy: \",svcaccuracy)\n",
    "        print(name, \" in group svc F1: \", svcmarcof1)\n",
    "        all_svcLinear_accuracy.append(svcaccuracy)\n",
    "        all_svcLinear_f1.append(svcmarcof1)\n",
    "        # using logistic regression\n",
    "        clf = LogisticRegression(multi_class='ovr')\n",
    "        # normal predict\n",
    "        LRaccuracy, LRmarcof1, tp, tn, fp, fn = normal_group_predict(X_train, y_train, X_test, y_test, clf)\n",
    "#         # 10 fold\n",
    "#         LRaccuracy, LRmarcof1, tp, tn, fp, fn = k_fold_cv(combinedata, label, clf, k=10)\n",
    "        lrTP+=tp\n",
    "        lrTN+=tn\n",
    "        lrFP+=fp\n",
    "        lrFN+=fn\n",
    "        print(\"LR Accuracy: \",LRaccuracy)\n",
    "        print(\"LR F1: \", LRmarcof1)\n",
    "        all_LR_accuracy.append(LRaccuracy)\n",
    "        all_LR_f1.append(LRmarcof1)\n",
    "        break\n",
    "\n",
    "# print f1 for entire model\n",
    "print(\"svc: TP: \",svcTP, \"TN: \",svcTN, \"FP: \",svcFP,\"FN: \",svcFN)\n",
    "print(\"lr: TP: \",lrTP, \"TN: \",lrTN, \"FP: \",lrFP,\"FN: \",lrFN)\n",
    "svcF1 = 2*svcTP / (2*svcTP + svcFP + svcFN)\n",
    "lrF1 = 2*lrTP / (2*lrTP + lrFP + lrFN)\n",
    "        \n",
    "# # write evaluation result to excel\n",
    "# output = pd.DataFrame({'Name Group':allname,\"Class number\":num_class, \"per_class_size\":per_class_count,\n",
    "#                        \"svc(linear) accuracy\":all_svcLinear_accuracy, \"svc(linear) macro f1\": all_svcLinear_f1, \n",
    "#                        \"logistic regression accuracy\":all_LR_accuracy, \"logistic regression macro f1\": all_LR_f1})\n",
    "\n",
    "# savePath = \"../../result/\"+Dataset+\"/skovr/\"\n",
    "# filename = \"textual=\"+pp_textual+\"_citation=\"+citation_emb+\"_threshold=\"+str(threshold)+\".csv\"\n",
    "# write_csv_df(savePath, filename, output)\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T22:22:12.719980Z",
     "start_time": "2018-12-16T22:22:12.706986Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"textual =\",pp_textual,\"_citation =\",citation_emb)\n",
    "print(\"svc: \", svcF1)\n",
    "print(\"lr:\", lrF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T23:10:05.635253Z",
     "start_time": "2018-12-13T23:10:05.605356Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "from statistics import mean \n",
    "cleaned_svcLinear_accuracy = [x for x in all_svcLinear_accuracy if isinstance(x, float)]\n",
    "cleaned_lr_accuracy = [x for x in all_LR_accuracy if isinstance(x, float)]\n",
    "print(len(cleaned_svcLinear_accuracy))\n",
    "print(len(cleaned_lr_accuracy))\n",
    "print(mean(cleaned_svcLinear_accuracy))\n",
    "print(mean(cleaned_lr_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T23:10:06.108636Z",
     "start_time": "2018-12-13T23:10:06.084585Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f1\n",
    "from statistics import mean \n",
    "# remove string from result\n",
    "cleaned_svcLinear_f1 = [x for x in all_svcLinear_f1 if isinstance(x, float)]\n",
    "cleaned_lr_f1 = [x for x in all_LR_f1 if isinstance(x, float)]\n",
    "print(len(cleaned_svcLinear_f1))\n",
    "print(len(cleaned_lr_f1))\n",
    "print(mean(cleaned_svcLinear_f1))\n",
    "print(mean(cleaned_lr_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
