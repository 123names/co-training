{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-training\n",
    "\n",
    "For visualization of co-training process, we apply PCA to feature before training. This will make co-training process clear, but the result will be not accuracy because apply PCA will loss lots of information.\n",
    "\n",
    "1. We assume only part of label exist\n",
    "\n",
    "2. We only select binary case (Only when one name indicate two and only two author)\n",
    "\n",
    "3. When we apply 10 fold with co-training, each fold of first iteration will be baseline compare to co-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved part\n",
    "1. adding stopping criterion where when confident score is 95% or number of iteration equal k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T00:52:38.064034Z",
     "start_time": "2020-01-27T00:52:36.005237Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "#warnings.filterwarnings('error')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import com_func\n",
    "\n",
    "#----- threshold for selecting set of name group -----------#\n",
    "threshold_select_name_group = 100\n",
    "#----- threshold for selecting min sample in name group ----#\n",
    "threshold_lower = 100\n",
    "threshold_upper = 110\n",
    "\n",
    "apply_threshold_to_name_group_samples = True\n",
    "\n",
    "pp_text = [\"pv_dbow\"]\n",
    "pp_citation = \"n2v\"\n",
    "\n",
    "Dataset = \"pubmed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T00:52:44.507047Z",
     "start_time": "2020-01-27T00:52:38.066377Z"
    },
    "code_folding": [
     13,
     30,
     45,
     57,
     100,
     108,
     329,
     332,
     335,
     342,
     370
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# create co training classifier\n",
    "class Co_training_clf(object):\n",
    "    \n",
    "    import copy\n",
    "    \n",
    "    def __init__(self, clf1, clf2=None, p=1, n=1, k=30, u = 75):\n",
    "        \n",
    "        self.clf1 = clf1\n",
    "        # assume co_training on one classifier\n",
    "        if clf2 == None:\n",
    "            self.clf2 = self.copy.deepcopy(clf1)\n",
    "        else:\n",
    "            self.clf2 = clf2\n",
    "        # take p example from most confidently positive labels to example\n",
    "        self.p = p\n",
    "        # take n example from most confidently negative label to example\n",
    "        self.n = n\n",
    "        # number of iteration\n",
    "        self.k = k\n",
    "        # size of pool of unlabeled samples\n",
    "        self.u = u\n",
    "\n",
    "    def init_L_U_U_prime(self, labels):\n",
    "        # index of the samples that are initially labeled\n",
    "        L = labels.index[labels != -1].tolist()\n",
    "        # index of unlabeled samples\n",
    "        U = labels.index[labels == -1].tolist()\n",
    "        print(\"Initial L size: \", len(L))\n",
    "        print(\"Initial U size: \", len(U))\n",
    "        # random drawing sample from U\n",
    "        random.shuffle(U)\n",
    "        U_prime = U[-min(len(U), self.u):]\n",
    "        # remove the samples in U_prime from U\n",
    "        U = U[:-len(U_prime)]\n",
    "        print(\"Initial U prime size: \", len(U_prime))\n",
    "        return L, U, U_prime\n",
    "    \n",
    "    def check_iter_label_mapping(self, iter_clf1, iter_clf2):\n",
    "        '''\n",
    "        In theory, it shouldn't occur that label not mapping since it trained on same dataset but different view\n",
    "        But add a check to make sure it won't occur and save the class mapping for late label unlabeled sample\n",
    "        '''\n",
    "        dv1_class_label = iter_clf1.classes_\n",
    "        dv2_class_label = iter_clf2.classes_\n",
    "        if all(dv1_class_label == dv2_class_label):\n",
    "            self.class_ = dv1_class_label\n",
    "        else:\n",
    "            sys.exit(\"Two view classifier label not mapping\")\n",
    "\n",
    "    def label_p_n_samples(self, proba, rank):\n",
    "        U_prime_size = len(proba)\n",
    "        self_trained_labels = []\n",
    "        self_trained_confident = []\n",
    "        for label, conf_measure in enumerate(rank):\n",
    "            # 0 positive sample\n",
    "            if label==0:\n",
    "                p = []\n",
    "                p_confident = []\n",
    "                index = 0\n",
    "                while(len(p) < self.p):\n",
    "                    max_conf_sample_index = conf_measure[index]\n",
    "                    # ---- if positive predict proba is more than 50% ------- #\n",
    "                    if (proba[max_conf_sample_index][label] > 0.5):\n",
    "                        print('P: ', max_conf_sample_index, \" : \", proba[max_conf_sample_index])\n",
    "                        p.append(max_conf_sample_index)\n",
    "                        p_confident.append(proba[max_conf_sample_index][label])\n",
    "                    index +=1\n",
    "                    if (index>=U_prime_size):\n",
    "                        break\n",
    "                self_trained_labels.append(p)\n",
    "                self_trained_confident.append(p_confident)\n",
    "            # 1 negative sample\n",
    "            elif label == 1:\n",
    "                n = []\n",
    "                n_confident = []\n",
    "                index = 0\n",
    "                while(len(n) < self.n):\n",
    "                    max_conf_sample_index = conf_measure[index]\n",
    "                    # ---- if negative predict proba is more than 50% ------- #\n",
    "                    if (proba[max_conf_sample_index][label] > 0.5):\n",
    "                        print('N: ', max_conf_sample_index, \" : \", proba[max_conf_sample_index])\n",
    "                        n.append(max_conf_sample_index)\n",
    "                        n_confident.append(proba[max_conf_sample_index][label])\n",
    "                    index +=1\n",
    "                    if (index>=U_prime_size):\n",
    "                        break\n",
    "                self_trained_labels.append(n)\n",
    "                self_trained_confident.append(n_confident)\n",
    "            else:\n",
    "                print(\"Class label error\")\n",
    "        return self_trained_labels, self_trained_confident\n",
    "\n",
    "    def get_self_labeled_sample(self):\n",
    "        '''\n",
    "        return:\n",
    "            self-labeled new positive, self-labeled new negative (Index)\n",
    "        '''\n",
    "        \n",
    "        return self.new_labeled_idx\n",
    "\n",
    "    def plot_co_training_process(self, iterCount, data, iter_train_label, unlabeled_idx, h1_new = [], h2_new = [],\n",
    "                                 h1_new_prob = [], h2_new_prob = [], plotSavingPath=None, name=None):\n",
    "        if not os.path.exists(plotSavingPath):\n",
    "            os.makedirs(plotSavingPath)\n",
    "        pca_one = data.values[:,0]\n",
    "        pca_two = data.values[:,1]\n",
    "        # Layer 1. plot unlabel samples in u_prime\n",
    "        fig, ax = plt.subplots(figsize=(9,7))\n",
    "        ax.scatter(pca_one[unlabeled_idx], pca_two[unlabeled_idx], color='grey', label = \"unlabeled\", s = 50, alpha = 0.5)\n",
    "        # Layer 2. plot the labeled samples\n",
    "        for author in np.unique(iter_train_label):\n",
    "            ix = iter_train_label.index[iter_train_label == author].tolist()\n",
    "            # print(ix)\n",
    "            ax.scatter(pca_one[ix], pca_two[ix], cmap='viridis', label = author, s = 50, alpha = 0.5)\n",
    "        if iterCount != 0:\n",
    "            # layer 3. mark self labeled samples\n",
    "            all_h1_new = list(itertools.chain(*h1_new))\n",
    "            all_h2_new = list(itertools.chain(*h2_new))\n",
    "            temp_h1 = ax.scatter(pca_one[all_h1_new], pca_two[all_h1_new], edgecolor='black', linewidth='1', s=50)\n",
    "            temp_h1.set_facecolor(\"none\")\n",
    "            temp_h1.set_label(\"h1 self-labeled\")\n",
    "            temp_h2 = ax.scatter(pca_one[all_h2_new], pca_two[all_h2_new], edgecolor='red', linewidth='1', s=50)\n",
    "            temp_h2.set_facecolor(\"none\")\n",
    "            temp_h2.set_label(\"h2 self-labeled\")\n",
    "            # layer 4. mark new samples confidence and which view produce it\n",
    "            last_iter_h1_new = h1_new[-1]\n",
    "            last_iter_h2_new = h2_new[-1]\n",
    "            text = []\n",
    "            for i, idx in enumerate(last_iter_h1_new):\n",
    "                text.append(plt.text(pca_one[idx], pca_two[idx], \"{:.2f}\".format(h1_new_prob[i]), color='black'))\n",
    "            for i, idx in enumerate(last_iter_h2_new):\n",
    "                text.append(plt.text(pca_one[idx], pca_two[idx], \"{:.2f}\".format(h2_new_prob[i]), color='red'))\n",
    "            adjust_text(text, x=pca_one, y=pca_two, force_points=0.3, force_text=0.3, expand_points=(2, 2), \n",
    "                        expand_text=(2, 2), arrowprops=dict(arrowstyle='Simple', color='red'))\n",
    "        legend = ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.25), ncol=3,prop={'size': 13})\n",
    "        plt.title('Co-training iteration: '+ str(iterCount), fontsize=14)\n",
    "        plt.xlabel(\"First principal component\",fontsize=14)\n",
    "        plt.ylabel(\"Second principal component\",fontsize=14)\n",
    "        plt.savefig((plotSavingPath+name+\"_PCA_i-\"+str(iterCount)+\".png\").encode('utf-8'), dpi=100, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "        plt.close(\"all\")\n",
    "        # plt.show()\n",
    "        \n",
    "\n",
    "    def fit(self, dataView1, dataView2, labels, dv1_test, dv2_test, label_test, plot_save_name=None, plot_save_path=None):\n",
    "        # using all unlabeled sample instead of pool of unlabeled sample\n",
    "        self.u = len(labels)\n",
    "        # index of self labeled samples\n",
    "        self.new_labeled_idx = defaultdict(list)\n",
    "        self.h1_new_idx = defaultdict(list)\n",
    "        self.h2_new_idx = defaultdict(list)\n",
    "        \n",
    "        # sync input datatype\n",
    "        if not all(isinstance(i, pd.DataFrame) for i in [dataView1, dataView2, labels]):\n",
    "            if not isinstance(dataView1, pd.DataFrame):\n",
    "                dataView1 = pd.DataFrame(dataView1)\n",
    "            if not isinstance(dataView2, pd.DataFrame):\n",
    "                dataView2 = pd.DataFrame(dataView2)\n",
    "            if not isinstance(labels, pd.DataFrame):\n",
    "                labels = pd.DataFrame(labels, index = dataView1.index.values)\n",
    "        labels = pd.Series(labels[0].values, index=dataView1.index.values) \n",
    "        # when fit co-train, we collect f1 on test samples wrt each iteration\n",
    "        self.f1_on_test_dv1 = []\n",
    "        self.f1_on_test_dv2 = []\n",
    "        \n",
    "        print(\"P value: \", self.p, \" N value: \", self.n)\n",
    "        print(dataView1.index.values)\n",
    "        \n",
    "        L, U, U_prime = self.init_L_U_U_prime(labels)\n",
    "        print(\"L: \", L)\n",
    "        print(\"U: \", U)\n",
    "        print(\"U_prime: \", U_prime)\n",
    "        \n",
    "        iterCount = 0\n",
    "        # --------- plot initial stage -------------- #\n",
    "        init_train_label = labels[L]\n",
    "        plot_save_dv1_name = plot_save_name+\"_dv1\"\n",
    "        if plot_save_name != None:\n",
    "            # ----- save pca reduced plot for dv1 ------ #\n",
    "            self.plot_co_training_process(iterCount, dataView1, init_train_label, U_prime,\n",
    "                                          plotSavingPath = plot_save_path, name = plot_save_dv1_name)\n",
    "            # ----- dv2 -------- #\n",
    "            plot_save_dv2_name = plot_save_name+\"_dv2\"\n",
    "            self.plot_co_training_process(iterCount, dataView2, init_train_label, U_prime,\n",
    "                                          plotSavingPath = plot_save_path, name = plot_save_dv2_name)\n",
    "        \n",
    "        #loop until we have assigned labels to every sample in U and U_prime or we hit our iteration break condition\n",
    "        while iterCount < self.k and U_prime:\n",
    "            # print(\"step\",iterCount, \" L: \",L)\n",
    "            # print(\"step\",iterCount, \" U_prime: \",U_prime)\n",
    "            # ------------- get labeled samples for train ----------- # \n",
    "            iter_train_d1 = dataView1.iloc[L]\n",
    "            iter_train_d2 = dataView2.iloc[L]\n",
    "            iter_train_label = labels[L]\n",
    "            # print(iter_train_label)\n",
    "            # ----------- get U_prime unlabeled samples  ------------ #\n",
    "            iter_unlabeled_d1 = dataView1.iloc[U_prime]\n",
    "            iter_unlabeled_d2 = dataView2.iloc[U_prime]\n",
    "            # ------------ train different view classifier ----------- #\n",
    "            iter_clf1 = self.copy.deepcopy(self.clf1) \n",
    "            iter_clf2 = self.copy.deepcopy(self.clf2)\n",
    "            iter_clf1.fit(iter_train_d1, iter_train_label.ravel())\n",
    "            iter_clf2.fit(iter_train_d2, iter_train_label.ravel())\n",
    "            self.check_iter_label_mapping(iter_clf1, iter_clf2)\n",
    "            # --------- test error on test data --------------------- #\n",
    "            # make prediction on test data\n",
    "            y1 = iter_clf1.predict(dv1_test)\n",
    "            y2 = iter_clf2.predict(dv2_test)\n",
    "            # f1 score on each iteration\n",
    "            f1_dv1 = f1_score(label_test, y1, average='macro')\n",
    "            f1_dv2 = f1_score(label_test, y2, average='macro')\n",
    "            # collect f1 for current iteration\n",
    "            self.f1_on_test_dv1.append(f1_dv1)\n",
    "            self.f1_on_test_dv2.append(f1_dv2)\n",
    "            ''' \n",
    "            Notice here dv1_proba and dv2_proba's index is index for u' (Unlabeled data only)\n",
    "            We use index of u' to find index (position) of data in U where U and L is all data index\n",
    "            '''\n",
    "            # rank class probabilities for unlabeled sample for it's confidence measure\n",
    "            dv1_proba = iter_clf1.predict_proba(iter_unlabeled_d1)\n",
    "            dv2_proba = iter_clf2.predict_proba(iter_unlabeled_d2)\n",
    "            dv1_proba_rank = []\n",
    "            dv2_proba_rank = []\n",
    "            # proba1_rank[i] is label i's confidence measure\n",
    "            for class_proba in dv1_proba.T:\n",
    "                dv1_proba_rank.append((-class_proba).argsort())\n",
    "            for class_proba in dv2_proba.T:\n",
    "                dv2_proba_rank.append((-class_proba).argsort())\n",
    "            # print(dv1_proba)\n",
    "            # print(dv1_proba_rank)\n",
    "            # print(dv2_proba)\n",
    "            # print(dv2_proba_rank)\n",
    "            # h1 classifier\n",
    "            h1_new_sample, h1_new_sample_probs = self.label_p_n_samples(dv1_proba, dv1_proba_rank)\n",
    "            # h2 classifier\n",
    "            h2_new_sample, h2_new_sample_probs = self.label_p_n_samples(dv2_proba, dv2_proba_rank)\n",
    "            # collect statistic for plot only\n",
    "            h1_new_flatten = list(itertools.chain(*h1_new_sample))\n",
    "            h2_new_flatten = list(itertools.chain(*h2_new_sample))\n",
    "            iter_h1_prob = list(itertools.chain(*h1_new_sample_probs))\n",
    "            iter_h2_prob = list(itertools.chain(*h2_new_sample_probs))\n",
    "            iter_h1_for_plot = [U_prime[x] for x in h1_new_flatten]\n",
    "            iter_h2_for_plot = [U_prime[x] for x in h2_new_flatten]\n",
    "            self.h1_new_idx[\"index\"].append(iter_h1_for_plot)\n",
    "            self.h1_new_idx[\"confident\"].append(iter_h1_prob)\n",
    "            self.h2_new_idx[\"index\"].append(iter_h2_for_plot)\n",
    "            self.h2_new_idx[\"confident\"].append(iter_h2_prob)\n",
    "            # add most confidence samples as new training samples\n",
    "            roundNew = list(zip(h1_new_sample, h2_new_sample))\n",
    "            print(roundNew)\n",
    "            # auto label the samples and remove it from U_prime\n",
    "            round_auto_labeled = []\n",
    "            for label, round_new in enumerate(roundNew):\n",
    "                round_new = set([item for sublist in round_new for item in sublist])\n",
    "                auto_labeled = [U_prime[x] for x in round_new]\n",
    "                round_auto_labeled.extend(auto_labeled)\n",
    "                self.new_labeled_idx[self.class_[label]].append(auto_labeled)\n",
    "                # add label to those new samples\n",
    "                labels[auto_labeled] = self.class_[label]\n",
    "                print(self.class_[label],\" (u' idx): \",round_new)\n",
    "                print(self.class_[label],\" (U idx): \",auto_labeled)\n",
    "            print(roundNew)\n",
    "            print(round_auto_labeled)\n",
    "            # extend the labeled sample\n",
    "            L.extend(round_auto_labeled)\n",
    "            # remove the labeled sample from U_prime\n",
    "            U_prime = [x for x in U_prime if x not in round_auto_labeled]\n",
    "            #print(U_prime)\n",
    "            # randomly choice 2p+2n examples from u to replenish u_prime\n",
    "            replenishItem = U[-(2*self.p+2*self.n):]\n",
    "            U_prime.extend(replenishItem)\n",
    "            U = U[:-len(replenishItem)]\n",
    "            iterCount +=1\n",
    "            # ----------- plot the co-training process -------------- #\n",
    "            if plot_save_name != None:\n",
    "                new_train_label = labels[L]\n",
    "                h1_new = self.h1_new_idx[\"index\"]\n",
    "                h2_new = self.h2_new_idx[\"index\"]\n",
    "                # self_labeled_idx = [val for sublist in self_labeled_idx_temp for subsublist in sublist for val in subsublist]\n",
    "                print(\"Current iter h1 new: \", iter_h1_for_plot, \" probs: \", iter_h1_prob)\n",
    "                print(\"Current iter h2 new: \", iter_h2_for_plot, \" probs: \", iter_h2_prob)\n",
    "                # ----- save pca reduced plot for dv1 ------ #\n",
    "                plot_save_dv1_name = plot_save_name+\"_dv1\"\n",
    "                self.plot_co_training_process(iterCount, dataView1, new_train_label, U_prime,\n",
    "                                              h1_new, h2_new, iter_h1_prob, iter_h2_prob,\n",
    "                                              plot_save_path, plot_save_dv1_name)\n",
    "                # ----- dv2 -------- #\n",
    "                plot_save_dv2_name = plot_save_name+\"_dv2\"\n",
    "                self.plot_co_training_process(iterCount, dataView2, new_train_label, U_prime,\n",
    "                                              h1_new, h2_new, iter_h1_prob, iter_h2_prob,\n",
    "                                              plot_save_path, plot_save_dv2_name)\n",
    "        print(\"Total Labeled number: \", len(L), \" Still unlabeled number: \", len(U_prime))\n",
    "        print(self.f1_on_test_dv1)\n",
    "        print(self.f1_on_test_dv2)\n",
    "        # final train\n",
    "        newtrain_d1 = dataView1.iloc[L]\n",
    "        newtrain_d2 = dataView2.iloc[L]\n",
    "        self.clf1.fit(newtrain_d1, labels.iloc[L])\n",
    "        self.clf2.fit(newtrain_d2, labels.iloc[L])\n",
    "        # ------ save f1 vs number of iteration plot ------- #\n",
    "        if plot_save_name != None:\n",
    "            default_text_based = [self.f1_on_test_dv1[0]] * iterCount\n",
    "            default_citation_based = [self.f1_on_test_dv2[0]] * iterCount\n",
    "            default_step = np.arange(0,iterCount)\n",
    "            co_train_text_based = self.f1_on_test_dv1[1:]\n",
    "            co_train_citation_based = self.f1_on_test_dv2[1:]\n",
    "            co_training_step = np.arange(1,iterCount)\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes()\n",
    "            plt.plot(default_step, default_text_based, linestyle='dashed', label=\"Text based default\")\n",
    "            plt.plot(default_step, default_citation_based, linestyle='dashdot', label=\"Citation based default\")\n",
    "            plt.plot(co_training_step, co_train_text_based, linestyle='solid', marker = \"*\", label=\"Text based\")\n",
    "            plt.plot(co_training_step, co_train_citation_based, linestyle='dotted', marker = \"+\", label=\"Citation based\")\n",
    "            ax.autoscale_view()\n",
    "            legend = ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=2)\n",
    "            plt.xlabel('Co-Training Iterations')\n",
    "            plt.ylabel('F1 score')\n",
    "            plt.savefig((plot_save_path+plot_save_name+\"_diff_iter_f1.png\"), dpi=300, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "            # plt.show()\n",
    "            plt.close(\"all\")\n",
    "            \n",
    "    def co_train_process_f1(self):\n",
    "        return self.f1_on_test_dv1, self.f1_on_test_dv2\n",
    "\n",
    "    def get_iter_count(self):\n",
    "        return self.k\n",
    "\n",
    "    def supports_proba(self, clf, x):\n",
    "        try:\n",
    "            clf.predict_proba([x])\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def predict(self, dataView1, dataView2):\n",
    "        y1 = self.clf1.predict(dataView1)\n",
    "        y2 = self.clf2.predict(dataView2)\n",
    "        proba_supported = self.supports_proba(self.clf1, dataView1.iloc[0]) and self.supports_proba(self.clf2, dataView2.iloc[0])\n",
    "        #fill pred with -1 so we can identify the samples in which sample classifiers failed to agree\n",
    "        y_pred = [\"-1\"] * dataView1.shape[0]\n",
    "        for i, (y1_i, y2_i) in enumerate(zip(y1, y2)):\n",
    "            # if both agree on label\n",
    "            if y1_i == y2_i:\n",
    "                y_pred[i] = y1_i\n",
    "            # if disagree on label, times probability together, choice the class have higher probabilities\n",
    "            elif proba_supported:\n",
    "                y1_probas = self.clf1.predict_proba([dataView1.iloc[i]])[0]\n",
    "                y2_probas = self.clf2.predict_proba([dataView2.iloc[i]])[0]\n",
    "                print(\"y1 disagree on\",i, \" Proba: \",y1_probas)\n",
    "                print(\"y2 not aggreed on \",i, \"Proba: \", y2_probas)\n",
    "                prod_y_probas = [proba_y1 * proba_y2 for (proba_y1, proba_y2) in zip(y1_probas, y2_probas)]\n",
    "                print(\"product probas:\",prod_y_probas)\n",
    "                max_prob_idx = prod_y_probas.index(max(prod_y_probas))\n",
    "                y_pred[i] = self.class_[max_prob_idx]\n",
    "                print(\"result idx: \", max_prob_idx, \" result: \",y_pred[i])\n",
    "            else:\n",
    "                #the classifiers disagree and don't support probability, exit\n",
    "                sys.exit(\"classifiers disagree with label, result may not accurate\")\n",
    "        # convert final result to np array\n",
    "        y_pred_np_array = np.asarray(y_pred)\n",
    "        return y_pred_np_array\n",
    "\n",
    "    def predict_proba(self, dataView1, dataView2):\n",
    "        # the predicted probabilities is simply a product (*) of probabilities given from each classifier trained\n",
    "        y1_probas = self.clf1.predict_proba(dataView1)\n",
    "        y2_probas = self.clf2.predict_proba(dataView2)\n",
    "        \n",
    "        proba = (y1_probas*y2_probas)\n",
    "        return proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-27T00:52:41.361Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "\n",
    "# cross validation\n",
    "def k_fold_cv_co_train_binary(dataview1, dataview2, label, init_labeled_size, clf, k=10, plot_save_name=None, plot_save_path=None):\n",
    "    kf = StratifiedKFold(n_splits=k)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel_co_train,allPredLabel_LR,allPredLabel_SVM = ([] for i in range(3))\n",
    "    all_fold_coTrain_diff_iter_on_test_dv1 = []\n",
    "    all_fold_coTrain_diff_iter_on_test_dv2 = []\n",
    "    \n",
    "    all_fold_statistic = []\n",
    "    fold = 0\n",
    "    co_train_iteration = 0\n",
    "    # convert different input type to dataframe for consistency\n",
    "    dataview1 = pd.DataFrame(dataview1)\n",
    "    dataview2 = pd.DataFrame(dataview2)\n",
    "    \n",
    "    for train_index, test_index in kf.split(dataview1, label):\n",
    "        detailed_plot_path = plot_save_path+plot_save_name+\"/fold\"+str(fold)+\"/\"\n",
    "        fold +=1\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # ---------------split train and test -------------------- #\n",
    "        dv1_train, dv1_test = dataview1.iloc[train_index], dataview1.iloc[test_index]\n",
    "        dv2_train, dv2_test = dataview2.iloc[train_index], dataview2.iloc[test_index]\n",
    "        all_label_train, label_test = label.iloc[train_index], label.iloc[test_index]\n",
    "        \n",
    "        # plot true labeled result for different view\n",
    "        if not os.path.exists(detailed_plot_path):\n",
    "            os.makedirs(detailed_plot_path)\n",
    "        # view one\n",
    "        dv1_pca_one = dv1_train.iloc[:,0]\n",
    "        dv1_pca_two = dv1_train.iloc[:,1]\n",
    "        fig, ax = plt.subplots(figsize=(9,7))\n",
    "        for author in np.unique(all_label_train):\n",
    "            ix = all_label_train.index[all_label_train == author].tolist()\n",
    "            ax.scatter(dv1_pca_one[ix], dv1_pca_two[ix], cmap='viridis', label = author, s = 50, alpha = 0.5)\n",
    "        legend = ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=2,prop={'size': 13})\n",
    "        plt.title('True label', fontsize=14)\n",
    "        plt.xlabel(\"First principal component\",fontsize=14)\n",
    "        plt.ylabel(\"Second principal component\",fontsize=14)\n",
    "        plt.savefig((detailed_plot_path+name+\"_PCA_true_label_dv1.png\").encode('utf-8'), dpi=100, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "        # view two\n",
    "        dv2_pca_one = dv2_train.iloc[:,0]\n",
    "        dv2_pca_two = dv2_train.iloc[:,1]\n",
    "        fig, ax = plt.subplots(figsize=(9,7))\n",
    "        for author in np.unique(all_label_train):\n",
    "            ix = all_label_train.index[all_label_train == author].tolist()\n",
    "            ax.scatter(dv2_pca_one[ix], dv2_pca_two[ix], cmap='viridis', label = author, s = 50, alpha = 0.5)\n",
    "        legend = ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=2,prop={'size': 13})\n",
    "        plt.title('True label', fontsize=14)\n",
    "        plt.xlabel(\"First principal component\",fontsize=14)\n",
    "        plt.ylabel(\"Second principal component\",fontsize=14)\n",
    "        plt.savefig((detailed_plot_path+name+\"_PCA_true_label_dv2.png\").encode('utf-8'), dpi=100, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "        \n",
    "        # ----------- set some labeled data as unlabeled ------------ #\n",
    "        # 1. obtain data ratio\n",
    "        c = Counter(all_label_train)\n",
    "        data_ratio = [(i, c[i] / len(all_label_train)) for i in c]\n",
    "        print(data_ratio)\n",
    "        # 2. use co_train_per_class_size to draw \"init_labeled_size\" of samples as labeled, other as unlabeled\n",
    "        co_train_per_class_size = [(label, round(ratio*init_labeled_size)) for label, ratio in data_ratio]\n",
    "        final_train_label = all_label_train.tolist()\n",
    "        train_sample_idx = []\n",
    "        # 3. mark other as unlabeled\n",
    "        for unique_label, training_size in co_train_per_class_size:\n",
    "            curr_label_idx = [i for i, x in enumerate(final_train_label) if x == unique_label]\n",
    "            curr_label_size = len(curr_label_idx)\n",
    "            unlabeled_size = curr_label_size - training_size\n",
    "            unlabel_item_idx = random.sample(curr_label_idx, unlabeled_size)\n",
    "            train_sample_idx += [x for x in curr_label_idx if x not in unlabel_item_idx]\n",
    "            for unlabel_idx in unlabel_item_idx:\n",
    "                final_train_label[unlabel_idx]=-1\n",
    "        print(final_train_label)\n",
    "        unlabeled_sample_size = len(final_train_label)-len(train_sample_idx)\n",
    "        final_dv1_train = dv1_train.reset_index(drop=True)\n",
    "        final_dv2_train = dv2_train.reset_index(drop=True)\n",
    "        ''' -------------- train binary co-training ------------------- '''\n",
    "        per_fold_clf = copy.deepcopy(clf)\n",
    "        per_fold_clf.fit(final_dv1_train, final_dv2_train, final_train_label, dv1_test, dv2_test, label_test,\n",
    "                         plot_save_name, detailed_plot_path)\n",
    "        # get self-labeled sample index #\n",
    "        self_labeled_index = per_fold_clf.get_self_labeled_sample()\n",
    "        print(\"Self labeled sample index: \", self_labeled_index)\n",
    "        self_labeled_idx_temp = [idx for idx in self_labeled_index.values()]\n",
    "        all_self_labeled_index = [val for sublist in self_labeled_idx_temp for subsublist in sublist for val in subsublist]\n",
    "        # -------- use concatenated features for comparsion -------- #\n",
    "        concatenated_train = pd.concat([final_dv1_train.iloc[train_sample_idx],final_dv2_train.iloc[train_sample_idx]], axis=1, ignore_index=True)\n",
    "        train_label = [final_train_label[i] for i in train_sample_idx]\n",
    "        ''' --- train LR on concatenated features with \"init_labeled_size\" labeled samples  --- '''\n",
    "        LR_clf = LogisticRegression(solver= \"liblinear\")\n",
    "        LR_clf.fit(concatenated_train, train_label)\n",
    "        ''' --- train SVM on concatenated features with \"init_labeled_size\" labeled samples  --- '''\n",
    "        SVM_clf = SVC(gamma=\"auto\", kernel='linear')\n",
    "        SVM_clf.fit(concatenated_train, train_label)\n",
    "        # ------------ generate concatenated test dataset ------------ #\n",
    "        concatenated_test = pd.concat([dv1_test,dv2_test], axis=1, ignore_index=True)\n",
    "        # ------------- get predicted label for test set ------------- #\n",
    "        co_lr_label_predict = per_fold_clf.predict(dv1_test, dv2_test)\n",
    "        LR_predict = LR_clf.predict(concatenated_test)\n",
    "        SVM_predict = SVM_clf.predict(concatenated_test)\n",
    "        print(\"co-train f1: \", metrics.classification_report(label_test, co_lr_label_predict))\n",
    "        print(\"LR f1: \", metrics.classification_report(label_test, LR_predict) )\n",
    "        print(\"SVM f1: \", metrics.classification_report(label_test, SVM_predict))\n",
    "        # ------------- get co-training iterations f1 score ---------- #\n",
    "        co_train_iteration = per_fold_clf.get_iter_count()\n",
    "        coTrain_diff_iter_on_test_dv1, coTrain_diff_iter_on_test_dv2 = per_fold_clf.co_train_process_f1()\n",
    "        all_fold_coTrain_diff_iter_on_test_dv1.append(coTrain_diff_iter_on_test_dv1)\n",
    "        all_fold_coTrain_diff_iter_on_test_dv2.append(coTrain_diff_iter_on_test_dv2)\n",
    "        \n",
    "        allTrueLabel.extend(label_test.values.tolist())\n",
    "        allPredLabel_co_train.extend(co_lr_label_predict)\n",
    "        allPredLabel_LR.extend(LR_predict)\n",
    "        allPredLabel_SVM.extend(SVM_predict)\n",
    "        # collect per fold statistic\n",
    "        curr_fold_statistic = {'author': plot_save_name, 'fold':fold, 'train_size': co_train_per_class_size, 'test_size': dv1_test.shape[0],\n",
    "                               'total_self_labeled_train': len(all_self_labeled_index), \"unlabeled size\": unlabeled_sample_size,\n",
    "                               'co-train f1': f1_score(label_test.values.tolist(), co_lr_label_predict,average='macro'),\n",
    "                               'LR f1': f1_score(label_test.values.tolist(), LR_predict,average='macro'),\n",
    "                               'SVM f1': f1_score(label_test.values.tolist(), SVM_predict,average='macro')}\n",
    "        all_fold_statistic.append(curr_fold_statistic)\n",
    "    if plot_save_path !=None:\n",
    "        # --------------- plot per fold result f1 variance --------------- #\n",
    "        all_per_fold_f1_score_variance_plot = pd.DataFrame(all_fold_statistic)\n",
    "        plot_temp_data = all_per_fold_f1_score_variance_plot[['co-train f1', 'LR f1', 'SVM f1']].copy()\n",
    "        plot_temp_data = pd.melt(plot_temp_data, var_name='methods', value_name='f1')\n",
    "        ax = sns.boxplot(x=\"methods\", y=\"f1\", data=plot_temp_data)\n",
    "        ax = sns.swarmplot(x=\"methods\", y=\"f1\", data=plot_temp_data, color=\".25\")\n",
    "        ax.set_title(plot_save_name+\" result variance with 10 fold\")\n",
    "        plt.savefig(plot_save_path+plot_save_name+\"/\"+plot_save_name+\"_result_variance.png\", dpi=300)\n",
    "        plt.show()\n",
    "    # plot averaged f1 score wrt different iterations in co-training process\n",
    "    averaged_coTrain_diff_iter_on_test_dv1 = np.mean(all_fold_coTrain_diff_iter_on_test_dv1, axis=0)\n",
    "    averaged_coTrain_diff_iter_on_test_dv2 = np.mean(all_fold_coTrain_diff_iter_on_test_dv2, axis=0)\n",
    "    \n",
    "    default_text_based = [averaged_coTrain_diff_iter_on_test_dv1[0]] * co_train_iteration\n",
    "    default_citation_based = [averaged_coTrain_diff_iter_on_test_dv2[0]] * co_train_iteration\n",
    "    default_step = np.arange(0, co_train_iteration)\n",
    "    co_train_text_based = averaged_coTrain_diff_iter_on_test_dv1[1:]\n",
    "    co_train_citation_based = averaged_coTrain_diff_iter_on_test_dv2[1:]\n",
    "    co_training_step = np.arange(1, co_train_iteration)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    plt.plot(default_step, default_text_based, linestyle='dashed', label=\"Text based default\")\n",
    "    plt.plot(default_step, default_citation_based, linestyle='dashdot', label=\"Citation based default\")\n",
    "    plt.plot(co_training_step, co_train_text_based, linestyle='solid', marker = \"*\", label=\"Text based\")\n",
    "    plt.plot(co_training_step, co_train_citation_based, linestyle='dotted', marker = \"+\", label=\"Citation based\")\n",
    "    ax.autoscale_view()\n",
    "    legend = ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=2)\n",
    "    plt.xlabel('Co-Training Iterations')\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.savefig((plot_save_path+plot_save_name+\"_diff_iter_f1_avg.png\"), dpi=300, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    co_train_accuracy = accuracy_score(allTrueLabel, allPredLabel_co_train)\n",
    "    co_train_f1 = f1_score(allTrueLabel, allPredLabel_co_train,average='macro')\n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel_co_train))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel_co_train).ravel())\n",
    "    \n",
    "    LR_accuracy = accuracy_score(allTrueLabel, allPredLabel_LR)\n",
    "    LR_f1 = f1_score(allTrueLabel, allPredLabel_LR,average='macro')\n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel_LR))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel_LR).ravel())\n",
    "    \n",
    "    SVM_accuracy = accuracy_score(allTrueLabel, allPredLabel_SVM)\n",
    "    SVM_f1 = f1_score(allTrueLabel, allPredLabel_SVM,average='macro')\n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel_SVM))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel_SVM).ravel())\n",
    "\n",
    "    \n",
    "    return LR_f1, SVM_f1, co_train_f1, all_fold_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-27T00:52:42.062Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load text embedding:  pv_dbow\n",
      "Total text vector records: 135796\n",
      "Vector dimension:  100\n",
      "Load citation embedding:  n2v\n",
      "Total citation vector records: 124922\n",
      "Vector dimension:  101\n",
      "For name:  j_read\n",
      "(136, 2)\n",
      "j_read  pass\n",
      "For name:  f_esteves\n",
      "(34, 2)\n",
      "f_esteves  pass\n",
      "For name:  c_miller\n",
      "(252, 2)\n",
      "c_miller  pass\n",
      "For name:  r_jha\n",
      "(11, 2)\n",
      "r_jha  pass\n",
      "For name:  a_lowe\n",
      "(102, 2)\n",
      "a_lowe  pass\n",
      "For name:  a_vega\n",
      "(20, 2)\n",
      "a_vega  pass\n",
      "For name:  k_smith\n",
      "(338, 2)\n",
      "k_smith  pass\n",
      "For name:  j_gordon\n",
      "(19, 2)\n",
      "j_gordon  pass\n",
      "For name:  s_liao\n",
      "(104, 2)\n",
      "s_liao  pass\n",
      "For name:  j_qian\n",
      "(17, 2)\n",
      "j_qian  pass\n",
      "For name:  s_bernardi\n",
      "(91, 2)\n",
      "s_bernardi  pass\n",
      "For name:  t_hill\n",
      "(15, 2)\n",
      "t_hill  pass\n",
      "For name:  s_schindler\n",
      "(51, 2)\n",
      "s_schindler  pass\n",
      "For name:  j_williams\n",
      "(625, 2)\n",
      "j_williams  pass\n",
      "For name:  s_jacobson\n",
      "(28, 2)\n",
      "s_jacobson  pass\n",
      "For name:  e_andrade\n",
      "(17, 2)\n",
      "e_andrade  pass\n",
      "For name:  t_santos\n",
      "(45, 2)\n",
      "t_santos  pass\n",
      "For name:  k_kim\n",
      "(1111, 2)\n",
      "Total sample size before apply threshold:  1111\n",
      "Counter({'0000-0002-6929-5359': 211, '0000-0001-9498-284X': 154, '0000-0002-5878-8895': 139, '0000-0002-1864-3392': 92, '0000-0002-7045-8004': 57, '0000-0001-7896-6751': 57, '0000-0002-7991-9428': 55, '0000-0002-4010-1063': 45, '0000-0002-2186-3484': 28, '0000-0002-4899-1929': 25, '0000-0003-0487-4242': 24, '0000-0002-3642-1486': 22, '0000-0001-9965-3535': 17, '0000-0002-4168-757X': 17, '0000-0001-6525-3744': 14, '0000-0002-3897-0278': 14, '0000-0002-1181-5112': 12, '0000-0003-1447-9385': 11, '0000-0002-7305-8786': 11, '0000-0002-2655-7806': 10, '0000-0003-3466-5353': 9, '0000-0002-7359-663X': 8, '0000-0003-4600-8668': 6, '0000-0002-1382-7088': 5, '0000-0002-9505-4882': 5, '0000-0003-3667-9900': 4, '0000-0001-9714-6038': 4, '0000-0002-4760-0228': 3, '0000-0003-4188-7915': 3, '0000-0001-9454-0427': 3, '0000-0002-0333-6808': 3, '0000-0003-2134-4964': 3, '0000-0002-6658-047X': 3, '0000-0003-1273-379X': 3, '0000-0002-7047-3183': 3, '0000-0002-1814-9546': 3, '0000-0003-4812-6297': 2, '0000-0001-6597-578X': 2, '0000-0002-5285-9138': 2, '0000-0002-6796-7844': 2, '0000-0002-1130-8698': 2, '0000-0001-8518-8150': 2, '0000-0002-7103-924X': 2, '0000-0002-5407-0202': 1, '0000-0001-6220-8411': 1, '0000-0002-7440-6703': 1, '0000-0002-1603-7559': 1, '0000-0003-0257-1707': 1, '0000-0001-8532-6517': 1, '0000-0001-6626-316X': 1, '0000-0002-3246-9861': 1, '0000-0002-7207-4389': 1, '0000-0001-9682-9654': 1, '0000-0002-0196-3832': 1, '0000-0001-8063-6081': 1, '0000-0003-2037-3333': 1, '0000-0001-8872-6751': 1})\n",
      "Total author before apply threshoid:  57\n",
      "Total author after apply threshoid:  3\n",
      "Total sample size after apply threshold:  504\n",
      "Total missing sample:  0\n",
      "(504, 101)\n",
      "Total missing sample:  47\n",
      "(504, 101)\n",
      "Labeled:  504  :  504\n",
      "(504, 103)\n",
      "(504, 103)\n",
      "k_kim is multi-class case, ignored\n",
      "For name:  d_ricci\n",
      "(40, 2)\n",
      "d_ricci  pass\n",
      "For name:  s_cameron\n",
      "(66, 2)\n",
      "s_cameron  pass\n",
      "For name:  t_wright\n",
      "(31, 2)\n",
      "t_wright  pass\n",
      "For name:  r_cunha\n",
      "(209, 2)\n",
      "r_cunha  pass\n",
      "For name:  s_fuchs\n",
      "(32, 2)\n",
      "s_fuchs  pass\n",
      "For name:  m_nawaz\n",
      "(9, 2)\n",
      "m_nawaz  pass\n",
      "For name:  k_harris\n",
      "(47, 2)\n",
      "k_harris  pass\n",
      "For name:  r_daniel\n",
      "(173, 2)\n",
      "r_daniel  pass\n",
      "For name:  k_xu\n",
      "(37, 2)\n",
      "k_xu  pass\n",
      "For name:  s_antunes\n",
      "(54, 2)\n",
      "s_antunes  pass\n",
      "For name:  k_cho\n",
      "(126, 2)\n",
      "k_cho  pass\n",
      "For name:  j_sanderson\n",
      "(31, 2)\n",
      "j_sanderson  pass\n",
      "For name:  s_uddin\n",
      "(39, 2)\n",
      "s_uddin  pass\n",
      "For name:  a_batista\n",
      "(48, 2)\n",
      "a_batista  pass\n",
      "For name:  h_pereira\n",
      "(70, 2)\n",
      "h_pereira  pass\n",
      "For name:  a_patel\n",
      "(262, 2)\n",
      "a_patel  pass\n",
      "For name:  r_graham\n",
      "(52, 2)\n",
      "r_graham  pass\n",
      "For name:  a_nilsson\n",
      "(42, 2)\n",
      "a_nilsson  pass\n",
      "For name:  m_soto\n",
      "(97, 2)\n",
      "m_soto  pass\n",
      "For name:  g_guidi\n",
      "(37, 2)\n",
      "g_guidi  pass\n",
      "For name:  e_andersson\n",
      "(138, 2)\n",
      "e_andersson  pass\n",
      "For name:  s_reid\n",
      "(132, 2)\n",
      "s_reid  pass\n",
      "For name:  a_maleki\n",
      "(25, 2)\n",
      "a_maleki  pass\n",
      "For name:  j_moon\n",
      "(203, 2)\n",
      "j_moon  pass\n",
      "For name:  t_abe\n",
      "(50, 2)\n",
      "t_abe  pass\n",
      "For name:  x_fu\n",
      "(16, 2)\n",
      "x_fu  pass\n",
      "For name:  f_ortega\n",
      "(368, 2)\n",
      "f_ortega  pass\n",
      "For name:  r_morris\n",
      "(409, 2)\n",
      "r_morris  pass\n",
      "For name:  w_fang\n",
      "(43, 2)\n",
      "w_fang  pass\n",
      "For name:  m_amaral\n",
      "(134, 2)\n",
      "m_amaral  pass\n",
      "For name:  h_song\n",
      "(210, 2)\n",
      "h_song  pass\n",
      "For name:  h_dai\n",
      "(6, 2)\n",
      "h_dai  pass\n",
      "For name:  y_nakajima\n",
      "(12, 2)\n",
      "y_nakajima  pass\n",
      "For name:  t_warner\n",
      "(68, 2)\n",
      "t_warner  pass\n",
      "For name:  s_saha\n",
      "(111, 2)\n",
      "s_saha  pass\n",
      "For name:  j_fernandez\n",
      "(28, 2)\n",
      "j_fernandez  pass\n",
      "For name:  m_pan\n",
      "(146, 2)\n",
      "m_pan  pass\n",
      "For name:  a_simon\n",
      "(117, 2)\n",
      "a_simon  pass\n",
      "For name:  r_freitas\n",
      "(73, 2)\n",
      "r_freitas  pass\n",
      "For name:  c_yun\n",
      "(284, 2)\n",
      "c_yun  pass\n",
      "For name:  j_huang\n",
      "(443, 2)\n",
      "j_huang  pass\n",
      "For name:  p_santos\n",
      "(92, 2)\n",
      "p_santos  pass\n",
      "For name:  n_young\n",
      "(182, 2)\n",
      "n_young  pass\n",
      "For name:  d_ross\n",
      "(25, 2)\n",
      "d_ross  pass\n",
      "For name:  q_wang\n",
      "(348, 2)\n",
      "q_wang  pass\n",
      "For name:  c_cardoso\n",
      "(52, 2)\n",
      "c_cardoso  pass\n",
      "For name:  j_matthews\n",
      "(65, 2)\n",
      "j_matthews  pass\n",
      "For name:  g_lee\n",
      "(202, 2)\n",
      "g_lee  pass\n",
      "For name:  m_salem\n",
      "(25, 2)\n",
      "m_salem  pass\n",
      "For name:  h_lai\n",
      "(165, 2)\n",
      "h_lai  pass\n",
      "For name:  r_harris\n",
      "(50, 2)\n",
      "r_harris  pass\n",
      "For name:  c_vaughan\n",
      "(83, 2)\n",
      "c_vaughan  pass\n",
      "For name:  e_thompson\n",
      "(181, 2)\n",
      "e_thompson  pass\n",
      "For name:  r_gomes\n",
      "(52, 2)\n",
      "r_gomes  pass\n",
      "For name:  r_bennett\n",
      "(93, 2)\n",
      "r_bennett  pass\n",
      "For name:  m_collins\n",
      "(57, 2)\n",
      "m_collins  pass\n",
      "For name:  m_cowley\n",
      "(132, 2)\n",
      "m_cowley  pass\n",
      "For name:  p_teixeira\n",
      "(213, 2)\n",
      "p_teixeira  pass\n",
      "For name:  c_cox\n",
      "(48, 2)\n",
      "c_cox  pass\n",
      "For name:  s_hsu\n",
      "(204, 2)\n",
      "s_hsu  pass\n",
      "For name:  f_williams\n",
      "(149, 2)\n",
      "f_williams  pass\n",
      "For name:  d_parsons\n",
      "(30, 2)\n",
      "d_parsons  pass\n",
      "For name:  a_choudhury\n",
      "(56, 2)\n",
      "a_choudhury  pass\n",
      "For name:  c_richter\n",
      "(11, 2)\n",
      "c_richter  pass\n",
      "For name:  m_hossain\n",
      "(102, 2)\n",
      "m_hossain  pass\n",
      "For name:  v_alves\n",
      "(24, 2)\n",
      "v_alves  pass\n",
      "For name:  j_becker\n",
      "(177, 2)\n",
      "j_becker  pass\n",
      "For name:  m_soares\n",
      "(247, 2)\n",
      "m_soares  pass\n",
      "For name:  j_yi\n",
      "(29, 2)\n",
      "j_yi  pass\n",
      "For name:  s_khan\n",
      "(193, 2)\n",
      "s_khan  pass\n",
      "For name:  a_rao\n",
      "(93, 2)\n",
      "a_rao  pass\n",
      "For name:  d_cameron\n",
      "(49, 2)\n",
      "d_cameron  pass\n",
      "For name:  c_morgan\n",
      "(43, 2)\n",
      "c_morgan  pass\n",
      "For name:  h_cui\n",
      "(40, 2)\n",
      "h_cui  pass\n",
      "For name:  p_zhang\n",
      "(137, 2)\n",
      "p_zhang  pass\n",
      "For name:  j_fernandes\n",
      "(208, 2)\n",
      "j_fernandes  pass\n",
      "For name:  a_jain\n",
      "(67, 2)\n",
      "a_jain  pass\n",
      "For name:  d_zhang\n",
      "(94, 2)\n",
      "d_zhang  pass\n",
      "For name:  b_huang\n",
      "(48, 2)\n",
      "b_huang  pass\n",
      "For name:  m_chong\n",
      "(43, 2)\n",
      "m_chong  pass\n",
      "For name:  m_cerqueira\n",
      "(41, 2)\n",
      "m_cerqueira  pass\n",
      "For name:  p_yang\n",
      "(227, 2)\n",
      "p_yang  pass\n",
      "For name:  j_marques\n",
      "(183, 2)\n",
      "j_marques  pass\n",
      "For name:  n_ali\n",
      "(14, 2)\n",
      "n_ali  pass\n",
      "For name:  h_ng\n",
      "(109, 2)\n",
      "h_ng  pass\n",
      "For name:  m_viana\n",
      "(139, 2)\n",
      "m_viana  pass\n",
      "For name:  t_inoue\n",
      "(70, 2)\n",
      "t_inoue  pass\n",
      "For name:  b_meyer\n",
      "(92, 2)\n",
      "b_meyer  pass\n",
      "For name:  c_liao\n",
      "(35, 2)\n",
      "c_liao  pass\n",
      "For name:  k_wheeler\n",
      "(28, 2)\n",
      "k_wheeler  pass\n",
      "For name:  m_rizzo\n",
      "(152, 2)\n",
      "m_rizzo  pass\n",
      "For name:  y_shi\n",
      "(67, 2)\n",
      "y_shi  pass\n",
      "For name:  c_luo\n",
      "(78, 2)\n",
      "c_luo  pass\n",
      "For name:  j_arthur\n",
      "(42, 2)\n",
      "j_arthur  pass\n",
      "For name:  m_ansari\n",
      "(34, 2)\n",
      "m_ansari  pass\n",
      "For name:  g_anderson\n",
      "(103, 2)\n",
      "g_anderson  pass\n",
      "For name:  m_hidalgo\n",
      "(279, 2)\n",
      "m_hidalgo  pass\n",
      "For name:  k_jacobsen\n",
      "(113, 2)\n",
      "k_jacobsen  pass\n",
      "For name:  s_kelly\n",
      "(102, 2)\n",
      "s_kelly  pass\n",
      "For name:  s_james\n",
      "(59, 2)\n",
      "s_james  pass\n",
      "For name:  p_persson\n",
      "(80, 2)\n",
      "p_persson  pass\n",
      "For name:  y_tanaka\n",
      "(20, 2)\n",
      "y_tanaka  pass\n",
      "For name:  c_gao\n",
      "(189, 2)\n",
      "c_gao  pass\n",
      "For name:  w_jung\n",
      "(33, 2)\n",
      "w_jung  pass\n",
      "For name:  s_lewis\n",
      "(306, 2)\n",
      "s_lewis  pass\n",
      "For name:  w_han\n",
      "(34, 2)\n",
      "w_han  pass\n",
      "For name:  m_shah\n",
      "(17, 2)\n",
      "m_shah  pass\n",
      "For name:  c_arango\n",
      "(185, 2)\n",
      "c_arango  pass\n",
      "For name:  r_young\n",
      "(361, 2)\n",
      "r_young  pass\n",
      "For name:  r_coleman\n",
      "(34, 2)\n",
      "r_coleman  pass\n",
      "For name:  b_kang\n",
      "(20, 2)\n",
      "b_kang  pass\n",
      "For name:  s_carter\n",
      "(205, 2)\n",
      "s_carter  pass\n",
      "For name:  c_thomas\n",
      "(102, 2)\n",
      "c_thomas  pass\n",
      "For name:  m_gutierrez\n",
      "(32, 2)\n",
      "m_gutierrez  pass\n",
      "For name:  s_moon\n",
      "(85, 2)\n",
      "s_moon  pass\n",
      "For name:  r_pereira\n",
      "(202, 2)\n",
      "r_pereira  pass\n",
      "For name:  a_nielsen\n",
      "(132, 2)\n",
      "a_nielsen  pass\n",
      "For name:  j_conde\n",
      "(84, 2)\n",
      "j_conde  pass\n",
      "For name:  k_wright\n",
      "(59, 2)\n",
      "k_wright  pass\n",
      "For name:  m_parker\n",
      "(280, 2)\n",
      "m_parker  pass\n",
      "For name:  h_huang\n",
      "(224, 2)\n",
      "h_huang  pass\n",
      "For name:  j_terry\n",
      "(57, 2)\n",
      "j_terry  pass\n",
      "For name:  y_xu\n",
      "(137, 2)\n",
      "y_xu  pass\n",
      "For name:  a_melo\n",
      "(48, 2)\n",
      "a_melo  pass\n",
      "For name:  r_doyle\n",
      "(11, 2)\n",
      "r_doyle  pass\n",
      "For name:  m_bernardo\n",
      "(250, 2)\n",
      "m_bernardo  pass\n",
      "For name:  j_soares\n",
      "(49, 2)\n",
      "j_soares  pass\n",
      "For name:  j_richard\n",
      "(179, 2)\n",
      "j_richard  pass\n",
      "For name:  p_robinson\n",
      "(275, 2)\n",
      "Total sample size before apply threshold:  275\n",
      "Counter({'0000-0002-7878-0313': 133, '0000-0002-0736-9199': 119, '0000-0002-3156-3418': 19, '0000-0002-0577-3147': 4})\n",
      "Total author before apply threshoid:  4\n",
      "Total author after apply threshoid:  2\n",
      "Total sample size after apply threshold:  252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing sample:  0\n",
      "(252, 101)\n",
      "Total missing sample:  6\n",
      "(252, 101)\n",
      "Labeled:  252  :  252\n",
      "(252, 103)\n",
      "(252, 103)\n",
      "p_robinson is binary case\n",
      "[('p_robinson_0', 0.47345132743362833), ('p_robinson_1', 0.5265486725663717)]\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_0', -1, -1, -1, -1, -1, -1, 'p_robinson_1', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_0', -1, -1, 'p_robinson_1', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_1', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_0', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_0', -1, -1, -1, -1, -1, -1, -1, 'p_robinson_0', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_1', -1, -1, 'p_robinson_1', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "P value:  1  N value:  1\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225]\n",
      "Initial L size:  10\n",
      "Initial U size:  216\n",
      "Initial U prime size:  216\n",
      "L:  [11, 18, 41, 44, 110, 124, 157, 165, 189, 192]\n",
      "U:  []\n",
      "U_prime:  [132, 122, 193, 45, 104, 170, 63, 88, 210, 81, 213, 24, 4, 62, 133, 102, 3, 211, 12, 216, 95, 84, 164, 71, 38, 144, 53, 65, 223, 158, 138, 173, 106, 31, 14, 10, 30, 20, 89, 137, 186, 188, 34, 119, 130, 25, 61, 92, 9, 60, 204, 73, 50, 94, 121, 207, 225, 80, 32, 224, 57, 33, 174, 7, 51, 194, 72, 82, 28, 91, 142, 131, 47, 43, 176, 93, 154, 177, 26, 134, 222, 79, 49, 212, 118, 155, 85, 52, 190, 46, 76, 5, 220, 97, 148, 13, 187, 70, 197, 218, 166, 123, 139, 147, 146, 101, 184, 152, 111, 203, 37, 141, 180, 96, 17, 128, 105, 178, 159, 66, 99, 179, 0, 27, 114, 8, 78, 200, 214, 208, 151, 209, 35, 199, 86, 36, 143, 175, 29, 58, 163, 198, 108, 77, 40, 100, 167, 23, 98, 75, 191, 39, 145, 127, 68, 129, 150, 161, 172, 185, 153, 206, 90, 103, 67, 221, 55, 149, 156, 169, 125, 219, 59, 109, 2, 202, 136, 54, 64, 120, 162, 116, 48, 21, 42, 83, 1, 182, 135, 215, 16, 117, 112, 87, 217, 160, 181, 15, 107, 126, 69, 140, 183, 168, 201, 113, 115, 74, 56, 22, 6, 195, 205, 19, 171, 196]\n",
      "P:  48  :  [0.9297 0.0703]\n",
      "N:  105  :  [0.0512 0.9488]\n",
      "P:  154  :  [0.9602 0.0398]\n",
      "N:  53  :  [0.0227 0.9773]\n",
      "[([48], [154]), ([105], [53])]\n",
      "p_robinson_0  (u' idx):  {48, 154}\n",
      "p_robinson_0  (U idx):  [9, 68]\n",
      "p_robinson_1  (u' idx):  {105, 53}\n",
      "p_robinson_1  (U idx):  [101, 94]\n",
      "[([48], [154]), ([105], [53])]\n",
      "[9, 68, 101, 94]\n",
      "Current iter h1 new:  [9, 101]  probs:  [0.929726524614125, 0.9487625041008787]\n",
      "Current iter h2 new:  [68, 94]  probs:  [0.960185578113633, 0.9773205810261463]\n",
      "P:  84  :  [0.946 0.054]\n",
      "N:  38  :  [0.0369 0.9631]\n",
      "P:  39  :  [0.9598 0.0402]\n",
      "N:  5  :  [0.0222 0.9778]\n",
      "[([84], [39]), ([38], [5])]\n",
      "p_robinson_0  (u' idx):  {84, 39}\n",
      "p_robinson_0  (U idx):  [85, 137]\n",
      "p_robinson_1  (u' idx):  {5, 38}\n",
      "p_robinson_1  (U idx):  [170, 89]\n",
      "[([84], [39]), ([38], [5])]\n",
      "[85, 137, 170, 89]\n",
      "Current iter h1 new:  [85, 89]  probs:  [0.9459534037880913, 0.9630522430655222]\n",
      "Current iter h2 new:  [137, 170]  probs:  [0.9597758654402104, 0.977768063582695]\n",
      "P:  109  :  [0.9501 0.0499]\n",
      "N:  1  :  [0.034 0.966]\n",
      "P:  115  :  [0.9627 0.0373]\n",
      "N:  63  :  [0.018 0.982]\n",
      "[([109], [115]), ([1], [63])]\n",
      "p_robinson_0  (u' idx):  {115, 109}\n",
      "p_robinson_0  (U idx):  [0, 105]\n",
      "p_robinson_1  (u' idx):  {1, 63}\n",
      "p_robinson_1  (U idx):  [122, 28]\n",
      "[([109], [115]), ([1], [63])]\n",
      "[0, 105, 122, 28]\n",
      "Current iter h1 new:  [105, 122]  probs:  [0.9501394266240023, 0.9659645244407937]\n",
      "Current iter h2 new:  [0, 28]  probs:  [0.9627159389627913, 0.9819862928339917]\n",
      "P:  154  :  [0.9589 0.0411]\n",
      "N:  75  :  [0.0303 0.9697]\n",
      "P:  64  :  [0.9693 0.0307]\n",
      "N:  161  :  [0.0249 0.9751]\n",
      "[([154], [64]), ([75], [161])]\n",
      "p_robinson_0  (u' idx):  {64, 154}\n",
      "p_robinson_0  (U idx):  [131, 55]\n",
      "p_robinson_1  (u' idx):  {161, 75}\n",
      "p_robinson_1  (U idx):  [109, 49]\n",
      "[([154], [64]), ([75], [161])]\n",
      "[131, 55, 109, 49]\n",
      "Current iter h1 new:  [55, 49]  probs:  [0.9588917699424305, 0.9696568100020242]\n",
      "Current iter h2 new:  [131, 109]  probs:  [0.9693377695004997, 0.9750999530000889]\n",
      "P:  177  :  [0.9641 0.0359]\n",
      "N:  45  :  [0.0283 0.9717]\n",
      "P:  108  :  [0.9666 0.0334]\n",
      "N:  149  :  [0.0211 0.9789]\n",
      "[([177], [108]), ([45], [149])]\n",
      "p_robinson_0  (u' idx):  {177, 108}\n",
      "p_robinson_0  (U idx):  [87, 99]\n",
      "p_robinson_1  (u' idx):  {45, 149}\n",
      "p_robinson_1  (U idx):  [204, 103]\n",
      "[([177], [108]), ([45], [149])]\n",
      "[87, 99, 204, 103]\n",
      "Current iter h1 new:  [87, 204]  probs:  [0.9640901656304637, 0.9717293540694719]\n",
      "Current iter h2 new:  [99, 103]  probs:  [0.9666486910569666, 0.9789350261850788]\n",
      "P:  27  :  [0.9571 0.0429]\n",
      "N:  154  :  [0.0247 0.9753]\n",
      "P:  78  :  [0.9704 0.0296]\n",
      "N:  64  :  [0.0174 0.9826]\n",
      "[([27], [78]), ([154], [64])]\n",
      "p_robinson_0  (u' idx):  {27, 78}\n",
      "p_robinson_0  (U idx):  [158, 46]\n",
      "p_robinson_1  (u' idx):  {64, 154}\n",
      "p_robinson_1  (U idx):  [43, 59]\n",
      "[([27], [78]), ([154], [64])]\n",
      "[158, 46, 43, 59]\n",
      "Current iter h1 new:  [158, 59]  probs:  [0.9570712621047542, 0.9752826630763516]\n",
      "Current iter h2 new:  [46, 43]  probs:  [0.9703616293968678, 0.9826345857828374]\n",
      "P:  173  :  [0.958 0.042]\n",
      "N:  63  :  [0.0241 0.9759]\n",
      "P:  173  :  [0.9716 0.0284]\n",
      "N:  122  :  [0.0162 0.9838]\n",
      "[([173], [173]), ([63], [122])]\n",
      "p_robinson_0  (u' idx):  {173}\n",
      "p_robinson_0  (U idx):  [15]\n",
      "p_robinson_1  (u' idx):  {122, 63}\n",
      "p_robinson_1  (U idx):  [163, 176]\n",
      "[([173], [173]), ([63], [122])]\n",
      "[15, 163, 176]\n",
      "Current iter h1 new:  [15, 176]  probs:  [0.9580048125122432, 0.9759229047425094]\n",
      "Current iter h2 new:  [15, 163]  probs:  [0.9716138627773626, 0.9837671106008063]\n",
      "P:  24  :  [0.9583 0.0417]\n",
      "N:  135  :  [0.0236 0.9764]\n",
      "P:  71  :  [0.9718 0.0282]\n",
      "N:  59  :  [0.0158 0.9842]\n",
      "[([24], [71]), ([135], [59])]\n",
      "p_robinson_0  (u' idx):  {24, 71}\n",
      "p_robinson_0  (U idx):  [53, 118]\n",
      "p_robinson_1  (u' idx):  {59, 135}\n",
      "p_robinson_1  (U idx):  [82, 150]\n",
      "[([24], [71]), ([135], [59])]\n",
      "[53, 118, 82, 150]\n",
      "Current iter h1 new:  [53, 150]  probs:  [0.9582619596572, 0.976405864645078]\n",
      "Current iter h2 new:  [118, 82]  probs:  [0.9718081660704778, 0.9842019362962188]\n",
      "P:  6  :  [0.9618 0.0382]\n",
      "N:  22  :  [0.0218 0.9782]\n",
      "P:  91  :  [0.9698 0.0302]\n",
      "N:  159  :  [0.0149 0.9851]\n",
      "[([6], [91]), ([22], [159])]\n",
      "p_robinson_0  (u' idx):  {91, 6}\n",
      "p_robinson_0  (U idx):  [37, 210]\n",
      "p_robinson_1  (u' idx):  {22, 159}\n",
      "p_robinson_1  (U idx):  [38, 135]\n",
      "[([6], [91]), ([22], [159])]\n",
      "[37, 210, 38, 135]\n",
      "Current iter h1 new:  [210, 38]  probs:  [0.9618224965799047, 0.9781710535711474]\n",
      "Current iter h2 new:  [37, 135]  probs:  [0.9698070995537983, 0.9850530261271783]\n",
      "P:  32  :  [0.9631 0.0369]\n",
      "N:  162  :  [0.0209 0.9791]\n",
      "P:  128  :  [0.9723 0.0277]\n",
      "N:  5  :  [0.0126 0.9874]\n",
      "[([32], [128]), ([162], [5])]\n",
      "p_robinson_0  (u' idx):  {32, 128}\n",
      "p_robinson_0  (U idx):  [186, 129]\n",
      "p_robinson_1  (u' idx):  {162, 5}\n",
      "p_robinson_1  (U idx):  [181, 88]\n",
      "[([32], [128]), ([162], [5])]\n",
      "[186, 129, 181, 88]\n",
      "Current iter h1 new:  [186, 181]  probs:  [0.9630994724668376, 0.979147424633133]\n",
      "Current iter h2 new:  [129, 88]  probs:  [0.9723284210261284, 0.9874299147398073]\n",
      "P:  147  :  [0.9664 0.0336]\n",
      "N:  110  :  [0.0199 0.9801]\n",
      "P:  40  :  [0.9729 0.0271]\n",
      "N:  78  :  [0.0127 0.9873]\n",
      "[([147], [40]), ([110], [78])]\n",
      "p_robinson_0  (u' idx):  {40, 147}\n",
      "p_robinson_0  (U idx):  [50, 48]\n",
      "p_robinson_1  (u' idx):  {78, 110}\n",
      "p_robinson_1  (U idx):  [166, 175]\n",
      "[([147], [40]), ([110], [78])]\n",
      "[50, 48, 166, 175]\n",
      "Current iter h1 new:  [48, 175]  probs:  [0.9663690911697986, 0.9800804256895087]\n",
      "Current iter h2 new:  [50, 166]  probs:  [0.9728937238710929, 0.9873471231123301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  79  :  [0.96 0.04]\n",
      "N:  91  :  [0.0191 0.9809]\n",
      "P:  153  :  [0.9739 0.0261]\n",
      "N:  56  :  [0.0123 0.9877]\n",
      "[([79], [153]), ([91], [56])]\n",
      "p_robinson_0  (u' idx):  {153, 79}\n",
      "p_robinson_0  (U idx):  [217, 147]\n",
      "p_robinson_1  (u' idx):  {56, 91}\n",
      "p_robinson_1  (U idx):  [93, 159]\n",
      "[([79], [153]), ([91], [56])]\n",
      "[217, 147, 93, 159]\n",
      "Current iter h1 new:  [147, 159]  probs:  [0.9600069224404275, 0.980883421179994]\n",
      "Current iter h2 new:  [217, 93]  probs:  [0.9738676994628555, 0.9876578492382213]\n",
      "P:  134  :  [0.9703 0.0297]\n",
      "N:  109  :  [0.0186 0.9814]\n",
      "P:  156  :  [0.976 0.024]\n",
      "N:  56  :  [0.0124 0.9876]\n",
      "[([134], [156]), ([109], [56])]\n",
      "p_robinson_0  (u' idx):  {156, 134}\n",
      "p_robinson_0  (U idx):  [168, 202]\n",
      "p_robinson_1  (u' idx):  {56, 109}\n",
      "p_robinson_1  (U idx):  [154, 77]\n",
      "[([134], [156]), ([109], [56])]\n",
      "[168, 202, 154, 77]\n",
      "Current iter h1 new:  [202, 77]  probs:  [0.9703441114966747, 0.9814159956618238]\n",
      "Current iter h2 new:  [168, 154]  probs:  [0.976017885735231, 0.9875963669845647]\n",
      "P:  34  :  [0.9692 0.0308]\n",
      "N:  149  :  [0.0177 0.9823]\n",
      "P:  95  :  [0.9713 0.0287]\n",
      "N:  120  :  [0.0121 0.9879]\n",
      "[([34], [95]), ([149], [120])]\n",
      "p_robinson_0  (u' idx):  {34, 95}\n",
      "p_robinson_0  (U idx):  [130, 214]\n",
      "p_robinson_1  (u' idx):  {120, 149}\n",
      "p_robinson_1  (U idx):  [185, 126]\n",
      "[([34], [95]), ([149], [120])]\n",
      "[130, 214, 185, 126]\n",
      "Current iter h1 new:  [130, 126]  probs:  [0.9691694238352407, 0.9823289115115675]\n",
      "Current iter h2 new:  [214, 185]  probs:  [0.9712682089895537, 0.9879452385712065]\n",
      "P:  60  :  [0.9698 0.0302]\n",
      "N:  109  :  [0.0188 0.9812]\n",
      "P:  143  :  [0.9678 0.0322]\n",
      "N:  73  :  [0.0126 0.9874]\n",
      "[([60], [143]), ([109], [73])]\n",
      "p_robinson_0  (u' idx):  {60, 143}\n",
      "p_robinson_0  (U idx):  [212, 112]\n",
      "p_robinson_1  (u' idx):  {73, 109}\n",
      "p_robinson_1  (U idx):  [218, 23]\n",
      "[([60], [143]), ([109], [73])]\n",
      "[212, 112, 218, 23]\n",
      "Current iter h1 new:  [212, 23]  probs:  [0.9698084078546648, 0.9812135141502654]\n",
      "Current iter h2 new:  [112, 218]  probs:  [0.9678289063914748, 0.9874460649670763]\n",
      "P:  94  :  [0.9724 0.0276]\n",
      "N:  103  :  [0.0189 0.9811]\n",
      "P:  117  :  [0.9691 0.0309]\n",
      "N:  40  :  [0.0135 0.9865]\n",
      "[([94], [117]), ([103], [40])]\n",
      "p_robinson_0  (u' idx):  {117, 94}\n",
      "p_robinson_0  (U idx):  [90, 209]\n",
      "p_robinson_1  (u' idx):  {40, 103}\n",
      "p_robinson_1  (U idx):  [207, 108]\n",
      "[([94], [117]), ([103], [40])]\n",
      "[90, 209, 207, 108]\n",
      "Current iter h1 new:  [209, 108]  probs:  [0.9724118172414479, 0.9810908179153055]\n",
      "Current iter h2 new:  [90, 207]  probs:  [0.969084188614613, 0.9865015262579843]\n",
      "P:  60  :  [0.9717 0.0283]\n",
      "N:  61  :  [0.0184 0.9816]\n",
      "P:  80  :  [0.97 0.03]\n",
      "N:  61  :  [0.013 0.987]\n",
      "[([60], [80]), ([61], [61])]\n",
      "p_robinson_0  (u' idx):  {80, 60}\n",
      "p_robinson_0  (U idx):  [96, 52]\n",
      "p_robinson_1  (u' idx):  {61}\n",
      "p_robinson_1  (U idx):  [190]\n",
      "[([60], [80]), ([61], [61])]\n",
      "[96, 52, 190]\n",
      "Current iter h1 new:  [52, 190]  probs:  [0.9716567443141847, 0.981627785954447]\n",
      "Current iter h2 new:  [96, 190]  probs:  [0.9700099806492934, 0.9869528665687596]\n",
      "P:  146  :  [0.9723 0.0277]\n",
      "N:  124  :  [0.0183 0.9817]\n",
      "P:  128  :  [0.9641 0.0359]\n",
      "N:  100  :  [0.0128 0.9872]\n",
      "[([146], [128]), ([124], [100])]\n",
      "p_robinson_0  (u' idx):  {128, 146}\n",
      "p_robinson_0  (U idx):  [1, 205]\n",
      "p_robinson_1  (u' idx):  {100, 124}\n",
      "p_robinson_1  (U idx):  [167, 116]\n",
      "[([146], [128]), ([124], [100])]\n",
      "[1, 205, 167, 116]\n",
      "Current iter h1 new:  [205, 116]  probs:  [0.9723148269615575, 0.9816712675235534]\n",
      "Current iter h2 new:  [1, 167]  probs:  [0.9641424441467292, 0.9871857207064816]\n",
      "P:  139  :  [0.9762 0.0238]\n",
      "N:  116  :  [0.0166 0.9834]\n",
      "P:  29  :  [0.9588 0.0412]\n",
      "N:  114  :  [0.0127 0.9873]\n",
      "[([139], [29]), ([116], [114])]\n",
      "p_robinson_0  (u' idx):  {139, 29}\n",
      "p_robinson_0  (U idx):  [56, 30]\n",
      "p_robinson_1  (u' idx):  {114, 116}\n",
      "p_robinson_1  (U idx):  [169, 219]\n",
      "[([139], [29]), ([116], [114])]\n",
      "[56, 30, 169, 219]\n",
      "Current iter h1 new:  [56, 219]  probs:  [0.9762053367062118, 0.9833931672400033]\n",
      "Current iter h2 new:  [30, 169]  probs:  [0.958829279351678, 0.98732901226754]\n",
      "P:  10  :  [0.9745 0.0255]\n",
      "N:  121  :  [0.0169 0.9831]\n",
      "P:  73  :  [0.9614 0.0386]\n",
      "N:  55  :  [0.0129 0.9871]\n",
      "[([10], [73]), ([121], [55])]\n",
      "p_robinson_0  (u' idx):  {73, 10}\n",
      "p_robinson_0  (U idx):  [111, 133]\n",
      "p_robinson_1  (u' idx):  {121, 55}\n",
      "p_robinson_1  (U idx):  [42, 134]\n",
      "[([10], [73]), ([121], [55])]\n",
      "[111, 133, 42, 134]\n",
      "Current iter h1 new:  [133, 42]  probs:  [0.9744931350638254, 0.9830515433561606]\n",
      "Current iter h2 new:  [111, 134]  probs:  [0.9613633627904833, 0.9870791402170738]\n",
      "P:  2  :  [0.9735 0.0265]\n",
      "N:  19  :  [0.0165 0.9835]\n",
      "P:  56  :  [0.9618 0.0382]\n",
      "N:  39  :  [0.0161 0.9839]\n",
      "[([2], [56]), ([19], [39])]\n",
      "p_robinson_0  (u' idx):  {56, 2}\n",
      "p_robinson_0  (U idx):  [155, 45]\n",
      "p_robinson_1  (u' idx):  {19, 39}\n",
      "p_robinson_1  (U idx):  [144, 80]\n",
      "[([2], [56]), ([19], [39])]\n",
      "[155, 45, 144, 80]\n",
      "Current iter h1 new:  [45, 144]  probs:  [0.9735079323573301, 0.9835237303249417]\n",
      "Current iter h2 new:  [155, 80]  probs:  [0.9618036303823543, 0.9839158593750272]\n",
      "P:  34  :  [0.9697 0.0303]\n",
      "N:  23  :  [0.0171 0.9829]\n",
      "P:  29  :  [0.9655 0.0345]\n",
      "N:  106  :  [0.0166 0.9834]\n",
      "[([34], [29]), ([23], [106])]\n",
      "p_robinson_0  (u' idx):  {34, 29}\n",
      "p_robinson_0  (U idx):  [73, 119]\n",
      "p_robinson_1  (u' idx):  {106, 23}\n",
      "p_robinson_1  (U idx):  [125, 31]\n",
      "[([34], [29]), ([23], [106])]\n",
      "[73, 119, 125, 31]\n",
      "Current iter h1 new:  [73, 31]  probs:  [0.9696676629221873, 0.9828578763855577]\n",
      "Current iter h2 new:  [119, 125]  probs:  [0.9655015404105058, 0.9833691074406523]\n",
      "P:  34  :  [0.9698 0.0302]\n",
      "N:  21  :  [0.0152 0.9848]\n",
      "P:  119  :  [0.9687 0.0313]\n",
      "N:  39  :  [0.0152 0.9848]\n",
      "[([34], [119]), ([21], [39])]\n",
      "p_robinson_0  (u' idx):  {34, 119}\n",
      "p_robinson_0  (U idx):  [32, 183]\n",
      "p_robinson_1  (u' idx):  {21, 39}\n",
      "p_robinson_1  (U idx):  [173, 7]\n",
      "[([34], [119]), ([21], [39])]\n",
      "[32, 183, 173, 7]\n",
      "Current iter h1 new:  [32, 173]  probs:  [0.969785488356119, 0.9847927271935254]\n",
      "Current iter h2 new:  [183, 7]  probs:  [0.9686935597793961, 0.9847576542042256]\n",
      "P:  82  :  [0.9829 0.0171]\n",
      "N:  121  :  [0.0147 0.9853]\n",
      "P:  95  :  [0.9678 0.0322]\n",
      "N:  14  :  [0.0152 0.9848]\n",
      "[([82], [95]), ([121], [14])]\n",
      "p_robinson_0  (u' idx):  {82, 95}\n",
      "p_robinson_0  (U idx):  [58, 206]\n",
      "p_robinson_1  (u' idx):  {121, 14}\n",
      "p_robinson_1  (U idx):  [6, 95]\n",
      "[([82], [95]), ([121], [14])]\n",
      "[58, 206, 6, 95]\n",
      "Current iter h1 new:  [58, 6]  probs:  [0.9828635842789449, 0.9852845690705068]\n",
      "Current iter h2 new:  [206, 95]  probs:  [0.9677731321738726, 0.9848365422998173]\n",
      "P:  43  :  [0.9783 0.0217]\n",
      "N:  39  :  [0.015 0.985]\n",
      "P:  81  :  [0.9685 0.0315]\n",
      "N:  1  :  [0.0167 0.9833]\n",
      "[([43], [81]), ([39], [1])]\n",
      "p_robinson_0  (u' idx):  {81, 43}\n",
      "p_robinson_0  (U idx):  [198, 26]\n",
      "p_robinson_1  (u' idx):  {1, 39}\n",
      "p_robinson_1  (U idx):  [193, 91]\n",
      "[([43], [81]), ([39], [1])]\n",
      "[198, 26, 193, 91]\n",
      "Current iter h1 new:  [26, 91]  probs:  [0.9782607936339394, 0.9850404089576885]\n",
      "Current iter h2 new:  [198, 193]  probs:  [0.9685477200987092, 0.9833290901528142]\n",
      "P:  54  :  [0.98 0.02]\n",
      "N:  13  :  [0.0179 0.9821]\n",
      "P:  81  :  [0.9629 0.0371]\n",
      "N:  5  :  [0.0193 0.9807]\n",
      "[([54], [81]), ([13], [5])]\n",
      "p_robinson_0  (u' idx):  {81, 54}\n",
      "p_robinson_0  (U idx):  [75, 146]\n",
      "p_robinson_1  (u' idx):  {5, 13}\n",
      "p_robinson_1  (U idx):  [24, 84]\n",
      "[([54], [81]), ([13], [5])]\n",
      "[75, 146, 24, 84]\n",
      "Current iter h1 new:  [146, 84]  probs:  [0.9800036188008946, 0.9821418463049711]\n",
      "Current iter h2 new:  [75, 24]  probs:  [0.962876745248235, 0.9806613707888229]\n",
      "P:  102  :  [0.978 0.022]\n",
      "N:  29  :  [0.0174 0.9826]\n",
      "P:  102  :  [0.9639 0.0361]\n",
      "N:  54  :  [0.0187 0.9813]\n",
      "[([102], [102]), ([29], [54])]\n",
      "p_robinson_0  (u' idx):  {102}\n",
      "p_robinson_0  (U idx):  [107]\n",
      "p_robinson_1  (u' idx):  {29, 54}\n",
      "p_robinson_1  (U idx):  [224, 203]\n",
      "[([102], [102]), ([29], [54])]\n",
      "[107, 224, 203]\n",
      "Current iter h1 new:  [107, 224]  probs:  [0.978034561320736, 0.9825858428650963]\n",
      "Current iter h2 new:  [107, 203]  probs:  [0.9639011895153374, 0.9813436640787062]\n",
      "P:  88  :  [0.9783 0.0217]\n",
      "N:  76  :  [0.0191 0.9809]\n",
      "P:  106  :  [0.964 0.036]\n",
      "N:  84  :  [0.0184 0.9816]\n",
      "[([88], [106]), ([76], [84])]\n",
      "p_robinson_0  (u' idx):  {88, 106}\n",
      "p_robinson_0  (U idx):  [136, 22]\n",
      "p_robinson_1  (u' idx):  {76, 84}\n",
      "p_robinson_1  (U idx):  [191, 221]\n",
      "[([88], [106]), ([76], [84])]\n",
      "[136, 22, 191, 221]\n",
      "Current iter h1 new:  [136, 191]  probs:  [0.9782989767874759, 0.9809019077509266]\n",
      "Current iter h2 new:  [22, 221]  probs:  [0.9639752379221037, 0.9815601437273143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  33  :  [0.9754 0.0246]\n",
      "N:  69  :  [0.0212 0.9788]\n",
      "P:  74  :  [0.9646 0.0354]\n",
      "N:  30  :  [0.0212 0.9788]\n",
      "[([33], [74]), ([69], [30])]\n",
      "p_robinson_0  (u' idx):  {33, 74}\n",
      "p_robinson_0  (U idx):  [194, 100]\n",
      "p_robinson_1  (u' idx):  {69, 30}\n",
      "p_robinson_1  (U idx):  [86, 33]\n",
      "[([33], [74]), ([69], [30])]\n",
      "[194, 100, 86, 33]\n",
      "Current iter h1 new:  [194, 86]  probs:  [0.9753614680190892, 0.9787531605767716]\n",
      "Current iter h2 new:  [100, 33]  probs:  [0.9646368155181921, 0.9788256770468118]\n",
      "P:  34  :  [0.9782 0.0218]\n",
      "N:  50  :  [0.0235 0.9765]\n",
      "P:  88  :  [0.9638 0.0362]\n",
      "N:  85  :  [0.0206 0.9794]\n",
      "[([34], [88]), ([50], [85])]\n",
      "p_robinson_0  (u' idx):  {88, 34}\n",
      "p_robinson_0  (U idx):  [182, 47]\n",
      "p_robinson_1  (u' idx):  {50, 85}\n",
      "p_robinson_1  (U idx):  [152, 162]\n",
      "[([34], [88]), ([50], [85])]\n",
      "[182, 47, 152, 162]\n",
      "Current iter h1 new:  [47, 152]  probs:  [0.9781995261992055, 0.9765388361001414]\n",
      "Current iter h2 new:  [182, 162]  probs:  [0.9637959145395408, 0.9793588899657775]\n",
      "Total Labeled number:  127  Still unlabeled number:  99\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9610194902548725, 0.9610194902548725, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.9614814814814816, 0.923076923076923, 0.923076923076923, 0.923076923076923, 0.923076923076923, 0.9614814814814816, 0.923076923076923, 0.923076923076923, 0.923076923076923, 0.923076923076923, 0.923076923076923, 0.923076923076923]\n",
      "Self labeled sample index:  defaultdict(<class 'list'>, {'p_robinson_0': [[9, 68], [85, 137], [0, 105], [131, 55], [87, 99], [158, 46], [15], [53, 118], [37, 210], [186, 129], [50, 48], [217, 147], [168, 202], [130, 214], [212, 112], [90, 209], [96, 52], [1, 205], [56, 30], [111, 133], [155, 45], [73, 119], [32, 183], [58, 206], [198, 26], [75, 146], [107], [136, 22], [194, 100], [182, 47]], 'p_robinson_1': [[101, 94], [170, 89], [122, 28], [109, 49], [204, 103], [43, 59], [163, 176], [82, 150], [38, 135], [181, 88], [166, 175], [93, 159], [154, 77], [185, 126], [218, 23], [207, 108], [190], [167, 116], [169, 219], [42, 134], [144, 80], [125, 31], [173, 7], [6, 95], [193, 91], [24, 84], [224, 203], [191, 221], [86, 33], [152, 162]]})\n",
      "y1 disagree on 12  Proba:  [0.1446 0.8554]\n",
      "y2 not aggreed on  12 Proba:  [0.6113 0.3887]\n",
      "product probas: [0.08841723879206606, 0.3325062492474803]\n",
      "result idx:  1  result:  p_robinson_1\n",
      "y1 disagree on 21  Proba:  [0.0724 0.9276]\n",
      "y2 not aggreed on  21 Proba:  [0.5236 0.4764]\n",
      "product probas: [0.0379328172122086, 0.44186880955348506]\n",
      "result idx:  1  result:  p_robinson_1\n",
      "co-train f1:                precision    recall  f1-score   support\n",
      "\n",
      "p_robinson_0       1.00      1.00      1.00        12\n",
      "p_robinson_1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "LR f1:                precision    recall  f1-score   support\n",
      "\n",
      "p_robinson_0       1.00      0.92      0.96        12\n",
      "p_robinson_1       0.93      1.00      0.97        14\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.97      0.96      0.96        26\n",
      "weighted avg       0.96      0.96      0.96        26\n",
      "\n",
      "SVM f1:                precision    recall  f1-score   support\n",
      "\n",
      "p_robinson_0       1.00      0.92      0.96        12\n",
      "p_robinson_1       0.93      1.00      0.97        14\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.97      0.96      0.96        26\n",
      "weighted avg       0.96      0.96      0.96        26\n",
      "\n",
      "[('p_robinson_0', 0.47345132743362833), ('p_robinson_1', 0.5265486725663717)]\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_1', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_0', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_1', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_1', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_0', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_0', -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_1', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_0', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 'p_robinson_1', 'p_robinson_0', -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "P value:  1  N value:  1\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225]\n",
      "Initial L size:  10\n",
      "Initial U size:  216\n",
      "Initial U prime size:  216\n",
      "L:  [19, 53, 82, 109, 130, 158, 167, 183, 199, 200]\n",
      "U:  []\n",
      "U_prime:  [224, 150, 216, 175, 64, 187, 124, 120, 2, 115, 35, 146, 22, 140, 191, 139, 117, 31, 131, 20, 61, 23, 151, 104, 46, 219, 134, 196, 94, 107, 83, 21, 121, 95, 168, 75, 59, 220, 149, 170, 202, 25, 55, 214, 76, 100, 218, 147, 78, 157, 73, 127, 18, 45, 206, 8, 114, 103, 171, 77, 180, 125, 36, 57, 88, 47, 166, 142, 101, 172, 123, 52, 179, 41, 37, 177, 99, 7, 66, 5, 15, 74, 80, 155, 85, 138, 67, 65, 156, 173, 39, 60, 145, 129, 44, 90, 72, 118, 50, 207, 13, 116, 30, 169, 32, 4, 106, 38, 194, 105, 17, 217, 176, 11, 102, 198, 215, 161, 12, 128, 14, 56, 48, 122, 213, 112, 81, 222, 96, 84, 119, 212, 203, 34, 135, 49, 210, 87, 0, 162, 164, 3, 6, 208, 204, 40, 132, 113, 201, 221, 136, 28, 188, 42, 93, 133, 211, 71, 192, 193, 182, 223, 185, 174, 68, 24, 92, 178, 154, 159, 195, 43, 54, 165, 137, 189, 58, 1, 181, 148, 27, 89, 163, 97, 62, 16, 98, 63, 91, 186, 225, 108, 152, 126, 29, 110, 205, 69, 26, 33, 70, 51, 79, 209, 160, 9, 143, 144, 86, 153, 197, 111, 184, 10, 190, 141]\n",
      "P:  40  :  [0.9652 0.0348]\n",
      "N:  135  :  [0.0531 0.9469]\n",
      "P:  164  :  [0.9773 0.0227]\n",
      "N:  28  :  [0.0169 0.9831]\n",
      "[([40], [164]), ([135], [28])]\n",
      "p_robinson_0  (u' idx):  {40, 164}\n",
      "p_robinson_0  (U idx):  [202, 68]\n",
      "p_robinson_1  (u' idx):  {28, 135}\n",
      "p_robinson_1  (U idx):  [94, 49]\n",
      "[([40], [164]), ([135], [28])]\n",
      "[202, 68, 94, 49]\n",
      "Current iter h1 new:  [202, 49]  probs:  [0.9651875940690613, 0.9468913746444156]\n",
      "Current iter h2 new:  [68, 94]  probs:  [0.9773207488443635, 0.9830937999741033]\n",
      "P:  209  :  [0.9737 0.0263]\n",
      "N:  177  :  [0.044 0.956]\n",
      "P:  170  :  [0.9713 0.0287]\n",
      "N:  38  :  [0.0227 0.9773]\n",
      "[([209], [170]), ([177], [38])]\n",
      "p_robinson_0  (u' idx):  {209, 170}\n",
      "p_robinson_0  (U idx):  [10, 137]\n",
      "p_robinson_1  (u' idx):  {177, 38}\n",
      "p_robinson_1  (U idx):  [89, 170]\n",
      "[([209], [170]), ([177], [38])]\n",
      "[10, 137, 89, 170]\n",
      "Current iter h1 new:  [10, 89]  probs:  [0.9736642039187878, 0.9560276382576388]\n",
      "Current iter h2 new:  [137, 170]  probs:  [0.9712740574217427, 0.9773480981444186]\n",
      "P:  118  :  [0.9764 0.0236]\n",
      "N:  76  :  [0.0384 0.9616]\n",
      "P:  18  :  [0.9787 0.0213]\n",
      "N:  76  :  [0.0177 0.9823]\n",
      "[([118], [18]), ([76], [76])]\n",
      "p_robinson_0  (u' idx):  {18, 118}\n",
      "p_robinson_0  (U idx):  [131, 56]\n",
      "p_robinson_1  (u' idx):  {76}\n",
      "p_robinson_1  (U idx):  [5]\n",
      "[([118], [18]), ([76], [76])]\n",
      "[131, 56, 5]\n",
      "Current iter h1 new:  [56, 5]  probs:  [0.9763949746491515, 0.9615687612986135]\n",
      "Current iter h2 new:  [131, 5]  probs:  [0.9786962159302999, 0.9822769560381536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  125  :  [0.9774 0.0226]\n",
      "N:  161  :  [0.0378 0.9622]\n",
      "P:  72  :  [0.9805 0.0195]\n",
      "N:  53  :  [0.024 0.976]\n",
      "[([125], [72]), ([161], [53])]\n",
      "p_robinson_0  (u' idx):  {72, 125}\n",
      "p_robinson_0  (U idx):  [99, 212]\n",
      "p_robinson_1  (u' idx):  {161, 53}\n",
      "p_robinson_1  (U idx):  [159, 103]\n",
      "[([125], [72]), ([161], [53])]\n",
      "[99, 212, 159, 103]\n",
      "Current iter h1 new:  [212, 159]  probs:  [0.9773547817449242, 0.9621544322894119]\n",
      "Current iter h2 new:  [99, 103]  probs:  [0.9805233865840419, 0.9759785930712684]\n",
      "P:  102  :  [0.9828 0.0172]\n",
      "N:  63  :  [0.0295 0.9705]\n",
      "P:  23  :  [0.9823 0.0177]\n",
      "N:  113  :  [0.023 0.977]\n",
      "[([102], [23]), ([63], [113])]\n",
      "p_robinson_0  (u' idx):  {102, 23}\n",
      "p_robinson_0  (U idx):  [105, 46]\n",
      "p_robinson_1  (u' idx):  {113, 63}\n",
      "p_robinson_1  (U idx):  [14, 101]\n",
      "[([102], [23]), ([63], [113])]\n",
      "[105, 46, 14, 101]\n",
      "Current iter h1 new:  [105, 101]  probs:  [0.9827807352815912, 0.9704949569195778]\n",
      "Current iter h2 new:  [46, 14]  probs:  [0.9823368021107229, 0.9769602812684696]\n",
      "P:  75  :  [0.9853 0.0147]\n",
      "N:  130  :  [0.0272 0.9728]\n",
      "P:  100  :  [0.983 0.017]\n",
      "N:  155  :  [0.0205 0.9795]\n",
      "[([75], [100]), ([130], [155])]\n",
      "p_robinson_0  (u' idx):  {75, 100}\n",
      "p_robinson_0  (U idx):  [85, 17]\n",
      "p_robinson_1  (u' idx):  {130, 155}\n",
      "p_robinson_1  (U idx):  [204, 43]\n",
      "[([75], [100]), ([130], [155])]\n",
      "[85, 17, 204, 43]\n",
      "Current iter h1 new:  [85, 204]  probs:  [0.9852844207017439, 0.9727559466162418]\n",
      "Current iter h2 new:  [17, 43]  probs:  [0.9829907607434665, 0.979501733375803]\n",
      "P:  138  :  [0.9818 0.0182]\n",
      "N:  109  :  [0.0248 0.9752]\n",
      "P:  67  :  [0.982 0.018]\n",
      "N:  160  :  [0.0175 0.9825]\n",
      "[([138], [67]), ([109], [160])]\n",
      "p_robinson_0  (u' idx):  {138, 67}\n",
      "p_robinson_0  (U idx):  [133, 37]\n",
      "p_robinson_1  (u' idx):  {160, 109}\n",
      "p_robinson_1  (U idx):  [163, 122]\n",
      "[([138], [67]), ([109], [160])]\n",
      "[133, 37, 163, 122]\n",
      "Current iter h1 new:  [133, 122]  probs:  [0.9818289331892256, 0.9752282368786187]\n",
      "Current iter h2 new:  [37, 163]  probs:  [0.9819707078799813, 0.9824886440600894]\n",
      "P:  37  :  [0.983 0.017]\n",
      "N:  96  :  [0.0245 0.9755]\n",
      "P:  86  :  [0.9851 0.0149]\n",
      "N:  117  :  [0.0174 0.9826]\n",
      "[([37], [86]), ([96], [117])]\n",
      "p_robinson_0  (u' idx):  {37, 86}\n",
      "p_robinson_0  (U idx):  [55, 118]\n",
      "p_robinson_1  (u' idx):  {96, 117}\n",
      "p_robinson_1  (U idx):  [38, 135]\n",
      "[([37], [86]), ([96], [117])]\n",
      "[55, 118, 38, 135]\n",
      "Current iter h1 new:  [55, 38]  probs:  [0.9830035482284255, 0.9754999051921314]\n",
      "Current iter h2 new:  [118, 135]  probs:  [0.9850601133552913, 0.9826245102767109]\n",
      "P:  173  :  [0.9836 0.0164]\n",
      "N:  96  :  [0.023 0.977]\n",
      "P:  81  :  [0.985 0.015]\n",
      "N:  57  :  [0.0158 0.9842]\n",
      "[([173], [81]), ([96], [57])]\n",
      "p_robinson_0  (u' idx):  {81, 173}\n",
      "p_robinson_0  (U idx):  [129, 209]\n",
      "p_robinson_1  (u' idx):  {96, 57}\n",
      "p_robinson_1  (U idx):  [176, 88]\n",
      "[([173], [81]), ([96], [57])]\n",
      "[129, 209, 176, 88]\n",
      "Current iter h1 new:  [209, 176]  probs:  [0.9835889661322106, 0.9770284361685266]\n",
      "Current iter h2 new:  [129, 88]  probs:  [0.985008729848117, 0.9842020199558388]\n",
      "P:  85  :  [0.9846 0.0154]\n",
      "N:  33  :  [0.0211 0.9789]\n",
      "P:  64  :  [0.9862 0.0138]\n",
      "N:  128  :  [0.0139 0.9861]\n",
      "[([85], [64]), ([33], [128])]\n",
      "p_robinson_0  (u' idx):  {64, 85}\n",
      "p_robinson_0  (U idx):  [41, 13]\n",
      "p_robinson_1  (u' idx):  {128, 33}\n",
      "p_robinson_1  (U idx):  [93, 59]\n",
      "[([85], [64]), ([33], [128])]\n",
      "[41, 13, 93, 59]\n",
      "Current iter h1 new:  [13, 59]  probs:  [0.9845706753162967, 0.9788794042369401]\n",
      "Current iter h2 new:  [41, 93]  probs:  [0.9862293148029473, 0.9861130254813002]\n",
      "P:  109  :  [0.9853 0.0147]\n",
      "N:  143  :  [0.0227 0.9773]\n",
      "P:  98  :  [0.9871 0.0129]\n",
      "N:  57  :  [0.0135 0.9865]\n",
      "[([109], [98]), ([143], [57])]\n",
      "p_robinson_0  (u' idx):  {98, 109}\n",
      "p_robinson_0  (U idx):  [48, 87]\n",
      "p_robinson_1  (u' idx):  {57, 143}\n",
      "p_robinson_1  (U idx):  [166, 181]\n",
      "[([109], [98]), ([143], [57])]\n",
      "[48, 87, 166, 181]\n",
      "Current iter h1 new:  [87, 181]  probs:  [0.9853049254636425, 0.9772699745712673]\n",
      "Current iter h2 new:  [48, 166]  probs:  [0.9870636043950171, 0.9864775104794734]\n",
      "P:  86  :  [0.985 0.015]\n",
      "N:  111  :  [0.0209 0.9791]\n",
      "P:  6  :  [0.9871 0.0129]\n",
      "N:  18  :  [0.0142 0.9858]\n",
      "[([86], [6]), ([111], [18])]\n",
      "p_robinson_0  (u' idx):  {86, 6}\n",
      "p_robinson_0  (U idx):  [4, 124]\n",
      "p_robinson_1  (u' idx):  {18, 111}\n",
      "p_robinson_1  (U idx):  [20, 6]\n",
      "[([86], [6]), ([111], [18])]\n",
      "[4, 124, 20, 6]\n",
      "Current iter h1 new:  [4, 6]  probs:  [0.9849596539072165, 0.9791180205196154]\n",
      "Current iter h2 new:  [124, 20]  probs:  [0.9870810388921786, 0.9857855014365708]\n",
      "P:  151  :  [0.9858 0.0142]\n",
      "N:  49  :  [0.0225 0.9775]\n",
      "P:  78  :  [0.9887 0.0113]\n",
      "N:  126  :  [0.0137 0.9863]\n",
      "[([151], [78]), ([49], [126])]\n",
      "p_robinson_0  (u' idx):  {78, 151}\n",
      "p_robinson_0  (U idx):  [50, 205]\n",
      "p_robinson_1  (u' idx):  {49, 126}\n",
      "p_robinson_1  (U idx):  [77, 24]\n",
      "[([151], [78]), ([49], [126])]\n",
      "[50, 205, 77, 24]\n",
      "Current iter h1 new:  [205, 77]  probs:  [0.9858066647278984, 0.9774963054311611]\n",
      "Current iter h2 new:  [50, 24]  probs:  [0.988682406323508, 0.9863115738901203]\n",
      "P:  44  :  [0.9852 0.0148]\n",
      "N:  1  :  [0.0215 0.9785]\n",
      "P:  84  :  [0.989 0.011]\n",
      "N:  126  :  [0.0129 0.9871]\n",
      "[([44], [84]), ([1], [126])]\n",
      "p_robinson_0  (u' idx):  {44, 84}\n",
      "p_robinson_0  (U idx):  [45, 217]\n",
      "p_robinson_1  (u' idx):  {1, 126}\n",
      "p_robinson_1  (U idx):  [150, 154]\n",
      "[([44], [84]), ([1], [126])]\n",
      "[45, 217, 150, 154]\n",
      "Current iter h1 new:  [45, 150]  probs:  [0.9852361346494071, 0.9784834237718136]\n",
      "Current iter h2 new:  [217, 154]  probs:  [0.9889973308185043, 0.9870863639254464]\n",
      "P:  79  :  [0.9861 0.0139]\n",
      "N:  32  :  [0.0214 0.9786]\n",
      "P:  28  :  [0.9901 0.0099]\n",
      "N:  119  :  [0.0138 0.9862]\n",
      "[([79], [28]), ([32], [119])]\n",
      "p_robinson_0  (u' idx):  {28, 79}\n",
      "p_robinson_0  (U idx):  [168, 32]\n",
      "p_robinson_1  (u' idx):  {32, 119}\n",
      "p_robinson_1  (U idx):  [25, 185]\n",
      "[([79], [28]), ([32], [119])]\n",
      "[168, 32, 25, 185]\n",
      "Current iter h1 new:  [32, 25]  probs:  [0.9860620448458527, 0.9786062844903106]\n",
      "Current iter h2 new:  [168, 185]  probs:  [0.9901405201085438, 0.9862445548965039]\n",
      "P:  95  :  [0.9862 0.0138]\n",
      "N:  2  :  [0.0228 0.9772]\n",
      "P:  133  :  [0.9899 0.0101]\n",
      "N:  17  :  [0.0136 0.9864]\n",
      "[([95], [133]), ([2], [17])]\n",
      "p_robinson_0  (u' idx):  {133, 95}\n",
      "p_robinson_0  (U idx):  [186, 210]\n",
      "p_robinson_1  (u' idx):  {17, 2}\n",
      "p_robinson_1  (U idx):  [23, 175]\n",
      "[([95], [133]), ([2], [17])]\n",
      "[186, 210, 23, 175]\n",
      "Current iter h1 new:  [210, 175]  probs:  [0.9862013233910484, 0.9771802885401984]\n",
      "Current iter h2 new:  [186, 23]  probs:  [0.9898636584539702, 0.9863957624840023]\n",
      "P:  118  :  [0.9867 0.0133]\n",
      "N:  133  :  [0.0225 0.9775]\n",
      "P:  29  :  [0.9879 0.0121]\n",
      "N:  32  :  [0.0129 0.9871]\n",
      "[([118], [29]), ([133], [32])]\n",
      "p_robinson_0  (u' idx):  {29, 118}\n",
      "p_robinson_0  (U idx):  [214, 165]\n",
      "p_robinson_1  (u' idx):  {32, 133}\n",
      "p_robinson_1  (U idx):  [218, 126]\n",
      "[([118], [29]), ([133], [32])]\n",
      "[214, 165, 218, 126]\n",
      "Current iter h1 new:  [165, 126]  probs:  [0.9866760091663609, 0.9774730026243728]\n",
      "Current iter h2 new:  [214, 218]  probs:  [0.9879209221801518, 0.9870832321986214]\n",
      "P:  117  :  [0.9844 0.0156]\n",
      "N:  18  :  [0.0224 0.9776]\n",
      "P:  38  :  [0.9881 0.0119]\n",
      "N:  131  :  [0.0127 0.9873]\n",
      "[([117], [38]), ([18], [131])]\n",
      "p_robinson_0  (u' idx):  {117, 38}\n",
      "p_robinson_0  (U idx):  [58, 8]\n",
      "p_robinson_1  (u' idx):  {18, 131}\n",
      "p_robinson_1  (U idx):  [219, 110]\n",
      "[([117], [38]), ([18], [131])]\n",
      "[58, 8, 219, 110]\n",
      "Current iter h1 new:  [58, 219]  probs:  [0.9844324046601061, 0.9776188563819215]\n",
      "Current iter h2 new:  [8, 110]  probs:  [0.9880651881704051, 0.9872887548080506]\n",
      "P:  47  :  [0.9848 0.0152]\n",
      "N:  143  :  [0.0215 0.9785]\n",
      "P:  81  :  [0.9875 0.0125]\n",
      "N:  67  :  [0.0122 0.9878]\n",
      "[([47], [81]), ([143], [67])]\n",
      "p_robinson_0  (u' idx):  {81, 47}\n",
      "p_robinson_0  (U idx):  [112, 52]\n",
      "p_robinson_1  (u' idx):  {67, 143}\n",
      "p_robinson_1  (U idx):  [207, 190]\n",
      "[([47], [81]), ([143], [67])]\n",
      "[112, 52, 207, 190]\n",
      "Current iter h1 new:  [52, 190]  probs:  [0.9848139375567047, 0.9784976233420117]\n",
      "Current iter h2 new:  [112, 207]  probs:  [0.987514237625199, 0.9877516304348304]\n",
      "P:  32  :  [0.9858 0.0142]\n",
      "N:  99  :  [0.021 0.979]\n",
      "P:  64  :  [0.9862 0.0138]\n",
      "N:  68  :  [0.0136 0.9864]\n",
      "[([32], [64]), ([99], [68])]\n",
      "p_robinson_0  (u' idx):  {32, 64}\n",
      "p_robinson_0  (U idx):  [157, 90]\n",
      "p_robinson_1  (u' idx):  {99, 68}\n",
      "p_robinson_1  (U idx):  [42, 169]\n",
      "[([32], [64]), ([99], [68])]\n",
      "[157, 90, 42, 169]\n",
      "Current iter h1 new:  [157, 42]  probs:  [0.9857740280829039, 0.9789591925296265]\n",
      "Current iter h2 new:  [90, 169]  probs:  [0.9862108862044489, 0.9863648156606255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  30  :  [0.9875 0.0125]\n",
      "N:  68  :  [0.0209 0.9791]\n",
      "P:  78  :  [0.9873 0.0127]\n",
      "N:  18  :  [0.0134 0.9866]\n",
      "[([30], [78]), ([68], [18])]\n",
      "p_robinson_0  (u' idx):  {78, 30}\n",
      "p_robinson_0  (U idx):  [96, 147]\n",
      "p_robinson_1  (u' idx):  {18, 68}\n",
      "p_robinson_1  (U idx):  [134, 11]\n",
      "[([30], [78]), ([68], [18])]\n",
      "[96, 147, 134, 11]\n",
      "Current iter h1 new:  [147, 11]  probs:  [0.9875104896899415, 0.97910245356872]\n",
      "Current iter h2 new:  [96, 134]  probs:  [0.9873305772409648, 0.9865957532311087]\n",
      "P:  51  :  [0.985 0.015]\n",
      "N:  114  :  [0.0204 0.9796]\n",
      "P:  104  :  [0.9874 0.0126]\n",
      "N:  50  :  [0.0139 0.9861]\n",
      "[([51], [104]), ([114], [50])]\n",
      "p_robinson_0  (u' idx):  {104, 51}\n",
      "p_robinson_0  (U idx):  [1, 155]\n",
      "p_robinson_1  (u' idx):  {114, 50}\n",
      "p_robinson_1  (U idx):  [108, 80]\n",
      "[([51], [104]), ([114], [50])]\n",
      "[1, 155, 108, 80]\n",
      "Current iter h1 new:  [155, 108]  probs:  [0.9850022629789462, 0.9796376004739115]\n",
      "Current iter h2 new:  [1, 80]  probs:  [0.9873903219279206, 0.9860682499258941]\n",
      "P:  80  :  [0.9863 0.0137]\n",
      "N:  14  :  [0.0195 0.9805]\n",
      "P:  61  :  [0.9809 0.0191]\n",
      "N:  37  :  [0.0158 0.9842]\n",
      "[([80], [61]), ([14], [37])]\n",
      "p_robinson_0  (u' idx):  {80, 61}\n",
      "p_robinson_0  (U idx):  [3, 30]\n",
      "p_robinson_1  (u' idx):  {37, 14}\n",
      "p_robinson_1  (U idx):  [125, 31]\n",
      "[([80], [61]), ([14], [37])]\n",
      "[3, 30, 125, 31]\n",
      "Current iter h1 new:  [3, 31]  probs:  [0.9862753120014995, 0.9805054601790709]\n",
      "Current iter h2 new:  [30, 125]  probs:  [0.9808742142295972, 0.9841782090558154]\n",
      "P:  84  :  [0.984 0.016]\n",
      "N:  58  :  [0.0186 0.9814]\n",
      "P:  122  :  [0.9809 0.0191]\n",
      "N:  89  :  [0.0166 0.9834]\n",
      "[([84], [122]), ([58], [89])]\n",
      "p_robinson_0  (u' idx):  {122, 84}\n",
      "p_robinson_0  (U idx):  [111, 28]\n",
      "p_robinson_1  (u' idx):  {89, 58}\n",
      "p_robinson_1  (U idx):  [193, 116]\n",
      "[([84], [122]), ([58], [89])]\n",
      "[111, 28, 193, 116]\n",
      "Current iter h1 new:  [28, 116]  probs:  [0.9840419494765447, 0.9813915222213551]\n",
      "Current iter h2 new:  [111, 193]  probs:  [0.9808798245540884, 0.9834215703185951]\n",
      "P:  61  :  [0.9845 0.0155]\n",
      "N:  115  :  [0.0183 0.9817]\n",
      "P:  96  :  [0.9787 0.0213]\n",
      "N:  22  :  [0.019 0.981]\n",
      "[([61], [96]), ([115], [22])]\n",
      "p_robinson_0  (u' idx):  {96, 61}\n",
      "p_robinson_0  (U idx):  [27, 198]\n",
      "p_robinson_1  (u' idx):  {115, 22}\n",
      "p_robinson_1  (U idx):  [144, 95]\n",
      "[([61], [96]), ([115], [22])]\n",
      "[27, 198, 144, 95]\n",
      "Current iter h1 new:  [198, 144]  probs:  [0.9845007282127126, 0.9816655950040176]\n",
      "Current iter h2 new:  [27, 95]  probs:  [0.978699893486525, 0.980996343089129]\n",
      "P:  28  :  [0.9855 0.0145]\n",
      "N:  51  :  [0.017 0.983]\n",
      "P:  68  :  [0.9788 0.0212]\n",
      "N:  69  :  [0.019 0.981]\n",
      "[([28], [68]), ([51], [69])]\n",
      "p_robinson_0  (u' idx):  {28, 68}\n",
      "p_robinson_0  (U idx):  [73, 119]\n",
      "p_robinson_1  (u' idx):  {51, 69}\n",
      "p_robinson_1  (U idx):  [173, 203]\n",
      "[([28], [68]), ([51], [69])]\n",
      "[73, 119, 173, 203]\n",
      "Current iter h1 new:  [73, 173]  probs:  [0.9855492594821376, 0.9829916160982526]\n",
      "Current iter h2 new:  [119, 203]  probs:  [0.9788200134263182, 0.9810332628627187]\n",
      "P:  16  :  [0.982 0.018]\n",
      "N:  95  :  [0.0181 0.9819]\n",
      "P:  30  :  [0.9787 0.0213]\n",
      "N:  68  :  [0.0216 0.9784]\n",
      "[([16], [30]), ([95], [68])]\n",
      "p_robinson_0  (u' idx):  {16, 30}\n",
      "p_robinson_0  (U idx):  [104, 206]\n",
      "p_robinson_1  (u' idx):  {68, 95}\n",
      "p_robinson_1  (U idx):  [162, 91]\n",
      "[([16], [30]), ([95], [68])]\n",
      "[104, 206, 162, 91]\n",
      "Current iter h1 new:  [104, 91]  probs:  [0.981958895506661, 0.9819343130754185]\n",
      "Current iter h2 new:  [206, 162]  probs:  [0.9787292022124494, 0.9783671740478288]\n",
      "P:  17  :  [0.9823 0.0177]\n",
      "N:  63  :  [0.0219 0.9781]\n",
      "P:  21  :  [0.9743 0.0257]\n",
      "N:  97  :  [0.0218 0.9782]\n",
      "[([17], [21]), ([63], [97])]\n",
      "p_robinson_0  (u' idx):  {17, 21}\n",
      "p_robinson_0  (U idx):  [107, 75]\n",
      "p_robinson_1  (u' idx):  {97, 63}\n",
      "p_robinson_1  (U idx):  [33, 84]\n",
      "[([17], [21]), ([63], [97])]\n",
      "[107, 75, 33, 84]\n",
      "Current iter h1 new:  [107, 84]  probs:  [0.9822922014068594, 0.9780582222976001]\n",
      "Current iter h2 new:  [75, 33]  probs:  [0.9742771508597576, 0.9781521408299034]\n",
      "P:  24  :  [0.9825 0.0175]\n",
      "N:  11  :  [0.0234 0.9766]\n",
      "P:  44  :  [0.9746 0.0254]\n",
      "N:  69  :  [0.0213 0.9787]\n",
      "[([24], [44]), ([11], [69])]\n",
      "p_robinson_0  (u' idx):  {24, 44}\n",
      "p_robinson_0  (U idx):  [78, 65]\n",
      "p_robinson_1  (u' idx):  {11, 69}\n",
      "p_robinson_1  (U idx):  [191, 221]\n",
      "[([24], [44]), ([11], [69])]\n",
      "[78, 65, 191, 221]\n",
      "Current iter h1 new:  [78, 191]  probs:  [0.9824526446558113, 0.9765948862529024]\n",
      "Current iter h2 new:  [65, 221]  probs:  [0.9746293005893374, 0.9787177178621356]\n",
      "P:  8  :  [0.983 0.017]\n",
      "N:  0  :  [0.0225 0.9775]\n",
      "P:  22  :  [0.9727 0.0273]\n",
      "N:  83  :  [0.0221 0.9779]\n",
      "[([8], [22]), ([0], [83])]\n",
      "p_robinson_0  (u' idx):  {8, 22}\n",
      "p_robinson_0  (U idx):  [146, 100]\n",
      "p_robinson_1  (u' idx):  {0, 83}\n",
      "p_robinson_1  (U idx):  [224, 98]\n",
      "[([8], [22]), ([0], [83])]\n",
      "[146, 100, 224, 98]\n",
      "Current iter h1 new:  [146, 224]  probs:  [0.9830361683564655, 0.9774702091678316]\n",
      "Current iter h2 new:  [100, 98]  probs:  [0.9727098608224704, 0.9779470562925251]\n",
      "Total Labeled number:  129  Still unlabeled number:  97\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.923076923076923, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.8844444444444445, 0.923076923076923, 0.923076923076923, 0.923076923076923, 0.923076923076923]\n",
      "Self labeled sample index:  defaultdict(<class 'list'>, {'p_robinson_0': [[202, 68], [10, 137], [131, 56], [99, 212], [105, 46], [85, 17], [133, 37], [55, 118], [129, 209], [41, 13], [48, 87], [4, 124], [50, 205], [45, 217], [168, 32], [186, 210], [214, 165], [58, 8], [112, 52], [157, 90], [96, 147], [1, 155], [3, 30], [111, 28], [27, 198], [73, 119], [104, 206], [107, 75], [78, 65], [146, 100]], 'p_robinson_1': [[94, 49], [89, 170], [5], [159, 103], [14, 101], [204, 43], [163, 122], [38, 135], [176, 88], [93, 59], [166, 181], [20, 6], [77, 24], [150, 154], [25, 185], [23, 175], [218, 126], [219, 110], [207, 190], [42, 169], [134, 11], [108, 80], [125, 31], [193, 116], [144, 95], [173, 203], [162, 91], [33, 84], [191, 221], [224, 98]]})\n",
      "y1 disagree on 19  Proba:  [0.039 0.961]\n",
      "y2 not aggreed on  19 Proba:  [0.674 0.326]\n",
      "product probas: [0.02631821757166112, 0.3132634147862371]\n",
      "result idx:  1  result:  p_robinson_1\n",
      "y1 disagree on 23  Proba:  [0.1858 0.8142]\n",
      "y2 not aggreed on  23 Proba:  [0.6798 0.3202]\n",
      "product probas: [0.12632793094554964, 0.26067715578344136]\n",
      "result idx:  1  result:  p_robinson_1\n",
      "co-train f1:                precision    recall  f1-score   support\n",
      "\n",
      "p_robinson_0       1.00      1.00      1.00        12\n",
      "p_robinson_1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "LR f1:                precision    recall  f1-score   support\n",
      "\n",
      "p_robinson_0       1.00      1.00      1.00        12\n",
      "p_robinson_1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "SVM f1:                precision    recall  f1-score   support\n",
      "\n",
      "p_robinson_0       1.00      1.00      1.00        12\n",
      "p_robinson_1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# loop through all files in directory add name to name list\n",
    "fileDir = \"../Data/\"+Dataset+\"/canopies_labeled/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "\n",
    "init_labeled_size = 10\n",
    "\n",
    "co_lr_diff_embedding_result = []\n",
    "\n",
    "#---------------- load different embeddings for view one ---------------#\n",
    "for select_emb in pp_text:\n",
    "    print(\"Load text embedding: \", select_emb)\n",
    "    # read viewone embeddings\n",
    "    viewone_text_emb, viewone_emb_pid = com_func.read_text_embedding(emb_type=select_emb, training_size = \"140k\")\n",
    "    viewone_text_emb = np.column_stack((viewone_emb_pid,viewone_text_emb))\n",
    "    # read viewtwo embedding, notice here we only use labeled data\n",
    "    print(\"Load citation embedding: \", pp_citation)\n",
    "    viewtwo_citation_embedding = com_func.read_citation_embedding_sorted(emb_type = pp_citation, labeled_only = True)\n",
    "    # print(viewone_text_emb[0])\n",
    "    # print(viewtwo_citation_embedding[0])\n",
    "    \n",
    "    threshold_change_all_co_lr_f1s = []\n",
    "    threshold_change = []\n",
    "    \n",
    "    # -------------- different threshold (step by 10) -----------------------#\n",
    "    for step_threshold in range(threshold_lower, threshold_upper, 10):\n",
    "        plot_save_path = \"../../plot/co_train_detail_plots/threshold=\"+str(step_threshold)+\"/V1=\"+select_emb+\"_V2=\"+pp_citation+\"/\"\n",
    "        threshold_change.append(step_threshold)\n",
    "        # collect statistic to output\n",
    "        name_group, total_sample_size, train_sample_size, test_sample_size= ([] for i in range(4))\n",
    "        unlabeled_count, co_train_self_labeled = ([] for i in range(2))\n",
    "\n",
    "        all_LR_f1,all_SVM_f1, all_co_LR_f1 = ([] for i in range(3))\n",
    "        all_per_fold_f1_score_variance = []\n",
    "\n",
    "        total_selected_group = 0\n",
    "\n",
    "        # ------- different name group in all name group --------------------#\n",
    "        for file in listfiles:\n",
    "            # group name\n",
    "            temp = file.split(\"_\")\n",
    "            name = temp[1]+\"_\"+temp[-1]\n",
    "            print(\"For name: \",name)\n",
    "            # read labeled pid and aid from file\n",
    "            data = com_func.read_pid_aid(fileDir+file)\n",
    "            labeled_mask = data[\"authorID\"] != \"-1\"\n",
    "            labeled_data = data[labeled_mask]\n",
    "            print(labeled_data.shape)\n",
    "            # ---------------- collect all labeled sample -------------------- #\n",
    "            # ---------------- if use all samples as negative --------------- #\n",
    "            all_labeled_samples = labeled_data[\"paperID\"].tolist()\n",
    "            authorCounter = com_func.select_productive_groups(labeled_data, threshold_select_name_group)\n",
    "            # if only have one class or no class pass the threshold, not applicable\n",
    "            if(len(authorCounter)==0) or (len(authorCounter)==1):\n",
    "                print(name,\" pass\")\n",
    "            else:\n",
    "                total_selected_group+= 1\n",
    "                # --------------for each name group---------------- #\n",
    "                if apply_threshold_to_name_group_samples == True:\n",
    "                    # ---------- only use sample pass threshold ------- #\n",
    "                    #-------- only select authors in name group are very productive (more than threshold)---------#\n",
    "                    labeled_data, author_list, _= com_func.only_select_productive_authors(labeled_data, step_threshold)\n",
    "                    # ----------------- if use filtered samples as negative  --------- #\n",
    "                    filtered_all_labeled_samples = labeled_data[\"paperID\"].tolist()\n",
    "                else:\n",
    "                    # ----------- use all sample in name group --------- #\n",
    "                    author_list = com_func.productive_authors_list(labeled_data, step_threshold)\n",
    "                    print(name, \" name group sample size: \",labeled_data.shape)\n",
    "                # -------------- extract all samples for name group -------------- #\n",
    "                # for each name group\n",
    "                # read in labeled data\n",
    "                labeled_viewone_text = com_func.extract_sorted_embedding(viewone_text_emb, labeled_data[\"paperID\"])\n",
    "                print(labeled_viewone_text.shape)\n",
    "                labeled_viewtwo_citation = com_func.extract_sorted_embedding(viewtwo_citation_embedding, labeled_data[\"paperID\"])\n",
    "                print(labeled_viewtwo_citation.shape)\n",
    "                print(\"Labeled: \",len(labeled_viewone_text), \" : \", len(labeled_viewtwo_citation))\n",
    "                # ---------------- shuffle the data ----------------- #\n",
    "                labeled_data = labeled_data.sample(frac=1).reset_index(drop=True)\n",
    "                # ------------------ alignment ---------------------- #\n",
    "                labeled_viewone_text = pd.merge(labeled_data, labeled_viewone_text, left_on=\"paperID\", right_on = [0], how = \"left\")\n",
    "                labeled_viewtwo_citation = pd.merge(labeled_data, labeled_viewtwo_citation, left_on=\"paperID\", right_on = [0], how = \"left\")\n",
    "                labeled_viewtwo_citation.fillna(0, inplace=True)\n",
    "                unique_labels = labeled_viewone_text.authorID.unique()\n",
    "                map_dict = {}\n",
    "                for idx, unique_label in enumerate(unique_labels):\n",
    "                    map_dict[unique_label] = name+\"_\"+str(idx)\n",
    "                true_label = labeled_viewone_text[\"authorID\"].replace(map_dict)\n",
    "                \n",
    "                print(labeled_viewone_text.shape)\n",
    "                print(labeled_viewtwo_citation.shape)\n",
    "                '''\n",
    "                only work on binary case, ignored multi-class case\n",
    "                We need to check whether the name group only contain binary case or not\n",
    "                '''\n",
    "                if len(author_list) == 2:\n",
    "                    name_group.append(name)\n",
    "                    print(name + \" is binary case\")\n",
    "                    viewone_text_final = labeled_viewone_text.drop([\"paperID\", \"authorID\", 0], axis=1)\n",
    "                    viewtwo_citation_final = labeled_viewtwo_citation.drop([\"paperID\", \"authorID\", 0], axis=1)\n",
    "                    '''Only for visualization of co-training process, use PCA to reduce views to 2d'''\n",
    "                    # 1. apply PCA to different views\n",
    "                    pca = PCA(n_components=2)\n",
    "                    pca_dv1 = pca.fit_transform(X=viewone_text_final)\n",
    "                    pca_dv2 = pca.fit_transform(X=viewtwo_citation_final)\n",
    "                    \n",
    "                    # 2. apply co-training\n",
    "                    co_logistic_clf = Co_training_clf(clf1=LogisticRegression(solver= \"liblinear\"),p=1,n=1, k=30)\n",
    "                    LR_f1, SVM_f1, co_lr_f1, name_per_fold_status= k_fold_cv_co_train_binary(pca_dv1, pca_dv2, true_label, \n",
    "                                                                                init_labeled_size, co_logistic_clf, \n",
    "                                                                                10, name, plot_save_path)\n",
    "                    total_sample_size.append(len(true_label))\n",
    "                    train_sample_size.append(name_per_fold_status[0][\"train_size\"])\n",
    "                    test_sample_size.append(name_per_fold_status[0][\"test_size\"])\n",
    "                    unlabeled_count.append(name_per_fold_status[0][\"unlabeled size\"])\n",
    "                    co_train_self_labeled.append(name_per_fold_status[0][\"total_self_labeled_train\"])\n",
    "                    all_LR_f1.append(LR_f1)\n",
    "                    all_SVM_f1.append(SVM_f1)\n",
    "                    all_co_LR_f1.append(co_lr_f1)\n",
    "                else:\n",
    "                    print(name+ \" is multi-class case, ignored\")\n",
    "                    \n",
    "        # write evaluation result to excel\n",
    "        output = pd.DataFrame({'Name':name_group, \"Total sample size\":total_sample_size, \"train size\":train_sample_size,\n",
    "                               \"test size\":test_sample_size, \"unlabeled sample size\": unlabeled_count, \n",
    "                               \"total self labeled sample\":co_train_self_labeled,\n",
    "                               \"LR F1\": all_LR_f1, \"SVM F1\": all_SVM_f1, \"co_logisticRegression F1\": all_co_LR_f1})\n",
    "        savePath = \"../../result/\"+Dataset+\"/co_train_sample=140k/\"\n",
    "        filename = \"(init_labeled_size=\"+str(init_labeled_size)+\") V1=\"+select_emb+\"_V2=\"+pp_citation+\"_threshold=\"+str(step_threshold)+\".csv\"\n",
    "        com_func.write_csv_df(savePath, filename, output)\n",
    "        print(\"Done\")\n",
    "        \n",
    "        threshold_change_all_co_lr_f1s.append(all_co_LR_f1)\n",
    "        \n",
    "    co_lr_diff_embedding_result.append(threshold_change_all_co_lr_f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T00:09:05.597965Z",
     "start_time": "2019-03-24T00:09:04.587Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statistics import mean \n",
    "\n",
    "print(threshold_change_all_co_lr_f1s)\n",
    "print(co_lr_diff_embedding_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#         # --------------- plot overall result f1 variance --------------- #\n",
    "#         all_per_fold_f1_score_variance_plot = pd.DataFrame(all_per_fold_f1_score_variance)\n",
    "#         ax = sns.boxplot(x=\"author\", y=\"f1\", data=all_per_fold_f1_score_variance_plot)\n",
    "#         ax = sns.swarmplot(x=\"author\", y=\"f1\", data=all_per_fold_f1_score_variance_plot, color=\".25\")\n",
    "#         plt.savefig(plot_save_path+\"all_result_variance.png\", dpi=300)\n",
    "#         # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-23T03:52:46.851Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %whos\n",
    "del viewtwo_citation_embedding\n",
    "del viewone_text_emb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
