{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-29T00:10:03.056Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean \n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import com_func\n",
    "\n",
    "Dataset = \"pubmed\"\n",
    "result_path = \"../../result/\"+Dataset+\"/2_OCEN_Different_train_percentage_sample=140k/\"\n",
    "filter_size = 100\n",
    "fig_save_path = \"../../plot/2_OCEN/filter=\"+str(filter_size)+\"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase zero: Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-29T00:10:04.123Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------- load result --------------- #\n",
    "import collections\n",
    "pp_text_emb = [\"tf\", \"tf_idf\", \"lsa\", \"pv_dm\", \"pv_dbow\"]\n",
    "pp_citation_emb = [\"off\",\"n2v\"]\n",
    "diff_percent_result = collections.defaultdict(list)\n",
    "prevent_repeat_load = []\n",
    "for text_emb in pp_text_emb:\n",
    "    for citation_emb in pp_citation_emb:\n",
    "        curr_embedding_result = collections.defaultdict(list)\n",
    "        if text_emb is \"off\" and citation_emb is \"off\":\n",
    "            break\n",
    "        if text_emb is \"tf\" or text_emb is \"tf_idf\":\n",
    "            citation_emb=\"off\"\n",
    "        result_filename = \"citation=\"+citation_emb+\"_textual=\"+text_emb+\"_threshold=\"+str(filter_size)+\".csv\"\n",
    "        if result_filename in prevent_repeat_load:\n",
    "            break\n",
    "        print(text_emb+\" \"+citation_emb)\n",
    "        final_path = os.path.normpath(os.path.join(result_path,result_filename))\n",
    "        result = pd.read_csv(final_path)\n",
    "        prevent_repeat_load.append(result_filename)\n",
    "        # save all percent result in array\n",
    "        curr_embedding_result[\"used_train_percent\"]=result[\"used_train_percent\"].values\n",
    "        curr_embedding_result[\"Name group\"]=result[\"Name group\"].values\n",
    "        if text_emb is \"tf\":\n",
    "            curr_embedding_result[\"MNB macro F1\"]=result[\"MNB macro F1\"].values\n",
    "        curr_embedding_result[\"LR macro f1\"]=result[\"LR macro f1\"].values\n",
    "        curr_embedding_result[\"SVM macro f1\"]=result[\"SVM(linear) macro f1\"].values\n",
    "        \n",
    "        diff_percent_result[text_emb+\" \"+citation_emb]=curr_embedding_result\n",
    "        \n",
    "#print(diff_percent_result)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-29T00:10:07.476Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_duplicates(seq):\n",
    "    tally = collections.defaultdict(list)\n",
    "    for i,item in enumerate(seq):\n",
    "        tally[item].append(i)\n",
    "    return ((key,locs) for key,locs in tally.items() if len(locs)>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-29T00:10:08.044Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statistics import mean \n",
    "# -------------- extract different training size mean f1 score and case when train percentage=1  ------------ #\n",
    "author_group = []\n",
    "diff_embedding_mean_result = collections.defaultdict(list)\n",
    "diff_embedding_all_train_result = collections.defaultdict(list)\n",
    "for emb_setting, emb_result in diff_percent_result.items():\n",
    "    print(emb_setting)\n",
    "    used_train_percent = []\n",
    "    curr_embedding_mean_result = collections.defaultdict(list)\n",
    "    curr_embedding_all_train_result = collections.defaultdict(list)\n",
    "    for key, key_result in emb_result.items():\n",
    "        # extract train percentage and result index\n",
    "        if key == \"used_train_percent\":\n",
    "            used_train_percent = list(list_duplicates(key_result))\n",
    "        # extract unqiue author groups\n",
    "        if key == \"Name group\":\n",
    "            author_group = [v for (i,v) in enumerate(key_result) if v not in key_result[0:i]]\n",
    "        # use index we get to extract result and save it\n",
    "        for att_key in [\"MNB macro F1\",\"LR macro f1\",\"SVM macro f1\"]:\n",
    "            if key == att_key:\n",
    "                temp = []\n",
    "                for percentage, idx in used_train_percent:\n",
    "                    # mean w.r.t different dataset\n",
    "                    curr_embedding_mean_result[att_key].append(mean(key_result[idx]))\n",
    "                    # extract result of all datasets for percentage = 1\n",
    "                    if percentage == 1:\n",
    "                        curr_embedding_all_train_result[att_key]=key_result[idx]\n",
    "                    temp.append(percentage)\n",
    "                curr_embedding_mean_result[\"train_percent\"] = temp\n",
    "    diff_embedding_mean_result[emb_setting]=curr_embedding_mean_result\n",
    "    diff_embedding_all_train_result[emb_setting]=curr_embedding_all_train_result\n",
    "#print(diff_embedding_mean_result)\n",
    "print(diff_embedding_all_train_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 1: Influence of different training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-29T00:10:11.857Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_methods = [\"LR\",\"SVM\"]\n",
    "embedding_methods = [\"TF\",\"TF-IDF\",\"LSA\", \"LSA&n2v\",\"PV-DM\",\"PV-DM&n2v\",\"PV-DBOW\",\"PV-DBOW&n2v\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:28:51.172438Z",
     "start_time": "2020-05-28T01:28:51.125597Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------- reformate result -------------- #\n",
    "all_mean_result_clfwise = []\n",
    "LR_result = []\n",
    "SVM_result = []\n",
    "train_percentage = []\n",
    "for emb_setting, emb_result in diff_embedding_mean_result.items():\n",
    "    print(emb_setting)\n",
    "    for key, key_result in emb_result.items():\n",
    "        if key == \"LR macro f1\":\n",
    "            LR_result.append(key_result)\n",
    "        if key == \"SVM macro f1\":\n",
    "            SVM_result.append(key_result)\n",
    "        if key == \"train_percent\":\n",
    "            train_percentage = ['%.1f' % elem for elem in key_result]\n",
    "    #print(LR_result)\n",
    "    #print(SVM_result)\n",
    "print(train_percentage)\n",
    "all_mean_result_clfwise.append(LR_result)\n",
    "all_mean_result_clfwise.append(SVM_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:29:35.586717Z",
     "start_time": "2020-05-28T01:29:33.583580Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "figsize = (10, 6)\n",
    "\n",
    "for idx, (result,method) in enumerate(zip(all_mean_result_clfwise,clf_methods)):\n",
    "    fig, axs = plt.subplots(figsize=figsize)\n",
    "    plt.setp(axs, xticks=range(len(train_percentage)), xticklabels=train_percentage)\n",
    "    print(method)\n",
    "    print(embedding_methods)\n",
    "    for emb,emb_label in zip(result, embedding_methods):\n",
    "        print(np.mean(emb))\n",
    "        axs.plot(emb, marker='o',label=emb_label)\n",
    "    legend=axs.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2),ncol=4)\n",
    "    plt.ylabel('macro F1 score')\n",
    "    try:\n",
    "        plt.savefig(fname=fig_save_path+\"OCEN_diff_train_percent_filter=\"+str(filter_size)+\"_\"+method+\".png\",dpi=200,bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "    except:\n",
    "        if not os.path.exists(fig_save_path):\n",
    "            os.makedirs(fig_save_path)\n",
    "        plt.savefig(fname=fig_save_path+\"OCEN_diff_train_percent_filter=\"+str(filter_size)+\"_\"+method+\".png\",dpi=200,bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 2: All dataset result w.r.t. different embedding on MNB, LR and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-29T00:10:19.706Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_embedding_all_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-29T00:10:24.268Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------- reformate result -------------- #\n",
    "all_result_clfwise = []\n",
    "MNB_result = []\n",
    "LR_result = []\n",
    "SVM_result = []\n",
    "for emb_setting, emb_result in diff_embedding_all_train_result.items():\n",
    "    print(emb_setting)\n",
    "    for key, key_result in emb_result.items():\n",
    "        if key == \"LR macro f1\":\n",
    "            LR_result.append(key_result)\n",
    "        if key == \"SVM macro f1\":\n",
    "            SVM_result.append(key_result)\n",
    "        if key == \"MNB macro F1\":\n",
    "            MNB_result.append(key_result)\n",
    "    #print(LR_result)\n",
    "    #print(SVM_result)\n",
    "all_result_clfwise.append(LR_result)\n",
    "all_result_clfwise.append(SVM_result)\n",
    "print(all_result_clfwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T03:21:27.485320Z",
     "start_time": "2020-05-28T03:21:25.122243Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "figsize = (16, 6)\n",
    "\n",
    "for idx, (result,method) in enumerate(zip(all_result_clfwise,clf_methods)):\n",
    "    print(method)\n",
    "    fig, axs = plt.subplots(figsize=figsize)\n",
    "    plt.setp(axs, xticks=range(len(author_group)), xticklabels=author_group)\n",
    "    plt.setp(axs.get_xticklabels(), rotation=45, horizontalalignment='center')\n",
    "    print(embedding_methods)\n",
    "    for emb,emb_label in zip(result, embedding_methods):\n",
    "        print(np.mean(emb))\n",
    "        axs.plot(emb, marker='o',label=emb_label)\n",
    "    legend=axs.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2),ncol=4)\n",
    "    plt.ylabel('macro F1 score')\n",
    "    try:\n",
    "        plt.savefig(fname=fig_save_path+\"OCEN_filter=\"+str(filter_size)+\"_\"+method+\".png\",dpi=150,bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "    except:\n",
    "        if not os.path.exists(fig_save_path):\n",
    "            os.makedirs(fig_save_path)\n",
    "        plt.savefig(fname=fig_save_path+\"OCEN_filter=\"+str(filter_size)+\"_\"+method+\".png\",dpi=150,bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 3: All dataset result w.r.t. different algorithm on different vector type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T03:21:50.407733Z",
     "start_time": "2020-05-28T03:21:50.401353Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------- reformate ------------- #\n",
    "all_result_embeddingwise=list(zip(*all_result_clfwise))\n",
    "#print(all_result_embeddingwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T03:34:22.227576Z",
     "start_time": "2020-05-28T03:34:15.968822Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figsize = (16, 6)\n",
    "\n",
    "for idx, (result,method) in enumerate(zip(all_result_embeddingwise,embedding_methods)):\n",
    "    fig, axs = plt.subplots(figsize=figsize)\n",
    "    plt.setp(axs, xticks=range(len(author_group)), xticklabels=author_group)\n",
    "    plt.setp(axs.get_xticklabels(), rotation=45, horizontalalignment='center')\n",
    "    print(method)\n",
    "    # add naive bayes result\n",
    "    if method is \"TF\":\n",
    "        result = result+tuple(MNB_result)\n",
    "        clf_methods.append(\"NB\")\n",
    "    for clf_result,clf_label in zip(result, clf_methods):\n",
    "        print(clf_label)\n",
    "        print(np.mean(clf_result))\n",
    "        axs.plot(clf_result, marker='o',label=clf_label)\n",
    "    legend=axs.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2),ncol=4)\n",
    "    plt.ylabel('macro F1 score')\n",
    "    try:\n",
    "        plt.savefig(fname=fig_save_path+\"OCEN_filter=\"+str(filter_size)+\"_\"+method+\".png\",dpi=150,bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "    except:\n",
    "        if not os.path.exists(fig_save_path):\n",
    "            os.makedirs(fig_save_path)\n",
    "        plt.savefig(fname=fig_save_path+\"OCEN_filter=\"+str(filter_size)+\"_\"+method+\".png\",dpi=150,bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    if method is \"TF\":\n",
    "        clf_methods.remove(\"NB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
