{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T03:02:11.317742Z",
     "start_time": "2020-08-20T03:02:10.977373Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One classifier each name: OCEN with different train percentage\n",
    "1. This method throw away the authors write less than 100 papers  \n",
    "2. We will collect result of different train size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T22:21:58.252499Z",
     "start_time": "2020-08-21T22:21:56.972342Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import com_func\n",
    "\n",
    "# parameters\n",
    "#----- filter for selecting set of name group -----------#\n",
    "filter_select_name_group = 100\n",
    "#----- filter for selecting productive authors ----#\n",
    "filter_lower = 100\n",
    "filter_upper = 110\n",
    "\n",
    "Dataset = \"pubmed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T22:42:51.863023Z",
     "start_time": "2020-08-21T22:42:51.858287Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# text embedding only\n",
    "pp_text_emb = [\"tf\", \"tf_idf\", \"lsa\", \"pv_dm\", \"pv_dbow\"]\n",
    "pp_citation_emb = [\"off\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T01:42:51.132690Z",
     "start_time": "2020-08-18T01:42:51.126112Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# citation embedding only\n",
    "pp_text_emb = [\"off\"]\n",
    "pp_citation_emb = [\"n2v\",\"node2vec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T21:26:03.534071Z",
     "start_time": "2020-08-21T21:26:03.523749Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined embedding\n",
    "pp_text_emb = [\"lsa\", \"pv_dm\", \"pv_dbow\"]\n",
    "pp_citation_emb = [\"n2v\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T22:42:54.158668Z",
     "start_time": "2020-08-21T22:42:54.152117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tf']\n",
      "['off']\n"
     ]
    }
   ],
   "source": [
    "print(pp_text_emb)\n",
    "print(pp_citation_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-21T22:42:55.475Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import collections\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# cross validation\n",
    "def k_fold_cv_with_different_train_size(data, label, clf, train_size=1, k=10, random_state=None):\n",
    "    '''\n",
    "    Split train and test for each fold first, then reduce train size\n",
    "    train_size: between 0-1 is percentage, larger than one is train size count\n",
    "    '''\n",
    "    temp_train_percent = train_size\n",
    "    #random.seed(1)\n",
    "    if train_size<=0:\n",
    "        sys.exit(\"Training size must be larger than 0\")\n",
    "    # sync input datatype\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        data = pd.DataFrame(data)\n",
    "    if not isinstance(label, pd.Series):\n",
    "        label = pd.Series(label, index = data.index.values)\n",
    "        \n",
    "    # obtain data ratio\n",
    "    c = collections.Counter(label)\n",
    "    data_ratio = [(i, c[i] / len(label)) for i in c]\n",
    "    #print(temp_train_percent)\n",
    "    #print(data_ratio)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel = []\n",
    "    all_fold_statistic = []\n",
    "    test_size = 0\n",
    "    fold = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(data, label):\n",
    "        fold +=1\n",
    "        #print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # ---------------1. split train and test -------------------- #\n",
    "        data_train, data_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        all_label_train, label_test = label.iloc[train_index], label.iloc[test_index]\n",
    "        # ---------------2. train classifier with different training size -------------------- #\n",
    "        if train_size<=1:\n",
    "            train_size = len(all_label_train)*train_size\n",
    "        if train_size > len(all_label_train):\n",
    "            sys.exit(\"Training size must be less or equal to total training samples\")\n",
    "        # if train_size float, take floor of a float train_size\n",
    "        train_size = int(train_size)\n",
    "        test_size = len(data_test)\n",
    "        #print(\"train: \",train_size, \" test: \",test_size)\n",
    "        # 1. number of samples for each class when perserve it's data ratio\n",
    "        train_per_class_size = [(label, round(ratio*train_size)) for label, ratio in data_ratio]\n",
    "        #print(train_per_class_size)\n",
    "        selected_train_sample_idx = []\n",
    "        # 2. select samples from train using variable we generated \n",
    "        for unique_label, training_size in train_per_class_size:\n",
    "            curr_label_idx = all_label_train.index[all_label_train == unique_label].tolist()\n",
    "            curr_label_size = len(curr_label_idx)\n",
    "            # ----------- sometime round may cause error ----------------- #\n",
    "            if temp_train_percent ==1:\n",
    "                selected_train_sample_idx+=curr_label_idx\n",
    "                #print(\"class:\",unique_label,\" all size: \", curr_label_size, \" training size:\", curr_label_size)\n",
    "            else:\n",
    "                selected_train_sample_idx += random.sample(curr_label_idx, training_size)\n",
    "                #print(\"class:\",unique_label,\" all size: \", curr_label_size, \" training size:\", training_size)\n",
    "        # .loc use index, .iloc use position\n",
    "        final_data_train = data_train.loc[selected_train_sample_idx]\n",
    "        final_label_train = all_label_train.loc[selected_train_sample_idx]\n",
    "        # 3. train classifier\n",
    "        per_fold_clf = copy.deepcopy(clf)\n",
    "        per_fold_clf.fit(final_data_train, final_label_train)\n",
    "        # 4. make predcit on test\n",
    "        per_fold_predict_test = per_fold_clf.predict(data_test)\n",
    "                \n",
    "        allTrueLabel.extend(label_test.values.tolist())\n",
    "        allPredLabel.extend(per_fold_predict_test)\n",
    "        # collect per fold statistic\n",
    "        curr_fold_statistic = {'fold':fold, 'train_size': train_per_class_size, 'test_size': data_test.shape[0],\n",
    "                               'macro f1': f1_score(label_test, per_fold_predict_test,average='macro')}\n",
    "        all_fold_statistic.append(curr_fold_statistic)\n",
    "        \n",
    "    # macro weighs each class equally \n",
    "    # micro weights each sample equally.\n",
    "    accuracy = accuracy_score(allTrueLabel, allPredLabel)\n",
    "    macro_f1 = f1_score(allTrueLabel, allPredLabel,average='macro')\n",
    "    \n",
    "    return accuracy, macro_f1, train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-21T22:42:55.773Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load text embedding:  tf\n",
      "Load citation embedding:  off\n",
      "For name:  j_read\n",
      "j_read  pass\n",
      "For name:  f_esteves\n",
      "f_esteves  pass\n",
      "For name:  c_miller\n",
      "c_miller  pass\n",
      "For name:  r_jha\n",
      "r_jha  pass\n",
      "For name:  a_lowe\n",
      "a_lowe  pass\n",
      "For name:  a_vega\n",
      "a_vega  pass\n",
      "For name:  k_smith\n",
      "k_smith  pass\n",
      "For name:  j_gordon\n",
      "j_gordon  pass\n",
      "For name:  s_liao\n",
      "s_liao  pass\n",
      "For name:  j_qian\n",
      "j_qian  pass\n",
      "For name:  s_bernardi\n",
      "s_bernardi  pass\n",
      "For name:  t_hill\n",
      "t_hill  pass\n",
      "For name:  s_schindler\n",
      "s_schindler  pass\n",
      "For name:  j_williams\n",
      "j_williams  pass\n",
      "For name:  s_jacobson\n",
      "s_jacobson  pass\n",
      "For name:  e_andrade\n",
      "e_andrade  pass\n",
      "For name:  t_santos\n",
      "t_santos  pass\n",
      "For name:  k_kim\n",
      "Total sample size before apply filter:  1111\n",
      "Counter({'0000-0002-6929-5359': 211, '0000-0001-9498-284X': 154, '0000-0002-5878-8895': 139, '0000-0002-1864-3392': 92, '0000-0002-7045-8004': 57, '0000-0001-7896-6751': 57, '0000-0002-7991-9428': 55, '0000-0002-4010-1063': 45, '0000-0002-2186-3484': 28, '0000-0002-4899-1929': 25, '0000-0003-0487-4242': 24, '0000-0002-3642-1486': 22, '0000-0001-9965-3535': 17, '0000-0002-4168-757X': 17, '0000-0001-6525-3744': 14, '0000-0002-3897-0278': 14, '0000-0002-1181-5112': 12, '0000-0003-1447-9385': 11, '0000-0002-7305-8786': 11, '0000-0002-2655-7806': 10, '0000-0003-3466-5353': 9, '0000-0002-7359-663X': 8, '0000-0003-4600-8668': 6, '0000-0002-1382-7088': 5, '0000-0002-9505-4882': 5, '0000-0003-3667-9900': 4, '0000-0001-9714-6038': 4, '0000-0002-4760-0228': 3, '0000-0003-4188-7915': 3, '0000-0001-9454-0427': 3, '0000-0002-0333-6808': 3, '0000-0003-2134-4964': 3, '0000-0002-6658-047X': 3, '0000-0003-1273-379X': 3, '0000-0002-7047-3183': 3, '0000-0002-1814-9546': 3, '0000-0003-4812-6297': 2, '0000-0001-6597-578X': 2, '0000-0002-5285-9138': 2, '0000-0002-6796-7844': 2, '0000-0002-1130-8698': 2, '0000-0001-8518-8150': 2, '0000-0002-7103-924X': 2, '0000-0002-5407-0202': 1, '0000-0001-6220-8411': 1, '0000-0002-7440-6703': 1, '0000-0002-1603-7559': 1, '0000-0003-0257-1707': 1, '0000-0001-8532-6517': 1, '0000-0001-6626-316X': 1, '0000-0002-3246-9861': 1, '0000-0002-7207-4389': 1, '0000-0001-9682-9654': 1, '0000-0002-0196-3832': 1, '0000-0001-8063-6081': 1, '0000-0003-2037-3333': 1, '0000-0001-8872-6751': 1})\n",
      "Total author before apply threshoid:  57\n",
      "['0000-0001-9498-284X', '0000-0002-6929-5359', '0000-0002-5878-8895']\n",
      "Total author after apply threshoid:  3\n",
      "Total sample size after apply filter:  504\n",
      "Total missing sample:  0\n",
      "Text embedding shape:  (504, 50000)\n",
      "Total missing sample:  0\n",
      "Citation embedding shape:  (0, 0)\n",
      "Final feature (combined embedding) shape:  (504, 50000)\n",
      "MNB F1:  0.9706798900937912\n"
     ]
    }
   ],
   "source": [
    "# load the file\n",
    "import io\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statistics import mean \n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "#np.random.seed(1)\n",
    "\n",
    "fileDir = \"../Data/\"+Dataset+\"/canopies_labeled/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "\n",
    "diff_embedding_result = collections.defaultdict(list)\n",
    "\n",
    "# ----------------------- different text embedding ----------------------#\n",
    "for text_emb in pp_text_emb:\n",
    "    print(\"Load text embedding: \", text_emb)\n",
    "    all_text_embedding = []\n",
    "    all_text_emb_pid = []\n",
    "    # read pretrained embeddings\n",
    "    if text_emb in [\"tf\", \"tf_idf\"]:\n",
    "        all_text_emb_pid, all_text_embedding = com_func.read_text_embedding(emb_type=text_emb, training_size=\"140k\")\n",
    "    elif text_emb != \"off\":\n",
    "        all_text_embedding = com_func.read_text_embedding(emb_type=text_emb, training_size=\"140k\")\n",
    "        all_text_emb_pid = [emb[0] for emb in all_text_embedding]\n",
    "        all_text_embedding = [emb[1:] for emb in all_text_embedding]\n",
    "\n",
    "    for citation_emb in pp_citation_emb:\n",
    "        print(\"Load citation embedding: \", citation_emb)\n",
    "        all_citation_embedding = com_func.read_citation_embedding_sorted(emb_type = citation_emb)\n",
    "        all_citation_emb_pid = []\n",
    "        if citation_emb!= \"off\":\n",
    "            all_citation_emb_pid = [emb[0] for emb in all_citation_embedding]\n",
    "            all_citation_embedding = [emb[1:] for emb in all_citation_embedding]\n",
    "        \n",
    "        diff_threshold_result = collections.defaultdict(list)\n",
    "\n",
    "        # -------------- different filter (step by 10) -----------------------#\n",
    "        for step_filter in range(filter_lower, filter_upper, 10):\n",
    "            # collect statistic to output\n",
    "            statistic_detail = collections.defaultdict(list)\n",
    "            \n",
    "            # ------- select useful name group in all name group --------------------#\n",
    "            for file in listfiles:\n",
    "                # group name\n",
    "                temp = file.split(\"_\")\n",
    "                name = temp[1]+\"_\"+temp[-1]\n",
    "                print(\"For name: \",name)\n",
    "                # read needed content in labeled file\n",
    "                labeled_data = com_func.read_pid_aid(fileDir+file)\n",
    "                #----------- select name group contain productive author------------------------------------#\n",
    "                #----------- (contain pair of author write more than 100 papers) ---------------------------#\n",
    "                # count number of paper each author write based on author ID\n",
    "                authorCounter = collections.Counter(labeled_data[\"authorID\"])\n",
    "                # remove name group that do not contain pair of author write more than 100 papers\n",
    "                for k in list(authorCounter):\n",
    "                    if authorCounter[k] < filter_select_name_group:\n",
    "                        del authorCounter[k]\n",
    "                # if only have one class or no class pass the filter, not applicable\n",
    "                if(len(authorCounter)==0) or (len(authorCounter)==1):\n",
    "                    print(name, \" pass\")\n",
    "                else:\n",
    "                    temp_orginal_sample_size = len(labeled_data)\n",
    "                    #--------select authors in name group are very productive (more than filter)---------#\n",
    "                    print(\"Total sample size before apply filter: \",len(labeled_data))\n",
    "                    # count number of paper each author write based on author ID\n",
    "                    paperCounter = collections.Counter(labeled_data[\"authorID\"])\n",
    "                    print(paperCounter)\n",
    "                    print(\"Total author before apply threshoid: \", len(paperCounter))\n",
    "                    # collect per class statistic\n",
    "                    for k in list(paperCounter):\n",
    "                        if paperCounter[k] < step_filter:\n",
    "                            del paperCounter[k]\n",
    "                    temp =list(paperCounter.keys())\n",
    "                    print(temp)\n",
    "                    print(\"Total author after apply threshoid: \", len(temp))\n",
    "                    # remove samples that are smaller than filter\n",
    "                    labeled_data = labeled_data[labeled_data.authorID.isin(temp)]\n",
    "                    print(\"Total sample size after apply filter: \",len(labeled_data))\n",
    "                    #------------ extract paper representation -------------------------------------------#\n",
    "                    # shuffle the data\n",
    "                    labeled_data = labeled_data.sample(frac=1).reset_index(drop=True)\n",
    "                    # extract true label and pid\n",
    "                    label = labeled_data[\"authorID\"]\n",
    "                    pid = labeled_data[\"paperID\"]\n",
    "                    # list of different data field\n",
    "                    part_collection = []\n",
    "                    # select feature wanted to fit to clustering/classification algorithm\n",
    "                    # data part, text information\n",
    "                    data_part_text = com_func.extract_embedding(all_text_embedding, all_text_emb_pid, pid)\n",
    "                    print(\"Text embedding shape: \", data_part_text.shape)\n",
    "                    part_collection.append(data_part_text)\n",
    "                    # data part, citation information\n",
    "                    data_part_citation = com_func.extract_embedding(all_citation_embedding, all_citation_emb_pid, pid)\n",
    "                    data_part_citation.fillna(0, inplace=True)\n",
    "                    print(\"Citation embedding shape: \", data_part_citation.shape)\n",
    "                    part_collection.append(data_part_citation)\n",
    "                    # merge different part of data data together by concatenate it all together\n",
    "                    # remove empty emb (when emb set off)\n",
    "                    part_collection = [part for part in part_collection if len(part)!=0]\n",
    "                    if len(part_collection)>1:\n",
    "                        combinedata = np.concatenate(part_collection,axis=1)\n",
    "                    elif len(part_collection)==1:\n",
    "                        if isinstance(part_collection[0], pd.DataFrame):\n",
    "                            combinedata = part_collection[0].values\n",
    "                        else:\n",
    "                            combinedata = part_collection[0]\n",
    "                    else:\n",
    "                        print(\"No data available\")\n",
    "                        break\n",
    "                    print(\"Final feature (combined embedding) shape: \", combinedata.shape)\n",
    "                    # ------------- 10% to 100% training size changes -----------------------#\n",
    "                    # for train_percent in np.arange(0.1, 1.1, 0.1):\n",
    "                    for train_percent in [1]:\n",
    "                        statistic_detail[\"Name group\"].append(name)\n",
    "                        statistic_detail[\"Class number\"].append(len(paperCounter))\n",
    "                        statistic_detail[\"Per class size\"].append(paperCounter)\n",
    "                        statistic_detail[\"Orginal sample size\"].append(temp_orginal_sample_size)\n",
    "                        statistic_detail[\"Total selected sample size\"].append(len(labeled_data))\n",
    "                        statistic_detail[\"used_train_percent\"].append(train_percent)\n",
    "                        # -------------- using converted feature vector to train classifier-------------------#\n",
    "                        # ------------------------------ 20*10 fold for 200 runs ---------------------------- #\n",
    "                        per_run_result = collections.defaultdict(list)\n",
    "                        for i in range(100):\n",
    "                            if text_emb == \"tf\":\n",
    "                                # using multinomial naive bayes\n",
    "                                clf = MultinomialNB()\n",
    "                                mnbaccuracy, mnbmarcof1, train_size, test_size = k_fold_cv_with_different_train_size(combinedata, label, clf, train_size=train_percent, k=10, random_state=i)\n",
    "                                print(\"MNB F1: \", mnbmarcof1)\n",
    "                                per_run_result['MNB Accuracy'].append(mnbaccuracy)\n",
    "                                per_run_result['MNB macro F1'].append(mnbmarcof1)\n",
    "                            # using logistic regression\n",
    "                            clf = LogisticRegression(solver= \"liblinear\")\n",
    "                            LRaccuracy, LRmarcof1, train_size, test_size = k_fold_cv_with_different_train_size(combinedata, label, clf, train_size=train_percent, k=10, random_state=i)\n",
    "                            print(\"LR F1: \", LRmarcof1)\n",
    "                            per_run_result[\"LR accuracy\"].append(LRaccuracy)\n",
    "                            per_run_result[\"LR macro f1\"].append(LRmarcof1)\n",
    "                            # using SVM with linear kernal\n",
    "                            clf = SVC(gamma=\"auto\", kernel='linear')\n",
    "                            svcaccuracy, svcmarcof1, train_size, test_size = k_fold_cv_with_different_train_size(combinedata, label, clf, train_size=train_percent, k=10, random_state=i)\n",
    "                            print(\"SVM F1: \", svcmarcof1)\n",
    "                            per_run_result[\"SVM(linear) accuracy\"].append(svcaccuracy)\n",
    "                            per_run_result[\"SVM(linear) macro f1\"].append(svcmarcof1)\n",
    "                        print(per_run_result)\n",
    "                        for method, results in per_run_result.items():\n",
    "                            #print(method, \" mean result: \",mean(per_run_result[method]))\n",
    "                            statistic_detail[method].append(mean(per_run_result[method]))\n",
    "\n",
    "            # write evaluation result to excel\n",
    "            output = pd.DataFrame(statistic_detail)\n",
    "            print(output)\n",
    "\n",
    "            savePath = \"../../result/\"+Dataset+\"/2_OCEN_Different_train_percentage_sample=140k/100_runs/\"\n",
    "            filename = \"citation=\"+citation_emb+\"_textual=\"+text_emb+\"_threshold=\"+str(step_filter)+\".csv\"\n",
    "            com_func.write_csv_df(savePath, filename, output)\n",
    "            print(\"Done\")\n",
    "            \n",
    "            diff_threshold_result[step_filter].append(statistic_detail)\n",
    "        \n",
    "        diff_embedding_result[\"text=\"+text_emb+\"_citation=\"+citation_emb].append(diff_threshold_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T22:13:52.192261Z",
     "start_time": "2020-08-21T22:13:12.943Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
