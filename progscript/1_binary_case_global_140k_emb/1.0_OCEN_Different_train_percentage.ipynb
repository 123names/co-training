{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T11:40:10.460431Z",
     "start_time": "2020-05-25T11:40:09.775288Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One classifier each name: OCEN with different train percentage\n",
    "1. This method throw away the authors write less than 100 papers  \n",
    "2. We will collect result of different train size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T14:27:12.759840Z",
     "start_time": "2020-05-25T14:27:10.716537Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import com_func\n",
    "\n",
    "# parameters\n",
    "#----- filter for selecting set of name group -----------#\n",
    "filter_select_name_group = 100\n",
    "#----- filter for selecting productive authors ----#\n",
    "filter_lower = 100\n",
    "filter_upper = 110\n",
    "\n",
    "Dataset = \"pubmed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T14:27:17.145259Z",
     "start_time": "2020-05-25T14:27:17.120689Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# text embedding only\n",
    "pp_text_emb = [\"tf\", \"tf_idf\", \"lsa\", \"pv_dm\", \"pv_dbow\"]\n",
    "pp_citation_emb = [\"off\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T09:12:13.734489Z",
     "start_time": "2020-05-25T09:12:13.709970Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# citation embedding only\n",
    "pp_text_emb = [\"off\"]\n",
    "pp_citation_emb = [\"n2v\",\"node2vec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T07:32:49.368360Z",
     "start_time": "2020-05-25T07:32:49.365275Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined embedding\n",
    "pp_text_emb = [\"lsa\", \"pv_dm\", \"pv_dbow\"]\n",
    "pp_citation_emb = [\"n2v\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T14:27:20.839750Z",
     "start_time": "2020-05-25T14:27:20.831917Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pp_text_emb)\n",
    "print(pp_citation_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T14:27:24.124829Z",
     "start_time": "2020-05-25T14:27:23.534145Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# cross validation\n",
    "def k_fold_cv_with_different_train_size(data, label, clf, train_size=1, k=10):\n",
    "    '''\n",
    "    Split train and test for each fold first, then reduce train size\n",
    "    train_size: between 0-1 is percentage, larger than one is train size count\n",
    "    '''\n",
    "    temp_train_percent = train_size\n",
    "    random.seed(1)\n",
    "    if train_size<=0:\n",
    "        sys.exit(\"Training size must be larger than 0\")\n",
    "    # sync input datatype\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        data = pd.DataFrame(data)\n",
    "    if not isinstance(label, pd.Series):\n",
    "        label = pd.Series(label, index = data.index.values)\n",
    "        \n",
    "    # obtain data ratio\n",
    "    c = collections.Counter(label)\n",
    "    data_ratio = [(i, c[i] / len(label)) for i in c]\n",
    "    print(temp_train_percent)\n",
    "    #print(data_ratio)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=k)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel = []\n",
    "    all_fold_statistic = []\n",
    "    test_size = 0\n",
    "    fold = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(data, label):\n",
    "        fold +=1\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # ---------------1. split train and test -------------------- #\n",
    "        data_train, data_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        all_label_train, label_test = label.iloc[train_index], label.iloc[test_index]\n",
    "        # ---------------2. train classifier with different training size -------------------- #\n",
    "        if train_size<=1:\n",
    "            train_size = len(all_label_train)*train_size\n",
    "        if train_size > len(all_label_train):\n",
    "            sys.exit(\"Training size must be less or equal to total training samples\")\n",
    "        # if train_size float, take floor of a float train_size\n",
    "        train_size = int(train_size)\n",
    "        test_size = len(data_test)\n",
    "        #print(\"train: \",train_size, \" test: \",test_size)\n",
    "        # 1. number of samples for each class when perserve it's data ratio\n",
    "        train_per_class_size = [(label, round(ratio*train_size)) for label, ratio in data_ratio]\n",
    "        #print(train_per_class_size)\n",
    "        selected_train_sample_idx = []\n",
    "        # 2. select samples from train using variable we generated \n",
    "        for unique_label, training_size in train_per_class_size:\n",
    "            curr_label_idx = all_label_train.index[all_label_train == unique_label].tolist()\n",
    "            curr_label_size = len(curr_label_idx)\n",
    "            # ----------- sometime round may cause error ----------------- #\n",
    "            if temp_train_percent ==1:\n",
    "                selected_train_sample_idx+=curr_label_idx\n",
    "                #print(\"class:\",unique_label,\" all size: \", curr_label_size, \" training size:\", curr_label_size)\n",
    "            else:\n",
    "                selected_train_sample_idx += random.sample(curr_label_idx, training_size)\n",
    "                #print(\"class:\",unique_label,\" all size: \", curr_label_size, \" training size:\", training_size)\n",
    "        # .loc use index, .iloc use position\n",
    "        final_data_train = data_train.loc[selected_train_sample_idx]\n",
    "        final_label_train = all_label_train.loc[selected_train_sample_idx]\n",
    "        # 3. train classifier\n",
    "        per_fold_clf = copy.deepcopy(clf)\n",
    "        per_fold_clf.fit(final_data_train, final_label_train)\n",
    "        # 4. make predcit on test\n",
    "        per_fold_predict_test = per_fold_clf.predict(data_test)\n",
    "                \n",
    "        allTrueLabel.extend(label_test.values.tolist())\n",
    "        allPredLabel.extend(per_fold_predict_test)\n",
    "        # collect per fold statistic\n",
    "        curr_fold_statistic = {'fold':fold, 'train_size': train_per_class_size, 'test_size': data_test.shape[0],\n",
    "                               'macro f1': f1_score(label_test, per_fold_predict_test,average='macro')}\n",
    "        all_fold_statistic.append(curr_fold_statistic)\n",
    "        \n",
    "    # macro weighs each class equally \n",
    "    # micro weights each sample equally.\n",
    "    accuracy = accuracy_score(allTrueLabel, allPredLabel)\n",
    "    macro_f1 = f1_score(allTrueLabel, allPredLabel,average='macro')\n",
    "    \n",
    "    return accuracy, macro_f1, train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-25T14:28:35.915Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# load the file\n",
    "import io\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statistics import mean \n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "fileDir = \"../Data/\"+Dataset+\"/canopies_labeled/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "\n",
    "diff_embedding_result = collections.defaultdict(list)\n",
    "\n",
    "# ----------------------- different text embedding ----------------------#\n",
    "for text_emb in pp_text_emb:\n",
    "    print(\"Load text embedding: \", text_emb)\n",
    "    all_text_embedding = []\n",
    "    all_text_emb_pid = []\n",
    "    # read pretrained embeddings\n",
    "    if text_emb in [\"tf\", \"tf_idf\"]:\n",
    "        all_text_emb_pid, all_text_embedding = com_func.read_text_embedding(emb_type=text_emb, training_size=\"140k\")\n",
    "    elif text_emb != \"off\":\n",
    "        all_text_embedding = com_func.read_text_embedding(emb_type=text_emb, training_size=\"140k\")\n",
    "        all_text_emb_pid = [emb[0] for emb in all_text_embedding]\n",
    "        all_text_embedding = [emb[1:] for emb in all_text_embedding]\n",
    "\n",
    "    for citation_emb in pp_citation_emb:\n",
    "        print(\"Load citation embedding: \", citation_emb)\n",
    "        all_citation_embedding = com_func.read_citation_embedding_sorted(emb_type = citation_emb)\n",
    "        all_citation_emb_pid = []\n",
    "        if citation_emb!= \"off\":\n",
    "            all_citation_emb_pid = [emb[0] for emb in all_citation_embedding]\n",
    "            all_citation_embedding = [emb[1:] for emb in all_citation_embedding]\n",
    "        \n",
    "        diff_threshold_result = collections.defaultdict(list)\n",
    "\n",
    "        # -------------- different filter (step by 10) -----------------------#\n",
    "        for step_filter in range(filter_lower, filter_upper, 10):\n",
    "            # collect statistic to output\n",
    "            statistic_detail = collections.defaultdict(list)\n",
    "            \n",
    "            # ------- select useful name group in all name group --------------------#\n",
    "            for file in listfiles:\n",
    "                # group name\n",
    "                temp = file.split(\"_\")\n",
    "                name = temp[1]+\"_\"+temp[-1]\n",
    "                print(\"For name: \",name)\n",
    "                # read needed content in labeled file\n",
    "                labeled_data = com_func.read_pid_aid(fileDir+file)\n",
    "                #----------- select name group contain productive author------------------------------------#\n",
    "                #----------- (contain pair of author write more than 100 papers) ---------------------------#\n",
    "                # count number of paper each author write based on author ID\n",
    "                authorCounter = collections.Counter(labeled_data[\"authorID\"])\n",
    "                # remove name group that do not contain pair of author write more than 100 papers\n",
    "                for k in list(authorCounter):\n",
    "                    if authorCounter[k] < filter_select_name_group:\n",
    "                        del authorCounter[k]\n",
    "                # if only have one class or no class pass the filter, not applicable\n",
    "                if(len(authorCounter)==0) or (len(authorCounter)==1):\n",
    "                    print(name, \" pass\")\n",
    "                else:\n",
    "                    temp_orginal_sample_size = len(labeled_data)\n",
    "                    #--------select authors in name group are very productive (more than filter)---------#\n",
    "                    print(\"Total sample size before apply filter: \",len(labeled_data))\n",
    "                    # count number of paper each author write based on author ID\n",
    "                    paperCounter = collections.Counter(labeled_data[\"authorID\"])\n",
    "                    print(paperCounter)\n",
    "                    print(\"Total author before apply threshoid: \", len(paperCounter))\n",
    "                    # collect per class statistic\n",
    "                    for k in list(paperCounter):\n",
    "                        if paperCounter[k] < step_filter:\n",
    "                            del paperCounter[k]\n",
    "                    temp =list(paperCounter.keys())\n",
    "                    print(temp)\n",
    "                    print(\"Total author after apply threshoid: \", len(temp))\n",
    "                    # remove samples that are smaller than filter\n",
    "                    labeled_data = labeled_data[labeled_data.authorID.isin(temp)]\n",
    "                    print(\"Total sample size after apply filter: \",len(labeled_data))\n",
    "                    #------------ extract paper representation -------------------------------------------#\n",
    "                    # shuffle the data\n",
    "                    labeled_data = labeled_data.sample(frac=1).reset_index(drop=True)\n",
    "                    # extract true label and pid\n",
    "                    label = labeled_data[\"authorID\"]\n",
    "                    pid = labeled_data[\"paperID\"]\n",
    "                    # list of different data field\n",
    "                    part_collection = []\n",
    "                    # select feature wanted to fit to clustering/classification algorithm\n",
    "                    # data part, text information\n",
    "                    data_part_text = com_func.extract_embedding(all_text_embedding, all_text_emb_pid, pid)\n",
    "                    print(\"Text embedding shape: \", data_part_text.shape)\n",
    "                    part_collection.append(data_part_text)\n",
    "                    # data part, citation information\n",
    "                    data_part_citation = com_func.extract_embedding(all_citation_embedding, all_citation_emb_pid, pid)\n",
    "                    data_part_citation.fillna(0, inplace=True)\n",
    "                    print(\"Citation embedding shape: \", data_part_citation.shape)\n",
    "                    part_collection.append(data_part_citation)\n",
    "                    # merge different part of data data together by concatenate it all together\n",
    "                    # remove empty emb (when emb set off)\n",
    "                    part_collection = [part for part in part_collection if len(part)!=0]\n",
    "                    if len(part_collection)>1:\n",
    "                        combinedata = np.concatenate(part_collection,axis=1)\n",
    "                    elif len(part_collection)==1:\n",
    "                        if isinstance(part_collection[0], pd.DataFrame):\n",
    "                            combinedata = part_collection[0].values\n",
    "                        else:\n",
    "                            combinedata = part_collection[0]\n",
    "                    else:\n",
    "                        print(\"No data available\")\n",
    "                        break\n",
    "                    print(\"Final feature (combined embedding) shape: \", combinedata.shape)\n",
    "                    # ------------- 10% to 100% training size changes -----------------------#\n",
    "                    for train_percent in np.arange(0.1, 1.1, 0.1):\n",
    "                        statistic_detail[\"Name group\"].append(name)\n",
    "                        statistic_detail[\"Class number\"].append(len(paperCounter))\n",
    "                        statistic_detail[\"Per class size\"].append(paperCounter)\n",
    "                        statistic_detail[\"Orginal sample size\"].append(temp_orginal_sample_size)\n",
    "                        statistic_detail[\"Total selected sample size\"].append(len(labeled_data))\n",
    "                        statistic_detail[\"used_train_percent\"].append(train_percent)\n",
    "                        # -------------- using converted feature vector to train classifier-------------------#\n",
    "                        if text_emb == \"tf\":\n",
    "                            # using multinomial naive bayes\n",
    "                            clf = MultinomialNB()\n",
    "                            mnbaccuracy, mnbmarcof1, train_size, test_size = k_fold_cv_with_different_train_size(combinedata, label, clf, train_size=train_percent, k=10)\n",
    "                            print(\"MNB F1: \", mnbmarcof1)\n",
    "                            statistic_detail['MNB Accuracy'].append(mnbaccuracy)\n",
    "                            statistic_detail['MNB macro F1'].append(mnbmarcof1)\n",
    "                        # using logistic regression\n",
    "                        clf = LogisticRegression(solver= \"liblinear\")\n",
    "                        LRaccuracy, LRmarcof1, train_size, test_size = k_fold_cv_with_different_train_size(combinedata, label, clf, train_size=train_percent, k=10)\n",
    "                        print(\"LR F1: \", LRmarcof1)\n",
    "                        statistic_detail[\"LR accuracy\"].append(LRaccuracy)\n",
    "                        statistic_detail[\"LR macro f1\"].append(LRmarcof1)\n",
    "                        # using SVM with linear kernal\n",
    "                        clf = SVC(gamma=\"auto\", kernel='linear')\n",
    "                        svcaccuracy, svcmarcof1, train_size, test_size = k_fold_cv_with_different_train_size(combinedata, label, clf, train_size=train_percent, k=10)\n",
    "                        print(\"SVM F1: \", svcmarcof1)\n",
    "                        statistic_detail[\"SVM(linear) accuracy\"].append(svcaccuracy)\n",
    "                        statistic_detail[\"SVM(linear) macro f1\"].append(svcmarcof1)\n",
    "\n",
    "            # write evaluation result to excel\n",
    "            output = pd.DataFrame(statistic_detail)\n",
    "            print(output)\n",
    "\n",
    "            savePath = \"../../result/\"+Dataset+\"/2_OCEN_Different_train_percentage_sample=140k/\"\n",
    "            filename = \"citation=\"+citation_emb+\"_textual=\"+text_emb+\"_threshold=\"+str(step_filter)+\".csv\"\n",
    "            com_func.write_csv_df(savePath, filename, output)\n",
    "            print(\"Done\")\n",
    "            \n",
    "            diff_threshold_result[step_filter].append(statistic_detail)\n",
    "        \n",
    "        diff_embedding_result[\"text=\"+text_emb+\"_citation=\"+citation_emb].append(diff_threshold_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T22:40:25.421850Z",
     "start_time": "2020-05-27T22:40:25.409373Z"
    }
   },
   "outputs": [],
   "source": [
    "diff_embedding_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T16:40:50.910860Z",
     "start_time": "2019-01-10T16:40:50.871136Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%who"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
