{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vector records: 3149075\n",
      "['3', '-0.07245799', '-0.15048164', '-0.04320673', '0.01244448', '0.05051953', '-0.05573996', '0.03158288', '-0.04663554', '-0.00442508', '-0.02417533', '-0.03292065', '0.03798062', '0.08195730', '-0.09100581', '-0.04666801', '-0.06315092', '-0.05957321', '0.09766518', '0.01981102', '0.09956500', '-0.02059892', '-0.02321497', '0.10300557', '0.09654117', '0.02085607', '0.15179265', '0.03320639', '0.04716884', '0.04259005', '-0.01022485', '0.07371941', '0.02970656', '0.18967280', '0.07049462', '-0.07849123', '0.10272161', '0.05396378', '0.04138396', '0.08093689', '-0.04713648', '-0.08277001', '0.06004119', '0.15147503', '-0.10719796', '-0.06268646', '0.15823838', '0.10273122', '0.04453533', '-0.00394740', '-0.01239040', '-0.06826647', '-0.02995823', '0.14925463', '0.12254845', '-0.05894163', '0.11628735', '0.03898517', '0.01221054', '-0.00804257', '-0.06178775', '-0.04752085', '-0.04040224', '0.09192738', '0.01171173', '0.02951661', '-0.02156392', '-0.02458819', '-0.00003645', '-0.06527787', '0.07321506', '0.00926040', '0.04152755', '-0.06273570', '0.00205773', '-0.14158797', '0.01341034', '0.05070017', '-0.06785034', '0.01392612', '0.01312939', '-0.03518058', '-0.04593558', '-0.04542769', '-0.03334041', '0.02727035', '0.03331508', '-0.05495675', '-0.02231646', '-0.01770608', '0.02452897', '0.03648302', '0.02217655', '0.01033537', '0.00610828', '-0.03949452', '0.01911573', '-0.08300079', '-0.04561001', '0.01872506', '0.01281491\\n']\n"
     ]
    }
   ],
   "source": [
    "# load the vector files\n",
    "import sys\n",
    "import io\n",
    "setting = \"d2v\"\n",
    "\n",
    "vectorFilesDir = \"../Data/vectors/\"+setting+\"/\"+setting+\".txt\"\n",
    "allPaperVectors = []\n",
    "\n",
    "with open(vectorFilesDir, 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        read_data = line.split(\" \")\n",
    "        paper_Vectors = read_data\n",
    "        allPaperVectors.append(paper_Vectors)\n",
    "f.close()\n",
    "        \n",
    "print(\"Total vector records:\",len(allPaperVectors))\n",
    "print(allPaperVectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alfredo martinez.txt', 'alfredo martinez0.txt', 'alfredo martinez1.txt', 'amit patel.txt', 'amit patel0.txt', 'amit patel1.txt', 'ana castro.txt', 'ana castro0.txt', 'ana castro1.txt', 'ana castro2.txt', 'anna ferrari.txt', 'anna ferrari0.txt', 'anna ferrari1.txt', 'bin liu.txt', 'bin liu0.txt', 'bin liu1.txt', 'carmen moreno.txt', 'carmen moreno0.txt', 'carmen moreno1.txt', 'carmen torres.txt', 'carmen torres0.txt', 'carmen torres1.txt', 'chao liu.txt', 'chao liu0.txt', 'chao liu1.txt', 'cheng luo.txt', 'cheng luo0.txt', 'cheng luo1.txt', 'chung-may yang.txt', 'chung-may yang0.txt', 'chung-may yang1.txt', 'david g lloyd.txt', 'david g lloyd0.txt', 'david g lloyd1.txt', 'fang liu.txt', 'fang liu0.txt', 'fang liu1.txt', 'feng liu.txt', 'feng liu0.txt', 'feng liu1.txt', 'feng xu.txt', 'feng xu0.txt', 'feng xu1.txt', 'francisco esteves.txt', 'francisco esteves0.txt', 'francisco esteves1.txt', 'francisco j blanco.txt', 'francisco j blanco0.txt', 'francisco j blanco1.txt', 'giovanni volpe.txt', 'giovanni volpe0.txt', 'giovanni volpe1.txt', 'hao song.txt', 'hao song0.txt', 'hao song1.txt', 'hong yang.txt', 'hong yang0.txt', 'hong yang1.txt', 'jacob john.txt', 'jacob john0.txt', 'jacob john1.txt', 'jeong hwan kim.txt', 'jeong hwan kim0.txt', 'jeong hwan kim1.txt', 'jeremy m brown.txt', 'jeremy m brown0.txt', 'jeremy m brown1.txt', 'jie zhang.txt', 'jie zhang0.txt', 'jie zhang1.txt', 'jin young kim.txt', 'jin young kim0.txt', 'jin young kim1.txt', 'john f marshall.txt', 'john f marshall0.txt', 'john f marshall1.txt', 'jong hee chang.txt', 'jong hee chang0.txt', 'jong hee chang1.txt', 'jun chen.txt', 'jun chen0.txt', 'jun chen1.txt', 'jun chen2.txt', 'jun zhang.txt', 'jun zhang0.txt', 'jun zhang1.txt', 'kevin m. ryan.txt', 'kevin m. ryan0.txt', 'kevin m. ryan1.txt', 'kyung su kim.txt', 'kyung su kim0.txt', 'kyung su kim1.txt', 'lei wang.txt', 'lei wang0.txt', 'lei wang1.txt', 'lei wang2.txt', 'lei wang3.txt', 'lin yang.txt', 'lin yang0.txt', 'lin yang1.txt', 'lu\\udcc3\\udcads alves.txt', 'lu\\udcc3\\udcads alves0.txt', 'lu\\udcc3\\udcads alves1.txt', 'marco ferrari.txt', 'marco ferrari0.txt', 'marco ferrari1.txt', 'marta crespo.txt', 'marta crespo0.txt', 'marta crespo1.txt', 'martin wagner.txt', 'martin wagner0.txt', 'martin wagner1.txt', 'michael wagner.txt', 'michael wagner0.txt', 'michael wagner1.txt', 'michael wagner2.txt', 'mikael svensson.txt', 'mikael svensson0.txt', 'mikael svensson1.txt', 'pei-ming yang.txt', 'pei-ming yang0.txt', 'pei-ming yang1.txt', 'peng zhang.txt', 'peng zhang0.txt', 'peng zhang1.txt', 'peng zhang2.txt', 'peng zhang3.txt', 'qian wang.txt', 'qian wang0.txt', 'qian wang1.txt', 'qiang wang.txt', 'qiang wang0.txt', 'qiang wang1.txt', 'qin li.txt', 'qin li0.txt', 'qin li1.txt', 'richard w morris.txt', 'richard w morris0.txt', 'richard w morris1.txt', 'robert j young.txt', 'robert j young0.txt', 'robert j young1.txt', 'sebastian wolf.txt', 'sebastian wolf0.txt', 'sebastian wolf1.txt', 'vineet gupta.txt', 'vineet gupta0.txt', 'vineet gupta1.txt', 'vivek gupta.txt', 'vivek gupta0.txt', 'vivek gupta1.txt', 'vivek kumar.txt', 'vivek kumar0.txt', 'vivek kumar1.txt', 'wei lu.txt', 'wei lu0.txt', 'wei lu1.txt', 'wei wang.txt', 'wei wang0.txt', 'wei wang1.txt', 'wei wang2.txt', 'wei wang3.txt', 'wei wang4.txt', 'wei xu.txt', 'wei xu0.txt', 'wei xu1.txt', 'xin li.txt', 'xin li0.txt', 'xin li1.txt', 'yang wang.txt', 'yang wang0.txt', 'yang wang1.txt', 'yang zhao.txt', 'yang zhao0.txt', 'yang zhao1.txt', 'ying liu.txt', 'ying liu0.txt', 'ying liu1.txt', 'ying liu2.txt', 'ying zhang.txt', 'ying zhang0.txt', 'ying zhang1.txt', 'yong liu.txt', 'yong liu0.txt', 'yong liu1.txt', 'yong wang.txt', 'yong wang0.txt', 'yong wang1.txt', 'yongsheng liu.txt', 'yongsheng liu0.txt', 'yongsheng liu1.txt', 'yu zhang.txt', 'yu zhang0.txt', 'yu zhang1.txt', 'yu-jun zhao.txt', 'yu-jun zhao0.txt', 'yu-jun zhao1.txt']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# collect data\n",
    "fileDir = \"../Data/filteredSameNameAuthor/filter=10/\"\n",
    "fileList = os.listdir(fileDir)\n",
    "fileList.sort()\n",
    "print(fileList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove author(positive sample) from other(negative sample)\n",
    "import random\n",
    "def extractNegativeSample(positiveSample, allSample):\n",
    "    negativeSample = [x for x in allSample if x not in positiveSample]\n",
    "    print(\"Total negative sample size:\", len(negativeSample))\n",
    "    return negativeSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect class vectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extractVectors(author_pids, NegativeSample_pid, allPaperVectors):\n",
    "    # extract class one vectors\n",
    "    author_features = []\n",
    "    for pid in author_pids:\n",
    "         for paper_Vectors in allPaperVectors:\n",
    "            if(paper_Vectors[0] == pid):\n",
    "                author_features.append(paper_Vectors)\n",
    "    print(\"Positive sample size: \", len(author_features))\n",
    "    classOne = pd.DataFrame(author_features)\n",
    "    classOne[\"label\"] = 0\n",
    "    # extract class two vectors\n",
    "    other_features = []\n",
    "    for pid in NegativeSample_pid:\n",
    "        for paper_Vectors in allPaperVectors:\n",
    "            if(paper_Vectors[0] == pid):\n",
    "                other_features.append(paper_Vectors)\n",
    "    print(\"Negative sample size: \", len(other_features))\n",
    "    classTwo = pd.DataFrame(other_features)\n",
    "    classTwo[\"label\"] = 1\n",
    "    return classOne, classTwo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine data from different class get all data\n",
    "def combineClassesData(classOne,classTwo):\n",
    "    combinedData = pd.concat([classOne, classTwo])\n",
    "    combinedData = combinedData.sample(frac=1).reset_index(drop=True)\n",
    "    # take the paper id out\n",
    "    paperID = combinedData[0]\n",
    "    # split data and label\n",
    "    data = combinedData.drop([0,'label'], axis=1)\n",
    "    label = combinedData['label']\n",
    "    print(\"Total sample size and shape: \",data.shape)\n",
    "    return data, label, paperID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score,accuracy_score)\n",
    "# cross validation\n",
    "def k_fold_cv(author, data, label, classifier, k=10):\n",
    "    kf = KFold(n_splits=k, shuffle=False)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel = []\n",
    "    for counter,(train_index, test_index) in enumerate(kf.split(data)):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        label_train, test_true_label = label.iloc[train_index], label.iloc[test_index]\n",
    "        # fit data to svm\n",
    "        classifier.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = classifier.predict(data_test)\n",
    "        allTrueLabel.extend(test_true_label)\n",
    "        allPredLabel.extend(label_pred)\n",
    "#         # get predict proba\n",
    "#         proba = classifier.predict_proba(data_test)\n",
    "        # find out which sample cause the issue\n",
    "        print(\"Pred: \",label_pred)\n",
    "        print(\"True: \", test_true_label.values.tolist())\n",
    "        print(\"Mislabeled sample: \",end='')\n",
    "        for i in range(len(test_true_label)):\n",
    "            if(label_pred[i]!=test_true_label[test_index[i]]):\n",
    "                print(paperID[test_index[i]]+\",\",end='')\n",
    "        print()\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "\n",
    "    accuracy = accuracy_score(allTrueLabel, allPredLabel)\n",
    "    f1 = f1_score(allTrueLabel, allPredLabel,average='binary')\n",
    "    precision = precision_score(allTrueLabel, allPredLabel)\n",
    "    recall = recall_score(allTrueLabel, allPredLabel)\n",
    "    tn,fp,fn,tp = metrics.confusion_matrix(allTrueLabel, allPredLabel).ravel()\n",
    "    \n",
    "    print(\"Author: \", author)\n",
    "    print(\"Classifier: \",classifier)\n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel).ravel())\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print(\"F1: \", f1)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    \n",
    "    return accuracy, f1, precision, recall, tn, fp, fn, tp\n",
    "    # return ppv, npv, specificity, sensitivity, accuracy, f1proba = linear_svc.predict_proba(allDatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alfredo martinez0\n",
      "17\n",
      "37\n",
      "Total negative sample size: 20\n",
      "20\n",
      "Positive sample size:  17\n",
      "Negative sample size:  20\n",
      "(17, 102)\n",
      "(20, 102)\n",
      "Total sample size and shape:  (37, 100)\n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0]\n",
      "True:  [0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1]\n",
      "True:  [1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  alfredo martinez0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        17\n",
      "          1       1.00      1.00      1.00        20\n",
      "\n",
      "avg / total       1.00      1.00      1.00        37\n",
      "\n",
      "[17  0  0 20]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "alfredo martinez1\n",
      "20\n",
      "37\n",
      "Total negative sample size: 17\n",
      "17\n",
      "Positive sample size:  20\n",
      "Negative sample size:  17\n",
      "(20, 102)\n",
      "(17, 102)\n",
      "Total sample size and shape:  (37, 100)\n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1]\n",
      "True:  [0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 1]\n",
      "True:  [1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1]\n",
      "True:  [0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Author:  alfredo martinez1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        20\n",
      "          1       1.00      1.00      1.00        17\n",
      "\n",
      "avg / total       1.00      1.00      1.00        37\n",
      "\n",
      "[20  0  0 17]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "amit patel0\n",
      "11\n",
      "29\n",
      "Total negative sample size: 18\n",
      "18\n",
      "Positive sample size:  11\n",
      "Negative sample size:  18\n",
      "(11, 102)\n",
      "(18, 102)\n",
      "Total sample size and shape:  (29, 100)\n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: 23154265,\n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: 24758713,\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: \n",
      "Author:  amit patel0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        11\n",
      "          1       0.94      0.94      0.94        18\n",
      "\n",
      "avg / total       0.93      0.93      0.93        29\n",
      "\n",
      "[10  1  1 17]\n",
      "Accuracy:  0.9310344827586207\n",
      "F1:  0.9444444444444444\n",
      "Precision:  0.9444444444444444\n",
      "Recall:  0.9444444444444444\n",
      "amit patel1\n",
      "18\n",
      "29\n",
      "Total negative sample size: 11\n",
      "11\n",
      "Positive sample size:  18\n",
      "Negative sample size:  11\n",
      "(18, 102)\n",
      "(11, 102)\n",
      "Total sample size and shape:  (29, 100)\n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: 24758713,\n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0]\n",
      "True:  [1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  amit patel1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        18\n",
      "          1       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[17  1  0 11]\n",
      "Accuracy:  0.9655172413793104\n",
      "F1:  0.9565217391304348\n",
      "Precision:  0.9166666666666666\n",
      "Recall:  1.0\n",
      "ana castro0\n",
      "11\n",
      "63\n",
      "Total negative sample size: 52\n",
      "52\n",
      "Positive sample size:  11\n",
      "Negative sample size:  52\n",
      "(11, 102)\n",
      "(52, 102)\n",
      "Total sample size and shape:  (63, 100)\n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 0 1]\n",
      "True:  [0, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: 9521057,\n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [0, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: 7927409,22001288,\n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 20435699,\n",
      "Pred:  [1 0 1 1 1 1]\n",
      "True:  [1, 0, 1, 0, 1, 1]\n",
      "Mislabeled sample: 10189172,\n",
      "Pred:  [1 0 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  ana castro0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.91      1.00      0.95        52\n",
      "\n",
      "avg / total       0.93      0.92      0.91        63\n",
      "\n",
      "[ 6  5  0 52]\n",
      "Accuracy:  0.9206349206349206\n",
      "F1:  0.9541284403669724\n",
      "Precision:  0.9122807017543859\n",
      "Recall:  1.0\n",
      "ana castro1\n",
      "13\n",
      "63\n",
      "Total negative sample size: 50\n",
      "50\n",
      "Positive sample size:  13\n",
      "Negative sample size:  50\n",
      "(13, 102)\n",
      "(50, 102)\n",
      "Total sample size and shape:  (63, 100)\n",
      "Pred:  [1 1 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1 0 1 1]\n",
      "True:  [0, 0, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 0 1]\n",
      "True:  [1, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1 0]\n",
      "True:  [1, 0, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 0]\n",
      "True:  [1, 1, 1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1]\n",
      "True:  [1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Author:  ana castro1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        50\n",
      "\n",
      "avg / total       1.00      1.00      1.00        63\n",
      "\n",
      "[13  0  0 50]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "ana castro2\n",
      "39\n",
      "63\n",
      "Total negative sample size: 24\n",
      "24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  39\n",
      "Negative sample size:  24\n",
      "(39, 102)\n",
      "(24, 102)\n",
      "Total sample size and shape:  (63, 100)\n",
      "Pred:  [0 0 1 1 0 0 1]\n",
      "True:  [0, 0, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 0 0 1]\n",
      "True:  [0, 1, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1 1 1]\n",
      "True:  [0, 0, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 0]\n",
      "True:  [1, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 0]\n",
      "True:  [1, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: 20435699,\n",
      "Pred:  [0 0 1 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1 0 0]\n",
      "True:  [0, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: 7927409,1418300,\n",
      "Pred:  [1 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  ana castro2\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        39\n",
      "          1       1.00      0.88      0.93        24\n",
      "\n",
      "avg / total       0.96      0.95      0.95        63\n",
      "\n",
      "[39  0  3 21]\n",
      "Accuracy:  0.9523809523809523\n",
      "F1:  0.9333333333333333\n",
      "Precision:  1.0\n",
      "Recall:  0.875\n",
      "anna ferrari0\n",
      "17\n",
      "66\n",
      "Total negative sample size: 49\n",
      "49\n",
      "Positive sample size:  17\n",
      "Negative sample size:  49\n",
      "(17, 102)\n",
      "(49, 102)\n",
      "Total sample size and shape:  (66, 100)\n",
      "Pred:  [1 1 1 0 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: 20962862,\n",
      "Pred:  [1 1 1 0 1 1 0]\n",
      "True:  [1, 1, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1 1 1 1]\n",
      "True:  [0, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 0 1 1]\n",
      "True:  [1, 1, 0, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 0 1 1]\n",
      "True:  [1, 1, 0, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0 1]\n",
      "True:  [1, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 0 1]\n",
      "True:  [0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Author:  anna ferrari0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        17\n",
      "          1       0.98      1.00      0.99        49\n",
      "\n",
      "avg / total       0.99      0.98      0.98        66\n",
      "\n",
      "[16  1  0 49]\n",
      "Accuracy:  0.9848484848484849\n",
      "F1:  0.98989898989899\n",
      "Precision:  0.98\n",
      "Recall:  1.0\n",
      "anna ferrari1\n",
      "49\n",
      "66\n",
      "Total negative sample size: 17\n",
      "17\n",
      "Positive sample size:  49\n",
      "Negative sample size:  17\n",
      "(49, 102)\n",
      "(17, 102)\n",
      "Total sample size and shape:  (66, 100)\n",
      "Pred:  [0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 1 1]\n",
      "True:  [0, 1, 0, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 1 0 0]\n",
      "True:  [0, 0, 0, 1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0 0 1 0]\n",
      "True:  [1, 0, 1, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1 0]\n",
      "True:  [0, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: 20962862,\n",
      "Pred:  [0 1 0 1 0 0]\n",
      "True:  [0, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 1]\n",
      "True:  [0, 1, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1 0]\n",
      "True:  [0, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  anna ferrari1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        49\n",
      "          1       1.00      0.94      0.97        17\n",
      "\n",
      "avg / total       0.99      0.98      0.98        66\n",
      "\n",
      "[49  0  1 16]\n",
      "Accuracy:  0.9848484848484849\n",
      "F1:  0.9696969696969697\n",
      "Precision:  1.0\n",
      "Recall:  0.9411764705882353\n",
      "bin liu0\n",
      "14\n",
      "111\n",
      "Total negative sample size: 97\n",
      "97\n",
      "Positive sample size:  14\n",
      "Negative sample size:  97\n",
      "(14, 102)\n",
      "(97, 102)\n",
      "Total sample size and shape:  (111, 100)\n",
      "Pred:  [0 1 0 1 1 1 1 1 1 1 1 1]\n",
      "True:  [0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 16113220,\n",
      "Pred:  [1 0 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 1 1 1 0 0 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 21511871,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 0 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 20943427,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  bin liu0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        14\n",
      "          1       0.97      1.00      0.98        97\n",
      "\n",
      "avg / total       0.97      0.97      0.97       111\n",
      "\n",
      "[11  3  0 97]\n",
      "Accuracy:  0.972972972972973\n",
      "F1:  0.9847715736040609\n",
      "Precision:  0.97\n",
      "Recall:  1.0\n",
      "bin liu1\n",
      "97\n",
      "111\n",
      "Total negative sample size: 14\n",
      "14\n",
      "Positive sample size:  97\n",
      "Negative sample size:  14\n",
      "(97, 102)\n",
      "(14, 102)\n",
      "Total sample size and shape:  (111, 100)\n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0 0 0 0 0 0 0 0]\n",
      "True:  [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: 16113220,\n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 1 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 1 0 0 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 1 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1]\n",
      "Mislabeled sample: 20943427,\n",
      "Pred:  [0 0 0 0 0 1 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 1 0 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: 21511871,\n",
      "Pred:  [0 1 0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  bin liu1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        97\n",
      "          1       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97       111\n",
      "\n",
      "[97  0  3 11]\n",
      "Accuracy:  0.972972972972973\n",
      "F1:  0.88\n",
      "Precision:  1.0\n",
      "Recall:  0.7857142857142857\n",
      "carmen moreno0\n",
      "13\n",
      "48\n",
      "Total negative sample size: 35\n",
      "35\n",
      "Positive sample size:  13\n",
      "Negative sample size:  35\n",
      "(13, 102)\n",
      "(35, 102)\n",
      "Total sample size and shape:  (48, 100)\n",
      "Pred:  [0 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1]\n",
      "True:  [1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1 1]\n",
      "True:  [0, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  carmen moreno0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        35\n",
      "\n",
      "avg / total       1.00      1.00      1.00        48\n",
      "\n",
      "[13  0  0 35]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "carmen moreno1\n",
      "35\n",
      "48\n",
      "Total negative sample size: 13\n",
      "13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  35\n",
      "Negative sample size:  13\n",
      "(35, 102)\n",
      "(13, 102)\n",
      "Total sample size and shape:  (48, 100)\n",
      "Pred:  [0 0 1 0 1]\n",
      "True:  [0, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0 0]\n",
      "True:  [1, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 0]\n",
      "True:  [1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 1]\n",
      "True:  [0, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0]\n",
      "True:  [0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  carmen moreno1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        35\n",
      "          1       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        48\n",
      "\n",
      "[35  0  0 13]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "carmen torres0\n",
      "20\n",
      "257\n",
      "Total negative sample size: 237\n",
      "237\n",
      "Positive sample size:  20\n",
      "Negative sample size:  237\n",
      "(20, 102)\n",
      "(237, 102)\n",
      "Total sample size and shape:  (257, 100)\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 12818358,\n",
      "Pred:  [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 12002520,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  carmen torres0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        20\n",
      "          1       0.99      1.00      1.00       237\n",
      "\n",
      "avg / total       0.99      0.99      0.99       257\n",
      "\n",
      "[ 18   2   0 237]\n",
      "Accuracy:  0.9922178988326849\n",
      "F1:  0.995798319327731\n",
      "Precision:  0.9916317991631799\n",
      "Recall:  1.0\n",
      "carmen torres1\n",
      "237\n",
      "257\n",
      "Total negative sample size: 20\n",
      "20\n",
      "Positive sample size:  237\n",
      "Negative sample size:  20\n",
      "(237, 102)\n",
      "(20, 102)\n",
      "Total sample size and shape:  (257, 100)\n",
      "Pred:  [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0]\n",
      "True:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: 12002520,\n",
      "Pred:  [0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  carmen torres1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       237\n",
      "          1       1.00      0.95      0.97        20\n",
      "\n",
      "avg / total       1.00      1.00      1.00       257\n",
      "\n",
      "[237   0   1  19]\n",
      "Accuracy:  0.9961089494163424\n",
      "F1:  0.9743589743589743\n",
      "Precision:  1.0\n",
      "Recall:  0.95\n",
      "chao liu0\n",
      "16\n",
      "45\n",
      "Total negative sample size: 29\n",
      "29\n",
      "Positive sample size:  16\n",
      "Negative sample size:  29\n",
      "(16, 102)\n",
      "(29, 102)\n",
      "Total sample size and shape:  (45, 100)\n",
      "Pred:  [0 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 23831010,\n",
      "Pred:  [1 0 1 0 1]\n",
      "True:  [1, 0, 0, 0, 1]\n",
      "Mislabeled sample: 22916059,\n",
      "Pred:  [1 1 0 0 0]\n",
      "True:  [1, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1]\n",
      "True:  [1, 0, 1, 1, 0]\n",
      "Mislabeled sample: 16549344,\n",
      "Pred:  [1 0 1 1]\n",
      "True:  [1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0]\n",
      "True:  [1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0]\n",
      "True:  [1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  chao liu0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.91      1.00      0.95        29\n",
      "\n",
      "avg / total       0.94      0.93      0.93        45\n",
      "\n",
      "[13  3  0 29]\n",
      "Accuracy:  0.9333333333333333\n",
      "F1:  0.9508196721311475\n",
      "Precision:  0.90625\n",
      "Recall:  1.0\n",
      "chao liu1\n",
      "29\n",
      "45\n",
      "Total negative sample size: 16\n",
      "16\n",
      "Positive sample size:  29\n",
      "Negative sample size:  16\n",
      "(29, 102)\n",
      "(16, 102)\n",
      "Total sample size and shape:  (45, 100)\n",
      "Pred:  [0 1 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 0]\n",
      "True:  [0, 0, 0, 1, 1]\n",
      "Mislabeled sample: 22916059,\n",
      "Pred:  [0 0 1 0 0]\n",
      "True:  [0, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0]\n",
      "True:  [0, 1, 0, 0, 1]\n",
      "Mislabeled sample: 23831010,\n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 1]\n",
      "Mislabeled sample: 16549344,\n",
      "Pred:  [0 1 1 1]\n",
      "True:  [0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1]\n",
      "True:  [0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  chao liu1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        29\n",
      "          1       1.00      0.81      0.90        16\n",
      "\n",
      "avg / total       0.94      0.93      0.93        45\n",
      "\n",
      "[29  0  3 13]\n",
      "Accuracy:  0.9333333333333333\n",
      "F1:  0.896551724137931\n",
      "Precision:  1.0\n",
      "Recall:  0.8125\n",
      "cheng luo0\n",
      "15\n",
      "51\n",
      "Total negative sample size: 36\n",
      "36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  15\n",
      "Negative sample size:  36\n",
      "(15, 102)\n",
      "(36, 102)\n",
      "Total sample size and shape:  (51, 100)\n",
      "Pred:  [0 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 0]\n",
      "True:  [1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1]\n",
      "True:  [1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0]\n",
      "True:  [1, 1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0]\n",
      "True:  [1, 1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1]\n",
      "True:  [1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  cheng luo0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       1.00      1.00      1.00        36\n",
      "\n",
      "avg / total       1.00      1.00      1.00        51\n",
      "\n",
      "[15  0  0 36]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "cheng luo1\n",
      "36\n",
      "51\n",
      "Total negative sample size: 15\n",
      "15\n",
      "Positive sample size:  36\n",
      "Negative sample size:  15\n",
      "(36, 102)\n",
      "(15, 102)\n",
      "Total sample size and shape:  (51, 100)\n",
      "Pred:  [0 0 1 1 0 1]\n",
      "True:  [0, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 0]\n",
      "True:  [0, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 1]\n",
      "True:  [1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1 0]\n",
      "True:  [0, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 1]\n",
      "True:  [0, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1 0]\n",
      "True:  [0, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  cheng luo1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        36\n",
      "          1       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        51\n",
      "\n",
      "[36  0  0 15]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "chung-may yang0\n",
      "42\n",
      "113\n",
      "Total negative sample size: 71\n",
      "71\n",
      "Positive sample size:  42\n",
      "Negative sample size:  71\n",
      "(42, 102)\n",
      "(71, 102)\n",
      "Total sample size and shape:  (113, 100)\n",
      "Pred:  [1 0 1 1 1 0 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: 9395771,20847676,26582311,18682973,\n",
      "Pred:  [1 1 1 0 1 1 1 1 1 1 0 1]\n",
      "True:  [0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: 24126678,15389271,10704565,16226531,\n",
      "Pred:  [1 1 1 0 1 0 1 1 1 0 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0]\n",
      "Mislabeled sample: 25061523,22538426,17013703,14574305,24669373,\n",
      "Pred:  [1 0 0 0 1 1 1 0 1 1 1]\n",
      "True:  [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "Mislabeled sample: 24296307,21822163,16397616,15650518,15621160,8282044,\n",
      "Pred:  [0 0 0 0 0 0 0 1 1 1 0]\n",
      "True:  [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "Mislabeled sample: 18997639,26611649,18569793,24658779,18547539,\n",
      "Pred:  [0 1 0 1 1 1 0 1 1 0 0]\n",
      "True:  [1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 19832732,19394702,20127106,22688252,\n",
      "Pred:  [0 0 1 0 1 0 1 0 1 0 1]\n",
      "True:  [1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: 18292791,16139013,26047532,\n",
      "Pred:  [1 0 1 1 0 0 1 1 1 0 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 16543926,27084002,25812553,22222267,\n",
      "Pred:  [1 1 1 1 1 0 1 1 1 0 0]\n",
      "True:  [0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 9798216,20673589,11884879,\n",
      "Pred:  [1 0 1 1 1 0 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: 15846382,25653869,26934453,26803488,17721499,22967867,18347622,\n",
      "Author:  chung-may yang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.43      0.44        42\n",
      "          1       0.68      0.70      0.69        71\n",
      "\n",
      "avg / total       0.60      0.60      0.60       113\n",
      "\n",
      "[18 24 21 50]\n",
      "Accuracy:  0.6017699115044248\n",
      "F1:  0.689655172413793\n",
      "Precision:  0.6756756756756757\n",
      "Recall:  0.704225352112676\n",
      "chung-may yang1\n",
      "71\n",
      "113\n",
      "Total negative sample size: 42\n",
      "42\n",
      "Positive sample size:  71\n",
      "Negative sample size:  42\n",
      "(71, 102)\n",
      "(42, 102)\n",
      "Total sample size and shape:  (113, 100)\n",
      "Pred:  [0 1 1 0 0 0 1 0 1 0 0 0]\n",
      "True:  [0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: 9798216,26934453,16767385,26803488,23142991,24669373,15389271,27084002,\n",
      "Pred:  [0 0 0 0 0 1 0 0 0 0 1 1]\n",
      "True:  [1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "Mislabeled sample: 24126678,24296307,16139013,19832732,19394702,16543926,\n",
      "Pred:  [0 0 1 0 1 0 0 1 0 0 0 0]\n",
      "True:  [1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1]\n",
      "Mislabeled sample: 20847676,24658779,26582311,18682973,22538426,10704565,26047532,\n",
      "Pred:  [0 0 1 0 0 0 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "Mislabeled sample: 16159720,22967867,18997639,16691255,21822163,18569793,\n",
      "Pred:  [1 0 1 1 0 0 0 1 1 0 0]\n",
      "True:  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
      "Mislabeled sample: 25653869,25812553,22688252,17721499,8282044,16397616,15846382,\n",
      "Pred:  [1 1 0 0 1 1 1 0 0 1 0]\n",
      "True:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "Mislabeled sample: 26611649,15953438,11884879,\n",
      "Pred:  [1 0 0 0 0 1 0 0 1 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 1 0 0 0 0 1 1]\n",
      "True:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: 23680863,14574305,16226531,23635418,\n",
      "Pred:  [1 0 0 1 0 0 0 0 1 0 1]\n",
      "True:  [1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: 9395771,17013703,25061523,15650518,\n",
      "Pred:  [0 0 0 0 1 0 0 1 0 0 0]\n",
      "True:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: 22222267,15621160,\n",
      "Author:  chung-may yang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.68      0.67        71\n",
      "          1       0.44      0.43      0.43        42\n",
      "\n",
      "avg / total       0.58      0.58      0.58       113\n",
      "\n",
      "[48 23 24 18]\n",
      "Accuracy:  0.584070796460177\n",
      "F1:  0.4337349397590361\n",
      "Precision:  0.43902439024390244\n",
      "Recall:  0.42857142857142855\n",
      "david g lloyd0\n",
      "50\n",
      "154\n",
      "Total negative sample size: 104\n",
      "104\n",
      "Positive sample size:  50\n",
      "Negative sample size:  104\n",
      "(50, 102)\n",
      "(104, 102)\n",
      "Total sample size and shape:  (154, 100)\n",
      "Pred:  [1 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0]\n",
      "True:  [1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: 16854626,\n",
      "Pred:  [1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1]\n",
      "True:  [1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1]\n",
      "True:  [0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 1 1 0 1 1 1 1 0 1 0 1]\n",
      "True:  [1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 0]\n",
      "True:  [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 19074587,\n",
      "Pred:  [0 1 1 1 0 1 0 0 1 1 1 0 1 1 1]\n",
      "True:  [0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: 19881006,\n",
      "Pred:  [1 0 1 1 1 0 1 1 1 0 1 1 0 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 0 0 0 1 0 1 0 0 1 0 1]\n",
      "True:  [1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Author:  david g lloyd0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97        50\n",
      "          1       0.99      0.98      0.99       104\n",
      "\n",
      "avg / total       0.98      0.98      0.98       154\n",
      "\n",
      "[ 49   1   2 102]\n",
      "Accuracy:  0.9805194805194806\n",
      "F1:  0.9855072463768114\n",
      "Precision:  0.9902912621359223\n",
      "Recall:  0.9807692307692307\n",
      "david g lloyd1\n",
      "104\n",
      "154\n",
      "Total negative sample size: 50\n",
      "50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  104\n",
      "Negative sample size:  50\n",
      "(104, 102)\n",
      "(50, 102)\n",
      "Total sample size and shape:  (154, 100)\n",
      "Pred:  [0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1]\n",
      "True:  [0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0]\n",
      "True:  [1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0 0 1 0 0 1 0 0 0 1 0]\n",
      "True:  [0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: 19881006,\n",
      "Pred:  [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: 19074587,\n",
      "Pred:  [0 0 0 1 0 0 0 0 1 0 1 0 1 1 0]\n",
      "True:  [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 0 1 1 1 1 0 0 0 1 0 0]\n",
      "True:  [1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: 16854626,\n",
      "Pred:  [0 0 1 0 1 1 0 1 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 1 0 0 1 1 0 1 1 0 0 0]\n",
      "True:  [0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  david g lloyd1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.99       104\n",
      "          1       0.96      0.98      0.97        50\n",
      "\n",
      "avg / total       0.98      0.98      0.98       154\n",
      "\n",
      "[102   2   1  49]\n",
      "Accuracy:  0.9805194805194806\n",
      "F1:  0.9702970297029702\n",
      "Precision:  0.9607843137254902\n",
      "Recall:  0.98\n",
      "fang liu0\n",
      "11\n",
      "28\n",
      "Total negative sample size: 17\n",
      "17\n",
      "Positive sample size:  11\n",
      "Negative sample size:  17\n",
      "(11, 102)\n",
      "(17, 102)\n",
      "Total sample size and shape:  (28, 100)\n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1]\n",
      "True:  [1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1]\n",
      "True:  [1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  fang liu0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        17\n",
      "\n",
      "avg / total       1.00      1.00      1.00        28\n",
      "\n",
      "[11  0  0 17]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "fang liu1\n",
      "17\n",
      "28\n",
      "Total negative sample size: 11\n",
      "11\n",
      "Positive sample size:  17\n",
      "Negative sample size:  11\n",
      "(17, 102)\n",
      "(11, 102)\n",
      "Total sample size and shape:  (28, 100)\n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: 24721548,\n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0]\n",
      "True:  [0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: \n",
      "Author:  fang liu1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        17\n",
      "          1       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.97      0.96      0.96        28\n",
      "\n",
      "[16  1  0 11]\n",
      "Accuracy:  0.9642857142857143\n",
      "F1:  0.9565217391304348\n",
      "Precision:  0.9166666666666666\n",
      "Recall:  1.0\n",
      "feng liu0\n",
      "30\n",
      "61\n",
      "Total negative sample size: 31\n",
      "31\n",
      "Positive sample size:  30\n",
      "Negative sample size:  31\n",
      "(30, 102)\n",
      "(31, 102)\n",
      "Total sample size and shape:  (61, 100)\n",
      "Pred:  [0 1 0 0 1 1 1]\n",
      "True:  [0, 1, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 1 0]\n",
      "True:  [0, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 1 1]\n",
      "True:  [1, 1, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 1 0]\n",
      "True:  [0, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 1 1]\n",
      "True:  [0, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 0]\n",
      "True:  [1, 1, 1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 1 1]\n",
      "True:  [1, 1, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 1 0 1]\n",
      "True:  [1, 0, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0 0]\n",
      "True:  [1, 1, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  feng liu0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        30\n",
      "          1       1.00      1.00      1.00        31\n",
      "\n",
      "avg / total       1.00      1.00      1.00        61\n",
      "\n",
      "[30  0  0 31]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "feng liu1\n",
      "31\n",
      "61\n",
      "Total negative sample size: 30\n",
      "30\n",
      "Positive sample size:  31\n",
      "Negative sample size:  30\n",
      "(31, 102)\n",
      "(30, 102)\n",
      "Total sample size and shape:  (61, 100)\n",
      "Pred:  [0 1 0 1 1 1 1]\n",
      "True:  [0, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 0]\n",
      "True:  [1, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1 0 1]\n",
      "True:  [0, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 0 1]\n",
      "True:  [0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1 0]\n",
      "True:  [1, 0, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 0 1]\n",
      "True:  [0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 0 0]\n",
      "True:  [1, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1 0]\n",
      "True:  [0, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  feng liu1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       1.00      1.00      1.00        30\n",
      "\n",
      "avg / total       1.00      1.00      1.00        61\n",
      "\n",
      "[31  0  0 30]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "feng xu0\n",
      "12\n",
      "41\n",
      "Total negative sample size: 29\n",
      "29\n",
      "Positive sample size:  12\n",
      "Negative sample size:  29\n",
      "(12, 102)\n",
      "(29, 102)\n",
      "Total sample size and shape:  (41, 100)\n",
      "Pred:  [1 1 0 1 1]\n",
      "True:  [1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1]\n",
      "True:  [0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1]\n",
      "True:  [0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1]\n",
      "True:  [0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1]\n",
      "True:  [0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 1]\n",
      "True:  [1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  feng xu0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       1.00      1.00      1.00        41\n",
      "\n",
      "[12  0  0 29]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "feng xu1\n",
      "29\n",
      "41\n",
      "Total negative sample size: 12\n",
      "12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  29\n",
      "Negative sample size:  12\n",
      "(29, 102)\n",
      "(12, 102)\n",
      "Total sample size and shape:  (41, 100)\n",
      "Pred:  [0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1]\n",
      "True:  [0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1]\n",
      "True:  [0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0]\n",
      "True:  [0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  feng xu1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        29\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        41\n",
      "\n",
      "[29  0  0 12]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "francisco esteves0\n",
      "12\n",
      "30\n",
      "Total negative sample size: 18\n",
      "18\n",
      "Positive sample size:  12\n",
      "Negative sample size:  18\n",
      "(12, 102)\n",
      "(18, 102)\n",
      "Total sample size and shape:  (30, 100)\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 25144403,\n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Author:  francisco esteves0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.95      1.00      0.97        18\n",
      "\n",
      "avg / total       0.97      0.97      0.97        30\n",
      "\n",
      "[11  1  0 18]\n",
      "Accuracy:  0.9666666666666667\n",
      "F1:  0.972972972972973\n",
      "Precision:  0.9473684210526315\n",
      "Recall:  1.0\n",
      "francisco esteves1\n",
      "18\n",
      "30\n",
      "Total negative sample size: 12\n",
      "12\n",
      "Positive sample size:  18\n",
      "Negative sample size:  12\n",
      "(18, 102)\n",
      "(12, 102)\n",
      "Total sample size and shape:  (30, 100)\n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  francisco esteves1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        30\n",
      "\n",
      "[18  0  0 12]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "francisco j blanco0\n",
      "16\n",
      "71\n",
      "Total negative sample size: 55\n",
      "55\n",
      "Positive sample size:  16\n",
      "Negative sample size:  55\n",
      "(16, 102)\n",
      "(55, 102)\n",
      "Total sample size and shape:  (71, 100)\n",
      "Pred:  [1 1 1 1 1 1 0 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: 11719592,\n",
      "Pred:  [1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 0 1 1]\n",
      "True:  [1, 1, 0, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 1 1 1]\n",
      "True:  [1, 0, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 1 1 0]\n",
      "True:  [0, 1, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 19965692,\n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 0, 1, 1]\n",
      "Mislabeled sample: 22347366,17081563,\n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  francisco j blanco0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        16\n",
      "          1       0.93      1.00      0.96        55\n",
      "\n",
      "avg / total       0.95      0.94      0.94        71\n",
      "\n",
      "[12  4  0 55]\n",
      "Accuracy:  0.9436619718309859\n",
      "F1:  0.9649122807017544\n",
      "Precision:  0.9322033898305084\n",
      "Recall:  1.0\n",
      "francisco j blanco1\n",
      "55\n",
      "71\n",
      "Total negative sample size: 16\n",
      "16\n",
      "Positive sample size:  55\n",
      "Negative sample size:  16\n",
      "(55, 102)\n",
      "(16, 102)\n",
      "Total sample size and shape:  (71, 100)\n",
      "Pred:  [0 0 1 0 0 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 1 0]\n",
      "True:  [0, 1, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1 0 1]\n",
      "True:  [0, 1, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: 21982971,22347366,\n",
      "Pred:  [0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: 17081563,\n",
      "Pred:  [1 0 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 0 0 0]\n",
      "True:  [0, 1, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: 11719592,\n",
      "Pred:  [0 0 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: 19965692,\n",
      "Pred:  [0 1 0 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  francisco j blanco1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        55\n",
      "          1       1.00      0.69      0.81        16\n",
      "\n",
      "avg / total       0.94      0.93      0.92        71\n",
      "\n",
      "[55  0  5 11]\n",
      "Accuracy:  0.9295774647887324\n",
      "F1:  0.8148148148148148\n",
      "Precision:  1.0\n",
      "Recall:  0.6875\n",
      "giovanni volpe0\n",
      "14\n",
      "29\n",
      "Total negative sample size: 15\n",
      "15\n",
      "Positive sample size:  14\n",
      "Negative sample size:  15\n",
      "(14, 102)\n",
      "(15, 102)\n",
      "Total sample size and shape:  (29, 100)\n",
      "Pred:  [0 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: 25375496,\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: 24217466,\n",
      "Pred:  [1 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 26469625,\n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: 24202536,\n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 18233825,15828794,\n",
      "Pred:  [0 1]\n",
      "True:  [0, 0]\n",
      "Mislabeled sample: 23705745,\n",
      "Author:  giovanni volpe0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.64      0.72        14\n",
      "          1       0.72      0.87      0.79        15\n",
      "\n",
      "avg / total       0.77      0.76      0.76        29\n",
      "\n",
      "[ 9  5  2 13]\n",
      "Accuracy:  0.7586206896551724\n",
      "F1:  0.7878787878787877\n",
      "Precision:  0.7222222222222222\n",
      "Recall:  0.8666666666666667\n",
      "giovanni volpe1\n",
      "15\n",
      "29\n",
      "Total negative sample size: 14\n",
      "14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  15\n",
      "Negative sample size:  14\n",
      "(15, 102)\n",
      "(14, 102)\n",
      "Total sample size and shape:  (29, 100)\n",
      "Pred:  [1 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: 25375496,\n",
      "Pred:  [1 0 0]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: 18233825,15828794,\n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 26469625,\n",
      "Pred:  [1 1 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: 22739052,26956085,\n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: 23003302,\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: 24202536,24217466,\n",
      "Pred:  [0 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: 23705745,\n",
      "Pred:  [0 1]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: \n",
      "Author:  giovanni volpe1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.67      0.67        15\n",
      "          1       0.64      0.64      0.64        14\n",
      "\n",
      "avg / total       0.66      0.66      0.66        29\n",
      "\n",
      "[10  5  5  9]\n",
      "Accuracy:  0.6551724137931034\n",
      "F1:  0.6428571428571429\n",
      "Precision:  0.6428571428571429\n",
      "Recall:  0.6428571428571429\n",
      "hao song0\n",
      "29\n",
      "59\n",
      "Total negative sample size: 30\n",
      "30\n",
      "Positive sample size:  29\n",
      "Negative sample size:  30\n",
      "(29, 102)\n",
      "(30, 102)\n",
      "Total sample size and shape:  (59, 100)\n",
      "Pred:  [1 1 1 1 0 0]\n",
      "True:  [1, 1, 1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1 1 0]\n",
      "True:  [0, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0 1]\n",
      "True:  [1, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1 1]\n",
      "True:  [0, 0, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 0]\n",
      "True:  [1, 0, 1, 1, 1, 0]\n",
      "Mislabeled sample: 17690953,\n",
      "Pred:  [0 1 1 1 0 1]\n",
      "True:  [0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 0 1]\n",
      "True:  [0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1 0]\n",
      "True:  [0, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 0 1]\n",
      "True:  [1, 1, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 0]\n",
      "True:  [0, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  hao song0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        29\n",
      "          1       0.97      1.00      0.98        30\n",
      "\n",
      "avg / total       0.98      0.98      0.98        59\n",
      "\n",
      "[28  1  0 30]\n",
      "Accuracy:  0.9830508474576272\n",
      "F1:  0.9836065573770492\n",
      "Precision:  0.967741935483871\n",
      "Recall:  1.0\n",
      "hao song1\n",
      "30\n",
      "59\n",
      "Total negative sample size: 29\n",
      "29\n",
      "Positive sample size:  30\n",
      "Negative sample size:  29\n",
      "(30, 102)\n",
      "(29, 102)\n",
      "Total sample size and shape:  (59, 100)\n",
      "Pred:  [0 1 1 0 1 0]\n",
      "True:  [1, 1, 1, 0, 1, 0]\n",
      "Mislabeled sample: 17690953,\n",
      "Pred:  [1 1 0 1 0 0]\n",
      "True:  [1, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 1 0]\n",
      "True:  [1, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 0 0]\n",
      "True:  [0, 1, 1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 0 1]\n",
      "True:  [0, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0 0 0]\n",
      "True:  [1, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1]\n",
      "True:  [1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  hao song1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        30\n",
      "          1       1.00      0.97      0.98        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        59\n",
      "\n",
      "[30  0  1 28]\n",
      "Accuracy:  0.9830508474576272\n",
      "F1:  0.9824561403508771\n",
      "Precision:  1.0\n",
      "Recall:  0.9655172413793104\n",
      "hong yang0\n",
      "18\n",
      "63\n",
      "Total negative sample size: 45\n",
      "45\n",
      "Positive sample size:  18\n",
      "Negative sample size:  45\n",
      "(18, 102)\n",
      "(45, 102)\n",
      "Total sample size and shape:  (63, 100)\n",
      "Pred:  [1 1 1 0 1 1 1]\n",
      "True:  [1, 0, 0, 0, 0, 1, 1]\n",
      "Mislabeled sample: 21376387,18449872,19810064,\n",
      "Pred:  [0 0 1 1 1 0 1]\n",
      "True:  [0, 0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: 20974846,26151444,25895966,\n",
      "Pred:  [1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: 19594172,\n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 19810065,\n",
      "Pred:  [1 0 0 0 1 1]\n",
      "True:  [1, 0, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: 17850149,\n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 21948562,\n",
      "Author:  hong yang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.44      0.62        18\n",
      "          1       0.82      1.00      0.90        45\n",
      "\n",
      "avg / total       0.87      0.84      0.82        63\n",
      "\n",
      "[ 8 10  0 45]\n",
      "Accuracy:  0.8412698412698413\n",
      "F1:  0.9\n",
      "Precision:  0.8181818181818182\n",
      "Recall:  1.0\n",
      "hong yang1\n",
      "45\n",
      "63\n",
      "Total negative sample size: 18\n",
      "18\n",
      "Positive sample size:  45\n",
      "Negative sample size:  18\n",
      "(45, 102)\n",
      "(18, 102)\n",
      "Total sample size and shape:  (63, 100)\n",
      "Pred:  [0 0 0 0 1 1 0]\n",
      "True:  [0, 0, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: 21376387,\n",
      "Pred:  [1 0 0 1 0 0 0]\n",
      "True:  [1, 0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 1 0]\n",
      "True:  [0, 1, 0, 1, 0, 1, 0]\n",
      "Mislabeled sample: 19810065,\n",
      "Pred:  [0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: 21948562,\n",
      "Pred:  [0 0 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: 20974846,\n",
      "Pred:  [1 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 0]\n",
      "True:  [0, 1, 1, 0, 0, 0]\n",
      "Mislabeled sample: 19810064,\n",
      "Pred:  [0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 1]\n",
      "Mislabeled sample: 26151444,18449872,\n",
      "Pred:  [0 0 1 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 1]\n",
      "True:  [0, 1, 0, 0, 0, 1]\n",
      "Mislabeled sample: 19594172,\n",
      "Author:  hong yang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        45\n",
      "          1       1.00      0.56      0.71        18\n",
      "\n",
      "avg / total       0.89      0.87      0.86        63\n",
      "\n",
      "[45  0  8 10]\n",
      "Accuracy:  0.873015873015873\n",
      "F1:  0.7142857142857143\n",
      "Precision:  1.0\n",
      "Recall:  0.5555555555555556\n",
      "jacob john0\n",
      "11\n",
      "27\n",
      "Total negative sample size: 16\n",
      "16\n",
      "Positive sample size:  11\n",
      "Negative sample size:  16\n",
      "(11, 102)\n",
      "(16, 102)\n",
      "Total sample size and shape:  (27, 100)\n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: 23644312,\n",
      "Pred:  [0 1]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0]\n",
      "True:  [1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  jacob john0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        11\n",
      "          1       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.97      0.96      0.96        27\n",
      "\n",
      "[11  0  1 15]\n",
      "Accuracy:  0.9629629629629629\n",
      "F1:  0.967741935483871\n",
      "Precision:  1.0\n",
      "Recall:  0.9375\n",
      "jacob john1\n",
      "16\n",
      "27\n",
      "Total negative sample size: 11\n",
      "11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  16\n",
      "Negative sample size:  11\n",
      "(16, 102)\n",
      "(11, 102)\n",
      "Total sample size and shape:  (27, 100)\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: 23644312,\n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0]\n",
      "True:  [0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1]\n",
      "True:  [1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  jacob john1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        16\n",
      "          1       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.97      0.96      0.96        27\n",
      "\n",
      "[15  1  0 11]\n",
      "Accuracy:  0.9629629629629629\n",
      "F1:  0.9565217391304348\n",
      "Precision:  0.9166666666666666\n",
      "Recall:  1.0\n",
      "jeong hwan kim0\n",
      "33\n",
      "84\n",
      "Total negative sample size: 51\n",
      "51\n",
      "Positive sample size:  33\n",
      "Negative sample size:  51\n",
      "(33, 102)\n",
      "(51, 102)\n",
      "Total sample size and shape:  (84, 100)\n",
      "Pred:  [1 1 1 1 0 0 1 0 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: 15209628,\n",
      "Pred:  [0 0 0 1 1 0 1 0 1]\n",
      "True:  [0, 0, 0, 1, 1, 0, 0, 0, 1]\n",
      "Mislabeled sample: 19346790,\n",
      "Pred:  [1 1 0 1 0 1 0 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: 14641842,23323252,\n",
      "Pred:  [1 1 0 1 1 0 1 0 1]\n",
      "True:  [1, 1, 0, 1, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 1 0 1 0]\n",
      "True:  [1, 1, 0, 0, 1, 0, 1, 1]\n",
      "Mislabeled sample: 16336441,\n",
      "Pred:  [1 1 1 0 1 0 1 0]\n",
      "True:  [1, 1, 1, 0, 1, 0, 0, 1]\n",
      "Mislabeled sample: 22381530,21814595,\n",
      "Pred:  [0 0 1 1 1 1 0 1]\n",
      "True:  [0, 0, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 0 1 0]\n",
      "True:  [1, 1, 0, 1, 1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 0 1 1]\n",
      "True:  [1, 0, 1, 0, 1, 0, 1, 1]\n",
      "Mislabeled sample: 21728030,22669208,\n",
      "Pred:  [0 1 1 0 0 1 0 1]\n",
      "True:  [0, 1, 1, 0, 1, 0, 0, 1]\n",
      "Mislabeled sample: 15107843,21525770,\n",
      "Author:  jeong hwan kim0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.82      0.83        33\n",
      "          1       0.88      0.90      0.89        51\n",
      "\n",
      "avg / total       0.87      0.87      0.87        84\n",
      "\n",
      "[27  6  5 46]\n",
      "Accuracy:  0.8690476190476191\n",
      "F1:  0.8932038834951457\n",
      "Precision:  0.8846153846153846\n",
      "Recall:  0.9019607843137255\n",
      "jeong hwan kim1\n",
      "51\n",
      "84\n",
      "Total negative sample size: 33\n",
      "33\n",
      "Positive sample size:  51\n",
      "Negative sample size:  33\n",
      "(51, 102)\n",
      "(33, 102)\n",
      "Total sample size and shape:  (84, 100)\n",
      "Pred:  [0 0 1 0 1 0 0 1 0]\n",
      "True:  [0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: 14641842,\n",
      "Pred:  [1 1 0 0 0 0 1 0 0]\n",
      "True:  [1, 1, 1, 0, 0, 1, 1, 0, 0]\n",
      "Mislabeled sample: 21525770,23323252,\n",
      "Pred:  [1 1 1 1 0 0 1 0 0]\n",
      "True:  [1, 1, 1, 1, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0 0 1 1 0 1]\n",
      "True:  [0, 0, 1, 0, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: 15209628,\n",
      "Pred:  [0 0 0 1 1 0 0 0]\n",
      "True:  [0, 1, 1, 1, 1, 1, 0, 0]\n",
      "Mislabeled sample: 22093336,22381530,22133043,\n",
      "Pred:  [0 1 0 1 0 1 1 0]\n",
      "True:  [1, 1, 0, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: 22669208,16336441,\n",
      "Pred:  [0 1 0 0 0 1 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1 0 0 0]\n",
      "True:  [0, 0, 0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 0 1 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: 15107843,\n",
      "Pred:  [0 1 1 0 1 0 0 1]\n",
      "True:  [0, 1, 1, 1, 1, 0, 0, 0]\n",
      "Mislabeled sample: 21728030,21814595,\n",
      "Author:  jeong hwan kim1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.90      0.88        51\n",
      "          1       0.84      0.79      0.81        33\n",
      "\n",
      "avg / total       0.86      0.86      0.86        84\n",
      "\n",
      "[46  5  7 26]\n",
      "Accuracy:  0.8571428571428571\n",
      "F1:  0.8125\n",
      "Precision:  0.8387096774193549\n",
      "Recall:  0.7878787878787878\n",
      "jeremy m brown0\n",
      "14\n",
      "29\n",
      "Total negative sample size: 15\n",
      "15\n",
      "Positive sample size:  14\n",
      "Negative sample size:  15\n",
      "(14, 102)\n",
      "(15, 102)\n",
      "Total sample size and shape:  (29, 100)\n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0]\n",
      "True:  [1, 0]\n",
      "Mislabeled sample: 24562916,\n",
      "Author:  jeremy m brown0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        14\n",
      "          1       1.00      0.93      0.97        15\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[14  0  1 14]\n",
      "Accuracy:  0.9655172413793104\n",
      "F1:  0.9655172413793104\n",
      "Precision:  1.0\n",
      "Recall:  0.9333333333333333\n",
      "jeremy m brown1\n",
      "15\n",
      "29\n",
      "Total negative sample size: 14\n",
      "14\n",
      "Positive sample size:  15\n",
      "Negative sample size:  14\n",
      "(15, 102)\n",
      "(14, 102)\n",
      "Total sample size and shape:  (29, 100)\n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: 24562916,\n",
      "Pred:  [1 0]\n",
      "True:  [1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  jeremy m brown1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        15\n",
      "          1       0.93      1.00      0.97        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[14  1  0 14]\n",
      "Accuracy:  0.9655172413793104\n",
      "F1:  0.9655172413793104\n",
      "Precision:  0.9333333333333333\n",
      "Recall:  1.0\n",
      "jie zhang0\n",
      "11\n",
      "69\n",
      "Total negative sample size: 58\n",
      "58\n",
      "Positive sample size:  11\n",
      "Negative sample size:  58\n",
      "(11, 102)\n",
      "(58, 102)\n",
      "Total sample size and shape:  (69, 100)\n",
      "Pred:  [0 1 1 1 1 0 1]\n",
      "True:  [0, 1, 1, 1, 1, 0, 0]\n",
      "Mislabeled sample: 17377119,\n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: 26086502,\n",
      "Pred:  [1 0 1 0 1 1 1]\n",
      "True:  [1, 0, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: 21357616,\n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 26467333,\n",
      "Pred:  [0 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  jie zhang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.94      1.00      0.97        58\n",
      "\n",
      "avg / total       0.95      0.94      0.94        69\n",
      "\n",
      "[ 7  4  0 58]\n",
      "Accuracy:  0.9420289855072463\n",
      "F1:  0.9666666666666666\n",
      "Precision:  0.9354838709677419\n",
      "Recall:  1.0\n",
      "jie zhang1\n",
      "58\n",
      "69\n",
      "Total negative sample size: 11\n",
      "11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  58\n",
      "Negative sample size:  11\n",
      "(58, 102)\n",
      "(11, 102)\n",
      "Total sample size and shape:  (69, 100)\n",
      "Pred:  [0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 1, 0]\n",
      "Mislabeled sample: 21357616,17377119,\n",
      "Pred:  [0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 1 0]\n",
      "True:  [0, 0, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 0 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0, 1]\n",
      "Mislabeled sample: 26467333,26086502,\n",
      "Pred:  [0 0 0 1 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  jie zhang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        58\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.95      0.94      0.94        69\n",
      "\n",
      "[58  0  4  7]\n",
      "Accuracy:  0.9420289855072463\n",
      "F1:  0.7777777777777778\n",
      "Precision:  1.0\n",
      "Recall:  0.6363636363636364\n",
      "jin young kim0\n",
      "11\n",
      "52\n",
      "Total negative sample size: 41\n",
      "41\n",
      "Positive sample size:  11\n",
      "Negative sample size:  41\n",
      "(11, 102)\n",
      "(41, 102)\n",
      "Total sample size and shape:  (52, 100)\n",
      "Pred:  [1 1 1 0 0 1]\n",
      "True:  [1, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1]\n",
      "True:  [1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1]\n",
      "True:  [1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1]\n",
      "True:  [1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 1 1]\n",
      "True:  [1, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1]\n",
      "True:  [1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 0]\n",
      "True:  [1, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  jin young kim0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        41\n",
      "\n",
      "avg / total       1.00      1.00      1.00        52\n",
      "\n",
      "[11  0  0 41]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "jin young kim1\n",
      "41\n",
      "52\n",
      "Total negative sample size: 11\n",
      "11\n",
      "Positive sample size:  41\n",
      "Negative sample size:  11\n",
      "(41, 102)\n",
      "(11, 102)\n",
      "Total sample size and shape:  (52, 100)\n",
      "Pred:  [0 0 0 0 1 0]\n",
      "True:  [0, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 0]\n",
      "True:  [1, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: 12684031,\n",
      "Pred:  [0 0 1 1 0]\n",
      "True:  [0, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 1]\n",
      "True:  [0, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 0]\n",
      "True:  [0, 1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  jin young kim1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        41\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.98      0.98      0.98        52\n",
      "\n",
      "[41  0  1 10]\n",
      "Accuracy:  0.9807692307692307\n",
      "F1:  0.9523809523809523\n",
      "Precision:  1.0\n",
      "Recall:  0.9090909090909091\n",
      "john f marshall0\n",
      "11\n",
      "27\n",
      "Total negative sample size: 16\n",
      "16\n",
      "Positive sample size:  11\n",
      "Negative sample size:  16\n",
      "(11, 102)\n",
      "(16, 102)\n",
      "Total sample size and shape:  (27, 100)\n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 18052797,\n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1]\n",
      "True:  [1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1]\n",
      "True:  [1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1]\n",
      "True:  [1, 0]\n",
      "Mislabeled sample: 20838674,\n",
      "Author:  john f marshall0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        11\n",
      "          1       0.94      0.94      0.94        16\n",
      "\n",
      "avg / total       0.93      0.93      0.93        27\n",
      "\n",
      "[10  1  1 15]\n",
      "Accuracy:  0.9259259259259259\n",
      "F1:  0.9375\n",
      "Precision:  0.9375\n",
      "Recall:  0.9375\n",
      "john f marshall1\n",
      "16\n",
      "27\n",
      "Total negative sample size: 11\n",
      "11\n",
      "Positive sample size:  16\n",
      "Negative sample size:  11\n",
      "(16, 102)\n",
      "(11, 102)\n",
      "Total sample size and shape:  (27, 100)\n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: 20838674,\n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 18052797,\n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0]\n",
      "True:  [0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0]\n",
      "True:  [0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0]\n",
      "True:  [1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  john f marshall1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        16\n",
      "          1       0.91      0.91      0.91        11\n",
      "\n",
      "avg / total       0.93      0.93      0.93        27\n",
      "\n",
      "[15  1  1 10]\n",
      "Accuracy:  0.9259259259259259\n",
      "F1:  0.9090909090909091\n",
      "Precision:  0.9090909090909091\n",
      "Recall:  0.9090909090909091\n",
      "jong hee chang0\n",
      "15\n",
      "38\n",
      "Total negative sample size: 23\n",
      "23\n",
      "Positive sample size:  15\n",
      "Negative sample size:  23\n",
      "(15, 102)\n",
      "(23, 102)\n",
      "Total sample size and shape:  (38, 100)\n",
      "Pred:  [0 1 1 0]\n",
      "True:  [0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0]\n",
      "True:  [0, 0, 1, 1]\n",
      "Mislabeled sample: 25434952,\n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: 25892035,\n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1]\n",
      "True:  [0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: 23620866,\n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: 26605265,\n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  jong hee chang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.93      0.87        15\n",
      "          1       0.95      0.87      0.91        23\n",
      "\n",
      "avg / total       0.90      0.89      0.90        38\n",
      "\n",
      "[14  1  3 20]\n",
      "Accuracy:  0.8947368421052632\n",
      "F1:  0.909090909090909\n",
      "Precision:  0.9523809523809523\n",
      "Recall:  0.8695652173913043\n",
      "jong hee chang1\n",
      "23\n",
      "38\n",
      "Total negative sample size: 15\n",
      "15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  23\n",
      "Negative sample size:  15\n",
      "(23, 102)\n",
      "(15, 102)\n",
      "Total sample size and shape:  (38, 100)\n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 0, 0, 0]\n",
      "Mislabeled sample: 25892035,\n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1]\n",
      "True:  [0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 0, 1]\n",
      "Mislabeled sample: 23620866,\n",
      "Pred:  [1 1 0 0]\n",
      "True:  [1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0]\n",
      "True:  [0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: 25434952,\n",
      "Author:  jong hee chang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.91      0.93        23\n",
      "          1       0.88      0.93      0.90        15\n",
      "\n",
      "avg / total       0.92      0.92      0.92        38\n",
      "\n",
      "[21  2  1 14]\n",
      "Accuracy:  0.9210526315789473\n",
      "F1:  0.9032258064516129\n",
      "Precision:  0.875\n",
      "Recall:  0.9333333333333333\n",
      "jun chen0\n",
      "11\n",
      "36\n",
      "Total negative sample size: 25\n",
      "25\n",
      "Positive sample size:  11\n",
      "Negative sample size:  25\n",
      "(11, 102)\n",
      "(25, 102)\n",
      "Total sample size and shape:  (36, 100)\n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0]\n",
      "True:  [0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0]\n",
      "True:  [1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  jun chen0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        25\n",
      "\n",
      "avg / total       1.00      1.00      1.00        36\n",
      "\n",
      "[11  0  0 25]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "jun chen1\n",
      "12\n",
      "36\n",
      "Total negative sample size: 24\n",
      "24\n",
      "Positive sample size:  12\n",
      "Negative sample size:  24\n",
      "(12, 102)\n",
      "(24, 102)\n",
      "Total sample size and shape:  (36, 100)\n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1]\n",
      "True:  [0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1]\n",
      "True:  [0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1]\n",
      "True:  [1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: 19334768,\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  jun chen1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.96      1.00      0.98        24\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[11  1  0 24]\n",
      "Accuracy:  0.9722222222222222\n",
      "F1:  0.9795918367346939\n",
      "Precision:  0.96\n",
      "Recall:  1.0\n",
      "jun chen2\n",
      "13\n",
      "36\n",
      "Total negative sample size: 23\n",
      "23\n",
      "Positive sample size:  13\n",
      "Negative sample size:  23\n",
      "(13, 102)\n",
      "(23, 102)\n",
      "Total sample size and shape:  (36, 100)\n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1]\n",
      "True:  [0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: 19334768,\n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  jun chen2\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.96      0.98        23\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[13  0  1 22]\n",
      "Accuracy:  0.9722222222222222\n",
      "F1:  0.9777777777777777\n",
      "Precision:  1.0\n",
      "Recall:  0.9565217391304348\n",
      "jun zhang0\n",
      "14\n",
      "38\n",
      "Total negative sample size: 24\n",
      "24\n",
      "Positive sample size:  14\n",
      "Negative sample size:  24\n",
      "(14, 102)\n",
      "(24, 102)\n",
      "Total sample size and shape:  (38, 100)\n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: 21899348,23563961,\n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: 20078068,25166416,\n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: 20715249,\n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: 23508233,\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: 22215006,\n",
      "Author:  jun zhang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.64      0.72        14\n",
      "          1       0.81      0.92      0.86        24\n",
      "\n",
      "avg / total       0.82      0.82      0.81        38\n",
      "\n",
      "[ 9  5  2 22]\n",
      "Accuracy:  0.8157894736842105\n",
      "F1:  0.8627450980392156\n",
      "Precision:  0.8148148148148148\n",
      "Recall:  0.9166666666666666\n",
      "jun zhang1\n",
      "24\n",
      "38\n",
      "Total negative sample size: 14\n",
      "14\n",
      "Positive sample size:  24\n",
      "Negative sample size:  14\n",
      "(24, 102)\n",
      "(14, 102)\n",
      "Total sample size and shape:  (38, 100)\n",
      "Pred:  [0 1 1 0]\n",
      "True:  [0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0]\n",
      "True:  [0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: 23508233,\n",
      "Pred:  [0 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: 18972482,\n",
      "Pred:  [0 0 1 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: 25166416,23184414,\n",
      "Pred:  [0 0 0 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: 22839450,\n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 22215006,\n",
      "Author:  jun zhang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88        24\n",
      "          1       0.79      0.79      0.79        14\n",
      "\n",
      "avg / total       0.84      0.84      0.84        38\n",
      "\n",
      "[21  3  3 11]\n",
      "Accuracy:  0.8421052631578947\n",
      "F1:  0.7857142857142857\n",
      "Precision:  0.7857142857142857\n",
      "Recall:  0.7857142857142857\n",
      "kevin m. ryan0\n",
      "36\n",
      "115\n",
      "Total negative sample size: 79\n",
      "79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  36\n",
      "Negative sample size:  79\n",
      "(36, 102)\n",
      "(79, 102)\n",
      "Total sample size and shape:  (115, 100)\n",
      "Pred:  [1 0 0 1 1 0 1 1 0 0 1 1]\n",
      "True:  [1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 1 0 1 0 1 1 1 1]\n",
      "True:  [0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: 23780738,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 0 0 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 1 1 1 0 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 0 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1 1 1 0 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0 1 1 0 0 1 1]\n",
      "True:  [1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 1 1 1 1 0 1 1]\n",
      "True:  [0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 1 1 0 1 1 1 1]\n",
      "True:  [0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 1 0 0 0 1 1 1 0]\n",
      "True:  [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  kevin m. ryan0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        36\n",
      "          1       0.99      1.00      0.99        79\n",
      "\n",
      "avg / total       0.99      0.99      0.99       115\n",
      "\n",
      "[35  1  0 79]\n",
      "Accuracy:  0.991304347826087\n",
      "F1:  0.9937106918238994\n",
      "Precision:  0.9875\n",
      "Recall:  1.0\n",
      "kevin m. ryan1\n",
      "79\n",
      "115\n",
      "Total negative sample size: 36\n",
      "36\n",
      "Positive sample size:  79\n",
      "Negative sample size:  36\n",
      "(79, 102)\n",
      "(36, 102)\n",
      "Total sample size and shape:  (115, 100)\n",
      "Pred:  [0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 0 1 1 1 1 0 1]\n",
      "True:  [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 0 0 1 0 0 0 0 0]\n",
      "True:  [0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 0 0 0 1 1 0 0 1]\n",
      "True:  [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 0 1 0 0 0 0 0 0]\n",
      "True:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 0 0 1 1 0 1]\n",
      "True:  [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1 0 1 1 0 0 1 0]\n",
      "True:  [0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 1 0 0 0 1 0]\n",
      "True:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 1 0 0 0 0 1]\n",
      "True:  [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: 23780738,\n",
      "Author:  kevin m. ryan1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99        79\n",
      "          1       1.00      0.97      0.99        36\n",
      "\n",
      "avg / total       0.99      0.99      0.99       115\n",
      "\n",
      "[79  0  1 35]\n",
      "Accuracy:  0.991304347826087\n",
      "F1:  0.9859154929577464\n",
      "Precision:  1.0\n",
      "Recall:  0.9722222222222222\n",
      "kyung su kim0\n",
      "14\n",
      "69\n",
      "Total negative sample size: 55\n",
      "55\n",
      "Positive sample size:  14\n",
      "Negative sample size:  55\n",
      "(14, 102)\n",
      "(55, 102)\n",
      "Total sample size and shape:  (69, 100)\n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: 21722666,20975550,18660392,\n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [0, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: 20825813,23528677,\n",
      "Pred:  [0 1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 0]\n",
      "Mislabeled sample: 22463971,19097734,19996791,\n",
      "Pred:  [1 1 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 18722743,\n",
      "Pred:  [1 0 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 21218029,\n",
      "Pred:  [0 1 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 20825912,\n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: 22924652,21982990,\n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 22101201,\n",
      "Author:  kyung su kim0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.14      0.22        14\n",
      "          1       0.82      0.96      0.88        55\n",
      "\n",
      "avg / total       0.75      0.80      0.75        69\n",
      "\n",
      "[ 2 12  2 53]\n",
      "Accuracy:  0.7971014492753623\n",
      "F1:  0.8833333333333333\n",
      "Precision:  0.8153846153846154\n",
      "Recall:  0.9636363636363636\n",
      "kyung su kim1\n",
      "55\n",
      "69\n",
      "Total negative sample size: 14\n",
      "14\n",
      "Positive sample size:  55\n",
      "Negative sample size:  14\n",
      "(55, 102)\n",
      "(14, 102)\n",
      "Total sample size and shape:  (69, 100)\n",
      "Pred:  [0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: 20825912,\n",
      "Pred:  [0 0 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 1, 0, 1, 0]\n",
      "Mislabeled sample: 23528677,19825222,19996791,\n",
      "Pred:  [0 0 0 0 0 1 0]\n",
      "True:  [0, 1, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: 22101201,\n",
      "Pred:  [0 0 0 0 0 0 1]\n",
      "True:  [1, 0, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: 22924652,19097734,18996670,\n",
      "Pred:  [0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 0, 1]\n",
      "Mislabeled sample: 18660392,21982990,\n",
      "Pred:  [0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: 21722666,\n",
      "Pred:  [0 0 0 0 1 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: 22463971,\n",
      "Pred:  [1 0 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: 20825813,\n",
      "Pred:  [0 0 0 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: 21218029,\n",
      "Author:  kyung su kim1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.96      0.88        55\n",
      "          1       0.50      0.14      0.22        14\n",
      "\n",
      "avg / total       0.75      0.80      0.75        69\n",
      "\n",
      "[53  2 12  2]\n",
      "Accuracy:  0.7971014492753623\n",
      "F1:  0.22222222222222224\n",
      "Precision:  0.5\n",
      "Recall:  0.14285714285714285\n",
      "lei wang0\n",
      "16\n",
      "150\n",
      "Total negative sample size: 134\n",
      "134\n",
      "Positive sample size:  16\n",
      "Negative sample size:  134\n",
      "(16, 102)\n",
      "(134, 102)\n",
      "Total sample size and shape:  (150, 100)\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 19810450,\n",
      "Pred:  [1 1 1 1 1 0 1 0 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 1 1 1 1 0 1 1 0 1 1 1]\n",
      "True:  [0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 19329495,\n",
      "Pred:  [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 22023607,17927539,22751827,\n",
      "Pred:  [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  lei wang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.75      0.83        16\n",
      "          1       0.97      0.99      0.98       134\n",
      "\n",
      "avg / total       0.97      0.97      0.97       150\n",
      "\n",
      "[ 12   4   1 133]\n",
      "Accuracy:  0.9666666666666667\n",
      "F1:  0.981549815498155\n",
      "Precision:  0.9708029197080292\n",
      "Recall:  0.9925373134328358\n",
      "lei wang1\n",
      "17\n",
      "150\n",
      "Total negative sample size: 133\n",
      "133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  17\n",
      "Negative sample size:  133\n",
      "(17, 102)\n",
      "(133, 102)\n",
      "Total sample size and shape:  (150, 100)\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 0 0 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1 1 1 1 1 1 1 0 0 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1 1 1 1 1 1 0 1 0 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1]\n",
      "Mislabeled sample: 23005662,24933687,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 0 1 0 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 19908274,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  lei wang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        17\n",
      "          1       0.98      1.00      0.99       133\n",
      "\n",
      "avg / total       0.98      0.98      0.98       150\n",
      "\n",
      "[ 14   3   0 133]\n",
      "Accuracy:  0.98\n",
      "F1:  0.9888475836431226\n",
      "Precision:  0.9779411764705882\n",
      "Recall:  1.0\n",
      "lei wang2\n",
      "53\n",
      "150\n",
      "Total negative sample size: 97\n",
      "97\n",
      "Positive sample size:  53\n",
      "Negative sample size:  97\n",
      "(53, 102)\n",
      "(97, 102)\n",
      "Total sample size and shape:  (150, 100)\n",
      "Pred:  [0 0 0 0 1 0 0 1 1 0 1 1 1 1 0]\n",
      "True:  [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 1 1 0 0 1 1 1 0 1 0 1]\n",
      "True:  [0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 1 0 0 1 1 1 0 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0 1 0 0 0 1 1 1 1 0 1]\n",
      "True:  [1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 1 1 0 1 0 1 0 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: 21751313,\n",
      "Pred:  [0 0 0 1 0 1 1 1 1 1 1 0 0 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 0 1 0 0 0 1 0 1 0 1 0]\n",
      "True:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0]\n",
      "Mislabeled sample: 19908274,\n",
      "Pred:  [1 1 1 1 1 0 1 0 1 0 1 0 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 0 1 1 0 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 0 1 1 1 1 0 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  lei wang2\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98        53\n",
      "          1       0.99      0.99      0.99        97\n",
      "\n",
      "avg / total       0.99      0.99      0.99       150\n",
      "\n",
      "[52  1  1 96]\n",
      "Accuracy:  0.9866666666666667\n",
      "F1:  0.9896907216494846\n",
      "Precision:  0.9896907216494846\n",
      "Recall:  0.9896907216494846\n",
      "lei wang3\n",
      "64\n",
      "150\n",
      "Total negative sample size: 86\n",
      "86\n",
      "Positive sample size:  64\n",
      "Negative sample size:  86\n",
      "(64, 102)\n",
      "(86, 102)\n",
      "Total sample size and shape:  (150, 100)\n",
      "Pred:  [1 1 1 0 1 0 0 1 0 0 0 0 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 1 1 0 0 1 1 1 1 1 1 0]\n",
      "True:  [0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 0 1 1 0 0 0 1 0 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 0 0 0 1 0 1 1 0 1 0]\n",
      "True:  [1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 1 0 1 0 0 1 1 1 0 1 1]\n",
      "True:  [0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 0 1 0 0 1 1 1 0 0 0 1]\n",
      "True:  [0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1 0 1 1 1 1 0 1 0 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: 22751827,\n",
      "Pred:  [1 1 1 1 1 0 0 1 0 1 1 1 0 0 0]\n",
      "True:  [0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0]\n",
      "Mislabeled sample: 22362200,\n",
      "Pred:  [1 0 1 1 0 0 0 1 0 0 1 1 0 0 1]\n",
      "True:  [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 0 1 1 1 1 0 0 1 1 0]\n",
      "True:  [1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  lei wang3\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        64\n",
      "          1       0.98      1.00      0.99        86\n",
      "\n",
      "avg / total       0.99      0.99      0.99       150\n",
      "\n",
      "[62  2  0 86]\n",
      "Accuracy:  0.9866666666666667\n",
      "F1:  0.9885057471264368\n",
      "Precision:  0.9772727272727273\n",
      "Recall:  1.0\n",
      "lin yang0\n",
      "11\n",
      "34\n",
      "Total negative sample size: 23\n",
      "23\n",
      "Positive sample size:  11\n",
      "Negative sample size:  23\n",
      "(11, 102)\n",
      "(23, 102)\n",
      "Total sample size and shape:  (34, 100)\n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: 15470263,\n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  lin yang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        11\n",
      "          1       1.00      0.96      0.98        23\n",
      "\n",
      "avg / total       0.97      0.97      0.97        34\n",
      "\n",
      "[11  0  1 22]\n",
      "Accuracy:  0.9705882352941176\n",
      "F1:  0.9777777777777777\n",
      "Precision:  1.0\n",
      "Recall:  0.9565217391304348\n",
      "lin yang1\n",
      "23\n",
      "34\n",
      "Total negative sample size: 11\n",
      "11\n",
      "Positive sample size:  23\n",
      "Negative sample size:  11\n",
      "(23, 102)\n",
      "(11, 102)\n",
      "Total sample size and shape:  (34, 100)\n",
      "Pred:  [0 0 0 0]\n",
      "True:  [0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1]\n",
      "True:  [0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 1]\n",
      "Mislabeled sample: 21080928,\n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: 15470263,\n",
      "Author:  lin yang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        23\n",
      "          1       0.91      0.91      0.91        11\n",
      "\n",
      "avg / total       0.94      0.94      0.94        34\n",
      "\n",
      "[22  1  1 10]\n",
      "Accuracy:  0.9411764705882353\n",
      "F1:  0.9090909090909091\n",
      "Precision:  0.9090909090909091\n",
      "Recall:  0.9090909090909091\n",
      "lus alves0\n",
      "11\n",
      "25\n",
      "Total negative sample size: 14\n",
      "14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  11\n",
      "Negative sample size:  14\n",
      "(11, 102)\n",
      "(14, 102)\n",
      "Total sample size and shape:  (25, 100)\n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0]\n",
      "True:  [1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0]\n",
      "True:  [0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0]\n",
      "True:  [1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0]\n",
      "True:  [1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  lus alves0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        25\n",
      "\n",
      "[11  0  0 14]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "lus alves1\n",
      "14\n",
      "25\n",
      "Total negative sample size: 11\n",
      "11\n",
      "Positive sample size:  14\n",
      "Negative sample size:  11\n",
      "(14, 102)\n",
      "(11, 102)\n",
      "Total sample size and shape:  (25, 100)\n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0]\n",
      "True:  [0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0]\n",
      "True:  [0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0]\n",
      "True:  [1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  lus alves1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        25\n",
      "\n",
      "[14  0  0 11]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "marco ferrari0\n",
      "22\n",
      "96\n",
      "Total negative sample size: 74\n",
      "74\n",
      "Positive sample size:  22\n",
      "Negative sample size:  74\n",
      "(22, 102)\n",
      "(74, 102)\n",
      "Total sample size and shape:  (96, 100)\n",
      "Pred:  [1 1 1 1 1 0 1 1 0 1]\n",
      "True:  [1, 1, 1, 0, 1, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: 12639714,\n",
      "Pred:  [1 0 1 0 1 1 0 1 0 1]\n",
      "True:  [1, 0, 1, 0, 1, 0, 0, 1, 0, 1]\n",
      "Mislabeled sample: 22901441,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 25300812,\n",
      "Pred:  [1 0 1 0 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 0 1 1 1 1]\n",
      "True:  [1, 0, 0, 1, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: 15219975,\n",
      "Pred:  [1 1 1 0 1 1 1 1 0 1]\n",
      "True:  [1, 1, 0, 0, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 14596880,\n",
      "Pred:  [0 1 1 1 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 17106203,\n",
      "Pred:  [1 1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 0 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 21481946,\n",
      "Author:  marco ferrari0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        22\n",
      "          1       0.91      1.00      0.95        74\n",
      "\n",
      "avg / total       0.93      0.93      0.92        96\n",
      "\n",
      "[15  7  0 74]\n",
      "Accuracy:  0.9270833333333334\n",
      "F1:  0.9548387096774192\n",
      "Precision:  0.9135802469135802\n",
      "Recall:  1.0\n",
      "marco ferrari1\n",
      "74\n",
      "96\n",
      "Total negative sample size: 22\n",
      "22\n",
      "Positive sample size:  74\n",
      "Negative sample size:  22\n",
      "(74, 102)\n",
      "(22, 102)\n",
      "Total sample size and shape:  (96, 100)\n",
      "Pred:  [0 0 0 0 0 0 0 1 0 1]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: 17106203,\n",
      "Pred:  [1 0 1 0 0 0 0 0 0 0]\n",
      "True:  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 1 1]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 1 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: 15228623,12639714,\n",
      "Pred:  [0 0 0 0 0 1 0 1 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 25300812,14596880,\n",
      "Pred:  [0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: 15219975,\n",
      "Pred:  [1 0 0 0 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 0 0 0 0 0]\n",
      "True:  [0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 0 1 0 0]\n",
      "True:  [1, 0, 0, 1, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: 21481946,\n",
      "Author:  marco ferrari1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        74\n",
      "          1       1.00      0.68      0.81        22\n",
      "\n",
      "avg / total       0.93      0.93      0.92        96\n",
      "\n",
      "[74  0  7 15]\n",
      "Accuracy:  0.9270833333333334\n",
      "F1:  0.8108108108108109\n",
      "Precision:  1.0\n",
      "Recall:  0.6818181818181818\n",
      "marta crespo0\n",
      "12\n",
      "32\n",
      "Total negative sample size: 20\n",
      "20\n",
      "Positive sample size:  12\n",
      "Negative sample size:  20\n",
      "(12, 102)\n",
      "(20, 102)\n",
      "Total sample size and shape:  (32, 100)\n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0]\n",
      "True:  [0, 1, 1, 0]\n",
      "Mislabeled sample: 22709602,\n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: 12773332,\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Author:  marta crespo0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        12\n",
      "          1       0.95      0.95      0.95        20\n",
      "\n",
      "avg / total       0.94      0.94      0.94        32\n",
      "\n",
      "[11  1  1 19]\n",
      "Accuracy:  0.9375\n",
      "F1:  0.9500000000000001\n",
      "Precision:  0.95\n",
      "Recall:  0.95\n",
      "marta crespo1\n",
      "20\n",
      "32\n",
      "Total negative sample size: 12\n",
      "12\n",
      "Positive sample size:  20\n",
      "Negative sample size:  12\n",
      "(20, 102)\n",
      "(12, 102)\n",
      "Total sample size and shape:  (32, 100)\n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: 12773332,\n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 22709602,\n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Author:  marta crespo1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        20\n",
      "          1       0.92      0.92      0.92        12\n",
      "\n",
      "avg / total       0.94      0.94      0.94        32\n",
      "\n",
      "[19  1  1 11]\n",
      "Accuracy:  0.9375\n",
      "F1:  0.9166666666666666\n",
      "Precision:  0.9166666666666666\n",
      "Recall:  0.9166666666666666\n",
      "martin wagner0\n",
      "15\n",
      "30\n",
      "Total negative sample size: 15\n",
      "15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  15\n",
      "Negative sample size:  15\n",
      "(15, 102)\n",
      "(15, 102)\n",
      "Total sample size and shape:  (30, 100)\n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 24042927,\n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: 25384705,\n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: 19836499,\n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: 27017846,\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  martin wagner0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.87      0.87        15\n",
      "          1       0.87      0.87      0.87        15\n",
      "\n",
      "avg / total       0.87      0.87      0.87        30\n",
      "\n",
      "[13  2  2 13]\n",
      "Accuracy:  0.8666666666666667\n",
      "F1:  0.8666666666666667\n",
      "Precision:  0.8666666666666667\n",
      "Recall:  0.8666666666666667\n",
      "martin wagner1\n",
      "15\n",
      "30\n",
      "Total negative sample size: 15\n",
      "15\n",
      "Positive sample size:  15\n",
      "Negative sample size:  15\n",
      "(15, 102)\n",
      "(15, 102)\n",
      "Total sample size and shape:  (30, 100)\n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: 19836499,\n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 23625661,25384705,\n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 27017846,\n",
      "Pred:  [0 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: 24042927,\n",
      "Author:  martin wagner1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.80      0.83        15\n",
      "          1       0.81      0.87      0.84        15\n",
      "\n",
      "avg / total       0.83      0.83      0.83        30\n",
      "\n",
      "[12  3  2 13]\n",
      "Accuracy:  0.8333333333333334\n",
      "F1:  0.8387096774193549\n",
      "Precision:  0.8125\n",
      "Recall:  0.8666666666666667\n",
      "michael wagner0\n",
      "16\n",
      "255\n",
      "Total negative sample size: 239\n",
      "239\n",
      "Positive sample size:  16\n",
      "Negative sample size:  239\n",
      "(16, 102)\n",
      "(239, 102)\n",
      "Total sample size and shape:  (255, 100)\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 24450576,20722033,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 11913376,12973727,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 25493568,18333798,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 26330430,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0]\n",
      "True:  [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 22354554,20459663,24575121,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 17081057,\n",
      "Author:  michael wagner0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.48        16\n",
      "          1       0.96      1.00      0.98       239\n",
      "\n",
      "avg / total       0.96      0.96      0.95       255\n",
      "\n",
      "[  5  11   0 239]\n",
      "Accuracy:  0.9568627450980393\n",
      "F1:  0.9775051124744376\n",
      "Precision:  0.956\n",
      "Recall:  1.0\n",
      "michael wagner1\n",
      "98\n",
      "255\n",
      "Total negative sample size: 157\n",
      "157\n",
      "Positive sample size:  98\n",
      "Negative sample size:  157\n",
      "(98, 102)\n",
      "(157, 102)\n",
      "Total sample size and shape:  (255, 100)\n",
      "Pred:  [1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "Mislabeled sample: 24348519,25493568,20722033,\n",
      "Pred:  [1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 26372590,\n",
      "Pred:  [1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 0 0]\n",
      "True:  [1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1]\n",
      "True:  [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1]\n",
      "True:  [0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 26330430,24338591,22889924,\n",
      "Pred:  [1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0]\n",
      "True:  [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0]\n",
      "Mislabeled sample: 15811989,\n",
      "Pred:  [1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0]\n",
      "True:  [1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: 24089318,22354554,24138519,\n",
      "Pred:  [1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 0]\n",
      "True:  [1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
      "Mislabeled sample: 25042114,23564357,\n",
      "Author:  michael wagner1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.93      0.93        98\n",
      "          1       0.96      0.96      0.96       157\n",
      "\n",
      "avg / total       0.95      0.95      0.95       255\n",
      "\n",
      "[ 91   7   6 151]\n",
      "Accuracy:  0.9490196078431372\n",
      "F1:  0.9587301587301587\n",
      "Precision:  0.9556962025316456\n",
      "Recall:  0.9617834394904459\n",
      "michael wagner2\n",
      "141\n",
      "255\n",
      "Total negative sample size: 114\n",
      "114\n",
      "Positive sample size:  141\n",
      "Negative sample size:  114\n",
      "(141, 102)\n",
      "(114, 102)\n",
      "Total sample size and shape:  (255, 100)\n",
      "Pred:  [1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1]\n",
      "True:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 24975266,11827344,\n",
      "Pred:  [1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 1 0 1 1 0]\n",
      "True:  [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1]\n",
      "True:  [1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: 24138519,26372590,\n",
      "Pred:  [1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1]\n",
      "True:  [1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 1]\n",
      "True:  [0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: 16572761,24338591,\n",
      "Pred:  [0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1]\n",
      "True:  [0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: 15811989,\n",
      "Pred:  [1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 0]\n",
      "True:  [1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1]\n",
      "Mislabeled sample: 18333798,24450576,\n",
      "Pred:  [1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0]\n",
      "True:  [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0]\n",
      "True:  [0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: 21890669,\n",
      "Author:  michael wagner2\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96       141\n",
      "          1       0.96      0.96      0.96       114\n",
      "\n",
      "avg / total       0.96      0.96      0.96       255\n",
      "\n",
      "[136   5   5 109]\n",
      "Accuracy:  0.9607843137254902\n",
      "F1:  0.956140350877193\n",
      "Precision:  0.956140350877193\n",
      "Recall:  0.956140350877193\n",
      "mikael svensson0\n",
      "18\n",
      "58\n",
      "Total negative sample size: 40\n",
      "40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  18\n",
      "Negative sample size:  40\n",
      "(18, 102)\n",
      "(40, 102)\n",
      "Total sample size and shape:  (58, 100)\n",
      "Pred:  [0 0 1 0 1 0]\n",
      "True:  [0, 0, 1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 0]\n",
      "True:  [1, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 0]\n",
      "True:  [1, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1]\n",
      "True:  [1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1 0 1]\n",
      "True:  [0, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 0 1]\n",
      "True:  [1, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 0]\n",
      "True:  [1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  mikael svensson0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       1.00      1.00      1.00        40\n",
      "\n",
      "avg / total       1.00      1.00      1.00        58\n",
      "\n",
      "[18  0  0 40]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "mikael svensson1\n",
      "40\n",
      "58\n",
      "Total negative sample size: 18\n",
      "18\n",
      "Positive sample size:  40\n",
      "Negative sample size:  18\n",
      "(40, 102)\n",
      "(18, 102)\n",
      "Total sample size and shape:  (58, 100)\n",
      "Pred:  [0 0 0 0 1 0]\n",
      "True:  [0, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1]\n",
      "True:  [1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 0]\n",
      "True:  [1, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0 0]\n",
      "True:  [1, 1, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 0 1]\n",
      "True:  [0, 0, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0 0 1]\n",
      "True:  [1, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0 0 0]\n",
      "True:  [1, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 0]\n",
      "True:  [1, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  mikael svensson1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        40\n",
      "          1       1.00      1.00      1.00        18\n",
      "\n",
      "avg / total       1.00      1.00      1.00        58\n",
      "\n",
      "[40  0  0 18]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "pei-ming yang0\n",
      "17\n",
      "63\n",
      "Total negative sample size: 46\n",
      "46\n",
      "Positive sample size:  17\n",
      "Negative sample size:  46\n",
      "(17, 102)\n",
      "(46, 102)\n",
      "Total sample size and shape:  (63, 100)\n",
      "Pred:  [1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 0 1]\n",
      "True:  [1, 1, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 0 1 0]\n",
      "True:  [1, 0, 1, 1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 1 1 1]\n",
      "True:  [1, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 1]\n",
      "True:  [0, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: 20962572,\n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 1 1 0]\n",
      "True:  [1, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 0, 0, 1]\n",
      "Mislabeled sample: 24340011,\n",
      "Pred:  [1 0 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  pei-ming yang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        17\n",
      "          1       0.96      1.00      0.98        46\n",
      "\n",
      "avg / total       0.97      0.97      0.97        63\n",
      "\n",
      "[15  2  0 46]\n",
      "Accuracy:  0.9682539682539683\n",
      "F1:  0.9787234042553191\n",
      "Precision:  0.9583333333333334\n",
      "Recall:  1.0\n",
      "pei-ming yang1\n",
      "46\n",
      "63\n",
      "Total negative sample size: 17\n",
      "17\n",
      "Positive sample size:  46\n",
      "Negative sample size:  17\n",
      "(46, 102)\n",
      "(17, 102)\n",
      "Total sample size and shape:  (63, 100)\n",
      "Pred:  [0 0 1 0 0 0 1]\n",
      "True:  [1, 0, 1, 0, 0, 0, 1]\n",
      "Mislabeled sample: 20962572,\n",
      "Pred:  [0 0 1 0 1 0 0]\n",
      "True:  [0, 0, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1 1 0 0]\n",
      "True:  [0, 1, 0, 1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 0 0]\n",
      "True:  [0, 1, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 1 0]\n",
      "True:  [0, 0, 1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 0 0]\n",
      "True:  [1, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: 24340011,\n",
      "Author:  pei-ming yang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        46\n",
      "          1       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.97      0.97      0.97        63\n",
      "\n",
      "[46  0  2 15]\n",
      "Accuracy:  0.9682539682539683\n",
      "F1:  0.9375\n",
      "Precision:  1.0\n",
      "Recall:  0.8823529411764706\n",
      "peng zhang0\n",
      "16\n",
      "78\n",
      "Total negative sample size: 62\n",
      "62\n",
      "Positive sample size:  16\n",
      "Negative sample size:  62\n",
      "(16, 102)\n",
      "(62, 102)\n",
      "Total sample size and shape:  (78, 100)\n",
      "Pred:  [1 0 1 1 0 0 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 21034809,\n",
      "Pred:  [1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: 20096454,22341214,\n",
      "Pred:  [1 0 0 1 1 1 1 1]\n",
      "True:  [1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 27622986,\n",
      "Pred:  [1 1 1 1 1 1 1 1]\n",
      "True:  [0, 1, 0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 22983358,27063489,26071692,\n",
      "Pred:  [0 1 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 27063423,\n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: 22356743,22763501,\n",
      "Author:  peng zhang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.44      0.58        16\n",
      "          1       0.87      0.98      0.92        62\n",
      "\n",
      "avg / total       0.87      0.87      0.85        78\n",
      "\n",
      "[ 7  9  1 61]\n",
      "Accuracy:  0.8717948717948718\n",
      "F1:  0.9242424242424242\n",
      "Precision:  0.8714285714285714\n",
      "Recall:  0.9838709677419355\n",
      "peng zhang1\n",
      "17\n",
      "78\n",
      "Total negative sample size: 61\n",
      "61\n",
      "Positive sample size:  17\n",
      "Negative sample size:  61\n",
      "(17, 102)\n",
      "(61, 102)\n",
      "Total sample size and shape:  (78, 100)\n",
      "Pred:  [1 1 1 1 1 1 1 0]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 25463714,\n",
      "Pred:  [1 1 1 0 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: 23027545,\n",
      "Pred:  [1 1 1 1 0 1 0 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 1 1 1]\n",
      "True:  [0, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 21034809,\n",
      "Pred:  [1 1 1 1 0 0 1 0]\n",
      "True:  [1, 1, 1, 1, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 1 1 1]\n",
      "True:  [0, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: 25515687,\n",
      "Pred:  [0 1 1 0 1 1 1]\n",
      "True:  [0, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  peng zhang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.87        17\n",
      "          1       0.94      1.00      0.97        61\n",
      "\n",
      "avg / total       0.95      0.95      0.95        78\n",
      "\n",
      "[13  4  0 61]\n",
      "Accuracy:  0.9487179487179487\n",
      "F1:  0.9682539682539683\n",
      "Precision:  0.9384615384615385\n",
      "Recall:  1.0\n",
      "peng zhang2\n",
      "20\n",
      "78\n",
      "Total negative sample size: 58\n",
      "58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  20\n",
      "Negative sample size:  58\n",
      "(20, 102)\n",
      "(58, 102)\n",
      "Total sample size and shape:  (78, 100)\n",
      "Pred:  [1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 25641771,26091246,\n",
      "Pred:  [1 1 0 0 1 1 1 1]\n",
      "True:  [0, 1, 0, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: 23598799,11535102,26649814,23223190,\n",
      "Pred:  [1 0 1 0 1 0 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 0]\n",
      "Mislabeled sample: 15969183,20096454,23824999,\n",
      "Pred:  [1 1 0 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 24740883,\n",
      "Pred:  [1 1 1 1 1 0 1 1]\n",
      "True:  [1, 0, 0, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: 23400298,22627393,22320198,27174982,\n",
      "Pred:  [1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 1 1 1 1]\n",
      "True:  [1, 0, 0, 0, 1, 1, 1, 0]\n",
      "Mislabeled sample: 25113466,27011264,\n",
      "Pred:  [1 1 0 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 26602295,\n",
      "Pred:  [1 0 1 1 1 0 1]\n",
      "True:  [1, 0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  peng zhang2\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.40      0.48        20\n",
      "          1       0.82      0.91      0.86        58\n",
      "\n",
      "avg / total       0.76      0.78      0.77        78\n",
      "\n",
      "[ 8 12  5 53]\n",
      "Accuracy:  0.782051282051282\n",
      "F1:  0.8617886178861788\n",
      "Precision:  0.8153846153846154\n",
      "Recall:  0.9137931034482759\n",
      "peng zhang3\n",
      "25\n",
      "78\n",
      "Total negative sample size: 53\n",
      "53\n",
      "Positive sample size:  25\n",
      "Negative sample size:  53\n",
      "(25, 102)\n",
      "(53, 102)\n",
      "Total sample size and shape:  (78, 100)\n",
      "Pred:  [1 0 1 1 0 0 0 1]\n",
      "True:  [0, 0, 1, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: 22573020,25511500,\n",
      "Pred:  [1 1 0 1 1 1 0 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1 1 0]\n",
      "True:  [1, 1, 1, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: 26602295,11535102,\n",
      "Pred:  [1 1 1 1 1 1 0 0]\n",
      "True:  [1, 1, 1, 1, 1, 0, 0, 0]\n",
      "Mislabeled sample: 24786074,\n",
      "Pred:  [0 1 1 1 0 1 1 1]\n",
      "True:  [0, 1, 1, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: 20540100,\n",
      "Pred:  [1 1 0 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: 27174982,\n",
      "Pred:  [1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 0 0 1 0]\n",
      "True:  [1, 1, 0, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 26091246,23824999,24740883,\n",
      "Pred:  [0 1 1 1 0 1 1]\n",
      "True:  [0, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  peng zhang3\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.72      0.78        25\n",
      "          1       0.88      0.94      0.91        53\n",
      "\n",
      "avg / total       0.87      0.87      0.87        78\n",
      "\n",
      "[18  7  3 50]\n",
      "Accuracy:  0.8717948717948718\n",
      "F1:  0.9090909090909091\n",
      "Precision:  0.8771929824561403\n",
      "Recall:  0.9433962264150944\n",
      "qian wang0\n",
      "12\n",
      "27\n",
      "Total negative sample size: 15\n",
      "15\n",
      "Positive sample size:  12\n",
      "Negative sample size:  15\n",
      "(12, 102)\n",
      "(15, 102)\n",
      "Total sample size and shape:  (27, 100)\n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: 21899569,\n",
      "Pred:  [0 1]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1]\n",
      "True:  [1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: \n",
      "Author:  qian wang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.97      0.96      0.96        27\n",
      "\n",
      "[11  1  0 15]\n",
      "Accuracy:  0.9629629629629629\n",
      "F1:  0.967741935483871\n",
      "Precision:  0.9375\n",
      "Recall:  1.0\n",
      "qian wang1\n",
      "15\n",
      "27\n",
      "Total negative sample size: 12\n",
      "12\n",
      "Positive sample size:  15\n",
      "Negative sample size:  12\n",
      "(15, 102)\n",
      "(12, 102)\n",
      "Total sample size and shape:  (27, 100)\n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: 21899569,\n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0]\n",
      "True:  [1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1]\n",
      "True:  [0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0]\n",
      "True:  [0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  qian wang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        15\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.96      0.96        27\n",
      "\n",
      "[15  0  1 11]\n",
      "Accuracy:  0.9629629629629629\n",
      "F1:  0.9565217391304348\n",
      "Precision:  1.0\n",
      "Recall:  0.9166666666666666\n",
      "qiang wang0\n",
      "12\n",
      "43\n",
      "Total negative sample size: 31\n",
      "31\n",
      "Positive sample size:  12\n",
      "Negative sample size:  31\n",
      "(12, 102)\n",
      "(31, 102)\n",
      "Total sample size and shape:  (43, 100)\n",
      "Pred:  [0 1 1 1 1]\n",
      "True:  [0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1]\n",
      "True:  [0, 1, 1, 0, 0]\n",
      "Mislabeled sample: 25472809,25220502,24986329,\n",
      "Pred:  [0 1 1 0 1]\n",
      "True:  [0, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1]\n",
      "True:  [1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1]\n",
      "True:  [0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  qiang wang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       0.91      1.00      0.95        31\n",
      "\n",
      "avg / total       0.94      0.93      0.93        43\n",
      "\n",
      "[ 9  3  0 31]\n",
      "Accuracy:  0.9302325581395349\n",
      "F1:  0.9538461538461539\n",
      "Precision:  0.9117647058823529\n",
      "Recall:  1.0\n",
      "qiang wang1\n",
      "31\n",
      "43\n",
      "Total negative sample size: 12\n",
      "12\n",
      "Positive sample size:  31\n",
      "Negative sample size:  12\n",
      "(31, 102)\n",
      "(12, 102)\n",
      "Total sample size and shape:  (43, 100)\n",
      "Pred:  [0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 1]\n",
      "True:  [0, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: 25472809,\n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: 25220502,\n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  qiang wang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        31\n",
      "          1       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.96      0.95      0.95        43\n",
      "\n",
      "[31  0  2 10]\n",
      "Accuracy:  0.9534883720930233\n",
      "F1:  0.9090909090909091\n",
      "Precision:  1.0\n",
      "Recall:  0.8333333333333334\n",
      "qin li0\n",
      "14\n",
      "34\n",
      "Total negative sample size: 20\n",
      "20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  14\n",
      "Negative sample size:  20\n",
      "(14, 102)\n",
      "(20, 102)\n",
      "Total sample size and shape:  (34, 100)\n",
      "Pred:  [1 1 1 0]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0]\n",
      "True:  [0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: 23775134,\n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: 24654958,\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  qin li0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.91      1.00      0.95        20\n",
      "\n",
      "avg / total       0.95      0.94      0.94        34\n",
      "\n",
      "[12  2  0 20]\n",
      "Accuracy:  0.9411764705882353\n",
      "F1:  0.9523809523809523\n",
      "Precision:  0.9090909090909091\n",
      "Recall:  1.0\n",
      "qin li1\n",
      "20\n",
      "34\n",
      "Total negative sample size: 14\n",
      "14\n",
      "Positive sample size:  20\n",
      "Negative sample size:  14\n",
      "(20, 102)\n",
      "(14, 102)\n",
      "Total sample size and shape:  (34, 100)\n",
      "Pred:  [0 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: 23775134,\n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1]\n",
      "True:  [1, 0, 1, 1]\n",
      "Mislabeled sample: 16930824,24654958,\n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  qin li1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        20\n",
      "          1       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.92      0.91      0.91        34\n",
      "\n",
      "[20  0  3 11]\n",
      "Accuracy:  0.9117647058823529\n",
      "F1:  0.88\n",
      "Precision:  1.0\n",
      "Recall:  0.7857142857142857\n",
      "richard w morris0\n",
      "21\n",
      "128\n",
      "Total negative sample size: 107\n",
      "107\n",
      "Positive sample size:  21\n",
      "Negative sample size:  107\n",
      "(21, 102)\n",
      "(107, 102)\n",
      "Total sample size and shape:  (128, 100)\n",
      "Pred:  [1 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0 1 1 0 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 1 0 1 1 1 1 0 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1 1 1 0 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 0 1 1 1 0 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 1 1 0 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 0 0 0 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1 0 1 1 1 1 1 1 1]\n",
      "True:  [0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  richard w morris0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        21\n",
      "          1       1.00      1.00      1.00       107\n",
      "\n",
      "avg / total       1.00      1.00      1.00       128\n",
      "\n",
      "[ 21   0   0 107]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "richard w morris1\n",
      "107\n",
      "128\n",
      "Total negative sample size: 21\n",
      "21\n",
      "Positive sample size:  107\n",
      "Negative sample size:  21\n",
      "(107, 102)\n",
      "(21, 102)\n",
      "Total sample size and shape:  (128, 100)\n",
      "Pred:  [0 0 1 0 0 0 0 1 1 0 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "True:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 0 0 1 0 1 0 1 0 1]\n",
      "True:  [0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 0 0 0 0 0 1 0 0 1]\n",
      "True:  [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  richard w morris1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       107\n",
      "          1       1.00      1.00      1.00        21\n",
      "\n",
      "avg / total       1.00      1.00      1.00       128\n",
      "\n",
      "[107   0   0  21]\n",
      "Accuracy:  1.0\n",
      "F1:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "robert j young0\n",
      "24\n",
      "62\n",
      "Total negative sample size: 38\n",
      "38\n",
      "Positive sample size:  24\n",
      "Negative sample size:  38\n",
      "(24, 102)\n",
      "(38, 102)\n",
      "Total sample size and shape:  (62, 100)\n",
      "Pred:  [1 1 0 0 1 1 1]\n",
      "True:  [1, 1, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1 0 1 1]\n",
      "True:  [0, 1, 0, 0, 0, 1, 1]\n",
      "Mislabeled sample: 730761,20473982,\n",
      "Pred:  [1 0 1 1 0 0]\n",
      "True:  [1, 0, 1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1 0 1]\n",
      "True:  [1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 22025460,\n",
      "Pred:  [0 0 0 1 1 1]\n",
      "True:  [0, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: 18504721,\n",
      "Pred:  [1 1 0 1 0 1]\n",
      "True:  [1, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1 1 1]\n",
      "True:  [0, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 0]\n",
      "True:  [1, 1, 0, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 1 1]\n",
      "True:  [0, 0, 0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  robert j young0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.88      0.91        24\n",
      "          1       0.93      0.97      0.95        38\n",
      "\n",
      "avg / total       0.94      0.94      0.93        62\n",
      "\n",
      "[21  3  1 37]\n",
      "Accuracy:  0.9354838709677419\n",
      "F1:  0.9487179487179489\n",
      "Precision:  0.925\n",
      "Recall:  0.9736842105263158\n",
      "robert j young1\n",
      "38\n",
      "62\n",
      "Total negative sample size: 24\n",
      "24\n",
      "Positive sample size:  38\n",
      "Negative sample size:  24\n",
      "(38, 102)\n",
      "(24, 102)\n",
      "Total sample size and shape:  (62, 100)\n",
      "Pred:  [0 1 0 0 1 0 1]\n",
      "True:  [0, 1, 0, 0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 0 0]\n",
      "True:  [0, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: 730761,\n",
      "Pred:  [1 0 0 0 1 0]\n",
      "True:  [1, 0, 0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 1 1]\n",
      "True:  [0, 0, 0, 0, 1, 1]\n",
      "Mislabeled sample: 22025460,21257937,\n",
      "Pred:  [0 1 0 0 0 0]\n",
      "True:  [0, 1, 0, 1, 0, 0]\n",
      "Mislabeled sample: 18504721,\n",
      "Pred:  [0 0 0 1 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 1]\n",
      "Mislabeled sample: 20473982,\n",
      "Pred:  [0 0 1 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 1 1]\n",
      "True:  [0, 0, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  robert j young1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.94        38\n",
      "          1       0.91      0.88      0.89        24\n",
      "\n",
      "avg / total       0.92      0.92      0.92        62\n",
      "\n",
      "[36  2  3 21]\n",
      "Accuracy:  0.9193548387096774\n",
      "F1:  0.8936170212765957\n",
      "Precision:  0.9130434782608695\n",
      "Recall:  0.875\n",
      "sebastian wolf0\n",
      "15\n",
      "117\n",
      "Total negative sample size: 102\n",
      "102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  15\n",
      "Negative sample size:  102\n",
      "(15, 102)\n",
      "(102, 102)\n",
      "Total sample size and shape:  (117, 100)\n",
      "Pred:  [1 1 1 1 1 1 0 1 1 1 0 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 0 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1 1 1 1 1 1 0 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 1 1 0 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 0 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1 1 1 1 0 1]\n",
      "True:  [1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 15528298,\n",
      "Pred:  [1 1 1 0 0 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  sebastian wolf0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        15\n",
      "          1       0.99      1.00      1.00       102\n",
      "\n",
      "avg / total       0.99      0.99      0.99       117\n",
      "\n",
      "[ 14   1   0 102]\n",
      "Accuracy:  0.9914529914529915\n",
      "F1:  0.9951219512195122\n",
      "Precision:  0.9902912621359223\n",
      "Recall:  1.0\n",
      "sebastian wolf1\n",
      "102\n",
      "117\n",
      "Total negative sample size: 15\n",
      "15\n",
      "Positive sample size:  102\n",
      "Negative sample size:  15\n",
      "(102, 102)\n",
      "(15, 102)\n",
      "Total sample size and shape:  (117, 100)\n",
      "Pred:  [0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0 0 0 0 0 0 0 0 1]\n",
      "True:  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 1 0 0 0 0 1 0 0]\n",
      "True:  [0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0]\n",
      "Mislabeled sample: 15528298,\n",
      "Pred:  [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 0 0 0 0 0 0 0]\n",
      "True:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 0 0 0 0 1 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Author:  sebastian wolf1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       102\n",
      "          1       1.00      0.93      0.97        15\n",
      "\n",
      "avg / total       0.99      0.99      0.99       117\n",
      "\n",
      "[102   0   1  14]\n",
      "Accuracy:  0.9914529914529915\n",
      "F1:  0.9655172413793104\n",
      "Precision:  1.0\n",
      "Recall:  0.9333333333333333\n",
      "vineet gupta0\n",
      "14\n",
      "36\n",
      "Total negative sample size: 22\n",
      "22\n",
      "Positive sample size:  14\n",
      "Negative sample size:  22\n",
      "(14, 102)\n",
      "(22, 102)\n",
      "Total sample size and shape:  (36, 100)\n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1]\n",
      "True:  [0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 1]\n",
      "True:  [0, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0]\n",
      "True:  [1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: 19067551,25530967,\n",
      "Author:  vineet gupta0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        14\n",
      "          1       0.95      0.95      0.95        22\n",
      "\n",
      "avg / total       0.94      0.94      0.94        36\n",
      "\n",
      "[13  1  1 21]\n",
      "Accuracy:  0.9444444444444444\n",
      "F1:  0.9545454545454546\n",
      "Precision:  0.9545454545454546\n",
      "Recall:  0.9545454545454546\n",
      "vineet gupta1\n",
      "22\n",
      "36\n",
      "Total negative sample size: 14\n",
      "14\n",
      "Positive sample size:  22\n",
      "Negative sample size:  14\n",
      "(22, 102)\n",
      "(14, 102)\n",
      "Total sample size and shape:  (36, 100)\n",
      "Pred:  [0 0 1 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 1]\n",
      "True:  [1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0]\n",
      "True:  [1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0]\n",
      "True:  [0, 1, 1, 0]\n",
      "Mislabeled sample: 17438069,\n",
      "Pred:  [0 1 1 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: 25530967,\n",
      "Pred:  [1 1 0 0]\n",
      "True:  [1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: 19067551,\n",
      "Author:  vineet gupta1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.95      0.93        22\n",
      "          1       0.92      0.86      0.89        14\n",
      "\n",
      "avg / total       0.92      0.92      0.92        36\n",
      "\n",
      "[21  1  2 12]\n",
      "Accuracy:  0.9166666666666666\n",
      "F1:  0.888888888888889\n",
      "Precision:  0.9230769230769231\n",
      "Recall:  0.8571428571428571\n",
      "vivek gupta0\n",
      "14\n",
      "40\n",
      "Total negative sample size: 26\n",
      "26\n",
      "Positive sample size:  14\n",
      "Negative sample size:  26\n",
      "(14, 102)\n",
      "(26, 102)\n",
      "Total sample size and shape:  (40, 100)\n",
      "Pred:  [0 1 0 1]\n",
      "True:  [0, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 1]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: 23873194,\n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0]\n",
      "True:  [1, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 1, 0]\n",
      "Mislabeled sample: 21245586,\n",
      "Pred:  [1 0 0 1]\n",
      "True:  [1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: 19876447,\n",
      "Author:  vivek gupta0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        14\n",
      "          1       0.90      1.00      0.95        26\n",
      "\n",
      "avg / total       0.93      0.93      0.92        40\n",
      "\n",
      "[11  3  0 26]\n",
      "Accuracy:  0.925\n",
      "F1:  0.9454545454545454\n",
      "Precision:  0.896551724137931\n",
      "Recall:  1.0\n",
      "vivek gupta1\n",
      "26\n",
      "40\n",
      "Total negative sample size: 14\n",
      "14\n",
      "Positive sample size:  26\n",
      "Negative sample size:  14\n",
      "(26, 102)\n",
      "(14, 102)\n",
      "Total sample size and shape:  (40, 100)\n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0]\n",
      "True:  [0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 1, 0]\n",
      "Mislabeled sample: 21245586,\n",
      "Pred:  [0 0 1 1]\n",
      "True:  [0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1]\n",
      "True:  [0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 0]\n",
      "True:  [0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1]\n",
      "True:  [0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0]\n",
      "True:  [0, 1, 1, 0]\n",
      "Mislabeled sample: 19876447,\n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  vivek gupta1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        26\n",
      "          1       1.00      0.86      0.92        14\n",
      "\n",
      "avg / total       0.95      0.95      0.95        40\n",
      "\n",
      "[26  0  2 12]\n",
      "Accuracy:  0.95\n",
      "F1:  0.923076923076923\n",
      "Precision:  1.0\n",
      "Recall:  0.8571428571428571\n",
      "vivek kumar0\n",
      "15\n",
      "33\n",
      "Total negative sample size: 18\n",
      "18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  15\n",
      "Negative sample size:  18\n",
      "(15, 102)\n",
      "(18, 102)\n",
      "Total sample size and shape:  (33, 100)\n",
      "Pred:  [0 0 1 0]\n",
      "True:  [0, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 1]\n",
      "True:  [1, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0]\n",
      "True:  [1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: 20850006,\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: 24286354,\n",
      "Pred:  [1 1 1]\n",
      "True:  [1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: 8649508,12419229,\n",
      "Author:  vivek kumar0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.85        15\n",
      "          1       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.90      0.88      0.88        33\n",
      "\n",
      "[11  4  0 18]\n",
      "Accuracy:  0.8787878787878788\n",
      "F1:  0.9\n",
      "Precision:  0.8181818181818182\n",
      "Recall:  1.0\n",
      "vivek kumar1\n",
      "18\n",
      "33\n",
      "Total negative sample size: 15\n",
      "15\n",
      "Positive sample size:  18\n",
      "Negative sample size:  15\n",
      "(18, 102)\n",
      "(15, 102)\n",
      "Total sample size and shape:  (33, 100)\n",
      "Pred:  [1 0 0 1]\n",
      "True:  [1, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 0 0]\n",
      "True:  [1, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 1]\n",
      "True:  [0, 1, 1, 1]\n",
      "Mislabeled sample: 8649508,\n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1]\n",
      "True:  [0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: 20850006,12419229,\n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Author:  vivek kumar1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        18\n",
      "          1       1.00      0.80      0.89        15\n",
      "\n",
      "avg / total       0.92      0.91      0.91        33\n",
      "\n",
      "[18  0  3 12]\n",
      "Accuracy:  0.9090909090909091\n",
      "F1:  0.888888888888889\n",
      "Precision:  1.0\n",
      "Recall:  0.8\n",
      "wei lu0\n",
      "30\n",
      "63\n",
      "Total negative sample size: 33\n",
      "33\n",
      "Positive sample size:  30\n",
      "Negative sample size:  33\n",
      "(30, 102)\n",
      "(33, 102)\n",
      "Total sample size and shape:  (63, 100)\n",
      "Pred:  [1 1 1 0 0 1 1]\n",
      "True:  [1, 1, 1, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0 1 1]\n",
      "True:  [1, 1, 0, 0, 0, 1, 1]\n",
      "Mislabeled sample: 19449861,\n",
      "Pred:  [0 0 1 0 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 26310671,25534763,\n",
      "Pred:  [0 1 0 0 0 0]\n",
      "True:  [0, 1, 0, 0, 1, 0]\n",
      "Mislabeled sample: 21117110,\n",
      "Pred:  [0 0 1 1 0 1]\n",
      "True:  [0, 0, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1 0 1 0]\n",
      "True:  [1, 0, 1, 0, 1, 1]\n",
      "Mislabeled sample: 19099066,\n",
      "Pred:  [1 0 1 1 0 1]\n",
      "True:  [0, 0, 1, 1, 0, 0]\n",
      "Mislabeled sample: 22473661,22308117,\n",
      "Pred:  [0 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1]\n",
      "True:  [1, 1, 1, 0, 0, 0]\n",
      "Mislabeled sample: 25413572,17313187,\n",
      "Pred:  [0 1 0 0 1 0]\n",
      "True:  [0, 1, 1, 0, 1, 0]\n",
      "Mislabeled sample: 21393706,\n",
      "Author:  wei lu0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83        30\n",
      "          1       0.85      0.85      0.85        33\n",
      "\n",
      "avg / total       0.84      0.84      0.84        63\n",
      "\n",
      "[25  5  5 28]\n",
      "Accuracy:  0.8412698412698413\n",
      "F1:  0.8484848484848486\n",
      "Precision:  0.8484848484848485\n",
      "Recall:  0.8484848484848485\n",
      "wei lu1\n",
      "33\n",
      "63\n",
      "Total negative sample size: 30\n",
      "30\n",
      "Positive sample size:  33\n",
      "Negative sample size:  30\n",
      "(33, 102)\n",
      "(30, 102)\n",
      "Total sample size and shape:  (63, 100)\n",
      "Pred:  [0 1 0 0 1 0 0]\n",
      "True:  [0, 1, 0, 0, 1, 1, 0]\n",
      "Mislabeled sample: 17313187,\n",
      "Pred:  [1 1 0 0 0 0 1]\n",
      "True:  [1, 1, 0, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 0 0 1]\n",
      "True:  [1, 1, 1, 0, 0, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 1 0 0 1]\n",
      "True:  [0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: 21393706,\n",
      "Pred:  [0 0 0 0 0 1]\n",
      "True:  [0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: 22308117,21117110,\n",
      "Pred:  [1 0 0 0 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 25413572,19449861,\n",
      "Pred:  [1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 1 0 0 0]\n",
      "True:  [0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: 26310671,19099066,\n",
      "Pred:  [1 1 1 0 1 0]\n",
      "True:  [1, 1, 1, 0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0 0 0 1]\n",
      "True:  [1, 1, 0, 1, 0, 1]\n",
      "Mislabeled sample: 20128591,\n",
      "Author:  wei lu1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.88      0.87        33\n",
      "          1       0.86      0.83      0.85        30\n",
      "\n",
      "avg / total       0.86      0.86      0.86        63\n",
      "\n",
      "[29  4  5 25]\n",
      "Accuracy:  0.8571428571428571\n",
      "F1:  0.847457627118644\n",
      "Precision:  0.8620689655172413\n",
      "Recall:  0.8333333333333334\n",
      "wei wang0\n",
      "12\n",
      "154\n",
      "Total negative sample size: 142\n",
      "142\n",
      "Positive sample size:  12\n",
      "Negative sample size:  142\n",
      "(12, 102)\n",
      "(142, 102)\n",
      "Total sample size and shape:  (154, 100)\n",
      "Pred:  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 20162168,22122514,23000999,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 21793508,\n",
      "Pred:  [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 18219578,17539034,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 21336333,20852765,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 24328222,22920036,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 22922540,\n",
      "Author:  wei wang0\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.17      0.27        12\n",
      "          1       0.93      0.99      0.96       142\n",
      "\n",
      "avg / total       0.91      0.93      0.91       154\n",
      "\n",
      "[  2  10   1 141]\n",
      "Accuracy:  0.9285714285714286\n",
      "F1:  0.9624573378839592\n",
      "Precision:  0.9337748344370861\n",
      "Recall:  0.9929577464788732\n",
      "wei wang1\n",
      "13\n",
      "154\n",
      "Total negative sample size: 141\n",
      "141\n",
      "Positive sample size:  13\n",
      "Negative sample size:  141\n",
      "(13, 102)\n",
      "(141, 102)\n",
      "Total sample size and shape:  (154, 100)\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 20544114,\n",
      "Pred:  [1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 22396721,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 21161384,\n",
      "Pred:  [1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 23573176,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 22662028,\n",
      "Pred:  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 16345097,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 18219578,19350096,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Author:  wei wang1\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.56        13\n",
      "          1       0.95      1.00      0.97       141\n",
      "\n",
      "avg / total       0.95      0.95      0.94       154\n",
      "\n",
      "[  5   8   0 141]\n",
      "Accuracy:  0.948051948051948\n",
      "F1:  0.9724137931034482\n",
      "Precision:  0.9463087248322147\n",
      "Recall:  1.0\n",
      "wei wang2\n",
      "14\n",
      "154\n",
      "Total negative sample size: 140\n",
      "140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  14\n",
      "Negative sample size:  140\n",
      "(14, 102)\n",
      "(140, 102)\n",
      "Total sample size and shape:  (154, 100)\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 24039303,21493014,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "Mislabeled sample: 22435608,20087515,\n",
      "Pred:  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1]\n",
      "True:  [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 15281248,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 24357885,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 17381133,\n",
      "Pred:  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 20090966,\n",
      "Pred:  [1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample: 22427896,\n",
      "Author:  wei wang2\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.43      0.57        14\n",
      "          1       0.95      0.99      0.97       140\n",
      "\n",
      "avg / total       0.94      0.94      0.93       154\n",
      "\n",
      "[  6   8   1 139]\n",
      "Accuracy:  0.9415584415584416\n",
      "F1:  0.9686411149825784\n",
      "Precision:  0.9455782312925171\n",
      "Recall:  0.9928571428571429\n",
      "wei wang3\n",
      "14\n",
      "154\n",
      "Total negative sample size: 140\n",
      "140\n",
      "Positive sample size:  14\n",
      "Negative sample size:  140\n",
      "(14, 102)\n",
      "(140, 102)\n",
      "Total sample size and shape:  (154, 100)\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 23795959,\n",
      "Pred:  [1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "Mislabeled sample: 26865256,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Mislabeled sample: 25434824,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "True:  [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: 24954815,\n",
      "Pred:  [1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 23540330,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "Mislabeled sample: 26132348,\n",
      "Pred:  [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 21370921,\n",
      "Author:  wei wang3\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        14\n",
      "          1       0.95      1.00      0.98       140\n",
      "\n",
      "avg / total       0.96      0.95      0.95       154\n",
      "\n",
      "[  7   7   0 140]\n",
      "Accuracy:  0.9545454545454546\n",
      "F1:  0.975609756097561\n",
      "Precision:  0.9523809523809523\n",
      "Recall:  1.0\n",
      "wei wang4\n",
      "101\n",
      "154\n",
      "Total negative sample size: 53\n",
      "53\n",
      "Positive sample size:  101\n",
      "Negative sample size:  53\n",
      "(101, 102)\n",
      "(53, 102)\n",
      "Total sample size and shape:  (154, 100)\n",
      "Pred:  [1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0]\n",
      "True:  [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
      "Mislabeled sample: 17381133,21900129,24357885,\n",
      "Pred:  [0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0]\n",
      "True:  [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0]\n",
      "Mislabeled sample: 24328222,15281248,\n",
      "Pred:  [0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1]\n",
      "True:  [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
      "Mislabeled sample: 21787666,\n",
      "Pred:  [1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "True:  [1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 0 1 0 0 1 0 0 1 0 0 0 0]\n",
      "True:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "Mislabeled sample: 22345304,20090966,\n",
      "Pred:  [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1]\n",
      "True:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 1 0 1 0 0 1 0 0 0 0 0 1 0 0]\n",
      "True:  [0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [0 0 0 1 1 0 0 1 0 0 0 1 0 0 0]\n",
      "True:  [0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0]\n",
      "Mislabeled sample: 19103161,21493014,\n",
      "Pred:  [1 1 0 1 1 1 1 0 1 1 0 1 0 0 0]\n",
      "True:  [1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]\n",
      "Mislabeled sample: 22435608,\n",
      "Pred:  [1 1 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
      "True:  [1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n",
      "Mislabeled sample: 20852765,\n",
      "Author:  wei wang4\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.95      0.94       101\n",
      "          1       0.90      0.87      0.88        53\n",
      "\n",
      "avg / total       0.92      0.92      0.92       154\n",
      "\n",
      "[96  5  7 46]\n",
      "Accuracy:  0.922077922077922\n",
      "F1:  0.8846153846153846\n",
      "Precision:  0.9019607843137255\n",
      "Recall:  0.8679245283018868\n",
      "wei xu0\n",
      "16\n",
      "35\n",
      "Total negative sample size: 19\n",
      "19\n",
      "Positive sample size:  16\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# loop through files in directory |\n",
    "# add name to name list\n",
    "# author as positive sample, other as all samples\n",
    "name_list = []\n",
    "# create name list for all authors have same name\n",
    "for file in fileList:\n",
    "    if not file.startswith('.'):\n",
    "        if not re.match(r'\\D*\\d+.txt$', file):\n",
    "            # fix the coding issue\n",
    "            name_list.append(file.encode(\"utf-8\", \"surrogateescape\").decode('utf8','surrogateescape')[:-4])\n",
    "# print(name_list)\n",
    "\n",
    "# loop through all the author and gather result\n",
    "allauthor = []\n",
    "authorSampleSize = []\n",
    "allSampleSize = []\n",
    "allaccuracy = []\n",
    "allf1 = []\n",
    "allprecision = []\n",
    "allrecall = []\n",
    "alltn = []\n",
    "allfp = []\n",
    "allfn = []\n",
    "alltp = []\n",
    "\n",
    "for name in name_list:\n",
    "    other_pids = []\n",
    "    # read other sample\n",
    "    with open((fileDir+name+\".txt\").encode('utf-8'), 'r', encoding = 'utf8') as f:\n",
    "        for line in f:\n",
    "            other_pids.extend(line.strip().split(\" \"))\n",
    "#     print(name)\n",
    "    for file in fileList:\n",
    "        file=file.encode(\"utf-8\", \"surrogateescape\").decode('utf8','surrogateescape')\n",
    "        if not file.startswith('.'):\n",
    "            if re.match(r'\\D*\\d+.txt$', file):\n",
    "                if name in file:\n",
    "                    print(os.path.splitext(file)[0])\n",
    "                    # add author to list for final output\n",
    "                    allauthor.append(os.path.splitext(file)[0])\n",
    "                    author_pids = []\n",
    "                    # read author sample\n",
    "                    with open((fileDir+os.path.splitext(file)[0]+\".txt\").encode('utf-8'), 'r', encoding = 'utf8') as f:\n",
    "                        for line in f:\n",
    "                            author_pids.extend(line.strip().split(\" \"))\n",
    "                    # print properties\n",
    "                    authorSampleSize.append(len(author_pids))\n",
    "                    allSampleSize.append(len(other_pids))\n",
    "                    print(len(author_pids))\n",
    "                    print(len(other_pids))\n",
    "                    # remove author(positive sample) from other(all sample) to create negative sample\n",
    "                    NegativeSample_pid = extractNegativeSample(author_pids, other_pids)\n",
    "                    print(len(NegativeSample_pid))\n",
    "                    # collect all vector\n",
    "                    classOne, classTwo = extractVectors(author_pids,NegativeSample_pid,allPaperVectors)\n",
    "                    print(classOne.shape)\n",
    "                    print(classTwo.shape)\n",
    "                    # combine data from different class get all data\n",
    "                    data, label, paperID = combineClassesData(classOne, classTwo)\n",
    "#                     # PCA transform\n",
    "#                     pca = PCA(n_components=2)\n",
    "#                     pca_transformed = pd.DataFrame(pca.fit_transform(X=data, y=label))\n",
    "#                     pca_transformed[\"label\"] = label\n",
    "#                     # 10 fold cv SVM linear kernel\n",
    "#                     linear_svc = svm.SVC(kernel='linear', class_weight='balanced', probability=True,cache_size=4000)\n",
    "#                     accuracy, f1, precision, recall, tn, fp, fn, tp= k_fold_cv(os.path.splitext(file)[0],data, label, linear_svc,10)\n",
    "#                     # 10 fold cv SVM rbf kernel\n",
    "#                     rbf_svc = svm.SVC(kernel='rbf')\n",
    "#                     accuracy, f1, precision, recall, tn, fp, fn, tp = k_fold_cv(os.path.splitext(file)[0],data, label, rbf_svc,10)\n",
    "                    # 10 fold cv logistic regression\n",
    "                    logistic = linear_model.LogisticRegression()\n",
    "                    accuracy, f1, precision, recall, tn, fp, fn, tp = k_fold_cv(os.path.splitext(file)[0],data, label, logistic,10)\n",
    "                    allaccuracy.append(accuracy)\n",
    "                    allf1.append(f1)\n",
    "                    allprecision.append(precision)\n",
    "                    allrecall.append(recall)\n",
    "                    alltn.append(tn)\n",
    "                    alltp.append(tp)\n",
    "                    allfn.append(fn)\n",
    "                    allfp.append(fp)\n",
    "# write evaluation result to excel\n",
    "output = pd.DataFrame({'author':allauthor,\"AuthorSampleSize\":authorSampleSize,\n",
    "                       \"accuracy\":allaccuracy,\"f1\":allf1, \"precision\":allprecision,\n",
    "                      \"recall\":allrecall, \"AllSameNameSampleCount\":allSampleSize,\n",
    "                      \"True positive\": alltp, \"True negative\":alltn,\n",
    "                      \"False positive\": allfp, \"False negative\": allfn})\n",
    "filename = \"logistic_regression\"+setting+\"_filter=10.csv\"\n",
    "output.to_csv(\"../result/\"+filename, encoding='utf-8',index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "# hard code to read the file one by one\n",
    "# store the features for classification\n",
    "author_pids = []\n",
    "other_pids = []\n",
    "name = \"michael wagner0\"\n",
    "# author as positive sample, other as all samples\n",
    "with open(fileDir+name+\".txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        author_pids.extend(line.strip().split(\" \"))\n",
    "\n",
    "with open(fileDir+\"michael wagner.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        other_pids.extend(line.strip().split(\" \"))\n",
    "        \n",
    "# size of each class\n",
    "print(len(author_pids))\n",
    "print(len(other_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative sample size: 239\n",
      "Choicen negative sample  239\n"
     ]
    }
   ],
   "source": [
    "# extract negative Sample\n",
    "NegativeSample_pid = extractNegativeSample(author_pids, other_pids)\n",
    "print(\"Choicen negative sample \", len(NegativeSample_pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  16\n",
      "Negative sample size:  239\n",
      "(16, 102)\n",
      "(239, 102)\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "classOne, classTwo = extractVectors(author_pids,NegativeSample_pid,allPaperVectors)\n",
    "print(classOne.shape)\n",
    "print(classTwo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size and shape:  (255, 100)\n"
     ]
    }
   ],
   "source": [
    "data, label, paperID = combineClassesData(classOne, classTwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:  [1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 20459663,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 26330430,18333798,25493568,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 27054571,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 25158072,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 22572638,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 21892778,\n",
      "Pred:  [1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 26200043,26372590,24138519,24450576,\n",
      "Author:  michael wagner0\n",
      "Classifier:  SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.69      0.65        16\n",
      "          1       0.98      0.97      0.97       239\n",
      "\n",
      "avg / total       0.96      0.95      0.95       255\n",
      "\n",
      "[ 11   5   7 232]\n",
      "Accuracy:  0.9529411764705882\n",
      "F1:  0.9542263964409293\n",
      "Precision:  0.9789029535864979\n",
      "Recall:  0.9707112970711297\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "Mislabeled sample: 24575121,19994909,20722033,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 12973727,20459663,15857247,24348519,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 26330430,18333798,25493568,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 22354554,22387186,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 21787302,11913376,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 17081057,\n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Mislabeled sample: 24450576,\n",
      "Author:  michael wagner0\n",
      "Classifier:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.94      1.00      0.97       239\n",
      "\n",
      "avg / total       0.88      0.94      0.91       255\n",
      "\n",
      "[  0  16   0 239]\n",
      "Accuracy:  0.9372549019607843\n",
      "F1:  0.90689846788918\n",
      "Precision:  0.9372549019607843\n",
      "Recall:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9372549019607843, 0.90689846788918, 0.9372549019607843, 1.0, 0, 16, 0, 239)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# create linear SVM model\n",
    "linear_svc = svm.SVC(kernel='linear', class_weight='balanced', probability=True)\n",
    "\n",
    "# fit model and do 10-fold cv\n",
    "k_fold_cv(name,data, label, linear_svc,10)\n",
    "\n",
    "# get number of support vectors for each class\n",
    "print(linear_svc.n_support_)\n",
    "\n",
    "'''\n",
    "# compute the distance to decision boundry (Not same as confidence measure)\n",
    "Distance = linear_svc.decision_function(allDatas)\n",
    "\n",
    "# computer the confidence measure (Platt scaling: transforming the outputs of a \n",
    "# classification model into a probability distribution over classes)\n",
    "# P(class/input) = 1 / (1 + exp(A * f(input) + B))\n",
    "# P(class/input) is the probability that input belongs to class \n",
    "# and f(input) is the signed distance of the input datapoint from the boundary,\n",
    "# which is basically the output of decision_function. \n",
    "\n",
    "proba = linear_svc.predict_proba(allDatas)\n",
    "\n",
    "'''\n",
    "\n",
    "# create rbf SVM model with C=10 where (C*Error) is added into minimize function\n",
    "# C big means error matter more\n",
    "rbf_svc = svm.SVC(kernel='rbf',probability=True)\n",
    "\n",
    "# fit model and do 10-fold cv\n",
    "k_fold_cv(name,data, label, rbf_svc)\n",
    "\n",
    "# get number of support vectors for each class\n",
    "print(rbf_svc.n_support_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
