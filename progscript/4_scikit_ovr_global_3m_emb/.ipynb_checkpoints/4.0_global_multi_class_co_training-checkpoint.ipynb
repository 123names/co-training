{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-class co-training\n",
    "\n",
    "Directly apply co-train to multi-class problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T03:53:16.150288Z",
     "start_time": "2019-02-16T03:53:13.996378Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings('error')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import com_func\n",
    "# parameters\n",
    "#----- threshold for selecting set of name group -----------#\n",
    "threshold_select_name_group = 100\n",
    "#----- threshold for selecting min sample in name group ----#\n",
    "threshold_lower = 100\n",
    "threshold_upper = 110\n",
    "\n",
    "pp_textual = [\"pv_dbow\"]\n",
    "# pp_textual = [\"lsa\", \"pv_dm\", \"pv_dbow\"]\n",
    "pp_citation = \"n2v\"\n",
    "\n",
    "Dataset = \"pubmed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T19:29:28.279831Z",
     "start_time": "2019-02-16T19:29:26.155341Z"
    },
    "code_folding": [
     11,
     26,
     34,
     47,
     144,
     152,
     159,
     166,
     194
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "# create co training classifier\n",
    "class Multi_Class_Co_training(object):\n",
    "    \n",
    "    import copy\n",
    "    \n",
    "    def __init__(self, clf1, clf2=None, k=30, u = 100):\n",
    "        \n",
    "        self.clf1 = clf1\n",
    "        # assume co_training on one classifier\n",
    "        if clf2 == None:\n",
    "            self.clf2 = self.copy.deepcopy(clf1)\n",
    "        else:\n",
    "            self.clf2 = clf2\n",
    "        # base of number of self labeled samples\n",
    "        self.self_labeled_base = 1\n",
    "        # number of iteration\n",
    "        self.k = k\n",
    "        # minimal size of pool of unlabeled samples\n",
    "        self.minimal_u = u\n",
    "\n",
    "    def init_U_prime(self, U):\n",
    "        # random drawing sample from U\n",
    "        random.shuffle(U)\n",
    "        U_prime = U[-min(len(U), self.u):]\n",
    "        # remove the samples in U_prime from U\n",
    "        U = U[:-len(U_prime)]\n",
    "        return U, U_prime\n",
    "\n",
    "    def check_iter_label_mapping(self, iter_clf1, iter_clf2):\n",
    "        '''\n",
    "        In theory, it shouldn't occur that label not mapping since it trained on same dataset but different view\n",
    "        But add a check to make sure it won't occur and save the class mapping for late label unlabeled sample\n",
    "        '''\n",
    "        dv1_class_label = iter_clf1.classes_\n",
    "        dv2_class_label = iter_clf2.classes_\n",
    "        if all(dv1_class_label == dv2_class_label):\n",
    "            self.class_ = dv1_class_label\n",
    "        else:\n",
    "            sys.exit(\"Two view classifier label not mapping\")\n",
    "        \n",
    "\n",
    "    def label_unlabeled_samples(self, proba, rank):\n",
    "        U_prime_size = len(proba)\n",
    "        self_trained_labels = []\n",
    "        for label, conf_measure in enumerate(rank):\n",
    "            index = 0\n",
    "            new_label = []\n",
    "            while(len(new_label)<self.self_labeled_base):\n",
    "                max_conf_sample_index = conf_measure[index]\n",
    "                # ---- if predict proba is more than 50% ------- #\n",
    "                if (proba[max_conf_sample_index][label] > 0.5):\n",
    "                    # print(label, ': ', max_conf_sample_index, \" : \", proba[max_conf_sample_index])\n",
    "                    new_label.append(max_conf_sample_index)\n",
    "                index +=1\n",
    "                if (index>=U_prime_size):\n",
    "                    break\n",
    "            self_trained_labels.append(new_label)\n",
    "        # print(self_trained_labels)\n",
    "        return self_trained_labels\n",
    "\n",
    "    def fit(self, dataView1, dataView2, labels):\n",
    "        # index of self labeled samples\n",
    "        self.new_labeled_idx = defaultdict(list)\n",
    "        # count of self labeled samples\n",
    "        self.new_labeled_count = {}\n",
    "        \n",
    "        # index of the samples that are initially labeled\n",
    "        L = [i for i, label_i in enumerate(labels) if label_i != \"-1\"]\n",
    "        # index of unlabeled samples\n",
    "        U = [i for i, label_i in enumerate(labels) if label_i == \"-1\"]\n",
    "        # ----------our u prime will be max(user_input, number of labeled train) ------- #\n",
    "        self.u = max(self.minimal_u, len(L))\n",
    "        U, U_prime = self.init_U_prime(U)\n",
    "        print(\"L: \", len(L), \"U: \",len(U))\n",
    "        init_train_label = labels[L]\n",
    "        num_class = len(set(init_train_label))\n",
    "        print(\"init class count: \", num_class)\n",
    "        iterCount = 0\n",
    "        #loop until we have assigned labels to every sample in U and U_prime or we hit our iteration break condition\n",
    "        while iterCount < self.k and U_prime:\n",
    "            # print(\"step\",iterCount, \" L: \",L)\n",
    "            # print(\"step\",iterCount, \" U_prime: \",U_prime)\n",
    "            iter_train_d1 = dataView1.iloc[L]\n",
    "            iter_train_d2= dataView2.iloc[L]\n",
    "            iter_train_label = labels[L]\n",
    "            iter_clf1 = self.copy.deepcopy(self.clf1) \n",
    "            iter_clf2 = self.copy.deepcopy(self.clf2)\n",
    "            iter_clf1.fit(X=iter_train_d1, y=iter_train_label)\n",
    "            iter_clf2.fit(X=iter_train_d2, y=iter_train_label)\n",
    "            \n",
    "            self.check_iter_label_mapping(iter_clf1, iter_clf2)\n",
    "            \n",
    "            iter_unlabeled_d1 = dataView1.iloc[U_prime]\n",
    "            iter_unlabeled_d2 = dataView2.iloc[U_prime]\n",
    "            # rank class probabilities for unlabeled sample for it's confidence measure\n",
    "            dv1_proba = iter_clf1.predict_proba(iter_unlabeled_d1)\n",
    "            dv2_proba = iter_clf2.predict_proba(iter_unlabeled_d2)\n",
    "            dv1_proba_rank = []\n",
    "            dv2_proba_rank = []\n",
    "            # proba1_rank[i] is label i's confidence measure\n",
    "            for class_proba in dv1_proba.T:\n",
    "                dv1_proba_rank.append((-class_proba).argsort())\n",
    "            for class_proba in dv2_proba.T:\n",
    "                dv2_proba_rank.append((-class_proba).argsort())\n",
    "            #print(dv1_proba)\n",
    "            #print(dv1_proba_rank)\n",
    "            #print(dv2_proba)\n",
    "            #print(dv2_proba_rank)\n",
    "            # h1 classifier\n",
    "            newly_labeled_dv1 = self.label_unlabeled_samples(dv1_proba, dv1_proba_rank)\n",
    "            # h2 classifier\n",
    "            newly_labeled_dv2 = self.label_unlabeled_samples(dv2_proba, dv2_proba_rank)\n",
    "            roundNew = list(zip(newly_labeled_dv1, newly_labeled_dv2))\n",
    "            # auto label the samples and remove it from U_prime\n",
    "            round_auto_labeled = []\n",
    "            for label, round_new in enumerate(roundNew):\n",
    "                round_new = set([item for sublist in round_new for item in sublist])\n",
    "                auto_labeled = [U_prime[x] for x in round_new]\n",
    "                round_auto_labeled.extend(auto_labeled)\n",
    "                self.new_labeled_idx[self.class_[label]].append(auto_labeled)\n",
    "                # add label to those new samples\n",
    "                labels[auto_labeled] = self.class_[label]\n",
    "                #print(self.class_[label],\" (u' idx): \",round_new)\n",
    "                #print(self.class_[label],\" (U idx): \",auto_labeled)\n",
    "            print(round_auto_labeled)\n",
    "            # extend the labeled sample\n",
    "            L.extend(round_auto_labeled)\n",
    "            # remove the labeled sample from U_prime\n",
    "            U_prime = [x for x in U_prime if x not in round_auto_labeled]\n",
    "            #print(U_prime)\n",
    "            # randomly choice 2p+2n examples from u to replenish u_prime\n",
    "            replenishItem = U[-(2*num_class*self.self_labeled_base):]\n",
    "            U_prime.extend(replenishItem)\n",
    "            U = U[:-len(replenishItem)]\n",
    "            iterCount +=1\n",
    "            \n",
    "        print(\"Total Labeled number: \", len(L), \" Still unlabeled number: \", len(U_prime))\n",
    "        # final train\n",
    "        newtrain_d1 = dataView1.iloc[L]\n",
    "        newtrain_d2 = dataView2.iloc[L]\n",
    "        self.clf1.fit(newtrain_d1, labels[L])\n",
    "        self.clf2.fit(newtrain_d2, labels[L])\n",
    "\n",
    "    def get_self_labeled_sample(self):\n",
    "        '''\n",
    "        return:\n",
    "            self-labeled sample Index\n",
    "        '''\n",
    "\n",
    "        return self.new_labeled_idx\n",
    "    \n",
    "    def get_self_labeled_sample_count(self):\n",
    "        for key, value in self.new_labeled_idx.items():\n",
    "            flated_value = [item for sublist in value for item in sublist]\n",
    "            # print(key, \" : \", flated_value)\n",
    "            self.new_labeled_count[key] = len(flated_value)\n",
    "        return self.new_labeled_count\n",
    "\n",
    "    def supports_proba(self, clf, x):\n",
    "        try:\n",
    "            clf.predict_proba([x])\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def predict(self, dataView1, dataView2):\n",
    "        y1 = self.clf1.predict(dataView1)\n",
    "        y2 = self.clf2.predict(dataView2)\n",
    "        proba_supported = self.supports_proba(self.clf1, dataView1.iloc[0]) and self.supports_proba(self.clf2, dataView2.iloc[0])\n",
    "        #fill pred with -1 so we can identify the samples in which sample classifiers failed to agree\n",
    "        y_pred = [\" \"] * dataView1.shape[0]\n",
    "        for i, (y1_i, y2_i) in enumerate(zip(y1, y2)):\n",
    "            # if both clf agree on label\n",
    "            if y1_i == y2_i:\n",
    "                y_pred[i] = y1_i\n",
    "            # if disagree on label, times probability together, choice the class have higher probabilities\n",
    "            elif proba_supported:\n",
    "                y1_probas = self.clf1.predict_proba([dataView1.iloc[i]])[0]\n",
    "                y2_probas = self.clf2.predict_proba([dataView2.iloc[i]])[0]\n",
    "                print(\"y1 disagree on\",i, \" Proba: \",y1_probas)\n",
    "                print(\"y2 not aggreed on \",i, \"Proba: \", y2_probas)\n",
    "                prod_y_probas = [proba_y1 * proba_y2 for (proba_y1, proba_y2) in zip(y1_probas, y2_probas)]\n",
    "                print(\"product probas:\",prod_y_probas)\n",
    "                max_prob_idx = prod_y_probas.index(max(prod_y_probas))\n",
    "                y_pred[i] = self.class_[max_prob_idx]\n",
    "                print(\"result idx: \", max_prob_idx, \" result: \",y_pred[i])\n",
    "            else:\n",
    "                #the classifiers disagree and don't support probability, exit\n",
    "                sys.exit(\"classifiers disagree with label, result may not accurate\")\n",
    "        # convert final result to np array\n",
    "        y_pred_np_array = np.asarray(y_pred)\n",
    "        return y_pred_np_array\n",
    "\n",
    "    def predict_proba(self, dataView1, dataView2):\n",
    "        # the predicted probabilities is simply a product of probabilities given from each classifier trained\n",
    "        y1_probas = self.clf1.predict_proba(dataView1)\n",
    "        y2_probas = self.clf2.predict_proba(dataView2)\n",
    "        \n",
    "        proba = (y1_probas*y2_probas)\n",
    "        return proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T19:29:28.468948Z",
     "start_time": "2019-02-16T19:29:28.282441Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# cross validation\n",
    "def k_fold_cv_co_train(dataview1, dataview2, unlabeled_dv1, unlabeled_dv2, label, clf, k=10):\n",
    "    kf = StratifiedKFold(n_splits=k)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel = []\n",
    "    all_generated_train = []\n",
    "    for train_index, test_index in kf.split(dataview1, label):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # ---------------split train and test -------------------- #\n",
    "        dv1_train, dv1_test = dataview1.iloc[train_index], dataview1.iloc[test_index]\n",
    "        dv2_train, dv2_test = dataview2.iloc[train_index], dataview2.iloc[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        # -------------- add unlabeled to train ------------------ #\n",
    "        final_dv1 = pd.concat([dv1_train,unlabeled_dv1], ignore_index=True)\n",
    "        final_dv2 = pd.concat([dv2_train,unlabeled_dv2], ignore_index=True)\n",
    "        final_dv1 = final_dv1.drop([\"authorID\", \"paperID\", \"label\"], axis=1)\n",
    "        final_dv2 = final_dv2.drop([\"authorID\", \"paperID\", \"label\"], axis=1)\n",
    "        final_labels = label_train.append(unlabeled_dv1[\"label\"], ignore_index=True)\n",
    "        # -------------- train co-training multi class ------------------- #\n",
    "        co_train_clf = copy.deepcopy(clf)\n",
    "        co_train_clf.fit(final_dv1, final_dv2, final_labels)\n",
    "        all_generated_train.append(co_train_clf.get_self_labeled_sample_count())\n",
    "\n",
    "        # -------------- test ovr co-training -------------------- #\n",
    "        dv1_test = dv1_test.drop([\"authorID\", \"paperID\"], axis=1)\n",
    "        dv2_test = dv2_test.drop([\"authorID\", \"paperID\"], axis=1)\n",
    "        \n",
    "        # get predicted label\n",
    "        co_lr_label_predict = co_train_clf.predict(dv1_test, dv2_test)\n",
    "        allTrueLabel.extend(label_test)\n",
    "        allPredLabel.extend(co_lr_label_predict)\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "    \n",
    "    # --------- find average of positive/negative self labeled sample for each author --- #\n",
    "    all_fold_averaged_generated_train = defaultdict(list)\n",
    "    print(all_generated_train)\n",
    "    for per_fold_count_dic in all_generated_train:\n",
    "        for key, value in per_fold_count_dic.items():\n",
    "            all_fold_averaged_generated_train[key].append(value)\n",
    "    print(all_fold_averaged_generated_train)\n",
    "    for key, value in all_fold_averaged_generated_train.items():\n",
    "        all_fold_averaged_generated_train[key] = np.around(np.mean(value, axis=0))\n",
    "    # ------------- accuracy and f1 ---------- #\n",
    "    accuracy = accuracy_score(allTrueLabel, allPredLabel)\n",
    "    f1 = f1_score(allTrueLabel, allPredLabel,average='macro')\n",
    "    \n",
    "    print(all_fold_averaged_generated_train)\n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel).ravel())\n",
    "    \n",
    "    return accuracy, f1, all_fold_averaged_generated_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T19:29:45.412086Z",
     "start_time": "2019-02-16T19:29:28.471281Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For name:  j_read\n",
      "956\n",
      "(136, 2)\n",
      "j_read  pass\n",
      "For name:  f_esteves\n",
      "120\n",
      "(34, 2)\n",
      "f_esteves  pass\n",
      "For name:  c_miller\n",
      "6564\n",
      "(252, 2)\n",
      "c_miller  pass\n",
      "For name:  r_jha\n",
      "362\n",
      "(11, 2)\n",
      "r_jha  pass\n",
      "For name:  a_lowe\n",
      "772\n",
      "(102, 2)\n",
      "a_lowe  pass\n",
      "For name:  a_vega\n",
      "559\n",
      "(20, 2)\n",
      "a_vega  pass\n",
      "For name:  k_smith\n",
      "8516\n",
      "(338, 2)\n",
      "k_smith  pass\n",
      "For name:  j_gordon\n",
      "3753\n",
      "(19, 2)\n",
      "j_gordon  pass\n",
      "For name:  s_liao\n",
      "2273\n",
      "(104, 2)\n",
      "s_liao  pass\n",
      "For name:  j_qian\n",
      "3452\n",
      "(17, 2)\n",
      "j_qian  pass\n",
      "For name:  s_bernardi\n",
      "160\n",
      "(91, 2)\n",
      "s_bernardi  pass\n",
      "For name:  t_hill\n",
      "1180\n",
      "(15, 2)\n",
      "t_hill  pass\n",
      "For name:  s_schindler\n",
      "177\n",
      "(51, 2)\n",
      "s_schindler  pass\n",
      "For name:  j_williams\n",
      "13317\n",
      "(625, 2)\n",
      "j_williams  pass\n",
      "For name:  s_jacobson\n",
      "1535\n",
      "(28, 2)\n",
      "s_jacobson  pass\n",
      "For name:  e_andrade\n",
      "333\n",
      "(17, 2)\n",
      "e_andrade  pass\n",
      "For name:  t_santos\n",
      "587\n",
      "(45, 2)\n",
      "t_santos  pass\n",
      "For name:  k_kim\n",
      "29577\n",
      "(1111, 2)\n",
      "Total sample size before apply threshold:  1111\n",
      "Counter({'0000-0002-6929-5359': 211, '0000-0001-9498-284X': 154, '0000-0002-5878-8895': 139, '0000-0002-1864-3392': 92, '0000-0002-7045-8004': 57, '0000-0001-7896-6751': 57, '0000-0002-7991-9428': 55, '0000-0002-4010-1063': 45, '0000-0002-2186-3484': 28, '0000-0002-4899-1929': 25, '0000-0003-0487-4242': 24, '0000-0002-3642-1486': 22, '0000-0001-9965-3535': 17, '0000-0002-4168-757X': 17, '0000-0001-6525-3744': 14, '0000-0002-3897-0278': 14, '0000-0002-1181-5112': 12, '0000-0003-1447-9385': 11, '0000-0002-7305-8786': 11, '0000-0002-2655-7806': 10, '0000-0003-3466-5353': 9, '0000-0002-7359-663X': 8, '0000-0003-4600-8668': 6, '0000-0002-1382-7088': 5, '0000-0002-9505-4882': 5, '0000-0003-3667-9900': 4, '0000-0001-9714-6038': 4, '0000-0002-4760-0228': 3, '0000-0003-4188-7915': 3, '0000-0001-9454-0427': 3, '0000-0002-0333-6808': 3, '0000-0003-2134-4964': 3, '0000-0002-6658-047X': 3, '0000-0003-1273-379X': 3, '0000-0002-7047-3183': 3, '0000-0002-1814-9546': 3, '0000-0003-4812-6297': 2, '0000-0001-6597-578X': 2, '0000-0002-5285-9138': 2, '0000-0002-6796-7844': 2, '0000-0002-1130-8698': 2, '0000-0001-8518-8150': 2, '0000-0002-7103-924X': 2, '0000-0002-5407-0202': 1, '0000-0001-6220-8411': 1, '0000-0002-7440-6703': 1, '0000-0002-1603-7559': 1, '0000-0003-0257-1707': 1, '0000-0001-8532-6517': 1, '0000-0001-6626-316X': 1, '0000-0002-3246-9861': 1, '0000-0002-7207-4389': 1, '0000-0001-9682-9654': 1, '0000-0002-0196-3832': 1, '0000-0001-8063-6081': 1, '0000-0003-2037-3333': 1, '0000-0001-8872-6751': 1})\n",
      "Total author before apply threshoid:  57\n",
      "Total author after apply threshoid:  3\n",
      "Total sample size after apply threshold:  504\n",
      "Total missing sample:  0\n",
      "(504, 101)\n",
      "Total missing sample:  47\n",
      "(504, 101)\n",
      "Labeled:  504  :  504\n",
      "(28524, 102)\n",
      "(23077, 102)\n",
      "Unlabeled:  28524  :  23077\n",
      "Unlabeled no citation link size:  5447\n",
      "(504, 102)\n",
      "(504, 102)\n",
      "(23077, 102)\n",
      "(23077, 102)\n",
      "L:  251 U:  22826\n",
      "init class count:  3\n",
      "[6680, 18672, 7488, 22089, 12369]\n",
      "[2886, 8275, 12599, 9858, 21445, 9217]\n",
      "[7761, 3788, 18263, 19011, 20084, 12356]\n",
      "[7339, 8916, 11514, 16349, 8849]\n",
      "[15502, 9508, 19073, 13567, 2793, 17458]\n",
      "[21046, 22654, 6437, 21442, 11969, 6261]\n",
      "[431, 11619, 13320, 14535, 2023, 10005]\n",
      "[5707, 2588, 10933, 22253]\n",
      "[14628, 2575, 11407, 23210, 15196, 5918]\n",
      "[10010, 1354, 14407, 7521, 18849, 20560]\n",
      "[14716, 3177, 6323, 4338, 16336, 19617]\n",
      "[7183, 9043, 17268, 3969, 21801]\n",
      "[20129, 3479, 6478, 9580, 3014, 10248]\n",
      "[15880, 3433, 17210, 10454, 19289, 14472]\n",
      "[17217, 9684, 3042, 22916]\n",
      "[9429, 15000, 13664, 8850, 17369, 4574]\n",
      "[11583, 7419, 8065, 12184, 6444, 8332]\n",
      "[6205, 12718, 3714, 13928, 5320]\n",
      "[11488, 10868, 20149, 19387, 3596]\n",
      "[21886, 6645, 5155, 13606, 8409, 13298]\n",
      "[9713, 23023, 9575, 13539, 8928, 11193]\n",
      "[12224, 15908, 12241, 21211, 7087]\n",
      "[10952, 6335, 3703, 9018, 5816]\n",
      "[2348, 23216, 22131, 866, 11521]\n",
      "[19721, 1622, 3407, 20557, 9664]\n",
      "[5637, 16845, 18419, 18701, 11896, 14325]\n",
      "[20147, 16749, 7052, 21627, 11646]\n",
      "[1710, 17805, 7872, 1803, 3735]\n",
      "[4486, 18510, 3009, 6042, 17566]\n",
      "[5569, 6203, 16027, 20167, 20155]\n",
      "Total Labeled number:  414  Still unlabeled number:  268\n",
      "y1 disagree on 15  Proba:  [0.27212366 0.71422148 0.01365486]\n",
      "y2 not aggreed on  15 Proba:  [7.78197510e-01 2.21658002e-01 1.44487227e-04]\n",
      "product probas: [0.211765951387059, 0.1583129064014552, 1.9729535156109874e-06]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 19  Proba:  [0.97502482 0.01707736 0.00789782]\n",
      "y2 not aggreed on  19 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.345523255022171, 0.0033304406213457874, 0.003558799045881015]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 35  Proba:  [9.82904738e-02 9.01591676e-01 1.17850436e-04]\n",
      "y2 not aggreed on  35 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.03483156908336697, 0.17582913292442867, 5.310404218012629e-05]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 43  Proba:  [3.20139715e-01 6.79564994e-01 2.95290949e-04]\n",
      "y2 not aggreed on  43 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.11344912844177178, 0.13252931115835284, 0.00013305969388158236]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 44  Proba:  [0.85897784 0.10326472 0.03775744]\n",
      "y2 not aggreed on  44 Proba:  [0.12291357 0.86253602 0.0145504 ]\n",
      "product probas: [0.1055800349596322, 0.08906953941031684, 0.0005493860556495369]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 74  Proba:  [0.99340899 0.00450572 0.00208529]\n",
      "y2 not aggreed on  74 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.352038120980691, 0.0008787095519731675, 0.0009396439929276643]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 76  Proba:  [0.00670138 0.99125604 0.00204258]\n",
      "y2 not aggreed on  76 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.0023747945950019244, 0.193315548744463, 0.0009203974156360313]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 86  Proba:  [0.35424147 0.64373315 0.00202538]\n",
      "y2 not aggreed on  86 Proba:  [0.73370223 0.26537131 0.00092646]\n",
      "product probas: [0.2599077592714204, 0.17082831053795614, 1.876430371719576e-06]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 88  Proba:  [0.07025661 0.92753969 0.0022037 ]\n",
      "y2 not aggreed on  88 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.024897101602889347, 0.18088953525414966, 0.0009930003598238835]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 96  Proba:  [7.65782128e-02 9.23082745e-01 3.39042383e-04]\n",
      "y2 not aggreed on  96 Proba:  [0.4642172  0.45643304 0.07934976]\n",
      "product probas: [0.03554892369496535, 0.4213254621977837, 2.6902931366313097e-05]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 97  Proba:  [0.93120715 0.06610625 0.0026866 ]\n",
      "y2 not aggreed on  97 Proba:  [0.38562434 0.19394323 0.42043244]\n",
      "product probas: [0.3590961382944061, 0.012820859903637209, 0.0011295332429640324]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 109  Proba:  [0.41529957 0.4595583  0.12514213]\n",
      "y2 not aggreed on  109 Proba:  [0.46128408 0.45607585 0.08264007]\n",
      "product probas: [0.1915710809137205, 0.20959344180172917, 0.01034175448233139]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 117  Proba:  [0.92358731 0.02078371 0.05562898]\n",
      "y2 not aggreed on  117 Proba:  [0.2911675  0.38577456 0.32305794]\n",
      "product probas: [0.2689186109488632, 0.008017827669689575, 0.017971383888031864]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 127  Proba:  [0.02660224 0.97145057 0.00194719]\n",
      "y2 not aggreed on  127 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.009427137746797978, 0.1894530696372838, 0.0008774155658566329]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 130  Proba:  [0.92033485 0.02111591 0.05854923]\n",
      "y2 not aggreed on  130 Proba:  [0.39752657 0.40587584 0.19659759]\n",
      "product probas: [0.3658575569067638, 0.008570439485889017, 0.011510638624601515]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 154  Proba:  [0.07954786 0.88455721 0.03589493]\n",
      "y2 not aggreed on  154 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.028189676852581547, 0.1725070586964149, 0.016174447912824217]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 175  Proba:  [9.43793463e-01 5.60735640e-02 1.32972901e-04]\n",
      "y2 not aggreed on  175 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.3344556795961152, 0.010935511493359716, 5.991830632723489e-05]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 179  Proba:  [0.45098128 0.53412415 0.01489457]\n",
      "y2 not aggreed on  179 Proba:  [0.84255749 0.09463822 0.06280429]\n",
      "product probas: [0.3799776542513914, 0.05054855677544191, 0.0009354429375956851]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 190  Proba:  [0.87075448 0.12328815 0.00595737]\n",
      "y2 not aggreed on  190 Proba:  [0.43402308 0.56302603 0.00295088]\n",
      "product probas: [0.3779275441947971, 0.06941443581375477, 1.7579507330187032e-05]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 194  Proba:  [0.42905522 0.56632649 0.00461829]\n",
      "y2 not aggreed on  194 Proba:  [0.50708992 0.31178856 0.18112152]\n",
      "product probas: [0.2175695796424562, 0.17657412120944171, 0.0008364715237659686]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 218  Proba:  [0.96135961 0.03320563 0.00543477]\n",
      "y2 not aggreed on  218 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.3406806603089159, 0.006475788253666861, 0.0024489350551205806]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 221  Proba:  [0.97908755 0.01666343 0.00424902]\n",
      "y2 not aggreed on  221 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.3469629794594959, 0.003249716212049555, 0.0019146296362564275]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 226  Proba:  [0.82150241 0.1764361  0.00206149]\n",
      "y2 not aggreed on  226 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.29111893471574585, 0.03440870955261959, 0.000928918454450296]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 231  Proba:  [0.31667723 0.68158737 0.0017354 ]\n",
      "y2 not aggreed on  231 Proba:  [0.66446384 0.30143431 0.03410185]\n",
      "product probas: [0.21042057228181144, 0.20545381715529706, 5.918027119461039e-05]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 234  Proba:  [0.67091437 0.32652574 0.00255989]\n",
      "y2 not aggreed on  234 Proba:  [0.01608392 0.97231956 0.01159652]\n",
      "product probas: [0.01079093089780914, 0.31748736119323734, 2.9685822658130888e-05]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 242  Proba:  [0.0093477  0.98117961 0.00947268]\n",
      "y2 not aggreed on  242 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.0033125805173453596, 0.19135043671498514, 0.0042684424283426885]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 248  Proba:  [0.04938034 0.94720058 0.00341908]\n",
      "y2 not aggreed on  248 Proba:  [0.50687879 0.492455   0.00066621]\n",
      "product probas: [0.02502984765034434, 0.4664536648780112, 2.277808022006572e-06]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 252  Proba:  [0.36591749 0.61904069 0.01504183]\n",
      "y2 not aggreed on  252 Proba:  [0.3543738  0.1950208  0.45060539]\n",
      "product probas: [0.12967157113651592, 0.1207258122592398, 0.006777928352065486]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:  253 U:  22824\n",
      "init class count:  3\n",
      "[7465, 23203, 2411, 17915, 20690, 13841]\n",
      "[20731, 17210, 15892, 7241, 22631, 10364]\n",
      "[6653, 8565, 11402, 11512, 1989]\n",
      "[2470, 3947, 15907, 15394, 10912, 9061]\n",
      "[11548, 18733, 11755, 21313, 20061, 21038]\n",
      "[15497, 18977, 9691, 8975, 20621, 13963]\n",
      "[7983, 13922, 12004, 9225, 13042, 3649]\n",
      "[15421, 13269, 14098, 13791, 20610, 16685]\n",
      "[23064, 12603, 10157, 22073, 19238, 8180]\n",
      "[13054, 6440, 13932, 1704, 7307, 10317]\n",
      "[16153, 10147, 14174, 15979, 6481, 19591]\n",
      "[15396, 18815, 10136, 3603, 3420, 15234]\n",
      "[18491, 12546, 8758, 1653, 15783]\n",
      "[13352, 5967, 22350, 13700, 6882, 8787]\n",
      "[21658, 4582, 11214, 10094, 9591, 8176]\n",
      "[6386, 5622, 13920, 10008, 21836, 16811]\n",
      "[17579, 18809, 20762, 19139, 22799]\n",
      "[4674, 20347, 5185, 17229, 19528, 17690]\n",
      "[18534, 19644, 21240, 2219, 20546, 7797]\n",
      "[10965, 19095, 13325, 10361, 14820, 21220]\n",
      "[14784, 8992, 4699, 7634, 13581]\n",
      "[19885, 17792, 5429, 16523, 11909]\n",
      "[12027, 4752, 8360, 4515, 17162, 12906]\n",
      "[18867, 5752, 21823, 4529, 8567, 22793]\n",
      "[15861, 19721, 8432, 7951, 22964, 2893]\n",
      "[17063, 11114, 10845, 6556, 13297, 9552]\n",
      "[13341, 5698, 19451, 14133, 4270]\n",
      "[14534, 20950, 18236, 19801, 22917]\n",
      "[22819, 2714, 17437, 19208, 12564]\n",
      "[17124, 7883, 16426, 15226]\n",
      "Total Labeled number:  423  Still unlabeled number:  263\n",
      "y1 disagree on 26  Proba:  [0.26587805 0.727736   0.00638595]\n",
      "y2 not aggreed on  26 Proba:  [0.57510524 0.19563234 0.22926242]\n",
      "product probas: [0.15290785702955803, 0.14236869544347533, 0.0014640592618170923]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 44  Proba:  [0.30852178 0.68988741 0.0015908 ]\n",
      "y2 not aggreed on  44 Proba:  [0.87756425 0.12080512 0.00163063]\n",
      "product probas: [0.2707476886186882, 0.08334193117804631, 2.594007712536579e-06]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 47  Proba:  [0.11434325 0.08302533 0.80263142]\n",
      "y2 not aggreed on  47 Proba:  [0.55016986 0.28987357 0.15995657]\n",
      "product probas: [0.06290821202119508, 0.024066847615716896, 0.12838617256971746]\n",
      "result idx:  2  result:  0000-0002-6929-5359\n",
      "y1 disagree on 107  Proba:  [4.66295195e-01 5.33234040e-01 4.70765010e-04]\n",
      "y2 not aggreed on  107 Proba:  [0.91272721 0.07291725 0.01435555]\n",
      "product probas: [0.4256003113266868, 0.03888195773960048, 6.758088597075885e-06]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 110  Proba:  [0.3840794  0.01043973 0.60548087]\n",
      "y2 not aggreed on  110 Proba:  [0.9209627  0.02906079 0.04997652]\n",
      "product probas: [0.3537228021989837, 0.0003033867418846082, 0.030259825561487166]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 111  Proba:  [0.95867786 0.03371112 0.00761102]\n",
      "y2 not aggreed on  111 Proba:  [0.35173084 0.23445039 0.41381877]\n",
      "product probas: [0.3371965714003747, 0.007903585790731232, 0.0031495826574501205]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 127  Proba:  [0.39506524 0.6007822  0.00415256]\n",
      "y2 not aggreed on  127 Proba:  [0.94707295 0.04830281 0.00462424]\n",
      "product probas: [0.3741556041086403, 0.029019468472046384, 1.9202409910081274e-05]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 135  Proba:  [0.62150471 0.36726701 0.01122829]\n",
      "y2 not aggreed on  135 Proba:  [0.37831227 0.6173013  0.00438643]\n",
      "product probas: [0.23512285575635367, 0.22671440214905578, 4.9252050411783264e-05]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 141  Proba:  [0.30556335 0.69326147 0.00117518]\n",
      "y2 not aggreed on  141 Proba:  [0.39380932 0.37445761 0.23173307]\n",
      "product probas: [0.12033369297967808, 0.25959703458996, 0.00027232852801076685]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 144  Proba:  [0.17124727 0.7614562  0.06729653]\n",
      "y2 not aggreed on  144 Proba:  [0.50962918 0.45200847 0.03836235]\n",
      "product probas: [0.08727260403026445, 0.3441846547009196, 0.0025816529475921647]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 155  Proba:  [0.48144578 0.50627261 0.0122816 ]\n",
      "y2 not aggreed on  155 Proba:  [0.59205555 0.40639583 0.00154862]\n",
      "product probas: [0.2850426483126528, 0.20574707798476827, 1.901955817195516e-05]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 157  Proba:  [0.8167758  0.18226899 0.00095522]\n",
      "y2 not aggreed on  157 Proba:  [0.35173084 0.23445039 0.41381877]\n",
      "product probas: [0.28728523949610585, 0.04273303440030206, 0.0003952867460952072]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 161  Proba:  [0.8901047  0.06482716 0.04506814]\n",
      "y2 not aggreed on  161 Proba:  [0.35173084 0.23445039 0.41381877]\n",
      "product probas: [0.31307727702077137, 0.015198752788280456, 0.01865004185496413]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 169  Proba:  [9.89446484e-01 9.91519686e-03 6.38318700e-04]\n",
      "y2 not aggreed on  169 Proba:  [0.35173084 0.23445039 0.41381877]\n",
      "product probas: [0.3480188464221352, 0.0023246217312739527, 0.00026414825962836505]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 174  Proba:  [0.96404953 0.02175684 0.01419363]\n",
      "y2 not aggreed on  174 Proba:  [0.35173084 0.23445039 0.41381877]\n",
      "product probas: [0.3390859527865561, 0.005100899865604478, 0.0058735916216620465]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 181  Proba:  [9.97633450e-01 7.96047912e-04 1.57050248e-03]\n",
      "y2 not aggreed on  181 Proba:  [0.35173084 0.23445039 0.41381877]\n",
      "product probas: [0.35089845458585783, 0.00018663374019873205, 0.0006499034035858511]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 185  Proba:  [9.48802346e-01 5.08738301e-02 3.23823514e-04]\n",
      "y2 not aggreed on  185 Proba:  [0.35173084 0.23445039 0.41381877]\n",
      "product probas: [0.33372304945908915, 0.01192738911322678, 0.00013400424862636853]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 189  Proba:  [0.44269051 0.51847157 0.03883793]\n",
      "y2 not aggreed on  189 Proba:  [9.64089210e-01 3.56575380e-02 2.53251953e-04]\n",
      "product probas: [0.4267931400845625, 0.01848741960582582, 9.835780840463717e-06]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 192  Proba:  [0.87906579 0.11989343 0.00104078]\n",
      "y2 not aggreed on  192 Proba:  [0.10557481 0.8614535  0.03297168]\n",
      "product probas: [0.0928072083924142, 0.10328261193438605, 3.431631491557615e-05]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 193  Proba:  [6.72194943e-04 9.89144217e-01 1.01835877e-02]\n",
      "y2 not aggreed on  193 Proba:  [0.35173084 0.23445039 0.41381877]\n",
      "product probas: [0.0002364316941743509, 0.23190524365345455, 0.004214159743060842]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 194  Proba:  [0.45775991 0.54148372 0.00075636]\n",
      "y2 not aggreed on  194 Proba:  [5.78901587e-01 4.21058460e-01 3.99532494e-05]\n",
      "product probas: [0.26499794115859227, 0.22799630267819668, 3.021909417189932e-08]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 199  Proba:  [0.5764134  0.42108289 0.00250371]\n",
      "y2 not aggreed on  199 Proba:  [0.33814518 0.2478715  0.41398332]\n",
      "product probas: [0.19491141384424415, 0.10437444488594101, 0.0010364955266521023]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 208  Proba:  [0.07863009 0.45788221 0.4634877 ]\n",
      "y2 not aggreed on  208 Proba:  [0.77343185 0.21306892 0.01349923]\n",
      "product probas: [0.06081501788080666, 0.09756047038290508, 0.006256725596609637]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 210  Proba:  [0.17228537 0.80055451 0.02716012]\n",
      "y2 not aggreed on  210 Proba:  [0.82536369 0.16653592 0.00810039]\n",
      "product probas: [0.14219808816738236, 0.13332107952102337, 0.00022000751598593633]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 215  Proba:  [0.68117481 0.05590017 0.26292501]\n",
      "y2 not aggreed on  215 Proba:  [0.35173084 0.23445039 0.41381877]\n",
      "product probas: [0.2395901914129037, 0.013105817140102049, 0.1088033060852846]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "y1 disagree on 221  Proba:  [0.50051601 0.38618533 0.11329867]\n",
      "y2 not aggreed on  221 Proba:  [0.00299193 0.81906506 0.17794301]\n",
      "product probas: [0.0014975086171004777, 0.3163109096177549, 0.020160705358005127]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 224  Proba:  [0.002353   0.99650738 0.00113962]\n",
      "y2 not aggreed on  224 Proba:  [0.33549926 0.31919447 0.34530628]\n",
      "product probas: [0.0007894302331717205, 0.3180796395345429, 0.00039351888448887806]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 245  Proba:  [0.10341566 0.87334638 0.02323796]\n",
      "y2 not aggreed on  245 Proba:  [0.39195187 0.26503777 0.34301036]\n",
      "product probas: [0.04053396255527993, 0.23146977508931832, 0.007970859706355285]\n",
      "result idx:  1  result:  0000-0002-5878-8895\n",
      "y1 disagree on 247  Proba:  [0.87161672 0.0881686  0.04021468]\n",
      "y2 not aggreed on  247 Proba:  [0.18146118 0.68176693 0.13677189]\n",
      "product probas: [0.15816459863148014, 0.060110433815211445, 0.005500237918901061]\n",
      "result idx:  0  result:  0000-0001-9498-284X\n",
      "[{'0000-0001-9498-284X': 52, '0000-0002-5878-8895': 57, '0000-0002-6929-5359': 54}, {'0000-0001-9498-284X': 57, '0000-0002-5878-8895': 58, '0000-0002-6929-5359': 55}]\n",
      "defaultdict(<class 'list'>, {'0000-0001-9498-284X': [52, 57], '0000-0002-5878-8895': [57, 58], '0000-0002-6929-5359': [54, 55]})\n",
      "defaultdict(<class 'list'>, {'0000-0001-9498-284X': 54.0, '0000-0002-5878-8895': 58.0, '0000-0002-6929-5359': 54.0})\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "0000-0001-9498-284X       0.94      0.97      0.96       154\n",
      "0000-0002-5878-8895       0.97      0.94      0.95       139\n",
      "0000-0002-6929-5359       1.00      1.00      1.00       211\n",
      "\n",
      "          micro avg       0.97      0.97      0.97       504\n",
      "          macro avg       0.97      0.97      0.97       504\n",
      "       weighted avg       0.97      0.97      0.97       504\n",
      "\n",
      "[149   4   1   9 130   0   0   0 211]\n",
      "lr macro f1:  0.9683816971051015\n",
      "Co-training self-labeled samples:  defaultdict(<class 'list'>, {'0000-0001-9498-284X': 54.0, '0000-0002-5878-8895': 58.0, '0000-0002-6929-5359': 54.0})\n"
     ]
    }
   ],
   "source": [
    "# load the file\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from statistics import mean \n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# loop through all files in directory add name to name list\n",
    "fileDir = \"../../Data/\"+Dataset+\"/canopies/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "\n",
    "co_lr_diff_embedding_result = []\n",
    "\n",
    "# # ------------ view two citation is fix, so move out to save time ------- #\n",
    "# # read viewtwo embedding\n",
    "# print(\"Load citation embedding: \", pp_citation)\n",
    "# viewtwo_citation_embedding = com_func.read_all_citation_embedding_sorted(emb_type = pp_citation)\n",
    "\n",
    "for select_emb in pp_textual:\n",
    "#     #---------------- load embeddings for different view ---------------#\n",
    "#     print(\"Load textual embedding: \", select_emb)\n",
    "#     # read viewone embeddings\n",
    "#     viewone_textual_emb = com_func.read_all_textual_embedding_sorted(emb_type=select_emb, training_size = \"3m\")\n",
    "\n",
    "    threshold_change_all_co_lr_f1s = []\n",
    "    threshold_change = []\n",
    "    \n",
    "    # -------------- different threshold (step by 10) -----------------------#\n",
    "    for step_threshold in range(threshold_lower, threshold_upper, 10):\n",
    "        threshold_change.append(step_threshold)\n",
    "        # collect statistic to output\n",
    "        allname, num_class, per_class_count, all_labeled_count, selected_labeled_count, unlabeled_count = ([] for i in range(6))\n",
    "\n",
    "        all_co_LR_accuracy, all_co_LR_f1, co_train_generated_label_details= ([] for i in range(3))\n",
    "\n",
    "        total_selected_group = 0\n",
    "\n",
    "        # ------- different name group in all name group --------------------#\n",
    "        for file in listfiles:\n",
    "            # group name\n",
    "            temp = file.split(\"_\")\n",
    "            name = temp[1]+\"_\"+temp[-1]\n",
    "            print(\"For name: \",name)\n",
    "            # read pid and aid from file\n",
    "            data = com_func.read_pid_aid(fileDir+file)\n",
    "            labeled_mask = data[\"authorID\"] != \"-1\"\n",
    "            labeled_data = data[labeled_mask]\n",
    "            unlabeled_mask = data[\"authorID\"] == \"-1\"\n",
    "            ublabeled_data = data[unlabeled_mask]\n",
    "            unlabeled_pid = ublabeled_data[\"paperID\"]\n",
    "            print(len(unlabeled_pid))\n",
    "            print(labeled_data.shape)\n",
    "            #----------- select name group contain productive author------------------------------------#\n",
    "            #----------- (contain pair of author write more than 100 papers) ---------------------------#\n",
    "            # count number of paper each author write based on author ID\n",
    "            authorCounter = com_func.select_productive_groups(labeled_data, threshold_select_name_group)\n",
    "            # if only have one class or no class pass the threshold, not applicable\n",
    "            if(len(authorCounter)==0) or (len(authorCounter)==1):\n",
    "                print(name, \" pass\")\n",
    "            else:\n",
    "                all_labeled_count.append(len(labeled_data))\n",
    "                total_selected_group+= 1\n",
    "                labeled_data, author_list, paperCounter= com_func.only_select_productive_authors(labeled_data, step_threshold)\n",
    "                allname.append(name)\n",
    "                num_class.append(len(paperCounter))\n",
    "                per_class_count.append(paperCounter)\n",
    "\n",
    "                # -------------- extract all samples for name group -------------- #\n",
    "                # for each name group\n",
    "                # read in labeled data\n",
    "                labeled_viewone_textual = com_func.extract_sorted_embedding(viewone_textual_emb, labeled_data[\"paperID\"])\n",
    "                print(labeled_viewone_textual.shape)\n",
    "                labeled_viewtwo_citation = com_func.extract_sorted_embedding(viewtwo_citation_embedding, labeled_data[\"paperID\"])\n",
    "                print(labeled_viewtwo_citation.shape)\n",
    "                print(\"Labeled: \",len(labeled_viewone_textual), \" : \", len(labeled_viewtwo_citation))\n",
    "\n",
    "                # read in unlabeled data\n",
    "                unlabeled_viewone_textual = com_func.extract_unlabeled_embedding(viewone_textual_emb, unlabeled_pid)\n",
    "                print(unlabeled_viewone_textual.shape)\n",
    "                unlabeled_viewtwo_citation = com_func.extract_unlabeled_embedding(viewtwo_citation_embedding, unlabeled_pid)\n",
    "                print(unlabeled_viewtwo_citation.shape)\n",
    "                print(\"Unlabeled: \",len(unlabeled_viewone_textual), \" : \", len(unlabeled_viewtwo_citation))\n",
    "                # remove samples that have no citation link from ublabeled data\n",
    "                noCitationPids_unlabeled = set(unlabeled_viewone_textual['paperID'])-set(unlabeled_viewtwo_citation['paperID'])\n",
    "                print(\"Unlabeled no citation link size: \", len(noCitationPids_unlabeled))\n",
    "                # process unlabeled data\n",
    "                unlabeled_dv1 = unlabeled_viewone_textual[~unlabeled_viewone_textual['paperID'].isin(noCitationPids_unlabeled)].reset_index(drop=True)\n",
    "                unlabeled_dv2 = unlabeled_viewtwo_citation\n",
    "                \n",
    "                # ---------------- shuffle the data ----------------- #\n",
    "                labeled_data = labeled_data.sample(frac=1).reset_index(drop=True)\n",
    "                # ------------------ alignment ---------------------- #\n",
    "                labeled_viewone_textual = pd.merge(labeled_data, labeled_viewone_textual, left_on=\"paperID\", right_on = [0], how = \"left\")\n",
    "                labeled_viewtwo_citation = pd.merge(labeled_data, labeled_viewtwo_citation, left_on=\"paperID\", right_on = [0], how = \"left\")\n",
    "                labeled_viewtwo_citation.fillna(0, inplace=True)\n",
    "                \n",
    "                labeled_viewone_textual = labeled_viewone_textual.drop([0], axis=1)\n",
    "                labeled_viewtwo_citation = labeled_viewtwo_citation.drop([0], axis=1)\n",
    "                \n",
    "                #print(labeled_viewone_textual.head())\n",
    "                #print(unlabeled_dv1.head())\n",
    "                \n",
    "                print(labeled_viewone_textual.shape)\n",
    "                print(labeled_viewtwo_citation.shape)\n",
    "                print(unlabeled_dv1.shape)\n",
    "                print(unlabeled_dv2.shape)\n",
    "                unlabeled_count.append(unlabeled_dv1.shape[0])\n",
    "                selected_labeled_count.append(labeled_viewone_textual.shape[0])\n",
    "                # ---------------------- 10 fold cv ------------------------------------------------- #\n",
    "                co_logistic_clf = Multi_Class_Co_training(clf1=LogisticRegression(multi_class='ovr'))\n",
    "                co_lr_accuracy, co_lr_f1, all_fold_averaged_generated_train = k_fold_cv_co_train(labeled_viewone_textual, \n",
    "                                                                                                 labeled_viewtwo_citation,\n",
    "                                                                                                 unlabeled_dv1, unlabeled_dv2,\n",
    "                                                                                                 labeled_data[\"authorID\"], \n",
    "                                                                                                 co_logistic_clf, k=2)\n",
    "                print(\"lr macro f1: \",co_lr_f1)\n",
    "                print(\"Co-training self-labeled samples: \", all_fold_averaged_generated_train)\n",
    "                all_co_LR_accuracy.append(co_lr_accuracy)\n",
    "                all_co_LR_f1.append(co_lr_f1)\n",
    "                co_train_generated_label_details.append(all_fold_averaged_generated_train)\n",
    "                break\n",
    "                \n",
    "#         # write evaluation result to excel\n",
    "#         output = pd.DataFrame({'Name Group':allname,\"Class number\":num_class, \"Per class size\":per_class_count, \n",
    "#                                \"Total labeled samples\":all_labeled_count, \"Total unlabeled samples\":unlabeled_count, \n",
    "#                                \"selected labeled samples\": selected_labeled_count,\n",
    "#                                \"Co-training self-labeled samples\": co_train_generated_label_details, \n",
    "#                                \"co-train with lr accuracy\":all_co_LR_accuracy, \"co-train with lr f1\": all_co_LR_f1})\n",
    "\n",
    "#         savePath = \"../../result/\"+Dataset+\"/co_train/\"\n",
    "#         filename = \"(Global emb sample 3m) viewone_textual=\"+select_emb+\"_viewtwo_citation=\"+pp_citation+\"_threshold=\"+str(step_threshold)+\"_namegroupcount=\"+str(total_selected_group)+\".csv\"\n",
    "#         com_func.write_csv_df(savePath, filename, output)\n",
    "#         print(\"Done\")\n",
    "        \n",
    "#         threshold_change_all_co_lr_f1s.append(all_co_LR_f1)\n",
    "#     co_lr_diff_embedding_result.append(threshold_change_all_co_lr_f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T18:44:12.922301Z",
     "start_time": "2019-02-16T18:44:12.911782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0000-0001-9498-284X': 59, '0000-0002-5878-8895': 59, '0000-0002-6929-5359': 55}\n",
      "{'0000-0001-9498-284X': 58, '0000-0002-5878-8895': 57, '0000-0002-6929-5359': 54}\n",
      "defaultdict(<class 'list'>, {'0000-0001-9498-284X': [59, 58], '0000-0002-5878-8895': [59, 57], '0000-0002-6929-5359': [55, 54]})\n"
     ]
    }
   ],
   "source": [
    "all_fold_averaged_generated_train = defaultdict(list)\n",
    "test = [{'0000-0001-9498-284X': 59, '0000-0002-5878-8895': 59, '0000-0002-6929-5359': 55}, {'0000-0001-9498-284X': 58, '0000-0002-5878-8895': 57, '0000-0002-6929-5359': 54}]\n",
    "for per_fold_count_dic in test:\n",
    "    for key, value in per_fold_count_dic.items():\n",
    "        all_fold_averaged_generated_train[key].append(value)\n",
    "    print(per_fold_count_dic)\n",
    "print(all_fold_averaged_generated_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T18:30:19.652579Z",
     "start_time": "2019-02-16T18:30:02.180Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T14:00:02.559218Z",
     "start_time": "2019-01-13T14:00:00.967099Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#               # ------------------- train test split ------------------------------ --------------#\n",
    "#                 # ------------------- train test split 1:9 ratio -----------------------------------#\n",
    "#                 dv1_train, dv1_test, dv_y_train, dv1_y_test = train_test_split(sorted_dv1, labeled_data[\"authorID\"], \n",
    "#                                                                     test_size=0.1, stratify = labeled_data[\"authorID\"])\n",
    "#                 # get index of train and test\n",
    "#                 train_index = dv_y_train.index.tolist()\n",
    "#                 test_index = dv1_y_test.index.tolist()\n",
    "#                 dv2_train, dv2_test = sorted_dv2.iloc[train_index], sorted_dv2.iloc[test_index]\n",
    "#                 # ----------------------add ublabeled data to labeled to form final train set---------#\n",
    "#                 # rename authorID as label\n",
    "#                 print(\"labeled size: \", sorted_dv1.shape)\n",
    "#                 print(\"unlabeled size: \", unlabeled_dv1.shape)\n",
    "#                 print(dv1_train.head())\n",
    "#                 final_dv1 = pd.concat([dv1_train,unlabeled_dv1], ignore_index=True)\n",
    "#                 final_dv2 = pd.concat([dv2_train,unlabeled_dv2], ignore_index=True)\n",
    "#                 print(final_dv1.head())\n",
    "#                 print(final_dv1.shape)\n",
    "#                 # get pid and labels for true labels\n",
    "#                 test_true_label =labeled_data[\"authorID\"].iloc[test_index]\n",
    "#                 dv1_test.drop([\"authorID\", \"paperID\"], axis=1, inplace = True)\n",
    "#                 dv2_test.drop([\"authorID\", \"paperID\"], axis=1, inplace = True)\n",
    "#                 # ----------------------------------- ovr co-training --------------------------------#\n",
    "#                 # co-training with logistic regression\n",
    "#                 co_logistic_clf = Co_training_clf(clf1=LogisticRegression(),p=1,n=1)\n",
    "#                 co_lr_clf_ovr = co_train_one_vs_rest().fit_one_vs_rest(final_dv1, final_dv2, co_logistic_clf)\n",
    "#                 co_lr_label_predict = co_lr_clf_ovr.predict(dv1_test, dv2_test)\n",
    "#                 co_lr_accuracy = accuracy_score(test_true_label, co_lr_label_predict)\n",
    "#                 co_lr_f1 = f1_score(test_true_label, co_lr_label_predict,average='macro')\n",
    "#                 print(\"lr macro f1: \",co_lr_f1)\n",
    "#                 all_co_LR_accuracy.append(co_lr_accuracy)\n",
    "#                 all_co_LR_f1.append(co_lr_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
