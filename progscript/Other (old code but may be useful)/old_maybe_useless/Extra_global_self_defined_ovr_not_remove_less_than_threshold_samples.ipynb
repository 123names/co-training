{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T16:55:40.706022Z",
     "start_time": "2019-01-12T16:55:39.093280Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import com_func\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "# parameters\n",
    "threshold = 30\n",
    "cutoff = 3\n",
    "\n",
    "pp_textual = \"tf\"\n",
    "\n",
    "Dataset = \"pubmed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T16:55:41.574554Z",
     "start_time": "2019-01-12T16:55:40.708847Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim\n",
    "# read trained rec to rec textual graph\n",
    "def read_textual_embedding(Dataset = \"pubmed\", emb_type = \"off\"):\n",
    "    textual_emb = []\n",
    "    emb_pid = []\n",
    "    while True:\n",
    "        if emb_type == \"tf\":\n",
    "            modelSaveDir = \"../Data/\"+Dataset+\"/models/tf/textual_sample=140k/\"\n",
    "            with open(modelSaveDir+'tf_features.pickle', \"rb\") as input_file:\n",
    "                vec = pickle.load(input_file)\n",
    "            with open(modelSaveDir+'feature_pid.pickle', \"rb\") as input_file:\n",
    "                allPaperid = pickle.load(input_file)\n",
    "            textual_emb = vec.toarray()\n",
    "            emb_pid = allPaperid\n",
    "            break\n",
    "        elif emb_type == \"tfidf\":\n",
    "            modelSaveDir = \"../Data/\"+Dataset+\"/models/tf_idf/textual_sample=140k/\"\n",
    "            with open(modelSaveDir+'tf_idf_trained_features.pickle', \"rb\") as input_file:\n",
    "                vec = pickle.load(input_file)\n",
    "            with open(modelSaveDir+'feature_pid.pickle', \"rb\") as input_file:\n",
    "                allPaperid = pickle.load(input_file)\n",
    "            textual_emb = vec.toarray()\n",
    "            emb_pid = allPaperid\n",
    "            break\n",
    "        elif emb_type == \"lsa\":\n",
    "            modelSaveDir = \"../Data/\"+Dataset+\"/models/lsa/textual_sample=140k/\"\n",
    "            with open(modelSaveDir+'lsa_Matrix.pickle', \"rb\") as input_file:\n",
    "                vec = pickle.load(input_file)\n",
    "            with open(modelSaveDir+'feature_pid.pickle', \"rb\") as input_file:\n",
    "                allPaperid = pickle.load(input_file)\n",
    "            textual_emb = vec\n",
    "            emb_pid = allPaperid\n",
    "            break\n",
    "        elif emb_type == \"pv_dm\":\n",
    "            modelSaveDir = \"../Data/\"+Dataset+\"/models/doc2v/textual_sample=140k/\"\n",
    "            model = gensim.models.Doc2Vec.load(modelSaveDir+\"pv_dm/Doc2Vec(dmm,d100,n5,w5,mc2,s0.001,t24)\")\n",
    "            allPaperTags = model.docvecs.offset2doctag\n",
    "            for pid in allPaperTags:\n",
    "                vectorRepresentation = model.docvecs[pid].tolist()\n",
    "                vectorRepresentation = [float(i) for i in vectorRepresentation]\n",
    "                textual_emb.append(vectorRepresentation)\n",
    "            emb_pid = allPaperTags\n",
    "            break\n",
    "        elif emb_type == \"pv_dbow\":\n",
    "            modelSaveDir = \"../Data/\"+Dataset+\"/models/doc2v/textual_sample=140k/\"\n",
    "            model = gensim.models.Doc2Vec.load(modelSaveDir+\"pv_dbow/Doc2Vec(dbow,d100,n5,mc2,s0.001,t24)\")\n",
    "\n",
    "            allPaperTags = model.docvecs.offset2doctag\n",
    "            for pid in allPaperTags:\n",
    "                vectorRepresentation = model.docvecs[pid].tolist()\n",
    "                vectorRepresentation = [float(i) for i in vectorRepresentation]\n",
    "                textual_emb.append(vectorRepresentation)\n",
    "            emb_pid = allPaperTags\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    print(\"Total textual vector records:\",len(textual_emb))\n",
    "    print(\"Vector dimension: \", len(textual_emb[0]))\n",
    "    return textual_emb, emb_pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T16:55:41.612375Z",
     "start_time": "2019-01-12T16:55:41.577417Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_embedding(all_embedding, all_embedding_pid, wanted_pid_list):\n",
    "    extracted_emb = []\n",
    "    wanted_pid_list = wanted_pid_list.values.tolist()\n",
    "    total_missing_sample = 0\n",
    "    # only if embedding exist\n",
    "    if len(all_embedding)>0:\n",
    "        # loop through wanted pid list to keep input order\n",
    "        for wanted_pid in wanted_pid_list:\n",
    "            # if wanted paper in all pretrained embeddings\n",
    "            if wanted_pid in all_embedding_pid:\n",
    "                emb_idx = all_embedding_pid.index(wanted_pid)\n",
    "                extracted_emb.append(all_embedding[emb_idx])\n",
    "            # if wanted paper not in all pretrained embeddings, fill missing sample with 0's\n",
    "            else:\n",
    "                total_missing_sample+=1\n",
    "                print(\"Missing Sample: \", wanted_pid)\n",
    "                temp = [0] * len(all_embedding[0])\n",
    "                extracted_emb.append(temp)\n",
    "    print(\"Total missing sample: \", total_missing_sample)\n",
    "    extracted_emb = pd.DataFrame(extracted_emb)\n",
    "    return extracted_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T16:55:41.634585Z",
     "start_time": "2019-01-12T16:55:41.614712Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy(doc):\n",
    "    return doc\n",
    "def read_labeled_file(infile):\n",
    "    LabeledRecords_original = []\n",
    "    with open(infile, 'r', encoding = 'utf8') as f:\n",
    "        for line in f:\n",
    "            read_data = line.split(\"\\t\")\n",
    "            # get ride of bad formated lines\n",
    "            if(len(read_data)==13 or len(read_data)==12):\n",
    "                paper_detail = {\"paperID\": read_data[0], \"authorID\":read_data[1], \n",
    "                                \"co-author\": read_data[5], \"venue_id\": read_data[7]}\n",
    "                LabeledRecords_original.append(paper_detail)\n",
    "            else:\n",
    "                print(len(read_data))\n",
    "        f.close()\n",
    "    return pd.DataFrame(LabeledRecords_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T16:55:41.641880Z",
     "start_time": "2019-01-12T16:55:41.636785Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove author(positive sample) from other(negative sample)\n",
    "import random\n",
    "def extractNegativeSample(positiveSample, allSample):\n",
    "    negativeSample = [x for x in allSample if x not in positiveSample]\n",
    "    return negativeSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T16:55:41.717685Z",
     "start_time": "2019-01-12T16:55:41.666487Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "# cross validation\n",
    "def k_fold_cv(data, label, clf, k=10):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=False)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel = []\n",
    "    for train_index, test_index in kf.split(data, label):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data[train_index], data[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        # fit data to clf\n",
    "        clf.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = clf.predict(data_test)\n",
    "        allTrueLabel.extend(label_test)\n",
    "        allPredLabel.extend(label_pred)\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "\n",
    "    accuracy = accuracy_score(allTrueLabel, allPredLabel)\n",
    "    f1 = f1_score(allTrueLabel, allPredLabel,average='macro')\n",
    "    \n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel).ravel())\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T17:05:30.896248Z",
     "start_time": "2019-01-12T17:05:30.323619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "# self defined one vs rest\n",
    "class one_vs_rest:\n",
    "    \n",
    "    def __init__ (self):\n",
    "        self.binary_clf = []\n",
    "\n",
    "    def fit_one_vs_rest(self, train_data, labeled_data, clf, clf_type):\n",
    "        self.clf_type = clf_type\n",
    "        self.classes = np.unique(labeled_data[\"authorID\"]).tolist()\n",
    "        # check for \"RARE_VALUE\" special marker that only used for train binary classifier, not creating new class\n",
    "        for author in self.classes:\n",
    "            if author ==\"RARE_VALUE\":\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Binary clf: \", author)\n",
    "                mask = labeled_data[\"authorID\"] == author\n",
    "                temp = labeled_data[mask]\n",
    "                positive_sample_pid = temp[\"paperID\"].tolist()\n",
    "                negative_sample_pid = extractNegativeSample(positive_sample_pid, all_labeled_sample)\n",
    "                # append to statistic collection\n",
    "                positive_sample_size.append(len(positive_sample_pid))\n",
    "                negative_sample_size.append(len(negative_sample_pid))\n",
    "                # form positive and negative (negative class come from similar name group)\n",
    "                all_authors = []\n",
    "                all_authors.append(positive_sample_pid)\n",
    "                all_authors.append(negative_sample_pid)\n",
    "                appended_data = []\n",
    "                for label, pid in enumerate(all_authors):\n",
    "                    # create df save one author data \n",
    "                    authordf = pd.DataFrame({\"paperID\":pid})\n",
    "                    authordf['label'] = label\n",
    "                    appended_data.append(authordf)\n",
    "                processed_data = pd.concat(appended_data, axis=0,ignore_index=True)\n",
    "                \n",
    "                # alignment \n",
    "                processed_data = pd.merge(labeled_data[\"paperID\"].to_frame(), processed_data, on=\"paperID\")\n",
    "                \n",
    "                # extract true label and it's corresponeding pid for check\n",
    "                label = processed_data[\"label\"]\n",
    "                pid = processed_data[\"paperID\"]\n",
    "                \n",
    "\n",
    "#                 LRaccuracy, LRmarcof1 = k_fold_cv(train_data, label, clf, k=10)\n",
    "#                 print(\"LR Accuracy: \",LRaccuracy)\n",
    "#                 print(\"LR F1: \", LRmarcof1)\n",
    "\n",
    "                # using converted feature vector to train classifier\n",
    "                traing_clf = clone(clf)\n",
    "                traing_clf.fit(train_data, label)\n",
    "                print(traing_clf.coef_)\n",
    "                self.binary_clf.append(traing_clf)\n",
    "        self.classes.remove('RARE_VALUE')\n",
    "        return self\n",
    "        \n",
    "    def predict(self, data_to_predict):\n",
    "        author_proba = pd.DataFrame()\n",
    "        for author, author_clf in zip(self.classes, self.binary_clf):\n",
    "            # only look at probability of 0 (belone to that author)\n",
    "            if self.clf_type in [\"Logistic\", \"prob_svm\"]:\n",
    "                author_proba[author] = author_clf.predict_proba(data_to_predict)[:,0]\n",
    "            # distance for svm\n",
    "            elif self.clf_type == \"SVM\":\n",
    "                print(author_clf.decision_function(data_to_predict).shape)\n",
    "                author_proba[author] = author_clf.decision_function(data_to_predict)\n",
    "        # for author less than threshold number of samples\n",
    "        self.predict_proba = author_proba\n",
    "        print(self.predict_proba)\n",
    "        if self.clf_type in [\"Logistic\", \"prob_svm\"]:\n",
    "            labels = author_proba.idxmax(axis=1).values\n",
    "        elif self.clf_type == \"SVM\":\n",
    "            labels = author_proba.idxmin(axis=1).values\n",
    "        return labels\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T17:05:39.838019Z",
     "start_time": "2019-01-12T17:05:30.900556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embedding:  pv_dm\n",
      "Total textual vector records: 135796\n",
      "Vector dimension:  100\n",
      "For name:  j_read\n",
      "Total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5159-1192': 57, '0000-0002-9029-5185': 39, '0000-0002-9697-0962': 31, '0000-0002-4739-9245': 3, '0000-0003-0605-5259': 3, '0000-0003-4316-7006': 1, '0000-0002-0784-0091': 1, '0000-0002-3888-6631': 1})\n",
      "Total author before apply threshoid:  8\n",
      "['0000-0002-9697-0962', '0000-0002-9029-5185', '0000-0002-5159-1192']\n",
      "Total author after apply threshoid:  3\n",
      "Total missing sample:  0\n",
      "(136, 100)\n",
      "1\n",
      "(136, 100)\n",
      "Binary clf:  0000-0002-5159-1192\n",
      "[[ 0.02222388  0.17957971  0.12327487  0.23665527  0.46883194 -0.46871769\n",
      "  -0.35149199  0.08322612 -0.41095083  0.11814027 -0.44210205  0.46083861\n",
      "  -0.02273823  0.23913143  0.18668481 -0.34983477 -0.03687433  0.25842248\n",
      "  -0.21655542 -0.16086778  0.25058371 -0.22296218 -0.26438318 -0.13153422\n",
      "  -0.49796063 -0.08962691  0.44790371  0.58694331  0.38215174 -0.05784242\n",
      "  -0.62307023 -0.61337599  0.20895517 -0.22721995  0.24706036 -0.0373874\n",
      "   0.28300871  0.08945816 -0.0293282  -0.05701937  0.02262227  0.46903002\n",
      "   0.37207954  0.24843119  0.54657196 -0.0790218  -0.19046497 -0.19715731\n",
      "  -0.18390053  0.52672865  0.22830802  0.10775715 -0.98213275  0.31538512\n",
      "   0.35238621  0.07196809  0.06223964 -0.53909907  0.4682859   0.39138565\n",
      "  -0.49519187  0.18760779 -0.62348763 -0.19212286  0.16740137 -0.03337849\n",
      "   0.31671053 -0.14362762 -0.37229562 -0.11474156 -0.46172981  0.13106919\n",
      "   0.22424854  0.17892048 -0.36236513  0.58193541  0.59880933  0.24331298\n",
      "   0.42681133 -0.14694673  0.18629373  0.32100884 -0.02855937  0.204599\n",
      "  -0.14569496  0.17800424 -0.00306871  0.16663169  0.01424133  0.20896431\n",
      "   0.08879314 -0.35667008 -0.06480463  0.57091156  0.4319679  -0.07022329\n",
      "  -0.22995938 -0.16401683  0.63838292  0.21139562]]\n",
      "Binary clf:  0000-0002-9029-5185\n",
      "[[-0.19122078 -0.10899537 -0.53312808 -0.63785614 -0.15598029  0.21860785\n",
      "   0.23579754 -0.4591154   0.02932534  0.53139953  0.58621337 -0.00468046\n",
      "  -0.02867332 -0.06635512  0.07623743  0.13099393 -0.14951051 -0.53219405\n",
      "  -0.16657238 -0.06463401 -0.16641472  0.55375093  0.15059275  0.05767935\n",
      "   0.20780562  0.41035785 -0.0765219  -0.29486578 -0.45832064  0.2869035\n",
      "   0.35566807 -0.18070371 -0.00191908  0.16467785 -0.04122021  0.07662184\n",
      "   0.1981044  -0.52253014  0.10080127  0.10630401  1.08940427 -0.07329862\n",
      "  -0.16240028 -0.24985986 -0.2558125  -0.02170314  0.22354635 -0.02431781\n",
      "   0.32930351 -0.28195263 -0.62893806  0.06995285  0.71367234  0.18920387\n",
      "  -0.05276786  0.03043048  0.09559816 -0.0620247  -0.26519452 -0.05301069\n",
      "   0.46349589 -0.03932191 -0.14375129  0.18521378  0.20427795  0.11928376\n",
      "  -0.01664978  0.54044196  0.06098802  0.03343549  0.30442563 -0.34482117\n",
      "  -0.06492159 -0.30938567  0.03915777 -0.20234158 -0.28780701 -0.0934407\n",
      "  -0.17277217 -0.00476306 -0.16210957 -0.25038662 -0.59346704 -0.21391568\n",
      "  -0.16038177 -0.11835852 -0.27835837 -0.35838736  0.45307817 -0.14262567\n",
      "  -0.2143007  -0.15242593  0.01987633 -0.15579317  0.13461936  0.33963951\n",
      "  -0.04049606 -0.19119065 -0.38378502 -0.38704987]]\n",
      "Binary clf:  0000-0002-9697-0962\n",
      "[[ 0.16434771  0.02148303 -0.01443621  0.61715771  0.03552951 -0.22379185\n",
      "   0.01932041  0.08645369  0.27044066 -0.24839875 -0.18215667  0.20166437\n",
      "   0.27896692 -0.49368276  0.18087034  0.54212225 -0.06946397  0.30437937\n",
      "   0.09443616  0.13644158 -0.25383569  0.01584923 -0.03402178 -0.18492772\n",
      "   0.45283625  0.02113728 -0.48445509 -0.43018    -0.12795385 -0.23430021\n",
      "   0.1111101   0.77467557 -0.08688287 -0.19390003  0.04594412  0.02774006\n",
      "   0.11998299  0.63764817 -0.04606575  0.09863892 -0.47322734 -0.22010447\n",
      "  -0.33775928 -0.19585267 -0.4131575   0.1835016   0.02333935  0.02229468\n",
      "  -0.01134691 -0.25531522 -0.09735293  0.07206696  0.15495696 -0.13616989\n",
      "  -0.19060709 -0.04597973 -0.24853337  0.62154973 -0.06704947  0.24541315\n",
      "   0.00573277 -0.29175212  0.34844089  0.03589125 -0.76149473 -0.14348708\n",
      "  -0.43772325 -0.07621714  0.16764299  0.05999617 -0.19346242 -0.07633425\n",
      "   0.05369545 -0.16819443 -0.01897495 -0.00842713 -0.53496648 -0.00382036\n",
      "  -0.21219562  0.459645   -0.129884   -0.3712129   0.13503924  0.15534264\n",
      "   0.29312328 -0.52805507 -0.14195786 -0.01403459 -0.70276931  0.2265525\n",
      "   0.25096749  0.407794    0.13462058 -0.34850921 -0.12510339 -0.17073868\n",
      "   0.69370571  0.1089956   0.25243185 -0.28336916]]\n",
      "    0000-0002-5159-1192  0000-0002-9029-5185  0000-0002-9697-0962\n",
      "0              0.000624             0.999986             0.000401\n",
      "1              0.000173             0.997993             0.003530\n",
      "2              0.007623             0.000719             0.961575\n",
      "3              0.884026             0.154715             0.051547\n",
      "4              0.998434             0.009810             0.002393\n",
      "5              0.037131             0.365131             0.165486\n",
      "6              0.999405             0.022626             0.000324\n",
      "7              0.007173             0.001310             0.988495\n",
      "8              0.993880             0.003247             0.008481\n",
      "9              0.011104             0.990568             0.000087\n",
      "10             0.766855             0.128353             0.121794\n",
      "11             0.946668             0.009980             0.016915\n",
      "12             0.000376             0.995047             0.040151\n",
      "13             0.082217             0.015834             0.916288\n",
      "['0000-0002-9029-5185' '0000-0002-9029-5185' '0000-0002-9697-0962'\n",
      " '0000-0002-5159-1192' '0000-0002-5159-1192' '0000-0002-9029-5185'\n",
      " '0000-0002-5159-1192' '0000-0002-9697-0962' '0000-0002-5159-1192'\n",
      " '0000-0002-9029-5185' '0000-0002-5159-1192' '0000-0002-5159-1192'\n",
      " '0000-0002-9029-5185' '0000-0002-9697-0962']\n",
      "60     0000-0002-9029-5185\n",
      "34     0000-0002-9029-5185\n",
      "128    0000-0002-9697-0962\n",
      "122    0000-0002-5159-1192\n",
      "61     0000-0002-5159-1192\n",
      "74              RARE_VALUE\n",
      "86     0000-0002-5159-1192\n",
      "88     0000-0002-9697-0962\n",
      "72     0000-0002-5159-1192\n",
      "28     0000-0002-9029-5185\n",
      "9      0000-0002-5159-1192\n",
      "110    0000-0002-5159-1192\n",
      "30     0000-0002-9029-5185\n",
      "101    0000-0002-9697-0962\n",
      "Name: authorID, dtype: object\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "0000-0002-5159-1192       1.00      1.00      1.00         6\n",
      "0000-0002-9029-5185       0.80      1.00      0.89         4\n",
      "0000-0002-9697-0962       1.00      1.00      1.00         3\n",
      "         RARE_VALUE       0.00      0.00      0.00         1\n",
      "\n",
      "          micro avg       0.93      0.93      0.93        14\n",
      "          macro avg       0.70      0.75      0.72        14\n",
      "       weighted avg       0.87      0.93      0.90        14\n",
      "\n",
      "LR Accuracy:  0.9285714285714286\n",
      "LR F1:  0.7222222222222222\n",
      "Binary clf:  0000-0002-5159-1192\n",
      "[[ 0.21719855  0.1284002   0.15740088  0.20670285  0.38680025 -0.14509423\n",
      "  -0.23640139  0.02001562 -0.09471575 -0.02244648 -0.35513452  0.31595217\n",
      "   0.02965728  0.15862762  0.37052093 -0.21964967  0.2716705   0.08126682\n",
      "  -0.01613624 -0.13159339  0.1001475   0.1399577  -0.14988552 -0.15389613\n",
      "  -0.27361464 -0.09742551  0.31200569  0.36606078  0.2106479   0.05453195\n",
      "  -0.55345507 -0.64515379  0.12286566 -0.11669318  0.11741966 -0.04471089\n",
      "   0.07635328  0.453894    0.0337565  -0.16425865  0.10303671  0.33127464\n",
      "   0.1618914   0.02464082  0.5186399   0.07570572  0.1769321  -0.41674762\n",
      "   0.13180106  0.30930109  0.09006413  0.13774796 -0.53190547  0.00096699\n",
      "   0.19997268  0.16433606  0.06810754 -0.51256975  0.19455925  0.27872678\n",
      "  -0.47438512  0.13970604 -0.4295378   0.12873701  0.03440312  0.05314356\n",
      "   0.22921238 -0.05363088 -0.21327591 -0.4111297  -0.44661404  0.03158746\n",
      "   0.23426736  0.05396939 -0.28549509  0.27295518  0.41154731 -0.07689263\n",
      "   0.17913358 -0.04570312 -0.04588105  0.11860173  0.18397103  0.09736567\n",
      "  -0.04287498 -0.00136038  0.04851005 -0.09373953  0.15440705  0.02600701\n",
      "   0.27622889 -0.20243328  0.1277797   0.0250142   0.18878333  0.04299694\n",
      "  -0.28964093  0.03325598  0.59728223 -0.04323481]]\n",
      "Binary clf:  0000-0002-9029-5185\n",
      "[[-0.30400901 -0.11518159 -0.18934298 -0.38680819 -0.06593601  0.13148733\n",
      "   0.07573385 -0.02617351 -0.02818578  0.21001925  0.46177705 -0.03674042\n",
      "  -0.08962699 -0.01762018  0.01866766  0.10664088 -0.13699952 -0.3053714\n",
      "  -0.04882883 -0.00957746  0.08634516 -0.09768204  0.11077943 -0.04381431\n",
      "   0.09797716  0.2591139   0.13722217 -0.16782401 -0.33832798  0.11712685\n",
      "   0.14162093  0.01962397 -0.04172728  0.06345352  0.03737737  0.14452472\n",
      "  -0.08854912 -0.45695814  0.06443399  0.06272841  0.49572376 -0.1295237\n",
      "  -0.10554048 -0.14609553 -0.28203953 -0.10196575 -0.10191007  0.27143705\n",
      "  -0.049238   -0.0260093  -0.22480704  0.08413475  0.19562967  0.21511254\n",
      "   0.21077968  0.00787029 -0.03276316  0.02816295 -0.07934458 -0.08483276\n",
      "   0.17192918  0.07575043 -0.11847088  0.15185595  0.24985653  0.15524617\n",
      "  -0.07988252  0.2909473  -0.04380797 -0.02722439  0.2163051  -0.09403139\n",
      "  -0.00086448 -0.21280998  0.03463269 -0.24389308 -0.19688593 -0.01396667\n",
      "  -0.09828414 -0.07048984  0.03987676 -0.00469454 -0.16780508 -0.24587282\n",
      "  -0.178591   -0.13176223 -0.08903749 -0.10669647  0.16750813 -0.03320335\n",
      "  -0.16754718 -0.0920755  -0.04716938 -0.07228118 -0.07621042  0.32000107\n",
      "  -0.02150677 -0.08505551 -0.36488955  0.07486892]]\n",
      "Binary clf:  0000-0002-9697-0962\n",
      "[[ 0.04174345 -0.02000081 -0.14134128  0.23728792 -0.20803512 -0.0868209\n",
      "   0.15866354 -0.08144257  0.21250939 -0.01790082 -0.29481484  0.03419238\n",
      "  -0.01643226 -0.24205771 -0.09563134  0.26945122 -0.25657451  0.22295961\n",
      "  -0.0301499   0.18044464 -0.08420557 -0.1550584  -0.26639132 -0.00728198\n",
      "   0.27354534  0.03505468 -0.35362434 -0.22773277  0.02405785 -0.13919774\n",
      "   0.0877792   0.55332619 -0.01968788 -0.1640762   0.04824903  0.07681326\n",
      "   0.15227701  0.22398458 -0.010572    0.01604153 -0.42861273 -0.15543251\n",
      "  -0.06001744 -0.0837198  -0.3500617  -0.09691118 -0.17772703  0.17773545\n",
      "  -0.02585681 -0.15480642 -0.11630478  0.07300303  0.11059545 -0.03260003\n",
      "  -0.28914815 -0.14615013 -0.34713584  0.4956559  -0.05478019  0.1553791\n",
      "   0.25223316 -0.26585915  0.3757782  -0.17572814 -0.46066399 -0.19954664\n",
      "  -0.05294795 -0.06155048  0.161487    0.15041611  0.02766808 -0.02286474\n",
      "  -0.06754663 -0.15408599  0.05769498  0.07732266 -0.18934648  0.10152692\n",
      "  -0.14161098  0.32693923 -0.07862177 -0.18351008 -0.00688918  0.25102889\n",
      "   0.08948033 -0.19979865  0.02683073  0.12018757 -0.37589853  0.07487361\n",
      "   0.21010537  0.19576948  0.04006071  0.09132563 -0.03308765 -0.08025909\n",
      "   0.53201268  0.0283559   0.09524739 -0.16680155]]\n",
      "    0000-0002-5159-1192  0000-0002-9029-5185  0000-0002-9697-0962\n",
      "0          2.310082e-06             0.999855         5.175809e-08\n",
      "1          8.414401e-08             0.996824         6.462825e-03\n",
      "2          1.445184e-02             0.004753         9.062466e-01\n",
      "3          8.450984e-01             0.076894         2.728938e-02\n",
      "4          9.936688e-01             0.064296         4.683156e-06\n",
      "5          1.204410e-02             0.355704         2.173562e-01\n",
      "6          9.923199e-01             0.253311         4.246573e-07\n",
      "7          7.425841e-02             0.000003         9.715287e-01\n",
      "8          9.723580e-01             0.009870         1.316153e-02\n",
      "9          7.746251e-02             0.977708         9.400079e-10\n",
      "10         7.584100e-01             0.077021         3.779364e-02\n",
      "11         9.814442e-01             0.013590         1.009471e-02\n",
      "12         5.154529e-07             0.957982         5.300782e-02\n",
      "13         1.445756e-01             0.080188         7.590514e-01\n",
      "['0000-0002-9029-5185' '0000-0002-9029-5185' '0000-0002-9697-0962'\n",
      " '0000-0002-5159-1192' '0000-0002-5159-1192' '0000-0002-9029-5185'\n",
      " '0000-0002-5159-1192' '0000-0002-9697-0962' '0000-0002-5159-1192'\n",
      " '0000-0002-9029-5185' '0000-0002-5159-1192' '0000-0002-5159-1192'\n",
      " '0000-0002-9029-5185' '0000-0002-9697-0962']\n",
      "60     0000-0002-9029-5185\n",
      "34     0000-0002-9029-5185\n",
      "128    0000-0002-9697-0962\n",
      "122    0000-0002-5159-1192\n",
      "61     0000-0002-5159-1192\n",
      "74              RARE_VALUE\n",
      "86     0000-0002-5159-1192\n",
      "88     0000-0002-9697-0962\n",
      "72     0000-0002-5159-1192\n",
      "28     0000-0002-9029-5185\n",
      "9      0000-0002-5159-1192\n",
      "110    0000-0002-5159-1192\n",
      "30     0000-0002-9029-5185\n",
      "101    0000-0002-9697-0962\n",
      "Name: authorID, dtype: object\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "0000-0002-5159-1192       1.00      1.00      1.00         6\n",
      "0000-0002-9029-5185       0.80      1.00      0.89         4\n",
      "0000-0002-9697-0962       1.00      1.00      1.00         3\n",
      "         RARE_VALUE       0.00      0.00      0.00         1\n",
      "\n",
      "          micro avg       0.93      0.93      0.93        14\n",
      "          macro avg       0.70      0.75      0.72        14\n",
      "       weighted avg       0.87      0.93      0.90        14\n",
      "\n",
      "SVC Accuracy:  0.9285714285714286\n",
      "SVC F1:  0.7222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# load the file\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "fileDir = \"../Data/\"+Dataset+\"/canopies_labeled/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "\n",
    "# different embeddings\n",
    "embeddings = [\"pv_dm\", \"pv_dbow\"]\n",
    "for select_emb in embeddings:\n",
    "    print(\"Load embedding: \", select_emb)\n",
    "    # read pretrained embeddings\n",
    "    pretrained_emb, pretrained_emb_pid = read_textual_embedding(emb_type=select_emb)\n",
    "    # collect statistic to output\n",
    "    allname, positive_sample_size, negative_sample_size = ([] for i in range(3))\n",
    "\n",
    "    all_LR_accuracy, all_LR_f1, all_svcLinear_accuracy, all_svcLinear_f1 = ([] for i in range(4))\n",
    "\n",
    "    # read all file in labeled group\n",
    "    for file in listfiles:\n",
    "        # group name\n",
    "        temp = file.split(\"_\")\n",
    "        name = temp[1]+\"_\"+temp[-1]\n",
    "        print(\"For name: \",name)\n",
    "        # read needed content in labeled file\n",
    "        labeled_data = read_labeled_file(fileDir+file)\n",
    "        # collect all labeled sample\n",
    "        all_labeled_sample = labeled_data[\"paperID\"].tolist()\n",
    "        print(\"Total sample size before apply threshold: \",len(labeled_data))\n",
    "        # count number of paper each author write based on author ID\n",
    "        paperCounter = collections.Counter(labeled_data[\"authorID\"])\n",
    "        print(paperCounter)\n",
    "        print(\"Total author before apply threshoid: \", len(paperCounter))\n",
    "        # collect per class statistic\n",
    "        for k in list(paperCounter):\n",
    "            if paperCounter[k] < threshold:\n",
    "                del paperCounter[k]\n",
    "        temp =list(paperCounter.keys())\n",
    "        print(temp)\n",
    "        # remove authors that write smaller than threshold number of authors\n",
    "        temp = labeled_data[labeled_data.authorID.isin(temp)]\n",
    "        author_list = set(temp[\"authorID\"])\n",
    "        print(\"Total author after apply threshoid: \", len(author_list))\n",
    "        # generate label for self defined one vs rest\n",
    "        labeled_data.loc[labeled_data[\"authorID\"].value_counts()[labeled_data[\"authorID\"]].values < 10, \"authorID\"] = \"RARE_VALUE\"\n",
    "        # if only have one class or no class pass the threshold, not applicable\n",
    "        if(len(paperCounter)==0) or (len(paperCounter)==1):\n",
    "            print(name,\" pass\")\n",
    "        else:\n",
    "            allname.append(name)\n",
    "            # shuffle the data\n",
    "            labeled_data = labeled_data.sample(frac=1).reset_index(drop=True)\n",
    "            # for each name group\n",
    "            # read in data\n",
    "            # list of different data field\n",
    "            part_collection = []\n",
    "            # select feature wanted to fit to clustering/classification algorithm\n",
    "            data_textual = extract_embedding(pretrained_emb, pretrained_emb_pid, labeled_data[\"paperID\"])\n",
    "            print(data_textual.shape)\n",
    "            part_collection.append(data_textual)\n",
    "            # merge different part of data data together by concatenate it all together\n",
    "            # remove empty emb (when emb set off)\n",
    "            part_collection = [part for part in part_collection if len(part)!=0]\n",
    "            print(len(part_collection))\n",
    "            if len(part_collection)>1:\n",
    "                combinedata = np.concatenate(part_collection,axis=1)\n",
    "            elif len(part_collection)==1:\n",
    "                if isinstance(part_collection[0], pd.DataFrame):\n",
    "                    combinedata = part_collection[0].values\n",
    "                else:\n",
    "                    combinedata = part_collection[0]\n",
    "            else:\n",
    "                print(\"No data available\")\n",
    "                break\n",
    "            print(combinedata.shape)\n",
    "            # train test split 1:9 ratio\n",
    "            X_train, X_test, y_train, y_test = train_test_split(combinedata, labeled_data[\"authorID\"], \n",
    "                                                                test_size=0.1, stratify = labeled_data[\"authorID\"])\n",
    "            # get index of y_train\n",
    "            train_index = y_train.index.tolist()\n",
    "            # use it to get label and pid \n",
    "            train_label_data = labeled_data.loc[train_index]\n",
    "            # use logistic regression\n",
    "            lr_clf = LogisticRegression()\n",
    "            lr_clf_ovr = one_vs_rest().fit_one_vs_rest(X_train, train_label_data, lr_clf, clf_type = \"Logistic\")\n",
    "            lr_label_predict = lr_clf_ovr.predict(X_test)\n",
    "            print(lr_label_predict)\n",
    "            print(y_test)\n",
    "            lr_acc = accuracy_score(y_test, lr_label_predict)\n",
    "            lr_f1 = f1_score(y_test, lr_label_predict, average='macro')\n",
    "            print(metrics.classification_report(y_test, lr_label_predict))\n",
    "            print(\"LR Accuracy: \",lr_acc)\n",
    "            print(\"LR F1: \", lr_f1)\n",
    "            \n",
    "            # use svm\n",
    "            scv_clf = SVC(kernel='linear', probability = True)\n",
    "            scv_clf_ovr = one_vs_rest().fit_one_vs_rest(X_train, train_label_data, scv_clf, clf_type = \"prob_svm\")\n",
    "            svc_label_predict = scv_clf_ovr.predict(X_test)\n",
    "            svc_acc = accuracy_score(y_test, svc_label_predict)\n",
    "            svc_f1 = f1_score(y_test, svc_label_predict, average='macro')\n",
    "            print(svc_label_predict)\n",
    "            print(y_test)\n",
    "            print(metrics.classification_report(y_test, svc_label_predict))\n",
    "            print(\"SVC Accuracy: \",svc_acc)\n",
    "            print(\"SVC F1: \", svc_f1)\n",
    "            \n",
    "        break\n",
    "    break\n",
    "#     # write evaluation result to excel\n",
    "#     output = pd.DataFrame({'Author Name':allname,\n",
    "#                            \"positive sample size\":positive_sample_size,\"negative sample size\":negative_sample_size, \n",
    "#                            \"svc(linear) accuracy\":all_svcLinear_accuracy, \"svc(linear) f1\": all_svcLinear_f1, \n",
    "#                            \"logistic regression accuracy\":all_LR_accuracy, \"logistic regression f1\": all_LR_f1})\n",
    "\n",
    "#     savePath = \"../result/\"+Dataset+\"/binary_global_emb_sample=140k/\"\n",
    "#     if not os.path.exists(savePath):\n",
    "#         os.makedirs(savePath)\n",
    "#     filename = \"textual=\"+select_emb+\"_threshold=\"+str(threshold)+\".csv\"\n",
    "#     output.to_csv(savePath+filename, encoding='utf-8',index=False)\n",
    "#     print(select_emb, \" Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T05:41:47.457017Z",
     "start_time": "2018-12-14T05:41:47.395996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "from statistics import mean \n",
    "cleaned_svcLinear_accuracy = [x for x in all_svcLinear_accuracy if isinstance(x, float)]\n",
    "cleaned_lr_accuracy = [x for x in all_LR_accuracy if isinstance(x, float)]\n",
    "print(len(cleaned_svcLinear_accuracy))\n",
    "print(len(cleaned_lr_accuracy))\n",
    "print(mean(cleaned_svcLinear_accuracy))\n",
    "print(mean(cleaned_lr_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T05:42:02.178971Z",
     "start_time": "2018-12-14T05:42:02.117477Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f1\n",
    "from statistics import mean \n",
    "# remove string from result\n",
    "cleaned_svcLinear_f1 = [x for x in all_svcLinear_f1 if isinstance(x, float)]\n",
    "cleaned_lr_f1 = [x for x in all_LR_f1 if isinstance(x, float)]\n",
    "print(len(cleaned_svcLinear_f1))\n",
    "print(len(cleaned_lr_f1))\n",
    "print(mean(cleaned_svcLinear_f1))\n",
    "print(mean(cleaned_lr_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T08:45:20.440022Z",
     "start_time": "2018-12-13T08:45:20.436671Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(listfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T12:42:27.304331Z",
     "start_time": "2018-12-13T08:45:20.441801Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T12:42:27.326923Z",
     "start_time": "2018-12-13T12:42:27.306916Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
