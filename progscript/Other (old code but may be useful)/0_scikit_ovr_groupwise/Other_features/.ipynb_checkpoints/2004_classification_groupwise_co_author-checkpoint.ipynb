{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:23.963072Z",
     "start_time": "2018-12-02T02:12:15.855457Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import com_func\n",
    "\n",
    "Dataset = \"pubmed\"\n",
    "\n",
    "# parameters\n",
    "threshold = 10\n",
    "cutoff = 3\n",
    "\n",
    "coauthor_emb_type = \"tf_idf\"\n",
    "venue_emb_type = \"off\"\n",
    "year_emb_type = \"off\"\n",
    "pp_textual_emb_type = \"off\"\n",
    "citation_emb_type = \"off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:19:24.632920Z",
     "start_time": "2018-12-02T02:19:24.583746Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy(doc):\n",
    "    return doc\n",
    "def read_labeled_file(infile):\n",
    "    LabeledRecords_original = []\n",
    "    with open(infile, 'r', encoding = 'utf8') as f:\n",
    "        for line in f:\n",
    "            read_data = line.split(\"\\t\")\n",
    "            # get ride of bad formated lines\n",
    "            if(len(read_data)==13 or len(read_data)==12):\n",
    "                paper_detail = {\"paperID\": read_data[0], \"authorID\":read_data[1], \n",
    "                                \"co-author\": read_data[5], \"venue_id\": read_data[7],\n",
    "                                \"publish_year\": read_data[10]}\n",
    "                LabeledRecords_original.append(paper_detail)\n",
    "            else:\n",
    "                print(len(read_data))\n",
    "        f.close()\n",
    "    return pd.DataFrame(LabeledRecords_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:24.057943Z",
     "start_time": "2018-12-02T02:12:24.020201Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSA(cleaned_token, dim=100):\n",
    "    # Tf-idf Transformation\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True, tokenizer=dummy,\n",
    "                                               preprocessor=dummy, stop_words = None,min_df=cutoff)\n",
    "    tfidfMatrix = tfidf_vectorizer.fit_transform(cleaned_token).toarray()\n",
    "    if(tfidfMatrix.shape[1]<dim):\n",
    "        dim = tfidfMatrix.shape[1] -1\n",
    "    # tf-idf + svd\n",
    "    svd = TruncatedSVD(n_components=dim)\n",
    "    final_lsa_Matrix = svd.fit_transform(tfidfMatrix)\n",
    "    print(svd.explained_variance_ratio_.sum())\n",
    "    return final_lsa_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:24.127563Z",
     "start_time": "2018-12-02T02:12:24.062441Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# co-author relation to frequence count\n",
    "def co_author_to_vector(raw_co_author_data, emb_type=\"off\"):\n",
    "    while True:\n",
    "        if emb_type == \"tf\":\n",
    "            co_author_vectorizer = CountVectorizer()\n",
    "            print(co_author_vectorizer)\n",
    "            result_vector = co_author_vectorizer.fit_transform(raw_co_author_data).toarray()\n",
    "            #print(co_author_vectorizer.get_feature_names())\n",
    "            #print(len(co_author_vectorizer.vocabulary_))\n",
    "            break\n",
    "        elif emb_type == \"tf_idf\":\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
    "                                               stop_words = None)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(raw_co_author_data).toarray()\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:24.195364Z",
     "start_time": "2018-12-02T02:12:24.132239Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# venue relation with author\n",
    "def venue_to_vector(raw_venue_id, emb_type=\"off\"):\n",
    "    while True:\n",
    "        if emb_type == \"tf\":\n",
    "            venue_count_vectorizer = CountVectorizer()\n",
    "            print(venue_count_vectorizer)\n",
    "            result_vector = venue_count_vectorizer.fit_transform(raw_venue_id).toarray()\n",
    "            #print(len(venue_count_vectorizer.vocabulary_))\n",
    "            break\n",
    "        elif emb_type == \"tf_idf\":\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
    "                                               stop_words = None)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(raw_co_author_data).toarray()\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:24.257723Z",
     "start_time": "2018-12-02T02:12:24.199938Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# author-year relation to emb\n",
    "def year_to_vector(raw_year, emb_type=\"off\"):\n",
    "    while True:\n",
    "        if emb_type == \"tf\":\n",
    "            count_vectorizer = CountVectorizer()\n",
    "            result_vector = count_vectorizer.fit_transform(raw_year).toarray()\n",
    "            #print(len(count_vectorizer.vocabulary_))\n",
    "            break\n",
    "        elif emb_type == \"tf_idf\":\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
    "                                               stop_words = None)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(raw_co_author_data).toarray()\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"tf\"\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:27.634494Z",
     "start_time": "2018-12-02T02:12:27.487428Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# document relation wrt textual content\n",
    "# convert raw text to numerical feature vectors\n",
    "# bow(Bags of words) are used with uni-gram setting\n",
    "def raw_text_to_vector(raw_textual_content, emb_type=\"off\", stopword=True):\n",
    "    cleaned_token, sample_size= com_func.clean_batch_of_raw(raw_textual_content, stopword=stopword)\n",
    "    average_sample_size = sum(sample_size)/len(sample_size)\n",
    "    print(\"Minimal sample size: \", min(sample_size))\n",
    "    print(\"maximal sample size: \", max(sample_size))\n",
    "    while True:\n",
    "        if emb_type == \"tf_idf\":\n",
    "            # using tf-idf\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True, tokenizer=dummy,\n",
    "                                               preprocessor=dummy, stop_words = None,min_df=cutoff)\n",
    "            print(tfidf_vectorizer)\n",
    "            result_vector = tfidf_vectorizer.fit_transform(cleaned_token).toarray()\n",
    "            #print(len(tfidf_vectorizer.vocabulary_))\n",
    "            #print(tfidf_vectorizer.get_feature_names())\n",
    "            break\n",
    "        elif emb_type == \"tf\":\n",
    "            # Document-Term frequence Matrix\n",
    "            count_vectorizer = CountVectorizer(tokenizer=dummy,preprocessor=dummy, min_df=cutoff)\n",
    "            result_vector = count_vectorizer.fit_transform(cleaned_token).toarray()\n",
    "            break\n",
    "        elif emb_type == \"lsa\":\n",
    "            # use lsa\n",
    "            result_vector = LSA(cleaned_token, dim=100)\n",
    "            break\n",
    "        elif emb_type == \"off\":\n",
    "            result_vector = pd.DataFrame()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Embedding type not available, selecting default setting\")\n",
    "            emb_type=\"off\"\n",
    "    return result_vector, average_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:12:30.672868Z",
     "start_time": "2018-12-02T02:12:30.555139Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
    "# cross validation\n",
    "def k_fold_cv(data, label, clf, k=10):\n",
    "    kf = KFold(n_splits=k, shuffle=False)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data[train_index], data[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        # fit data to clf\n",
    "        clf.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = clf.predict(data_test)\n",
    "        allTrueLabel.extend(label_test)\n",
    "        allPredLabel.extend(label_pred)\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "\n",
    "    accuracy = accuracy_score(allTrueLabel, allPredLabel)\n",
    "    f1 = f1_score(allTrueLabel, allPredLabel,average='macro')\n",
    "    \n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel).ravel())\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:36:48.003565Z",
     "start_time": "2018-12-02T02:25:03.747872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For name:  j_read\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5159-1192': 57, '0000-0002-9029-5185': 39, '0000-0002-9697-0962': 31, '0000-0002-4739-9245': 3, '0000-0003-0605-5259': 3, '0000-0003-4316-7006': 1, '0000-0002-0784-0091': 1, '0000-0002-3888-6631': 1})\n",
      "['0000-0002-9697-0962', '0000-0002-9029-5185', '0000-0002-5159-1192']\n",
      "Total sample size after apply threshold:  127\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 263)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        31\n",
      "          1       0.90      0.69      0.78        39\n",
      "          2       0.77      0.98      0.86        57\n",
      "\n",
      "avg / total       0.86      0.84      0.84       127\n",
      "\n",
      "[24  2  5  0 27 12  0  1 56]\n",
      "MNB Accuracy:  0.84251968503937\n",
      "MNB F1:  0.8389581433059693\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        31\n",
      "          1       1.00      0.64      0.78        39\n",
      "          2       0.70      1.00      0.83        57\n",
      "\n",
      "avg / total       0.87      0.81      0.81       127\n",
      "\n",
      "[21  0 10  0 25 14  0  0 57]\n",
      "svc Accuracy:  0.8110236220472441\n",
      "svc F1:  0.8050097547380157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        31\n",
      "          1       1.00      0.54      0.70        39\n",
      "          2       0.64      1.00      0.78        57\n",
      "\n",
      "avg / total       0.84      0.75      0.74       127\n",
      "\n",
      "[17  0 14  0 21 18  0  0 57]\n",
      "LR Accuracy:  0.7480314960629921\n",
      "LR F1:  0.7297184170471841\n",
      "For name:  f_esteves\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-3046-1313': 18, '0000-0002-5403-0091': 12, '0000-0003-0589-0746': 3, '0000-0003-3172-6253': 1})\n",
      "['0000-0002-5403-0091', '0000-0002-3046-1313']\n",
      "Total sample size after apply threshold:  30\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(30, 63)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "30\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.89      0.87      0.86        30\n",
      "\n",
      "[ 8  4  0 18]\n",
      "MNB Accuracy:  0.8666666666666667\n",
      "MNB F1:  0.8500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.95      1.00      0.97        18\n",
      "\n",
      "avg / total       0.97      0.97      0.97        30\n",
      "\n",
      "[11  1  0 18]\n",
      "svc Accuracy:  0.9666666666666667\n",
      "svc F1:  0.9647473560517039\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.78      1.00      0.88        18\n",
      "\n",
      "avg / total       0.87      0.83      0.82        30\n",
      "\n",
      "[ 7  5  0 18]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.8074454428754814\n",
      "For name:  c_miller\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  252\n",
      "Counter({'0000-0003-4341-1283': 51, '0000-0002-3989-7973': 40, '0000-0002-3813-1706': 39, '0000-0003-2772-9531': 27, '0000-0001-6082-9273': 22, '0000-0002-2601-4422': 22, '0000-0002-9448-8144': 19, '0000-0001-8628-4902': 15, '0000-0002-2936-7717': 6, '0000-0003-3898-9734': 6, '0000-0002-5074-6914': 2, '0000-0003-4266-6700': 1, '0000-0002-9286-9787': 1, '0000-0002-0821-0892': 1})\n",
      "['0000-0003-4341-1283', '0000-0002-9448-8144', '0000-0003-2772-9531', '0000-0001-6082-9273', '0000-0002-3813-1706', '0000-0001-8628-4902', '0000-0002-3989-7973', '0000-0002-2601-4422']\n",
      "Total sample size after apply threshold:  235\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(235, 683)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      1.00      0.65        51\n",
      "          1       1.00      0.42      0.59        19\n",
      "          2       1.00      0.70      0.83        27\n",
      "          3       0.91      0.45      0.61        22\n",
      "          4       0.86      0.95      0.90        39\n",
      "          5       1.00      0.33      0.50        15\n",
      "          6       0.97      0.78      0.86        40\n",
      "          7       1.00      0.45      0.62        22\n",
      "\n",
      "avg / total       0.85      0.73      0.73       235\n",
      "\n",
      "[51  0  0  0  0  0  0  0  9  8  0  1  1  0  0  0  8  0 19  0  0  0  0  0\n",
      " 12  0  0 10  0  0  0  0  1  0  0  0 37  0  1  0  7  0  0  0  3  5  0  0\n",
      "  7  0  0  0  2  0 31  0 12  0  0  0  0  0  0 10]\n",
      "MNB Accuracy:  0.7276595744680852\n",
      "MNB F1:  0.6948574888661821\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      1.00      0.70        51\n",
      "          1       1.00      0.63      0.77        19\n",
      "          2       1.00      0.67      0.80        27\n",
      "          3       0.94      0.68      0.79        22\n",
      "          4       1.00      0.90      0.95        39\n",
      "          5       1.00      0.80      0.89        15\n",
      "          6       0.97      0.78      0.86        40\n",
      "          7       1.00      0.68      0.81        22\n",
      "\n",
      "avg / total       0.89      0.80      0.82       235\n",
      "\n",
      "[51  0  0  0  0  0  0  0  6 12  0  1  0  0  0  0  9  0 18  0  0  0  0  0\n",
      "  7  0  0 15  0  0  0  0  3  0  0  0 35  0  1  0  3  0  0  0  0 12  0  0\n",
      "  9  0  0  0  0  0 31  0  7  0  0  0  0  0  0 15]\n",
      "svc Accuracy:  0.8042553191489362\n",
      "svc F1:  0.8211317657925852\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      1.00      0.60        51\n",
      "          1       1.00      0.42      0.59        19\n",
      "          2       1.00      0.59      0.74        27\n",
      "          3       1.00      0.45      0.62        22\n",
      "          4       1.00      0.92      0.96        39\n",
      "          5       1.00      0.47      0.64        15\n",
      "          6       1.00      0.72      0.84        40\n",
      "          7       1.00      0.50      0.67        22\n",
      "\n",
      "avg / total       0.88      0.71      0.73       235\n",
      "\n",
      "[51  0  0  0  0  0  0  0 11  8  0  0  0  0  0  0 11  0 16  0  0  0  0  0\n",
      " 12  0  0 10  0  0  0  0  3  0  0  0 36  0  0  0  8  0  0  0  0  7  0  0\n",
      " 11  0  0  0  0  0 29  0 11  0  0  0  0  0  0 11]\n",
      "LR Accuracy:  0.7148936170212766\n",
      "LR F1:  0.7086173685171799\n",
      "For name:  r_jha\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0002-2891-8353': 6, '0000-0003-0332-2542': 3, '0000-0003-1877-1973': 1, '0000-0002-7755-7443': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  a_lowe\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0002-4691-8162': 69, '0000-0001-6650-7486': 22, '0000-0002-0558-3597': 10, '0000-0003-1139-2516': 1})\n",
      "['0000-0002-0558-3597', '0000-0002-4691-8162', '0000-0001-6650-7486']\n",
      "Total sample size after apply threshold:  101\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 262)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "101\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.83      1.00      0.91        69\n",
      "          2       1.00      0.82      0.90        22\n",
      "\n",
      "avg / total       0.79      0.86      0.82       101\n",
      "\n",
      "[ 0 10  0  0 69  0  0  4 18]\n",
      "MNB Accuracy:  0.8613861386138614\n",
      "MNB F1:  0.6026315789473684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.90      1.00      0.95        69\n",
      "          2       1.00      0.91      0.95        22\n",
      "\n",
      "avg / total       0.93      0.92      0.91       101\n",
      "\n",
      "[ 4  6  0  0 69  0  0  2 20]\n",
      "svc Accuracy:  0.9207920792079208\n",
      "svc F1:  0.8230050010871928\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.79      1.00      0.88        69\n",
      "          2       1.00      0.50      0.67        22\n",
      "\n",
      "avg / total       0.86      0.82      0.80       101\n",
      "\n",
      "[ 3  7  0  0 69  0  0 11 11]\n",
      "LR Accuracy:  0.8217821782178217\n",
      "LR F1:  0.6709401709401709\n",
      "For name:  a_vega\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-8207-9925': 10, '0000-0002-2178-2780': 8, '0000-0002-8148-5702': 1, '0000-0003-1082-0961': 1})\n",
      "['0000-0002-8207-9925']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  k_smith\n",
      "total sample size before apply threshold:  338\n",
      "Counter({'0000-0002-6736-4779': 133, '0000-0001-8088-566X': 75, '0000-0002-1323-627X': 29, '0000-0002-8914-6457': 23, '0000-0001-6828-7480': 19, '0000-0001-8150-5702': 15, '0000-0003-2793-3460': 14, '0000-0002-4530-6914': 13, '0000-0003-2802-4939': 8, '0000-0002-0932-1412': 4, '0000-0002-2424-6254': 1, '0000-0001-6957-5361': 1, '0000-0002-7807-2472': 1, '0000-0002-0346-2820': 1, '0000-0003-2060-9369': 1})\n",
      "['0000-0001-8150-5702', '0000-0002-1323-627X', '0000-0002-4530-6914', '0000-0002-6736-4779', '0000-0003-2793-3460', '0000-0002-8914-6457', '0000-0001-8088-566X', '0000-0001-6828-7480']\n",
      "Total sample size after apply threshold:  321\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(321, 719)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "321\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        15\n",
      "          1       1.00      0.93      0.96        29\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.71      0.98      0.83       133\n",
      "          4       1.00      0.50      0.67        14\n",
      "          5       1.00      0.61      0.76        23\n",
      "          6       0.91      0.84      0.87        75\n",
      "          7       1.00      0.68      0.81        19\n",
      "\n",
      "avg / total       0.82      0.82      0.80       321\n",
      "\n",
      "[  7   0   0   5   0   0   3   0   0  27   0   2   0   0   0   0   0   0\n",
      "   0  13   0   0   0   0   0   0   0 131   0   0   2   0   0   0   0   7\n",
      "   7   0   0   0   0   0   0   8   0  14   1   0   0   0   0  12   0   0\n",
      "  63   0   0   0   0   6   0   0   0  13]\n",
      "MNB Accuracy:  0.8161993769470405\n",
      "MNB F1:  0.6922588995982135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        15\n",
      "          1       1.00      0.93      0.96        29\n",
      "          2       1.00      0.38      0.56        13\n",
      "          3       0.80      0.99      0.89       133\n",
      "          4       1.00      0.64      0.78        14\n",
      "          5       1.00      0.96      0.98        23\n",
      "          6       0.98      0.87      0.92        75\n",
      "          7       1.00      0.79      0.88        19\n",
      "\n",
      "avg / total       0.92      0.90      0.89       321\n",
      "\n",
      "[ 13   0   0   2   0   0   0   0   0  27   0   2   0   0   0   0   0   0\n",
      "   5   8   0   0   0   0   0   0   0 132   0   0   1   0   0   0   0   5\n",
      "   9   0   0   0   0   0   0   1   0  22   0   0   0   0   0  10   0   0\n",
      "  65   0   0   0   0   4   0   0   0  15]\n",
      "svc Accuracy:  0.897196261682243\n",
      "svc F1:  0.8627533521888557\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        15\n",
      "          1       1.00      0.93      0.96        29\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.64      0.98      0.77       133\n",
      "          4       1.00      0.50      0.67        14\n",
      "          5       1.00      0.70      0.82        23\n",
      "          6       0.96      0.60      0.74        75\n",
      "          7       1.00      0.47      0.64        19\n",
      "\n",
      "avg / total       0.80      0.76      0.74       321\n",
      "\n",
      "[  9   0   0   6   0   0   0   0   0  27   0   2   0   0   0   0   0   0\n",
      "   0  13   0   0   0   0   0   0   0 131   0   0   2   0   0   0   0   7\n",
      "   7   0   0   0   0   0   0   7   0  16   0   0   0   0   0  30   0   0\n",
      "  45   0   0   0   0  10   0   0   0   9]\n",
      "LR Accuracy:  0.7601246105919003\n",
      "LR F1:  0.6693610774109106\n",
      "For name:  j_gordon\n",
      "total sample size before apply threshold:  19\n",
      "Counter({'0000-0002-0061-2168': 12, '0000-0001-9494-0586': 4, '0000-0001-7811-9245': 2, '0000-0002-5911-4219': 1})\n",
      "['0000-0002-0061-2168']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  s_liao\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0003-4129-0879': 46, '0000-0002-4312-5351': 43, '0000-0003-0943-0667': 10, '0000-0002-3122-8249': 2, '0000-0002-2372-9502': 1, '0000-0002-8872-2117': 1, '0000-0002-7339-2768': 1})\n",
      "['0000-0003-0943-0667', '0000-0003-4129-0879', '0000-0002-4312-5351']\n",
      "Total sample size after apply threshold:  99\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(99, 88)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.65      0.87      0.74        46\n",
      "          2       0.81      0.70      0.75        43\n",
      "\n",
      "avg / total       0.65      0.71      0.67        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  9  1  0 40  6  0 13 30]\n",
      "MNB Accuracy:  0.7070707070707071\n",
      "MNB F1:  0.49691358024691357\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.75      0.85      0.80        46\n",
      "          2       0.81      0.88      0.84        43\n",
      "\n",
      "avg / total       0.70      0.78      0.74        99\n",
      "\n",
      "[ 0  8  2  0 39  7  0  5 38]\n",
      "svc Accuracy:  0.7777777777777778\n",
      "svc F1:  0.5467876039304611\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.71      0.85      0.77        46\n",
      "          2       0.82      0.84      0.83        43\n",
      "\n",
      "avg / total       0.68      0.76      0.72        99\n",
      "\n",
      "[ 0  9  1  0 39  7  0  7 36]\n",
      "LR Accuracy:  0.7575757575757576\n",
      "LR F1:  0.5332878115397747\n",
      "For name:  j_qian\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-8793-9330': 6, '0000-0001-6145-045X': 6, '0000-0003-3162-2913': 1, '0000-0002-9522-6445': 1, '0000-0002-1325-6975': 1, '0000-0002-5438-0833': 1, '0000-0001-5043-020X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_bernardi\n",
      "total sample size before apply threshold:  91\n",
      "Counter({'0000-0001-5672-0881': 38, '0000-0002-7429-3075': 30, '0000-0002-1050-3096': 17, '0000-0001-6130-8533': 6})\n",
      "['0000-0002-7429-3075', '0000-0001-5672-0881', '0000-0002-1050-3096']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 403)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        30\n",
      "          1       0.90      1.00      0.95        38\n",
      "          2       1.00      0.65      0.79        17\n",
      "\n",
      "avg / total       0.94      0.93      0.92        85\n",
      "\n",
      "[30  0  0  0 38  0  2  4 11]\n",
      "MNB Accuracy:  0.9294117647058824\n",
      "MNB F1:  0.9011520737327189\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        30\n",
      "          1       0.90      1.00      0.95        38\n",
      "          2       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.96      0.95      0.95        85\n",
      "\n",
      "[30  0  0  0 38  0  0  4 13]\n",
      "svc Accuracy:  0.9529411764705882\n",
      "svc F1:  0.938888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        30\n",
      "          1       0.72      1.00      0.84        38\n",
      "          2       1.00      0.29      0.45        17\n",
      "\n",
      "avg / total       0.87      0.82      0.80        85\n",
      "\n",
      "[27  3  0  0 38  0  0 12  5]\n",
      "LR Accuracy:  0.8235294117647058\n",
      "LR F1:  0.7456929035876404\n",
      "For name:  t_hill\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0003-4159-9104': 7, '0000-0001-6996-9475': 3, '0000-0002-4125-7895': 2, '0000-0003-2980-4099': 2, '0000-0002-7995-9315': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_schindler\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-9991-9513': 26, '0000-0002-7054-5431': 13, '0000-0003-1028-3115': 6, '0000-0003-1378-0053': 5, '0000-0002-1755-4304': 1})\n",
      "['0000-0002-7054-5431', '0000-0002-9991-9513']\n",
      "Total sample size after apply threshold:  39\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 129)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.96      1.00      0.98        26\n",
      "\n",
      "avg / total       0.98      0.97      0.97        39\n",
      "\n",
      "[12  1  0 26]\n",
      "MNB Accuracy:  0.9743589743589743\n",
      "MNB F1:  0.9705660377358492\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.93      1.00      0.96        26\n",
      "\n",
      "avg / total       0.95      0.95      0.95        39\n",
      "\n",
      "[11  2  0 26]\n",
      "svc Accuracy:  0.9487179487179487\n",
      "svc F1:  0.9398148148148149\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.84      1.00      0.91        26\n",
      "\n",
      "avg / total       0.89      0.87      0.86        39\n",
      "\n",
      "[ 8  5  0 26]\n",
      "LR Accuracy:  0.8717948717948718\n",
      "LR F1:  0.837092731829574\n",
      "For name:  j_williams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  625\n",
      "Counter({'0000-0001-5188-7957': 141, '0000-0002-6063-7615': 82, '0000-0001-6665-6596': 79, '0000-0002-4688-3000': 66, '0000-0001-7152-765X': 51, '0000-0001-8251-4176': 28, '0000-0003-1235-5186': 26, '0000-0002-8883-7838': 25, '0000-0001-8331-3181': 20, '0000-0001-8377-5175': 15, '0000-0002-8861-0596': 14, '0000-0002-3804-2594': 14, '0000-0003-3815-0891': 14, '0000-0002-4497-4961': 10, '0000-0002-9801-9580': 9, '0000-0003-4400-5180': 5, '0000-0002-3500-914X': 5, '0000-0002-0195-6771': 4, '0000-0001-6105-0296': 3, '0000-0002-4681-3360': 3, '0000-0003-0161-0532': 3, '0000-0002-6511-1284': 3, '0000-0002-0195-5509': 2, '0000-0003-0500-1961': 2, '0000-0002-5355-3210': 1})\n",
      "['0000-0003-1235-5186', '0000-0002-8861-0596', '0000-0001-7152-765X', '0000-0001-6665-6596', '0000-0002-4497-4961', '0000-0002-6063-7615', '0000-0001-5188-7957', '0000-0002-3804-2594', '0000-0002-8883-7838', '0000-0001-8251-4176', '0000-0003-3815-0891', '0000-0001-8331-3181', '0000-0002-4688-3000', '0000-0001-8377-5175']\n",
      "Total sample size after apply threshold:  585\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(585, 1669)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        26\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       0.96      0.84      0.90        51\n",
      "          3       0.99      0.89      0.93        79\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.88      0.73      0.80        82\n",
      "          6       0.44      0.99      0.61       141\n",
      "          7       0.00      0.00      0.00        14\n",
      "          8       1.00      0.12      0.21        25\n",
      "          9       1.00      0.18      0.30        28\n",
      "         10       0.00      0.00      0.00        14\n",
      "         11       1.00      0.25      0.40        20\n",
      "         12       0.98      0.79      0.87        66\n",
      "         13       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.75      0.68      0.64       585\n",
      "\n",
      "[  8   0   0   0   0   1  17   0   0   0   0   0   0   0   0  12   0   0\n",
      "   0   0   2   0   0   0   0   0   0   0   0   0  43   0   0   0   8   0\n",
      "   0   0   0   0   0   0   0   0   1  70   0   0   8   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0\n",
      "   0   1   0  60  21   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      " 140   0   0   0   0   0   0   0   0   0   1   0   0   0  13   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1  20   0   3   0   0   0   1   0\n",
      "   0   0   0   0   0   0  23   0   0   5   0   0   0   0   0   0   0   0\n",
      "   0   1  13   0   0   0   0   0   0   0   0   0   0   0   0   2  13   0\n",
      "   0   0   0   5   0   0   0   0   0   0   0   0  14   0   0   0   0   0\n",
      "  52   0   0   0   0   0   0   2  13   0   0   0   0   0   0   0]\n",
      "MNB Accuracy:  0.6803418803418804\n",
      "MNB F1:  0.4591523221360682\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.85      0.90        26\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       1.00      0.82      0.90        51\n",
      "          3       1.00      0.84      0.91        79\n",
      "          4       1.00      0.40      0.57        10\n",
      "          5       0.85      0.77      0.81        82\n",
      "          6       0.61      1.00      0.76       141\n",
      "          7       1.00      0.43      0.60        14\n",
      "          8       1.00      0.80      0.89        25\n",
      "          9       0.95      0.64      0.77        28\n",
      "         10       1.00      0.50      0.67        14\n",
      "         11       1.00      0.80      0.89        20\n",
      "         12       0.98      0.88      0.93        66\n",
      "         13       1.00      0.33      0.50        15\n",
      "\n",
      "avg / total       0.88      0.82      0.82       585\n",
      "\n",
      "[ 22   0   0   0   0   0   3   0   0   0   0   0   1   0   0  12   0   0\n",
      "   0   0   2   0   0   0   0   0   0   0   0   0  42   0   0   0   9   0\n",
      "   0   0   0   0   0   0   1   0   0  66   0   1  11   0   0   0   0   0\n",
      "   0   0   0   0   0   0   4   0   5   0   0   1   0   0   0   0   0   0\n",
      "   0   0   0  63  19   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 141   0   0   0   0   0   0   0   0   0   0   0   0   2   6   6   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   5   0  20   0   0   0   0   0\n",
      "   0   0   0   0   0   2   8   0   0  18   0   0   0   0   0   0   0   0\n",
      "   0   2   5   0   0   0   7   0   0   0   0   0   0   0   0   1   3   0\n",
      "   0   0   0  16   0   0   0   0   0   0   0   0   8   0   0   0   0   0\n",
      "  58   0   0   0   0   0   0   3   7   0   0   0   0   0   0   5]\n",
      "svc Accuracy:  0.8205128205128205\n",
      "svc F1:  0.7862972630531296\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        26\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       0.98      0.82      0.89        51\n",
      "          3       1.00      0.85      0.92        79\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       1.00      0.70      0.82        82\n",
      "          6       0.45      1.00      0.62       141\n",
      "          7       1.00      0.07      0.13        14\n",
      "          8       1.00      0.44      0.61        25\n",
      "          9       1.00      0.25      0.40        28\n",
      "         10       0.00      0.00      0.00        14\n",
      "         11       1.00      0.65      0.79        20\n",
      "         12       0.98      0.71      0.82        66\n",
      "         13       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.80      0.70      0.69       585\n",
      "\n",
      "[ 14   0   0   0   0   0  12   0   0   0   0   0   0   0   0  12   0   0\n",
      "   0   0   2   0   0   0   0   0   0   0   0   0  42   0   0   0   9   0\n",
      "   0   0   0   0   0   0   0   0   0  67   0   0  12   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  57  25   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 141   0   0   0   0   0   0   0   0   0   1   0   0   0  12   1   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  13   0  11   0   0   0   1   0\n",
      "   0   0   0   0   0   0  21   0   0   7   0   0   0   0   0   0   0   0\n",
      "   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   7   0\n",
      "   0   0   0  13   0   0   0   0   0   0   0   0  19   0   0   0   0   0\n",
      "  47   0   0   0   0   0   0   0  15   0   0   0   0   0   0   0]\n",
      "LR Accuracy:  0.7042735042735043\n",
      "LR F1:  0.5452890886105058\n",
      "For name:  s_jacobson\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-9042-8750': 20, '0000-0002-3955-5746': 4, '0000-0002-4952-9007': 3, '0000-0001-9937-419X': 1})\n",
      "['0000-0002-9042-8750']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  e_andrade\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-1941-580X': 7, '0000-0001-7080-7035': 5, '0000-0003-2016-8305': 4, '0000-0002-5030-1675': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_santos\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0002-5365-4863': 18, '0000-0003-3765-5863': 14, '0000-0001-9072-5010': 3, '0000-0001-9947-6022': 2, '0000-0002-7694-306X': 2, '0000-0003-4171-5806': 1, '0000-0002-9744-0410': 1, '0000-0002-5325-3090': 1, '0000-0003-4620-0174': 1, '0000-0002-5738-4995': 1, '0000-0001-6892-0354': 1})\n",
      "['0000-0003-3765-5863', '0000-0002-5365-4863']\n",
      "Total sample size after apply threshold:  32\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 83)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        14\n",
      "          1       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.90      0.88      0.87        32\n",
      "\n",
      "[10  4  0 18]\n",
      "MNB Accuracy:  0.875\n",
      "MNB F1:  0.8666666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       1.00      1.00      1.00        18\n",
      "\n",
      "avg / total       1.00      1.00      1.00        32\n",
      "\n",
      "[14  0  0 18]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        14\n",
      "          1       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.90      0.88      0.87        32\n",
      "\n",
      "[10  4  0 18]\n",
      "LR Accuracy:  0.875\n",
      "LR F1:  0.8666666666666667\n",
      "For name:  k_kim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  1111\n",
      "Counter({'0000-0002-6929-5359': 211, '0000-0001-9498-284X': 154, '0000-0002-5878-8895': 139, '0000-0002-1864-3392': 92, '0000-0002-7045-8004': 57, '0000-0001-7896-6751': 57, '0000-0002-7991-9428': 55, '0000-0002-4010-1063': 45, '0000-0002-2186-3484': 28, '0000-0002-4899-1929': 25, '0000-0003-0487-4242': 24, '0000-0002-3642-1486': 22, '0000-0001-9965-3535': 17, '0000-0002-4168-757X': 17, '0000-0001-6525-3744': 14, '0000-0002-3897-0278': 14, '0000-0002-1181-5112': 12, '0000-0003-1447-9385': 11, '0000-0002-7305-8786': 11, '0000-0002-2655-7806': 10, '0000-0003-3466-5353': 9, '0000-0002-7359-663X': 8, '0000-0003-4600-8668': 6, '0000-0002-1382-7088': 5, '0000-0002-9505-4882': 5, '0000-0003-3667-9900': 4, '0000-0001-9714-6038': 4, '0000-0002-4760-0228': 3, '0000-0003-4188-7915': 3, '0000-0001-9454-0427': 3, '0000-0002-0333-6808': 3, '0000-0003-2134-4964': 3, '0000-0002-6658-047X': 3, '0000-0003-1273-379X': 3, '0000-0002-7047-3183': 3, '0000-0002-1814-9546': 3, '0000-0003-4812-6297': 2, '0000-0001-6597-578X': 2, '0000-0002-5285-9138': 2, '0000-0002-6796-7844': 2, '0000-0002-1130-8698': 2, '0000-0001-8518-8150': 2, '0000-0002-7103-924X': 2, '0000-0002-5407-0202': 1, '0000-0001-6220-8411': 1, '0000-0002-7440-6703': 1, '0000-0002-1603-7559': 1, '0000-0003-0257-1707': 1, '0000-0001-8532-6517': 1, '0000-0001-6626-316X': 1, '0000-0002-3246-9861': 1, '0000-0002-7207-4389': 1, '0000-0001-9682-9654': 1, '0000-0002-0196-3832': 1, '0000-0001-8063-6081': 1, '0000-0003-2037-3333': 1, '0000-0001-8872-6751': 1})\n",
      "['0000-0003-1447-9385', '0000-0001-6525-3744', '0000-0001-9498-284X', '0000-0002-3642-1486', '0000-0001-9965-3535', '0000-0002-7305-8786', '0000-0002-4899-1929', '0000-0002-6929-5359', '0000-0002-7045-8004', '0000-0002-2186-3484', '0000-0002-5878-8895', '0000-0002-4010-1063', '0000-0003-0487-4242', '0000-0001-7896-6751', '0000-0002-3897-0278', '0000-0002-7991-9428', '0000-0002-1864-3392', '0000-0002-4168-757X', '0000-0002-2655-7806', '0000-0002-1181-5112']\n",
      "Total sample size after apply threshold:  1015\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(1015, 674)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.39      0.84      0.53       154\n",
      "          3       0.00      0.00      0.00        22\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00        11\n",
      "          6       0.00      0.00      0.00        25\n",
      "          7       0.51      0.88      0.64       211\n",
      "          8       0.00      0.00      0.00        57\n",
      "          9       0.00      0.00      0.00        28\n",
      "         10       0.53      0.88      0.66       139\n",
      "         11       1.00      0.16      0.27        45\n",
      "         12       0.00      0.00      0.00        24\n",
      "         13       0.00      0.00      0.00        57\n",
      "         14       0.00      0.00      0.00        14\n",
      "         15       0.76      0.45      0.57        55\n",
      "         16       0.81      0.32      0.45        92\n",
      "         17       1.00      0.12      0.21        17\n",
      "         18       0.00      0.00      0.00        10\n",
      "         19       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.41      0.49      0.39      1015\n",
      "\n",
      "[  0   0   6   0   0   0   0   1   0   0   4   0   0   0   0   0   0   0\n",
      "   0   0   0   0   7   0   0   0   0   7   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 130   0   0   0   0  12   0   0  12   0   0   0\n",
      "   0   0   0   0   0   0   0   0  11   0   0   0   0   9   0   0   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   8   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   7\n",
      "   0   0   2   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0\n",
      "   0   2   0   0   2   0   0   0   0   0   0   0   0   0   0   0  17   0\n",
      "   0   0   0 186   0   0   8   0   0   0   0   0   0   0   0   0   0   0\n",
      "  13   0   0   0   0  23   0   0  21   0   0   0   0   0   0   0   0   0\n",
      "   0   0  10   0   0   0   0  15   0   0   3   0   0   0   0   0   0   0\n",
      "   0   0   0   0  11   0   0   0   0   3   0   0 123   0   0   0   0   0\n",
      "   2   0   0   0   0   0   9   0   0   0   0  27   0   0   1   7   0   1\n",
      "   0   0   0   0   0   0   0   0   7   0   0   0   0  17   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  24   0   0   0   0  13   0   0\n",
      "  18   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   7   0   0   0   0   7   0   0   0   0   0   0  18   0   0   0\n",
      "   0   2   0   0  10   0   0   0   0  25   0   0   0   0   0   0  30   0\n",
      "   0   0   0  17   0   0  16   0   0   0   0   0  29   0   0   0   0   0\n",
      "   0   0   0   0   0  11   0   0   0   0   0   0   0   0   4   2   0   0\n",
      "   0   0   7   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   4   0   0   0   0   5   0   0   3   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "MNB Accuracy:  0.4945812807881773\n",
      "MNB F1:  0.16686179855062339\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.82      0.75        11\n",
      "          1       1.00      0.64      0.78        14\n",
      "          2       0.70      0.80      0.75       154\n",
      "          3       0.75      0.27      0.40        22\n",
      "          4       1.00      0.47      0.64        17\n",
      "          5       0.50      0.09      0.15        11\n",
      "          6       0.83      0.80      0.82        25\n",
      "          7       0.58      0.89      0.70       211\n",
      "          8       0.59      0.33      0.43        57\n",
      "          9       0.64      0.32      0.43        28\n",
      "         10       0.77      0.79      0.78       139\n",
      "         11       0.85      0.51      0.64        45\n",
      "         12       1.00      0.33      0.50        24\n",
      "         13       0.70      0.53      0.60        57\n",
      "         14       0.67      0.29      0.40        14\n",
      "         15       0.73      0.75      0.74        55\n",
      "         16       0.59      0.66      0.62        92\n",
      "         17       1.00      0.53      0.69        17\n",
      "         18       1.00      0.80      0.89        10\n",
      "         19       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.71      0.68      0.66      1015\n",
      "\n",
      "[  9   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "   0   0   0   9   3   0   0   0   0   1   0   1   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 123   0   0   0   0  15   0   0   8   0   0   3\n",
      "   0   1   4   0   0   0   0   0   3   6   0   0   0   6   0   2   1   1\n",
      "   0   0   0   1   2   0   0   0   0   0   1   0   8   0   0   5   0   0\n",
      "   0   0   0   0   0   0   3   0   0   0   0   0   2   0   0   1   0   5\n",
      "   0   1   2   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0\n",
      "  20   0   2   0   0   0   0   0   0   0   1   0   0   0   0   0   7   0\n",
      "   0   0   0 188   2   1   1   0   0   2   0   1   9   0   0   0   1   0\n",
      "   6   0   0   0   1  16  19   0   5   0   0   2   0   0   7   0   0   0\n",
      "   0   0   1   1   0   0   1  14   0   9   0   2   0   0   0   0   0   0\n",
      "   0   0   0   0  10   0   0   0   0  14   1   0 110   0   0   0   0   1\n",
      "   3   0   0   0   0   0   7   0   0   0   0  10   1   0   0  23   0   3\n",
      "   0   0   1   0   0   0   0   0   0   0   0   0   0  10   0   0   0   1\n",
      "   8   0   0   0   5   0   0   0   3   0   2   0   0   0   0   8   4   0\n",
      "   4   0   0  30   0   1   5   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   4  10   0   0   0   0   0   0   3   0   0   0\n",
      "   0   4   0   0   3   0   0   1   2  41   1   0   0   0   0   0   3   1\n",
      "   0   0   2  14   3   0   6   0   0   2   0   0  61   0   0   0   0   0\n",
      "   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   9   0   0\n",
      "   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0\n",
      "   8   0   0   0   1   0   0   1   0   3   0   0   2   0   0   0   0   0\n",
      "   1   0   0   4]\n",
      "svc Accuracy:  0.6798029556650246\n",
      "svc F1:  0.6107175326813988\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82        11\n",
      "          1       1.00      0.50      0.67        14\n",
      "          2       0.67      0.78      0.72       154\n",
      "          3       1.00      0.09      0.17        22\n",
      "          4       1.00      0.24      0.38        17\n",
      "          5       0.00      0.00      0.00        11\n",
      "          6       0.90      0.72      0.80        25\n",
      "          7       0.50      0.91      0.65       211\n",
      "          8       0.65      0.26      0.38        57\n",
      "          9       0.62      0.29      0.39        28\n",
      "         10       0.69      0.85      0.76       139\n",
      "         11       0.86      0.40      0.55        45\n",
      "         12       1.00      0.29      0.45        24\n",
      "         13       0.71      0.39      0.50        57\n",
      "         14       0.60      0.21      0.32        14\n",
      "         15       0.74      0.67      0.70        55\n",
      "         16       0.65      0.58      0.61        92\n",
      "         17       1.00      0.06      0.11        17\n",
      "         18       1.00      0.60      0.75        10\n",
      "         19       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.67      0.63      0.60      1015\n",
      "\n",
      "[  9   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   7   3   0   0   0   0   4   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 120   0   0   0   0  16   0   0  13   0   0   2\n",
      "   0   1   2   0   0   0   0   0   2   2   0   0   0  11   0   2   3   0\n",
      "   0   0   0   1   1   0   0   0   0   0   2   0   4   0   0   9   0   0\n",
      "   0   0   0   0   0   0   2   0   0   0   0   0   1   0   0   0   0   6\n",
      "   0   1   2   0   0   0   0   0   1   0   0   0   0   0   4   0   0   0\n",
      "  18   2   1   0   0   0   0   0   0   0   0   0   0   0   0   0   7   0\n",
      "   0   0   0 192   0   1   2   0   0   2   0   0   7   0   0   0   0   0\n",
      "   6   0   0   0   0  18  15   1  10   0   0   2   0   0   5   0   0   0\n",
      "   0   0   2   0   0   0   0  16   1   8   0   0   0   1   0   0   0   0\n",
      "   0   0   0   0   6   0   0   0   0  13   0   0 118   0   0   0   0   0\n",
      "   2   0   0   0   0   0   4   0   0   0   0  20   0   0   0  18   0   2\n",
      "   0   0   1   0   0   0   0   0   1   0   0   0   0  12   0   0   0   1\n",
      "   7   0   0   0   3   0   0   0   2   0   6   0   0   0   0  11   3   0\n",
      "   8   1   0  22   0   2   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   2   0   0   0   3   9   0   0   0   0   0   0   5   0   0   0\n",
      "   0   8   0   0   2   0   0   0   2  37   1   0   0   0   0   0   4   0\n",
      "   0   0   2  22   3   0   8   0   0   0   0   0  53   0   0   0   0   0\n",
      "   0   0   0   0   0  16   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "   0   0   2   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0\n",
      "   6   0   0   0   1   0   0   0   0   6   0   0   2   1   0   0   0   0\n",
      "   2   0   0   0]\n",
      "LR Accuracy:  0.6305418719211823\n",
      "LR F1:  0.48588302691379964\n",
      "For name:  d_ricci\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0003-0015-6374': 26, '0000-0003-2853-4816': 12, '0000-0001-9678-904X': 1, '0000-0002-9790-0552': 1})\n",
      "['0000-0003-0015-6374', '0000-0003-2853-4816']\n",
      "Total sample size after apply threshold:  38\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 139)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        26\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        38\n",
      "\n",
      "[26  0  0 12]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        26\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97        38\n",
      "\n",
      "[26  0  1 11]\n",
      "svc Accuracy:  0.9736842105263158\n",
      "svc F1:  0.9688269073010665\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        26\n",
      "          1       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.91      0.89      0.89        38\n",
      "\n",
      "[26  0  4  8]\n",
      "LR Accuracy:  0.8947368421052632\n",
      "LR F1:  0.8642857142857143\n",
      "For name:  s_cameron\n",
      "total sample size before apply threshold:  66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'0000-0002-6694-4130': 41, '0000-0002-3050-7262': 16, '0000-0001-9570-135X': 7, '0000-0001-5680-2641': 2})\n",
      "['0000-0002-6694-4130', '0000-0002-3050-7262']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 173)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        41\n",
      "          1       0.94      1.00      0.97        16\n",
      "\n",
      "avg / total       0.98      0.98      0.98        57\n",
      "\n",
      "[40  1  0 16]\n",
      "MNB Accuracy:  0.9824561403508771\n",
      "MNB F1:  0.978675645342312\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        41\n",
      "          1       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00        57\n",
      "\n",
      "[41  0  0 16]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        41\n",
      "          1       1.00      0.62      0.77        16\n",
      "\n",
      "avg / total       0.91      0.89      0.89        57\n",
      "\n",
      "[41  0  6 10]\n",
      "LR Accuracy:  0.8947368421052632\n",
      "LR F1:  0.8505244755244756\n",
      "For name:  t_wright\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-5071-9978': 19, '0000-0002-5813-9991': 6, '0000-0001-8338-5935': 5, '0000-0001-7836-6705': 1})\n",
      "['0000-0001-5071-9978']\n",
      "Total sample size after apply threshold:  19\n",
      "For name:  r_cunha\n",
      "total sample size before apply threshold:  209\n",
      "Counter({'0000-0003-2550-6422': 151, '0000-0002-0203-3143': 24, '0000-0002-0849-3247': 12, '0000-0002-6622-7043': 12, '0000-0003-2228-5492': 8, '0000-0002-2382-7479': 2})\n",
      "['0000-0002-0849-3247', '0000-0002-6622-7043', '0000-0003-2550-6422', '0000-0002-0203-3143']\n",
      "Total sample size after apply threshold:  199\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(199, 473)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.76      1.00      0.87       151\n",
      "          3       1.00      0.04      0.08        24\n",
      "\n",
      "avg / total       0.70      0.76      0.67       199\n",
      "\n",
      "[  0   0  12   0   0   0  12   0   0   0 151   0   0   0  23   1]\n",
      "MNB Accuracy:  0.7638190954773869\n",
      "MNB F1:  0.2363323782234957\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29        12\n",
      "          1       1.00      0.33      0.50        12\n",
      "          2       0.83      1.00      0.91       151\n",
      "          3       1.00      0.46      0.63        24\n",
      "\n",
      "avg / total       0.87      0.84      0.81       199\n",
      "\n",
      "[  2   0  10   0   0   4   8   0   0   0 151   0   0   0  13  11]\n",
      "svc Accuracy:  0.8442211055276382\n",
      "svc F1:  0.5802981552981553\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.76      1.00      0.86       151\n",
      "          3       0.00      0.00      0.00        24\n",
      "\n",
      "avg / total       0.58      0.76      0.65       199\n",
      "\n",
      "[  0   0  12   0   0   0  12   0   0   0 151   0   0   0  24   0]\n",
      "LR Accuracy:  0.7587939698492462\n",
      "LR F1:  0.21571428571428572\n",
      "For name:  s_fuchs\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0002-1338-2699': 18, '0000-0001-9191-7970': 11, '0000-0002-0644-2876': 2, '0000-0001-7261-9214': 1})\n",
      "['0000-0001-9191-7970', '0000-0002-1338-2699']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 271)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.89      0.86      0.85        29\n",
      "\n",
      "[ 7  4  0 18]\n",
      "MNB Accuracy:  0.8620689655172413\n",
      "MNB F1:  0.8388888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.90      1.00      0.95        18\n",
      "\n",
      "avg / total       0.94      0.93      0.93        29\n",
      "\n",
      "[ 9  2  0 18]\n",
      "svc Accuracy:  0.9310344827586207\n",
      "svc F1:  0.9236842105263159\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.78      1.00      0.88        18\n",
      "\n",
      "avg / total       0.87      0.83      0.81        29\n",
      "\n",
      "[ 6  5  0 18]\n",
      "LR Accuracy:  0.8275862068965517\n",
      "LR F1:  0.7919655667144907\n",
      "For name:  m_nawaz\n",
      "total sample size before apply threshold:  9\n",
      "Counter({'0000-0002-0792-8296': 4, '0000-0001-9016-9229': 3, '0000-0003-4249-4259': 1, '0000-0003-3387-484X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  k_harris\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0001-8486-1219': 15, '0000-0002-5930-6456': 10, '0000-0003-1769-2587': 8, '0000-0002-1199-2856': 7, '0000-0003-2162-9652': 3, '0000-0003-0302-2523': 2, '0000-0001-5190-4219': 1, '0000-0003-2806-1262': 1})\n",
      "['0000-0002-5930-6456', '0000-0001-8486-1219']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  25\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 42)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.50      0.62        10\n",
      "          1       0.74      0.93      0.82        15\n",
      "\n",
      "avg / total       0.78      0.76      0.74        25\n",
      "\n",
      "[ 5  5  1 14]\n",
      "MNB Accuracy:  0.76\n",
      "MNB F1:  0.7242647058823529\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        10\n",
      "          1       1.00      0.93      0.97        15\n",
      "\n",
      "avg / total       0.96      0.96      0.96        25\n",
      "\n",
      "[10  0  1 14]\n",
      "svc Accuracy:  0.96\n",
      "svc F1:  0.9589490968801313\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.40      0.53        10\n",
      "          1       0.70      0.93      0.80        15\n",
      "\n",
      "avg / total       0.74      0.72      0.69        25\n",
      "\n",
      "[ 4  6  1 14]\n",
      "LR Accuracy:  0.72\n",
      "LR F1:  0.6666666666666667\n",
      "For name:  r_daniel\n",
      "total sample size before apply threshold:  173\n",
      "Counter({'0000-0002-8646-7925': 123, '0000-0002-6483-5897': 37, '0000-0001-8835-8047': 8, '0000-0002-1753-6683': 5})\n",
      "['0000-0002-8646-7925', '0000-0002-6483-5897']\n",
      "Total sample size after apply threshold:  160\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(160, 787)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "160\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       123\n",
      "          1       1.00      0.68      0.81        37\n",
      "\n",
      "avg / total       0.93      0.93      0.92       160\n",
      "\n",
      "[123   0  12  25]\n",
      "MNB Accuracy:  0.925\n",
      "MNB F1:  0.8799699924981246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96       123\n",
      "          1       1.00      0.76      0.86        37\n",
      "\n",
      "avg / total       0.95      0.94      0.94       160\n",
      "\n",
      "[123   0   9  28]\n",
      "svc Accuracy:  0.94375\n",
      "svc F1:  0.9131221719457014\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       123\n",
      "          1       1.00      0.38      0.55        37\n",
      "\n",
      "avg / total       0.88      0.86      0.83       160\n",
      "\n",
      "[123   0  23  14]\n",
      "LR Accuracy:  0.85625\n",
      "LR F1:  0.7317588745535388\n",
      "For name:  k_xu\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0002-2788-194X': 19, '0000-0003-2036-3469': 14, '0000-0002-3985-739X': 3, '0000-0001-7851-2629': 1})\n",
      "['0000-0003-2036-3469', '0000-0002-2788-194X']\n",
      "Total sample size after apply threshold:  33\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 76)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.90      1.00      0.95        19\n",
      "\n",
      "avg / total       0.95      0.94      0.94        33\n",
      "\n",
      "[12  2  0 19]\n",
      "MNB Accuracy:  0.9393939393939394\n",
      "MNB F1:  0.9365384615384615\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.90      1.00      0.95        19\n",
      "\n",
      "avg / total       0.95      0.94      0.94        33\n",
      "\n",
      "[12  2  0 19]\n",
      "svc Accuracy:  0.9393939393939394\n",
      "svc F1:  0.9365384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.90      1.00      0.95        19\n",
      "\n",
      "avg / total       0.95      0.94      0.94        33\n",
      "\n",
      "[12  2  0 19]\n",
      "LR Accuracy:  0.9393939393939394\n",
      "LR F1:  0.9365384615384615\n",
      "For name:  s_antunes\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-6686-9919': 35, '0000-0002-5512-9093': 12, '0000-0003-3218-3924': 4, '0000-0002-2264-3774': 3})\n",
      "['0000-0002-5512-9093', '0000-0002-6686-9919']\n",
      "Total sample size after apply threshold:  47\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 95)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.88      1.00      0.93        35\n",
      "\n",
      "avg / total       0.91      0.89      0.88        47\n",
      "\n",
      "[ 7  5  0 35]\n",
      "MNB Accuracy:  0.8936170212765957\n",
      "MNB F1:  0.8350877192982455\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        12\n",
      "          1       0.95      1.00      0.97        35\n",
      "\n",
      "avg / total       0.96      0.96      0.96        47\n",
      "\n",
      "[10  2  0 35]\n",
      "svc Accuracy:  0.9574468085106383\n",
      "svc F1:  0.9406565656565656\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.81      1.00      0.90        35\n",
      "\n",
      "avg / total       0.86      0.83      0.80        47\n",
      "\n",
      "[ 4  8  0 35]\n",
      "LR Accuracy:  0.8297872340425532\n",
      "LR F1:  0.6987179487179487\n",
      "For name:  k_cho\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0002-7751-0469': 55, '0000-0001-6586-983X': 47, '0000-0002-5782-6028': 15, '0000-0003-2555-5048': 6, '0000-0003-3818-9403': 1, '0000-0003-1154-4065': 1, '0000-0003-2926-3958': 1})\n",
      "['0000-0001-6586-983X', '0000-0002-7751-0469', '0000-0002-5782-6028']\n",
      "Total sample size after apply threshold:  117\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 148)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        47\n",
      "          1       0.82      1.00      0.90        55\n",
      "          2       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.76      0.87      0.81       117\n",
      "\n",
      "[47  0  0  0 55  0  3 12  0]\n",
      "MNB Accuracy:  0.8717948717948718\n",
      "MNB F1:  0.6235705030702495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        47\n",
      "          1       0.92      0.98      0.95        55\n",
      "          2       0.88      0.47      0.61        15\n",
      "\n",
      "avg / total       0.92      0.92      0.91       117\n",
      "\n",
      "[47  0  0  0 54  1  3  5  7]\n",
      "svc Accuracy:  0.9230769230769231\n",
      "svc F1:  0.841712079391666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        47\n",
      "          1       0.85      1.00      0.92        55\n",
      "          2       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.76      0.87      0.81       117\n",
      "\n",
      "[47  0  0  0 55  0  5 10  0]\n",
      "LR Accuracy:  0.8717948717948718\n",
      "LR F1:  0.6220538720538721\n",
      "For name:  j_sanderson\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-7023-8442': 24, '0000-0003-3326-9842': 3, '0000-0002-1206-8833': 2, '0000-0003-1000-2897': 1, '0000-0002-4726-4885': 1})\n",
      "['0000-0001-7023-8442']\n",
      "Total sample size after apply threshold:  24\n",
      "For name:  s_uddin\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0003-4698-2225': 13, '0000-0003-1886-6710': 8, '0000-0003-0091-6919': 8, '0000-0001-6045-6059': 8, '0000-0002-7285-4262': 2})\n",
      "['0000-0003-4698-2225']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  a_batista\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-6652-3988': 14, '0000-0003-1904-0531': 9, '0000-0003-1593-0174': 8, '0000-0002-5672-8266': 6, '0000-0001-7366-1254': 5, '0000-0002-7788-1753': 3, '0000-0002-9617-8094': 2, '0000-0002-2287-4265': 1})\n",
      "['0000-0001-6652-3988']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  h_pereira\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0003-1043-1675': 16, '0000-0002-5393-4443': 16, '0000-0002-1369-2099': 10, '0000-0003-4373-7005': 9, '0000-0002-7933-6097': 6, '0000-0002-0104-8714': 6, '0000-0002-1423-3038': 4, '0000-0001-9448-682X': 2, '0000-0002-3561-4980': 1})\n",
      "['0000-0003-1043-1675', '0000-0002-5393-4443', '0000-0002-1369-2099']\n",
      "Total sample size after apply threshold:  42\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 220)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.12        16\n",
      "          1       0.52      1.00      0.68        16\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.82      0.64      0.54        42\n",
      "\n",
      "[ 1 15  0  0 16  0  0  0 10]\n",
      "MNB Accuracy:  0.6428571428571429\n",
      "MNB F1:  0.5994993742177722\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.94      0.88        16\n",
      "          1       1.00      0.81      0.90        16\n",
      "          2       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.91      0.90      0.90        42\n",
      "\n",
      "[15  0  1  3 13  0  0  0 10]\n",
      "svc Accuracy:  0.9047619047619048\n",
      "svc F1:  0.9104285392317847\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.94      0.86        16\n",
      "          1       0.93      0.81      0.87        16\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.89      0.88      0.88        42\n",
      "\n",
      "[15  1  0  3 13  0  1  0  9]\n",
      "LR Accuracy:  0.8809523809523809\n",
      "LR F1:  0.8903926482873853\n",
      "For name:  a_patel\n",
      "total sample size before apply threshold:  262\n",
      "Counter({'0000-0003-1984-1400': 61, '0000-0001-7621-6463': 32, '0000-0002-6570-8582': 27, '0000-0003-1751-0421': 25, '0000-0002-3840-2473': 20, '0000-0002-5549-9166': 19, '0000-0001-7214-5901': 18, '0000-0003-0075-3304': 13, '0000-0003-3874-3216': 11, '0000-0002-7129-7548': 10, '0000-0002-4914-5062': 9, '0000-0002-3632-4977': 8, '0000-0001-8915-8995': 3, '0000-0003-3423-5134': 2, '0000-0002-2344-4179': 1, '0000-0001-7857-8724': 1, '0000-0003-4213-7454': 1, '0000-0002-9245-731X': 1})\n",
      "['0000-0002-6570-8582', '0000-0003-1751-0421', '0000-0002-5549-9166', '0000-0002-7129-7548', '0000-0003-3874-3216', '0000-0002-3840-2473', '0000-0001-7214-5901', '0000-0003-0075-3304', '0000-0003-1984-1400', '0000-0001-7621-6463']\n",
      "Total sample size after apply threshold:  236\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(236, 760)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        27\n",
      "          1       1.00      0.72      0.84        25\n",
      "          2       0.95      1.00      0.97        19\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.09      0.17        11\n",
      "          5       1.00      0.60      0.75        20\n",
      "          6       1.00      0.78      0.88        18\n",
      "          7       0.00      0.00      0.00        13\n",
      "          8       0.48      1.00      0.65        61\n",
      "          9       1.00      0.78      0.88        32\n",
      "\n",
      "avg / total       0.77      0.72      0.69       236\n",
      "\n",
      "[20  0  1  0  0  0  0  0  6  0  0 18  0  0  0  0  0  0  7  0  0  0 19  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  1  0  0  0\n",
      " 10  0  0  0  0  0  0 12  0  0  8  0  0  0  0  0  0  0 14  0  4  0  0  0\n",
      "  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0 61  0  0  0  0  0  0  0\n",
      "  0  0  7 25]\n",
      "MNB Accuracy:  0.7203389830508474\n",
      "MNB F1:  0.5983898172706896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        27\n",
      "          1       1.00      0.80      0.89        25\n",
      "          2       0.95      1.00      0.97        19\n",
      "          3       1.00      0.50      0.67        10\n",
      "          4       1.00      0.73      0.84        11\n",
      "          5       1.00      0.95      0.97        20\n",
      "          6       1.00      0.94      0.97        18\n",
      "          7       0.86      0.46      0.60        13\n",
      "          8       0.66      1.00      0.80        61\n",
      "          9       1.00      0.84      0.92        32\n",
      "\n",
      "avg / total       0.90      0.86      0.86       236\n",
      "\n",
      "[21  0  1  0  0  0  0  0  5  0  0 20  0  0  0  0  0  0  5  0  0  0 19  0\n",
      "  0  0  0  0  0  0  0  0  0  5  0  0  0  0  5  0  0  0  0  0  8  0  0  0\n",
      "  3  0  0  0  0  0  0 19  0  0  1  0  0  0  0  0  0  0 17  0  1  0  0  0\n",
      "  0  0  0  0  0  6  7  0  0  0  0  0  0  0  0  0 61  0  0  0  0  0  0  0\n",
      "  0  1  4 27]\n",
      "svc Accuracy:  0.8601694915254238\n",
      "svc F1:  0.8505447197063137\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        27\n",
      "          1       1.00      0.76      0.86        25\n",
      "          2       0.95      1.00      0.97        19\n",
      "          3       1.00      0.10      0.18        10\n",
      "          4       1.00      0.55      0.71        11\n",
      "          5       1.00      0.80      0.89        20\n",
      "          6       1.00      0.94      0.97        18\n",
      "          7       1.00      0.23      0.38        13\n",
      "          8       0.56      1.00      0.72        61\n",
      "          9       1.00      0.78      0.88        32\n",
      "\n",
      "avg / total       0.88      0.79      0.78       236\n",
      "\n",
      "[20  0  1  0  0  0  0  0  6  0  0 19  0  0  0  0  0  0  6  0  0  0 19  0\n",
      "  0  0  0  0  0  0  0  0  0  1  0  0  0  0  9  0  0  0  0  0  6  0  0  0\n",
      "  5  0  0  0  0  0  0 16  0  0  4  0  0  0  0  0  0  0 17  0  1  0  0  0\n",
      "  0  0  0  0  0  3 10  0  0  0  0  0  0  0  0  0 61  0  0  0  0  0  0  0\n",
      "  0  0  7 25]\n",
      "LR Accuracy:  0.7923728813559322\n",
      "LR F1:  0.7406917204139061\n",
      "For name:  r_graham\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0002-8686-4867': 41, '0000-0002-5530-8120': 9, '0000-0003-3082-8784': 1, '0000-0003-0103-2971': 1})\n",
      "['0000-0002-8686-4867']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  a_nilsson\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0001-5885-7101': 29, '0000-0002-5609-4988': 5, '0000-0002-1217-2163': 4, '0000-0002-9476-4516': 2, '0000-0001-5774-7189': 1, '0000-0003-1968-8696': 1})\n",
      "['0000-0001-5885-7101']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  m_soto\n",
      "total sample size before apply threshold:  97\n",
      "Counter({'0000-0002-4541-8182': 40, '0000-0003-2045-7238': 30, '0000-0002-4843-556X': 14, '0000-0002-2140-2012': 13})\n",
      "['0000-0002-4541-8182', '0000-0002-2140-2012', '0000-0002-4843-556X', '0000-0003-2045-7238']\n",
      "Total sample size after apply threshold:  97\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(97, 226)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        40\n",
      "          1       1.00      0.77      0.87        13\n",
      "          2       1.00      0.43      0.60        14\n",
      "          3       1.00      0.93      0.97        30\n",
      "\n",
      "avg / total       0.90      0.87      0.86        97\n",
      "\n",
      "[40  0  0  0  3 10  0  0  8  0  6  0  2  0  0 28]\n",
      "MNB Accuracy:  0.865979381443299\n",
      "MNB F1:  0.823824378133514\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        40\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       1.00      0.50      0.67        14\n",
      "          3       0.96      0.90      0.93        30\n",
      "\n",
      "avg / total       0.91      0.89      0.88        97\n",
      "\n",
      "[40  0  0  0  1 12  0  0  6  0  7  1  3  0  0 27]\n",
      "svc Accuracy:  0.8865979381443299\n",
      "svc F1:  0.8616475095785441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      1.00      0.82        40\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       1.00      0.36      0.53        14\n",
      "          3       1.00      0.87      0.93        30\n",
      "\n",
      "avg / total       0.87      0.81      0.80        97\n",
      "\n",
      "[40  0  0  0  5  8  0  0  9  0  5  0  4  0  0 26]\n",
      "LR Accuracy:  0.8144329896907216\n",
      "LR F1:  0.7582796276405299\n",
      "For name:  g_guidi\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0002-3061-9870': 15, '0000-0003-3199-6624': 11, '0000-0001-9535-9152': 5, '0000-0002-1393-326X': 4, '0000-0002-8857-0096': 2})\n",
      "['0000-0003-3199-6624', '0000-0002-3061-9870']\n",
      "Total sample size after apply threshold:  26\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 1492)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        11\n",
      "          1       0.93      0.93      0.93        15\n",
      "\n",
      "avg / total       0.92      0.92      0.92        26\n",
      "\n",
      "[10  1  1 14]\n",
      "MNB Accuracy:  0.9230769230769231\n",
      "MNB F1:  0.9212121212121211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        26\n",
      "\n",
      "[11  0  0 15]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        26\n",
      "\n",
      "[11  0  0 15]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  e_andersson\n",
      "total sample size before apply threshold:  138\n",
      "Counter({'0000-0002-7864-1014': 36, '0000-0003-0088-8719': 33, '0000-0002-2854-0354': 29, '0000-0003-3095-465X': 26, '0000-0001-5856-6806': 10, '0000-0002-8608-625X': 2, '0000-0001-8453-2079': 1, '0000-0003-3398-0132': 1})\n",
      "['0000-0001-5856-6806', '0000-0003-3095-465X', '0000-0002-2854-0354', '0000-0003-0088-8719', '0000-0002-7864-1014']\n",
      "Total sample size after apply threshold:  134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 375)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "134\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        10\n",
      "          1       1.00      0.81      0.89        26\n",
      "          2       0.88      1.00      0.94        29\n",
      "          3       0.97      1.00      0.99        33\n",
      "          4       0.80      1.00      0.89        36\n",
      "\n",
      "avg / total       0.91      0.90      0.87       134\n",
      "\n",
      "[ 1  0  1  1  7  0 21  3  0  2  0  0 29  0  0  0  0  0 33  0  0  0  0  0\n",
      " 36]\n",
      "MNB Accuracy:  0.8955223880597015\n",
      "MNB F1:  0.776976517963416\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.80      0.92      0.86        26\n",
      "          2       1.00      0.97      0.98        29\n",
      "          3       1.00      0.94      0.97        33\n",
      "          4       0.85      0.97      0.91        36\n",
      "\n",
      "avg / total       0.92      0.91      0.90       134\n",
      "\n",
      "[ 4  3  0  0  3  0 24  0  0  2  0  0 28  0  1  0  2  0 31  0  0  1  0  0\n",
      " 35]\n",
      "svc Accuracy:  0.9104477611940298\n",
      "svc F1:  0.8577736956026429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        10\n",
      "          1       1.00      0.85      0.92        26\n",
      "          2       1.00      0.93      0.96        29\n",
      "          3       1.00      0.97      0.98        33\n",
      "          4       0.69      1.00      0.82        36\n",
      "\n",
      "avg / total       0.92      0.88      0.86       134\n",
      "\n",
      "[ 1  0  0  0  9  0 22  0  0  4  0  0 27  0  2  0  0  0 32  1  0  0  0  0\n",
      " 36]\n",
      "LR Accuracy:  0.8805970149253731\n",
      "LR F1:  0.773113553113553\n",
      "For name:  s_reid\n",
      "total sample size before apply threshold:  132\n",
      "Counter({'0000-0001-9916-7414': 43, '0000-0002-6103-4429': 42, '0000-0001-7779-4820': 34, '0000-0002-8068-6529': 12, '0000-0001-9415-5246': 1})\n",
      "['0000-0001-7779-4820', '0000-0001-9916-7414', '0000-0002-8068-6529', '0000-0002-6103-4429']\n",
      "Total sample size after apply threshold:  131\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(131, 396)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        34\n",
      "          1       0.87      0.95      0.91        43\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       0.89      0.93      0.91        42\n",
      "\n",
      "avg / total       0.92      0.92      0.92       131\n",
      "\n",
      "[31  1  0  2  0 41  0  2  0  2  9  1  0  3  0 39]\n",
      "MNB Accuracy:  0.916030534351145\n",
      "MNB F1:  0.9072692165715421\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        34\n",
      "          1       1.00      0.91      0.95        43\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       0.81      1.00      0.89        42\n",
      "\n",
      "avg / total       0.94      0.92      0.93       131\n",
      "\n",
      "[30  0  0  4  0 39  0  4  0  0 10  2  0  0  0 42]\n",
      "svc Accuracy:  0.9236641221374046\n",
      "svc F1:  0.9228568606406566\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        34\n",
      "          1       1.00      0.91      0.95        43\n",
      "          2       1.00      0.67      0.80        12\n",
      "          3       0.78      1.00      0.88        42\n",
      "\n",
      "avg / total       0.93      0.91      0.91       131\n",
      "\n",
      "[30  0  0  4  0 39  0  4  0  0  8  4  0  0  0 42]\n",
      "LR Accuracy:  0.9083969465648855\n",
      "LR F1:  0.8909298780487804\n",
      "For name:  a_maleki\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0001-5490-3350': 15, '0000-0001-8261-8717': 5, '0000-0003-3203-7492': 4, '0000-0001-7888-1985': 1})\n",
      "['0000-0001-5490-3350']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  j_moon\n",
      "total sample size before apply threshold:  203\n",
      "Counter({'0000-0001-8071-1491': 96, '0000-0001-6327-0575': 23, '0000-0001-7776-6889': 19, '0000-0002-9182-5475': 17, '0000-0001-9760-297X': 13, '0000-0002-9274-4554': 12, '0000-0002-8625-6562': 8, '0000-0003-1282-4528': 7, '0000-0003-1569-3068': 2, '0000-0003-1428-414X': 2, '0000-0002-7049-892X': 1, '0000-0001-8246-931X': 1, '0000-0003-4742-8744': 1, '0000-0002-4630-3301': 1})\n",
      "['0000-0001-7776-6889', '0000-0002-9274-4554', '0000-0001-8071-1491', '0000-0001-9760-297X', '0000-0002-9182-5475', '0000-0001-6327-0575']\n",
      "Total sample size after apply threshold:  180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(180, 623)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "180\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.53      0.69        19\n",
      "          1       1.00      0.08      0.15        12\n",
      "          2       0.73      0.94      0.82        96\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       1.00      0.82      0.90        17\n",
      "          5       0.74      1.00      0.85        23\n",
      "\n",
      "avg / total       0.75      0.77      0.71       180\n",
      "\n",
      "[10  0  9  0  0  0  0  1 11  0  0  0  0  0 90  0  0  6  0  0 11  0  0  2\n",
      "  0  0  3  0 14  0  0  0  0  0  0 23]\n",
      "MNB Accuracy:  0.7666666666666667\n",
      "MNB F1:  0.5694601337908717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        19\n",
      "          1       1.00      0.42      0.59        12\n",
      "          2       0.81      0.94      0.87        96\n",
      "          3       0.83      0.38      0.53        13\n",
      "          4       1.00      0.88      0.94        17\n",
      "          5       0.79      1.00      0.88        23\n",
      "\n",
      "avg / total       0.86      0.84      0.83       180\n",
      "\n",
      "[14  0  5  0  0  0  0  5  7  0  0  0  0  0 90  1  0  5  0  0  7  5  0  1\n",
      "  0  0  2  0 15  0  0  0  0  0  0 23]\n",
      "svc Accuracy:  0.8444444444444444\n",
      "svc F1:  0.7757860890138114\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        19\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.71      0.96      0.81        96\n",
      "          3       1.00      0.08      0.14        13\n",
      "          4       1.00      0.88      0.94        17\n",
      "          5       0.81      0.91      0.86        23\n",
      "\n",
      "avg / total       0.75      0.76      0.71       180\n",
      "\n",
      "[ 8  0 11  0  0  0  0  0 12  0  0  0  0  0 92  0  0  4  0  0 11  1  0  1\n",
      "  0  0  2  0 15  0  0  0  2  0  0 21]\n",
      "LR Accuracy:  0.7611111111111111\n",
      "LR F1:  0.5573753141046651\n",
      "For name:  t_abe\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0003-3496-1953': 19, '0000-0002-4185-5254': 17, '0000-0001-5298-082X': 12, '0000-0003-1251-7448': 2})\n",
      "['0000-0002-4185-5254', '0000-0001-5298-082X', '0000-0003-3496-1953']\n",
      "Total sample size after apply threshold:  48\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 117)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        17\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       0.90      1.00      0.95        19\n",
      "\n",
      "avg / total       0.96      0.96      0.96        48\n",
      "\n",
      "[16  0  1  0 11  1  0  0 19]\n",
      "MNB Accuracy:  0.9583333333333334\n",
      "MNB F1:  0.9587395696091349\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        17\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       0.98      0.98      0.98        48\n",
      "\n",
      "[17  0  0  1 11  0  0  0 19]\n",
      "svc Accuracy:  0.9791666666666666\n",
      "svc F1:  0.975983436853002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        17\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       0.98      0.98      0.98        48\n",
      "\n",
      "[17  0  0  1 11  0  0  0 19]\n",
      "LR Accuracy:  0.9791666666666666\n",
      "LR F1:  0.975983436853002\n",
      "For name:  x_fu\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-6928-4396': 8, '0000-0001-9295-6314': 6, '0000-0002-8012-4753': 1, '0000-0002-4305-6624': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  f_ortega\n",
      "total sample size before apply threshold:  368\n",
      "Counter({'0000-0003-2001-1121': 205, '0000-0003-2111-769X': 86, '0000-0002-4730-9270': 38, '0000-0002-3172-2095': 22, '0000-0002-7431-354X': 9, '0000-0001-7850-2105': 7, '0000-0003-0231-2051': 1})\n",
      "['0000-0002-3172-2095', '0000-0003-2001-1121', '0000-0002-4730-9270', '0000-0003-2111-769X']\n",
      "Total sample size after apply threshold:  351\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(351, 723)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "351\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        22\n",
      "          1       0.93      0.99      0.96       205\n",
      "          2       1.00      0.92      0.96        38\n",
      "          3       0.97      1.00      0.98        86\n",
      "\n",
      "avg / total       0.95      0.95      0.94       351\n",
      "\n",
      "[  9  13   0   0   0 203   0   2   0   2  35   1   0   0   0  86]\n",
      "MNB Accuracy:  0.9487179487179487\n",
      "MNB F1:  0.8705543221102495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        22\n",
      "          1       0.94      1.00      0.97       205\n",
      "          2       1.00      0.92      0.96        38\n",
      "          3       1.00      0.95      0.98        86\n",
      "\n",
      "avg / total       0.97      0.97      0.97       351\n",
      "\n",
      "[ 17   5   0   0   0 205   0   0   0   3  35   0   0   4   0  82]\n",
      "svc Accuracy:  0.9658119658119658\n",
      "svc F1:  0.9446133596542607\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        22\n",
      "          1       0.88      1.00      0.93       205\n",
      "          2       1.00      0.87      0.93        38\n",
      "          3       1.00      0.90      0.94        86\n",
      "\n",
      "avg / total       0.93      0.92      0.91       351\n",
      "\n",
      "[  7  15   0   0   0 205   0   0   0   5  33   0   0   9   0  77]\n",
      "LR Accuracy:  0.9173789173789174\n",
      "LR F1:  0.8227655340098696\n",
      "For name:  r_morris\n",
      "total sample size before apply threshold:  409\n",
      "Counter({'0000-0001-7240-4563': 107, '0000-0001-7809-0315': 73, '0000-0001-8661-1520': 59, '0000-0002-7574-9388': 51, '0000-0003-3080-2613': 44, '0000-0002-5018-1239': 21, '0000-0001-7431-6401': 20, '0000-0001-7450-5923': 14, '0000-0001-5511-3457': 10, '0000-0003-4764-3639': 7, '0000-0001-7443-7406': 2, '0000-0002-9193-3417': 1})\n",
      "['0000-0003-3080-2613', '0000-0002-5018-1239', '0000-0001-7809-0315', '0000-0001-5511-3457', '0000-0001-7240-4563', '0000-0001-7431-6401', '0000-0002-7574-9388', '0000-0001-8661-1520', '0000-0001-7450-5923']\n",
      "Total sample size after apply threshold:  399\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(399, 1936)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "399\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.66      0.79        44\n",
      "          1       1.00      0.14      0.25        21\n",
      "          2       0.90      0.88      0.89        73\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.50      0.97      0.66       107\n",
      "          5       1.00      0.25      0.40        20\n",
      "          6       1.00      0.80      0.89        51\n",
      "          7       0.97      0.64      0.78        59\n",
      "          8       1.00      0.29      0.44        14\n",
      "\n",
      "avg / total       0.82      0.72      0.71       399\n",
      "\n",
      "[ 29   0   1   0  14   0   0   0   0   0   3   0   0  18   0   0   0   0\n",
      "   0   0  64   0   9   0   0   0   0   0   0   0   0  10   0   0   0   0\n",
      "   0   0   2   0 104   0   0   1   0   0   0   1   0  14   5   0   0   0\n",
      "   0   0   1   0   9   0  41   0   0   0   0   2   0  19   0   0  38   0\n",
      "   0   0   0   0  10   0   0   0   4]\n",
      "MNB Accuracy:  0.7218045112781954\n",
      "MNB F1:  0.5674543128168738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        44\n",
      "          1       1.00      0.86      0.92        21\n",
      "          2       0.94      0.88      0.91        73\n",
      "          3       1.00      0.80      0.89        10\n",
      "          4       0.82      0.95      0.88       107\n",
      "          5       1.00      0.70      0.82        20\n",
      "          6       1.00      0.76      0.87        51\n",
      "          7       0.66      0.92      0.77        59\n",
      "          8       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.89      0.86      0.87       399\n",
      "\n",
      "[ 34   0   0   0   5   0   0   5   0   0  18   0   0   1   0   0   2   0\n",
      "   0   0  64   0   3   0   0   6   0   0   0   0   8   2   0   0   0   0\n",
      "   0   0   2   0 102   0   0   3   0   0   0   1   0   4  14   0   1   0\n",
      "   0   0   0   0   3   0  39   9   0   0   0   1   0   4   0   0  54   0\n",
      "   0   0   0   0   1   0   0   2  11]\n",
      "svc Accuracy:  0.8621553884711779\n",
      "svc F1:  0.8674473302519855\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        44\n",
      "          1       1.00      0.52      0.69        21\n",
      "          2       0.95      0.86      0.91        73\n",
      "          3       1.00      0.30      0.46        10\n",
      "          4       0.57      0.98      0.72       107\n",
      "          5       1.00      0.55      0.71        20\n",
      "          6       1.00      0.78      0.88        51\n",
      "          7       1.00      0.68      0.81        59\n",
      "          8       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.88      0.79      0.80       399\n",
      "\n",
      "[ 32   0   0   0  12   0   0   0   0   0  11   0   0  10   0   0   0   0\n",
      "   0   0  63   0  10   0   0   0   0   0   0   0   3   7   0   0   0   0\n",
      "   0   0   2   0 105   0   0   0   0   0   0   0   0   9  11   0   0   0\n",
      "   0   0   0   0  11   0  40   0   0   0   0   1   0  18   0   0  40   0\n",
      "   0   0   0   0   3   0   0   0  11]\n",
      "LR Accuracy:  0.7919799498746867\n",
      "LR F1:  0.7659639703987275\n",
      "For name:  w_fang\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0002-8431-8256': 31, '0000-0002-9580-3716': 6, '0000-0002-2449-3749': 3, '0000-0002-9724-898X': 3})\n",
      "['0000-0002-8431-8256']\n",
      "Total sample size after apply threshold:  31\n",
      "For name:  m_amaral\n",
      "total sample size before apply threshold:  134\n",
      "Counter({'0000-0002-0828-8630': 101, '0000-0002-3209-3366': 21, '0000-0003-4966-2614': 6, '0000-0002-4301-2760': 4, '0000-0001-5607-6475': 1, '0000-0001-9686-1312': 1})\n",
      "['0000-0002-0828-8630', '0000-0002-3209-3366']\n",
      "Total sample size after apply threshold:  122\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(122, 442)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       101\n",
      "          1       1.00      0.43      0.60        21\n",
      "\n",
      "avg / total       0.91      0.90      0.88       122\n",
      "\n",
      "[101   0  12   9]\n",
      "MNB Accuracy:  0.9016393442622951\n",
      "MNB F1:  0.7719626168224298\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       101\n",
      "          1       0.95      0.86      0.90        21\n",
      "\n",
      "avg / total       0.97      0.97      0.97       122\n",
      "\n",
      "[100   1   3  18]\n",
      "svc Accuracy:  0.9672131147540983\n",
      "svc F1:  0.9401960784313725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       101\n",
      "          1       1.00      0.05      0.09        21\n",
      "\n",
      "avg / total       0.86      0.84      0.77       122\n",
      "\n",
      "[101   0  20   1]\n",
      "LR Accuracy:  0.8360655737704918\n",
      "LR F1:  0.5004095004095004\n",
      "For name:  h_song\n",
      "total sample size before apply threshold:  210\n",
      "Counter({'0000-0001-5684-4059': 88, '0000-0001-5553-2539': 30, '0000-0002-3134-782X': 29, '0000-0003-3845-8079': 20, '0000-0002-7844-2293': 14, '0000-0001-5486-2560': 8, '0000-0002-8720-6436': 6, '0000-0002-2721-3626': 2, '0000-0002-3563-9504': 2, '0000-0003-2197-1562': 2, '0000-0002-9849-8091': 2, '0000-0002-2164-8813': 2, '0000-0001-6000-1572': 1, '0000-0001-5747-8847': 1, '0000-0002-2791-1723': 1, '0000-0002-4204-6459': 1, '0000-0003-2631-9223': 1})\n",
      "['0000-0002-3134-782X', '0000-0002-7844-2293', '0000-0001-5684-4059', '0000-0001-5553-2539', '0000-0003-3845-8079']\n",
      "Total sample size after apply threshold:  181\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 1094)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "181\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        29\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.69      1.00      0.82        88\n",
      "          3       0.85      0.57      0.68        30\n",
      "          4       1.00      0.40      0.57        20\n",
      "\n",
      "avg / total       0.75      0.77      0.73       181\n",
      "\n",
      "[26  0  1  2  0  0  0 14  0  0  0  0 88  0  0  0  0 13 17  0  0  0 11  1\n",
      "  8]\n",
      "MNB Accuracy:  0.7679558011049724\n",
      "MNB F1:  0.6030975536091816\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        29\n",
      "          1       1.00      0.36      0.53        14\n",
      "          2       0.88      1.00      0.94        88\n",
      "          3       0.87      0.90      0.89        30\n",
      "          4       0.94      0.80      0.86        20\n",
      "\n",
      "avg / total       0.91      0.91      0.90       181\n",
      "\n",
      "[28  0  0  1  0  0  5  9  0  0  0  0 88  0  0  0  0  2 27  1  0  0  1  3\n",
      " 16]\n",
      "svc Accuracy:  0.9060773480662984\n",
      "svc F1:  0.8390105818189456\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        29\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.73      1.00      0.85        88\n",
      "          3       0.96      0.77      0.85        30\n",
      "          4       1.00      0.45      0.62        20\n",
      "\n",
      "avg / total       0.79      0.82      0.78       181\n",
      "\n",
      "[28  0  1  0  0  0  0 14  0  0  0  0 88  0  0  0  0  7 23  0  0  0 10  1\n",
      "  9]\n",
      "LR Accuracy:  0.8176795580110497\n",
      "LR F1:  0.6602302987057977\n",
      "For name:  h_dai\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0003-1395-7904': 2, '0000-0002-1516-7255': 2, '0000-0003-3807-4585': 1, '0000-0001-6165-4196': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  y_nakajima\n",
      "total sample size before apply threshold:  12\n",
      "Counter({'0000-0001-6558-5378': 8, '0000-0001-9759-3487': 2, '0000-0002-7153-6238': 1, '0000-0002-7357-2910': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_warner\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0003-3988-4408': 56, '0000-0003-0604-0110': 6, '0000-0003-1809-102X': 3, '0000-0001-8397-6030': 3})\n",
      "['0000-0003-3988-4408']\n",
      "Total sample size after apply threshold:  56\n",
      "For name:  s_saha\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0001-9433-8894': 24, '0000-0001-6610-4820': 23, '0000-0002-0087-8652': 14, '0000-0001-8780-9117': 12, '0000-0001-6631-0464': 8, '0000-0003-3029-7995': 5, '0000-0003-1060-9402': 5, '0000-0003-1534-7130': 4, '0000-0002-5791-8635': 3, '0000-0002-8312-6711': 3, '0000-0003-1742-2974': 2, '0000-0003-2366-8620': 2, '0000-0002-7184-6906': 2, '0000-0002-7487-9885': 1, '0000-0001-6844-2516': 1, '0000-0002-6655-4001': 1, '0000-0001-9742-3306': 1})\n",
      "['0000-0002-0087-8652', '0000-0001-8780-9117', '0000-0001-9433-8894', '0000-0001-6610-4820']\n",
      "Total sample size after apply threshold:  73\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 210)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        14\n",
      "          1       1.00      0.25      0.40        12\n",
      "          2       0.67      1.00      0.80        24\n",
      "          3       0.92      1.00      0.96        23\n",
      "\n",
      "avg / total       0.87      0.81      0.78        73\n",
      "\n",
      "[ 9  0  4  1  0  3  8  1  0  0 24  0  0  0  0 23]\n",
      "MNB Accuracy:  0.8082191780821918\n",
      "MNB F1:  0.7352355072463769\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.79      0.85        14\n",
      "          1       0.91      0.83      0.87        12\n",
      "          2       0.82      0.96      0.88        24\n",
      "          3       1.00      0.96      0.98        23\n",
      "\n",
      "avg / total       0.91      0.90      0.90        73\n",
      "\n",
      "[11  1  2  0  0 10  2  0  1  0 23  0  0  0  1 22]\n",
      "svc Accuracy:  0.9041095890410958\n",
      "svc F1:  0.8945280564845782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        14\n",
      "          1       1.00      0.33      0.50        12\n",
      "          2       0.63      1.00      0.77        24\n",
      "          3       0.95      0.91      0.93        23\n",
      "\n",
      "avg / total       0.86      0.79      0.78        73\n",
      "\n",
      "[ 9  0  5  0  0  4  7  1  0  0 24  0  0  0  2 21]\n",
      "LR Accuracy:  0.7945205479452054\n",
      "LR F1:  0.747533894343151\n",
      "For name:  j_fernandez\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0003-2222-3355': 7, '0000-0002-4190-7341': 5, '0000-0003-2969-8150': 5, '0000-0003-4756-6645': 5, '0000-0002-8533-1858': 1, '0000-0003-4427-3935': 1, '0000-0002-7315-2326': 1, '0000-0002-7629-6106': 1, '0000-0001-5894-9866': 1, '0000-0002-9528-6173': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_pan\n",
      "total sample size before apply threshold:  146\n",
      "Counter({'0000-0002-5188-7030': 128, '0000-0001-5535-2714': 10, '0000-0001-5697-6086': 6, '0000-0003-1485-3154': 1, '0000-0003-3350-8719': 1})\n",
      "['0000-0001-5535-2714', '0000-0002-5188-7030']\n",
      "Total sample size after apply threshold:  138\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(138, 119)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "138\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.93      1.00      0.96       128\n",
      "\n",
      "avg / total       0.86      0.93      0.89       138\n",
      "\n",
      "[  0  10   0 128]\n",
      "MNB Accuracy:  0.927536231884058\n",
      "MNB F1:  0.48120300751879697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.30      0.43        10\n",
      "          1       0.95      0.99      0.97       128\n",
      "\n",
      "avg / total       0.93      0.94      0.93       138\n",
      "\n",
      "[  3   7   1 127]\n",
      "svc Accuracy:  0.9420289855072463\n",
      "svc F1:  0.6990185387131951\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.93      1.00      0.96       128\n",
      "\n",
      "avg / total       0.86      0.93      0.89       138\n",
      "\n",
      "[  0  10   0 128]\n",
      "LR Accuracy:  0.927536231884058\n",
      "LR F1:  0.48120300751879697\n",
      "For name:  a_simon\n",
      "total sample size before apply threshold:  117\n",
      "Counter({'0000-0002-6141-7921': 60, '0000-0002-0151-0120': 19, '0000-0002-6509-4541': 14, '0000-0001-6023-6427': 14, '0000-0002-1879-5628': 5, '0000-0002-3286-5776': 4, '0000-0003-4641-6186': 1})\n",
      "['0000-0002-6141-7921', '0000-0002-6509-4541', '0000-0002-0151-0120', '0000-0001-6023-6427']\n",
      "Total sample size after apply threshold:  107\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 437)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "107\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        60\n",
      "          1       1.00      0.14      0.25        14\n",
      "          2       1.00      0.84      0.91        19\n",
      "          3       1.00      0.71      0.83        14\n",
      "\n",
      "avg / total       0.87      0.82      0.79       107\n",
      "\n",
      "[60  0  0  0 12  2  0  0  3  0 16  0  4  0  0 10]\n",
      "MNB Accuracy:  0.822429906542056\n",
      "MNB F1:  0.7152321000342583\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90        60\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       1.00      0.84      0.91        19\n",
      "          3       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.89      0.87      0.86       107\n",
      "\n",
      "[60  0  0  0  8  6  0  0  3  0 16  0  3  0  0 11]\n",
      "svc Accuracy:  0.8691588785046729\n",
      "svc F1:  0.8224520255863539\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82        60\n",
      "          1       1.00      0.07      0.13        14\n",
      "          2       1.00      0.63      0.77        19\n",
      "          3       1.00      0.57      0.73        14\n",
      "\n",
      "avg / total       0.83      0.76      0.71       107\n",
      "\n",
      "[60  0  0  0 13  1  0  0  7  0 12  0  6  0  0  8]\n",
      "LR Accuracy:  0.7570093457943925\n",
      "LR F1:  0.6141793543030838\n",
      "For name:  r_freitas\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0003-4900-3897': 48, '0000-0001-8605-2925': 6, '0000-0002-0123-7232': 6, '0000-0002-4448-6458': 5, '0000-0001-5811-5255': 5, '0000-0002-1645-4125': 2, '0000-0001-8836-1422': 1})\n",
      "['0000-0003-4900-3897']\n",
      "Total sample size after apply threshold:  48\n",
      "For name:  c_yun\n",
      "total sample size before apply threshold:  284\n",
      "Counter({'0000-0002-9466-4531': 149, '0000-0002-0041-2887': 98, '0000-0003-2204-8067': 36, '0000-0002-6747-4628': 1})\n",
      "['0000-0002-9466-4531', '0000-0002-0041-2887', '0000-0003-2204-8067']\n",
      "Total sample size after apply threshold:  283\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(283, 1324)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.97      0.86       149\n",
      "          1       0.88      0.84      0.86        98\n",
      "          2       0.00      0.00      0.00        36\n",
      "\n",
      "avg / total       0.71      0.80      0.75       283\n",
      "\n",
      "[145   4   0  15  82   1  29   7   0]\n",
      "MNB Accuracy:  0.8021201413427562\n",
      "MNB F1:  0.5722089697119902\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.93      0.89       149\n",
      "          1       0.86      0.93      0.89        98\n",
      "          2       0.79      0.31      0.44        36\n",
      "\n",
      "avg / total       0.85      0.85      0.83       283\n",
      "\n",
      "[139   8   2   6  91   1  18   7  11]\n",
      "svc Accuracy:  0.8515901060070671\n",
      "svc F1:  0.7410608345902464\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.95      0.86       149\n",
      "          1       0.89      0.86      0.88        98\n",
      "          2       0.83      0.14      0.24        36\n",
      "\n",
      "avg / total       0.82      0.82      0.78       283\n",
      "\n",
      "[142   6   1  14  84   0  27   4   5]\n",
      "LR Accuracy:  0.8162544169611308\n",
      "LR F1:  0.656172308280742\n",
      "For name:  j_huang\n",
      "total sample size before apply threshold:  443\n",
      "Counter({'0000-0001-8011-2317': 69, '0000-0001-9207-8953': 68, '0000-0001-5495-3577': 68, '0000-0002-2742-5557': 32, '0000-0001-8993-2506': 25, '0000-0002-7027-3042': 22, '0000-0003-3282-8892': 21, '0000-0003-0996-9451': 18, '0000-0002-7163-5156': 17, '0000-0002-4452-4557': 15, '0000-0001-7281-663X': 14, '0000-0002-4569-0629': 12, '0000-0002-5761-2177': 12, '0000-0002-9570-4101': 10, '0000-0001-9069-5739': 8, '0000-0001-9639-2907': 6, '0000-0002-0901-9635': 5, '0000-0003-4435-7274': 4, '0000-0002-4051-4482': 4, '0000-0002-5153-506X': 3, '0000-0001-7288-9724': 2, '0000-0003-1776-9863': 1, '0000-0003-2314-7104': 1, '0000-0002-7531-4691': 1, '0000-0001-8111-0583': 1, '0000-0001-6589-4963': 1, '0000-0002-6135-1256': 1, '0000-0002-5736-6148': 1, '0000-0002-4189-3779': 1})\n",
      "['0000-0003-3282-8892', '0000-0001-9207-8953', '0000-0001-8011-2317', '0000-0002-7163-5156', '0000-0001-7281-663X', '0000-0001-8993-2506', '0000-0002-9570-4101', '0000-0002-2742-5557', '0000-0002-4569-0629', '0000-0002-4452-4557', '0000-0002-7027-3042', '0000-0003-0996-9451', '0000-0002-5761-2177', '0000-0001-5495-3577']\n",
      "Total sample size after apply threshold:  403\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(403, 752)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "403\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        21\n",
      "          1       0.44      1.00      0.61        68\n",
      "          2       0.50      1.00      0.66        69\n",
      "          3       0.00      0.00      0.00        17\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       1.00      0.68      0.81        25\n",
      "          6       0.00      0.00      0.00        10\n",
      "          7       1.00      0.38      0.55        32\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.00      0.00      0.00        15\n",
      "         10       1.00      0.23      0.37        22\n",
      "         11       1.00      0.22      0.36        18\n",
      "         12       0.00      0.00      0.00        12\n",
      "         13       0.92      0.85      0.89        68\n",
      "\n",
      "avg / total       0.61      0.60      0.53       403\n",
      "\n",
      "[ 9 10  2  0  0  0  0  0  0  0  0  0  0  0  0 68  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 69  0  0  0  0  0  0  0  0  0  0  0  0 14  3  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  9  4  0  0  0  0  0  0  0  0  0  0  1  0  7\n",
      "  1  0  0 17  0  0  0  0  0  0  0  0  0  7  3  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 11  9  0  0  0  0 12  0  0  0  0  0  0  0  4  5  0  0  0  0  0\n",
      "  0  0  0  0  0  3  0  2 13  0  0  0  0  0  0  0  0  0  0  0  0  3 14  0\n",
      "  0  0  0  0  0  0  5  0  0  0  0 13  0  0  0  0  0  0  0  0  0  4  0  1\n",
      "  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  6  4  0  0  0  0  0  0  0\n",
      "  0  0  0 58]\n",
      "MNB Accuracy:  0.6004962779156328\n",
      "MNB F1:  0.3464682445189533\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        21\n",
      "          1       0.96      1.00      0.98        68\n",
      "          2       0.79      0.97      0.87        69\n",
      "          3       0.64      0.53      0.58        17\n",
      "          4       0.88      0.50      0.64        14\n",
      "          5       1.00      0.88      0.94        25\n",
      "          6       1.00      0.90      0.95        10\n",
      "          7       0.89      0.75      0.81        32\n",
      "          8       1.00      0.58      0.74        12\n",
      "          9       1.00      0.60      0.75        15\n",
      "         10       0.79      0.68      0.73        22\n",
      "         11       1.00      0.78      0.88        18\n",
      "         12       1.00      0.67      0.80        12\n",
      "         13       0.71      1.00      0.83        68\n",
      "\n",
      "avg / total       0.87      0.85      0.84       403\n",
      "\n",
      "[14  0  0  3  0  0  0  0  0  0  1  0  0  3  0 68  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 67  0  0  0  0  0  0  0  1  0  0  1  0  0  1  9  1  0\n",
      "  0  0  0  0  0  0  0  6  0  2  0  1  7  0  0  0  0  0  0  0  0  4  0  0\n",
      "  0  1  0 22  0  1  0  0  0  0  0  1  0  0  0  0  0  0  9  1  0  0  0  0\n",
      "  0  0  0  1  0  0  0  0  0 24  0  0  0  0  0  7  0  0  3  0  0  0  0  0\n",
      "  7  0  0  0  0  2  0  0  5  0  0  0  0  0  0  9  1  0  0  0  0  0  7  0\n",
      "  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  4\n",
      "  0  0  2  0  0  0  0  1  0  0  1  0  8  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 68]\n",
      "svc Accuracy:  0.8461538461538461\n",
      "svc F1:  0.8061051146316159\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.62      0.74        21\n",
      "          1       0.85      1.00      0.92        68\n",
      "          2       0.72      0.99      0.83        69\n",
      "          3       0.62      0.29      0.40        17\n",
      "          4       1.00      0.21      0.35        14\n",
      "          5       1.00      0.84      0.91        25\n",
      "          6       1.00      0.80      0.89        10\n",
      "          7       1.00      0.47      0.64        32\n",
      "          8       1.00      0.42      0.59        12\n",
      "          9       1.00      0.20      0.33        15\n",
      "         10       1.00      0.50      0.67        22\n",
      "         11       1.00      0.39      0.56        18\n",
      "         12       1.00      0.42      0.59        12\n",
      "         13       0.53      1.00      0.69        68\n",
      "\n",
      "avg / total       0.83      0.74      0.72       403\n",
      "\n",
      "[13  2  0  2  0  0  0  0  0  0  0  0  0  4  0 68  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 68  0  0  0  0  0  0  0  0  0  0  1  0  2  1  5  0  0\n",
      "  0  0  0  0  0  0  0  9  1  4  0  1  3  0  0  0  0  0  0  0  0  5  0  1\n",
      "  0  0  0 21  0  0  0  0  0  0  0  3  0  0  0  0  0  0  8  0  0  0  0  0\n",
      "  0  2  0  1  0  0  0  0  0 15  0  0  0  0  0 16  0  0  3  0  0  0  0  0\n",
      "  5  0  0  0  0  4  0  2  8  0  0  0  0  0  0  3  0  0  0  2  0  0  8  0\n",
      "  0  0  0  0  0  0 11  0  0  3  0  0  0  0  0  0  0  0  0  0  0  7  0 11\n",
      "  0  0  6  0  0  0  0  0  0  0  0  0  5  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 68]\n",
      "LR Accuracy:  0.7444168734491315\n",
      "LR F1:  0.6511520874387304\n",
      "For name:  p_santos\n",
      "total sample size before apply threshold:  92\n",
      "Counter({'0000-0003-3234-4265': 24, '0000-0002-2225-455X': 17, '0000-0003-3548-700X': 16, '0000-0001-9669-9837': 9, '0000-0002-8723-4373': 8, '0000-0002-2362-5527': 4, '0000-0002-3363-0098': 3, '0000-0003-3045-4591': 3, '0000-0001-7907-5133': 2, '0000-0002-4188-7766': 1, '0000-0002-0257-592X': 1, '0000-0003-2505-8420': 1, '0000-0002-2537-5904': 1, '0000-0003-1179-3096': 1, '0000-0001-9785-0180': 1})\n",
      "['0000-0003-3548-700X', '0000-0003-3234-4265', '0000-0002-2225-455X']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 158)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91        16\n",
      "          1       1.00      0.83      0.91        24\n",
      "          2       0.85      1.00      0.92        17\n",
      "\n",
      "avg / total       0.92      0.91      0.91        57\n",
      "\n",
      "[15  0  1  2 20  2  0  0 17]\n",
      "MNB Accuracy:  0.9122807017543859\n",
      "MNB F1:  0.9123669123669123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        16\n",
      "          1       0.96      0.92      0.94        24\n",
      "          2       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.95      0.95      0.95        57\n",
      "\n",
      "[15  1  0  1 22  1  0  0 17]\n",
      "svc Accuracy:  0.9473684210526315\n",
      "svc F1:  0.9483662613981764\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        16\n",
      "          1       0.96      0.96      0.96        24\n",
      "          2       0.94      0.94      0.94        17\n",
      "\n",
      "avg / total       0.95      0.95      0.95        57\n",
      "\n",
      "[15  0  1  1 23  0  0  1 16]\n",
      "LR Accuracy:  0.9473684210526315\n",
      "LR F1:  0.9456699346405228\n",
      "For name:  n_young\n",
      "total sample size before apply threshold:  182\n",
      "Counter({'0000-0002-1739-3299': 72, '0000-0001-8756-229X': 66, '0000-0002-3323-2815': 30, '0000-0002-3263-4847': 8, '0000-0002-9323-9437': 6})\n",
      "['0000-0001-8756-229X', '0000-0002-3323-2815', '0000-0002-1739-3299']\n",
      "Total sample size after apply threshold:  168\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(168, 615)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97        66\n",
      "          1       1.00      0.57      0.72        30\n",
      "          2       0.87      1.00      0.93        72\n",
      "\n",
      "avg / total       0.93      0.92      0.91       168\n",
      "\n",
      "[65  0  1  3 17 10  0  0 72]\n",
      "MNB Accuracy:  0.9166666666666666\n",
      "MNB F1:  0.8741952557050027\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98        66\n",
      "          1       1.00      0.70      0.82        30\n",
      "          2       0.89      1.00      0.94        72\n",
      "\n",
      "avg / total       0.95      0.94      0.94       168\n",
      "\n",
      "[65  0  1  1 21  8  0  0 72]\n",
      "svc Accuracy:  0.9404761904761905\n",
      "svc F1:  0.9165181224004754\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        66\n",
      "          1       1.00      0.43      0.60        30\n",
      "          2       0.73      1.00      0.84        72\n",
      "\n",
      "avg / total       0.88      0.84      0.83       168\n",
      "\n",
      "[56  0 10  0 13 17  0  0 72]\n",
      "LR Accuracy:  0.8392857142857143\n",
      "LR F1:  0.7882630709446127\n",
      "For name:  d_ross\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-8272-1877': 8, '0000-0002-8659-3833': 7, '0000-0001-7426-9561': 7, '0000-0002-5480-9978': 2, '0000-0001-6353-6951': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  q_wang\n",
      "total sample size before apply threshold:  348\n",
      "Counter({'0000-0002-2149-384X': 85, '0000-0001-7929-7692': 54, '0000-0001-9409-0251': 31, '0000-0002-7982-7275': 22, '0000-0001-5988-1293': 18, '0000-0002-5125-3724': 16, '0000-0002-6514-3470': 15, '0000-0002-1355-1616': 12, '0000-0001-7309-9580': 12, '0000-0002-2359-3262': 11, '0000-0002-0645-6514': 8, '0000-0002-9808-5035': 7, '0000-0002-4036-1818': 7, '0000-0001-7692-6721': 7, '0000-0001-8566-1120': 6, '0000-0002-6010-2178': 6, '0000-0002-9706-2421': 5, '0000-0003-2645-5807': 5, '0000-0002-6411-984X': 4, '0000-0003-3525-3422': 4, '0000-0002-8460-6821': 3, '0000-0003-3514-455X': 3, '0000-0002-0757-5208': 2, '0000-0001-7952-7101': 1, '0000-0001-5483-0243': 1, '0000-0002-6858-2778': 1, '0000-0003-3484-4810': 1, '0000-0003-3715-9106': 1})\n",
      "['0000-0002-2149-384X', '0000-0002-7982-7275', '0000-0002-2359-3262', '0000-0002-1355-1616', '0000-0001-5988-1293', '0000-0001-7309-9580', '0000-0001-9409-0251', '0000-0002-5125-3724', '0000-0001-7929-7692', '0000-0002-6514-3470']\n",
      "Total sample size after apply threshold:  276\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(276, 541)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.92      0.74        85\n",
      "          1       1.00      0.73      0.84        22\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       1.00      0.44      0.62        18\n",
      "          5       0.00      0.00      0.00        12\n",
      "          6       1.00      0.84      0.91        31\n",
      "          7       1.00      0.25      0.40        16\n",
      "          8       0.59      0.98      0.74        54\n",
      "          9       1.00      0.40      0.57        15\n",
      "\n",
      "avg / total       0.68      0.69      0.64       276\n",
      "\n",
      "[78  0  0  0  0  0  0  0  7  0  6 16  0  0  0  0  0  0  0  0 10  0  0  0\n",
      "  0  0  0  0  1  0 12  0  0  0  0  0  0  0  0  0  3  0  0  0  8  0  0  0\n",
      "  7  0  2  0  0  0  0  0  0  0 10  0  3  0  0  0  0  0 26  0  2  0  2  0\n",
      "  0  0  0  0  0  4 10  0  1  0  0  0  0  0  0  0 53  0  9  0  0  0  0  0\n",
      "  0  0  0  6]\n",
      "MNB Accuracy:  0.6920289855072463\n",
      "MNB F1:  0.48166467557275733\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.95      0.84        85\n",
      "          1       1.00      0.86      0.93        22\n",
      "          2       0.86      0.55      0.67        11\n",
      "          3       1.00      0.83      0.91        12\n",
      "          4       1.00      0.78      0.88        18\n",
      "          5       1.00      0.50      0.67        12\n",
      "          6       1.00      0.94      0.97        31\n",
      "          7       0.92      0.75      0.83        16\n",
      "          8       0.84      0.91      0.88        54\n",
      "          9       1.00      0.87      0.93        15\n",
      "\n",
      "avg / total       0.88      0.87      0.86       276\n",
      "\n",
      "[81  0  1  0  0  0  0  0  3  0  3 19  0  0  0  0  0  0  0  0  5  0  6  0\n",
      "  0  0  0  0  0  0  2  0  0 10  0  0  0  0  0  0  2  0  0  0 14  0  0  0\n",
      "  2  0  3  0  0  0  0  6  0  0  3  0  1  0  0  0  0  0 29  0  1  0  4  0\n",
      "  0  0  0  0  0 12  0  0  4  0  0  0  0  0  0  1 49  0  2  0  0  0  0  0\n",
      "  0  0  0 13]\n",
      "svc Accuracy:  0.8659420289855072\n",
      "svc F1:  0.8485827812851573\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.96      0.74        85\n",
      "          1       1.00      0.64      0.78        22\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.58      0.74        12\n",
      "          4       1.00      0.67      0.80        18\n",
      "          5       1.00      0.08      0.15        12\n",
      "          6       1.00      0.87      0.93        31\n",
      "          7       0.92      0.69      0.79        16\n",
      "          8       0.82      0.91      0.86        54\n",
      "          9       1.00      0.33      0.50        15\n",
      "\n",
      "avg / total       0.79      0.75      0.72       276\n",
      "\n",
      "[82  0  0  0  0  0  0  0  3  0  8 14  0  0  0  0  0  0  0  0 11  0  0  0\n",
      "  0  0  0  0  0  0  5  0  0  7  0  0  0  0  0  0  3  0  0  0 12  0  0  0\n",
      "  3  0  7  0  0  0  0  1  0  0  4  0  3  0  0  0  0  0 27  0  1  0  5  0\n",
      "  0  0  0  0  0 11  0  0  4  0  0  0  0  0  0  1 49  0 10  0  0  0  0  0\n",
      "  0  0  0  5]\n",
      "LR Accuracy:  0.7536231884057971\n",
      "LR F1:  0.6280289937135622\n",
      "For name:  c_cardoso\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-6239-6651': 15, '0000-0003-3645-5368': 12, '0000-0001-7273-0676': 10, '0000-0002-9339-8075': 8, '0000-0003-3323-4447': 4, '0000-0002-7527-3973': 2, '0000-0003-1914-9553': 1})\n",
      "['0000-0001-6239-6651', '0000-0001-7273-0676', '0000-0003-3645-5368']\n",
      "Total sample size after apply threshold:  37\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 101)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        15\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       0.92      0.92      0.92        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        37\n",
      "\n",
      "[14  0  1  0 10  0  1  0 11]\n",
      "MNB Accuracy:  0.9459459459459459\n",
      "MNB F1:  0.9500000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        15\n",
      "          1       1.00      0.90      0.95        10\n",
      "          2       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        37\n",
      "\n",
      "[15  0  0  1  9  0  1  0 11]\n",
      "svc Accuracy:  0.9459459459459459\n",
      "svc F1:  0.9471300533943555\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.91      0.89      0.89        37\n",
      "\n",
      "[15  0  0  3  7  0  1  0 11]\n",
      "LR Accuracy:  0.8918918918918919\n",
      "LR F1:  0.887468030690537\n",
      "For name:  j_matthews\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0002-9815-8636': 46, '0000-0001-6184-1813': 7, '0000-0002-5993-7610': 5, '0000-0002-1832-4420': 4, '0000-0002-7282-8929': 1, '0000-0002-6888-9438': 1, '0000-0002-3968-8282': 1})\n",
      "['0000-0002-9815-8636']\n",
      "Total sample size after apply threshold:  46\n",
      "For name:  g_lee\n",
      "total sample size before apply threshold:  202\n",
      "Counter({'0000-0001-6910-9133': 102, '0000-0002-8441-0802': 27, '0000-0001-7895-5112': 18, '0000-0002-3028-867X': 15, '0000-0001-6250-8852': 13, '0000-0002-7619-8979': 5, '0000-0002-4521-8957': 4, '0000-0003-0932-4418': 4, '0000-0003-4122-7976': 3, '0000-0002-4676-4554': 3, '0000-0002-3488-8963': 2, '0000-0002-8705-9210': 2, '0000-0002-8492-650X': 1, '0000-0002-8206-1151': 1, '0000-0002-2587-2775': 1, '0000-0002-6412-9482': 1})\n",
      "['0000-0001-6250-8852', '0000-0001-6910-9133', '0000-0002-3028-867X', '0000-0002-8441-0802', '0000-0001-7895-5112']\n",
      "Total sample size after apply threshold:  175\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 175)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.15      0.25        13\n",
      "          1       0.89      0.98      0.93       102\n",
      "          2       1.00      0.47      0.64        15\n",
      "          3       0.61      0.81      0.70        27\n",
      "          4       0.82      0.78      0.80        18\n",
      "\n",
      "avg / total       0.83      0.83      0.81       175\n",
      "\n",
      "[  2   1   0   8   2   0 100   0   2   0   0   7   7   1   0   1   3   0\n",
      "  22   1   0   1   0   3  14]\n",
      "MNB Accuracy:  0.8285714285714286\n",
      "MNB F1:  0.6638711548057342\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.93      0.98      0.96       102\n",
      "          2       1.00      0.80      0.89        15\n",
      "          3       0.79      0.85      0.82        27\n",
      "          4       1.00      0.83      0.91        18\n",
      "\n",
      "avg / total       0.93      0.93      0.93       175\n",
      "\n",
      "[ 12   0   0   1   0   0 100   0   2   0   0   3  12   0   0   0   4   0\n",
      "  23   0   0   0   0   3  15]\n",
      "svc Accuracy:  0.9257142857142857\n",
      "svc F1:  0.9072692336902863\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        13\n",
      "          1       0.79      0.98      0.88       102\n",
      "          2       1.00      0.20      0.33        15\n",
      "          3       0.84      0.78      0.81        27\n",
      "          4       1.00      0.78      0.88        18\n",
      "\n",
      "avg / total       0.86      0.83      0.81       175\n",
      "\n",
      "[  7   5   0   1   0   0 100   0   2   0   0  12   3   0   0   0   6   0\n",
      "  21   0   0   3   0   1  14]\n",
      "LR Accuracy:  0.8285714285714286\n",
      "LR F1:  0.7186437246963562\n",
      "For name:  m_salem\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-4955-0479': 12, '0000-0003-3214-3711': 9, '0000-0002-3961-7935': 3, '0000-0002-4189-857X': 1})\n",
      "['0000-0003-4955-0479']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  h_lai\n",
      "total sample size before apply threshold:  165\n",
      "Counter({'0000-0002-7958-2183': 146, '0000-0003-4334-0243': 10, '0000-0003-1834-4154': 6, '0000-0003-2521-0509': 2, '0000-0001-6044-8470': 1})\n",
      "['0000-0002-7958-2183', '0000-0003-4334-0243']\n",
      "Total sample size after apply threshold:  156\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(156, 151)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "156\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97       146\n",
      "          1       0.50      0.10      0.17        10\n",
      "\n",
      "avg / total       0.91      0.94      0.92       156\n",
      "\n",
      "[145   1   9   1]\n",
      "MNB Accuracy:  0.9358974358974359\n",
      "MNB F1:  0.5666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98       146\n",
      "          1       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.96      0.96      0.94       156\n",
      "\n",
      "[146   0   7   3]\n",
      "svc Accuracy:  0.9551282051282052\n",
      "svc F1:  0.7190635451505016\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       146\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.88      0.94      0.90       156\n",
      "\n",
      "[146   0  10   0]\n",
      "LR Accuracy:  0.9358974358974359\n",
      "LR F1:  0.48344370860927155\n",
      "For name:  r_harris\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0002-4377-5063': 26, '0000-0002-7943-5650': 8, '0000-0002-2636-1520': 6, '0000-0003-1787-7784': 3, '0000-0002-9247-0768': 3, '0000-0003-0954-1981': 2, '0000-0003-3322-1371': 2})\n",
      "['0000-0002-4377-5063']\n",
      "Total sample size after apply threshold:  26\n",
      "For name:  c_vaughan\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0003-4314-7689': 73, '0000-0003-3988-8222': 7, '0000-0001-8714-4442': 2, '0000-0001-9147-8648': 1})\n",
      "['0000-0003-4314-7689']\n",
      "Total sample size after apply threshold:  73\n",
      "For name:  e_thompson\n",
      "total sample size before apply threshold:  181\n",
      "Counter({'0000-0002-9723-4924': 163, '0000-0001-8633-2417': 9, '0000-0002-6434-9290': 4, '0000-0003-3506-0401': 2, '0000-0002-5615-2893': 2, '0000-0002-7115-0001': 1})\n",
      "['0000-0002-9723-4924']\n",
      "Total sample size after apply threshold:  163\n",
      "For name:  r_gomes\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-7155-0059': 15, '0000-0002-9197-8279': 10, '0000-0003-0278-4876': 10, '0000-0002-7242-6540': 6, '0000-0002-9012-3287': 6, '0000-0002-5984-0712': 4, '0000-0002-6375-7014': 1})\n",
      "['0000-0001-7155-0059', '0000-0002-9197-8279', '0000-0003-0278-4876']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 462)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        15\n",
      "          1       1.00      0.60      0.75        10\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.89      0.86      0.85        35\n",
      "\n",
      "[15  0  0  4  6  0  1  0  9]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.8515037593984962\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        15\n",
      "          1       0.82      0.90      0.86        10\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.92      0.91      0.92        35\n",
      "\n",
      "[14  1  0  1  9  0  0  1  9]\n",
      "svc Accuracy:  0.9142857142857143\n",
      "svc F1:  0.9126148705096074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.91      0.89      0.88        35\n",
      "\n",
      "[15  0  0  3  7  0  1  0  9]\n",
      "LR Accuracy:  0.8857142857142857\n",
      "LR F1:  0.8844169246646026\n",
      "For name:  r_bennett\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-7526-3425': 74, '0000-0002-7227-4831': 11, '0000-0002-5780-8786': 3, '0000-0002-3746-367X': 3, '0000-0002-5210-1386': 1, '0000-0002-1200-2068': 1})\n",
      "['0000-0002-7526-3425', '0000-0002-7227-4831']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 310)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        74\n",
      "          1       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.91      0.89      0.86        85\n",
      "\n",
      "[74  0  9  2]\n",
      "MNB Accuracy:  0.8941176470588236\n",
      "MNB F1:  0.6251837334639883\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99        74\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.99      0.99      0.99        85\n",
      "\n",
      "[74  0  1 10]\n",
      "svc Accuracy:  0.9882352941176471\n",
      "svc F1:  0.9728347714924896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        74\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.76      0.87      0.81        85\n",
      "\n",
      "[74  0 11  0]\n",
      "LR Accuracy:  0.8705882352941177\n",
      "LR F1:  0.46540880503144655\n",
      "For name:  m_collins\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-7656-4975': 20, '0000-0003-3785-6008': 14, '0000-0003-3969-5797': 9, '0000-0002-2312-3172': 6, '0000-0003-2536-4508': 6, '0000-0003-1641-848X': 2})\n",
      "['0000-0002-7656-4975', '0000-0003-3785-6008']\n",
      "Total sample size after apply threshold:  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 160)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        20\n",
      "          1       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.85      0.79      0.78        34\n",
      "\n",
      "[20  0  7  7]\n",
      "MNB Accuracy:  0.7941176470588235\n",
      "MNB F1:  0.7588652482269503\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        20\n",
      "          1       0.88      1.00      0.93        14\n",
      "\n",
      "avg / total       0.95      0.94      0.94        34\n",
      "\n",
      "[18  2  0 14]\n",
      "svc Accuracy:  0.9411764705882353\n",
      "svc F1:  0.9403508771929825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        20\n",
      "          1       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.85      0.79      0.78        34\n",
      "\n",
      "[20  0  7  7]\n",
      "LR Accuracy:  0.7941176470588235\n",
      "LR F1:  0.7588652482269503\n",
      "For name:  m_cowley\n",
      "total sample size before apply threshold:  132\n",
      "Counter({'0000-0001-7811-134X': 57, '0000-0002-9519-5714': 49, '0000-0003-0664-2891': 17, '0000-0001-8564-4224': 9})\n",
      "['0000-0003-0664-2891', '0000-0002-9519-5714', '0000-0001-7811-134X']\n",
      "Total sample size after apply threshold:  123\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(123, 775)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        17\n",
      "          1       0.95      0.82      0.88        49\n",
      "          2       0.74      0.96      0.84        57\n",
      "\n",
      "avg / total       0.86      0.83      0.82       123\n",
      "\n",
      "[ 7  0 10  0 40  9  0  2 55]\n",
      "MNB Accuracy:  0.8292682926829268\n",
      "MNB F1:  0.767382956314254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        17\n",
      "          1       0.96      0.88      0.91        49\n",
      "          2       0.90      0.96      0.93        57\n",
      "\n",
      "avg / total       0.94      0.93      0.93       123\n",
      "\n",
      "[17  0  0  0 43  6  0  2 55]\n",
      "svc Accuracy:  0.9349593495934959\n",
      "svc F1:  0.9490323356172617\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.38        17\n",
      "          1       0.95      0.84      0.89        49\n",
      "          2       0.72      0.96      0.83        57\n",
      "\n",
      "avg / total       0.85      0.81      0.79       123\n",
      "\n",
      "[ 4  0 13  0 41  8  0  2 55]\n",
      "LR Accuracy:  0.8130081300813008\n",
      "LR F1:  0.6997747993171334\n",
      "For name:  p_teixeira\n",
      "total sample size before apply threshold:  213\n",
      "Counter({'0000-0002-7258-7977': 60, '0000-0002-6296-5137': 55, '0000-0001-7202-0527': 48, '0000-0003-2315-2261': 26, '0000-0003-2735-6608': 22, '0000-0002-7596-9735': 1, '0000-0002-1593-8064': 1})\n",
      "['0000-0001-7202-0527', '0000-0002-7258-7977', '0000-0003-2315-2261', '0000-0003-2735-6608', '0000-0002-6296-5137']\n",
      "Total sample size after apply threshold:  211\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(211, 378)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        48\n",
      "          1       0.94      1.00      0.97        60\n",
      "          2       1.00      0.62      0.76        26\n",
      "          3       1.00      0.86      0.93        22\n",
      "          4       0.76      1.00      0.87        55\n",
      "\n",
      "avg / total       0.92      0.90      0.90       211\n",
      "\n",
      "[40  0  0  0  8  0 60  0  0  0  0  4 16  0  6  0  0  0 19  3  0  0  0  0\n",
      " 55]\n",
      "MNB Accuracy:  0.9004739336492891\n",
      "MNB F1:  0.886341721411138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        48\n",
      "          1       1.00      0.98      0.99        60\n",
      "          2       0.95      0.73      0.83        26\n",
      "          3       1.00      0.86      0.93        22\n",
      "          4       1.00      1.00      1.00        55\n",
      "\n",
      "avg / total       0.95      0.95      0.95       211\n",
      "\n",
      "[48  0  0  0  0  1 59  0  0  0  7  0 19  0  0  2  0  1 19  0  0  0  0  0\n",
      " 55]\n",
      "svc Accuracy:  0.9478672985781991\n",
      "svc F1:  0.9300346481656749\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        48\n",
      "          1       1.00      1.00      1.00        60\n",
      "          2       1.00      0.62      0.76        26\n",
      "          3       1.00      0.91      0.95        22\n",
      "          4       0.73      1.00      0.85        55\n",
      "\n",
      "avg / total       0.93      0.91      0.90       211\n",
      "\n",
      "[40  0  0  0  8  0 60  0  0  0  0  0 16  0 10  0  0  0 20  2  0  0  0  0\n",
      " 55]\n",
      "LR Accuracy:  0.9052132701421801\n",
      "LR F1:  0.8939060939060939\n",
      "For name:  c_cox\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0002-4927-979X': 24, '0000-0003-0625-328X': 21, '0000-0003-1074-3839': 2, '0000-0002-4486-0681': 1})\n",
      "['0000-0003-0625-328X', '0000-0002-4927-979X']\n",
      "Total sample size after apply threshold:  45\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 210)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        21\n",
      "          1       0.92      1.00      0.96        24\n",
      "\n",
      "avg / total       0.96      0.96      0.96        45\n",
      "\n",
      "[19  2  0 24]\n",
      "MNB Accuracy:  0.9555555555555556\n",
      "MNB F1:  0.9550000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        21\n",
      "          1       0.92      1.00      0.96        24\n",
      "\n",
      "avg / total       0.96      0.96      0.96        45\n",
      "\n",
      "[19  2  0 24]\n",
      "svc Accuracy:  0.9555555555555556\n",
      "svc F1:  0.9550000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        21\n",
      "          1       0.86      1.00      0.92        24\n",
      "\n",
      "avg / total       0.92      0.91      0.91        45\n",
      "\n",
      "[17  4  0 24]\n",
      "LR Accuracy:  0.9111111111111111\n",
      "LR F1:  0.9089068825910931\n",
      "For name:  s_hsu\n",
      "total sample size before apply threshold:  204\n",
      "Counter({'0000-0003-3399-055X': 124, '0000-0002-7231-0185': 65, '0000-0002-8214-1696': 12, '0000-0002-8830-5305': 1, '0000-0002-6666-4665': 1, '0000-0002-7232-9839': 1})"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['0000-0002-8214-1696', '0000-0002-7231-0185', '0000-0003-3399-055X']\n",
      "Total sample size after apply threshold:  201\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(201, 228)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "201\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       1.00      0.62      0.76        65\n",
      "          2       0.77      1.00      0.87       124\n",
      "\n",
      "avg / total       0.80      0.82      0.78       201\n",
      "\n",
      "[  0   0  12   0  40  25   0   0 124]\n",
      "MNB Accuracy:  0.8159203980099502\n",
      "MNB F1:  0.5440267335004177\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.90      0.80      0.85        65\n",
      "          2       0.83      0.95      0.89       124\n",
      "\n",
      "avg / total       0.86      0.85      0.83       201\n",
      "\n",
      "[  1   0  11   0  52  13   0   6 118]\n",
      "svc Accuracy:  0.8507462686567164\n",
      "svc F1:  0.6288642180811629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.93      0.60      0.73        65\n",
      "          2       0.76      0.98      0.86       124\n",
      "\n",
      "avg / total       0.77      0.80      0.76       201\n",
      "\n",
      "[  0   0  12   0  39  26   0   3 121]\n",
      "LR Accuracy:  0.7960199004975125\n",
      "LR F1:  0.5280318791761611\n",
      "For name:  f_williams\n",
      "total sample size before apply threshold:  149\n",
      "Counter({'0000-0002-2998-2744': 84, '0000-0002-6194-2734': 33, '0000-0002-3046-9235': 29, '0000-0003-4144-1411': 2, '0000-0001-7507-4870': 1})\n",
      "['0000-0002-2998-2744', '0000-0002-6194-2734', '0000-0002-3046-9235']\n",
      "Total sample size after apply threshold:  146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(146, 1028)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "146\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90        84\n",
      "          1       1.00      0.79      0.88        33\n",
      "          2       0.95      0.66      0.78        29\n",
      "\n",
      "avg / total       0.89      0.88      0.87       146\n",
      "\n",
      "[83  0  1  7 26  0 10  0 19]\n",
      "MNB Accuracy:  0.8767123287671232\n",
      "MNB F1:  0.8530133497761669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        84\n",
      "          1       1.00      0.85      0.92        33\n",
      "          2       1.00      0.83      0.91        29\n",
      "\n",
      "avg / total       0.94      0.93      0.93       146\n",
      "\n",
      "[84  0  0  5 28  0  5  0 24]\n",
      "svc Accuracy:  0.9315068493150684\n",
      "svc F1:  0.9225044629876124\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        84\n",
      "          1       1.00      0.70      0.82        33\n",
      "          2       1.00      0.52      0.68        29\n",
      "\n",
      "avg / total       0.87      0.84      0.82       146\n",
      "\n",
      "[84  0  0 10 23  0 14  0 15]\n",
      "LR Accuracy:  0.8356164383561644\n",
      "LR F1:  0.7927489177489179\n",
      "For name:  d_parsons\n",
      "total sample size before apply threshold:  30\n",
      "Counter({'0000-0002-3956-6031': 26, '0000-0002-1393-8431': 2, '0000-0002-9121-7859': 1, '0000-0002-5142-4466': 1})\n",
      "['0000-0002-3956-6031']\n",
      "Total sample size after apply threshold:  26\n",
      "For name:  a_choudhury\n",
      "total sample size before apply threshold:  56\n",
      "Counter({'0000-0002-3561-6580': 28, '0000-0001-5496-7346': 24, '0000-0002-7042-8139': 3, '0000-0002-8990-879X': 1})\n",
      "['0000-0001-5496-7346', '0000-0002-3561-6580']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 306)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.92      0.86        24\n",
      "          1       0.92      0.82      0.87        28\n",
      "\n",
      "avg / total       0.87      0.87      0.87        52\n",
      "\n",
      "[22  2  5 23]\n",
      "MNB Accuracy:  0.8653846153846154\n",
      "MNB F1:  0.8653348131705512\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        24\n",
      "          1       0.82      1.00      0.90        28\n",
      "\n",
      "avg / total       0.90      0.88      0.88        52\n",
      "\n",
      "[18  6  0 28]\n",
      "svc Accuracy:  0.8846153846153846\n",
      "svc F1:  0.880184331797235\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        24\n",
      "          1       0.82      1.00      0.90        28\n",
      "\n",
      "avg / total       0.90      0.88      0.88        52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[18  6  0 28]\n",
      "LR Accuracy:  0.8846153846153846\n",
      "LR F1:  0.880184331797235\n",
      "For name:  c_richter\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0002-5658-6173': 4, '0000-0002-6591-1118': 4, '0000-0001-6017-1520': 2, '0000-0002-6839-7994': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_hossain\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0003-1408-2273': 26, '0000-0002-1878-8145': 17, '0000-0003-3967-2544': 10, '0000-0003-3399-581X': 9, '0000-0003-3303-5755': 7, '0000-0003-1271-1515': 7, '0000-0003-4733-0018': 6, '0000-0002-9953-586X': 5, '0000-0001-8019-843X': 4, '0000-0001-7996-9233': 3, '0000-0002-1917-8701': 1, '0000-0002-0984-984X': 1, '0000-0002-7673-8410': 1, '0000-0002-0977-4593': 1, '0000-0003-2970-2324': 1, '0000-0001-6753-4216': 1, '0000-0002-3929-6211': 1, '0000-0002-6621-8737': 1})\n",
      "['0000-0003-3967-2544', '0000-0003-1408-2273', '0000-0002-1878-8145']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 127)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.81      0.96      0.88        26\n",
      "          2       0.94      0.94      0.94        17\n",
      "\n",
      "avg / total       0.89      0.87      0.86        53\n",
      "\n",
      "[ 5  5  0  0 25  1  0  1 16]\n",
      "MNB Accuracy:  0.8679245283018868\n",
      "MNB F1:  0.828345373237014\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.93      0.96      0.94        26\n",
      "          2       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.95      0.94      0.94        53\n",
      "\n",
      "[ 8  2  0  0 25  1  0  0 17]\n",
      "svc Accuracy:  0.9433962264150944\n",
      "svc F1:  0.9345712289108516\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.74      1.00      0.85        26\n",
      "          2       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.87      0.83      0.82        53\n",
      "\n",
      "[ 5  5  0  0 26  0  0  4 13]\n",
      "LR Accuracy:  0.8301886792452831\n",
      "LR F1:  0.7952641165755919\n",
      "For name:  v_alves\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-8430-4380': 13, '0000-0002-6182-1748': 5, '0000-0003-1819-7051': 4, '0000-0002-1485-6032': 2})\n",
      "['0000-0002-8430-4380']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  j_becker\n",
      "total sample size before apply threshold:  177\n",
      "Counter({'0000-0003-4425-4726': 122, '0000-0002-6845-6122': 45, '0000-0003-4564-3192': 4, '0000-0001-5668-1544': 3, '0000-0002-5041-5488': 2, '0000-0002-7733-4522': 1})\n",
      "['0000-0002-6845-6122', '0000-0003-4425-4726']\n",
      "Total sample size after apply threshold:  167\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(167, 678)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "167\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.71      0.82        45\n",
      "          1       0.90      0.99      0.95       122\n",
      "\n",
      "avg / total       0.92      0.92      0.91       167\n",
      "\n",
      "[ 32  13   1 121]\n",
      "MNB Accuracy:  0.9161676646706587\n",
      "MNB F1:  0.8829126602564102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        45\n",
      "          1       0.93      1.00      0.96       122\n",
      "\n",
      "avg / total       0.95      0.95      0.94       167\n",
      "\n",
      "[ 36   9   0 122]\n",
      "svc Accuracy:  0.9461077844311377\n",
      "svc F1:  0.9266578831796224\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.42        45\n",
      "          1       0.79      1.00      0.88       122\n",
      "\n",
      "avg / total       0.84      0.80      0.76       167\n",
      "\n",
      "[ 12  33   0 122]\n",
      "LR Accuracy:  0.8023952095808383\n",
      "LR F1:  0.6509595287858636\n",
      "For name:  m_soares\n",
      "total sample size before apply threshold:  247\n",
      "Counter({'0000-0001-9701-836X': 75, '0000-0002-9314-4833': 68, '0000-0001-6071-0272': 44, '0000-0003-1579-8513': 32, '0000-0002-5213-2377': 10, '0000-0001-8860-0470': 7, '0000-0003-4227-4141': 4, '0000-0002-7181-1906': 3, '0000-0002-4614-8209': 2, '0000-0002-8059-7067': 1, '0000-0002-9013-2570': 1})\n",
      "['0000-0002-5213-2377', '0000-0001-6071-0272', '0000-0003-1579-8513', '0000-0002-9314-4833', '0000-0001-9701-836X']\n",
      "Total sample size after apply threshold:  229\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(229, 634)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "229\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.98      0.95      0.97        44\n",
      "          2       1.00      0.72      0.84        32\n",
      "          3       0.97      0.90      0.93        68\n",
      "          4       0.74      0.99      0.85        75\n",
      "\n",
      "avg / total       0.86      0.87      0.86       229\n",
      "\n",
      "[ 0  0  0  0 10  0 42  0  0  2  0  1 23  1  7  0  0  0 61  7  0  0  0  1\n",
      " 74]\n",
      "MNB Accuracy:  0.8733624454148472\n",
      "MNB F1:  0.7157785746761793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       1.00      0.91      0.95        44\n",
      "          2       1.00      0.75      0.86        32\n",
      "          3       0.89      0.93      0.91        68\n",
      "          4       0.83      0.96      0.89        75\n",
      "\n",
      "avg / total       0.91      0.90      0.90       229\n",
      "\n",
      "[ 7  0  0  0  3  0 40  0  2  2  0  0 24  3  5  0  0  0 63  5  0  0  0  3\n",
      " 72]\n",
      "svc Accuracy:  0.8995633187772926\n",
      "svc F1:  0.8856833860642579\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       1.00      0.86      0.93        44\n",
      "          2       1.00      0.62      0.77        32\n",
      "          3       0.95      0.91      0.93        68\n",
      "          4       0.73      0.99      0.84        75\n",
      "\n",
      "avg / total       0.90      0.86      0.86       229\n",
      "\n",
      "[ 4  0  0  0  6  0 38  0  1  5  0  0 20  1 11  0  0  0 62  6  0  0  0  1\n",
      " 74]\n",
      "LR Accuracy:  0.8646288209606987\n",
      "LR F1:  0.8071955256220177\n",
      "For name:  j_yi\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0001-5299-9897': 18, '0000-0002-9296-8443': 9, '0000-0002-1025-865X': 1, '0000-0003-1718-6326': 1})\n",
      "['0000-0001-5299-9897']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  s_khan\n",
      "total sample size before apply threshold:  193\n",
      "Counter({'0000-0001-5147-145X': 61, '0000-0001-5654-2835': 42, '0000-0003-4185-8882': 29, '0000-0002-6792-3577': 7, '0000-0003-0910-4095': 7, '0000-0002-0310-0424': 6, '0000-0002-0763-2583': 6, '0000-0002-9564-5092': 5, '0000-0003-0273-1248': 5, '0000-0002-2689-8563': 4, '0000-0002-0948-5003': 4, '0000-0003-0772-6122': 4, '0000-0002-3845-541X': 3, '0000-0001-6732-768X': 2, '0000-0002-9643-6858': 2, '0000-0002-1894-7839': 1, '0000-0002-1589-6634': 1, '0000-0001-9377-6382': 1, '0000-0002-6307-2023': 1, '0000-0002-0823-4042': 1, '0000-0001-8678-2872': 1})\n",
      "['0000-0003-4185-8882', '0000-0001-5147-145X', '0000-0001-5654-2835']\n",
      "Total sample size after apply threshold:  132\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(132, 942)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "132\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        29\n",
      "          1       0.71      0.98      0.82        61\n",
      "          2       0.88      0.50      0.64        42\n",
      "\n",
      "avg / total       0.82      0.79      0.78       132\n",
      "\n",
      "[23  4  2  0 60  1  0 21 21]\n",
      "MNB Accuracy:  0.7878787878787878\n",
      "MNB F1:  0.780965609732733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        29\n",
      "          1       1.00      0.92      0.96        61\n",
      "          2       0.81      1.00      0.89        42\n",
      "\n",
      "avg / total       0.94      0.92      0.93       132\n",
      "\n",
      "[24  0  5  0 56  5  0  0 42]\n",
      "svc Accuracy:  0.9242424242424242\n",
      "svc F1:  0.918847451966681\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93        29\n",
      "          1       0.75      0.95      0.84        61\n",
      "          2       0.87      0.62      0.72        42\n",
      "\n",
      "avg / total       0.84      0.83      0.82       132\n",
      "\n",
      "[25  3  1  0 58  3  0 16 26]\n",
      "LR Accuracy:  0.8257575757575758\n",
      "LR F1:  0.8295759527643586\n",
      "For name:  a_rao\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-2676-2762': 36, '0000-0003-0320-2962': 20, '0000-0002-2550-6097': 11, '0000-0001-6440-1274': 8, '0000-0003-2319-6539': 5, '0000-0002-2474-5010': 5, '0000-0003-4480-3190': 3, '0000-0003-4879-1123': 2, '0000-0002-7983-0773': 1, '0000-0002-0220-7131': 1, '0000-0002-6531-8728': 1})\n",
      "['0000-0002-2550-6097', '0000-0003-0320-2962', '0000-0002-2676-2762']\n",
      "Total sample size after apply threshold:  67\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 184)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       1.00      0.90      0.95        20\n",
      "          2       0.77      1.00      0.87        36\n",
      "\n",
      "avg / total       0.87      0.84      0.80        67\n",
      "\n",
      "[ 2  0  9  0 18  2  0  0 36]\n",
      "MNB Accuracy:  0.835820895522388\n",
      "MNB F1:  0.7075102027543373\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        11\n",
      "          1       1.00      0.95      0.97        20\n",
      "          2       0.80      1.00      0.89        36\n",
      "\n",
      "avg / total       0.89      0.87      0.84        67\n",
      "\n",
      "[ 3  0  8  0 19  1  0  0 36]\n",
      "svc Accuracy:  0.8656716417910447\n",
      "svc F1:  0.7639397639397639\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.75      0.86        20\n",
      "          2       0.69      1.00      0.82        36\n",
      "\n",
      "avg / total       0.67      0.76      0.70        67\n",
      "\n",
      "[ 0  0 11  0 15  5  0  0 36]\n",
      "LR Accuracy:  0.7611940298507462\n",
      "LR F1:  0.5584415584415584\n",
      "For name:  d_cameron\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0002-5439-6544': 29, '0000-0001-6274-2913': 17, '0000-0001-7520-7741': 2, '0000-0003-2567-0564': 1})\n",
      "['0000-0002-5439-6544', '0000-0001-6274-2913']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 154)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        29\n",
      "          1       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.94      0.93      0.93        46\n",
      "\n",
      "[29  0  3 14]\n",
      "MNB Accuracy:  0.9347826086956522\n",
      "MNB F1:  0.9270227392913801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        29\n",
      "          1       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.94      0.93      0.93        46\n",
      "\n",
      "[29  0  3 14]\n",
      "svc Accuracy:  0.9347826086956522\n",
      "svc F1:  0.9270227392913801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        29\n",
      "          1       1.00      0.53      0.69        17\n",
      "\n",
      "avg / total       0.86      0.83      0.81        46\n",
      "\n",
      "[29  0  8  9]\n",
      "LR Accuracy:  0.8260869565217391\n",
      "LR F1:  0.7855477855477856\n",
      "For name:  c_morgan\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0003-3131-9906': 15, '0000-0003-0931-5474': 11, '0000-0002-7511-0488': 11, '0000-0002-0118-1056': 3, '0000-0002-1508-2614': 2, '0000-0002-8191-3738': 1})\n",
      "['0000-0003-3131-9906', '0000-0003-0931-5474', '0000-0002-7511-0488']\n",
      "Total sample size after apply threshold:  37"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 170)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      1.00      0.71        15\n",
      "          1       1.00      0.45      0.62        11\n",
      "          2       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.82      0.68      0.66        37\n",
      "\n",
      "[15  0  0  6  5  0  6  0  5]\n",
      "MNB Accuracy:  0.6756756756756757\n",
      "MNB F1:  0.6547619047619048\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.80      0.69        15\n",
      "          1       0.88      0.64      0.74        11\n",
      "          2       0.78      0.64      0.70        11\n",
      "\n",
      "avg / total       0.73      0.70      0.71        37\n",
      "\n",
      "[12  1  2  4  7  0  4  0  7]\n",
      "svc Accuracy:  0.7027027027027027\n",
      "svc F1:  0.7075187969924812\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.93      0.67        15\n",
      "          1       1.00      0.36      0.53        11\n",
      "          2       0.83      0.45      0.59        11\n",
      "\n",
      "avg / total       0.76      0.62      0.60        37\n",
      "\n",
      "[14  0  1  7  4  0  6  0  5]\n",
      "LR Accuracy:  0.6216216216216216\n",
      "LR F1:  0.5960784313725491\n",
      "For name:  h_cui\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0001-6394-4808': 11, '0000-0003-3358-8958': 10, '0000-0002-9870-748X': 9, '0000-0002-6343-1014': 9, '0000-0002-8627-8534': 1})\n",
      "['0000-0001-6394-4808', '0000-0003-3358-8958']\n",
      "Total sample size after apply threshold:  21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 55)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "21\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        11\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.96      0.95      0.95        21\n",
      "\n",
      "[11  0  1  9]\n",
      "MNB Accuracy:  0.9523809523809523\n",
      "MNB F1:  0.9519450800915332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.96      0.95      0.95        21\n",
      "\n",
      "[10  1  0 10]\n",
      "svc Accuracy:  0.9523809523809523\n",
      "svc F1:  0.9523809523809523\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.96      0.95      0.95        21\n",
      "\n",
      "[10  1  0 10]\n",
      "LR Accuracy:  0.9523809523809523\n",
      "LR F1:  0.9523809523809523\n",
      "For name:  p_zhang\n",
      "total sample size before apply threshold:  137\n",
      "Counter({'0000-0002-1765-5965': 26, '0000-0003-3603-0175': 25, '0000-0003-2228-3569': 20, '0000-0002-2774-5534': 17, '0000-0002-5409-7480': 16, '0000-0001-5574-0899': 8, '0000-0002-6218-1885': 6, '0000-0002-1806-4200': 5, '0000-0001-9539-1136': 5, '0000-0003-0606-6855': 3, '0000-0001-6953-800X': 3, '0000-0002-8462-0340': 1, '0000-0001-7331-6020': 1, '0000-0003-3344-4823': 1})\n",
      "['0000-0002-5409-7480', '0000-0002-2774-5534', '0000-0003-3603-0175', '0000-0003-2228-3569', '0000-0002-1765-5965']\n",
      "Total sample size after apply threshold:  104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(104, 161)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "104\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.75      0.80        16\n",
      "          1       0.94      0.88      0.91        17\n",
      "          2       0.96      0.92      0.94        25\n",
      "          3       0.77      1.00      0.87        20\n",
      "          4       0.96      0.88      0.92        26\n",
      "\n",
      "avg / total       0.90      0.89      0.89       104\n",
      "\n",
      "[12  1  0  3  0  0 15  0  2  0  1  0 23  0  1  0  0  0 20  0  1  0  1  1\n",
      " 23]\n",
      "MNB Accuracy:  0.8942307692307693\n",
      "MNB F1:  0.887486327337259\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91        16\n",
      "          1       0.94      0.94      0.94        17\n",
      "          2       0.88      0.92      0.90        25\n",
      "          3       0.95      0.95      0.95        20\n",
      "          4       0.92      0.85      0.88        26\n",
      "\n",
      "avg / total       0.91      0.91      0.91       104\n",
      "\n",
      "[15  1  0  0  0  0 16  1  0  0  1  0 23  0  1  0  0  0 19  1  1  0  2  1\n",
      " 22]\n",
      "svc Accuracy:  0.9134615384615384\n",
      "svc F1:  0.9164456327985739\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88        16\n",
      "          1       0.94      0.94      0.94        17\n",
      "          2       0.85      0.92      0.88        25\n",
      "          3       0.95      0.95      0.95        20\n",
      "          4       0.92      0.85      0.88        26\n",
      "\n",
      "avg / total       0.91      0.90      0.90       104\n",
      "\n",
      "[14  1  1  0  0  0 16  1  0  0  1  0 23  0  1  0  0  0 19  1  1  0  2  1\n",
      " 22]\n",
      "LR Accuracy:  0.9038461538461539\n",
      "LR F1:  0.9061583710407239\n",
      "For name:  j_fernandes\n",
      "total sample size before apply threshold:  208\n",
      "Counter({'0000-0002-2550-1640': 63, '0000-0003-1556-1698': 38, '0000-0001-5512-4092': 33, '0000-0002-8565-2942': 27, '0000-0002-6726-5324': 22, '0000-0002-9089-273X': 6, '0000-0001-8205-5870': 4, '0000-0001-6387-2939': 3, '0000-0002-4505-4809': 3, '0000-0001-6616-3513': 3, '0000-0003-0337-7084': 3, '0000-0003-1519-8032': 2, '0000-0003-0934-9244': 1})\n",
      "['0000-0002-2550-1640', '0000-0003-1556-1698', '0000-0002-8565-2942', '0000-0001-5512-4092', '0000-0002-6726-5324']\n",
      "Total sample size after apply threshold:  183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(183, 329)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "183\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93        63\n",
      "          1       0.92      0.95      0.94        38\n",
      "          2       0.92      0.85      0.88        27\n",
      "          3       0.97      0.97      0.97        33\n",
      "          4       1.00      0.64      0.78        22\n",
      "\n",
      "avg / total       0.92      0.92      0.91       183\n",
      "\n",
      "[63  0  0  0  0  1 36  1  0  0  1  2 23  1  0  0  1  0 32  0  7  0  1  0\n",
      " 14]\n",
      "MNB Accuracy:  0.9180327868852459\n",
      "MNB F1:  0.9000976800976801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        63\n",
      "          1       0.94      0.89      0.92        38\n",
      "          2       0.95      0.78      0.86        27\n",
      "          3       1.00      0.97      0.98        33\n",
      "          4       1.00      0.73      0.84        22\n",
      "\n",
      "avg / total       0.92      0.91      0.91       183\n",
      "\n",
      "[63  0  0  0  0  3 34  1  0  0  4  2 21  0  0  1  0  0 32  0  6  0  0  0\n",
      " 16]\n",
      "svc Accuracy:  0.907103825136612\n",
      "svc F1:  0.9005564847670111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        63\n",
      "          1       0.94      0.87      0.90        38\n",
      "          2       1.00      0.74      0.85        27\n",
      "          3       1.00      0.97      0.98        33\n",
      "          4       1.00      0.55      0.71        22\n",
      "\n",
      "avg / total       0.90      0.87      0.87       183\n",
      "\n",
      "[63  0  0  0  0  5 33  0  0  0  5  2 20  0  0  1  0  0 32  0 10  0  0  0\n",
      " 12]\n",
      "LR Accuracy:  0.8743169398907104\n",
      "LR F1:  0.8605628027055496\n",
      "For name:  a_jain\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0001-7808-6180': 15, '0000-0003-0250-3608': 11, '0000-0001-5320-0880': 9, '0000-0003-2235-5139': 7, '0000-0003-4032-1442': 6, '0000-0002-3281-9729': 5, '0000-0003-2827-6263': 4, '0000-0001-9415-0883': 4, '0000-0001-5658-367X': 3, '0000-0002-2457-8144': 1, '0000-0002-8481-7119': 1, '0000-0002-3950-2601': 1})\n",
      "['0000-0003-0250-3608', '0000-0001-7808-6180']\n",
      "Total sample size after apply threshold:  26\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 63)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.79      1.00      0.88        15\n",
      "\n",
      "avg / total       0.88      0.85      0.84        26\n",
      "\n",
      "[ 7  4  0 15]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.8300653594771241\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        26\n",
      "\n",
      "[11  0  0 15]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.75      1.00      0.86        15\n",
      "\n",
      "avg / total       0.86      0.81      0.79        26\n",
      "\n",
      "[ 6  5  0 15]\n",
      "LR Accuracy:  0.8076923076923077\n",
      "LR F1:  0.7815126050420167\n",
      "For name:  d_zhang\n",
      "total sample size before apply threshold:  94\n",
      "Counter({'0000-0002-4175-5982': 17, '0000-0002-7665-2182': 12, '0000-0003-0779-6438': 11, '0000-0003-4280-0068': 8, '0000-0001-9295-4992': 7, '0000-0001-9508-8209': 7, '0000-0001-6930-5994': 6, '0000-0001-9478-5344': 6, '0000-0001-5809-0027': 5, '0000-0002-4149-4938': 4, '0000-0002-1581-2357': 4, '0000-0001-5956-4618': 2, '0000-0001-7063-7742': 2, '0000-0002-2541-837X': 1, '0000-0001-6259-7082': 1, '0000-0002-4515-2070': 1})\n",
      "['0000-0002-4175-5982', '0000-0002-7665-2182', '0000-0003-0779-6438']\n",
      "Total sample size after apply threshold:  40\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 77)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "40\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        17\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.90      0.88      0.88        40\n",
      "\n",
      "[17  0  0  3  9  0  2  0  9]\n",
      "MNB Accuracy:  0.875\n",
      "MNB F1:  0.8763125763125763\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.91        17\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.93      0.93      0.92        40\n",
      "\n",
      "[16  0  1  2 10  0  0  0 11]\n",
      "svc Accuracy:  0.925\n",
      "svc F1:  0.9266327875023528\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.94      0.78        17\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       0.86      0.55      0.67        11\n",
      "\n",
      "avg / total       0.82      0.78      0.77        40\n",
      "\n",
      "[16  0  1  3  9  0  5  0  6]\n",
      "LR Accuracy:  0.775\n",
      "LR F1:  0.7680991095625241\n",
      "For name:  b_huang\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-9082-2216': 16, '0000-0002-1981-5838': 12, '0000-0002-1246-7447': 9, '0000-0001-6189-814X': 5, '0000-0001-5009-3928': 3, '0000-0003-2838-6315': 3})\n",
      "['0000-0001-9082-2216', '0000-0002-1981-5838']\n",
      "Total sample size after apply threshold:  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 145)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.84        16\n",
      "          1       1.00      0.50      0.67        12\n",
      "\n",
      "avg / total       0.84      0.79      0.77        28\n",
      "\n",
      "[16  0  6  6]\n",
      "MNB Accuracy:  0.7857142857142857\n",
      "MNB F1:  0.7543859649122807\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.86      1.00      0.92        12\n",
      "\n",
      "avg / total       0.94      0.93      0.93        28\n",
      "\n",
      "[14  2  0 12]\n",
      "svc Accuracy:  0.9285714285714286\n",
      "svc F1:  0.9282051282051282\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.94      0.83        16\n",
      "          1       0.88      0.58      0.70        12\n",
      "\n",
      "avg / total       0.80      0.79      0.78        28\n",
      "\n",
      "[15  1  5  7]\n",
      "LR Accuracy:  0.7857142857142857\n",
      "LR F1:  0.7666666666666667\n",
      "For name:  m_chong\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0001-9324-5901': 20, '0000-0002-9586-6303': 20, '0000-0003-0587-2505': 1, '0000-0002-5507-1987': 1, '0000-0002-7324-1660': 1})\n",
      "['0000-0001-9324-5901', '0000-0002-9586-6303']\n",
      "Total sample size after apply threshold:  40\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 90)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "40\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.85      0.87        20\n",
      "          1       0.86      0.90      0.88        20\n",
      "\n",
      "avg / total       0.88      0.88      0.87        40\n",
      "\n",
      "[17  3  2 18]\n",
      "MNB Accuracy:  0.875\n",
      "MNB F1:  0.8749218261413383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.90      0.88        20\n",
      "          1       0.89      0.85      0.87        20\n",
      "\n",
      "avg / total       0.88      0.88      0.87        40\n",
      "\n",
      "[18  2  3 17]\n",
      "svc Accuracy:  0.875\n",
      "svc F1:  0.8749218261413383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.85      0.87        20\n",
      "          1       0.86      0.90      0.88        20\n",
      "\n",
      "avg / total       0.88      0.88      0.87        40\n",
      "\n",
      "[17  3  2 18]\n",
      "LR Accuracy:  0.875\n",
      "LR F1:  0.8749218261413383\n",
      "For name:  m_cerqueira\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-8342-2967': 12, '0000-0002-2430-7758': 12, '0000-0001-6614-3942': 11, '0000-0002-3505-6982': 4, '0000-0001-7237-5053': 2})\n",
      "['0000-0002-8342-2967', '0000-0002-2430-7758', '0000-0001-6614-3942']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 81)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.75      0.82        12\n",
      "          1       0.86      1.00      0.92        12\n",
      "          2       0.91      0.91      0.91        11\n",
      "\n",
      "avg / total       0.89      0.89      0.88        35\n",
      "\n",
      "[ 9  2  1  0 12  0  1  0 10]\n",
      "MNB Accuracy:  0.8857142857142857\n",
      "MNB F1:  0.8834498834498835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        12\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.95      0.94      0.94        35\n",
      "\n",
      "[12  0  0  1 11  0  1  0 10]\n",
      "svc Accuracy:  0.9428571428571428\n",
      "svc F1:  0.9439932048627702\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        12\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.93      0.91      0.92        35\n",
      "\n",
      "[12  0  0  1 11  0  2  0  9]\n",
      "LR Accuracy:  0.9142857142857143\n",
      "LR F1:  0.9151368760064412\n",
      "For name:  p_yang\n",
      "total sample size before apply threshold:  227\n",
      "Counter({'0000-0001-6330-6048': 102, '0000-0003-3473-4611': 46, '0000-0003-1098-3138': 17, '0000-0002-4004-2518': 17, '0000-0002-0463-1024': 14, '0000-0002-2334-5664': 10, '0000-0002-4635-1215': 6, '0000-0001-7554-5281': 5, '0000-0001-9227-3919': 4, '0000-0002-6610-1758': 3, '0000-0001-5247-1953': 1, '0000-0003-1840-6204': 1, '0000-0001-8472-0205': 1})\n",
      "['0000-0001-6330-6048', '0000-0003-3473-4611', '0000-0002-0463-1024', '0000-0003-1098-3138', '0000-0002-4004-2518', '0000-0002-2334-5664']\n",
      "Total sample size after apply threshold:  206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(206, 440)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "206\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.99      0.73       102\n",
      "          1       0.93      0.54      0.68        46\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       1.00      0.18      0.30        17\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.58      0.63      0.54       206\n",
      "\n",
      "[101   0   0   0   1   0  21  25   0   0   0   0  14   0   0   0   0   0\n",
      "  13   1   0   3   0   0  17   0   0   0   0   0   9   1   0   0   0   0]\n",
      "MNB Accuracy:  0.6262135922330098\n",
      "MNB F1:  0.2856955640176055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.97      0.87       102\n",
      "          1       0.90      0.80      0.85        46\n",
      "          2       0.88      0.50      0.64        14\n",
      "          3       1.00      0.82      0.90        17\n",
      "          4       1.00      0.35      0.52        17\n",
      "          5       0.83      1.00      0.91        10\n",
      "\n",
      "avg / total       0.86      0.84      0.83       206\n",
      "\n",
      "[99  3  0  0  0  0  9 37  0  0  0  0  5  0  7  0  0  2  2  0  1 14  0  0\n",
      " 10  1  0  0  6  0  0  0  0  0  0 10]\n",
      "svc Accuracy:  0.8398058252427184\n",
      "svc F1:  0.7822068151699769\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.99      0.79       102\n",
      "          1       0.94      0.70      0.80        46\n",
      "          2       1.00      0.14      0.25        14\n",
      "          3       1.00      0.29      0.45        17\n",
      "          4       1.00      0.18      0.30        17\n",
      "          5       0.89      0.80      0.84        10\n",
      "\n",
      "avg / total       0.81      0.73      0.69       206\n",
      "\n",
      "[101   1   0   0   0   0  14  32   0   0   0   0  11   0   2   0   0   1\n",
      "  12   0   0   5   0   0  13   1   0   0   3   0   2   0   0   0   0   8]\n",
      "LR Accuracy:  0.7330097087378641\n",
      "LR F1:  0.5731345967414079\n",
      "For name:  j_marques\n",
      "total sample size before apply threshold:  183\n",
      "Counter({'0000-0001-8865-8189': 30, '0000-0001-8157-8864': 28, '0000-0002-3800-7756': 27, '0000-0001-8910-4735': 18, '0000-0002-3457-3320': 14, '0000-0002-8124-3156': 12, '0000-0001-9436-1613': 11, '0000-0002-7234-9477': 8, '0000-0002-3724-5664': 8, '0000-0002-7333-9158': 6, '0000-0002-1014-0483': 5, '0000-0003-2199-9362': 4, '0000-0002-8740-642X': 4, '0000-0003-3429-0774': 2, '0000-0002-1644-7195': 2, '0000-0002-2523-6365': 1, '0000-0003-0972-1149': 1, '0000-0002-2354-433X': 1, '0000-0001-9834-1361': 1})\n",
      "['0000-0002-3457-3320', '0000-0002-8124-3156', '0000-0002-3800-7756', '0000-0001-8910-4735', '0000-0001-8865-8189', '0000-0001-9436-1613', '0000-0001-8157-8864']\n",
      "Total sample size after apply threshold:  140\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 285)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "140\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25        14\n",
      "          1       1.00      0.58      0.74        12\n",
      "          2       0.63      0.96      0.76        27\n",
      "          3       1.00      0.83      0.91        18\n",
      "          4       0.74      0.93      0.82        30\n",
      "          5       1.00      0.27      0.43        11\n",
      "          6       0.79      0.96      0.87        28\n",
      "\n",
      "avg / total       0.83      0.77      0.74       140\n",
      "\n",
      "[ 2  0  9  0  1  0  2  0  7  0  0  5  0  0  0  0 26  0  0  0  1  0  0  2\n",
      " 15  1  0  0  0  0  1  0 28  0  1  0  0  3  0  2  3  3  0  0  0  0  1  0\n",
      " 27]\n",
      "MNB Accuracy:  0.7714285714285715\n",
      "MNB F1:  0.6833867827112323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        14\n",
      "          1       0.91      0.83      0.87        12\n",
      "          2       1.00      0.93      0.96        27\n",
      "          3       1.00      0.89      0.94        18\n",
      "          4       0.63      0.97      0.76        30\n",
      "          5       1.00      0.36      0.53        11\n",
      "          6       1.00      0.96      0.98        28\n",
      "\n",
      "avg / total       0.91      0.87      0.87       140\n",
      "\n",
      "[11  0  0  0  3  0  0  0 10  0  0  2  0  0  0  0 25  0  2  0  0  0  0  0\n",
      " 16  2  0  0  0  1  0  0 29  0  0  0  0  0  0  7  4  0  0  0  0  0  1  0\n",
      " 27]\n",
      "svc Accuracy:  0.8714285714285714\n",
      "svc F1:  0.847227079915194\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.35        14\n",
      "          1       1.00      0.67      0.80        12\n",
      "          2       1.00      0.96      0.98        27\n",
      "          3       1.00      0.89      0.94        18\n",
      "          4       0.54      1.00      0.70        30\n",
      "          5       1.00      0.36      0.53        11\n",
      "          6       1.00      0.96      0.98        28\n",
      "\n",
      "avg / total       0.90      0.81      0.80       140\n",
      "\n",
      "[ 3  0  0  0 11  0  0  0  8  0  0  4  0  0  0  0 26  0  1  0  0  0  0  0\n",
      " 16  2  0  0  0  0  0  0 30  0  0  0  0  0  0  7  4  0  0  0  0  0  1  0\n",
      " 27]\n",
      "LR Accuracy:  0.8142857142857143\n",
      "LR F1:  0.7554393794695269\n",
      "For name:  n_ali\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0001-8121-0939': 6, '0000-0003-2063-2745': 3, '0000-0003-1245-4299': 2, '0000-0002-8292-0091': 1, '0000-0003-0858-7849': 1, '0000-0003-2924-6429': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_ng\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0002-9210-5349': 53, '0000-0001-6352-8417': 41, '0000-0002-4055-8151': 13, '0000-0001-6519-1942': 1, '0000-0003-2397-840X': 1})\n",
      "['0000-0001-6352-8417', '0000-0002-9210-5349', '0000-0002-4055-8151']\n",
      "Total sample size after apply threshold:  107\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 235)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "107\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.66      0.78        41\n",
      "          1       0.78      0.98      0.87        53\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.88      0.85      0.85       107\n",
      "\n",
      "[27 14  0  1 52  0  0  1 12]\n",
      "MNB Accuracy:  0.8504672897196262\n",
      "MNB F1:  0.8697584541062802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86        41\n",
      "          1       0.92      0.87      0.89        53\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.89      0.89      0.89       107\n",
      "\n",
      "[37  4  0  7 46  0  1  0 12]\n",
      "svc Accuracy:  0.8878504672897196\n",
      "svc F1:  0.9045563332580718\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.76      0.83        41\n",
      "          1       0.82      0.94      0.88        53\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.88      0.87      0.87       107\n",
      "\n",
      "[31 10  0  3 50  0  0  1 12]\n",
      "LR Accuracy:  0.8691588785046729\n",
      "LR F1:  0.887953216374269\n",
      "For name:  m_viana\n",
      "total sample size before apply threshold:  139\n",
      "Counter({'0000-0002-0464-4845': 34, '0000-0003-4356-8109': 31, '0000-0002-4073-3802': 29, '0000-0001-9665-2115': 26, '0000-0001-9288-2108': 13, '0000-0002-3074-767X': 5, '0000-0002-5657-5570': 1})\n",
      "['0000-0001-9665-2115', '0000-0003-4356-8109', '0000-0002-4073-3802', '0000-0001-9288-2108', '0000-0002-0464-4845']\n",
      "Total sample size after apply threshold:  133\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 440)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.92      0.87        26\n",
      "          1       0.86      0.97      0.91        31\n",
      "          2       0.97      0.97      0.97        29\n",
      "          3       0.83      0.38      0.53        13\n",
      "          4       0.97      0.97      0.97        34\n",
      "\n",
      "avg / total       0.90      0.90      0.89       133\n",
      "\n",
      "[24  1  0  1  0  0 30  0  0  1  0  1 28  0  0  4  3  1  5  0  1  0  0  0\n",
      " 33]\n",
      "MNB Accuracy:  0.9022556390977443\n",
      "MNB F1:  0.8488478895930587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.96      0.85        26\n",
      "          1       1.00      0.94      0.97        31\n",
      "          2       1.00      0.93      0.96        29\n",
      "          3       0.91      0.77      0.83        13\n",
      "          4       1.00      0.97      0.99        34\n",
      "\n",
      "avg / total       0.94      0.93      0.93       133\n",
      "\n",
      "[25  0  0  1  0  2 29  0  0  0  2  0 27  0  0  3  0  0 10  0  1  0  0  0\n",
      " 33]\n",
      "svc Accuracy:  0.9323308270676691\n",
      "svc F1:  0.919363593654006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.92      0.86        26\n",
      "          1       0.91      0.94      0.92        31\n",
      "          2       0.93      0.97      0.95        29\n",
      "          3       0.88      0.54      0.67        13\n",
      "          4       1.00      0.97      0.99        34\n",
      "\n",
      "avg / total       0.91      0.91      0.91       133\n",
      "\n",
      "[24  1  0  1  0  1 29  1  0  0  0  1 28  0  0  4  1  1  7  0  1  0  0  0\n",
      " 33]\n",
      "LR Accuracy:  0.9097744360902256\n",
      "LR F1:  0.8757343227365995\n",
      "For name:  t_inoue\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0002-2728-0060': 52, '0000-0003-3289-4478': 9, '0000-0002-7710-1526': 8, '0000-0003-0582-0908': 1})\n",
      "['0000-0002-2728-0060']\n",
      "Total sample size after apply threshold:  52\n",
      "For name:  b_meyer\n",
      "total sample size before apply threshold:  92\n",
      "Counter({'0000-0002-0388-9568': 60, '0000-0003-1100-0260': 25, '0000-0002-2549-1825': 3, '0000-0002-7903-5710': 2, '0000-0001-9321-1277': 1, '0000-0002-6530-4588': 1})\n",
      "['0000-0002-0388-9568', '0000-0003-1100-0260']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 518)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.98      0.89        60\n",
      "          1       0.92      0.44      0.59        25\n",
      "\n",
      "avg / total       0.84      0.82      0.80        85\n",
      "\n",
      "[59  1 14 11]\n",
      "MNB Accuracy:  0.8235294117647058\n",
      "MNB F1:  0.7409063198536883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.95        60\n",
      "          1       0.91      0.84      0.87        25\n",
      "\n",
      "avg / total       0.93      0.93      0.93        85\n",
      "\n",
      "[58  2  4 21]\n",
      "svc Accuracy:  0.9294117647058824\n",
      "svc F1:  0.9129098360655737\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        60\n",
      "          1       1.00      0.28      0.44        25\n",
      "\n",
      "avg / total       0.84      0.79      0.74        85\n",
      "\n",
      "[60  0 18  7]\n",
      "LR Accuracy:  0.788235294117647\n",
      "LR F1:  0.6535326086956522\n",
      "For name:  c_liao\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-1324-9644': 11, '0000-0001-5168-6493': 11, '0000-0001-9777-3701': 6, '0000-0003-3459-1913': 6, '0000-0003-4156-0912': 1})\n",
      "['0000-0002-1324-9644', '0000-0001-5168-6493']\n",
      "Total sample size after apply threshold:  22\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 50)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "22\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        22\n",
      "\n",
      "[11  0  0 11]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "[10  1  0 11]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.9544513457556936\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        22\n",
      "\n",
      "[11  0  0 11]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  k_wheeler\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0003-3728-8928': 18, '0000-0001-6752-7542': 6, '0000-0002-6806-4233': 2, '0000-0003-2056-9977': 2})\n",
      "['0000-0003-3728-8928']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  m_rizzo\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0002-9549-8504': 68, '0000-0002-3856-5010': 53, '0000-0001-5924-8615': 18, '0000-0002-1023-4260': 9, '0000-0003-4343-8937': 4})\n",
      "['0000-0002-9549-8504', '0000-0001-5924-8615', '0000-0002-3856-5010']\n",
      "Total sample size after apply threshold:  139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 378)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        68\n",
      "          1       1.00      0.67      0.80        18\n",
      "          2       0.83      1.00      0.91        53\n",
      "\n",
      "avg / total       0.93      0.92      0.92       139\n",
      "\n",
      "[63  0  5  0 12  6  0  0 53]\n",
      "MNB Accuracy:  0.920863309352518\n",
      "MNB F1:  0.8892716556838695\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        68\n",
      "          1       1.00      0.83      0.91        18\n",
      "          2       1.00      1.00      1.00        53\n",
      "\n",
      "avg / total       0.98      0.98      0.98       139\n",
      "\n",
      "[68  0  0  3 15  0  0  0 53]\n",
      "svc Accuracy:  0.9784172661870504\n",
      "svc F1:  0.9625027250926531\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        68\n",
      "          1       1.00      0.50      0.67        18\n",
      "          2       1.00      1.00      1.00        53\n",
      "\n",
      "avg / total       0.94      0.94      0.93       139\n",
      "\n",
      "[68  0  0  9  9  0  0  0 53]\n",
      "LR Accuracy:  0.935251798561151\n",
      "LR F1:  0.8681992337164751\n",
      "For name:  y_shi\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0001-6933-4971': 17, '0000-0003-4530-2056': 10, '0000-0003-2943-5465': 7, '0000-0001-6029-6526': 5, '0000-0001-7421-3306': 5, '0000-0001-7713-0813': 4, '0000-0003-4273-8663': 3, '0000-0001-9406-7967': 3, '0000-0003-1804-6990': 3, '0000-0002-6715-7681': 2, '0000-0002-7887-3050': 2, '0000-0001-7256-3628': 2, '0000-0001-6085-7880': 1, '0000-0003-0965-5751': 1, '0000-0001-7502-9201': 1, '0000-0002-3284-4449': 1})\n",
      "['0000-0001-6933-4971', '0000-0003-4530-2056']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 93)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        17\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.97      0.96      0.96        27\n",
      "\n",
      "[17  0  1  9]\n",
      "MNB Accuracy:  0.9629629629629629\n",
      "MNB F1:  0.9593984962406015\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        17\n",
      "          1       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.93      0.93      0.93        27\n",
      "\n",
      "[16  1  1  9]\n",
      "svc Accuracy:  0.9259259259259259\n",
      "svc F1:  0.9205882352941177\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        17\n",
      "          1       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.93      0.93      0.92        27\n",
      "\n",
      "[17  0  2  8]\n",
      "LR Accuracy:  0.9259259259259259\n",
      "LR F1:  0.9166666666666667\n",
      "For name:  c_luo\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0003-0524-5886': 36, '0000-0002-6453-7435': 18, '0000-0003-2193-3670': 15, '0000-0002-3477-5969': 5, '0000-0001-5876-5266': 1, '0000-0002-0879-3127': 1, '0000-0003-1152-0557': 1, '0000-0001-8806-1139': 1})\n",
      "['0000-0003-0524-5886', '0000-0002-6453-7435', '0000-0003-2193-3670']\n",
      "Total sample size after apply threshold:  69\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 134)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        36\n",
      "          1       1.00      0.89      0.94        18\n",
      "          2       1.00      0.87      0.93        15\n",
      "\n",
      "avg / total       0.95      0.94      0.94        69\n",
      "\n",
      "[36  0  0  2 16  0  2  0 13]\n",
      "MNB Accuracy:  0.9420289855072463\n",
      "MNB F1:  0.9390387734040985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        36\n",
      "          1       1.00      1.00      1.00        18\n",
      "          2       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        69\n",
      "\n",
      "[36  0  0  0 18  0  0  0 15]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        36\n",
      "          1       1.00      0.89      0.94        18\n",
      "          2       1.00      0.87      0.93        15\n",
      "\n",
      "avg / total       0.95      0.94      0.94        69\n",
      "\n",
      "[36  0  0  2 16  0  2  0 13]\n",
      "LR Accuracy:  0.9420289855072463\n",
      "LR F1:  0.9390387734040985\n",
      "For name:  j_arthur\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-4796-0207': 24, '0000-0002-9185-6108': 11, '0000-0003-4540-4511': 6, '0000-0003-0344-4478': 1})\n",
      "['0000-0002-4796-0207', '0000-0002-9185-6108']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 184)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        24\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        35\n",
      "\n",
      "[24  0  0 11]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        24\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        35\n",
      "\n",
      "[24  0  0 11]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        24\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.90      0.89      0.88        35\n",
      "\n",
      "[24  0  4  7]\n",
      "LR Accuracy:  0.8857142857142857\n",
      "LR F1:  0.8504273504273504\n",
      "For name:  m_ansari\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0001-6365-7104': 9, '0000-0002-8718-3078': 8, '0000-0001-7678-4639': 7, '0000-0003-2790-8353': 5, '0000-0002-9106-0978': 3, '0000-0002-0112-238X': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  g_anderson\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0001-5087-7837': 65, '0000-0001-7545-9893': 35, '0000-0002-5768-6360': 1, '0000-0001-6544-8007': 1, '0000-0003-2046-3152': 1})\n",
      "['0000-0001-7545-9893', '0000-0001-5087-7837']\n",
      "Total sample size after apply threshold:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 351)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "100\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        35\n",
      "          1       0.98      0.98      0.98        65\n",
      "\n",
      "avg / total       0.98      0.98      0.98       100\n",
      "\n",
      "[34  1  1 64]\n",
      "MNB Accuracy:  0.98\n",
      "MNB F1:  0.9780219780219781\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        35\n",
      "          1       0.97      1.00      0.98        65\n",
      "\n",
      "avg / total       0.98      0.98      0.98       100\n",
      "\n",
      "[33  2  0 65]\n",
      "svc Accuracy:  0.98\n",
      "svc F1:  0.9777183600713013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        35\n",
      "          1       0.89      1.00      0.94        65\n",
      "\n",
      "avg / total       0.93      0.92      0.92       100\n",
      "\n",
      "[27  8  0 65]\n",
      "LR Accuracy:  0.92\n",
      "LR F1:  0.9064983637213652\n",
      "For name:  m_hidalgo\n",
      "total sample size before apply threshold:  279\n",
      "Counter({'0000-0002-3765-3318': 238, '0000-0002-4450-3772': 31, '0000-0001-9862-6578': 5, '0000-0002-3494-9658': 3, '0000-0003-0684-0740': 2})\n",
      "['0000-0002-3765-3318', '0000-0002-4450-3772']\n",
      "Total sample size after apply threshold:  269\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(269, 1109)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "269\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       238\n",
      "          1       1.00      0.35      0.52        31\n",
      "\n",
      "avg / total       0.93      0.93      0.91       269\n",
      "\n",
      "[238   0  20  11]\n",
      "MNB Accuracy:  0.9256505576208178\n",
      "MNB F1:  0.7417434715821813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       238\n",
      "          1       1.00      0.81      0.89        31\n",
      "\n",
      "avg / total       0.98      0.98      0.98       269\n",
      "\n",
      "[238   0   6  25]\n",
      "svc Accuracy:  0.9776951672862454\n",
      "svc F1:  0.9402045050385299\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       238\n",
      "          1       1.00      0.13      0.23        31\n",
      "\n",
      "avg / total       0.91      0.90      0.86       269\n",
      "\n",
      "[238   0  27   4]\n",
      "LR Accuracy:  0.8996282527881041\n",
      "LR F1:  0.587446748082931\n",
      "For name:  k_jacobsen\n",
      "total sample size before apply threshold:  113\n",
      "Counter({'0000-0002-4198-6246': 93, '0000-0002-1121-2979': 17, '0000-0002-3450-0850': 2, '0000-0003-0135-0988': 1})\n",
      "['0000-0002-4198-6246', '0000-0002-1121-2979']\n",
      "Total sample size after apply threshold:  110\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(110, 1386)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "110\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        93\n",
      "          1       1.00      0.18      0.30        17\n",
      "\n",
      "avg / total       0.89      0.87      0.83       110\n",
      "\n",
      "[93  0 14  3]\n",
      "MNB Accuracy:  0.8727272727272727\n",
      "MNB F1:  0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        93\n",
      "          1       1.00      0.59      0.74        17\n",
      "\n",
      "avg / total       0.94      0.94      0.93       110\n",
      "\n",
      "[93  0  7 10]\n",
      "svc Accuracy:  0.9363636363636364\n",
      "svc F1:  0.8522356553444637\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        93\n",
      "          1       1.00      0.12      0.21        17\n",
      "\n",
      "avg / total       0.88      0.86      0.81       110\n",
      "\n",
      "[93  0 15  2]\n",
      "LR Accuracy:  0.8636363636363636\n",
      "LR F1:  0.5679497250589159\n",
      "For name:  s_kelly\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0003-4002-048X': 31, '0000-0001-8583-5362': 26, '0000-0002-8245-0181': 20, '0000-0003-3533-5268': 12, '0000-0002-0375-1040': 11, '0000-0002-3078-8404': 2})\n",
      "['0000-0002-8245-0181', '0000-0001-8583-5362', '0000-0003-3533-5268', '0000-0002-0375-1040', '0000-0003-4002-048X']\n",
      "Total sample size after apply threshold:  100\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 304)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "100\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        20\n",
      "          1       1.00      0.69      0.82        26\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       1.00      0.18      0.31        11\n",
      "          4       0.61      1.00      0.76        31\n",
      "\n",
      "avg / total       0.88      0.80      0.78       100\n",
      "\n",
      "[20  0  0  0  0  0 18  0  0  8  0  0  9  0  3  0  0  0  2  9  0  0  0  0\n",
      " 31]\n",
      "MNB Accuracy:  0.8\n",
      "MNB F1:  0.7478229087985184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        20\n",
      "          1       0.81      0.85      0.83        26\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       1.00      0.55      0.71        11\n",
      "          4       0.74      0.90      0.81        31\n",
      "\n",
      "avg / total       0.87      0.85      0.85       100\n",
      "\n",
      "[20  0  0  0  0  0 22  0  0  4  0  1  9  0  2  0  1  0  6  4  0  3  0  0\n",
      " 28]\n",
      "svc Accuracy:  0.85\n",
      "svc F1:  0.8409616184455734\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        20\n",
      "          1       1.00      0.54      0.70        26\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       1.00      0.18      0.31        11\n",
      "          4       0.56      1.00      0.72        31\n",
      "\n",
      "avg / total       0.86      0.76      0.74       100\n",
      "\n",
      "[20  0  0  0  0  0 14  0  0 12  0  0  9  0  3  0  0  0  2  9  0  0  0  0\n",
      " 31]\n",
      "LR Accuracy:  0.76\n",
      "LR F1:  0.7171530794786609\n",
      "For name:  s_james\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0001-9369-3288': 29, '0000-0003-0651-9842': 13, '0000-0001-7955-0491': 8, '0000-0001-6758-5726': 7, '0000-0003-1150-0628': 1, '0000-0002-8128-2139': 1})\n",
      "['0000-0003-0651-9842', '0000-0001-9369-3288']\n",
      "Total sample size after apply threshold:  42\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 162)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       1.00      1.00      1.00        42\n",
      "\n",
      "[13  0  0 29]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.97      1.00      0.98        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        42\n",
      "\n",
      "[12  1  0 29]\n",
      "svc Accuracy:  0.9761904761904762\n",
      "svc F1:  0.9715254237288136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       0.81      1.00      0.89        29\n",
      "\n",
      "avg / total       0.87      0.83      0.81        42\n",
      "\n",
      "[ 6  7  0 29]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.7619433198380567\n",
      "For name:  p_persson\n",
      "total sample size before apply threshold:  80\n",
      "Counter({'0000-0001-9172-3068': 39, '0000-0001-7600-3230': 26, '0000-0001-9140-6724': 8, '0000-0003-4468-032X': 7})\n",
      "['0000-0001-7600-3230', '0000-0001-9172-3068']\n",
      "Total sample size after apply threshold:  65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 172)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        26\n",
      "          1       0.87      1.00      0.93        39\n",
      "\n",
      "avg / total       0.92      0.91      0.90        65\n",
      "\n",
      "[20  6  0 39]\n",
      "MNB Accuracy:  0.9076923076923077\n",
      "MNB F1:  0.8990683229813665\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        26\n",
      "          1       0.89      1.00      0.94        39\n",
      "\n",
      "avg / total       0.93      0.92      0.92        65\n",
      "\n",
      "[21  5  0 39]\n",
      "svc Accuracy:  0.9230769230769231\n",
      "svc F1:  0.916688028710587\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.73        26\n",
      "          1       0.78      1.00      0.88        39\n",
      "\n",
      "avg / total       0.87      0.83      0.82        65\n",
      "\n",
      "[15 11  0 39]\n",
      "LR Accuracy:  0.8307692307692308\n",
      "LR F1:  0.8040559057275967\n",
      "For name:  y_tanaka\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-0674-660X': 12, '0000-0002-6190-4586': 5, '0000-0001-9598-5583': 2, '0000-0002-5163-7752': 1})\n",
      "['0000-0002-0674-660X']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  c_gao\n",
      "total sample size before apply threshold:  189\n",
      "Counter({'0000-0001-5084-7208': 144, '0000-0003-3429-3473': 17, '0000-0001-7386-692X': 13, '0000-0002-1445-7939': 11, '0000-0003-2792-5022': 2, '0000-0003-2736-3920': 1, '0000-0002-5456-451X': 1})\n",
      "['0000-0003-3429-3473', '0000-0002-1445-7939', '0000-0001-7386-692X', '0000-0001-5084-7208']\n",
      "Total sample size after apply threshold:  185\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(185, 131)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        17\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       0.84      1.00      0.91       144\n",
      "\n",
      "avg / total       0.81      0.85      0.80       185\n",
      "\n",
      "[  5   0   0  12   0   0   0  11   0   0   8   5   0   0   0 144]\n",
      "MNB Accuracy:  0.8486486486486486\n",
      "MNB F1:  0.5319606553783769\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.88      0.91        17\n",
      "          1       0.88      0.64      0.74        11\n",
      "          2       1.00      0.77      0.87        13\n",
      "          3       0.94      0.99      0.96       144\n",
      "\n",
      "avg / total       0.94      0.94      0.94       185\n",
      "\n",
      "[ 15   0   0   2   0   7   0   4   0   0  10   3   1   1   0 142]\n",
      "svc Accuracy:  0.9405405405405406\n",
      "svc F1:  0.8695525240380377\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        17\n",
      "          1       1.00      0.18      0.31        11\n",
      "          2       1.00      0.54      0.70        13\n",
      "          3       0.84      1.00      0.91       144\n",
      "\n",
      "avg / total       0.88      0.85      0.82       185\n",
      "\n",
      "[  5   0   0  12   0   2   0   9   0   0   7   6   0   0   0 144]\n",
      "LR Accuracy:  0.8540540540540541\n",
      "LR F1:  0.5941308691308691\n",
      "For name:  w_jung\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0002-8697-9584': 17, '0000-0002-6853-2885': 8, '0000-0001-5266-3795': 4, '0000-0001-9590-3859': 2, '0000-0002-1615-750X': 2})\n",
      "['0000-0002-8697-9584']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  s_lewis\n",
      "total sample size before apply threshold:  306\n",
      "Counter({'0000-0003-1861-4652': 112, '0000-0002-8343-612X': 69, '0000-0002-2049-1586': 35, '0000-0003-1210-2314': 27, '0000-0003-4555-4907': 20, '0000-0001-9537-5822': 19, '0000-0002-6929-6626': 15, '0000-0001-7262-3168': 7, '0000-0003-4557-4123': 1, '0000-0002-5250-7415': 1})\n",
      "['0000-0003-4555-4907', '0000-0001-9537-5822', '0000-0002-2049-1586', '0000-0002-8343-612X', '0000-0003-1861-4652', '0000-0002-6929-6626', '0000-0003-1210-2314']\n",
      "Total sample size after apply threshold:  297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(297, 1721)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "297\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        20\n",
      "          1       1.00      0.05      0.10        19\n",
      "          2       1.00      0.54      0.70        35\n",
      "          3       1.00      0.77      0.87        69\n",
      "          4       0.54      1.00      0.70       112\n",
      "          5       1.00      0.20      0.33        15\n",
      "          6       1.00      0.37      0.54        27\n",
      "\n",
      "avg / total       0.82      0.67      0.63       297\n",
      "\n",
      "[  2   0   0   0  18   0   0   0   1   0   0  18   0   0   0   0  19   0\n",
      "  16   0   0   0   0   0  53  16   0   0   0   0   0   0 112   0   0   0\n",
      "   0   0   0  12   3   0   0   0   0   0  17   0  10]\n",
      "MNB Accuracy:  0.6734006734006734\n",
      "MNB F1:  0.4894382190076997\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        20\n",
      "          1       1.00      0.63      0.77        19\n",
      "          2       1.00      0.74      0.85        35\n",
      "          3       0.97      0.94      0.96        69\n",
      "          4       0.74      1.00      0.85       112\n",
      "          5       1.00      0.80      0.89        15\n",
      "          6       1.00      0.63      0.77        27\n",
      "\n",
      "avg / total       0.90      0.86      0.86       297\n",
      "\n",
      "[ 12   0   0   0   8   0   0   0  12   0   0   7   0   0   0   0  26   0\n",
      "   9   0   0   0   0   0  65   4   0   0   0   0   0   0 112   0   0   0\n",
      "   0   0   0   3  12   0   0   0   0   2   8   0  17]\n",
      "svc Accuracy:  0.8619528619528619\n",
      "svc F1:  0.8351231579934068\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        20\n",
      "          1       1.00      0.32      0.48        19\n",
      "          2       1.00      0.57      0.73        35\n",
      "          3       1.00      0.86      0.92        69\n",
      "          4       0.61      1.00      0.75       112\n",
      "          5       1.00      0.40      0.57        15\n",
      "          6       1.00      0.48      0.65        27\n",
      "\n",
      "avg / total       0.85      0.75      0.74       297\n",
      "\n",
      "[  8   0   0   0  12   0   0   0   6   0   0  13   0   0   0   0  20   0\n",
      "  15   0   0   0   0   0  59  10   0   0   0   0   0   0 112   0   0   0\n",
      "   0   0   0   9   6   0   0   0   0   0  14   0  13]\n",
      "LR Accuracy:  0.7542087542087542\n",
      "LR F1:  0.6680305177626608\n",
      "For name:  w_han\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0001-9702-0523': 18, '0000-0001-8678-7147': 9, '0000-0003-2252-9311': 3, '0000-0002-4544-2908': 3, '0000-0002-7567-1883': 1})\n",
      "['0000-0001-9702-0523']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  m_shah\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0003-0299-8903': 10, '0000-0001-6126-7102': 2, '0000-0001-6599-7233': 2, '0000-0003-2191-7611': 1, '0000-0002-4354-9760': 1, '0000-0002-9740-8429': 1})\n",
      "['0000-0003-0299-8903']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  c_arango\n",
      "total sample size before apply threshold:  185\n",
      "Counter({'0000-0003-3382-4754': 177, '0000-0003-1098-830X': 6, '0000-0001-5920-5340': 1, '0000-0002-2970-4074': 1})\n",
      "['0000-0003-3382-4754']\n",
      "Total sample size after apply threshold:  177\n",
      "For name:  r_young\n",
      "total sample size before apply threshold:  361\n",
      "Counter({'0000-0002-6806-6503': 117, '0000-0001-8001-2914': 87, '0000-0002-6380-6314': 70, '0000-0001-7003-3017': 38, '0000-0001-6073-9489': 24, '0000-0002-1062-5691': 10, '0000-0002-5719-2205': 9, '0000-0001-7485-0604': 6})\n",
      "['0000-0001-8001-2914', '0000-0002-6806-6503', '0000-0001-7003-3017', '0000-0002-1062-5691', '0000-0001-6073-9489', '0000-0002-6380-6314']\n",
      "Total sample size after apply threshold:  346\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(346, 701)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "346\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.89      0.90        87\n",
      "          1       0.67      0.99      0.80       117\n",
      "          2       1.00      0.76      0.87        38\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.25      0.40        24\n",
      "          5       1.00      0.76      0.86        70\n",
      "\n",
      "avg / total       0.84      0.81      0.79       346\n",
      "\n",
      "[ 77  10   0   0   0   0   1 116   0   0   0   0   2   7  29   0   0   0\n",
      "   0  10   0   0   0   0   4  14   0   0   6   0   0  17   0   0   0  53]\n",
      "MNB Accuracy:  0.8121387283236994\n",
      "MNB F1:  0.6375493190175651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.94      0.77        87\n",
      "          1       0.98      0.95      0.97       117\n",
      "          2       0.97      0.79      0.87        38\n",
      "          3       1.00      0.40      0.57        10\n",
      "          4       1.00      0.58      0.74        24\n",
      "          5       0.90      0.76      0.82        70\n",
      "\n",
      "avg / total       0.88      0.85      0.85       346\n",
      "\n",
      "[ 82   0   1   0   0   4   5 111   0   0   0   1   8   0  30   0   0   0\n",
      "   4   2   0   4   0   0   9   0   0   0  14   1  17   0   0   0   0  53]\n",
      "svc Accuracy:  0.8497109826589595\n",
      "svc F1:  0.7897239362340579\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.93      0.76        87\n",
      "          1       0.85      0.97      0.90       117\n",
      "          2       0.96      0.71      0.82        38\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.25      0.40        24\n",
      "          5       1.00      0.77      0.87        70\n",
      "\n",
      "avg / total       0.83      0.81      0.79       346\n",
      "\n",
      "[ 81   5   1   0   0   0   4 113   0   0   0   0   9   2  27   0   0   0\n",
      "   4   6   0   0   0   0  15   3   0   0   6   0  12   4   0   0   0  54]\n",
      "LR Accuracy:  0.8121387283236994\n",
      "LR F1:  0.6262167505855881\n",
      "For name:  r_coleman\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0003-4136-5914': 15, '0000-0002-5194-8550': 13, '0000-0001-7118-524X': 3, '0000-0002-9731-7498': 3})\n",
      "['0000-0003-4136-5914', '0000-0002-5194-8550']\n",
      "Total sample size after apply threshold:  28\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 179)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90        15\n",
      "          1       0.92      0.85      0.88        13\n",
      "\n",
      "avg / total       0.89      0.89      0.89        28\n",
      "\n",
      "[14  1  2 11]\n",
      "MNB Accuracy:  0.8928571428571429\n",
      "MNB F1:  0.8916129032258064\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.89      0.86      0.85        28\n",
      "\n",
      "[15  0  4  9]\n",
      "svc Accuracy:  0.8571428571428571\n",
      "svc F1:  0.8502673796791443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        15\n",
      "          1       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.87      0.82      0.81        28\n",
      "\n",
      "[15  0  5  8]\n",
      "LR Accuracy:  0.8214285714285714\n",
      "LR F1:  0.8095238095238095\n",
      "For name:  b_kang\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0001-5902-0549': 10, '0000-0001-6946-2279': 5, '0000-0003-2637-4695': 2, '0000-0003-0901-4903': 1, '0000-0002-4299-2170': 1, '0000-0002-1690-7753': 1})\n",
      "['0000-0001-5902-0549']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  s_carter\n",
      "total sample size before apply threshold:  205\n",
      "Counter({'0000-0002-3585-9400': 124, '0000-0003-2617-8694': 44, '0000-0002-9080-519X': 15, '0000-0002-4670-0884': 12, '0000-0002-9817-0029': 5, '0000-0002-3619-8640': 2, '0000-0002-8169-4483': 2, '0000-0002-2907-9651': 1})\n",
      "['0000-0002-3585-9400', '0000-0002-4670-0884', '0000-0003-2617-8694', '0000-0002-9080-519X']\n",
      "Total sample size after apply threshold:  195\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(195, 439)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "195\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90       124\n",
      "          1       1.00      0.50      0.67        12\n",
      "          2       0.91      0.70      0.79        44\n",
      "          3       1.00      0.40      0.57        15\n",
      "\n",
      "avg / total       0.87      0.85      0.84       195\n",
      "\n",
      "[123   0   1   0   6   6   0   0  13   0  31   0   7   0   2   6]\n",
      "MNB Accuracy:  0.8512820512820513\n",
      "MNB F1:  0.7335164835164836\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       124\n",
      "          1       1.00      0.58      0.74        12\n",
      "          2       1.00      0.75      0.86        44\n",
      "          3       1.00      0.67      0.80        15\n",
      "\n",
      "avg / total       0.91      0.89      0.89       195\n",
      "\n",
      "[124   0   0   0   5   7   0   0  11   0  33   0   5   0   0  10]\n",
      "svc Accuracy:  0.8923076923076924\n",
      "svc F1:  0.8289795119769685\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85       124\n",
      "          1       1.00      0.50      0.67        12\n",
      "          2       1.00      0.45      0.62        44\n",
      "          3       1.00      0.13      0.24        15\n",
      "\n",
      "avg / total       0.84      0.78      0.74       195\n",
      "\n",
      "[124   0   0   0   6   6   0   0  24   0  20   0  13   0   0   2]\n",
      "LR Accuracy:  0.7794871794871795\n",
      "LR F1:  0.5947986153224176\n",
      "For name:  c_thomas\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0003-2822-1334': 56, '0000-0001-5855-1196': 15, '0000-0003-0316-6391': 15, '0000-0001-8704-3262': 8, '0000-0003-3091-5757': 2, '0000-0002-0351-0466': 2, '0000-0001-6662-6362': 2, '0000-0001-5706-3940': 1, '0000-0001-6536-4591': 1})\n",
      "['0000-0001-5855-1196', '0000-0003-2822-1334', '0000-0003-0316-6391']\n",
      "Total sample size after apply threshold:  86\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 280)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        15\n",
      "          1       0.70      1.00      0.82        56\n",
      "          2       1.00      0.07      0.12        15\n",
      "\n",
      "avg / total       0.80      0.72      0.65        86\n",
      "\n",
      "[ 5 10  0  0 56  0  0 14  1]\n",
      "MNB Accuracy:  0.7209302325581395\n",
      "MNB F1:  0.48284313725490197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        15\n",
      "          1       0.74      1.00      0.85        56\n",
      "          2       1.00      0.27      0.42        15\n",
      "\n",
      "avg / total       0.83      0.77      0.73        86\n",
      "\n",
      "[ 6  9  0  0 56  0  0 11  4]\n",
      "svc Accuracy:  0.7674418604651163\n",
      "svc F1:  0.6136553504974557\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.12        15\n",
      "          1       0.66      1.00      0.79        56\n",
      "          2       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.60      0.66      0.54        86\n",
      "\n",
      "[ 1 14  0  0 56  0  0 15  0]\n",
      "LR Accuracy:  0.6627906976744186\n",
      "LR F1:  0.3064420803782506\n",
      "For name:  m_gutierrez\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0003-3199-0337': 30, '0000-0003-0964-6222': 2})\n",
      "['0000-0003-3199-0337']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  s_moon\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0001-6248-9049': 30, '0000-0002-7513-4404': 20, '0000-0001-7282-2888': 16, '0000-0002-3803-6354': 16, '0000-0002-2249-7500': 1, '0000-0002-4662-7859': 1, '0000-0002-4989-0150': 1})\n",
      "['0000-0001-6248-9049', '0000-0001-7282-2888', '0000-0002-3803-6354', '0000-0002-7513-4404']\n",
      "Total sample size after apply threshold:  82\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 93)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.97      0.77        30\n",
      "          1       0.91      0.62      0.74        16\n",
      "          2       0.62      0.31      0.42        16\n",
      "          3       0.72      0.65      0.68        20\n",
      "\n",
      "avg / total       0.71      0.70      0.68        82\n",
      "\n",
      "[29  0  0  1  4 10  2  0  6  1  5  4  6  0  1 13]\n",
      "MNB Accuracy:  0.6951219512195121\n",
      "MNB F1:  0.6537378167641326\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        30\n",
      "          1       0.88      0.88      0.88        16\n",
      "          2       0.79      0.69      0.73        16\n",
      "          3       0.82      0.90      0.86        20\n",
      "\n",
      "avg / total       0.87      0.87      0.86        82\n",
      "\n",
      "[28  0  1  1  0 14  2  0  1  1 11  3  1  1  0 18]\n",
      "svc Accuracy:  0.8658536585365854\n",
      "svc F1:  0.849702380952381\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.93      0.84        30\n",
      "          1       0.92      0.75      0.83        16\n",
      "          2       0.69      0.56      0.62        16\n",
      "          3       0.79      0.75      0.77        20\n",
      "\n",
      "avg / total       0.78      0.78      0.78        82\n",
      "\n",
      "[28  0  1  1  1 12  2  1  4  1  9  2  4  0  1 15]\n",
      "LR Accuracy:  0.7804878048780488\n",
      "LR F1:  0.7633318817055307\n",
      "For name:  r_pereira\n",
      "total sample size before apply threshold:  202\n",
      "Counter({'0000-0001-6857-5968': 74, '0000-0003-3704-2848': 39, '0000-0002-3889-798X': 29, '0000-0002-8076-4822': 14, '0000-0002-7514-6130': 14, '0000-0003-1800-1450': 8, '0000-0001-7279-5728': 6, '0000-0003-2767-8535': 5, '0000-0003-1146-7506': 3, '0000-0003-1553-9693': 3, '0000-0001-8500-7364': 2, '0000-0002-3834-3709': 2, '0000-0002-5618-7690': 1, '0000-0002-9841-4775': 1, '0000-0002-2176-016X': 1})\n",
      "['0000-0002-8076-4822', '0000-0002-7514-6130', '0000-0002-3889-798X', '0000-0001-6857-5968', '0000-0003-3704-2848']\n",
      "Total sample size after apply threshold:  170\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(170, 377)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "170\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       1.00      0.57      0.73        14\n",
      "          2       1.00      0.76      0.86        29\n",
      "          3       0.65      1.00      0.79        74\n",
      "          4       0.89      0.62      0.73        39\n",
      "\n",
      "avg / total       0.74      0.75      0.72       170\n",
      "\n",
      "[ 0  0  0 12  2  0  8  0  6  0  0  0 22  6  1  0  0  0 74  0  0  0  0 15\n",
      " 24]\n",
      "MNB Accuracy:  0.7529411764705882\n",
      "MNB F1:  0.62174688057041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        14\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       0.96      0.86      0.91        29\n",
      "          3       0.95      0.95      0.95        74\n",
      "          4       0.73      0.95      0.82        39\n",
      "\n",
      "avg / total       0.91      0.89      0.89       170\n",
      "\n",
      "[ 7  0  0  1  6  0 12  0  1  1  0  0 25  1  3  0  0  0 70  4  0  0  1  1\n",
      " 37]\n",
      "svc Accuracy:  0.888235294117647\n",
      "svc F1:  0.8534005334005335\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        14\n",
      "          1       1.00      0.79      0.88        14\n",
      "          2       0.96      0.83      0.89        29\n",
      "          3       0.83      0.96      0.89        74\n",
      "          4       0.76      0.79      0.77        39\n",
      "\n",
      "avg / total       0.86      0.85      0.84       170\n",
      "\n",
      "[ 7  0  0  3  4  0 11  0  2  1  0  0 24  3  2  0  0  0 71  3  0  0  1  7\n",
      " 31]\n",
      "LR Accuracy:  0.8470588235294118\n",
      "LR F1:  0.8196111111111112\n",
      "For name:  a_nielsen\n",
      "total sample size before apply threshold:  132\n",
      "Counter({'0000-0003-4372-9961': 70, '0000-0001-6616-0187': 27, '0000-0003-4464-8549': 17, '0000-0002-6469-4473': 7, '0000-0002-4837-9449': 3, '0000-0001-9842-5303': 2, '0000-0002-4741-7992': 2, '0000-0002-8955-9374': 2, '0000-0003-2199-2857': 1, '0000-0002-7130-6432': 1})\n",
      "['0000-0001-6616-0187', '0000-0003-4372-9961', '0000-0003-4464-8549']\n",
      "Total sample size after apply threshold:  114\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 270)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "114\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        27\n",
      "          1       0.78      1.00      0.88        70\n",
      "          2       1.00      0.94      0.97        17\n",
      "\n",
      "avg / total       0.86      0.82      0.79       114\n",
      "\n",
      "[ 8 19  0  0 70  0  0  1 16]\n",
      "MNB Accuracy:  0.8245614035087719\n",
      "MNB F1:  0.7672799422799423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.83        27\n",
      "          1       0.89      1.00      0.94        70\n",
      "          2       1.00      0.94      0.97        17\n",
      "\n",
      "avg / total       0.93      0.92      0.92       114\n",
      "\n",
      "[19  8  0  0 70  0  0  1 16]\n",
      "svc Accuracy:  0.9210526315789473\n",
      "svc F1:  0.9117937472183169\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.14        27\n",
      "          1       0.72      1.00      0.84        70\n",
      "          2       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.83      0.76      0.69       114\n",
      "\n",
      "[ 2 25  0  0 70  0  0  2 15]\n",
      "LR Accuracy:  0.7631578947368421\n",
      "LR F1:  0.6379181292587239\n",
      "For name:  j_conde\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0001-8422-6792': 35, '0000-0002-2187-479X': 29, '0000-0002-5677-3024': 19, '0000-0001-8739-6893': 1})\n",
      "['0000-0001-8422-6792', '0000-0002-5677-3024', '0000-0002-2187-479X']\n",
      "Total sample size after apply threshold:  83\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(83, 131)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        35\n",
      "          1       0.95      0.95      0.95        19\n",
      "          2       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        83\n",
      "\n",
      "[34  1  0  1 18  0  0  0 29]\n",
      "MNB Accuracy:  0.9759036144578314\n",
      "MNB F1:  0.9729323308270676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        35\n",
      "          1       1.00      0.89      0.94        19\n",
      "          2       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        83\n",
      "\n",
      "[35  0  0  2 17  0  0  0 29]\n",
      "svc Accuracy:  0.9759036144578314\n",
      "svc F1:  0.9722222222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        35\n",
      "          1       1.00      0.89      0.94        19\n",
      "          2       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        83\n",
      "\n",
      "[35  0  0  2 17  0  0  0 29]\n",
      "LR Accuracy:  0.9759036144578314\n",
      "LR F1:  0.9722222222222222\n",
      "For name:  k_wright\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0003-0040-9247': 18, '0000-0002-9020-1572': 15, '0000-0003-3865-9743': 12, '0000-0002-0387-3048': 7, '0000-0001-6202-1737': 6, '0000-0003-0700-6010': 1})\n",
      "['0000-0003-0040-9247', '0000-0002-9020-1572', '0000-0003-3865-9743']\n",
      "Total sample size after apply threshold:  45\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 2167)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        18\n",
      "          1       0.93      0.93      0.93        15\n",
      "          2       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.89      0.87      0.86        45\n",
      "\n",
      "[18  0  0  1 14  0  4  1  7]\n",
      "MNB Accuracy:  0.8666666666666667\n",
      "MNB F1:  0.8494080730280987\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        18\n",
      "          1       1.00      0.87      0.93        15\n",
      "          2       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.90      0.87      0.87        45\n",
      "\n",
      "[18  0  0  2 13  0  4  0  8]\n",
      "svc Accuracy:  0.8666666666666667\n",
      "svc F1:  0.8619047619047618\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80        18\n",
      "          1       1.00      0.73      0.85        15\n",
      "          2       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.87      0.80      0.80        45\n",
      "\n",
      "[18  0  0  4 11  0  5  0  7]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.794331983805668\n",
      "For name:  m_parker\n",
      "total sample size before apply threshold:  280\n",
      "Counter({'0000-0002-3101-1138': 232, '0000-0002-7172-5231': 13, '0000-0003-1007-4612': 11, '0000-0002-3772-3742': 10, '0000-0002-1052-9296': 6, '0000-0002-3170-3505': 4, '0000-0002-1597-4858': 3, '0000-0001-9845-9108': 1})\n",
      "['0000-0002-3101-1138', '0000-0003-1007-4612', '0000-0002-7172-5231', '0000-0002-3772-3742']\n",
      "Total sample size after apply threshold:  266\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(266, 873)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "266\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93       232\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.80      0.88      0.82       266\n",
      "\n",
      "[232   0   0   0  10   1   0   0  13   0   0   0  10   0   0   0]\n",
      "MNB Accuracy:  0.8759398496240601\n",
      "MNB F1:  0.2750670690811536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96       232\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.94      0.94      0.93       266\n",
      "\n",
      "[232   0   0   0   5   6   0   0   5   0   8   0   7   0   0   3]\n",
      "svc Accuracy:  0.9360902255639098\n",
      "svc F1:  0.7234956352603412\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       232\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.76      0.87      0.81       266\n",
      "\n",
      "[232   0   0   0  11   0   0   0  13   0   0   0  10   0   0   0]\n",
      "LR Accuracy:  0.8721804511278195\n",
      "LR F1:  0.2329317269076305\n",
      "For name:  h_huang\n",
      "total sample size before apply threshold:  224\n",
      "Counter({'0000-0002-3386-0934': 87, '0000-0002-3382-305X': 24, '0000-0001-7640-7702': 18, '0000-0003-2657-3635': 16, '0000-0003-1461-5762': 16, '0000-0001-5497-0158': 14, '0000-0002-3778-4457': 9, '0000-0002-5647-7049': 6, '0000-0002-0919-4644': 5, '0000-0003-1743-7850': 5, '0000-0002-4564-7604': 5, '0000-0002-9665-2489': 4, '0000-0002-0534-2718': 4, '0000-0002-5948-317X': 3, '0000-0002-4104-9471': 2, '0000-0001-8346-1571': 1, '0000-0002-2650-3736': 1, '0000-0001-8237-0168': 1, '0000-0002-1188-9760': 1, '0000-0001-6455-676X': 1, '0000-0003-4184-3744': 1})\n",
      "['0000-0001-7640-7702', '0000-0002-3382-305X', '0000-0001-5497-0158', '0000-0003-2657-3635', '0000-0002-3386-0934', '0000-0003-1461-5762']\n",
      "Total sample size after apply threshold:  175\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 906)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.28      0.43        18\n",
      "          1       0.45      0.21      0.29        24\n",
      "          2       1.00      0.29      0.44        14\n",
      "          3       1.00      0.38      0.55        16\n",
      "          4       0.60      1.00      0.75        87\n",
      "          5       1.00      0.25      0.40        16\n",
      "\n",
      "avg / total       0.73      0.63      0.58       175\n",
      "\n",
      "[ 5  0  0  0 13  0  0  5  0  0 19  0  0  0  4  0 10  0  0  1  0  6  9  0\n",
      "  0  0  0  0 87  0  0  5  0  0  7  4]\n",
      "MNB Accuracy:  0.6342857142857142\n",
      "MNB F1:  0.47673264738482124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.78      0.82        18\n",
      "          1       0.80      0.83      0.82        24\n",
      "          2       1.00      0.79      0.88        14\n",
      "          3       1.00      0.88      0.93        16\n",
      "          4       0.89      0.98      0.93        87\n",
      "          5       0.85      0.69      0.76        16\n",
      "\n",
      "avg / total       0.89      0.89      0.88       175\n",
      "\n",
      "[14  3  0  0  1  0  2 20  0  0  2  0  0  1 11  0  2  0  0  0  0 14  1  1\n",
      "  0  1  0  0 85  1  0  0  0  0  5 11]\n",
      "svc Accuracy:  0.8857142857142857\n",
      "svc F1:  0.856795285666556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.67      0.77        18\n",
      "          1       1.00      0.42      0.59        24\n",
      "          2       1.00      0.57      0.73        14\n",
      "          3       1.00      0.56      0.72        16\n",
      "          4       0.67      1.00      0.81        87\n",
      "          5       1.00      0.38      0.55        16\n",
      "\n",
      "avg / total       0.83      0.75      0.73       175\n",
      "\n",
      "[12  0  0  0  6  0  1 10  0  0 13  0  0  0  8  0  6  0  0  0  0  9  7  0\n",
      "  0  0  0  0 87  0  0  0  0  0 10  6]\n",
      "LR Accuracy:  0.7542857142857143\n",
      "LR F1:  0.6934519451312621\n",
      "For name:  j_terry\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-6829-5736': 35, '0000-0001-5464-8679': 20, '0000-0003-4255-5509': 1, '0000-0002-6314-1412': 1})\n",
      "['0000-0001-5464-8679', '0000-0002-6829-5736']\n",
      "Total sample size after apply threshold:  55\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 207)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.26        20\n",
      "          1       0.67      1.00      0.80        35\n",
      "\n",
      "avg / total       0.79      0.69      0.61        55\n",
      "\n",
      "[ 3 17  0 35]\n",
      "MNB Accuracy:  0.6909090909090909\n",
      "MNB F1:  0.5327336331834083\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86        20\n",
      "          1       0.94      0.89      0.91        35\n",
      "\n",
      "avg / total       0.90      0.89      0.89        55\n",
      "\n",
      "[18  2  4 31]\n",
      "svc Accuracy:  0.8909090909090909\n",
      "svc F1:  0.884453781512605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        20\n",
      "          1       0.66      1.00      0.80        35\n",
      "\n",
      "avg / total       0.78      0.67      0.57        55\n",
      "\n",
      "[ 2 18  0 35]\n",
      "LR Accuracy:  0.6727272727272727\n",
      "LR F1:  0.48863636363636365\n",
      "For name:  y_xu\n",
      "total sample size before apply threshold:  137\n",
      "Counter({'0000-0002-2195-1695': 47, '0000-0002-6689-7768': 19, '0000-0002-6406-7832': 17, '0000-0001-6643-3173': 9, '0000-0002-0763-9953': 8, '0000-0002-4479-6157': 8, '0000-0001-7429-4724': 5, '0000-0002-5578-4960': 4, '0000-0002-1887-0632': 4, '0000-0002-9834-3006': 3, '0000-0002-9945-3514': 3, '0000-0001-8488-0399': 2, '0000-0001-9106-0049': 1, '0000-0003-4549-6110': 1, '0000-0002-2341-7971': 1, '0000-0003-4420-6353': 1, '0000-0002-7963-6890': 1, '0000-0002-7962-6668': 1, '0000-0003-1355-0055': 1, '0000-0002-1563-8811': 1})\n",
      "['0000-0002-6406-7832', '0000-0002-2195-1695', '0000-0002-6689-7768']\n",
      "Total sample size after apply threshold:  83\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(83, 154)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.38        17\n",
      "          1       0.67      1.00      0.80        47\n",
      "          2       1.00      0.47      0.64        19\n",
      "\n",
      "avg / total       0.81      0.72      0.68        83\n",
      "\n",
      "[ 4 13  0  0 47  0  0 10  9]\n",
      "MNB Accuracy:  0.7228915662650602\n",
      "MNB F1:  0.6090761090761091\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.87        17\n",
      "          1       0.84      1.00      0.91        47\n",
      "          2       0.86      0.63      0.73        19\n",
      "\n",
      "avg / total       0.88      0.87      0.86        83\n",
      "\n",
      "[13  2  2  0 47  0  0  7 12]\n",
      "svc Accuracy:  0.8674698795180723\n",
      "svc F1:  0.8355202510542316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        17\n",
      "          1       0.70      1.00      0.82        47\n",
      "          2       1.00      0.47      0.64        19\n",
      "\n",
      "avg / total       0.83      0.76      0.73        83\n",
      "\n",
      "[ 7 10  0  0 47  0  0 10  9]\n",
      "LR Accuracy:  0.7590361445783133\n",
      "LR F1:  0.6835839598997494\n",
      "For name:  a_melo\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-6455-7834': 26, '0000-0002-9153-0773': 11, '0000-0002-4606-7791': 7, '0000-0001-5682-2116': 4})\n",
      "['0000-0001-6455-7834', '0000-0002-9153-0773']\n",
      "Total sample size after apply threshold:  37\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 84)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        26\n",
      "          1       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.95      0.95      0.94        37\n",
      "\n",
      "[26  0  2  9]\n",
      "MNB Accuracy:  0.9459459459459459\n",
      "MNB F1:  0.9314814814814816\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        26\n",
      "          1       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.95      0.95      0.94        37\n",
      "\n",
      "[26  0  2  9]\n",
      "svc Accuracy:  0.9459459459459459\n",
      "svc F1:  0.9314814814814816\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        26\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.91      0.89      0.88        37\n",
      "\n",
      "[26  0  4  7]\n",
      "LR Accuracy:  0.8918918918918919\n",
      "LR F1:  0.8531746031746033\n",
      "For name:  r_doyle\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0001-6229-4700': 5, '0000-0001-5001-1945': 4, '0000-0003-1019-6783': 1, '0000-0002-4704-7178': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_bernardo\n",
      "total sample size before apply threshold:  250\n",
      "Counter({'0000-0001-8748-6717': 216, '0000-0002-9204-7230': 22, '0000-0002-5823-6636': 11, '0000-0003-2661-5380': 1})\n",
      "['0000-0002-9204-7230', '0000-0001-8748-6717', '0000-0002-5823-6636']\n",
      "Total sample size after apply threshold:  249\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(249, 586)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.98        22\n",
      "          1       0.97      1.00      0.99       216\n",
      "          2       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.98      0.98      0.97       249\n",
      "\n",
      "[ 21   1   0   0 216   0   0   5   6]\n",
      "MNB Accuracy:  0.9759036144578314\n",
      "MNB F1:  0.8896426362835673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93        22\n",
      "          1       0.99      1.00      0.99       216\n",
      "          2       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       0.99      0.99      0.99       249\n",
      "\n",
      "[ 19   3   0   0 216   0   0   0  11]\n",
      "svc Accuracy:  0.9879518072289156\n",
      "svc F1:  0.9733109055228484\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        22\n",
      "          1       0.90      1.00      0.95       216\n",
      "          2       1.00      0.27      0.43        11\n",
      "\n",
      "avg / total       0.92      0.91      0.89       249\n",
      "\n",
      "[  7  15   0   0 216   0   0   8   3]\n",
      "LR Accuracy:  0.9076305220883534\n",
      "LR F1:  0.6202601995705445\n",
      "For name:  j_soares\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0001-6558-4973': 17, '0000-0002-2775-131X': 8, '0000-0002-7105-2815': 6, '0000-0003-3464-6208': 5, '0000-0002-7241-8719': 5, '0000-0001-8496-156X': 3, '0000-0003-3908-0741': 2, '0000-0001-5277-4575': 2, '0000-0001-6534-1824': 1})\n",
      "['0000-0001-6558-4973']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  j_richard\n",
      "total sample size before apply threshold:  179\n",
      "Counter({'0000-0002-0440-2387': 110, '0000-0003-1503-3035': 57, '0000-0001-5750-0418': 10, '0000-0003-2514-8282': 2})\n",
      "['0000-0002-0440-2387', '0000-0003-1503-3035', '0000-0001-5750-0418']\n",
      "Total sample size after apply threshold:  177\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(177, 307)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "177\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       110\n",
      "          1       1.00      0.89      0.94        57\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.86      0.91      0.88       177\n",
      "\n",
      "[110   0   0   6  51   0  10   0   0]\n",
      "MNB Accuracy:  0.9096045197740112\n",
      "MNB F1:  0.625549278091651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       110\n",
      "          1       1.00      0.89      0.94        57\n",
      "          2       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.95      0.94      0.94       177\n",
      "\n",
      "[110   0   0   6  51   0   4   0   6]\n",
      "svc Accuracy:  0.943502824858757\n",
      "svc F1:  0.8836553945249598\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       110\n",
      "          1       1.00      0.82      0.90        57\n",
      "          2       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.92      0.90      0.89       177\n",
      "\n",
      "[110   0   0  10  47   0   7   0   3]\n",
      "LR Accuracy:  0.903954802259887\n",
      "LR F1:  0.7645515525262362\n",
      "For name:  p_robinson\n",
      "total sample size before apply threshold:  275\n",
      "Counter({'0000-0002-7878-0313': 133, '0000-0002-0736-9199': 119, '0000-0002-3156-3418': 19, '0000-0002-0577-3147': 4})\n",
      "['0000-0002-0736-9199', '0000-0002-7878-0313', '0000-0002-3156-3418']\n",
      "Total sample size after apply threshold:  271\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(271, 1067)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "271\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.94      0.97       119\n",
      "          1       0.84      1.00      0.91       133\n",
      "          2       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.85      0.90      0.87       271\n",
      "\n",
      "[112   7   0   0 133   0   1  18   0]\n",
      "MNB Accuracy:  0.9040590405904059\n",
      "MNB F1:  0.626535529486116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97       119\n",
      "          1       0.90      1.00      0.95       133\n",
      "          2       1.00      0.53      0.69        19\n",
      "\n",
      "avg / total       0.95      0.94      0.94       271\n",
      "\n",
      "[113   6   0   0 133   0   0   9  10]\n",
      "svc Accuracy:  0.9446494464944649\n",
      "svc F1:  0.8701374401767089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95       119\n",
      "          1       0.83      1.00      0.91       133\n",
      "          2       1.00      0.16      0.27        19\n",
      "\n",
      "avg / total       0.92      0.90      0.88       271\n",
      "\n",
      "[108  11   0   0 133   0   0  16   3]\n",
      "LR Accuracy:  0.9003690036900369\n",
      "LR F1:  0.7107063174330243\n",
      "For name:  c_zou\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0003-2484-7292': 22, '0000-0001-8569-3747': 8, '0000-0003-4305-5055': 1, '0000-0002-9712-4282': 1})\n",
      "['0000-0003-2484-7292']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  s_rana\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-8039-1149': 30, '0000-0001-9197-8378': 9, '0000-0003-0628-7076': 2, '0000-0002-6604-997X': 1})\n",
      "['0000-0002-8039-1149']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  a_nunes\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0003-2760-3277': 18, '0000-0001-9102-3600': 11, '0000-0001-8893-9247': 9, '0000-0001-8844-8333': 5, '0000-0002-3296-0183': 5, '0000-0002-0595-5821': 4, '0000-0002-5001-3534': 2, '0000-0002-4789-0253': 2, '0000-0003-4440-0391': 2, '0000-0001-6847-5764': 2, '0000-0001-8665-4459': 1})\n",
      "['0000-0001-9102-3600', '0000-0003-2760-3277']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 79)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       0.75      1.00      0.86        18\n",
      "\n",
      "avg / total       0.84      0.79      0.77        29\n",
      "\n",
      "[ 5  6  0 18]\n",
      "MNB Accuracy:  0.7931034482758621\n",
      "MNB F1:  0.7410714285714286\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.64      0.74        11\n",
      "          1       0.81      0.94      0.87        18\n",
      "\n",
      "avg / total       0.83      0.83      0.82        29\n",
      "\n",
      "[ 7  4  1 17]\n",
      "svc Accuracy:  0.8275862068965517\n",
      "svc F1:  0.8043184885290149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       0.75      1.00      0.86        18\n",
      "\n",
      "avg / total       0.84      0.79      0.77        29\n",
      "\n",
      "[ 5  6  0 18]\n",
      "LR Accuracy:  0.7931034482758621\n",
      "LR F1:  0.7410714285714286\n",
      "For name:  s_jeong\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0001-6178-8338': 33, '0000-0002-1958-8436': 21, '0000-0002-6376-7001': 13, '0000-0002-6480-7685': 7, '0000-0002-9084-5183': 6, '0000-0001-8995-3497': 5, '0000-0002-8370-3566': 1, '0000-0002-4004-3510': 1, '0000-0001-9175-9642': 1, '0000-0001-9197-1184': 1, '0000-0002-9868-621X': 1, '0000-0002-3309-0693': 1, '0000-0001-9575-0354': 1, '0000-0001-9588-1928': 1})\n",
      "['0000-0002-6376-7001', '0000-0002-1958-8436', '0000-0001-6178-8338']\n",
      "Total sample size after apply threshold:  67\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 138)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.75      0.57      0.65        21\n",
      "          2       0.68      0.97      0.80        33\n",
      "\n",
      "avg / total       0.76      0.72      0.69        67\n",
      "\n",
      "[ 4  3  6  0 12  9  0  1 32]\n",
      "MNB Accuracy:  0.7164179104477612\n",
      "MNB F1:  0.639745627980922\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.84      0.76      0.80        21\n",
      "          2       0.86      0.94      0.90        33\n",
      "\n",
      "avg / total       0.88      0.88      0.88        67\n",
      "\n",
      "[12  1  0  0 16  5  0  2 31]\n",
      "svc Accuracy:  0.8805970149253731\n",
      "svc F1:  0.8861835748792272\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        13\n",
      "          1       0.84      0.76      0.80        21\n",
      "          2       0.84      0.97      0.90        33\n",
      "\n",
      "avg / total       0.87      0.87      0.86        67\n",
      "\n",
      "[10  2  1  0 16  5  0  1 32]\n",
      "LR Accuracy:  0.8656716417910447\n",
      "LR F1:  0.85699122269851\n",
      "For name:  b_olsen\n",
      "total sample size before apply threshold:  213\n",
      "Counter({'0000-0002-4646-691X': 167, '0000-0002-7272-7140': 35, '0000-0001-9758-3641': 6, '0000-0001-5608-2779': 3, '0000-0002-6551-6812': 2})\n",
      "['0000-0002-7272-7140', '0000-0002-4646-691X']\n",
      "Total sample size after apply threshold:  202\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(202, 442)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "202\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        35\n",
      "          1       0.92      1.00      0.96       167\n",
      "\n",
      "avg / total       0.94      0.93      0.92       202\n",
      "\n",
      "[ 21  14   0 167]\n",
      "MNB Accuracy:  0.9306930693069307\n",
      "MNB F1:  0.8548850574712643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        35\n",
      "          1       0.95      1.00      0.97       167\n",
      "\n",
      "avg / total       0.96      0.96      0.95       202\n",
      "\n",
      "[ 26   9   0 167]\n",
      "svc Accuracy:  0.9554455445544554\n",
      "svc F1:  0.9131099746690245\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.11      0.21        35\n",
      "          1       0.84      1.00      0.92       167\n",
      "\n",
      "avg / total       0.87      0.85      0.79       202\n",
      "\n",
      "[  4  31   0 167]\n",
      "LR Accuracy:  0.8465346534653465\n",
      "LR F1:  0.560098349139445\n",
      "For name:  m_reilly\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0001-8029-0084': 17, '0000-0002-5526-8245': 1, '0000-0001-8746-3224': 1, '0000-0003-2506-3190': 1})\n",
      "['0000-0001-8029-0084']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  d_nguyen\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-4997-555X': 8, '0000-0002-3283-3504': 7, '0000-0001-6420-7308': 3, '0000-0002-6811-5897': 2, '0000-0001-6432-4467': 2, '0000-0002-1694-0617': 1, '0000-0001-7720-3592': 1, '0000-0002-9680-5772': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_santos\n",
      "total sample size before apply threshold:  184\n",
      "Counter({'0000-0003-3737-8296': 33, '0000-0002-1577-1663': 29, '0000-0001-5071-443X': 20, '0000-0002-3085-5128': 16, '0000-0001-7720-6806': 13, '0000-0002-7394-7604': 13, '0000-0002-4830-0470': 11, '0000-0001-6182-1708': 8, '0000-0002-7604-5753': 7, '0000-0001-5240-6799': 6, '0000-0003-0126-7420': 6, '0000-0002-8368-8618': 4, '0000-0001-8183-9649': 4, '0000-0001-6071-8100': 4, '0000-0002-0070-5735': 2, '0000-0003-4395-8078': 2, '0000-0001-7922-5357': 1, '0000-0002-9133-2187': 1, '0000-0002-7861-4366': 1, '0000-0002-5431-4756': 1, '0000-0001-6328-8097': 1, '0000-0001-5845-5698': 1})\n",
      "['0000-0003-3737-8296', '0000-0002-4830-0470', '0000-0001-7720-6806', '0000-0001-5071-443X', '0000-0002-1577-1663', '0000-0002-3085-5128', '0000-0002-7394-7604']\n",
      "Total sample size after apply threshold:  135\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(135, 235)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        33\n",
      "          1       1.00      0.45      0.62        11\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       1.00      0.80      0.89        20\n",
      "          4       0.64      0.93      0.76        29\n",
      "          5       1.00      0.81      0.90        16\n",
      "          6       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.88      0.83      0.83       135\n",
      "\n",
      "[33  0  0  0  0  0  0  2  5  0  0  4  0  0  0  0  8  0  5  0  0  2  0  0\n",
      " 16  2  0  0  2  0  0  0 27  0  0  1  0  0  0  2 13  0  1  0  0  0  2  0\n",
      " 10]\n",
      "MNB Accuracy:  0.8296296296296296\n",
      "MNB F1:  0.8134808377852097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        33\n",
      "          1       0.88      0.64      0.74        11\n",
      "          2       0.92      0.85      0.88        13\n",
      "          3       0.95      0.90      0.92        20\n",
      "          4       0.74      1.00      0.85        29\n",
      "          5       1.00      0.81      0.90        16\n",
      "          6       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.92      0.90      0.90       135\n",
      "\n",
      "[33  0  0  0  0  0  0  0  7  1  1  2  0  0  0  0 11  0  2  0  0  0  1  0\n",
      " 18  1  0  0  0  0  0  0 29  0  0  0  0  0  0  3 13  0  0  0  0  0  2  0\n",
      " 11]\n",
      "svc Accuracy:  0.9037037037037037\n",
      "svc F1:  0.8865826565164666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        33\n",
      "          1       1.00      0.64      0.78        11\n",
      "          2       0.89      0.62      0.73        13\n",
      "          3       1.00      0.90      0.95        20\n",
      "          4       0.64      0.97      0.77        29\n",
      "          5       1.00      0.81      0.90        16\n",
      "          6       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.90      0.87      0.87       135\n",
      "\n",
      "[33  0  0  0  0  0  0  0  7  1  0  3  0  0  0  0  8  0  5  0  0  0  0  0\n",
      " 18  2  0  0  1  0  0  0 28  0  0  0  0  0  0  3 13  0  0  0  0  0  3  0\n",
      " 10]\n",
      "LR Accuracy:  0.8666666666666667\n",
      "LR F1:  0.8529619688813251\n",
      "For name:  f_ferreira\n",
      "total sample size before apply threshold:  224\n",
      "Counter({'0000-0003-0989-2335': 125, '0000-0002-7571-1830': 18, '0000-0002-9160-7355': 18, '0000-0001-5765-576X': 16, '0000-0003-1516-1221': 15, '0000-0003-3326-1250': 12, '0000-0001-9616-295X': 5, '0000-0001-8714-2615': 5, '0000-0001-5177-6237': 4, '0000-0002-8857-2438': 3, '0000-0001-5815-2136': 2, '0000-0001-8818-6521': 1})\n",
      "['0000-0003-0989-2335', '0000-0003-1516-1221', '0000-0002-7571-1830', '0000-0003-3326-1250', '0000-0001-5765-576X', '0000-0002-9160-7355']\n",
      "Total sample size after apply threshold:  204\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(204, 649)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "204\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84       125\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       1.00      0.89      0.94        18\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       1.00      0.19      0.32        16\n",
      "          5       1.00      0.28      0.43        18\n",
      "\n",
      "avg / total       0.75      0.76      0.70       204\n",
      "\n",
      "[125   0   0   0   0   0  15   0   0   0   0   0   2   0  16   0   0   0\n",
      "   6   0   0   6   0   0  13   0   0   0   3   0  13   0   0   0   0   5]\n",
      "MNB Accuracy:  0.7598039215686274\n",
      "MNB F1:  0.5324226034954262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       125\n",
      "          1       1.00      0.20      0.33        15\n",
      "          2       1.00      0.94      0.97        18\n",
      "          3       1.00      0.92      0.96        12\n",
      "          4       0.86      0.75      0.80        16\n",
      "          5       1.00      0.61      0.76        18\n",
      "\n",
      "avg / total       0.89      0.88      0.86       204\n",
      "\n",
      "[125   0   0   0   0   0  12   3   0   0   0   0   1   0  17   0   0   0\n",
      "   1   0   0  11   0   0   4   0   0   0  12   0   5   0   0   0   2  11]\n",
      "svc Accuracy:  0.8774509803921569\n",
      "svc F1:  0.7892758748830713\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83       125\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       1.00      0.72      0.84        18\n",
      "          3       1.00      0.58      0.74        12\n",
      "          4       1.00      0.31      0.48        16\n",
      "          5       1.00      0.22      0.36        18\n",
      "\n",
      "avg / total       0.75      0.75      0.70       204\n",
      "\n",
      "[125   0   0   0   0   0  15   0   0   0   0   0   5   0  13   0   0   0\n",
      "   5   0   0   7   0   0  11   0   0   0   5   0  14   0   0   0   0   4]\n",
      "LR Accuracy:  0.7549019607843137\n",
      "LR F1:  0.5414519926404476\n",
      "For name:  y_ng\n",
      "total sample size before apply threshold:  19\n",
      "Counter({'0000-0003-4598-1829': 11, '0000-0001-9142-2126': 4, '0000-0002-7140-1616': 2, '0000-0002-4590-3364': 1, '0000-0002-7213-5030': 1})\n",
      "['0000-0003-4598-1829']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  j_madsen\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0001-7625-9498': 28, '0000-0003-1664-7645': 24, '0000-0003-1411-9080': 8, '0000-0003-3246-0215': 8, '0000-0002-6874-2970': 1})\n",
      "['0000-0001-7625-9498', '0000-0003-1664-7645']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 211)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        28\n",
      "          1       1.00      0.92      0.96        24\n",
      "\n",
      "avg / total       0.96      0.96      0.96        52\n",
      "\n",
      "[28  0  2 22]\n",
      "MNB Accuracy:  0.9615384615384616\n",
      "MNB F1:  0.9610194902548725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        28\n",
      "          1       0.96      1.00      0.98        24\n",
      "\n",
      "avg / total       0.98      0.98      0.98        52\n",
      "\n",
      "[27  1  0 24]\n",
      "svc Accuracy:  0.9807692307692307\n",
      "svc F1:  0.9807050092764378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        28\n",
      "          1       0.96      1.00      0.98        24\n",
      "\n",
      "avg / total       0.98      0.98      0.98        52\n",
      "\n",
      "[27  1  0 24]\n",
      "LR Accuracy:  0.9807692307692307\n",
      "LR F1:  0.9807050092764378\n",
      "For name:  d_collins\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-6754-9290': 8, '0000-0002-6248-9644': 7, '0000-0002-3283-0733': 6, '0000-0003-2274-0889': 5, '0000-0003-2484-1640': 2, '0000-0002-8432-7021': 1, '0000-0001-8891-1893': 1, '0000-0002-7981-3586': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  l_davies\n",
      "total sample size before apply threshold:  96\n",
      "Counter({'0000-0001-8801-3559': 62, '0000-0002-0451-8670': 19, '0000-0002-4876-6270': 11, '0000-0002-2986-705X': 4})\n",
      "['0000-0001-8801-3559', '0000-0002-4876-6270', '0000-0002-0451-8670']\n",
      "Total sample size after apply threshold:  92\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(92, 444)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "92\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        62\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       1.00      0.89      0.94        19\n",
      "\n",
      "avg / total       0.89      0.87      0.83        92\n",
      "\n",
      "[62  0  0 10  1  0  2  0 17]\n",
      "MNB Accuracy:  0.8695652173913043\n",
      "MNB F1:  0.6742919389978214\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        62\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       1.00      0.84      0.91        19\n",
      "\n",
      "avg / total       0.94      0.93      0.93        92\n",
      "\n",
      "[62  0  0  3  8  0  3  0 16]\n",
      "svc Accuracy:  0.9347826086956522\n",
      "svc F1:  0.9034123770965876\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        62\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.58      0.73        19\n",
      "\n",
      "avg / total       0.72      0.79      0.74        92\n",
      "\n",
      "[62  0  0 11  0  0  8  0 11]\n",
      "LR Accuracy:  0.7934782608695652\n",
      "LR F1:  0.5334887334887335\n",
      "For name:  m_mora\n",
      "total sample size before apply threshold:  131\n",
      "Counter({'0000-0002-5765-2320': 104, '0000-0002-8393-0216': 22, '0000-0002-2979-3601': 4, '0000-0003-0627-6764': 1})\n",
      "['0000-0002-8393-0216', '0000-0002-5765-2320']\n",
      "Total sample size after apply threshold:  126\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(126, 654)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "126\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        22\n",
      "          1       0.85      1.00      0.92       104\n",
      "\n",
      "avg / total       0.88      0.86      0.81       126\n",
      "\n",
      "[  4  18   0 104]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.6140231449965963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        22\n",
      "          1       0.88      1.00      0.94       104\n",
      "\n",
      "avg / total       0.90      0.89      0.87       126\n",
      "\n",
      "[  8  14   0 104]\n",
      "svc Accuracy:  0.8888888888888888\n",
      "svc F1:  0.7351351351351352\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        22\n",
      "          1       0.83      1.00      0.90       104\n",
      "\n",
      "avg / total       0.68      0.83      0.75       126\n",
      "\n",
      "[  0  22   0 104]\n",
      "LR Accuracy:  0.8253968253968254\n",
      "LR F1:  0.45217391304347826\n",
      "For name:  a_fontana\n",
      "total sample size before apply threshold:  203\n",
      "Counter({'0000-0002-6660-5315': 65, '0000-0002-5453-461X': 59, '0000-0002-5391-7520': 44, '0000-0002-8481-1219': 16, '0000-0002-4791-8746': 14, '0000-0003-3820-2823': 3, '0000-0003-1556-2770': 2})\n",
      "['0000-0002-5391-7520', '0000-0002-5453-461X', '0000-0002-4791-8746', '0000-0002-6660-5315', '0000-0002-8481-1219']\n",
      "Total sample size after apply threshold:  198\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(198, 702)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "198\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        44\n",
      "          1       0.80      0.97      0.88        59\n",
      "          2       1.00      0.50      0.67        14\n",
      "          3       0.94      0.97      0.95        65\n",
      "          4       1.00      0.62      0.77        16\n",
      "\n",
      "avg / total       0.92      0.91      0.90       198\n",
      "\n",
      "[43  1  0  0  0  0 57  0  2  0  0  5  7  2  0  0  2  0 63  0  0  6  0  0\n",
      " 10]\n",
      "MNB Accuracy:  0.9090909090909091\n",
      "MNB F1:  0.8511743428984809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.98        44\n",
      "          1       0.88      0.98      0.93        59\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       0.98      0.98      0.98        65\n",
      "          4       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       0.96      0.95      0.95       198\n",
      "\n",
      "[42  2  0  0  0  0 58  0  1  0  0  5  9  0  0  0  1  0 64  0  0  0  0  0\n",
      " 16]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.934393653262814\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.89      0.93        44\n",
      "          1       0.91      0.85      0.88        59\n",
      "          2       1.00      0.50      0.67        14\n",
      "          3       0.77      1.00      0.87        65\n",
      "          4       1.00      0.75      0.86        16\n",
      "\n",
      "avg / total       0.89      0.87      0.87       198\n",
      "\n",
      "[39  1  0  4  0  1 50  0  8  0  0  3  7  4  0  0  0  0 65  0  0  1  0  3\n",
      " 12]\n",
      "LR Accuracy:  0.8737373737373737\n",
      "LR F1:  0.8404114312627204\n",
      "For name:  r_chen\n",
      "total sample size before apply threshold:  367\n",
      "Counter({'0000-0002-8371-8629': 179, '0000-0001-6344-1442': 34, '0000-0003-0291-006X': 32, '0000-0001-6892-0602': 32, '0000-0003-3987-033X': 24, '0000-0002-7505-5415': 21, '0000-0003-1455-5093': 20, '0000-0001-9186-6747': 11, '0000-0002-5340-248X': 4, '0000-0002-8237-6612': 3, '0000-0001-6968-4955': 2, '0000-0003-1919-3335': 1, '0000-0003-4581-8204': 1, '0000-0001-8395-4392': 1, '0000-0001-9750-6670': 1, '0000-0003-1298-9381': 1})\n",
      "['0000-0003-0291-006X', '0000-0001-9186-6747', '0000-0001-6892-0602', '0000-0002-8371-8629', '0000-0003-1455-5093', '0000-0003-3987-033X', '0000-0002-7505-5415', '0000-0001-6344-1442']\n",
      "Total sample size after apply threshold:  353\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(353, 645)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.84      0.75        32\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.63      0.84      0.72        32\n",
      "          3       0.83      1.00      0.91       179\n",
      "          4       1.00      0.45      0.62        20\n",
      "          5       1.00      0.21      0.34        24\n",
      "          6       0.90      0.43      0.58        21\n",
      "          7       0.90      0.82      0.86        34\n",
      "\n",
      "avg / total       0.81      0.80      0.77       353\n",
      "\n",
      "[ 27   0   3   1   0   0   1   0   0   0   1  10   0   0   0   0   3   0\n",
      "  27   2   0   0   0   0   0   0   0 179   0   0   0   0   0   0   0   8\n",
      "   9   0   0   3   4   0   6   9   0   5   0   0   5   0   5   2   0   0\n",
      "   9   0   1   0   1   4   0   0   0  28]\n",
      "MNB Accuracy:  0.8045325779036827\n",
      "MNB F1:  0.5982912882290575\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85        32\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       0.79      0.84      0.82        32\n",
      "          3       0.93      0.99      0.96       179\n",
      "          4       0.88      0.75      0.81        20\n",
      "          5       0.64      0.58      0.61        24\n",
      "          6       0.71      0.48      0.57        21\n",
      "          7       0.83      0.85      0.84        34\n",
      "\n",
      "avg / total       0.87      0.87      0.86       353\n",
      "\n",
      "[ 28   0   1   0   0   2   1   0   0   6   0   5   0   0   0   0   2   0\n",
      "  27   2   0   1   0   0   0   0   1 178   0   0   0   0   0   0   0   1\n",
      "  15   0   0   4   1   0   3   2   0  14   3   1   3   0   2   1   0   4\n",
      "  10   1   0   0   0   2   2   1   0  29]\n",
      "svc Accuracy:  0.8696883852691218\n",
      "svc F1:  0.7707782407910284\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.88      0.84        32\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.79      0.81      0.80        32\n",
      "          3       0.72      1.00      0.84       179\n",
      "          4       1.00      0.55      0.71        20\n",
      "          5       0.67      0.08      0.15        24\n",
      "          6       0.78      0.33      0.47        21\n",
      "          7       0.92      0.35      0.51        34\n",
      "\n",
      "avg / total       0.75      0.75      0.70       353\n",
      "\n",
      "[ 28   0   1   2   0   0   1   0   0   0   0  11   0   0   0   0   2   0\n",
      "  26   4   0   0   0   0   0   0   0 179   0   0   0   0   0   0   0   8\n",
      "  11   0   0   1   3   0   2  16   0   2   1   0   2   0   4   7   0   1\n",
      "   7   0   0   0   0  22   0   0   0  12]\n",
      "LR Accuracy:  0.7507082152974505\n",
      "LR F1:  0.5384250032119029\n",
      "For name:  s_krause\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0002-5259-4651': 43, '0000-0003-1943-2703': 11, '0000-0002-8532-4244': 11, '0000-0002-7062-8472': 5})\n",
      "['0000-0003-1943-2703', '0000-0002-5259-4651', '0000-0002-8532-4244']\n",
      "Total sample size after apply threshold:  65\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 330)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        11\n",
      "          1       0.70      1.00      0.83        43\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.64      0.72      0.64        65\n",
      "\n",
      "[ 4  7  0  0 43  0  0 11  0]\n",
      "MNB Accuracy:  0.7230769230769231\n",
      "MNB F1:  0.4534188034188034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.80      1.00      0.89        43\n",
      "          2       1.00      0.36      0.53        11\n",
      "\n",
      "avg / total       0.87      0.83      0.81        65\n",
      "\n",
      "[ 7  4  0  0 43  0  0  7  4]\n",
      "svc Accuracy:  0.8307692307692308\n",
      "svc F1:  0.7325696830851469\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        11\n",
      "          1       0.70      1.00      0.83        43\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.64      0.72      0.64        65\n",
      "\n",
      "[ 4  7  0  0 43  0  0 11  0]\n",
      "LR Accuracy:  0.7230769230769231\n",
      "LR F1:  0.4534188034188034\n",
      "For name:  t_smith\n",
      "total sample size before apply threshold:  603\n",
      "Counter({'0000-0002-3650-9381': 154, '0000-0003-1673-2954': 113, '0000-0002-2120-2766': 85, '0000-0002-6279-9685': 84, '0000-0003-3528-6793': 65, '0000-0003-4453-9713': 32, '0000-0002-5197-5030': 26, '0000-0002-3945-630X': 10, '0000-0001-7894-6814': 9, '0000-0002-5750-0706': 6, '0000-0002-5495-8906': 4, '0000-0003-3762-6253': 4, '0000-0002-0479-4261': 3, '0000-0003-2389-461X': 2, '0000-0001-6272-8871': 2, '0000-0001-7683-2653': 1, '0000-0002-2104-2264': 1, '0000-0001-9068-4642': 1, '0000-0002-1881-2766': 1})\n",
      "['0000-0002-3945-630X', '0000-0003-4453-9713', '0000-0003-3528-6793', '0000-0002-6279-9685', '0000-0003-1673-2954', '0000-0002-3650-9381', '0000-0002-2120-2766', '0000-0002-5197-5030']\n",
      "Total sample size after apply threshold:  569\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(569, 1071)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.09      0.17        32\n",
      "          2       0.92      0.71      0.80        65\n",
      "          3       0.93      0.68      0.79        84\n",
      "          4       0.88      0.93      0.90       113\n",
      "          5       0.66      1.00      0.79       154\n",
      "          6       0.96      0.92      0.94        85\n",
      "          7       1.00      0.73      0.84        26\n",
      "\n",
      "avg / total       0.84      0.81      0.79       569\n",
      "\n",
      "[  0   0   0   1   2   7   0   0   0   3   2   1   9  17   0   0   0   0\n",
      "  46   1   2  13   3   0   0   0   2  57   2  23   0   0   0   0   0   0\n",
      " 105   8   0   0   0   0   0   0   0 154   0   0   0   0   0   0   0   7\n",
      "  78   0   0   0   0   1   0   6   0  19]\n",
      "MNB Accuracy:  0.81195079086116\n",
      "MNB F1:  0.654362535142212\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.50      0.67        32\n",
      "          2       0.95      0.80      0.87        65\n",
      "          3       0.88      0.80      0.84        84\n",
      "          4       0.96      0.92      0.94       113\n",
      "          5       0.71      0.99      0.83       154\n",
      "          6       0.99      0.92      0.95        85\n",
      "          7       1.00      0.81      0.89        26\n",
      "\n",
      "avg / total       0.87      0.86      0.86       569\n",
      "\n",
      "[  0   0   0   1   2   7   0   0   0  16   2   3   2   9   0   0   0   0\n",
      "  52   3   0   9   1   0   0   0   0  67   0  17   0   0   0   0   1   0\n",
      " 104   8   0   0   0   0   0   1   0 153   0   0   0   0   0   1   0   6\n",
      "  78   0   0   0   0   0   0   5   0  21]\n",
      "svc Accuracy:  0.8629173989455184\n",
      "svc F1:  0.748546009565465\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.22      0.36        32\n",
      "          2       0.94      0.68      0.79        65\n",
      "          3       0.95      0.68      0.79        84\n",
      "          4       0.98      0.88      0.93       113\n",
      "          5       0.59      1.00      0.74       154\n",
      "          6       0.99      0.84      0.90        85\n",
      "          7       1.00      0.77      0.87        26\n",
      "\n",
      "avg / total       0.85      0.79      0.79       569\n",
      "\n",
      "[  0   0   0   1   1   8   0   0   0   7   2   0   0  23   0   0   0   0\n",
      "  44   1   1  18   1   0   0   0   1  57   0  26   0   0   0   0   0   0\n",
      "  99  14   0   0   0   0   0   0   0 154   0   0   0   0   0   0   0  14\n",
      "  71   0   0   0   0   1   0   5   0  20]\n",
      "LR Accuracy:  0.7943760984182777\n",
      "LR F1:  0.671999673464645\n",
      "For name:  a_biswas\n",
      "total sample size before apply threshold:  10\n",
      "Counter({'0000-0003-2010-9524': 3, '0000-0002-5828-7230': 3, '0000-0002-0393-6280': 2, '0000-0002-7446-4639': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_day\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-9520-3465': 5, '0000-0003-1686-4885': 2, '0000-0001-8681-9831': 2, '0000-0001-6274-9197': 2, '0000-0001-6803-5865': 1, '0000-0003-4324-3486': 1, '0000-0003-1035-2117': 1, '0000-0003-4277-4816': 1, '0000-0003-3133-943X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_truong\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0003-4946-8969': 7, '0000-0002-1720-1744': 4, '0000-0003-3200-1297': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_pan\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0003-3154-6690': 34, '0000-0002-8247-2110': 12, '0000-0002-1189-4199': 11, '0000-0003-2082-4077': 10, '0000-0001-6451-4666': 10, '0000-0002-7581-1831': 9, '0000-0003-2620-7272': 6, '0000-0001-6565-3836': 5, '0000-0003-0794-527X': 4})\n",
      "['0000-0003-2082-4077', '0000-0001-6451-4666', '0000-0002-1189-4199', '0000-0002-8247-2110', '0000-0003-3154-6690']\n",
      "Total sample size after apply threshold:  77\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 211)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.75      0.25      0.38        12\n",
      "          4       0.47      1.00      0.64        34\n",
      "\n",
      "avg / total       0.32      0.48      0.34        77\n",
      "\n",
      "[ 0  0  0  0 10  0  0  0  0 10  0  0  0  1 10  0  0  0  3  9  0  0  0  0\n",
      " 34]\n",
      "MNB Accuracy:  0.4805194805194805\n",
      "MNB F1:  0.20210280373831777\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       0.67      0.55      0.60        11\n",
      "          3       0.91      0.83      0.87        12\n",
      "          4       0.80      0.97      0.88        34\n",
      "\n",
      "avg / total       0.85      0.84      0.84        77\n",
      "\n",
      "[ 9  0  0  0  1  0  7  0  0  3  0  0  6  1  4  0  0  2 10  0  0  0  1  0\n",
      " 33]\n",
      "svc Accuracy:  0.8441558441558441\n",
      "svc F1:  0.8240926100417283\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       1.00      0.40      0.57        10\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       0.55      1.00      0.71        34\n",
      "\n",
      "avg / total       0.66      0.64      0.58        77\n",
      "\n",
      "[ 5  0  0  0  5  0  4  0  0  6  0  0  0  0 11  0  0  0  6  6  0  0  0  0\n",
      " 34]\n",
      "LR Accuracy:  0.6363636363636364\n",
      "LR F1:  0.5226190476190476\n",
      "For name:  a_andrade\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-9569-6503': 18, '0000-0002-5689-6606': 13, '0000-0003-4902-8728': 10, '0000-0002-8107-7338': 9, '0000-0002-3540-6858': 1, '0000-0001-7128-3472': 1})\n",
      "['0000-0002-5689-6606', '0000-0003-4902-8728', '0000-0001-9569-6503']\n",
      "Total sample size after apply threshold:  41\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 142)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       0.72      1.00      0.84        18\n",
      "\n",
      "avg / total       0.88      0.83      0.81        41\n",
      "\n",
      "[ 6  0  7  0 10  0  0  0 18]\n",
      "MNB Accuracy:  0.8292682926829268\n",
      "MNB F1:  0.8229294165646674\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       0.95      1.00      0.97        18\n",
      "\n",
      "avg / total       0.98      0.98      0.98        41\n",
      "\n",
      "[12  0  1  0 10  0  0  0 18]\n",
      "svc Accuracy:  0.975609756097561\n",
      "svc F1:  0.9776576576576576\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       0.72      1.00      0.84        18\n",
      "\n",
      "avg / total       0.88      0.83      0.81        41\n",
      "\n",
      "[ 6  0  7  0 10  0  0  0 18]\n",
      "LR Accuracy:  0.8292682926829268\n",
      "LR F1:  0.8229294165646674\n",
      "For name:  t_oliveira\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-2654-0879': 17, '0000-0003-0843-7541': 11, '0000-0003-0509-0562': 9, '0000-0001-7040-7189': 1, '0000-0003-3947-1881': 1, '0000-0002-9200-3625': 1, '0000-0001-6055-058X': 1})\n",
      "['0000-0003-0843-7541', '0000-0002-2654-0879']\n",
      "Total sample size after apply threshold:  28\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 156)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.97      0.96      0.96        28\n",
      "\n",
      "[10  1  0 17]\n",
      "MNB Accuracy:  0.9642857142857143\n",
      "MNB F1:  0.9619047619047618\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.97      0.96      0.96        28\n",
      "\n",
      "[10  1  0 17]\n",
      "svc Accuracy:  0.9642857142857143\n",
      "svc F1:  0.9619047619047618\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.85      1.00      0.92        17\n",
      "\n",
      "avg / total       0.91      0.89      0.89        28\n",
      "\n",
      "[ 8  3  0 17]\n",
      "LR Accuracy:  0.8928571428571429\n",
      "LR F1:  0.8805120910384068\n",
      "For name:  n_romano\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0003-2765-4912': 7, '0000-0002-9541-8885': 2, '0000-0002-6105-1827': 1, '0000-0001-7276-6994': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_hara\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0003-2668-6218': 15, '0000-0003-0450-6829': 6, '0000-0002-6565-0720': 1, '0000-0002-0235-238X': 1})\n",
      "['0000-0003-2668-6218']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  t_wong\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-1045-2698': 9, '0000-0002-5752-7917': 2, '0000-0001-9234-4529': 1, '0000-0001-6187-8851': 1, '0000-0001-8611-4911': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_ross\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-2302-8415': 17, '0000-0001-7305-3451': 3, '0000-0002-3094-3769': 2, '0000-0003-3512-9579': 1, '0000-0001-5676-4489': 1, '0000-0001-5523-2376': 1})\n",
      "['0000-0002-2302-8415']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  d_richardson\n",
      "total sample size before apply threshold:  456\n",
      "Counter({'0000-0003-0960-6415': 231, '0000-0002-7751-1058': 167, '0000-0002-3992-8610': 22, '0000-0003-0247-9118': 17, '0000-0002-3189-2190': 12, '0000-0002-0054-6850': 7})\n",
      "['0000-0002-3189-2190', '0000-0003-0960-6415', '0000-0002-7751-1058', '0000-0002-3992-8610', '0000-0003-0247-9118']\n",
      "Total sample size after apply threshold:  449\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(449, 1208)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.86      1.00      0.93       231\n",
      "          2       0.98      0.95      0.96       167\n",
      "          3       0.92      0.50      0.65        22\n",
      "          4       1.00      0.47      0.64        17\n",
      "\n",
      "avg / total       0.89      0.91      0.89       449\n",
      "\n",
      "[  0  11   1   0   0   0 230   1   0   0   0   8 159   0   0   0  11   0\n",
      "  11   0   0   6   2   1   8]\n",
      "MNB Accuracy:  0.9086859688195991\n",
      "MNB F1:  0.6352497014170584\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.89      1.00      0.94       231\n",
      "          2       0.99      0.95      0.97       167\n",
      "          3       1.00      0.73      0.84        22\n",
      "          4       1.00      0.53      0.69        17\n",
      "\n",
      "avg / total       0.94      0.94      0.93       449\n",
      "\n",
      "[  6   6   0   0   0   0 231   0   0   0   0   9 158   0   0   0   6   0\n",
      "  16   0   0   7   1   0   9]\n",
      "svc Accuracy:  0.9354120267260579\n",
      "svc F1:  0.822652383672726\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.80      1.00      0.89       231\n",
      "          2       0.99      0.87      0.92       167\n",
      "          3       1.00      0.50      0.67        22\n",
      "          4       1.00      0.18      0.30        17\n",
      "\n",
      "avg / total       0.89      0.87      0.85       449\n",
      "\n",
      "[  1  10   1   0   0   0 231   0   0   0   0  22 145   0   0   0  11   0\n",
      "  11   0   0  13   1   0   3]\n",
      "LR Accuracy:  0.8708240534521158\n",
      "LR F1:  0.5871943182771208\n",
      "For name:  j_moraes\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0002-5766-6802': 13, '0000-0002-8563-6432': 7, '0000-0002-4490-8307': 4, '0000-0002-3067-5194': 2})\n",
      "['0000-0002-5766-6802']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  e_moreno\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0002-2309-4826': 26, '0000-0001-5040-452X': 21, '0000-0001-9490-7030': 14, '0000-0002-8434-2483': 8, '0000-0003-0491-7951': 5, '0000-0002-2301-4558': 4, '0000-0002-7197-5679': 3, '0000-0001-8520-8086': 1, '0000-0002-2733-0267': 1})\n",
      "['0000-0002-2309-4826', '0000-0001-9490-7030', '0000-0001-5040-452X']\n",
      "Total sample size after apply threshold:  61\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 143)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        26\n",
      "          1       1.00      0.79      0.88        14\n",
      "          2       0.85      0.81      0.83        21\n",
      "\n",
      "avg / total       0.89      0.89      0.88        61\n",
      "\n",
      "[26  0  0  0 11  3  4  0 17]\n",
      "MNB Accuracy:  0.8852459016393442\n",
      "MNB F1:  0.8792799070847851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        26\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       0.86      0.86      0.86        21\n",
      "\n",
      "avg / total       0.89      0.89      0.88        61\n",
      "\n",
      "[26  0  0  1 10  3  3  0 18]\n",
      "svc Accuracy:  0.8852459016393442\n",
      "svc F1:  0.873015873015873\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        26\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       1.00      0.76      0.86        21\n",
      "\n",
      "avg / total       0.89      0.85      0.85        61\n",
      "\n",
      "[26  0  0  4 10  0  5  0 16]\n",
      "LR Accuracy:  0.8524590163934426\n",
      "LR F1:  0.8502190715305469\n",
      "For name:  r_little\n",
      "total sample size before apply threshold:  4\n",
      "Counter({'0000-0002-4000-946X': 2, '0000-0002-7732-157X': 1, '0000-0003-1870-3241': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_kobayashi\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-4008-454X': 85, '0000-0002-0237-3623': 22, '0000-0002-2738-373X': 10, '0000-0002-7650-1763': 10, '0000-0002-0903-6259': 6, '0000-0002-9202-7643': 5, '0000-0001-7297-8524': 5, '0000-0002-6952-8669': 4, '0000-0003-0963-2525': 2, '0000-0003-4264-5117': 1})\n",
      "['0000-0002-4008-454X', '0000-0002-2738-373X', '0000-0002-0237-3623', '0000-0002-7650-1763']\n",
      "Total sample size after apply threshold:  127\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 325)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.99      0.81        85\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.75      0.14      0.23        22\n",
      "          3       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.67      0.69      0.60       127\n",
      "\n",
      "[84  0  1  0 10  0  0  0 19  0  3  0  9  0  0  1]\n",
      "MNB Accuracy:  0.6929133858267716\n",
      "MNB F1:  0.3060454038714909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        85\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.68      0.81        22\n",
      "          3       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.89      0.87      0.86       127\n",
      "\n",
      "[85  0  0  0  3  7  0  0  7  0 15  0  6  0  0  4]\n",
      "svc Accuracy:  0.8740157480314961\n",
      "svc F1:  0.779936822156936\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        85\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.36      0.53        22\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.65      0.73      0.65       127\n",
      "\n",
      "[85  0  0  0 10  0  0  0 14  0  8  0 10  0  0  0]\n",
      "LR Accuracy:  0.7322834645669292\n",
      "LR F1:  0.3416666666666667\n",
      "For name:  a_lin\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0003-4236-7233': 27, '0000-0001-6310-9765': 10, '0000-0001-9783-1270': 5, '0000-0003-0072-612X': 3, '0000-0001-8545-2222': 1})\n",
      "['0000-0003-4236-7233', '0000-0001-6310-9765']\n",
      "Total sample size after apply threshold:  37\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 55)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        27\n",
      "          1       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.87      0.84      0.81        37\n",
      "\n",
      "[27  0  6  4]\n",
      "MNB Accuracy:  0.8378378378378378\n",
      "MNB F1:  0.7357142857142858\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        27\n",
      "          1       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.91      0.89      0.88        37\n",
      "\n",
      "[27  0  4  6]\n",
      "svc Accuracy:  0.8918918918918919\n",
      "svc F1:  0.8405172413793103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.89        27\n",
      "          1       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.85      0.81      0.77        37\n",
      "\n",
      "[27  0  7  3]\n",
      "LR Accuracy:  0.8108108108108109\n",
      "LR F1:  0.6733921815889029\n",
      "For name:  a_miranda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0001-6998-5686': 48, '0000-0001-5807-5820': 11, '0000-0003-3957-6288': 4, '0000-0003-4964-2197': 2, '0000-0002-9066-6935': 2, '0000-0003-4872-0632': 2, '0000-0002-7297-9639': 1})\n",
      "['0000-0001-5807-5820', '0000-0001-6998-5686']\n",
      "Total sample size after apply threshold:  59\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 586)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.73      0.80        11\n",
      "          1       0.94      0.98      0.96        48\n",
      "\n",
      "avg / total       0.93      0.93      0.93        59\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  3  1 47]\n",
      "MNB Accuracy:  0.9322033898305084\n",
      "MNB F1:  0.8795918367346938\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        48\n",
      "\n",
      "avg / total       1.00      1.00      1.00        59\n",
      "\n",
      "[11  0  0 48]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       0.84      1.00      0.91        48\n",
      "\n",
      "avg / total       0.87      0.85      0.80        59\n",
      "\n",
      "[ 2  9  0 48]\n",
      "LR Accuracy:  0.847457627118644\n",
      "LR F1:  0.610989010989011\n",
      "For name:  h_vogel\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0001-9821-7731': 5, '0000-0002-9902-8120': 4, '0000-0003-2404-9485': 4, '0000-0003-0072-4239': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_campos\n",
      "total sample size before apply threshold:  148\n",
      "Counter({'0000-0001-7738-9892': 107, '0000-0003-3217-9001': 12, '0000-0003-4313-7069': 8, '0000-0003-1012-6240': 6, '0000-0002-0883-0610': 5, '0000-0002-5233-3769': 5, '0000-0003-4683-0176': 3, '0000-0002-9516-6526': 2})\n",
      "['0000-0001-7738-9892', '0000-0003-3217-9001']\n",
      "Total sample size after apply threshold:  119\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(119, 260)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "119\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       107\n",
      "          1       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.96      0.96      0.95       119\n",
      "\n",
      "[107   0   5   7]\n",
      "MNB Accuracy:  0.957983193277311\n",
      "MNB F1:  0.8570055275174238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       107\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.99      0.99      0.99       119\n",
      "\n",
      "[107   0   1  11]\n",
      "svc Accuracy:  0.9915966386554622\n",
      "svc F1:  0.9759352881698686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       107\n",
      "          1       1.00      0.42      0.59        12\n",
      "\n",
      "avg / total       0.94      0.94      0.93       119\n",
      "\n",
      "[107   0   7   5]\n",
      "LR Accuracy:  0.9411764705882353\n",
      "LR F1:  0.7782805429864253\n",
      "For name:  d_stewart\n",
      "total sample size before apply threshold:  294\n",
      "Counter({'0000-0002-8157-7746': 210, '0000-0001-7360-8592': 77, '0000-0002-6764-4842': 3, '0000-0002-8499-7105': 1, '0000-0002-4087-5544': 1, '0000-0001-5144-1234': 1, '0000-0002-3690-9844': 1})\n",
      "['0000-0001-7360-8592', '0000-0002-8157-7746']\n",
      "Total sample size after apply threshold:  287\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 519)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "287\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.92      0.95        77\n",
      "          1       0.97      0.99      0.98       210\n",
      "\n",
      "avg / total       0.97      0.97      0.97       287\n",
      "\n",
      "[ 71   6   2 208]\n",
      "MNB Accuracy:  0.9721254355400697\n",
      "MNB F1:  0.9638993710691823\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        77\n",
      "          1       0.96      1.00      0.98       210\n",
      "\n",
      "avg / total       0.97      0.97      0.97       287\n",
      "\n",
      "[ 69   8   0 210]\n",
      "svc Accuracy:  0.9721254355400697\n",
      "svc F1:  0.963256945333504\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        77\n",
      "          1       0.86      1.00      0.93       210\n",
      "\n",
      "avg / total       0.90      0.89      0.87       287\n",
      "\n",
      "[ 44  33   0 210]\n",
      "LR Accuracy:  0.8850174216027874\n",
      "LR F1:  0.827212522576761\n",
      "For name:  j_abrantes\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-8391-7134': 42, '0000-0003-1902-9017': 11, '0000-0003-4585-9831': 4})\n",
      "['0000-0003-1902-9017', '0000-0002-8391-7134']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 118)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.91      1.00      0.95        42\n",
      "\n",
      "avg / total       0.93      0.92      0.92        53\n",
      "\n",
      "[ 7  4  0 42]\n",
      "MNB Accuracy:  0.9245283018867925\n",
      "MNB F1:  0.8661616161616161\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.98      1.00      0.99        42\n",
      "\n",
      "avg / total       0.98      0.98      0.98        53\n",
      "\n",
      "[10  1  0 42]\n",
      "svc Accuracy:  0.9811320754716981\n",
      "svc F1:  0.9703081232492996\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.89      1.00      0.94        42\n",
      "\n",
      "avg / total       0.92      0.91      0.89        53\n",
      "\n",
      "[ 6  5  0 42]\n",
      "LR Accuracy:  0.9056603773584906\n",
      "LR F1:  0.8248512888301387\n",
      "For name:  j_arroyo\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0002-1971-1721': 65, '0000-0003-4749-2519': 18, '0000-0002-5992-5011': 10, '0000-0002-5674-6739': 10, '0000-0001-7658-8750': 6})\n",
      "['0000-0003-4749-2519', '0000-0002-5992-5011', '0000-0002-5674-6739', '0000-0002-1971-1721']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  103\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 412)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.22      0.35        18\n",
      "          1       1.00      0.10      0.18        10\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.66      0.98      0.79        65\n",
      "\n",
      "avg / total       0.65      0.67      0.58       103\n",
      "\n",
      "[ 4  0  0 14  0  1  0  9  0  0  0 10  1  0  0 64]\n",
      "MNB Accuracy:  0.6699029126213593\n",
      "MNB F1:  0.32994193139120676\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        18\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.60      0.75        10\n",
      "          3       0.83      1.00      0.91        65\n",
      "\n",
      "avg / total       0.89      0.87      0.87       103\n",
      "\n",
      "[12  0  0  6  0  7  0  3  0  0  6  4  0  0  0 65]\n",
      "svc Accuracy:  0.8737864077669902\n",
      "svc F1:  0.8206550802139038\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.11      0.20        18\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.64      1.00      0.78        65\n",
      "\n",
      "avg / total       0.58      0.65      0.53       103\n",
      "\n",
      "[ 2  0  0 16  0  0  0 10  0  0  0 10  0  0  0 65]\n",
      "LR Accuracy:  0.6504854368932039\n",
      "LR F1:  0.24578313253012046\n",
      "For name:  a_giuliani\n",
      "total sample size before apply threshold:  196\n",
      "Counter({'0000-0002-4640-804X': 155, '0000-0003-1710-4933': 36, '0000-0002-4315-1699': 4, '0000-0002-6823-2807': 1})\n",
      "['0000-0003-1710-4933', '0000-0002-4640-804X']\n",
      "Total sample size after apply threshold:  191\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 513)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        36\n",
      "          1       0.96      1.00      0.98       155\n",
      "\n",
      "avg / total       0.96      0.96      0.96       191\n",
      "\n",
      "[ 29   7   0 155]\n",
      "MNB Accuracy:  0.9633507853403142\n",
      "MNB F1:  0.9351128366901238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        36\n",
      "          1       0.95      1.00      0.97       155\n",
      "\n",
      "avg / total       0.96      0.95      0.95       191\n",
      "\n",
      "[ 27   9   0 155]\n",
      "svc Accuracy:  0.9528795811518325\n",
      "svc F1:  0.9144648454993283\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        36\n",
      "          1       0.86      1.00      0.93       155\n",
      "\n",
      "avg / total       0.89      0.87      0.84       191\n",
      "\n",
      "[ 11  25   0 155]\n",
      "LR Accuracy:  0.8691099476439791\n",
      "LR F1:  0.6967291203556685\n",
      "For name:  f_campos\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0001-8376-0977': 14, '0000-0002-5948-472X': 12, '0000-0002-1132-3257': 10, '0000-0001-8332-5043': 9, '0000-0001-9826-751X': 2, '0000-0001-5828-2862': 2})\n",
      "['0000-0001-8376-0977', '0000-0002-5948-472X', '0000-0002-1132-3257']\n",
      "Total sample size after apply threshold:  36\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 129)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       1.00      1.00      1.00        12\n",
      "          2       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[13  0  1  0 12  0  0  0 10]\n",
      "MNB Accuracy:  0.9722222222222222\n",
      "MNB F1:  0.9717813051146384\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.86      0.89        14\n",
      "          1       0.92      1.00      0.96        12\n",
      "          2       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.92      0.92      0.92        36\n",
      "\n",
      "[12  1  1  0 12  0  1  0  9]\n",
      "svc Accuracy:  0.9166666666666666\n",
      "svc F1:  0.9162962962962964\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.79      0.85        14\n",
      "          1       0.86      1.00      0.92        12\n",
      "          2       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.89      0.89      0.89        36\n",
      "\n",
      "[11  2  1  0 12  0  1  0  9]\n",
      "LR Accuracy:  0.8888888888888888\n",
      "LR F1:  0.8897435897435897\n",
      "For name:  a_mitchell\n",
      "total sample size before apply threshold:  436\n",
      "Counter({'0000-0001-6014-598X': 188, '0000-0002-0868-4000': 98, '0000-0002-2463-2956': 65, '0000-0001-8996-1067': 24, '0000-0001-8655-7966': 23, '0000-0002-9946-183X': 20, '0000-0003-1062-0716': 6, '0000-0001-5022-5898': 4, '0000-0003-2001-1738': 4, '0000-0003-0969-1680': 3, '0000-0003-3352-3046': 1})\n",
      "['0000-0002-9946-183X', '0000-0001-6014-598X', '0000-0001-8655-7966', '0000-0002-2463-2956', '0000-0002-0868-4000', '0000-0001-8996-1067']\n",
      "Total sample size after apply threshold:  418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(418, 1043)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "418\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        20\n",
      "          1       0.73      1.00      0.84       188\n",
      "          2       1.00      0.30      0.47        23\n",
      "          3       1.00      0.91      0.95        65\n",
      "          4       1.00      0.85      0.92        98\n",
      "          5       1.00      0.33      0.50        24\n",
      "\n",
      "avg / total       0.88      0.83      0.80       418\n",
      "\n",
      "[  2  18   0   0   0   0   0 188   0   0   0   0   0  16   7   0   0   0\n",
      "   0   6   0  59   0   0   0  15   0   0  83   0   0  16   0   0   0   8]\n",
      "MNB Accuracy:  0.8301435406698564\n",
      "MNB F1:  0.643064689082638\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        20\n",
      "          1       0.75      1.00      0.85       188\n",
      "          2       1.00      0.43      0.61        23\n",
      "          3       1.00      0.82      0.90        65\n",
      "          4       1.00      0.72      0.84        98\n",
      "          5       1.00      0.71      0.83        24\n",
      "\n",
      "avg / total       0.89      0.85      0.84       418\n",
      "\n",
      "[ 15   5   0   0   0   0   0 188   0   0   0   0   0  13  10   0   0   0\n",
      "   0  12   0  53   0   0   0  27   0   0  71   0   0   7   0   0   0  17]\n",
      "svc Accuracy:  0.84688995215311\n",
      "svc F1:  0.8142598302613567\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        20\n",
      "          1       0.65      1.00      0.79       188\n",
      "          2       1.00      0.17      0.30        23\n",
      "          3       1.00      0.66      0.80        65\n",
      "          4       1.00      0.68      0.81        98\n",
      "          5       1.00      0.38      0.55        24\n",
      "\n",
      "avg / total       0.84      0.76      0.74       418\n",
      "\n",
      "[  6  14   0   0   0   0   0 188   0   0   0   0   0  19   4   0   0   0\n",
      "   0  22   0  43   0   0   0  31   0   0  67   0   0  15   0   0   0   9]\n",
      "LR Accuracy:  0.7583732057416268\n",
      "LR F1:  0.6166611282963484\n",
      "For name:  c_murray\n",
      "total sample size before apply threshold:  112\n",
      "Counter({'0000-0002-0951-5700': 41, '0000-0001-6736-1546': 28, '0000-0002-2398-3914': 23, '0000-0002-5499-6857': 15, '0000-0003-4471-0509': 4, '0000-0002-4713-8475': 1})\n",
      "['0000-0001-6736-1546', '0000-0002-2398-3914', '0000-0002-5499-6857', '0000-0002-0951-5700']\n",
      "Total sample size after apply threshold:  107\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 296)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.50      0.65        28\n",
      "          1       1.00      0.78      0.88        23\n",
      "          2       1.00      0.20      0.33        15\n",
      "          3       0.56      0.98      0.71        41\n",
      "\n",
      "avg / total       0.82      0.70      0.68       107\n",
      "\n",
      "[14  0  0 14  0 18  0  5  0  0  3 12  1  0  0 40]\n",
      "MNB Accuracy:  0.7009345794392523\n",
      "MNB F1:  0.6442076547011317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.75      0.84        28\n",
      "          1       1.00      0.91      0.95        23\n",
      "          2       1.00      0.27      0.42        15\n",
      "          3       0.67      0.98      0.79        41\n",
      "\n",
      "avg / total       0.86      0.80      0.79       107\n",
      "\n",
      "[21  0  0  7  0 21  0  2  0  0  4 11  1  0  0 40]\n",
      "svc Accuracy:  0.8037383177570093\n",
      "svc F1:  0.7519193235112984\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        28\n",
      "          1       1.00      0.74      0.85        23\n",
      "          2       1.00      0.13      0.24        15\n",
      "          3       0.55      1.00      0.71        41\n",
      "\n",
      "avg / total       0.83      0.68      0.65       107\n",
      "\n",
      "[13  0  0 15  0 17  0  6  0  0  2 13  0  0  0 41]\n",
      "LR Accuracy:  0.6822429906542056\n",
      "LR F1:  0.6065842527086529\n",
      "For name:  m_grant\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-1380-2104': 28, '0000-0002-7838-8725': 9, '0000-0003-1003-4071': 1, '0000-0002-0377-2036': 1})\n",
      "['0000-0002-1380-2104']\n",
      "Total sample size after apply threshold:  28\n",
      "For name:  d_scott\n",
      "total sample size before apply threshold:  145\n",
      "Counter({'0000-0001-5226-1972': 65, '0000-0002-6726-2078': 64, '0000-0002-6878-9840': 10, '0000-0003-2230-0090': 2, '0000-0003-4918-2610': 2, '0000-0001-8560-0248': 1, '0000-0002-2592-1522': 1})\n",
      "['0000-0002-6726-2078', '0000-0001-5226-1972', '0000-0002-6878-9840']\n",
      "Total sample size after apply threshold:  139\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(139, 750)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.89      0.90        64\n",
      "          1       0.84      1.00      0.92        65\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.82      0.88      0.84       139\n",
      "\n",
      "[57  7  0  0 65  0  5  5  0]\n",
      "MNB Accuracy:  0.8776978417266187\n",
      "MNB F1:  0.6067516208361279\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        64\n",
      "          1       1.00      0.97      0.98        65\n",
      "          2       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.93      0.92      0.90       139\n",
      "\n",
      "[64  0  0  2 63  0  9  0  1]\n",
      "svc Accuracy:  0.920863309352518\n",
      "svc F1:  0.6956854970568999\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        64\n",
      "          1       1.00      0.97      0.98        65\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.86      0.91      0.88       139\n",
      "\n",
      "[64  0  0  2 63  0 10  0  0]\n",
      "LR Accuracy:  0.9136690647482014\n",
      "LR F1:  0.6328869047619047\n",
      "For name:  s_mohan\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0002-5305-9685': 43, '0000-0002-4797-9565': 4, '0000-0001-5628-2631': 2, '0000-0001-8980-0730': 1})\n",
      "['0000-0002-5305-9685']\n",
      "Total sample size after apply threshold:  43\n",
      "For name:  n_wong\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0003-3788-8114': 13, '0000-0002-7003-6020': 9, '0000-0003-4393-7541': 1, '0000-0002-5932-1015': 1})\n",
      "['0000-0003-3788-8114']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  k_anderson\n",
      "total sample size before apply threshold:  171\n",
      "Counter({'0000-0003-1657-2161': 78, '0000-0002-9324-9598': 44, '0000-0001-9843-404X': 22, '0000-0001-5613-5893': 14, '0000-0002-3289-2598': 6, '0000-0003-3927-8117': 4, '0000-0002-1472-3352': 2, '0000-0002-5458-6735': 1})\n",
      "['0000-0001-9843-404X', '0000-0002-9324-9598', '0000-0001-5613-5893', '0000-0003-1657-2161']\n",
      "Total sample size after apply threshold:  158\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(158, 453)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "158\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        22\n",
      "          1       1.00      0.70      0.83        44\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.67      1.00      0.80        78\n",
      "\n",
      "avg / total       0.75      0.75      0.71       158\n",
      "\n",
      "[10  0  0 12  0 31  0 13  0  0  0 14  0  0  0 78]\n",
      "MNB Accuracy:  0.7531645569620253\n",
      "MNB F1:  0.5629166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        22\n",
      "          1       1.00      0.68      0.81        44\n",
      "          2       1.00      0.71      0.83        14\n",
      "          3       0.76      1.00      0.86        78\n",
      "\n",
      "avg / total       0.88      0.84      0.84       158\n",
      "\n",
      "[15  0  0  7  0 30  0 14  0  0 10  4  0  0  0 78]\n",
      "svc Accuracy:  0.8417721518987342\n",
      "svc F1:  0.8292083519984073\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        22\n",
      "          1       1.00      0.55      0.71        44\n",
      "          2       1.00      0.07      0.13        14\n",
      "          3       0.62      1.00      0.76        78\n",
      "\n",
      "avg / total       0.81      0.70      0.65       158\n",
      "\n",
      "[ 7  0  0 15  0 24  0 20  0  0  1 13  0  0  0 78]\n",
      "LR Accuracy:  0.6962025316455697\n",
      "LR F1:  0.5216700473292766\n",
      "For name:  m_king\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-2587-9117': 26, '0000-0001-6030-5154': 13, '0000-0001-9895-7297': 9, '0000-0001-5611-9498': 7, '0000-0002-9558-8622': 2, '0000-0001-7993-8808': 1})\n",
      "['0000-0001-6030-5154', '0000-0002-2587-9117']\n",
      "Total sample size after apply threshold:  39\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 62)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       0.79      1.00      0.88        26\n",
      "\n",
      "avg / total       0.86      0.82      0.80        39\n",
      "\n",
      "[ 6  7  0 26]\n",
      "MNB Accuracy:  0.8205128205128205\n",
      "MNB F1:  0.7564674397859055\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        13\n",
      "          1       0.96      0.96      0.96        26\n",
      "\n",
      "avg / total       0.95      0.95      0.95        39\n",
      "\n",
      "[12  1  1 25]\n",
      "svc Accuracy:  0.9487179487179487\n",
      "svc F1:  0.9423076923076923\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       0.79      1.00      0.88        26\n",
      "\n",
      "avg / total       0.86      0.82      0.80        39\n",
      "\n",
      "[ 6  7  0 26]\n",
      "LR Accuracy:  0.8205128205128205\n",
      "LR F1:  0.7564674397859055\n",
      "For name:  a_srivastava\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0002-2031-4643': 14, '0000-0002-0211-7814': 13, '0000-0001-9866-8145': 6, '0000-0001-7042-4317': 5, '0000-0001-8340-856X': 3, '0000-0001-9871-5781': 3, '0000-0001-5345-6405': 2, '0000-0002-7046-405X': 1, '0000-0002-4590-7947': 1, '0000-0002-5295-7176': 1})\n",
      "['0000-0002-2031-4643', '0000-0002-0211-7814']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 105)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.87      1.00      0.93        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        27\n",
      "\n",
      "[12  2  0 13]\n",
      "MNB Accuracy:  0.9259259259259259\n",
      "MNB F1:  0.9258241758241759\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        14\n",
      "          1       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.97      0.96      0.96        27\n",
      "\n",
      "[14  0  1 12]\n",
      "svc Accuracy:  0.9629629629629629\n",
      "svc F1:  0.9627586206896552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        14\n",
      "          1       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.91      0.89      0.89        27\n",
      "\n",
      "[14  0  3 10]\n",
      "LR Accuracy:  0.8888888888888888\n",
      "LR F1:  0.8863955119214586\n",
      "For name:  m_scholz\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0001-8440-6785': 31, '0000-0002-4300-3020': 9, '0000-0001-9887-9831': 2})\n",
      "['0000-0001-8440-6785']\n",
      "Total sample size after apply threshold:  31\n",
      "For name:  y_ju\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0002-5120-6960': 14, '0000-0001-8325-1494': 9, '0000-0003-0103-1207': 3, '0000-0002-5514-4189': 1})\n",
      "['0000-0002-5120-6960']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  d_stanley\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0001-9806-5694': 4, '0000-0001-5992-8901': 1, '0000-0001-8948-8409': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_nogueira\n",
      "total sample size before apply threshold:  303\n",
      "Counter({'0000-0003-2950-3632': 279, '0000-0002-0853-5304': 16, '0000-0001-8464-0045': 4, '0000-0002-9152-754X': 4})\n",
      "['0000-0002-0853-5304', '0000-0003-2950-3632']\n",
      "Total sample size after apply threshold:  295\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 392)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.48        16\n",
      "          1       0.96      1.00      0.98       279\n",
      "\n",
      "avg / total       0.96      0.96      0.95       295\n",
      "\n",
      "[  5  11   0 279]\n",
      "MNB Accuracy:  0.9627118644067797\n",
      "MNB F1:  0.7284291572516528\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.48        16\n",
      "          1       0.96      1.00      0.98       279\n",
      "\n",
      "avg / total       0.96      0.96      0.95       295\n",
      "\n",
      "[  5  11   0 279]\n",
      "svc Accuracy:  0.9627118644067797\n",
      "svc F1:  0.7284291572516528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.95      1.00      0.97       279\n",
      "\n",
      "avg / total       0.89      0.95      0.92       295\n",
      "\n",
      "[  0  16   0 279]\n",
      "LR Accuracy:  0.9457627118644067\n",
      "LR F1:  0.48606271777003485\n",
      "For name:  j_cooper\n",
      "total sample size before apply threshold:  147\n",
      "Counter({'0000-0003-1339-4750': 85, '0000-0001-6009-3542': 24, '0000-0001-8163-2306': 19, '0000-0002-9014-4395': 14, '0000-0002-8626-7827': 4, '0000-0002-4932-1740': 1})\n",
      "['0000-0002-9014-4395', '0000-0001-6009-3542', '0000-0001-8163-2306', '0000-0003-1339-4750']\n",
      "Total sample size after apply threshold:  142\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 549)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "142\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       1.00      0.50      0.67        24\n",
      "          2       1.00      0.37      0.54        19\n",
      "          3       0.69      1.00      0.82        85\n",
      "\n",
      "avg / total       0.72      0.73      0.67       142\n",
      "\n",
      "[ 0  0  0 14  0 12  0 12  0  0  7 12  0  0  0 85]\n",
      "MNB Accuracy:  0.7323943661971831\n",
      "MNB F1:  0.5056089743589743\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        14\n",
      "          1       1.00      0.75      0.86        24\n",
      "          2       1.00      0.63      0.77        19\n",
      "          3       0.79      1.00      0.89        85\n",
      "\n",
      "avg / total       0.88      0.85      0.83       142\n",
      "\n",
      "[ 5  0  0  9  0 18  0  6  0  0 12  7  0  0  0 85]\n",
      "svc Accuracy:  0.8450704225352113\n",
      "svc F1:  0.7607672154175761\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       1.00      0.33      0.50        24\n",
      "          2       1.00      0.21      0.35        19\n",
      "          3       0.65      1.00      0.79        85\n",
      "\n",
      "avg / total       0.69      0.68      0.60       142\n",
      "\n",
      "[ 0  0  0 14  0  8  0 16  0  0  4 15  0  0  0 85]\n",
      "LR Accuracy:  0.6830985915492958\n",
      "LR F1:  0.4096309403437816\n",
      "For name:  k_lau\n",
      "total sample size before apply threshold:  121\n",
      "Counter({'0000-0003-2125-6841': 81, '0000-0003-3676-9228': 18, '0000-0001-8438-0319': 17, '0000-0002-7713-1928': 4, '0000-0003-2197-5539': 1})\n",
      "['0000-0001-8438-0319', '0000-0003-2125-6841', '0000-0003-3676-9228']\n",
      "Total sample size after apply threshold:  116\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(116, 242)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.38        17\n",
      "          1       0.76      1.00      0.86        81\n",
      "          2       1.00      0.28      0.43        18\n",
      "\n",
      "avg / total       0.83      0.78      0.73       116\n",
      "\n",
      "[ 4 13  0  0 81  0  0 13  5]\n",
      "MNB Accuracy:  0.7758620689655172\n",
      "MNB F1:  0.5591457057692025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        17\n",
      "          1       0.91      1.00      0.95        81\n",
      "          2       1.00      0.83      0.91        18\n",
      "\n",
      "avg / total       0.94      0.93      0.93       116\n",
      "\n",
      "[12  5  0  0 81  0  0  3 15]\n",
      "svc Accuracy:  0.9310344827586207\n",
      "svc F1:  0.8965394308193497\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.11        17\n",
      "          1       0.72      1.00      0.84        81\n",
      "          2       1.00      0.17      0.29        18\n",
      "\n",
      "avg / total       0.81      0.73      0.65       116\n",
      "\n",
      "[ 1 16  0  0 81  0  0 15  3]\n",
      "LR Accuracy:  0.7327586206896551\n",
      "LR F1:  0.412067878389122\n",
      "For name:  s_hussein\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0002-7946-0717': 18, '0000-0002-6305-508X': 9, '0000-0003-3657-7410': 4, '0000-0002-5394-4385': 1, '0000-0002-0139-1483': 1})\n",
      "['0000-0002-7946-0717']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  z_luo\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-3074-046X': 15, '0000-0002-2719-1025': 5, '0000-0002-8129-333X': 3, '0000-0003-0164-4492': 2})\n",
      "['0000-0002-3074-046X']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  c_pimentel\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0002-5158-6414': 16, '0000-0002-1106-8962': 3, '0000-0002-8364-8990': 2, '0000-0002-4932-0174': 1})\n",
      "['0000-0002-5158-6414']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  s_ito\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0003-1776-4608': 22, '0000-0001-9310-1852': 18, '0000-0003-1108-1371': 14, '0000-0002-0268-013X': 4, '0000-0002-3635-2580': 1})\n",
      "['0000-0001-9310-1852', '0000-0003-1108-1371', '0000-0003-1776-4608']\n",
      "Total sample size after apply threshold:  54\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 134)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       1.00      1.00      1.00        54\n",
      "\n",
      "[18  0  0  0 14  0  0  0 22]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       1.00      1.00      1.00        54\n",
      "\n",
      "[18  0  0  0 14  0  0  0 22]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       1.00      1.00      1.00        54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[18  0  0  0 14  0  0  0 22]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  f_zhang\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0001-6035-4829': 27, '0000-0001-7434-7339': 23, '0000-0002-0480-7501': 11, '0000-0001-9542-6634': 10, '0000-0003-1298-9795': 9, '0000-0002-1371-266X': 7, '0000-0002-1957-0543': 5, '0000-0002-2822-2049': 4, '0000-0002-9309-9577': 2, '0000-0003-1709-7788': 2, '0000-0001-7550-9483': 1, '0000-0002-8438-7155': 1, '0000-0003-2829-0735': 1})\n",
      "['0000-0001-7434-7339', '0000-0002-0480-7501', '0000-0001-6035-4829', '0000-0001-9542-6634']\n",
      "Total sample size after apply threshold:  71\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 158)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        23\n",
      "          1       1.00      0.64      0.78        11\n",
      "          2       0.80      0.89      0.84        27\n",
      "          3       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.85      0.82      0.80        71\n",
      "\n",
      "[23  0  0  0  3  7  1  0  3  0 24  0  1  0  5  4]\n",
      "MNB Accuracy:  0.8169014084507042\n",
      "MNB F1:  0.7648090351665328\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        23\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       0.90      0.96      0.93        27\n",
      "          3       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.95      0.94      0.94        71\n",
      "\n",
      "[23  0  0  0  0 11  0  0  1  0 26  0  0  0  3  7]\n",
      "svc Accuracy:  0.9436619718309859\n",
      "svc F1:  0.9327060611478633\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        23\n",
      "          1       1.00      0.91      0.95        11\n",
      "          2       0.79      0.96      0.87        27\n",
      "          3       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.91      0.89      0.87        71\n",
      "\n",
      "[23  0  0  0  0 10  1  0  1  0 26  0  0  0  6  4]\n",
      "LR Accuracy:  0.8873239436619719\n",
      "LR F1:  0.8422998986828775\n",
      "For name:  s_chapman\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0003-3347-6024': 23, '0000-0003-0053-1584': 23, '0000-0002-4314-9193': 15, '0000-0003-0778-084X': 7, '0000-0003-2342-3383': 3})\n",
      "['0000-0003-3347-6024', '0000-0003-0053-1584', '0000-0002-4314-9193']\n",
      "Total sample size after apply threshold:  61\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 128)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.91      0.93        23\n",
      "          1       0.85      1.00      0.92        23\n",
      "          2       1.00      0.80      0.89        15\n",
      "\n",
      "avg / total       0.93      0.92      0.92        61\n",
      "\n",
      "[21  2  0  0 23  0  1  2 12]\n",
      "MNB Accuracy:  0.9180327868852459\n",
      "MNB F1:  0.9140740740740741\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        23\n",
      "          1       0.88      1.00      0.94        23\n",
      "          2       1.00      0.80      0.89        15\n",
      "\n",
      "avg / total       0.92      0.92      0.92        61\n",
      "\n",
      "[21  2  0  0 23  0  2  1 12]\n",
      "svc Accuracy:  0.9180327868852459\n",
      "svc F1:  0.9135692924512799\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.89        23\n",
      "          1       0.85      1.00      0.92        23\n",
      "          2       1.00      0.67      0.80        15\n",
      "\n",
      "avg / total       0.90      0.89      0.88        61\n",
      "\n",
      "[21  2  0  0 23  0  3  2 10]\n",
      "LR Accuracy:  0.8852459016393442\n",
      "LR F1:  0.8712056737588654\n",
      "For name:  j_rosa\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0003-0857-3746': 15, '0000-0001-7770-5381': 7, '0000-0002-7154-2494': 4, '0000-0001-7947-2681': 2, '0000-0002-0015-6254': 1})\n",
      "['0000-0003-0857-3746']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  y_yin\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0003-0218-3042': 127, '0000-0003-1077-810X': 8, '0000-0003-3514-5712': 5, '0000-0003-0963-2672': 5, '0000-0003-0965-4951': 4, '0000-0002-8685-4378': 2, '0000-0001-5821-7497': 1})\n",
      "['0000-0003-0218-3042']\n",
      "Total sample size after apply threshold:  127\n",
      "For name:  p_tavares\n",
      "total sample size before apply threshold:  53\n",
      "Counter({'0000-0002-7398-2661': 29, '0000-0001-7589-1299': 13, '0000-0002-2287-2446': 8, '0000-0001-7832-4134': 3})\n",
      "['0000-0001-7589-1299', '0000-0002-7398-2661']\n",
      "Total sample size after apply threshold:  42\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 144)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.56        13\n",
      "          1       0.78      1.00      0.88        29\n",
      "\n",
      "avg / total       0.85      0.81      0.78        42\n",
      "\n",
      "[ 5  8  0 29]\n",
      "MNB Accuracy:  0.8095238095238095\n",
      "MNB F1:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7171717171717171\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.97      1.00      0.98        29\n",
      "\n",
      "avg / total       0.98      0.98      0.98        42\n",
      "\n",
      "[12  1  0 29]\n",
      "svc Accuracy:  0.9761904761904762\n",
      "svc F1:  0.9715254237288136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.14        13\n",
      "          1       0.71      1.00      0.83        29\n",
      "\n",
      "avg / total       0.80      0.71      0.62        42\n",
      "\n",
      "[ 1 12  0 29]\n",
      "LR Accuracy:  0.7142857142857143\n",
      "LR F1:  0.4857142857142857\n",
      "For name:  a_palma\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0003-2099-1297': 34, '0000-0002-8530-4913': 13, '0000-0002-5971-3676': 8, '0000-0003-0420-1785': 3, '0000-0002-1682-7032': 2, '0000-0002-7263-4868': 1})\n",
      "['0000-0002-8530-4913', '0000-0003-2099-1297']\n",
      "Total sample size after apply threshold:  47\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 71)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        34\n",
      "\n",
      "avg / total       1.00      1.00      1.00        47\n",
      "\n",
      "[13  0  0 34]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        34\n",
      "\n",
      "avg / total       1.00      1.00      1.00        47\n",
      "\n",
      "[13  0  0 34]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.97      1.00      0.99        34\n",
      "\n",
      "avg / total       0.98      0.98      0.98        47\n",
      "\n",
      "[12  1  0 34]\n",
      "LR Accuracy:  0.9787234042553191\n",
      "LR F1:  0.9727536231884057\n",
      "For name:  e_shaw\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0003-1424-7568': 9, '0000-0002-5653-0145': 4, '0000-0002-4148-3526': 2, '0000-0002-4334-1900': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_cameron\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0001-5788-8790': 17, '0000-0002-2277-7035': 9, '0000-0001-9464-8796': 1, '0000-0002-2508-7718': 1})\n",
      "['0000-0001-5788-8790']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  a_reid\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-0523-926X': 18, '0000-0003-1752-3302': 18, '0000-0003-4713-2951': 6, '0000-0002-2500-2980': 2})\n",
      "['0000-0002-0523-926X', '0000-0003-1752-3302']\n",
      "Total sample size after apply threshold:  36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 101)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        18\n",
      "          1       1.00      0.94      0.97        18\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[18  0  1 17]\n",
      "MNB Accuracy:  0.9722222222222222\n",
      "MNB F1:  0.9722007722007722\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.94      0.89        18\n",
      "          1       0.94      0.83      0.88        18\n",
      "\n",
      "avg / total       0.89      0.89      0.89        36\n",
      "\n",
      "[17  1  3 15]\n",
      "svc Accuracy:  0.8888888888888888\n",
      "svc F1:  0.8885448916408669\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        18\n",
      "          1       1.00      0.78      0.88        18\n",
      "\n",
      "avg / total       0.91      0.89      0.89        36\n",
      "\n",
      "[18  0  4 14]\n",
      "LR Accuracy:  0.8888888888888888\n",
      "LR F1:  0.8875000000000001\n",
      "For name:  d_gil\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0003-3179-1987': 23, '0000-0002-2770-4767': 16, '0000-0003-4241-1302': 16, '0000-0001-8910-2780': 4, '0000-0003-0791-8298': 1})\n",
      "['0000-0002-2770-4767', '0000-0003-3179-1987', '0000-0003-4241-1302']\n",
      "Total sample size after apply threshold:  55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 176)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.79      1.00      0.88        23\n",
      "          2       1.00      0.81      0.90        16\n",
      "\n",
      "avg / total       0.91      0.89      0.89        55\n",
      "\n",
      "[13  3  0  0 23  0  0  3 13]\n",
      "MNB Accuracy:  0.8909090909090909\n",
      "MNB F1:  0.8925729442970822\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.85      1.00      0.92        23\n",
      "          2       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.94      0.93      0.93        55\n",
      "\n",
      "[13  3  0  0 23  0  0  1 15]\n",
      "svc Accuracy:  0.9272727272727272\n",
      "svc F1:  0.9280978865406007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.77      1.00      0.87        23\n",
      "          2       1.00      0.75      0.86        16\n",
      "\n",
      "avg / total       0.90      0.87      0.87        55\n",
      "\n",
      "[13  3  0  0 23  0  0  4 12]\n",
      "LR Accuracy:  0.8727272727272727\n",
      "LR F1:  0.8738730365275584\n",
      "For name:  s_morgan\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0003-4069-3801': 38, '0000-0001-5091-3148': 28, '0000-0002-5340-0652': 7, '0000-0001-9528-8323': 4, '0000-0002-1734-4710': 2, '0000-0002-7529-0028': 2, '0000-0001-7601-3551': 1, '0000-0001-7610-4496': 1})\n",
      "['0000-0003-4069-3801', '0000-0001-5091-3148']\n",
      "Total sample size after apply threshold:  66\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 136)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        38\n",
      "          1       1.00      0.96      0.98        28\n",
      "\n",
      "avg / total       0.99      0.98      0.98        66\n",
      "\n",
      "[38  0  1 27]\n",
      "MNB Accuracy:  0.9848484848484849\n",
      "MNB F1:  0.9844155844155844\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        38\n",
      "          1       1.00      0.96      0.98        28\n",
      "\n",
      "avg / total       0.99      0.98      0.98        66\n",
      "\n",
      "[38  0  1 27]\n",
      "svc Accuracy:  0.9848484848484849\n",
      "svc F1:  0.9844155844155844\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        38\n",
      "          1       1.00      0.79      0.88        28\n",
      "\n",
      "avg / total       0.92      0.91      0.91        66\n",
      "\n",
      "[38  0  6 22]\n",
      "LR Accuracy:  0.9090909090909091\n",
      "LR F1:  0.9034146341463414\n",
      "For name:  p_ross\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0001-7105-7117': 14, '0000-0002-5051-5382': 10, '0000-0001-7984-6452': 2, '0000-0001-7645-7523': 1})\n",
      "['0000-0002-5051-5382', '0000-0001-7105-7117']\n",
      "Total sample size after apply threshold:  24\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 92)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.60      0.71        10\n",
      "          1       0.76      0.93      0.84        14\n",
      "\n",
      "avg / total       0.80      0.79      0.78        24\n",
      "\n",
      "[ 6  4  1 13]\n",
      "MNB Accuracy:  0.7916666666666666\n",
      "MNB F1:  0.7722960151802656\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.78      1.00      0.88        14\n",
      "\n",
      "avg / total       0.87      0.83      0.82        24\n",
      "\n",
      "[ 6  4  0 14]\n",
      "svc Accuracy:  0.8333333333333334\n",
      "svc F1:  0.8125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.74      1.00      0.85        14\n",
      "\n",
      "avg / total       0.85      0.79      0.77        24\n",
      "\n",
      "[ 5  5  0 14]\n",
      "LR Accuracy:  0.7916666666666666\n",
      "LR F1:  0.7575757575757576\n",
      "For name:  l_simon\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0003-4321-8539': 7, '0000-0003-4870-1052': 4, '0000-0002-5010-4778': 2, '0000-0002-0148-4217': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  k_thomas\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0003-3436-2184': 23, '0000-0003-3355-9583': 23, '0000-0001-8152-9974': 6, '0000-0003-2980-2384': 5, '0000-0001-8836-4631': 3})\n",
      "['0000-0003-3436-2184', '0000-0003-3355-9583']\n",
      "Total sample size after apply threshold:  46\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 66)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        23\n",
      "          1       0.96      0.96      0.96        23\n",
      "\n",
      "avg / total       0.96      0.96      0.96        46\n",
      "\n",
      "[22  1  1 22]\n",
      "MNB Accuracy:  0.9565217391304348\n",
      "MNB F1:  0.9565217391304348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        23\n",
      "          1       0.92      1.00      0.96        23\n",
      "\n",
      "avg / total       0.96      0.96      0.96        46\n",
      "\n",
      "[21  2  0 23]\n",
      "svc Accuracy:  0.9565217391304348\n",
      "svc F1:  0.9564393939393939\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        23\n",
      "          1       0.92      1.00      0.96        23\n",
      "\n",
      "avg / total       0.96      0.96      0.96        46\n",
      "\n",
      "[21  2  0 23]\n",
      "LR Accuracy:  0.9565217391304348\n",
      "LR F1:  0.9564393939393939\n",
      "For name:  l_torres\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0002-0194-7875': 56, '0000-0002-4598-1899': 7, '0000-0002-2512-1074': 1, '0000-0001-9945-7331': 1})\n",
      "['0000-0002-0194-7875']\n",
      "Total sample size after apply threshold:  56\n",
      "For name:  p_ding\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-3535-6053': 8, '0000-0003-2559-4696': 8, '0000-0002-2613-2496': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  g_morris\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0003-1731-8405': 50, '0000-0003-2588-6349': 23, '0000-0002-1097-4453': 19, '0000-0001-9893-6648': 16, '0000-0002-3067-3359': 15, '0000-0003-2892-8428': 5})\n",
      "['0000-0001-9893-6648', '0000-0003-2588-6349', '0000-0002-1097-4453', '0000-0002-3067-3359', '0000-0003-1731-8405']\n",
      "Total sample size after apply threshold:  123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(123, 377)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.56      0.72        16\n",
      "          1       1.00      0.57      0.72        23\n",
      "          2       1.00      0.47      0.64        19\n",
      "          3       1.00      0.27      0.42        15\n",
      "          4       0.57      1.00      0.72        50\n",
      "\n",
      "avg / total       0.82      0.69      0.67       123\n",
      "\n",
      "[ 9  0  0  0  7  0 13  0  0 10  0  0  9  0 10  0  0  0  4 11  0  0  0  0\n",
      " 50]\n",
      "MNB Accuracy:  0.6910569105691057\n",
      "MNB F1:  0.6461539355635465\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        16\n",
      "          1       1.00      0.61      0.76        23\n",
      "          2       1.00      0.74      0.85        19\n",
      "          3       1.00      0.53      0.70        15\n",
      "          4       0.65      1.00      0.79        50\n",
      "\n",
      "avg / total       0.86      0.78      0.78       123\n",
      "\n",
      "[10  0  0  0  6  0 14  0  0  9  0  0 14  0  5  0  0  0  8  7  0  0  0  0\n",
      " 50]\n",
      "svc Accuracy:  0.7804878048780488\n",
      "svc F1:  0.7715052246377135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.44      0.61        16\n",
      "          1       1.00      0.48      0.65        23\n",
      "          2       1.00      0.47      0.64        19\n",
      "          3       1.00      0.27      0.42        15\n",
      "          4       0.54      1.00      0.70        50\n",
      "\n",
      "avg / total       0.81      0.66      0.64       123\n",
      "\n",
      "[ 7  0  0  0  9  0 11  0  0 12  0  0  9  0 10  0  0  0  4 11  0  0  0  0\n",
      " 50]\n",
      "LR Accuracy:  0.6585365853658537\n",
      "LR F1:  0.6047779204504182\n",
      "For name:  s_andrews\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0003-4295-2686': 46, '0000-0002-2103-7748': 6, '0000-0002-3851-2197': 3, '0000-0003-0878-1182': 2, '0000-0002-5499-5125': 1, '0000-0003-2174-6728': 1, '0000-0003-4997-3906': 1})\n",
      "['0000-0003-4295-2686']\n",
      "Total sample size after apply threshold:  46\n",
      "For name:  b_yan\n",
      "total sample size before apply threshold:  129\n",
      "Counter({'0000-0001-8802-9606': 93, '0000-0003-4268-4757': 21, '0000-0003-3509-0686': 10, '0000-0001-7235-5554': 4, '0000-0003-2258-2817': 1})\n",
      "['0000-0003-4268-4757', '0000-0001-8802-9606', '0000-0003-3509-0686']\n",
      "Total sample size after apply threshold:  124\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(124, 363)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "124\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        21\n",
      "          1       0.88      1.00      0.93        93\n",
      "          2       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.91      0.90      0.87       124\n",
      "\n",
      "[17  4  0  0 93  0  0  9  1]\n",
      "MNB Accuracy:  0.8951612903225806\n",
      "MNB F1:  0.6704094635858718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        21\n",
      "          1       1.00      1.00      1.00        93\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00       124\n",
      "\n",
      "[21  0  0  0 93  0  0  0 10]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        21\n",
      "          1       0.82      1.00      0.90        93\n",
      "          2       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.87      0.84      0.81       124\n",
      "\n",
      "[ 9 12  0  0 93  0  0  8  2]\n",
      "LR Accuracy:  0.8387096774193549\n",
      "LR F1:  0.6120819848975189\n",
      "For name:  r_hu\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0001-6709-031X': 93, '0000-0001-7412-8451': 27, '0000-0001-6893-529X': 4, '0000-0001-5549-3082': 2, '0000-0002-7126-4076': 1, '0000-0001-5921-6891': 1})\n",
      "['0000-0001-6709-031X', '0000-0001-7412-8451']\n",
      "Total sample size after apply threshold:  120\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(120, 106)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "120\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99        93\n",
      "          1       1.00      0.96      0.98        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99       120\n",
      "\n",
      "[93  0  1 26]\n",
      "MNB Accuracy:  0.9916666666666667\n",
      "MNB F1:  0.9878922409444052\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        93\n",
      "          1       1.00      1.00      1.00        27\n",
      "\n",
      "avg / total       1.00      1.00      1.00       120\n",
      "\n",
      "[93  0  0 27]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        93\n",
      "          1       1.00      0.81      0.90        27\n",
      "\n",
      "avg / total       0.96      0.96      0.96       120\n",
      "\n",
      "[93  0  5 22]\n",
      "LR Accuracy:  0.9583333333333334\n",
      "LR F1:  0.9358905866011326\n",
      "For name:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j_braun\n",
      "total sample size before apply threshold:  72\n",
      "Counter({'0000-0002-8886-078X': 37, '0000-0002-4504-6235': 25, '0000-0002-8309-6401': 5, '0000-0002-2491-5788': 5})\n",
      "['0000-0002-8886-078X', '0000-0002-4504-6235']\n",
      "Total sample size after apply threshold:  62\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 157)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        37\n",
      "          1       1.00      0.80      0.89        25\n",
      "\n",
      "avg / total       0.93      0.92      0.92        62\n",
      "\n",
      "[37  0  5 20]\n",
      "MNB Accuracy:  0.9193548387096774\n",
      "MNB F1:  0.9127988748241913\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        37\n",
      "          1       1.00      0.84      0.91        25\n",
      "\n",
      "avg / total       0.94      0.94      0.93        62\n",
      "\n",
      "[37  0  4 21]\n",
      "svc Accuracy:  0.9354838709677419\n",
      "svc F1:  0.9308807134894093\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        37\n",
      "          1       1.00      0.64      0.78        25\n",
      "\n",
      "avg / total       0.88      0.85      0.85        62\n",
      "\n",
      "[37  0  9 16]\n",
      "LR Accuracy:  0.8548387096774194\n",
      "LR F1:  0.8360270349691448\n",
      "For name:  c_he\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0002-4868-331X': 20, '0000-0002-1918-5186': 13, '0000-0002-0663-275X': 7, '0000-0001-7869-7627': 5, '0000-0001-5426-769X': 2, '0000-0001-9867-9629': 1, '0000-0001-5842-9617': 1})\n",
      "['0000-0002-4868-331X', '0000-0002-1918-5186']\n",
      "Total sample size after apply threshold:  33\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 163)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        20\n",
      "          1       0.92      0.92      0.92        13\n",
      "\n",
      "avg / total       0.94      0.94      0.94        33\n",
      "\n",
      "[19  1  1 12]\n",
      "MNB Accuracy:  0.9393939393939394\n",
      "MNB F1:  0.9365384615384615\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        20\n",
      "          1       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.94      0.94      0.94        33\n",
      "\n",
      "[20  0  2 11]\n",
      "svc Accuracy:  0.9393939393939394\n",
      "svc F1:  0.9345238095238095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        20\n",
      "          1       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.90      0.88      0.87        33\n",
      "\n",
      "[20  0  4  9]\n",
      "LR Accuracy:  0.8787878787878788\n",
      "LR F1:  0.8636363636363635\n",
      "For name:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_lu\n",
      "total sample size before apply threshold:  138\n",
      "Counter({'0000-0003-4731-1976': 38, '0000-0001-6722-1527': 33, '0000-0001-5358-305X': 30, '0000-0001-7421-347X': 13, '0000-0002-1405-4806': 6, '0000-0001-9798-8964': 4, '0000-0003-4334-5722': 3, '0000-0002-6570-3044': 3, '0000-0002-5243-5554': 2, '0000-0001-5508-342X': 2, '0000-0002-1398-9933': 1, '0000-0001-6214-4024': 1, '0000-0002-5101-9778': 1, '0000-0002-4528-2246': 1})\n",
      "['0000-0001-5358-305X', '0000-0003-4731-1976', '0000-0001-7421-347X', '0000-0001-6722-1527']\n",
      "Total sample size after apply threshold:  114\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 152)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "114\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94        30\n",
      "          1       0.94      0.89      0.92        38\n",
      "          2       1.00      0.46      0.63        13\n",
      "          3       0.80      0.97      0.88        33\n",
      "\n",
      "avg / total       0.90      0.89      0.88       114\n",
      "\n",
      "[29  0  0  1  3 34  0  1  0  1  6  6  0  1  0 32]\n",
      "MNB Accuracy:  0.8859649122807017\n",
      "MNB F1:  0.8406735165055512\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        30\n",
      "          1       0.88      1.00      0.94        38\n",
      "          2       0.92      0.85      0.88        13\n",
      "          3       1.00      0.97      0.98        33\n",
      "\n",
      "avg / total       0.95      0.95      0.95       114\n",
      "\n",
      "[27  2  1  0  0 38  0  0  0  2 11  0  0  1  0 32]\n",
      "svc Accuracy:  0.9473684210526315\n",
      "svc F1:  0.9375638526515719\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.90      0.93        30\n",
      "          1       0.86      0.95      0.90        38\n",
      "          2       1.00      0.85      0.92        13\n",
      "          3       0.94      0.94      0.94        33\n",
      "\n",
      "avg / total       0.93      0.92      0.92       114\n",
      "\n",
      "[27  2  0  1  1 36  0  1  0  2 11  0  0  2  0 31]\n",
      "LR Accuracy:  0.9210526315789473\n",
      "LR F1:  0.9217737722048067\n",
      "For name:  r_radhakrishnan\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0003-0088-4777': 35, '0000-0002-8220-655X': 14, '0000-0001-6616-8525': 7, '0000-0001-7170-699X': 5, '0000-0002-3560-1020': 1})\n",
      "['0000-0003-0088-4777', '0000-0002-8220-655X']\n",
      "Total sample size after apply threshold:  49\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 119)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90        35\n",
      "          1       1.00      0.43      0.60        14\n",
      "\n",
      "avg / total       0.87      0.84      0.81        49\n",
      "\n",
      "[35  0  8  6]\n",
      "MNB Accuracy:  0.8367346938775511\n",
      "MNB F1:  0.7487179487179487\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93        35\n",
      "          1       1.00      0.64      0.78        14\n",
      "\n",
      "avg / total       0.91      0.90      0.89        49\n",
      "\n",
      "[35  0  5  9]\n",
      "svc Accuracy:  0.8979591836734694\n",
      "svc F1:  0.8579710144927537\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        35\n",
      "          1       1.00      0.29      0.44        14\n",
      "\n",
      "avg / total       0.84      0.80      0.75        49\n",
      "\n",
      "[35  0 10  4]\n",
      "LR Accuracy:  0.7959183673469388\n",
      "LR F1:  0.6597222222222223\n",
      "For name:  k_saito\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0003-4663-1134': 26, '0000-0002-2151-6204': 16, '0000-0002-5726-8775': 11, '0000-0003-2557-1726': 7, '0000-0001-6310-5342': 1})\n",
      "['0000-0002-2151-6204', '0000-0003-4663-1134', '0000-0002-5726-8775']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 189)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.70      1.00      0.83        26\n",
      "          2       1.00      0.27      0.43        11\n",
      "\n",
      "avg / total       0.85      0.79      0.76        53\n",
      "\n",
      "[13  3  0  0 26  0  0  8  3]\n",
      "MNB Accuracy:  0.7924528301886793\n",
      "MNB F1:  0.7168399927020617\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.81      1.00      0.90        26\n",
      "          2       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.91      0.89      0.88        53\n",
      "\n",
      "[14  2  0  0 26  0  0  4  7]\n",
      "svc Accuracy:  0.8867924528301887\n",
      "svc F1:  0.8692209450830141\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        16\n",
      "          1       0.62      1.00      0.76        26\n",
      "          2       1.00      0.09      0.17        11\n",
      "\n",
      "avg / total       0.81      0.70      0.64        53\n",
      "\n",
      "[10  6  0  0 26  0  0 10  1]\n",
      "LR Accuracy:  0.6981132075471698\n",
      "LR F1:  0.5668677727501258\n",
      "For name:  y_wang\n",
      "total sample size before apply threshold:  1689\n",
      "Counter({'0000-0001-8592-0698': 121, '0000-0003-0852-0767': 117, '0000-0002-6227-6112': 69, '0000-0001-5803-5343': 60, '0000-0002-1211-2822': 57, '0000-0002-3063-3066': 55, '0000-0003-2067-382X': 54, '0000-0003-0773-1212': 42, '0000-0002-6574-6706': 40, '0000-0001-9574-2194': 37, '0000-0001-5764-6740': 35, '0000-0001-6046-2934': 31, '0000-0001-8043-5757': 31, '0000-0003-2533-865X': 31, '0000-0001-8619-0455': 30, '0000-0003-0764-2279': 30, '0000-0002-9893-8296': 29, '0000-0001-7076-8312': 29, '0000-0001-5291-9826': 28, '0000-0002-0921-0122': 27, '0000-0003-3557-5085': 26, '0000-0002-0474-4790': 25, '0000-0003-2540-2199': 24, '0000-0003-0513-9039': 22, '0000-0003-3011-1919': 18, '0000-0002-1241-6252': 17, '0000-0002-5845-5150': 17, '0000-0001-9753-5535': 16, '0000-0003-0961-1716': 16, '0000-0001-6321-9542': 15, '0000-0002-0768-1676': 15, '0000-0002-7851-1623': 14, '0000-0003-1360-8931': 14, '0000-0001-7042-9804': 14, '0000-0002-5985-5244': 13, '0000-0001-5716-3183': 13, '0000-0002-7243-441X': 13, '0000-0002-0363-926X': 13, '0000-0001-6790-1311': 12, '0000-0003-0266-0224': 12, '0000-0001-8440-9388': 12, '0000-0002-2110-623X': 11, '0000-0002-2626-478X': 11, '0000-0001-8021-5180': 11, '0000-0001-8697-9165': 11, '0000-0002-1786-5970': 11, '0000-0003-0144-1388': 11, '0000-0002-3002-8069': 10, '0000-0002-6822-4778': 9, '0000-0002-9659-977X': 9, '0000-0002-8601-8302': 9, '0000-0001-9032-9990': 9, '0000-0002-1851-3483': 9, '0000-0002-1255-0937': 9, '0000-0002-7209-585X': 9, '0000-0002-5111-1443': 9, '0000-0002-6295-6492': 8, '0000-0002-4847-6273': 8, '0000-0002-0002-2467': 8, '0000-0002-7389-5066': 8, '0000-0003-2561-1855': 7, '0000-0003-1286-2401': 7, '0000-0002-2900-5126': 7, '0000-0003-3594-2658': 7, '0000-0003-4816-9182': 6, '0000-0001-5580-7766': 6, '0000-0002-0582-0855': 6, '0000-0002-3034-7377': 6, '0000-0002-2188-383X': 6, '0000-0003-1567-3358': 6, '0000-0001-5020-2020': 6, '0000-0001-9997-7636': 5, '0000-0002-6401-7464': 5, '0000-0003-3620-8455': 5, '0000-0002-2532-4832': 5, '0000-0002-3823-2136': 5, '0000-0002-5300-7121': 4, '0000-0002-7986-4500': 4, '0000-0003-3430-2210': 4, '0000-0002-3769-0020': 4, '0000-0001-8925-5277': 4, '0000-0001-6232-0382': 4, '0000-0003-2763-1008': 3, '0000-0001-5231-6283': 3, '0000-0003-3222-0211': 3, '0000-0002-5590-5881': 3, '0000-0002-3729-2743': 3, '0000-0002-1769-1966': 3, '0000-0003-1786-5767': 3, '0000-0003-0708-1950': 2, '0000-0002-1609-2523': 2, '0000-0001-8518-6745': 2, '0000-0001-5495-5839': 2, '0000-0003-1681-9566': 2, '0000-0001-9474-6396': 2, '0000-0001-6108-5157': 2, '0000-0001-5500-1228': 2, '0000-0002-8648-2172': 2, '0000-0002-3184-4201': 2, '0000-0003-3432-0603': 2, '0000-0002-8937-3000': 2, '0000-0002-0676-5886': 2, '0000-0003-1154-820X': 2, '0000-0002-5223-4074': 2, '0000-0001-6264-650X': 2, '0000-0002-6066-2634': 2, '0000-0003-1404-8526': 2, '0000-0003-3928-6926': 2, '0000-0002-5399-2803': 2, '0000-0002-1288-8997': 2, '0000-0001-6085-5615': 2, '0000-0002-3656-4284': 2, '0000-0002-5187-3755': 2, '0000-0002-9628-1382': 2, '0000-0002-2244-1742': 2, '0000-0003-1009-2087': 1, '0000-0001-6823-1225': 1, '0000-0002-5692-3117': 1, '0000-0001-6981-7797': 1, '0000-0001-7956-3102': 1, '0000-0002-2657-7057': 1, '0000-0002-2665-0365': 1, '0000-0002-4336-0474': 1, '0000-0002-7629-4178': 1, '0000-0001-5918-7525': 1, '0000-0002-0891-1517': 1, '0000-0002-9684-1730': 1, '0000-0002-2932-6042': 1, '0000-0001-8538-5998': 1, '0000-0002-4506-4230': 1, '0000-0003-3120-827X': 1, '0000-0002-9640-0871': 1, '0000-0003-3511-0288': 1, '0000-0001-9156-0377': 1, '0000-0002-7281-1908': 1, '0000-0003-2540-5824': 1, '0000-0002-9365-1851': 1, '0000-0002-2333-157X': 1})\n",
      "['0000-0002-0474-4790', '0000-0001-6790-1311', '0000-0002-2110-623X', '0000-0001-5291-9826', '0000-0002-7851-1623', '0000-0002-1241-6252', '0000-0001-5764-6740', '0000-0001-6046-2934', '0000-0002-0921-0122', '0000-0003-0266-0224', '0000-0002-5985-5244', '0000-0003-1360-8931', '0000-0002-9893-8296', '0000-0002-2626-478X', '0000-0001-8021-5180', '0000-0002-5845-5150', '0000-0003-2540-2199', '0000-0001-8619-0455', '0000-0001-6321-9542', '0000-0003-0513-9039', '0000-0002-1211-2822', '0000-0001-8697-9165', '0000-0002-3063-3066', '0000-0001-5716-3183', '0000-0001-8043-5757', '0000-0002-3002-8069', '0000-0001-7076-8312', '0000-0001-9753-5535', '0000-0003-0961-1716', '0000-0001-8592-0698', '0000-0003-0852-0767', '0000-0002-1786-5970', '0000-0003-0764-2279', '0000-0001-5803-5343', '0000-0002-7243-441X', '0000-0003-2067-382X', '0000-0001-7042-9804', '0000-0002-0768-1676', '0000-0002-0363-926X', '0000-0001-9574-2194', '0000-0003-3557-5085', '0000-0002-6574-6706', '0000-0003-0773-1212', '0000-0003-2533-865X', '0000-0003-3011-1919', '0000-0002-6227-6112', '0000-0003-0144-1388', '0000-0001-8440-9388']\n",
      "Total sample size after apply threshold:  1370\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(1370, 1958)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "1370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.39        25\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.11      0.19        28\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       1.00      0.41      0.58        17\n",
      "          6       1.00      0.83      0.91        35\n",
      "          7       1.00      0.10      0.18        31\n",
      "          8       1.00      0.19      0.31        27\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       0.00      0.00      0.00        13\n",
      "         11       1.00      0.07      0.13        14\n",
      "         12       1.00      0.41      0.59        29\n",
      "         13       0.00      0.00      0.00        11\n",
      "         14       0.00      0.00      0.00        11\n",
      "         15       1.00      0.18      0.30        17\n",
      "         16       1.00      0.71      0.83        24\n",
      "         17       0.75      0.10      0.18        30\n",
      "         18       0.00      0.00      0.00        15\n",
      "         19       1.00      0.95      0.98        22\n",
      "         20       0.92      0.40      0.56        57\n",
      "         21       0.00      0.00      0.00        11\n",
      "         22       1.00      0.96      0.98        55\n",
      "         23       0.00      0.00      0.00        13\n",
      "         24       1.00      0.29      0.45        31\n",
      "         25       0.00      0.00      0.00        10\n",
      "         26       1.00      0.72      0.84        29\n",
      "         27       0.00      0.00      0.00        16\n",
      "         28       1.00      0.38      0.55        16\n",
      "         29       0.28      0.93      0.43       121\n",
      "         30       0.41      0.84      0.55       117\n",
      "         31       0.00      0.00      0.00        11\n",
      "         32       0.67      0.07      0.12        30\n",
      "         33       0.52      0.92      0.67        60\n",
      "         34       0.00      0.00      0.00        13\n",
      "         35       1.00      0.54      0.70        54\n",
      "         36       0.00      0.00      0.00        14\n",
      "         37       0.00      0.00      0.00        15\n",
      "         38       0.00      0.00      0.00        13\n",
      "         39       0.79      0.92      0.85        37\n",
      "         40       1.00      0.92      0.96        26\n",
      "         41       0.67      0.30      0.41        40\n",
      "         42       1.00      0.21      0.35        42\n",
      "         43       0.78      0.94      0.85        31\n",
      "         44       1.00      0.17      0.29        18\n",
      "         45       0.28      0.96      0.44        69\n",
      "         46       0.00      0.00      0.00        11\n",
      "         47       1.00      0.50      0.67        12\n",
      "\n",
      "avg / total       0.63      0.51      0.46      1370\n",
      "\n",
      "[6 0 0 ... 0 0 6]\n",
      "MNB Accuracy:  0.5116788321167883\n",
      "MNB F1:  0.3381250646669425\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        25\n",
      "          1       0.80      0.67      0.73        12\n",
      "          2       0.90      0.82      0.86        11\n",
      "          3       0.72      0.64      0.68        28\n",
      "          4       1.00      0.93      0.96        14\n",
      "          5       1.00      0.94      0.97        17\n",
      "          6       0.91      0.89      0.90        35\n",
      "          7       0.89      0.77      0.83        31\n",
      "          8       0.90      0.70      0.79        27\n",
      "          9       1.00      0.08      0.15        12\n",
      "         10       0.89      0.62      0.73        13\n",
      "         11       1.00      1.00      1.00        14\n",
      "         12       0.83      0.83      0.83        29\n",
      "         13       1.00      0.64      0.78        11\n",
      "         14       0.60      0.55      0.57        11\n",
      "         15       1.00      0.94      0.97        17\n",
      "         16       1.00      0.83      0.91        24\n",
      "         17       0.88      0.77      0.82        30\n",
      "         18       0.91      0.67      0.77        15\n",
      "         19       1.00      0.95      0.98        22\n",
      "         20       0.81      0.67      0.73        57\n",
      "         21       0.89      0.73      0.80        11\n",
      "         22       1.00      0.91      0.95        55\n",
      "         23       1.00      0.23      0.38        13\n",
      "         24       0.62      0.77      0.69        31\n",
      "         25       1.00      0.40      0.57        10\n",
      "         26       1.00      0.83      0.91        29\n",
      "         27       1.00      0.62      0.77        16\n",
      "         28       1.00      0.94      0.97        16\n",
      "         29       0.64      0.90      0.75       121\n",
      "         30       0.47      0.86      0.61       117\n",
      "         31       1.00      0.64      0.78        11\n",
      "         32       0.78      0.93      0.85        30\n",
      "         33       0.89      0.80      0.84        60\n",
      "         34       1.00      0.62      0.76        13\n",
      "         35       0.92      0.83      0.87        54\n",
      "         36       1.00      0.71      0.83        14\n",
      "         37       1.00      0.60      0.75        15\n",
      "         38       0.57      0.31      0.40        13\n",
      "         39       0.94      0.92      0.93        37\n",
      "         40       1.00      0.92      0.96        26\n",
      "         41       0.57      0.68      0.62        40\n",
      "         42       0.96      0.57      0.72        42\n",
      "         43       0.94      0.94      0.94        31\n",
      "         44       0.89      0.89      0.89        18\n",
      "         45       0.79      0.84      0.82        69\n",
      "         46       0.83      0.45      0.59        11\n",
      "         47       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.83      0.79      0.79      1370\n",
      "\n",
      "[15  0  0 ...  0  0 11]\n",
      "svc Accuracy:  0.7854014598540145\n",
      "svc F1:  0.783113614122609\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        25\n",
      "          1       1.00      0.67      0.80        12\n",
      "          2       1.00      0.45      0.62        11\n",
      "          3       1.00      0.43      0.60        28\n",
      "          4       1.00      0.86      0.92        14\n",
      "          5       1.00      0.76      0.87        17\n",
      "          6       0.86      0.89      0.87        35\n",
      "          7       0.92      0.71      0.80        31\n",
      "          8       0.93      0.48      0.63        27\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       1.00      0.38      0.56        13\n",
      "         11       1.00      1.00      1.00        14\n",
      "         12       0.79      0.79      0.79        29\n",
      "         13       1.00      0.36      0.53        11\n",
      "         14       0.80      0.36      0.50        11\n",
      "         15       1.00      0.76      0.87        17\n",
      "         16       1.00      0.75      0.86        24\n",
      "         17       0.80      0.67      0.73        30\n",
      "         18       1.00      0.33      0.50        15\n",
      "         19       1.00      0.95      0.98        22\n",
      "         20       0.64      0.47      0.55        57\n",
      "         21       1.00      0.55      0.71        11\n",
      "         22       1.00      0.93      0.96        55\n",
      "         23       0.00      0.00      0.00        13\n",
      "         24       0.71      0.81      0.76        31\n",
      "         25       1.00      0.10      0.18        10\n",
      "         26       1.00      0.72      0.84        29\n",
      "         27       1.00      0.25      0.40        16\n",
      "         28       1.00      0.81      0.90        16\n",
      "         29       0.56      0.90      0.69       121\n",
      "         30       0.37      0.90      0.52       117\n",
      "         31       1.00      0.36      0.53        11\n",
      "         32       0.68      0.90      0.77        30\n",
      "         33       0.80      0.85      0.82        60\n",
      "         34       1.00      0.08      0.14        13\n",
      "         35       0.85      0.65      0.74        54\n",
      "         36       1.00      0.50      0.67        14\n",
      "         37       1.00      0.13      0.24        15\n",
      "         38       0.00      0.00      0.00        13\n",
      "         39       0.87      0.92      0.89        37\n",
      "         40       1.00      0.92      0.96        26\n",
      "         41       0.59      0.68      0.63        40\n",
      "         42       1.00      0.38      0.55        42\n",
      "         43       0.88      0.94      0.91        31\n",
      "         44       0.88      0.78      0.82        18\n",
      "         45       0.65      0.93      0.77        69\n",
      "         46       1.00      0.36      0.53        11\n",
      "         47       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.78      0.70      0.69      1370\n",
      "\n",
      "[ 8  0  0 ...  0  0 11]\n",
      "LR Accuracy:  0.7029197080291971\n",
      "LR F1:  0.6530849355520242\n",
      "For name:  j_gao\n",
      "total sample size before apply threshold:  222\n",
      "Counter({'0000-0003-3215-7013': 44, '0000-0001-9341-1287': 36, '0000-0001-9778-4312': 26, '0000-0002-6200-4141': 24, '0000-0001-9803-0256': 20, '0000-0001-5732-9905': 14, '0000-0002-4545-1126': 12, '0000-0002-9943-4786': 12, '0000-0002-5739-1781': 11, '0000-0002-3952-208X': 8, '0000-0003-2059-0290': 7, '0000-0002-9959-5600': 2, '0000-0001-6659-5770': 1, '0000-0002-1181-4531': 1, '0000-0003-1160-6553': 1, '0000-0003-2668-6672': 1, '0000-0003-4024-4694': 1, '0000-0002-5977-0021': 1})\n",
      "['0000-0002-6200-4141', '0000-0001-5732-9905', '0000-0001-9341-1287', '0000-0003-3215-7013', '0000-0001-9778-4312', '0000-0002-5739-1781', '0000-0002-4545-1126', '0000-0002-9943-4786', '0000-0001-9803-0256']\n",
      "Total sample size after apply threshold:  199\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(199, 272)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "199\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        24\n",
      "          1       1.00      0.29      0.44        14\n",
      "          2       0.82      0.89      0.85        36\n",
      "          3       0.39      1.00      0.56        44\n",
      "          4       0.85      0.65      0.74        26\n",
      "          5       1.00      0.18      0.31        11\n",
      "          6       0.00      0.00      0.00        12\n",
      "          7       1.00      0.17      0.29        12\n",
      "          8       1.00      0.30      0.46        20\n",
      "\n",
      "avg / total       0.75      0.60      0.57       199\n",
      "\n",
      "[12  0  1 11  0  0  0  0  0  0  4  0 10  0  0  0  0  0  0  0 32  4  0  0\n",
      "  0  0  0  0  0  0 44  0  0  0  0  0  0  0  0  9 17  0  0  0  0  0  0  2\n",
      "  7  0  2  0  0  0  0  0  0 10  2  0  0  0  0  0  0  2  7  1  0  0  2  0\n",
      "  0  0  2 12  0  0  0  0  6]\n",
      "MNB Accuracy:  0.5979899497487438\n",
      "MNB F1:  0.4794979954987293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        24\n",
      "          1       0.91      0.71      0.80        14\n",
      "          2       0.85      0.92      0.88        36\n",
      "          3       0.77      0.93      0.85        44\n",
      "          4       0.85      0.88      0.87        26\n",
      "          5       1.00      0.64      0.78        11\n",
      "          6       0.90      0.75      0.82        12\n",
      "          7       1.00      0.92      0.96        12\n",
      "          8       0.82      0.70      0.76        20\n",
      "\n",
      "avg / total       0.87      0.86      0.86       199\n",
      "\n",
      "[23  0  0  1  0  0  0  0  0  0 10  2  2  0  0  0  0  0  0  1 33  1  0  0\n",
      "  1  0  0  0  0  0 41  2  0  0  0  1  0  0  0  2 23  0  0  0  1  0  0  2\n",
      "  2  0  7  0  0  0  0  0  1  0  2  0  9  0  0  0  0  0  0  0  0  0 11  1\n",
      "  1  0  1  4  0  0  0  0 14]\n",
      "svc Accuracy:  0.8592964824120602\n",
      "svc F1:  0.8512063086915862\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        24\n",
      "          1       0.78      0.50      0.61        14\n",
      "          2       0.70      0.92      0.80        36\n",
      "          3       0.63      0.95      0.76        44\n",
      "          4       0.79      0.88      0.84        26\n",
      "          5       1.00      0.27      0.43        11\n",
      "          6       0.75      0.25      0.38        12\n",
      "          7       1.00      0.75      0.86        12\n",
      "          8       0.90      0.45      0.60        20\n",
      "\n",
      "avg / total       0.80      0.75      0.73       199\n",
      "\n",
      "[21  1  1  1  0  0  0  0  0  0  7  3  3  1  0  0  0  0  0  1 33  1  0  0\n",
      "  1  0  0  0  0  0 42  2  0  0  0  0  0  0  0  2 23  0  0  0  1  0  0  4\n",
      "  4  0  3  0  0  0  0  0  3  4  2  0  3  0  0  0  0  0  2  1  0  0  9  0\n",
      "  0  0  3  8  0  0  0  0  9]\n",
      "LR Accuracy:  0.7537688442211056\n",
      "LR F1:  0.6878938208037213\n",
      "For name:  d_fernandes\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0003-0599-3200': 20, '0000-0002-5056-5734': 9, '0000-0001-5263-2737': 5, '0000-0001-6155-6246': 4, '0000-0002-2208-6349': 1, '0000-0003-3466-9450': 1})\n",
      "['0000-0003-0599-3200']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  c_silva\n",
      "total sample size before apply threshold:  148\n",
      "Counter({'0000-0003-4521-6377': 23, '0000-0001-6348-0505': 16, '0000-0001-6252-8693': 13, '0000-0002-7870-8848': 9, '0000-0002-9310-2457': 9, '0000-0002-1015-5095': 8, '0000-0002-0495-3955': 8, '0000-0002-2357-3405': 7, '0000-0003-1413-8038': 7, '0000-0002-1399-6674': 4, '0000-0002-1439-9214': 3, '0000-0002-9413-4573': 3, '0000-0003-0104-8412': 3, '0000-0003-4331-3755': 3, '0000-0002-5831-2993': 3, '0000-0001-7590-9639': 2, '0000-0002-1196-306X': 2, '0000-0002-1549-6833': 2, '0000-0002-7103-9100': 2, '0000-0002-7092-1169': 2, '0000-0001-6827-8939': 2, '0000-0002-7238-546X': 2, '0000-0002-1771-1517': 2, '0000-0003-1731-7883': 2, '0000-0003-4327-5744': 1, '0000-0002-5656-0061': 1, '0000-0001-6475-6622': 1, '0000-0003-2701-179X': 1, '0000-0001-8172-5860': 1, '0000-0001-9777-8406': 1, '0000-0002-4327-6272': 1, '0000-0002-5077-5176': 1, '0000-0002-7477-1495': 1, '0000-0003-2506-1435': 1, '0000-0002-9148-5458': 1})\n",
      "['0000-0001-6348-0505', '0000-0003-4521-6377', '0000-0001-6252-8693']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 197)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.88      1.00      0.94        23\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.95      0.94      0.94        52\n",
      "\n",
      "[14  2  0  0 23  0  0  1 12]\n",
      "MNB Accuracy:  0.9423076923076923\n",
      "MNB F1:  0.9440362811791383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        16\n",
      "          1       0.79      1.00      0.88        23\n",
      "          2       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.91      0.88      0.88        52\n",
      "\n",
      "[12  4  0  0 23  0  0  2 11]\n",
      "svc Accuracy:  0.8846153846153846\n",
      "svc F1:  0.8861416361416361\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        16\n",
      "          1       0.72      1.00      0.84        23\n",
      "          2       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.88      0.83      0.82        52\n",
      "\n",
      "[10  6  0  0 23  0  0  3 10]\n",
      "LR Accuracy:  0.8269230769230769\n",
      "LR F1:  0.8250532076619033\n",
      "For name:  t_fitzgerald\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-3855-1591': 31, '0000-0002-2370-8496': 21, '0000-0001-9898-1166': 1, '0000-0002-1532-517X': 1})\n",
      "['0000-0002-3855-1591', '0000-0002-2370-8496']\n",
      "Total sample size after apply threshold:  52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 300)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.89        31\n",
      "          1       1.00      0.62      0.76        21\n",
      "\n",
      "avg / total       0.88      0.85      0.84        52\n",
      "\n",
      "[31  0  8 13]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.8252100840336135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.94      0.95        31\n",
      "          1       0.91      0.95      0.93        21\n",
      "\n",
      "avg / total       0.94      0.94      0.94        52\n",
      "\n",
      "[29  2  1 20]\n",
      "svc Accuracy:  0.9423076923076923\n",
      "svc F1:  0.9405261151353412\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.95        31\n",
      "          1       0.95      0.90      0.93        21\n",
      "\n",
      "avg / total       0.94      0.94      0.94        52\n",
      "\n",
      "[30  1  2 19]\n",
      "LR Accuracy:  0.9423076923076923\n",
      "LR F1:  0.9396051103368176\n",
      "For name:  j_mitchell\n",
      "total sample size before apply threshold:  143\n",
      "Counter({'0000-0002-0379-6097': 57, '0000-0002-8445-0935': 32, '0000-0002-7147-4604': 16, '0000-0002-2361-9805': 14, '0000-0003-4956-1530': 11, '0000-0002-2520-8428': 6, '0000-0001-6785-9352': 3, '0000-0002-0710-5580': 3, '0000-0002-8624-5070': 1})\n",
      "['0000-0002-0379-6097', '0000-0002-8445-0935', '0000-0002-7147-4604', '0000-0003-4956-1530', '0000-0002-2361-9805']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 130\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 274)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "130\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.98      0.74        57\n",
      "          1       0.96      0.72      0.82        32\n",
      "          2       1.00      0.50      0.67        16\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.21      0.35        14\n",
      "\n",
      "avg / total       0.73      0.69      0.65       130\n",
      "\n",
      "[56  1  0  0  0  9 23  0  0  0  8  0  8  0  0 11  0  0  0  0 11  0  0  0\n",
      "  3]\n",
      "MNB Accuracy:  0.6923076923076923\n",
      "MNB F1:  0.5155757039657968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.98      0.81        57\n",
      "          1       0.96      0.81      0.88        32\n",
      "          2       1.00      0.75      0.86        16\n",
      "          3       1.00      0.27      0.43        11\n",
      "          4       1.00      0.43      0.60        14\n",
      "\n",
      "avg / total       0.85      0.79      0.78       130\n",
      "\n",
      "[56  1  0  0  0  6 26  0  0  0  4  0 12  0  0  8  0  0  3  0  8  0  0  0\n",
      "  6]\n",
      "svc Accuracy:  0.7923076923076923\n",
      "svc F1:  0.7145651227202257\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.98      0.70        57\n",
      "          1       0.94      0.53      0.68        32\n",
      "          2       1.00      0.38      0.55        16\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.14      0.25        14\n",
      "\n",
      "avg / total       0.70      0.62      0.57       130\n",
      "\n",
      "[56  1  0  0  0 15 17  0  0  0 10  0  6  0  0 11  0  0  0  0 12  0  0  0\n",
      "  2]\n",
      "LR Accuracy:  0.6230769230769231\n",
      "LR F1:  0.4342213438735178\n",
      "For name:  a_gomes\n",
      "total sample size before apply threshold:  244\n",
      "Counter({'0000-0002-9819-3036': 44, '0000-0002-0567-064X': 42, '0000-0002-5940-9893': 32, '0000-0001-7883-2446': 20, '0000-0002-8221-6985': 19, '0000-0003-1052-8004': 18, '0000-0002-3348-0448': 16, '0000-0001-9598-1275': 13, '0000-0002-4989-6026': 7, '0000-0003-3976-238X': 6, '0000-0002-6390-9866': 6, '0000-0001-9565-8814': 5, '0000-0003-1998-0291': 5, '0000-0002-1707-9208': 3, '0000-0001-8702-4360': 2, '0000-0002-9793-4816': 1, '0000-0003-0010-2608': 1, '0000-0002-3498-7734': 1, '0000-0001-5466-0272': 1, '0000-0002-3332-834X': 1, '0000-0002-3201-0081': 1})\n",
      "['0000-0002-9819-3036', '0000-0002-5940-9893', '0000-0003-1052-8004', '0000-0002-8221-6985', '0000-0001-9598-1275', '0000-0001-7883-2446', '0000-0002-3348-0448', '0000-0002-0567-064X']\n",
      "Total sample size after apply threshold:  204\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(204, 3913)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.95        44\n",
      "          1       1.00      1.00      1.00        32\n",
      "          2       1.00      0.11      0.20        18\n",
      "          3       0.95      0.95      0.95        19\n",
      "          4       1.00      0.54      0.70        13\n",
      "          5       1.00      0.95      0.97        20\n",
      "          6       0.00      0.00      0.00        16\n",
      "          7       0.51      0.95      0.67        42\n",
      "\n",
      "avg / total       0.80      0.79      0.74       204\n",
      "\n",
      "[43  0  0  0  0  0  0  1  0 32  0  0  0  0  0  0  0  0  2  0  0  0  0 16\n",
      "  0  0  0 18  0  0  0  1  0  0  0  0  7  0  0  6  0  0  0  0  0 19  0  1\n",
      "  3  0  0  0  0  0  0 13  1  0  0  1  0  0  0 40]\n",
      "MNB Accuracy:  0.7892156862745098\n",
      "MNB F1:  0.6791811258916522\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.85        44\n",
      "          1       1.00      1.00      1.00        32\n",
      "          2       0.83      0.56      0.67        18\n",
      "          3       1.00      0.89      0.94        19\n",
      "          4       1.00      1.00      1.00        13\n",
      "          5       1.00      0.95      0.97        20\n",
      "          6       1.00      0.62      0.77        16\n",
      "          7       0.93      0.90      0.92        42\n",
      "\n",
      "avg / total       0.91      0.90      0.89       204\n",
      "\n",
      "[44  0  0  0  0  0  0  0  0 32  0  0  0  0  0  0  6  0 10  0  0  0  0  2\n",
      "  1  0  1 17  0  0  0  0  0  0  0  0 13  0  0  0  1  0  0  0  0 19  0  0\n",
      "  5  0  0  0  0  0 10  1  3  0  1  0  0  0  0 38]\n",
      "svc Accuracy:  0.8970588235294118\n",
      "svc F1:  0.8895646689321388\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      1.00      0.75        44\n",
      "          1       1.00      1.00      1.00        32\n",
      "          2       0.89      0.44      0.59        18\n",
      "          3       1.00      0.89      0.94        19\n",
      "          4       1.00      0.92      0.96        13\n",
      "          5       1.00      0.95      0.97        20\n",
      "          6       1.00      0.12      0.22        16\n",
      "          7       0.85      0.81      0.83        42\n",
      "\n",
      "avg / total       0.87      0.82      0.80       204\n",
      "\n",
      "[44  0  0  0  0  0  0  0  0 32  0  0  0  0  0  0  7  0  8  0  0  0  0  3\n",
      "  2  0  0 17  0  0  0  0  0  0  0  0 12  0  0  1  1  0  0  0  0 19  0  0\n",
      " 11  0  1  0  0  0  2  2  8  0  0  0  0  0  0 34]\n",
      "LR Accuracy:  0.8235294117647058\n",
      "LR F1:  0.7843779098047391\n",
      "For name:  t_weber\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0002-0494-0484': 29, '0000-0001-8994-1285': 13, '0000-0002-8260-5120': 12, '0000-0003-2931-8963': 10, '0000-0001-8320-361X': 7})\n",
      "['0000-0002-0494-0484', '0000-0001-8994-1285', '0000-0003-2931-8963', '0000-0002-8260-5120']\n",
      "Total sample size after apply threshold:  64\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(64, 421)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      1.00      0.76        29\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       1.00      0.70      0.82        10\n",
      "          3       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.83      0.72      0.70        64\n",
      "\n",
      "[29  0  0  0  7  6  0  0  3  0  7  0  8  0  0  4]\n",
      "MNB Accuracy:  0.71875\n",
      "MNB F1:  0.6795665634674922\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84        29\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       1.00      0.70      0.82        10\n",
      "          3       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.88      0.83      0.83        64\n",
      "\n",
      "[29  0  0  0  5  8  0  0  3  0  7  0  3  0  0  9]\n",
      "svc Accuracy:  0.828125\n",
      "svc F1:  0.8207891852393131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      1.00      0.72        29\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       1.00      0.50      0.67        10\n",
      "          3       1.00      0.17      0.29        12\n",
      "\n",
      "avg / total       0.80      0.66      0.61        64\n",
      "\n",
      "[29  0  0  0  7  6  0  0  5  0  5  0 10  0  0  2]\n",
      "LR Accuracy:  0.65625\n",
      "LR F1:  0.5772399749373432\n",
      "For name:  j_shim\n",
      "total sample size before apply threshold:  188\n",
      "Counter({'0000-0002-5361-2903': 91, '0000-0003-0167-7307': 36, '0000-0003-1881-8436': 30, '0000-0003-4088-2557': 12, '0000-0002-3974-1290': 6, '0000-0003-4577-1952': 6, '0000-0001-5485-160X': 3, '0000-0003-0101-3076': 2, '0000-0001-9367-2233': 1, '0000-0002-1909-5412': 1})\n",
      "['0000-0003-4088-2557', '0000-0002-5361-2903', '0000-0003-0167-7307', '0000-0003-1881-8436']\n",
      "Total sample size after apply threshold:  169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 220)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "169\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.79      1.00      0.88        91\n",
      "          2       0.96      0.61      0.75        36\n",
      "          3       0.90      0.90      0.90        30\n",
      "\n",
      "avg / total       0.86      0.83      0.81       169\n",
      "\n",
      "[ 1  9  0  2  0 91  0  0  0 13 22  1  0  2  1 27]\n",
      "MNB Accuracy:  0.834319526627219\n",
      "MNB F1:  0.6707760028354072\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.75      0.82        12\n",
      "          1       0.96      0.98      0.97        91\n",
      "          2       0.87      0.94      0.91        36\n",
      "          3       1.00      0.90      0.95        30\n",
      "\n",
      "avg / total       0.94      0.94      0.94       169\n",
      "\n",
      "[ 9  0  3  0  1 89  1  0  0  2 34  0  0  2  1 27]\n",
      "svc Accuracy:  0.9408284023668639\n",
      "svc F1:  0.9099020525622357\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.90      0.99      0.94        91\n",
      "          2       0.91      0.89      0.90        36\n",
      "          3       0.96      0.87      0.91        30\n",
      "\n",
      "avg / total       0.92      0.92      0.91       169\n",
      "\n",
      "[ 7  4  1  0  0 90  0  1  0  4 32  0  0  2  2 26]\n",
      "LR Accuracy:  0.9171597633136095\n",
      "LR F1:  0.8732349086712801\n",
      "For name:  k_kang\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0003-2622-9017': 53, '0000-0003-0446-469X': 22, '0000-0002-0457-842X': 12, '0000-0002-8790-9350': 11, '0000-0002-4465-0617': 9, '0000-0001-6374-8356': 8, '0000-0003-3290-1017': 3, '0000-0002-6529-4543': 3, '0000-0002-8428-8288': 3, '0000-0003-1230-3626': 2, '0000-0003-0611-9320': 1, '0000-0001-9135-1890': 1})\n",
      "['0000-0002-0457-842X', '0000-0002-8790-9350', '0000-0003-2622-9017', '0000-0003-0446-469X']\n",
      "Total sample size after apply threshold:  98\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 178)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       1.00      0.36      0.53        11\n",
      "          2       0.60      1.00      0.75        53\n",
      "          3       0.75      0.14      0.23        22\n",
      "\n",
      "avg / total       0.73      0.62      0.53        98\n",
      "\n",
      "[ 1  0 10  1  0  4  7  0  0  0 53  0  0  0 19  3]\n",
      "MNB Accuracy:  0.6224489795918368\n",
      "MNB F1:  0.4161068977970387\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       0.85      0.98      0.91        53\n",
      "          3       0.71      0.68      0.70        22\n",
      "\n",
      "avg / total       0.86      0.85      0.84        98\n",
      "\n",
      "[ 8  0  2  2  0  8  0  3  0  0 52  1  0  0  7 15]\n",
      "svc Accuracy:  0.8469387755102041\n",
      "svc F1:  0.813015095879233\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       0.68      0.98      0.80        53\n",
      "          3       0.86      0.27      0.41        22\n",
      "\n",
      "avg / total       0.79      0.73      0.70        98\n",
      "\n",
      "[ 6  0  6  0  0  8  3  0  0  0 52  1  0  0 16  6]\n",
      "LR Accuracy:  0.7346938775510204\n",
      "LR F1:  0.6806412583182093\n",
      "For name:  i_ferreira\n",
      "total sample size before apply threshold:  344\n",
      "Counter({'0000-0003-4910-4882': 166, '0000-0003-1434-0607': 90, '0000-0001-8424-1431': 44, '0000-0001-6552-4479': 19, '0000-0002-8838-0364': 13, '0000-0002-4934-917X': 7, '0000-0002-3164-8227': 3, '0000-0002-5368-9505': 2})\n",
      "['0000-0003-1434-0607', '0000-0001-6552-4479', '0000-0003-4910-4882', '0000-0002-8838-0364', '0000-0001-8424-1431']\n",
      "Total sample size after apply threshold:  332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(332, 492)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        90\n",
      "          1       0.00      0.00      0.00        19\n",
      "          2       0.76      1.00      0.86       166\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       1.00      0.57      0.72        44\n",
      "\n",
      "avg / total       0.78      0.84      0.80       332\n",
      "\n",
      "[ 88   0   2   0   0   0   0  19   0   0   0   0 166   0   0   0   0  13\n",
      "   0   0   0   0  19   0  25]\n",
      "MNB Accuracy:  0.8403614457831325\n",
      "MNB F1:  0.5151478776881806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        90\n",
      "          1       1.00      0.95      0.97        19\n",
      "          2       0.93      0.99      0.96       166\n",
      "          3       1.00      0.85      0.92        13\n",
      "          4       0.97      0.82      0.89        44\n",
      "\n",
      "avg / total       0.96      0.96      0.96       332\n",
      "\n",
      "[ 88   0   2   0   0   0  18   1   0   0   0   0 165   0   1   0   0   2\n",
      "  11   0   0   0   8   0  36]\n",
      "svc Accuracy:  0.9578313253012049\n",
      "svc F1:  0.9453189798107487\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        90\n",
      "          1       1.00      0.37      0.54        19\n",
      "          2       0.78      1.00      0.88       166\n",
      "          3       1.00      0.08      0.14        13\n",
      "          4       1.00      0.59      0.74        44\n",
      "\n",
      "avg / total       0.89      0.86      0.84       332\n",
      "\n",
      "[ 85   0   5   0   0   0   7  12   0   0   0   0 166   0   0   0   0  12\n",
      "   1   0   0   0  18   0  26]\n",
      "LR Accuracy:  0.858433734939759\n",
      "LR F1:  0.6543187683029371\n",
      "For name:  y_jia\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0002-2784-1905': 24, '0000-0003-3852-7302': 10, '0000-0002-8852-7557': 3, '0000-0001-9657-0806': 3, '0000-0001-7978-9312': 3, '0000-0001-9395-2139': 2, '0000-0003-4972-1004': 1})\n",
      "['0000-0003-3852-7302', '0000-0002-2784-1905']\n",
      "Total sample size after apply threshold:  34\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 73)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      1.00      1.00        24\n",
      "\n",
      "avg / total       1.00      1.00      1.00        34\n",
      "\n",
      "[10  0  0 24]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      1.00      1.00        24\n",
      "\n",
      "avg / total       1.00      1.00      1.00        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  0  0 24]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       0.89      1.00      0.94        24\n",
      "\n",
      "avg / total       0.92      0.91      0.91        34\n",
      "\n",
      "[ 7  3  0 24]\n",
      "LR Accuracy:  0.9117647058823529\n",
      "LR F1:  0.8823529411764706\n",
      "For name:  p_gaspar\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0003-4217-5717': 87, '0000-0001-5967-0584': 3, '0000-0002-4832-8537': 2, '0000-0003-3388-1724': 1})\n",
      "['0000-0003-4217-5717']\n",
      "Total sample size after apply threshold:  87\n",
      "For name:  r_o'connor\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0003-4426-2507': 36, '0000-0002-4643-9794': 27, '0000-0002-6869-7954': 13, '0000-0002-3916-3101': 6})\n",
      "['0000-0002-6869-7954', '0000-0003-4426-2507', '0000-0002-4643-9794']\n",
      "Total sample size after apply threshold:  76\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(76, 215)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "76\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        13\n",
      "          1       0.86      1.00      0.92        36\n",
      "          2       0.88      0.78      0.82        27\n",
      "\n",
      "avg / total       0.89      0.88      0.88        76\n",
      "\n",
      "[10  0  3  0 36  0  0  6 21]\n",
      "MNB Accuracy:  0.881578947368421\n",
      "MNB F1:  0.8720571840776445\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.92      0.94      0.93        36\n",
      "          2       0.86      0.89      0.87        27\n",
      "\n",
      "avg / total       0.91      0.91      0.91        76\n",
      "\n",
      "[11  0  2  0 34  2  0  3 24]\n",
      "svc Accuracy:  0.9078947368421053\n",
      "svc F1:  0.9069669295696693\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.69      1.00      0.82        36\n",
      "          2       1.00      0.59      0.74        27\n",
      "\n",
      "avg / total       0.85      0.79      0.78        76\n",
      "\n",
      "[ 8  5  0  0 36  0  0 11 16]\n",
      "LR Accuracy:  0.7894736842105263\n",
      "LR F1:  0.7747575421994027\n",
      "For name:  k_larsen\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0003-2172-7519': 35, '0000-0002-3918-6645': 6, '0000-0002-1421-6182': 4, '0000-0002-6473-7285': 1, '0000-0003-1182-7727': 1})\n",
      "['0000-0003-2172-7519']\n",
      "Total sample size after apply threshold:  35\n",
      "For name:  s_das\n",
      "total sample size before apply threshold:  197\n",
      "Counter({'0000-0002-1659-2499': 50, '0000-0002-2424-2851': 21, '0000-0002-8394-5303': 17, '0000-0002-5353-0422': 15, '0000-0002-0539-5174': 14, '0000-0003-1185-9366': 13, '0000-0002-2384-3903': 9, '0000-0001-6256-5646': 9, '0000-0002-7066-2128': 6, '0000-0002-8097-6542': 6, '0000-0002-4217-9972': 5, '0000-0001-6470-7302': 4, '0000-0002-5974-7649': 4, '0000-0001-9380-2907': 3, '0000-0002-8628-5128': 2, '0000-0003-0467-0872': 2, '0000-0002-4852-1396': 2, '0000-0003-0745-469X': 2, '0000-0002-9302-7645': 2, '0000-0002-3428-1862': 1, '0000-0001-5339-7708': 1, '0000-0002-0994-8960': 1, '0000-0003-2889-8644': 1, '0000-0003-2161-4784': 1, '0000-0002-0285-8970': 1, '0000-0002-4464-3417': 1, '0000-0002-7336-9568': 1, '0000-0002-3010-6469': 1, '0000-0001-7329-8264': 1, '0000-0002-9896-3520': 1})\n",
      "['0000-0002-0539-5174', '0000-0002-5353-0422', '0000-0002-2424-2851', '0000-0003-1185-9366', '0000-0002-8394-5303', '0000-0002-1659-2499']\n",
      "Total sample size after apply threshold:  130\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 271)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "130\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        14\n",
      "          1       1.00      0.60      0.75        15\n",
      "          2       1.00      0.90      0.95        21\n",
      "          3       1.00      0.77      0.87        13\n",
      "          4       1.00      0.65      0.79        17\n",
      "          5       0.68      1.00      0.81        50\n",
      "\n",
      "avg / total       0.88      0.82      0.81       130\n",
      "\n",
      "[ 7  0  0  0  0  7  0  9  0  0  0  6  0  0 19  0  0  2  0  0  0 10  0  3\n",
      "  0  0  0  0 11  6  0  0  0  0  0 50]\n",
      "MNB Accuracy:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8153846153846154\n",
      "MNB F1:  0.8047329637792471\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       1.00      0.93      0.97        15\n",
      "          2       1.00      0.86      0.92        21\n",
      "          3       1.00      1.00      1.00        13\n",
      "          4       1.00      0.71      0.83        17\n",
      "          5       0.82      1.00      0.90        50\n",
      "\n",
      "avg / total       0.93      0.92      0.91       130\n",
      "\n",
      "[12  0  0  0  0  2  0 14  0  0  0  1  0  0 18  0  0  3  0  0  0 13  0  0\n",
      "  0  0  0  0 12  5  0  0  0  0  0 50]\n",
      "svc Accuracy:  0.9153846153846154\n",
      "svc F1:  0.9233596992217681\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        14\n",
      "          1       1.00      0.67      0.80        15\n",
      "          2       1.00      0.86      0.92        21\n",
      "          3       1.00      0.62      0.76        13\n",
      "          4       1.00      0.65      0.79        17\n",
      "          5       0.64      1.00      0.78        50\n",
      "\n",
      "avg / total       0.86      0.78      0.78       130\n",
      "\n",
      "[ 5  0  0  0  0  9  0 10  0  0  0  5  0  0 18  0  0  3  0  0  0  8  0  5\n",
      "  0  0  0  0 11  6  0  0  0  0  0 50]\n",
      "LR Accuracy:  0.7846153846153846\n",
      "LR F1:  0.7630436266949424\n",
      "For name:  f_rodriguez\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0003-4044-8734': 3, '0000-0003-1213-0999': 2, '0000-0003-4053-099X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  w_peng\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0001-5093-7115': 14, '0000-0002-4506-0942': 13, '0000-0001-9747-2466': 8, '0000-0003-4917-6851': 3})\n",
      "['0000-0002-4506-0942', '0000-0001-5093-7115']\n",
      "Total sample size after apply threshold:  27\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 101)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.97      0.96      0.96        27\n",
      "\n",
      "[13  0  1 13]\n",
      "MNB Accuracy:  0.9629629629629629\n",
      "MNB F1:  0.962962962962963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        27\n",
      "\n",
      "[13  0  0 14]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        27\n",
      "\n",
      "[13  0  0 14]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  c_torres\n",
      "total sample size before apply threshold:  300\n",
      "Counter({'0000-0003-3709-1690': 237, '0000-0001-8573-0990': 20, '0000-0001-6303-4417': 16, '0000-0001-6786-8769': 15, '0000-0003-3991-0573': 9, '0000-0001-6322-5862': 2, '0000-0002-7908-6884': 1})\n",
      "['0000-0001-8573-0990', '0000-0001-6786-8769', '0000-0003-3709-1690', '0000-0001-6303-4417']\n",
      "Total sample size after apply threshold:  288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(288, 528)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "288\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        20\n",
      "          1       1.00      0.20      0.33        15\n",
      "          2       0.89      1.00      0.94       237\n",
      "          3       1.00      0.19      0.32        16\n",
      "\n",
      "avg / total       0.91      0.90      0.87       288\n",
      "\n",
      "[ 16   0   4   0   0   3  12   0   0   0 237   0   0   0  13   3]\n",
      "MNB Accuracy:  0.8993055555555556\n",
      "MNB F1:  0.6200894050899284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        20\n",
      "          1       1.00      0.53      0.70        15\n",
      "          2       0.94      1.00      0.97       237\n",
      "          3       1.00      0.75      0.86        16\n",
      "\n",
      "avg / total       0.95      0.95      0.94       288\n",
      "\n",
      "[ 16   0   4   0   0   8   7   0   0   0 237   0   0   0   4  12]\n",
      "svc Accuracy:  0.9479166666666666\n",
      "svc F1:  0.8527522683297557\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        20\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.85      1.00      0.92       237\n",
      "          3       1.00      0.12      0.22        16\n",
      "\n",
      "avg / total       0.82      0.85      0.80       288\n",
      "\n",
      "[  7   0  13   0   0   0  15   0   0   0 237   0   0   0  14   2]\n",
      "LR Accuracy:  0.8541666666666666\n",
      "LR F1:  0.41483634797588287\n",
      "For name:  s_rossi\n",
      "total sample size before apply threshold:  199\n",
      "Counter({'0000-0003-3257-8248': 86, '0000-0002-9963-8121': 34, '0000-0002-9919-0494': 25, '0000-0002-8854-7072': 14, '0000-0003-0346-8410': 13, '0000-0002-3278-8993': 10, '0000-0002-2694-9535': 8, '0000-0001-5134-8398': 5, '0000-0001-7048-7158': 1, '0000-0001-8853-0775': 1, '0000-0001-9511-3857': 1, '0000-0001-7479-5756': 1})\n",
      "['0000-0002-8854-7072', '0000-0002-9919-0494', '0000-0003-0346-8410', '0000-0002-9963-8121', '0000-0002-3278-8993', '0000-0003-3257-8248']\n",
      "Total sample size after apply threshold:  182\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(182, 538)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "182\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        14\n",
      "          1       1.00      0.76      0.86        25\n",
      "          2       1.00      0.77      0.87        13\n",
      "          3       1.00      0.85      0.92        34\n",
      "          4       1.00      0.20      0.33        10\n",
      "          5       0.75      1.00      0.86        86\n",
      "\n",
      "avg / total       0.88      0.85      0.83       182\n",
      "\n",
      "[ 8  0  0  0  0  6  0 19  0  0  0  6  0  0 10  0  0  3  0  0  0 29  0  5\n",
      "  0  0  0  0  2  8  0  0  0  0  0 86]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.7624070937114417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       1.00      0.88      0.94        25\n",
      "          2       1.00      0.92      0.96        13\n",
      "          3       0.94      0.91      0.93        34\n",
      "          4       1.00      0.80      0.89        10\n",
      "          5       0.91      1.00      0.95        86\n",
      "\n",
      "avg / total       0.94      0.94      0.94       182\n",
      "\n",
      "[12  0  0  1  0  1  0 22  0  1  0  2  0  0 12  0  0  1  0  0  0 31  0  3\n",
      "  0  0  0  0  8  2  0  0  0  0  0 86]\n",
      "svc Accuracy:  0.9395604395604396\n",
      "svc F1:  0.9306309003590084\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        14\n",
      "          1       1.00      0.84      0.91        25\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       1.00      0.79      0.89        34\n",
      "          4       1.00      0.40      0.57        10\n",
      "          5       0.74      1.00      0.85        86\n",
      "\n",
      "avg / total       0.88      0.84      0.83       182\n",
      "\n",
      "[ 6  0  0  0  0  8  0 21  0  0  0  4  0  0  8  0  0  5  0  0  0 27  0  7\n",
      "  0  0  0  0  4  6  0  0  0  0  0 86]\n",
      "LR Accuracy:  0.8351648351648352\n",
      "LR F1:  0.7638513102913999\n",
      "For name:  s_alavi\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0003-4328-4747': 23, '0000-0003-4009-4921': 14, '0000-0003-1130-3165': 1})\n",
      "['0000-0003-4328-4747', '0000-0003-4009-4921']\n",
      "Total sample size after apply threshold:  37\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 80)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        23\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        37\n",
      "\n",
      "[23  0  0 14]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        23\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        37\n",
      "\n",
      "[23  0  0 14]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        23\n",
      "          1       1.00      0.71      0.83        14\n",
      "\n",
      "avg / total       0.91      0.89      0.89        37\n",
      "\n",
      "[23  0  4 10]\n",
      "LR Accuracy:  0.8918918918918919\n",
      "LR F1:  0.8766666666666667\n",
      "For name:  r_marques\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-6949-0947': 11, '0000-0002-4749-7523': 11, '0000-0002-3125-3911': 8, '0000-0001-6239-5456': 3, '0000-0002-9416-1299': 2, '0000-0001-8261-4409': 1, '0000-0001-6925-041X': 1, '0000-0002-9197-9845': 1, '0000-0002-0672-9260': 1, '0000-0001-8622-9786': 1, '0000-0003-0314-3675': 1})\n",
      "['0000-0002-6949-0947', '0000-0002-4749-7523']\n",
      "Total sample size after apply threshold:  22"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 89)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "22\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.85      1.00      0.92        11\n",
      "\n",
      "avg / total       0.92      0.91      0.91        22\n",
      "\n",
      "[ 9  2  0 11]\n",
      "MNB Accuracy:  0.9090909090909091\n",
      "MNB F1:  0.9083333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        11\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "[11  0  1 10]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.9544513457556936\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        11\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "[11  0  1 10]\n",
      "LR Accuracy:  0.9545454545454546\n",
      "LR F1:  0.9544513457556936\n",
      "For name:  m_wheeler\n",
      "total sample size before apply threshold:  163\n",
      "Counter({'0000-0002-7480-7267': 112, '0000-0001-5589-357X': 47, '0000-0002-0319-1987': 3, '0000-0002-7404-7069': 1})\n",
      "['0000-0002-7480-7267', '0000-0001-5589-357X']\n",
      "Total sample size after apply threshold:  159\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 507)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "159\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       112\n",
      "          1       1.00      0.68      0.81        47\n",
      "\n",
      "avg / total       0.92      0.91      0.90       159\n",
      "\n",
      "[112   0  15  32]\n",
      "MNB Accuracy:  0.9056603773584906\n",
      "MNB F1:  0.8736825380011652\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       112\n",
      "          1       1.00      0.72      0.84        47\n",
      "\n",
      "avg / total       0.93      0.92      0.91       159\n",
      "\n",
      "[112   0  13  34]\n",
      "svc Accuracy:  0.9182389937106918\n",
      "svc F1:  0.8923269260822004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89       112\n",
      "          1       1.00      0.43      0.60        47\n",
      "\n",
      "avg / total       0.86      0.83      0.81       159\n",
      "\n",
      "[112   0  27  20]\n",
      "LR Accuracy:  0.8301886792452831\n",
      "LR F1:  0.7447226021287983\n",
      "For name:  l_rasmussen\n",
      "total sample size before apply threshold:  249\n",
      "Counter({'0000-0002-7480-3004': 214, '0000-0002-4497-8049': 24, '0000-0001-6613-2469': 5, '0000-0001-5962-6647': 4, '0000-0001-5795-4794': 1, '0000-0002-7301-3182': 1})\n",
      "['0000-0002-4497-8049', '0000-0002-7480-3004']\n",
      "Total sample size after apply threshold:  238\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(238, 523)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        24\n",
      "          1       0.98      1.00      0.99       214\n",
      "\n",
      "avg / total       0.98      0.98      0.98       238\n",
      "\n",
      "[ 19   5   0 214]\n",
      "MNB Accuracy:  0.9789915966386554\n",
      "MNB F1:  0.9360867930608519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        24\n",
      "          1       0.97      1.00      0.98       214\n",
      "\n",
      "avg / total       0.97      0.97      0.97       238\n",
      "\n",
      "[ 17   7   0 214]\n",
      "svc Accuracy:  0.9705882352941176\n",
      "svc F1:  0.9065881693299691\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        24\n",
      "          1       0.92      1.00      0.96       214\n",
      "\n",
      "avg / total       0.93      0.92      0.90       238\n",
      "\n",
      "[  6  18   0 214]\n",
      "LR Accuracy:  0.9243697478991597\n",
      "LR F1:  0.6798206278026906\n",
      "For name:  m_saad\n",
      "total sample size before apply threshold:  4\n",
      "Counter({'0000-0003-0458-5942': 1, '0000-0002-8071-2328': 1, '0000-0002-5655-8674': 1, '0000-0003-1291-366X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_carr\n",
      "total sample size before apply threshold:  271\n",
      "Counter({'0000-0002-4398-8237': 179, '0000-0002-6445-2992': 42, '0000-0002-5028-2160': 40, '0000-0002-2729-0920': 6, '0000-0002-9164-4156': 2, '0000-0002-2324-8944': 1, '0000-0002-1080-1472': 1})\n",
      "['0000-0002-6445-2992', '0000-0002-5028-2160', '0000-0002-4398-8237']\n",
      "Total sample size after apply threshold:  261\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(261, 791)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "261\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.50      0.66        42\n",
      "          1       1.00      0.40      0.57        40\n",
      "          2       0.80      0.99      0.89       179\n",
      "\n",
      "avg / total       0.85      0.82      0.80       261\n",
      "\n",
      "[ 21   0  21   0  16  24   1   0 178]\n",
      "MNB Accuracy:  0.8237547892720306\n",
      "MNB F1:  0.7044169035773513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        42\n",
      "          1       1.00      0.68      0.81        40\n",
      "          2       0.88      1.00      0.93       179\n",
      "\n",
      "avg / total       0.92      0.90      0.90       261\n",
      "\n",
      "[ 30   0  12   0  27  13   0   0 179]\n",
      "svc Accuracy:  0.9042145593869731\n",
      "svc F1:  0.8580097770503444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.35        42\n",
      "          1       1.00      0.25      0.40        40\n",
      "          2       0.74      1.00      0.85       179\n",
      "\n",
      "avg / total       0.82      0.76      0.70       261\n",
      "\n",
      "[  9   0  33   0  10  30   0   0 179]\n",
      "LR Accuracy:  0.7586206896551724\n",
      "LR F1:  0.5344324903358019\n",
      "For name:  j_fraser\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0002-5080-2859': 38, '0000-0002-6505-1883': 36, '0000-0002-5980-3989': 9, '0000-0003-0111-9137': 6, '0000-0002-8020-2985': 6, '0000-0001-9697-3795': 3, '0000-0003-4941-1997': 3})\n",
      "['0000-0002-6505-1883', '0000-0002-5080-2859']\n",
      "Total sample size after apply threshold:  74\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(74, 258)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "74\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91        36\n",
      "          1       0.97      0.84      0.90        38\n",
      "\n",
      "avg / total       0.91      0.91      0.91        74\n",
      "\n",
      "[35  1  6 32]\n",
      "MNB Accuracy:  0.9054054054054054\n",
      "MNB F1:  0.9052496798975672\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        36\n",
      "          1       0.93      1.00      0.96        38\n",
      "\n",
      "avg / total       0.96      0.96      0.96        74\n",
      "\n",
      "[33  3  0 38]\n",
      "svc Accuracy:  0.9594594594594594\n",
      "svc F1:  0.9592735277930655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        36\n",
      "          1       0.93      1.00      0.96        38\n",
      "\n",
      "avg / total       0.96      0.96      0.96        74\n",
      "\n",
      "[33  3  0 38]\n",
      "LR Accuracy:  0.9594594594594594\n",
      "LR F1:  0.9592735277930655\n",
      "For name:  s_woo\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-3692-7169': 22, '0000-0001-8788-2875': 1, '0000-0001-6765-4322': 1, '0000-0001-6902-0315': 1})\n",
      "['0000-0003-3692-7169']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  s_bartlett\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0001-9755-2490': 80, '0000-0003-4387-670X': 18, '0000-0002-7044-4454': 3, '0000-0003-0699-2250': 3})\n",
      "['0000-0003-4387-670X', '0000-0001-9755-2490']\n",
      "Total sample size after apply threshold:  98\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 486)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.06      0.10        18\n",
      "          1       0.82      0.99      0.90        80\n",
      "\n",
      "avg / total       0.76      0.82      0.75        98\n",
      "\n",
      "[ 1 17  1 79]\n",
      "MNB Accuracy:  0.8163265306122449\n",
      "MNB F1:  0.49886363636363634\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        18\n",
      "          1       0.87      1.00      0.93        80\n",
      "\n",
      "avg / total       0.89      0.88      0.85        98\n",
      "\n",
      "[ 6 12  0 80]\n",
      "svc Accuracy:  0.8775510204081632\n",
      "svc F1:  0.7151162790697674\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        18\n",
      "          1       0.82      1.00      0.90        80\n",
      "\n",
      "avg / total       0.67      0.82      0.73        98\n",
      "\n",
      "[ 0 18  0 80]\n",
      "LR Accuracy:  0.8163265306122449\n",
      "LR F1:  0.449438202247191\n",
      "For name:  m_lucas\n",
      "total sample size before apply threshold:  75\n",
      "Counter({'0000-0002-3252-0145': 25, '0000-0002-3625-9714': 19, '0000-0001-8672-9940': 15, '0000-0002-5463-0505': 14, '0000-0002-1646-4139': 2})\n",
      "['0000-0002-5463-0505', '0000-0001-8672-9940', '0000-0002-3625-9714', '0000-0002-3252-0145']\n",
      "Total sample size after apply threshold:  73\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 201)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "73\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       1.00      1.00      1.00        15\n",
      "          2       0.83      0.79      0.81        19\n",
      "          3       0.85      0.92      0.88        25\n",
      "\n",
      "avg / total       0.91      0.90      0.90        73\n",
      "\n",
      "[13  0  1  0  0 15  0  0  0  0 15  4  0  0  2 23]\n",
      "MNB Accuracy:  0.9041095890410958\n",
      "MNB F1:  0.9145972895972896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       1.00      0.93      0.97        15\n",
      "          2       1.00      0.79      0.88        19\n",
      "          3       0.78      1.00      0.88        25\n",
      "\n",
      "avg / total       0.93      0.90      0.91        73\n",
      "\n",
      "[12  0  0  2  0 14  0  1  0  0 15  4  0  0  0 25]\n",
      "svc Accuracy:  0.9041095890410958\n",
      "svc F1:  0.9120350220222111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        14\n",
      "          1       1.00      0.93      0.97        15\n",
      "          2       1.00      0.74      0.85        19\n",
      "          3       0.74      1.00      0.85        25\n",
      "\n",
      "avg / total       0.91      0.88      0.88        73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11  0  0  3  0 14  0  1  0  0 14  5  0  0  0 25]\n",
      "LR Accuracy:  0.8767123287671232\n",
      "LR F1:  0.8853649292457008\n",
      "For name:  w_lee\n",
      "total sample size before apply threshold:  590\n",
      "Counter({'0000-0003-3171-7672': 108, '0000-0001-5833-989X': 100, '0000-0003-3231-9764': 82, '0000-0002-1082-7592': 62, '0000-0003-3267-4811': 40, '0000-0001-7805-869X': 36, '0000-0003-2883-0391': 21, '0000-0002-0607-038X': 21, '0000-0002-5461-6770': 16, '0000-0002-3912-6095': 11, '0000-0001-6757-885X': 11, '0000-0001-6408-7668': 10, '0000-0002-9873-1033': 9, '0000-0001-7801-083X': 8, '0000-0001-8430-4797': 7, '0000-0002-2572-7287': 5, '0000-0002-6766-8481': 5, '0000-0001-8706-6026': 4, '0000-0002-0036-2859': 4, '0000-0002-9624-0505': 3, '0000-0002-3413-4029': 3, '0000-0003-1817-8395': 3, '0000-0003-1744-8525': 3, '0000-0001-8052-2420': 2, '0000-0003-0853-8561': 2, '0000-0001-7285-4054': 2, '0000-0001-9645-8179': 2, '0000-0002-4383-756X': 2, '0000-0003-1911-3454': 2, '0000-0003-4333-5444': 1, '0000-0002-7324-5792': 1, '0000-0002-2152-7210': 1, '0000-0003-4040-1100': 1, '0000-0003-0133-9076': 1, '0000-0002-7696-5517': 1})\n",
      "['0000-0001-7805-869X', '0000-0002-3912-6095', '0000-0003-2883-0391', '0000-0001-6408-7668', '0000-0003-3267-4811', '0000-0003-3171-7672', '0000-0003-3231-9764', '0000-0001-5833-989X', '0000-0002-0607-038X', '0000-0002-1082-7592', '0000-0001-6757-885X', '0000-0002-5461-6770']\n",
      "Total sample size after apply threshold:  518\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(518, 550)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "518\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.19      0.33        36\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.10      0.17        21\n",
      "          3       1.00      0.40      0.57        10\n",
      "          4       0.83      0.12      0.22        40\n",
      "          5       0.46      0.91      0.61       108\n",
      "          6       0.86      0.68      0.76        82\n",
      "          7       0.66      0.99      0.79       100\n",
      "          8       1.00      0.67      0.80        21\n",
      "          9       0.91      0.85      0.88        62\n",
      "         10       0.00      0.00      0.00        11\n",
      "         11       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.70      0.65      0.60       518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 7  0  0  0  0 13  0 15  0  1  0  0  0  0  0  0  0 10  0  1  0  0  0  0\n",
      "  0  0  2  0  0 18  1  0  0  0  0  0  0  0  0  4  0  0  0  5  0  1  0  0\n",
      "  0  0  0  0  5 34  1  0  0  0  0  0  0  0  0  0  1 98  7  2  0  0  0  0\n",
      "  0  0  0  0  0 26 56  0  0  0  0  0  0  0  0  0  0  0  0 99  0  1  0  0\n",
      "  0  0  0  0  0  7  0  0 14  0  0  0  0  0  0  0  0  2  0  7  0 53  0  0\n",
      "  0  0  0  0  0  2  0  8  0  1  0  0  0  0  0  0  0  1  0 14  0  1  0  0]\n",
      "MNB Accuracy:  0.6525096525096525\n",
      "MNB F1:  0.42806809117095507\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.67      0.79        36\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       1.00      0.43      0.60        21\n",
      "          3       1.00      0.70      0.82        10\n",
      "          4       0.71      0.68      0.69        40\n",
      "          5       0.56      0.88      0.68       108\n",
      "          6       0.87      0.71      0.78        82\n",
      "          7       0.89      0.98      0.93       100\n",
      "          8       1.00      0.71      0.83        21\n",
      "          9       0.91      0.94      0.92        62\n",
      "         10       0.00      0.00      0.00        11\n",
      "         11       1.00      0.69      0.81        16\n",
      "\n",
      "avg / total       0.81      0.78      0.77       518\n",
      "\n",
      "[24  0  0  0  0  8  0  2  0  2  0  0  0  1  0  0  0  9  0  1  0  0  0  0\n",
      "  0  0  9  0  0 12  0  0  0  0  0  0  0  0  0  7  0  0  0  3  0  0  0  0\n",
      "  0  0  0  0 27 10  3  0  0  0  0  0  0  0  0  0  7 95  6  0  0  0  0  0\n",
      "  0  0  0  0  4 20 58  0  0  0  0  0  0  0  0  0  0  0  0 98  0  2  0  0\n",
      "  0  0  0  0  0  6  0  0 15  0  0  0  1  0  0  0  0  3  0  0  0 58  0  0\n",
      "  0  0  0  0  0  5  0  5  0  1  0  0  0  0  0  0  0  3  0  1  0  1  0 11]\n",
      "svc Accuracy:  0.777992277992278\n",
      "svc F1:  0.6692527077432818\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        36\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.29      0.44        21\n",
      "          3       1.00      0.70      0.82        10\n",
      "          4       0.71      0.50      0.59        40\n",
      "          5       0.50      0.88      0.64       108\n",
      "          6       0.82      0.67      0.74        82\n",
      "          7       0.86      0.98      0.92       100\n",
      "          8       1.00      0.71      0.83        21\n",
      "          9       0.88      0.90      0.89        62\n",
      "         10       0.00      0.00      0.00        11\n",
      "         11       1.00      0.56      0.72        16\n",
      "\n",
      "avg / total       0.76      0.73      0.71       518\n",
      "\n",
      "[17  0  0  0  0 14  1  3  0  1  0  0  0  0  0  0  0 10  0  1  0  0  0  0\n",
      "  0  0  6  0  0 15  0  0  0  0  0  0  0  0  0  7  0  0  0  2  0  1  0  0\n",
      "  0  0  0  0 20 16  4  0  0  0  0  0  0  0  0  0  6 95  7  0  0  0  0  0\n",
      "  0  0  0  0  2 25 55  0  0  0  0  0  0  0  0  0  0  0  0 98  0  2  0  0\n",
      "  0  0  0  0  0  6  0  0 15  0  0  0  0  0  0  0  0  3  0  3  0 56  0  0\n",
      "  0  0  0  0  0  4  0  5  0  2  0  0  0  0  0  0  0  3  0  2  0  2  0  9]\n",
      "LR Accuracy:  0.7297297297297297\n",
      "LR F1:  0.6024612662960285\n",
      "For name:  j_cheng\n",
      "total sample size before apply threshold:  66\n",
      "Counter({'0000-0003-1786-6188': 19, '0000-0001-8285-3207': 16, '0000-0001-5318-5668': 8, '0000-0002-7004-5138': 6, '0000-0003-3928-1770': 6, '0000-0002-1881-012X': 5, '0000-0002-4364-9657': 3, '0000-0002-1722-2617': 1, '0000-0002-5434-1201': 1, '0000-0001-6065-2682': 1})\n",
      "['0000-0003-1786-6188', '0000-0001-8285-3207']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 76)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00        35\n",
      "\n",
      "[19  0  0 16]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        19\n",
      "          1       0.94      1.00      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        35\n",
      "\n",
      "[18  1  0 16]\n",
      "svc Accuracy:  0.9714285714285714\n",
      "svc F1:  0.9713349713349714\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        19\n",
      "          1       0.94      0.94      0.94        16\n",
      "\n",
      "avg / total       0.94      0.94      0.94        35\n",
      "\n",
      "[18  1  1 15]\n",
      "LR Accuracy:  0.9428571428571428\n",
      "LR F1:  0.9424342105263157\n",
      "For name:  g_lewis\n",
      "total sample size before apply threshold:  367\n",
      "Counter({'0000-0001-5205-8245': 343, '0000-0002-2548-8423': 12, '0000-0003-3081-9319': 7, '0000-0003-4112-5048': 5})\n",
      "['0000-0002-2548-8423', '0000-0001-5205-8245']\n",
      "Total sample size after apply threshold:  355\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(355, 707)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.97      1.00      0.98       343\n",
      "\n",
      "avg / total       0.93      0.96      0.95       355\n",
      "\n",
      "[  0  12   1 342]\n",
      "MNB Accuracy:  0.9633802816901409\n",
      "MNB F1:  0.49067431850789095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       1.00      1.00      1.00       343\n",
      "\n",
      "avg / total       1.00      1.00      1.00       355\n",
      "\n",
      "[ 11   1   0 343]\n",
      "svc Accuracy:  0.9971830985915493\n",
      "svc F1:  0.9775330675273717\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.97      1.00      0.98       343\n",
      "\n",
      "avg / total       0.93      0.97      0.95       355\n",
      "\n",
      "[  0  12   0 343]\n",
      "LR Accuracy:  0.9661971830985916\n",
      "LR F1:  0.49140401146131807\n",
      "For name:  j_albert\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0002-3420-7371': 40, '0000-0001-6538-9801': 19, '0000-0001-5330-1892': 13, '0000-0002-8256-2650': 6})\n",
      "['0000-0002-3420-7371', '0000-0001-6538-9801', '0000-0001-5330-1892']\n",
      "Total sample size after apply threshold:  72\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 249)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        40\n",
      "          1       1.00      0.95      0.97        19\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.97      0.97      0.97        72\n",
      "\n",
      "[40  0  0  1 18  0  1  0 12]\n",
      "MNB Accuracy:  0.9722222222222222\n",
      "MNB F1:  0.9695275763568447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        40\n",
      "          1       1.00      0.95      0.97        19\n",
      "          2       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.97      0.97      0.97        72\n",
      "\n",
      "[40  0  0  1 18  0  1  0 12]\n",
      "svc Accuracy:  0.9722222222222222\n",
      "svc F1:  0.9695275763568447\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        40\n",
      "          1       1.00      0.84      0.91        19\n",
      "          2       1.00      0.38      0.56        13\n",
      "\n",
      "avg / total       0.88      0.85      0.83        72\n",
      "\n",
      "[40  0  0  3 16  0  8  0  5]\n",
      "LR Accuracy:  0.8472222222222222\n",
      "LR F1:  0.782987382987383\n",
      "For name:  k_goh\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-2839-8722': 22, '0000-0002-3623-4891': 5, '0000-0003-0599-9696': 5, '0000-0001-5499-5187': 4, '0000-0002-2367-8303': 3, '0000-0001-5416-9627': 2, '0000-0002-8265-3421': 1})\n",
      "['0000-0002-2839-8722']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  n_harris\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-1320-282X': 5, '0000-0003-1256-3006': 4, '0000-0002-3443-3643': 2, '0000-0002-1965-6750': 2, '0000-0001-9664-2769': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_hill\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0002-4424-239X': 118, '0000-0002-6474-0214': 12, '0000-0003-3010-8998': 7, '0000-0002-5909-692X': 5, '0000-0002-2995-2596': 4, '0000-0001-8055-860X': 3, '0000-0001-6742-3620': 2, '0000-0002-3305-6954': 1})\n",
      "['0000-0002-4424-239X', '0000-0002-6474-0214']\n",
      "Total sample size after apply threshold:  130\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 182)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "130\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       118\n",
      "          1       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.82      0.91      0.86       130\n",
      "\n",
      "[118   0  12   0]\n",
      "MNB Accuracy:  0.9076923076923077\n",
      "MNB F1:  0.47580645161290325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98       118\n",
      "          1       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97       130\n",
      "\n",
      "[118   0   4   8]\n",
      "svc Accuracy:  0.9692307692307692\n",
      "svc F1:  0.8916666666666666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       118\n",
      "          1       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.82      0.91      0.86       130\n",
      "\n",
      "[118   0  12   0]\n",
      "LR Accuracy:  0.9076923076923077\n",
      "LR F1:  0.47580645161290325\n",
      "For name:  p_pathak\n",
      "total sample size before apply threshold:  9\n",
      "Counter({'0000-0003-0118-3235': 4, '0000-0002-1157-5550': 3, '0000-0002-9771-6624': 1, '0000-0003-2152-3938': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_zeng\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0002-8246-2000': 42, '0000-0002-0260-1059': 21, '0000-0002-9909-7732': 6, '0000-0002-9150-214X': 6, '0000-0003-0293-7692': 4, '0000-0002-7657-6714': 3})\n",
      "['0000-0002-0260-1059', '0000-0002-8246-2000']\n",
      "Total sample size after apply threshold:  63\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 118)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.81      0.87        21\n",
      "          1       0.91      0.98      0.94        42\n",
      "\n",
      "avg / total       0.92      0.92      0.92        63\n",
      "\n",
      "[17  4  1 41]\n",
      "MNB Accuracy:  0.9206349206349206\n",
      "MNB F1:  0.9071618037135278\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        21\n",
      "          1       0.88      1.00      0.93        42\n",
      "\n",
      "avg / total       0.92      0.90      0.90        63\n",
      "\n",
      "[15  6  0 42]\n",
      "svc Accuracy:  0.9047619047619048\n",
      "svc F1:  0.8833333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.52      0.69        21\n",
      "          1       0.81      1.00      0.89        42\n",
      "\n",
      "avg / total       0.87      0.84      0.82        63\n",
      "\n",
      "[11 10  0 42]\n",
      "LR Accuracy:  0.8412698412698413\n",
      "LR F1:  0.790558510638298\n",
      "For name:  h_liu\n",
      "total sample size before apply threshold:  439\n",
      "Counter({'0000-0001-6715-6366': 100, '0000-0002-0253-647X': 45, '0000-0002-1006-6666': 39, '0000-0001-7639-0904': 39, '0000-0002-7233-1509': 31, '0000-0001-9366-6204': 26, '0000-0002-4723-845X': 18, '0000-0003-3326-2640': 17, '0000-0002-3745-7202': 13, '0000-0003-4837-5373': 11, '0000-0003-3103-6949': 10, '0000-0002-4548-2002': 9, '0000-0003-0266-9472': 9, '0000-0001-7984-6305': 8, '0000-0002-7645-0855': 8, '0000-0003-2394-5421': 7, '0000-0001-5451-6828': 6, '0000-0002-1852-4537': 5, '0000-0003-2183-9609': 3, '0000-0003-1837-1435': 3, '0000-0002-2781-2637': 3, '0000-0001-8959-0315': 3, '0000-0003-1313-4000': 3, '0000-0003-1724-4418': 2, '0000-0003-0345-6647': 2, '0000-0001-8519-3240': 2, '0000-0002-3292-9303': 2, '0000-0003-1679-6560': 2, '0000-0003-4341-672X': 2, '0000-0001-8806-6204': 1, '0000-0003-3125-4399': 1, '0000-0002-5450-5958': 1, '0000-0003-0658-4425': 1, '0000-0002-6370-0704': 1, '0000-0001-6604-5509': 1, '0000-0002-6009-8797': 1, '0000-0003-4566-2107': 1, '0000-0003-3055-5528': 1, '0000-0002-5437-4695': 1, '0000-0003-3607-7176': 1})\n",
      "['0000-0003-4837-5373', '0000-0002-1006-6666', '0000-0003-3326-2640', '0000-0002-3745-7202', '0000-0001-6715-6366', '0000-0001-9366-6204', '0000-0002-0253-647X', '0000-0002-4723-845X', '0000-0001-7639-0904', '0000-0003-3103-6949', '0000-0002-7233-1509']\n",
      "Total sample size after apply threshold:  349\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(349, 633)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "349\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.44      0.61        39\n",
      "          2       0.00      0.00      0.00        17\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.49      1.00      0.66       100\n",
      "          5       1.00      0.77      0.87        26\n",
      "          6       0.83      0.76      0.79        45\n",
      "          7       1.00      0.39      0.56        18\n",
      "          8       0.77      0.85      0.80        39\n",
      "          9       0.00      0.00      0.00        10\n",
      "         10       1.00      0.58      0.73        31\n",
      "\n",
      "avg / total       0.66      0.66      0.61       349\n",
      "\n",
      "[  0   0   0   0  11   0   0   0   0   0   0   0  17   0   0  19   0   2\n",
      "   0   1   0   0   0   0   0   0  17   0   0   0   0   0   0   0   0   0\n",
      "   0  11   0   2   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "   0   0   0   0   0   6  20   0   0   0   0   0   0   0   0   0  10   0\n",
      "  34   0   1   0   0   0   0   0   0   4   0   1   7   6   0   0   0   0\n",
      "   0   0   6   0   0   0  33   0   0   0   0   0   0  10   0   0   0   0\n",
      "   0   0   0   0   0   0   9   0   2   0   2   0  18]\n",
      "MNB Accuracy:  0.6561604584527221\n",
      "MNB F1:  0.45700397108044866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.78      0.90      0.83        39\n",
      "          2       1.00      0.76      0.87        17\n",
      "          3       1.00      0.54      0.70        13\n",
      "          4       0.80      1.00      0.89       100\n",
      "          5       1.00      0.92      0.96        26\n",
      "          6       0.98      0.91      0.94        45\n",
      "          7       0.88      0.78      0.82        18\n",
      "          8       0.92      0.92      0.92        39\n",
      "          9       1.00      0.30      0.46        10\n",
      "         10       0.96      0.87      0.92        31\n",
      "\n",
      "avg / total       0.90      0.88      0.87       349\n",
      "\n",
      "[  7   0   0   0   4   0   0   0   0   0   0   0  35   0   0   2   0   0\n",
      "   1   1   0   0   0   0  13   0   3   0   0   1   0   0   0   0   0   0\n",
      "   7   6   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "   0   0   0   0   0   2  24   0   0   0   0   0   0   1   0   0   2   0\n",
      "  41   0   1   0   0   0   2   0   0   0   0   0  14   1   0   1   0   2\n",
      "   0   0   1   0   0   0  36   0   0   0   2   0   0   5   0   0   0   0\n",
      "   3   0   0   3   0   0   0   0   1   0   0   0  27]\n",
      "svc Accuracy:  0.8796561604584527\n",
      "svc F1:  0.8265994941788251\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       0.83      0.64      0.72        39\n",
      "          2       1.00      0.53      0.69        17\n",
      "          3       1.00      0.15      0.27        13\n",
      "          4       0.64      1.00      0.78       100\n",
      "          5       1.00      0.85      0.92        26\n",
      "          6       0.91      0.89      0.90        45\n",
      "          7       0.92      0.67      0.77        18\n",
      "          8       0.77      0.87      0.82        39\n",
      "          9       0.00      0.00      0.00        10\n",
      "         10       0.96      0.81      0.88        31\n",
      "\n",
      "avg / total       0.80      0.78      0.75       349\n",
      "\n",
      "[  2   0   0   0   9   0   0   0   0   0   0   0  25   0   0   8   0   0\n",
      "   1   5   0   0   0   0   9   0   8   0   0   0   0   0   0   0   2   0\n",
      "   2   9   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "   0   0   0   0   0   4  22   0   0   0   0   0   0   1   0   0   3   0\n",
      "  40   0   1   0   0   0   0   0   0   1   0   1  12   3   0   1   0   1\n",
      "   0   0   3   0   1   0  34   0   0   0   0   0   0  10   0   0   0   0\n",
      "   0   0   0   1   0   0   2   0   2   0   1   0  25]\n",
      "LR Accuracy:  0.7765042979942693\n",
      "LR F1:  0.641429197726875\n",
      "For name:  s_bae\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0003-0551-7618': 19, '0000-0002-3019-0584': 17, '0000-0002-4995-6543': 17, '0000-0002-8993-8884': 9, '0000-0003-0098-8816': 8, '0000-0003-1926-5466': 6, '0000-0001-7603-7676': 6, '0000-0003-0637-4110': 1})\n",
      "['0000-0003-0551-7618', '0000-0002-3019-0584', '0000-0002-4995-6543']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 92)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        19\n",
      "          1       0.86      0.35      0.50        17\n",
      "          2       0.64      0.94      0.76        17\n",
      "\n",
      "avg / total       0.80      0.77      0.75        53\n",
      "\n",
      "[19  0  0  2  6  9  0  1 16]\n",
      "MNB Accuracy:  0.7735849056603774\n",
      "MNB F1:  0.7373015873015873\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       0.93      0.82      0.87        17\n",
      "          2       0.84      0.94      0.89        17\n",
      "\n",
      "avg / total       0.93      0.92      0.92        53\n",
      "\n",
      "[19  0  0  0 14  3  0  1 16]\n",
      "svc Accuracy:  0.9245283018867925\n",
      "svc F1:  0.9212962962962963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        19\n",
      "          1       0.88      0.82      0.85        17\n",
      "          2       0.88      0.88      0.88        17\n",
      "\n",
      "avg / total       0.90      0.91      0.90        53\n",
      "\n",
      "[19  0  0  1 14  2  0  2 15]\n",
      "LR Accuracy:  0.9056603773584906\n",
      "LR F1:  0.9017322546734311\n",
      "For name:  s_fernandes\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0003-1128-833X': 20, '0000-0002-1295-5010': 6, '0000-0002-9035-793X': 5, '0000-0002-7871-6717': 5, '0000-0002-0790-303X': 2})\n",
      "['0000-0003-1128-833X']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  a_miller\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0002-7056-8502': 33, '0000-0001-8474-5090': 28, '0000-0002-7293-764X': 22, '0000-0002-0553-8470': 15, '0000-0001-9735-6609': 5, '0000-0001-8527-1595': 1, '0000-0002-1761-4143': 1, '0000-0002-3099-1648': 1, '0000-0002-0941-1717': 1, '0000-0001-9739-8462': 1, '0000-0003-0924-8443': 1})\n",
      "['0000-0001-8474-5090', '0000-0002-0553-8470', '0000-0002-7056-8502', '0000-0002-7293-764X']\n",
      "Total sample size after apply threshold:  98\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 283)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.79      0.79        28\n",
      "          1       1.00      0.80      0.89        15\n",
      "          2       0.72      0.88      0.79        33\n",
      "          3       0.94      0.77      0.85        22\n",
      "\n",
      "avg / total       0.83      0.82      0.82        98\n",
      "\n",
      "[22  0  6  0  2 12  0  1  4  0 29  0  0  0  5 17]\n",
      "MNB Accuracy:  0.8163265306122449\n",
      "MNB F1:  0.829780930637095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        28\n",
      "          1       1.00      0.87      0.93        15\n",
      "          2       0.72      1.00      0.84        33\n",
      "          3       0.94      0.73      0.82        22\n",
      "\n",
      "avg / total       0.89      0.86      0.86        98\n",
      "\n",
      "[22  0  6  0  0 13  1  1  0  0 33  0  0  0  6 16]\n",
      "svc Accuracy:  0.8571428571428571\n",
      "svc F1:  0.8661318217647331\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.64      0.71        28\n",
      "          1       1.00      0.80      0.89        15\n",
      "          2       0.62      0.91      0.74        33\n",
      "          3       1.00      0.68      0.81        22\n",
      "\n",
      "avg / total       0.81      0.77      0.77        98\n",
      "\n",
      "[18  0 10  0  2 12  1  0  3  0 30  0  0  0  7 15]\n",
      "LR Accuracy:  0.7653061224489796\n",
      "LR F1:  0.7865806983454042\n",
      "For name:  a_eklund\n",
      "total sample size before apply threshold:  118\n",
      "Counter({'0000-0002-2031-722X': 73, '0000-0003-0861-1001': 40, '0000-0003-1271-1814': 4, '0000-0002-2162-7537': 1})\n",
      "['0000-0003-0861-1001', '0000-0002-2031-722X']\n",
      "Total sample size after apply threshold:  113\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(113, 438)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "113\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        40\n",
      "          1       0.90      1.00      0.95        73\n",
      "\n",
      "avg / total       0.94      0.93      0.93       113\n",
      "\n",
      "[32  8  0 73]\n",
      "MNB Accuracy:  0.9292035398230089\n",
      "MNB F1:  0.9184704184704184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        40\n",
      "          1       1.00      1.00      1.00        73\n",
      "\n",
      "avg / total       1.00      1.00      1.00       113\n",
      "\n",
      "[40  0  0 73]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        40\n",
      "          1       0.94      1.00      0.97        73\n",
      "\n",
      "avg / total       0.96      0.96      0.96       113\n",
      "\n",
      "[35  5  0 73]\n",
      "LR Accuracy:  0.9557522123893806\n",
      "LR F1:  0.9501103752759382\n",
      "For name:  r_moore\n",
      "total sample size before apply threshold:  221\n",
      "Counter({'0000-0002-0776-5861': 75, '0000-0001-7221-6693': 51, '0000-0003-1072-2755': 45, '0000-0003-2027-2428': 44, '0000-0003-4196-1804': 6})\n",
      "['0000-0003-2027-2428', '0000-0003-1072-2755', '0000-0001-7221-6693', '0000-0002-0776-5861']\n",
      "Total sample size after apply threshold:  215\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(215, 579)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "215\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        44\n",
      "          1       1.00      0.87      0.93        45\n",
      "          2       0.96      0.96      0.96        51\n",
      "          3       0.80      0.99      0.88        75\n",
      "\n",
      "avg / total       0.92      0.90      0.90       215\n",
      "\n",
      "[32  0  0 12  0 39  1  5  0  0 49  2  0  0  1 74]\n",
      "MNB Accuracy:  0.9023255813953488\n",
      "MNB F1:  0.9031033466017987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        44\n",
      "          1       1.00      0.82      0.90        45\n",
      "          2       1.00      0.96      0.98        51\n",
      "          3       0.81      1.00      0.89        75\n",
      "\n",
      "avg / total       0.93      0.92      0.92       215\n",
      "\n",
      "[36  0  0  8  0 37  0  8  0  0 49  2  0  0  0 75]\n",
      "svc Accuracy:  0.9162790697674419\n",
      "svc F1:  0.9188240418118466\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        44\n",
      "          1       1.00      0.78      0.88        45\n",
      "          2       1.00      0.96      0.98        51\n",
      "          3       0.70      1.00      0.82        75\n",
      "\n",
      "avg / total       0.90      0.85      0.85       215\n",
      "\n",
      "[24  0  0 20  0 35  0 10  0  0 49  2  0  0  0 75]\n",
      "LR Accuracy:  0.8511627906976744\n",
      "LR F1:  0.8462645442792502\n",
      "For name:  m_thomsen\n",
      "total sample size before apply threshold:  98\n",
      "Counter({'0000-0002-2469-6458': 37, '0000-0003-2453-5141': 32, '0000-0001-6805-7247': 17, '0000-0003-3081-9220': 7, '0000-0003-3814-1709': 3, '0000-0003-1208-5497': 2})\n",
      "['0000-0003-2453-5141', '0000-0002-2469-6458', '0000-0001-6805-7247']\n",
      "Total sample size after apply threshold:  86\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 213)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94        32\n",
      "          1       0.87      0.92      0.89        37\n",
      "          2       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.91      0.91      0.91        86\n",
      "\n",
      "[31  1  0  3 34  0  0  4 13]\n",
      "MNB Accuracy:  0.9069767441860465\n",
      "MNB F1:  0.9002658160552898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.91      0.94        32\n",
      "          1       0.82      0.97      0.89        37\n",
      "          2       1.00      0.71      0.83        17\n",
      "\n",
      "avg / total       0.91      0.90      0.89        86\n",
      "\n",
      "[29  3  0  1 36  0  0  5 12]\n",
      "svc Accuracy:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8953488372093024\n",
      "svc F1:  0.8839863222510608\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        32\n",
      "          1       0.74      0.95      0.83        37\n",
      "          2       1.00      0.41      0.58        17\n",
      "\n",
      "avg / total       0.87      0.84      0.82        86\n",
      "\n",
      "[30  2  0  2 35  0  0 10  7]\n",
      "LR Accuracy:  0.8372093023255814\n",
      "LR F1:  0.7847222222222223\n",
      "For name:  l_ng\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0003-1905-3586': 37, '0000-0002-6973-9466': 3, '0000-0001-7500-9403': 1, '0000-0001-5988-008X': 1, '0000-0003-3135-244X': 1, '0000-0002-7189-1272': 1})\n",
      "['0000-0003-1905-3586']\n",
      "Total sample size after apply threshold:  37\n",
      "For name:  a_phillips\n",
      "total sample size before apply threshold:  170\n",
      "Counter({'0000-0002-5461-0598': 98, '0000-0001-6367-9784': 24, '0000-0001-5599-6499': 24, '0000-0003-4883-0022': 9, '0000-0003-4225-0158': 7, '0000-0003-4473-5108': 4, '0000-0001-6618-0145': 3, '0000-0001-6335-9430': 1})\n",
      "['0000-0001-6367-9784', '0000-0001-5599-6499', '0000-0002-5461-0598']\n",
      "Total sample size after apply threshold:  146\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(146, 333)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "146\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        24\n",
      "          1       1.00      0.58      0.74        24\n",
      "          2       0.82      1.00      0.90        98\n",
      "\n",
      "avg / total       0.88      0.85      0.83       146\n",
      "\n",
      "[12  0 12  0 14 10  0  0 98]\n",
      "MNB Accuracy:  0.8493150684931506\n",
      "MNB F1:  0.7675304469123879\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        24\n",
      "          1       1.00      0.83      0.91        24\n",
      "          2       0.92      1.00      0.96        98\n",
      "\n",
      "avg / total       0.94      0.94      0.94       146\n",
      "\n",
      "[19  0  5  0 20  4  0  0 98]\n",
      "svc Accuracy:  0.9383561643835616\n",
      "svc F1:  0.9163031334330256\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.55        24\n",
      "          1       1.00      0.54      0.70        24\n",
      "          2       0.79      1.00      0.88        98\n",
      "\n",
      "avg / total       0.86      0.82      0.80       146\n",
      "\n",
      "[ 9  0 15  0 13 11  0  0 98]\n",
      "LR Accuracy:  0.821917808219178\n",
      "LR F1:  0.7103467103467103\n",
      "For name:  y_ye\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0002-7517-1715': 75, '0000-0002-2029-4558': 8, '0000-0003-3962-8463': 1, '0000-0002-9172-6514': 1})\n",
      "['0000-0002-7517-1715']\n",
      "Total sample size after apply threshold:  75\n",
      "For name:  m_guerreiro\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0002-1948-1516': 23, '0000-0002-5133-8779': 6, '0000-0002-2863-887X': 6, '0000-0001-6774-9348': 1})\n",
      "['0000-0002-1948-1516']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  g_alves\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0002-4213-0714': 40, '0000-0003-0630-2870': 12, '0000-0003-3945-9962': 7, '0000-0003-4985-5555': 1})\n",
      "['0000-0003-0630-2870', '0000-0002-4213-0714']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 99)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        40\n",
      "\n",
      "avg / total       1.00      1.00      1.00        52\n",
      "\n",
      "[12  0  0 40]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        40\n",
      "\n",
      "avg / total       1.00      1.00      1.00        52\n",
      "\n",
      "[12  0  0 40]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.87      1.00      0.93        40\n",
      "\n",
      "avg / total       0.90      0.88      0.87        52\n",
      "\n",
      "[ 6  6  0 40]\n",
      "LR Accuracy:  0.8846153846153846\n",
      "LR F1:  0.7984496124031008\n",
      "For name:  m_mohammed\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0003-3423-0085': 2, '0000-0002-1795-579X': 2, '0000-0002-9695-396X': 1, '0000-0002-7103-0165': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_mohammadi\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0003-1311-9636': 42, '0000-0003-0650-6654': 13, '0000-0003-3450-6424': 1, '0000-0003-1658-9756': 1, '0000-0002-6656-025X': 1, '0000-0002-9209-3034': 1})\n",
      "['0000-0003-0650-6654', '0000-0003-1311-9636']\n",
      "Total sample size after apply threshold:  55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 148)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.95      1.00      0.98        42\n",
      "\n",
      "avg / total       0.97      0.96      0.96        55\n",
      "\n",
      "[11  2  0 42]\n",
      "MNB Accuracy:  0.9636363636363636\n",
      "MNB F1:  0.9467054263565892\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.95      1.00      0.98        42\n",
      "\n",
      "avg / total       0.97      0.96      0.96        55\n",
      "\n",
      "[11  2  0 42]\n",
      "svc Accuracy:  0.9636363636363636\n",
      "svc F1:  0.9467054263565892\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.56        13\n",
      "          1       0.84      1.00      0.91        42\n",
      "\n",
      "avg / total       0.88      0.85      0.83        55\n",
      "\n",
      "[ 5  8  0 42]\n",
      "LR Accuracy:  0.8545454545454545\n",
      "LR F1:  0.7342995169082126\n",
      "For name:  c_chao\n",
      "total sample size before apply threshold:  155\n",
      "Counter({'0000-0003-2892-7986': 86, '0000-0002-2804-7447': 34, '0000-0001-6499-5789': 19, '0000-0002-8789-7732': 7, '0000-0001-7769-9305': 7, '0000-0003-1215-8588': 1, '0000-0003-4108-2658': 1})\n",
      "['0000-0002-2804-7447', '0000-0003-2892-7986', '0000-0001-6499-5789']\n",
      "Total sample size after apply threshold:  139\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 106)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.56      0.72        34\n",
      "          1       0.79      1.00      0.88        86\n",
      "          2       1.00      0.58      0.73        19\n",
      "\n",
      "avg / total       0.87      0.83      0.82       139\n",
      "\n",
      "[19 15  0  0 86  0  0  8 11]\n",
      "MNB Accuracy:  0.8345323741007195\n",
      "MNB F1:  0.7774552491533623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.79      0.84        34\n",
      "          1       0.90      0.98      0.94        86\n",
      "          2       1.00      0.84      0.91        19\n",
      "\n",
      "avg / total       0.92      0.91      0.91       139\n",
      "\n",
      "[27  7  0  2 84  0  1  2 16]\n",
      "svc Accuracy:  0.9136690647482014\n",
      "svc F1:  0.8988610667730779\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.59      0.70        34\n",
      "          1       0.80      0.98      0.88        86\n",
      "          2       1.00      0.58      0.73        19\n",
      "\n",
      "avg / total       0.84      0.83      0.82       139\n",
      "\n",
      "[20 14  0  2 84  0  1  7 11]\n",
      "LR Accuracy:  0.8273381294964028\n",
      "LR F1:  0.7715562903769021\n",
      "For name:  s_teixeira\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0003-0419-2348': 12, '0000-0001-5845-058X': 11, '0000-0002-2462-8535': 3, '0000-0002-9473-0113': 3, '0000-0002-7464-3944': 3, '0000-0002-6603-7936': 3, '0000-0003-3664-2577': 1})\n",
      "['0000-0003-0419-2348', '0000-0001-5845-058X']\n",
      "Total sample size after apply threshold:  23\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 99)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "23\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        12\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.87      0.83      0.82        23\n",
      "\n",
      "[12  0  4  7]\n",
      "MNB Accuracy:  0.8260869565217391\n",
      "MNB F1:  0.8174603174603174\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        23\n",
      "\n",
      "[12  0  0 11]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        23\n",
      "\n",
      "[12  0  0 11]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  l_almeida\n",
      "total sample size before apply threshold:  133\n",
      "Counter({'0000-0002-4861-8649': 57, '0000-0002-7769-4712': 43, '0000-0003-1370-961X': 12, '0000-0003-0370-214X': 8, '0000-0002-0651-7014': 5, '0000-0001-9346-7520': 4, '0000-0002-1324-0068': 1, '0000-0002-9544-3028': 1, '0000-0003-4711-4454': 1, '0000-0002-0921-887X': 1})\n",
      "['0000-0003-1370-961X', '0000-0002-4861-8649', '0000-0002-7769-4712']\n",
      "Total sample size after apply threshold:  112\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(112, 197)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "112\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.97      0.98      0.97        57\n",
      "          2       0.90      1.00      0.95        43\n",
      "\n",
      "avg / total       0.94      0.94      0.93       112\n",
      "\n",
      "[ 6  2  4  0 56  1  0  0 43]\n",
      "MNB Accuracy:  0.9375\n",
      "MNB F1:  0.8618782183999576\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        12\n",
      "          1       0.98      0.98      0.98        57\n",
      "          2       1.00      1.00      1.00        43\n",
      "\n",
      "avg / total       0.98      0.98      0.98       112\n",
      "\n",
      "[11  1  0  1 56  0  0  0 43]\n",
      "svc Accuracy:  0.9821428571428571\n",
      "svc F1:  0.9663742690058479\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        12\n",
      "          1       0.97      1.00      0.98        57\n",
      "          2       0.90      1.00      0.95        43\n",
      "\n",
      "avg / total       0.94      0.94      0.93       112\n",
      "\n",
      "[ 5  2  5  0 57  0  0  0 43]\n",
      "LR Accuracy:  0.9375\n",
      "LR F1:  0.8386829532874157\n",
      "For name:  y_tseng\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-8461-6181': 45, '0000-0002-2354-5906': 9, '0000-0001-6917-893X': 2, '0000-0002-3803-7410': 2, '0000-0002-1814-5553': 2, '0000-0002-3511-7191': 1})\n",
      "['0000-0002-8461-6181']\n",
      "Total sample size after apply threshold:  45\n",
      "For name:  a_ferro\n",
      "total sample size before apply threshold:  125\n",
      "Counter({'0000-0002-5486-9145': 91, '0000-0003-2399-3626': 11, '0000-0001-6042-4591': 10, '0000-0003-4470-079X': 7, '0000-0001-8403-9823': 4, '0000-0002-9431-5788': 2})\n",
      "['0000-0001-6042-4591', '0000-0002-5486-9145', '0000-0003-2399-3626']\n",
      "Total sample size after apply threshold:  112\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(112, 289)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.88      1.00      0.94        91\n",
      "          2       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.91      0.89      0.87       112\n",
      "\n",
      "[ 3  7  0  0 91  0  0  5  6]\n",
      "MNB Accuracy:  0.8928571428571429\n",
      "MNB F1:  0.7018550481255149\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.93      1.00      0.96        91\n",
      "          2       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.94      0.94      0.93       112\n",
      "\n",
      "[ 8  2  0  0 91  0  0  5  6]\n",
      "svc Accuracy:  0.9375\n",
      "svc F1:  0.8525780682643429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.81      1.00      0.90        91\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.66      0.81      0.73       112\n",
      "\n",
      "[ 0 10  0  0 91  0  0 11  0]\n",
      "LR Accuracy:  0.8125\n",
      "LR F1:  0.2988505747126437\n",
      "For name:  d_he\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0003-3253-654X': 17, '0000-0003-2212-1973': 4, '0000-0002-9947-6177': 3, '0000-0002-2446-7436': 2, '0000-0002-4001-826X': 2, '0000-0002-3360-9352': 1})\n",
      "['0000-0003-3253-654X']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  k_ko\n",
      "total sample size before apply threshold:  168\n",
      "Counter({'0000-0002-0978-1937': 153, '0000-0003-3649-4594': 11, '0000-0002-6412-1026': 2, '0000-0002-0192-0269': 1, '0000-0002-0515-5904': 1})\n",
      "['0000-0003-3649-4594', '0000-0002-0978-1937']\n",
      "Total sample size after apply threshold:  164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(164, 224)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "164\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.93      0.99      0.96       153\n",
      "\n",
      "avg / total       0.87      0.92      0.89       164\n",
      "\n",
      "[  0  11   2 151]\n",
      "MNB Accuracy:  0.9207317073170732\n",
      "MNB F1:  0.4793650793650794\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       0.94      1.00      0.97       153\n",
      "\n",
      "avg / total       0.95      0.95      0.93       164\n",
      "\n",
      "[  2   9   0 153]\n",
      "svc Accuracy:  0.9451219512195121\n",
      "svc F1:  0.6395604395604395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.93      1.00      0.97       153\n",
      "\n",
      "avg / total       0.87      0.93      0.90       164\n",
      "\n",
      "[  0  11   0 153]\n",
      "LR Accuracy:  0.9329268292682927\n",
      "LR F1:  0.48264984227129337\n",
      "For name:  t_mori\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0003-3918-0873': 92, '0000-0002-0370-1924': 10, '0000-0001-5340-3282': 1, '0000-0001-7096-4161': 1})\n",
      "['0000-0002-0370-1924', '0000-0003-3918-0873']\n",
      "Total sample size after apply threshold:  102\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(102, 157)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.99      1.00      0.99        92\n",
      "\n",
      "avg / total       0.99      0.99      0.99       102\n",
      "\n",
      "[ 9  1  0 92]\n",
      "MNB Accuracy:  0.9901960784313726\n",
      "MNB F1:  0.9709815078236131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.99      1.00      0.99        92\n",
      "\n",
      "avg / total       0.99      0.99      0.99       102\n",
      "\n",
      "[ 9  1  0 92]\n",
      "svc Accuracy:  0.9901960784313726\n",
      "svc F1:  0.9709815078236131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.94      1.00      0.97        92\n",
      "\n",
      "avg / total       0.94      0.94      0.93       102\n",
      "\n",
      "[ 4  6  0 92]\n",
      "LR Accuracy:  0.9411764705882353\n",
      "LR F1:  0.7699248120300752\n",
      "For name:  p_lima\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-1252-2565': 8, '0000-0002-9739-0783': 8, '0000-0002-4323-3918': 4, '0000-0003-2081-571X': 2, '0000-0002-8962-8050': 1, '0000-0003-2937-9520': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_ferguson\n",
      "total sample size before apply threshold:  217\n",
      "Counter({'0000-0001-5045-819X': 174, '0000-0001-9302-5992': 35, '0000-0001-6448-8701': 4, '0000-0003-0612-6512': 3, '0000-0002-7400-7892': 1})\n",
      "['0000-0001-5045-819X', '0000-0001-9302-5992']\n",
      "Total sample size after apply threshold:  209\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(209, 856)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       174\n",
      "          1       1.00      0.66      0.79        35\n",
      "\n",
      "avg / total       0.95      0.94      0.94       209\n",
      "\n",
      "[174   0  12  23]\n",
      "MNB Accuracy:  0.9425837320574163\n",
      "MNB F1:  0.8798850574712643\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       174\n",
      "          1       1.00      0.77      0.87        35\n",
      "\n",
      "avg / total       0.96      0.96      0.96       209\n",
      "\n",
      "[174   0   8  27]\n",
      "svc Accuracy:  0.9617224880382775\n",
      "svc F1:  0.9242479159115622\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       174\n",
      "          1       1.00      0.26      0.41        35\n",
      "\n",
      "avg / total       0.89      0.88      0.84       209\n",
      "\n",
      "[174   0  26   9]\n",
      "LR Accuracy:  0.8755980861244019\n",
      "LR F1:  0.6697860962566844\n",
      "For name:  h_moreira\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-1487-0539': 13, '0000-0002-5481-0688': 10, '0000-0002-4674-5417': 3, '0000-0002-4556-5027': 1, '0000-0002-5588-374X': 1})\n",
      "['0000-0002-1487-0539', '0000-0002-5481-0688']\n",
      "Total sample size after apply threshold:  23\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 29)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "23\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.96      0.96      0.96        23\n",
      "\n",
      "[13  0  1  9]\n",
      "MNB Accuracy:  0.9565217391304348\n",
      "MNB F1:  0.9551656920077973\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.96      0.96      0.96        23\n",
      "\n",
      "[13  0  1  9]\n",
      "svc Accuracy:  0.9565217391304348\n",
      "svc F1:  0.9551656920077973\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.96      0.96      0.96        23\n",
      "\n",
      "[13  0  1  9]\n",
      "LR Accuracy:  0.9565217391304348\n",
      "LR F1:  0.9551656920077973\n",
      "For name:  s_yi\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0002-6656-6205': 29, '0000-0001-6333-4399': 19, '0000-0003-2689-8595': 11, '0000-0003-2804-7161': 3, '0000-0003-4932-8237': 3, '0000-0002-9190-5643': 2})\n",
      "['0000-0002-6656-6205', '0000-0003-2689-8595', '0000-0001-6333-4399']\n",
      "Total sample size after apply threshold:  59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 52)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.97      0.88        29\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       0.89      0.84      0.86        19\n",
      "\n",
      "avg / total       0.87      0.85      0.84        59\n",
      "\n",
      "[28  0  1  4  6  1  3  0 16]\n",
      "MNB Accuracy:  0.847457627118644\n",
      "MNB F1:  0.8152490726020138\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93        29\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       0.68      1.00      0.81        19\n",
      "\n",
      "avg / total       0.90      0.85      0.85        59\n",
      "\n",
      "[25  0  4  0  6  5  0  0 19]\n",
      "svc Accuracy:  0.847457627118644\n",
      "svc F1:  0.8134396390549915\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93        29\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       0.86      1.00      0.93        19\n",
      "\n",
      "avg / total       0.91      0.90      0.89        59\n",
      "\n",
      "[28  0  1  3  6  2  0  0 19]\n",
      "LR Accuracy:  0.8983050847457628\n",
      "LR F1:  0.8553483181890642\n",
      "For name:  q_liu\n",
      "total sample size before apply threshold:  264\n",
      "Counter({'0000-0001-8477-6452': 62, '0000-0001-8525-7961': 62, '0000-0002-1179-290X': 47, '0000-0002-8402-029X': 26, '0000-0001-5286-4423': 24, '0000-0003-3533-7140': 18, '0000-0003-4114-5540': 8, '0000-0002-3616-351X': 6, '0000-0002-2199-2999': 2, '0000-0003-1508-7172': 2, '0000-0003-0769-4642': 1, '0000-0001-9746-2938': 1, '0000-0002-6286-941X': 1, '0000-0002-7574-3752': 1, '0000-0002-4678-3333': 1, '0000-0002-8398-1021': 1, '0000-0002-7285-5425': 1})\n",
      "['0000-0002-1179-290X', '0000-0003-3533-7140', '0000-0001-8477-6452', '0000-0001-5286-4423', '0000-0002-8402-029X', '0000-0001-8525-7961']\n",
      "Total sample size after apply threshold:  239\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(239, 352)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.87      0.88        47\n",
      "          1       1.00      0.17      0.29        18\n",
      "          2       0.84      0.84      0.84        62\n",
      "          3       1.00      0.08      0.15        24\n",
      "          4       1.00      0.77      0.87        26\n",
      "          5       0.58      1.00      0.74        62\n",
      "\n",
      "avg / total       0.83      0.75      0.71       239\n",
      "\n",
      "[41  0  0  0  0  6  1  3  1  0  0 13  0  0 52  0  0 10  3  0  7  2  0 12\n",
      "  1  0  2  0 20  3  0  0  0  0  0 62]\n",
      "MNB Accuracy:  0.7531380753138075\n",
      "MNB F1:  0.6279418337623106\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.91      0.93        47\n",
      "          1       0.85      0.61      0.71        18\n",
      "          2       0.85      1.00      0.92        62\n",
      "          3       0.79      0.79      0.79        24\n",
      "          4       1.00      0.92      0.96        26\n",
      "          5       0.98      0.95      0.97        62\n",
      "\n",
      "avg / total       0.92      0.91      0.91       239\n",
      "\n",
      "[43  0  4  0  0  0  1 11  3  2  0  1  0  0 62  0  0  0  1  0  4 19  0  0\n",
      "  0  0  0  2 24  0  0  2  0  1  0 59]\n",
      "svc Accuracy:  0.9121338912133892\n",
      "svc F1:  0.880309721331629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.89      0.91        47\n",
      "          1       1.00      0.44      0.62        18\n",
      "          2       0.74      0.98      0.85        62\n",
      "          3       0.87      0.54      0.67        24\n",
      "          4       1.00      0.85      0.92        26\n",
      "          5       0.93      1.00      0.96        62\n",
      "\n",
      "avg / total       0.89      0.87      0.86       239\n",
      "\n",
      "[42  0  4  0  0  1  1  8  6  0  0  3  0  0 61  0  0  1  2  0  9 13  0  0\n",
      "  0  0  2  2 22  0  0  0  0  0  0 62]\n",
      "LR Accuracy:  0.8702928870292888\n",
      "LR F1:  0.8200373265464266\n",
      "For name:  m_ibrahim\n",
      "total sample size before apply threshold:  146\n",
      "Counter({'0000-0002-5756-5198': 20, '0000-0002-9698-0837': 19, '0000-0001-6509-2979': 17, '0000-0003-4614-7182': 15, '0000-0003-0257-860X': 14, '0000-0001-6019-5055': 9, '0000-0001-8657-3368': 9, '0000-0002-0116-597X': 6, '0000-0003-1412-2132': 6, '0000-0002-2603-8280': 5, '0000-0002-7762-1580': 5, '0000-0003-0623-5225': 4, '0000-0003-0468-617X': 3, '0000-0002-8854-8198': 3, '0000-0002-7925-4585': 2, '0000-0002-0021-5971': 2, '0000-0002-9288-2359': 2, '0000-0002-5121-7256': 1, '0000-0001-8433-7409': 1, '0000-0003-3407-4983': 1, '0000-0002-3425-600X': 1, '0000-0002-2953-2305': 1})\n",
      "['0000-0001-6509-2979', '0000-0003-4614-7182', '0000-0003-0257-860X', '0000-0002-9698-0837', '0000-0002-5756-5198']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 253)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89        17\n",
      "          1       1.00      0.33      0.50        15\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       0.60      0.95      0.73        19\n",
      "          4       0.91      1.00      0.95        20\n",
      "\n",
      "avg / total       0.86      0.80      0.78        85\n",
      "\n",
      "[16  0  0  1  0  1  5  0  8  1  2  0  9  3  0  0  0  0 18  1  0  0  0  0\n",
      " 20]\n",
      "MNB Accuracy:  0.8\n",
      "MNB F1:  0.771714482894607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        17\n",
      "          1       0.75      0.60      0.67        15\n",
      "          2       1.00      0.93      0.96        14\n",
      "          3       0.72      0.95      0.82        19\n",
      "          4       1.00      1.00      1.00        20\n",
      "\n",
      "avg / total       0.89      0.88      0.88        85\n",
      "\n",
      "[15  1  0  1  0  0  9  0  6  0  0  1 13  0  0  0  1  0 18  0  0  0  0  0\n",
      " 20]\n",
      "svc Accuracy:  0.8823529411764706\n",
      "svc F1:  0.8770622895622896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        17\n",
      "          1       1.00      0.40      0.57        15\n",
      "          2       1.00      0.79      0.88        14\n",
      "          3       0.62      0.95      0.75        19\n",
      "          4       0.87      1.00      0.93        20\n",
      "\n",
      "avg / total       0.88      0.84      0.83        85\n",
      "\n",
      "[16  0  0  1  0  0  6  0  8  1  0  0 11  2  1  0  0  0 18  1  0  0  0  0\n",
      " 20]\n",
      "LR Accuracy:  0.8352941176470589\n",
      "LR F1:  0.8202716198530153\n",
      "For name:  s_collins\n",
      "total sample size before apply threshold:  163\n",
      "Counter({'0000-0002-0193-2892': 43, '0000-0002-4276-5840': 38, '0000-0002-0648-7433': 24, '0000-0003-0204-5109': 15, '0000-0001-9989-8794': 13, '0000-0002-5245-6611': 10, '0000-0003-1571-7410': 9, '0000-0002-3110-1037': 7, '0000-0001-5503-7386': 2, '0000-0003-4721-0040': 2})\n",
      "['0000-0002-0193-2892', '0000-0002-4276-5840', '0000-0002-5245-6611', '0000-0003-0204-5109', '0000-0002-0648-7433', '0000-0001-9989-8794']\n",
      "Total sample size after apply threshold:  143\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(143, 693)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.98      0.73        43\n",
      "          1       0.93      1.00      0.96        38\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       1.00      0.47      0.64        15\n",
      "          4       1.00      0.71      0.83        24\n",
      "          5       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.79      0.77      0.74       143\n",
      "\n",
      "[42  1  0  0  0  0  0 38  0  0  0  0 10  0  0  0  0  0  8  0  0  7  0  0\n",
      "  6  1  0  0 17  0  6  1  0  0  0  6]\n",
      "MNB Accuracy:  0.7692307692307693\n",
      "MNB F1:  0.6316118292465626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.98      0.72        43\n",
      "          1       1.00      0.95      0.97        38\n",
      "          2       1.00      0.20      0.33        10\n",
      "          3       0.89      0.53      0.67        15\n",
      "          4       1.00      0.62      0.77        24\n",
      "          5       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.86      0.78      0.77       143\n",
      "\n",
      "[42  0  0  1  0  0  2 36  0  0  0  0  8  0  2  0  0  0  7  0  0  8  0  0\n",
      "  9  0  0  0 15  0  5  0  0  0  0  8]\n",
      "svc Accuracy:  0.7762237762237763\n",
      "svc F1:  0.7047077391904978\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.98      0.70        43\n",
      "          1       1.00      0.97      0.99        38\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.88      0.47      0.61        15\n",
      "          4       1.00      0.62      0.77        24\n",
      "          5       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.78      0.75      0.72       143\n",
      "\n",
      "[42  0  0  1  0  0  1 37  0  0  0  0 10  0  0  0  0  0  8  0  0  7  0  0\n",
      "  9  0  0  0 15  0  7  0  0  0  0  6]\n",
      "LR Accuracy:  0.7482517482517482\n",
      "LR F1:  0.616028672573295\n",
      "For name:  d_franco\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0002-5669-7164': 58, '0000-0002-0093-7042': 40, '0000-0003-3849-4272': 8, '0000-0001-5604-2531': 6, '0000-0002-8653-0488': 2, '0000-0002-2050-7883': 1})\n",
      "['0000-0002-0093-7042', '0000-0002-5669-7164']\n",
      "Total sample size after apply threshold:  98\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 228)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95        40\n",
      "          1       0.98      0.95      0.96        58\n",
      "\n",
      "avg / total       0.96      0.96      0.96        98\n",
      "\n",
      "[39  1  3 55]\n",
      "MNB Accuracy:  0.9591836734693877\n",
      "MNB F1:  0.9580658964484382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        40\n",
      "          1       0.95      1.00      0.97        58\n",
      "\n",
      "avg / total       0.97      0.97      0.97        98\n",
      "\n",
      "[37  3  0 58]\n",
      "svc Accuracy:  0.9693877551020408\n",
      "svc F1:  0.9679144385026738\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        40\n",
      "          1       0.91      1.00      0.95        58\n",
      "\n",
      "avg / total       0.94      0.94      0.94        98\n",
      "\n",
      "[34  6  0 58]\n",
      "LR Accuracy:  0.9387755102040817\n",
      "LR F1:  0.9348692955250332\n",
      "For name:  h_brown\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-8578-5510': 17, '0000-0002-0067-991X': 9, '0000-0003-4870-8369': 8, '0000-0001-7418-5536': 6, '0000-0001-6227-5147': 3, '0000-0001-9404-9515': 3, '0000-0003-2292-7766': 2})\n",
      "['0000-0001-8578-5510']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  s_martins\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0002-9396-5957': 18, '0000-0002-3720-2920': 15, '0000-0001-7217-6273': 15, '0000-0003-0237-6370': 12, '0000-0002-1812-8913': 8, '0000-0002-1874-0192': 7, '0000-0002-7733-4485': 5, '0000-0003-2122-0670': 3, '0000-0002-3526-3199': 1})\n",
      "['0000-0002-3720-2920', '0000-0003-0237-6370', '0000-0001-7217-6273', '0000-0002-9396-5957']\n",
      "Total sample size after apply threshold:  60\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 159)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "60\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        15\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       1.00      1.00      1.00        15\n",
      "          3       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.95      0.93      0.93        60\n",
      "\n",
      "[13  0  0  2  0 10  0  2  0  0 15  0  0  0  0 18]\n",
      "MNB Accuracy:  0.9333333333333333\n",
      "MNB F1:  0.9344155844155844\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       1.00      1.00      1.00        15\n",
      "          3       1.00      0.94      0.97        18\n",
      "\n",
      "avg / total       0.95      0.93      0.93        60\n",
      "\n",
      "[15  0  0  0  3  9  0  0  0  0 15  0  1  0  0 17]\n",
      "svc Accuracy:  0.9333333333333333\n",
      "svc F1:  0.9277310924369748\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        15\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       1.00      1.00      1.00        15\n",
      "          3       0.86      1.00      0.92        18\n",
      "\n",
      "avg / total       0.94      0.93      0.93        60\n",
      "\n",
      "[14  0  0  1  1  9  0  2  0  0 15  0  0  0  0 18]\n",
      "LR Accuracy:  0.9333333333333333\n",
      "LR F1:  0.9283882783882783\n",
      "For name:  m_ruiz\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0003-4174-6688': 40, '0000-0002-2734-2196': 32, '0000-0002-1530-9508': 9, '0000-0002-1337-0110': 5, '0000-0001-8617-667X': 4, '0000-0001-7492-9873': 3, '0000-0003-4419-1649': 3, '0000-0002-2926-702X': 3, '0000-0003-1437-5578': 2, '0000-0002-4670-9037': 2, '0000-0002-4917-1252': 2, '0000-0002-1286-6624': 2, '0000-0002-6799-1537': 1, '0000-0002-1116-206X': 1, '0000-0003-0118-668X': 1, '0000-0002-8527-4734': 1})\n",
      "['0000-0003-4174-6688', '0000-0002-2734-2196']\n",
      "Total sample size after apply threshold:  72\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 157)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        40\n",
      "          1       1.00      0.84      0.92        32\n",
      "\n",
      "avg / total       0.94      0.93      0.93        72\n",
      "\n",
      "[40  0  5 27]\n",
      "MNB Accuracy:  0.9305555555555556\n",
      "MNB F1:  0.9282153539381854\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        40\n",
      "          1       0.94      1.00      0.97        32\n",
      "\n",
      "avg / total       0.97      0.97      0.97        72\n",
      "\n",
      "[38  2  0 32]\n",
      "svc Accuracy:  0.9722222222222222\n",
      "svc F1:  0.9720279720279721\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        40\n",
      "          1       0.97      1.00      0.98        32\n",
      "\n",
      "avg / total       0.99      0.99      0.99        72\n",
      "\n",
      "[39  1  0 32]\n",
      "LR Accuracy:  0.9861111111111112\n",
      "LR F1:  0.9859785783836417\n",
      "For name:  a_levy\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0003-4770-1886': 13, '0000-0002-6709-4190': 6, '0000-0002-5856-8294': 3, '0000-0002-1521-658X': 1})\n",
      "['0000-0003-4770-1886']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  j_murray\n",
      "total sample size before apply threshold:  213\n",
      "Counter({'0000-0002-2282-3839': 78, '0000-0002-8897-0161': 32, '0000-0002-8992-7317': 23, '0000-0002-6928-2347': 23, '0000-0001-9314-2283': 18, '0000-0001-8224-679X': 13, '0000-0003-1941-9090': 11, '0000-0002-8577-7964': 8, '0000-0003-2994-4155': 3, '0000-0002-8741-4964': 1, '0000-0003-4390-1039': 1, '0000-0001-9721-992X': 1, '0000-0003-3000-9199': 1})\n",
      "['0000-0002-2282-3839', '0000-0001-9314-2283', '0000-0002-8992-7317', '0000-0003-1941-9090', '0000-0002-8897-0161', '0000-0001-8224-679X', '0000-0002-6928-2347']\n",
      "Total sample size after apply threshold:  198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(198, 651)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "198\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67        78\n",
      "          1       1.00      0.22      0.36        18\n",
      "          2       1.00      0.87      0.93        23\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.59      0.75        32\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.57      0.61      0.53       198\n",
      "\n",
      "[78  0  0  0  0  0  0 14  4  0  0  0  0  0  3  0 20  0  0  0  0 11  0  0\n",
      "  0  0  0  0 13  0  0  0 19  0  0 13  0  0  0  0  0  0 23  0  0  0  0  0\n",
      "  0]\n",
      "MNB Accuracy:  0.6111111111111112\n",
      "MNB F1:  0.38692783685532756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      1.00      0.78        78\n",
      "          1       1.00      0.56      0.71        18\n",
      "          2       1.00      0.91      0.95        23\n",
      "          3       1.00      0.45      0.62        11\n",
      "          4       1.00      0.69      0.81        32\n",
      "          5       1.00      0.46      0.63        13\n",
      "          6       0.92      0.52      0.67        23\n",
      "\n",
      "avg / total       0.85      0.78      0.77       198\n",
      "\n",
      "[78  0  0  0  0  0  0  8 10  0  0  0  0  0  2  0 21  0  0  0  0  6  0  0\n",
      "  5  0  0  0 10  0  0  0 22  0  0  6  0  0  0  0  6  1 11  0  0  0  0  0\n",
      " 12]\n",
      "svc Accuracy:  0.7777777777777778\n",
      "svc F1:  0.7415444565244317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      1.00      0.65        78\n",
      "          1       1.00      0.17      0.29        18\n",
      "          2       1.00      0.83      0.90        23\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.44      0.61        32\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.56      0.58      0.49       198\n",
      "\n",
      "[78  0  0  0  0  0  0 15  3  0  0  0  0  0  4  0 19  0  0  0  0 11  0  0\n",
      "  0  0  0  0 18  0  0  0 14  0  0 13  0  0  0  0  0  0 23  0  0  0  0  0\n",
      "  0]\n",
      "LR Accuracy:  0.5757575757575758\n",
      "LR F1:  0.3498816918071576\n",
      "For name:  y_hou\n",
      "total sample size before apply threshold:  162\n",
      "Counter({'0000-0001-6546-2597': 97, '0000-0002-3995-7219': 29, '0000-0002-0420-0726': 14, '0000-0002-8114-166X': 12, '0000-0002-7360-5751': 5, '0000-0002-4978-9829': 4, '0000-0003-3195-7430': 1})\n",
      "['0000-0002-3995-7219', '0000-0002-8114-166X', '0000-0001-6546-2597', '0000-0002-0420-0726']\n",
      "Total sample size after apply threshold:  152\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(152, 320)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "152\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        29\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.92      1.00      0.96        97\n",
      "          3       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.95      0.94      0.93       152\n",
      "\n",
      "[29  0  0  0  1 10  1  0  0  0 97  0  0  0  7  7]\n",
      "MNB Accuracy:  0.9407894736842105\n",
      "MNB F1:  0.8798011157047908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        29\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.95      1.00      0.97        97\n",
      "          3       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97       152\n",
      "\n",
      "[29  0  0  0  0 10  2  0  0  0 97  0  0  0  3 11]\n",
      "svc Accuracy:  0.9671052631578947\n",
      "svc F1:  0.9409913202375514\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        29\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.87      1.00      0.93        97\n",
      "          3       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.91      0.90      0.89       152\n",
      "\n",
      "[23  0  6  0  0 10  2  0  0  0 97  0  0  0  7  7]\n",
      "LR Accuracy:  0.9013157894736842\n",
      "LR F1:  0.8471506563611827\n",
      "For name:  m_sahin\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-7044-2953': 41, '0000-0002-3490-6009': 3, '0000-0001-6502-2209': 2, '0000-0001-7677-8423': 2})\n",
      "['0000-0001-7044-2953']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  c_feng\n",
      "total sample size before apply threshold:  88\n",
      "Counter({'0000-0002-1854-356X': 30, '0000-0002-2130-8851': 26, '0000-0003-3267-0968': 12, '0000-0002-7031-4211': 12, '0000-0002-3278-9451': 7, '0000-0003-1085-4395': 1})\n",
      "['0000-0002-1854-356X', '0000-0002-2130-8851', '0000-0003-3267-0968', '0000-0002-7031-4211']\n",
      "Total sample size after apply threshold:  80\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(80, 86)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "80\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        30\n",
      "          1       0.81      1.00      0.90        26\n",
      "          2       1.00      0.58      0.74        12\n",
      "          3       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.92      0.90      0.89        80\n",
      "\n",
      "[30  0  0  0  0 26  0  0  2  3  7  0  0  3  0  9]\n",
      "MNB Accuracy:  0.9\n",
      "MNB F1:  0.8645696555069543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        30\n",
      "          1       0.90      1.00      0.95        26\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.97      0.96      0.96        80\n",
      "\n",
      "[29  1  0  0  0 26  0  0  0  2 10  0  0  0  0 12]\n",
      "svc Accuracy:  0.9625\n",
      "svc F1:  0.9593990755007704\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        30\n",
      "          1       0.93      1.00      0.96        26\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.98      0.97      0.97        80\n",
      "\n",
      "[30  0  0  0  0 26  0  0  0  2 10  0  0  0  0 12]\n",
      "LR Accuracy:  0.975\n",
      "LR F1:  0.968013468013468\n",
      "For name:  j_coutinho\n",
      "total sample size before apply threshold:  129\n",
      "Counter({'0000-0002-3841-743X': 105, '0000-0002-6303-9549': 13, '0000-0002-1562-0099': 8, '0000-0003-0280-366X': 3})\n",
      "['0000-0002-6303-9549', '0000-0002-3841-743X']\n",
      "Total sample size after apply threshold:  118\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(118, 181)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "118\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.92      1.00      0.96       105\n",
      "\n",
      "avg / total       0.93      0.92      0.91       118\n",
      "\n",
      "[  4   9   0 105]\n",
      "MNB Accuracy:  0.923728813559322\n",
      "MNB F1:  0.7147461724415793\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.95      1.00      0.98       105\n",
      "\n",
      "avg / total       0.96      0.96      0.95       118\n",
      "\n",
      "[  8   5   0 105]\n",
      "svc Accuracy:  0.9576271186440678\n",
      "svc F1:  0.8693244739756368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.89      1.00      0.94       105\n",
      "\n",
      "avg / total       0.79      0.89      0.84       118\n",
      "\n",
      "[  0  13   0 105]\n",
      "LR Accuracy:  0.8898305084745762\n",
      "LR F1:  0.47085201793721976\n",
      "For name:  s_huber\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-4125-159X': 26, '0000-0003-3558-351X': 12, '0000-0002-8271-7835': 3, '0000-0002-5842-5859': 2, '0000-0001-6303-5188': 1})\n",
      "['0000-0003-3558-351X', '0000-0002-4125-159X']\n",
      "Total sample size after apply threshold:  38\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 93)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.84      1.00      0.91        26\n",
      "\n",
      "avg / total       0.89      0.87      0.86        38\n",
      "\n",
      "[ 7  5  0 26]\n",
      "MNB Accuracy:  0.868421052631579\n",
      "MNB F1:  0.8245614035087718\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.84      1.00      0.91        26\n",
      "\n",
      "avg / total       0.89      0.87      0.86        38\n",
      "\n",
      "[ 7  5  0 26]\n",
      "svc Accuracy:  0.868421052631579\n",
      "svc F1:  0.8245614035087718\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.70      1.00      0.83        26\n",
      "\n",
      "avg / total       0.80      0.71      0.61        38\n",
      "\n",
      "[ 1 11  0 26]\n",
      "LR Accuracy:  0.7105263157894737\n",
      "LR F1:  0.48962148962148966\n",
      "For name:  a_rocha\n",
      "total sample size before apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "Counter({'0000-0003-3218-7001': 26, '0000-0001-9710-9835': 21, '0000-0003-2165-5519': 12, '0000-0002-4094-7982': 3, '0000-0002-5637-1041': 3, '0000-0001-6528-9034': 3, '0000-0003-4940-6522': 2, '0000-0003-0298-8246': 2, '0000-0001-8679-2886': 1})\n",
      "['0000-0001-9710-9835', '0000-0003-2165-5519', '0000-0003-3218-7001']\n",
      "Total sample size after apply threshold:  59\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(59, 108)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        21\n",
      "          1       1.00      0.92      0.96        12\n",
      "          2       0.87      1.00      0.93        26\n",
      "\n",
      "avg / total       0.94      0.93      0.93        59\n",
      "\n",
      "[18  0  3  0 11  1  0  0 26]\n",
      "MNB Accuracy:  0.9322033898305084\n",
      "MNB F1:  0.9360566969262623\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.86      0.88        21\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.90      1.00      0.95        26\n",
      "\n",
      "avg / total       0.92      0.92      0.91        59\n",
      "\n",
      "[18  0  3  2 10  0  0  0 26]\n",
      "svc Accuracy:  0.9152542372881356\n",
      "svc F1:  0.9108647450110864\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        21\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.81      1.00      0.90        26\n",
      "\n",
      "avg / total       0.92      0.90      0.90        59\n",
      "\n",
      "[17  0  4  0 10  2  0  0 26]\n",
      "LR Accuracy:  0.8983050847457628\n",
      "LR F1:  0.9001264917780345\n",
      "For name:  a_white\n",
      "total sample size before apply threshold:  386\n",
      "Counter({'0000-0002-9668-4632': 108, '0000-0003-1802-9891': 87, '0000-0002-7686-2884': 85, '0000-0001-9639-5200': 41, '0000-0002-5442-6985': 16, '0000-0002-9859-0947': 13, '0000-0002-1539-0158': 9, '0000-0001-5530-742X': 9, '0000-0001-7499-7390': 4, '0000-0002-3904-2019': 4, '0000-0002-7771-3899': 3, '0000-0002-9708-2406': 2, '0000-0002-2783-895X': 2, '0000-0002-7268-5163': 1, '0000-0002-4837-7128': 1, '0000-0002-7106-6440': 1})\n",
      "['0000-0002-7686-2884', '0000-0002-5442-6985', '0000-0002-9668-4632', '0000-0002-9859-0947', '0000-0001-9639-5200', '0000-0003-1802-9891']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 350\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(350, 1067)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "350\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.91        85\n",
      "          1       1.00      0.19      0.32        16\n",
      "          2       0.76      0.99      0.86       108\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       1.00      0.73      0.85        41\n",
      "          5       0.98      0.98      0.98        87\n",
      "\n",
      "avg / total       0.86      0.87      0.84       350\n",
      "\n",
      "[ 80   0   4   0   0   1   5   3   8   0   0   0   0   0 107   0   0   1\n",
      "   2   0  11   0   0   0   3   0   8   0  30   0   0   0   2   0   0  85]\n",
      "MNB Accuracy:  0.8714285714285714\n",
      "MNB F1:  0.6525100550940768\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.89      0.93        85\n",
      "          1       1.00      0.69      0.81        16\n",
      "          2       0.74      1.00      0.85       108\n",
      "          3       1.00      0.31      0.47        13\n",
      "          4       1.00      0.73      0.85        41\n",
      "          5       1.00      0.92      0.96        87\n",
      "\n",
      "avg / total       0.91      0.88      0.88       350\n",
      "\n",
      "[ 76   0   9   0   0   0   1  11   4   0   0   0   0   0 108   0   0   0\n",
      "   0   0   9   4   0   0   2   0   9   0  30   0   0   0   7   0   0  80]\n",
      "svc Accuracy:  0.8828571428571429\n",
      "svc F1:  0.8109633790099263\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.88      0.91        85\n",
      "          1       1.00      0.25      0.40        16\n",
      "          2       0.68      1.00      0.81       108\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       1.00      0.68      0.81        41\n",
      "          5       1.00      0.92      0.96        87\n",
      "\n",
      "avg / total       0.85      0.84      0.82       350\n",
      "\n",
      "[ 75   0  10   0   0   0   2   4  10   0   0   0   0   0 108   0   0   0\n",
      "   0   0  13   0   0   0   2   0  11   0  28   0   0   0   7   0   0  80]\n",
      "LR Accuracy:  0.8428571428571429\n",
      "LR F1:  0.6488834909367146\n",
      "For name:  j_scott\n",
      "total sample size before apply threshold:  342\n",
      "Counter({'0000-0002-7203-8601': 155, '0000-0002-0744-0688': 60, '0000-0003-0765-9054': 44, '0000-0002-9116-948X': 36, '0000-0002-7513-6768': 21, '0000-0002-9916-6523': 8, '0000-0001-7782-3601': 7, '0000-0002-5073-0832': 6, '0000-0003-2368-8218': 1, '0000-0003-2971-7673': 1, '0000-0002-5616-2688': 1, '0000-0002-4900-0891': 1, '0000-0001-8408-5176': 1})\n",
      "['0000-0002-7203-8601', '0000-0003-0765-9054', '0000-0002-0744-0688', '0000-0002-9116-948X', '0000-0002-7513-6768']\n",
      "Total sample size after apply threshold:  316\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(316, 1124)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      1.00      0.78       155\n",
      "          1       1.00      0.41      0.58        44\n",
      "          2       1.00      0.65      0.79        60\n",
      "          3       1.00      0.44      0.62        36\n",
      "          4       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.76      0.72      0.68       316\n",
      "\n",
      "[155   0   0   0   0  26  18   0   0   0  21   0  39   0   0  20   0   0\n",
      "  16   0  21   0   0   0   0]\n",
      "MNB Accuracy:  0.7215189873417721\n",
      "MNB F1:  0.552560607383107\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85       155\n",
      "          1       1.00      0.61      0.76        44\n",
      "          2       1.00      0.72      0.83        60\n",
      "          3       1.00      0.75      0.86        36\n",
      "          4       1.00      0.48      0.65        21\n",
      "\n",
      "avg / total       0.87      0.83      0.82       316\n",
      "\n",
      "[155   0   0   0   0  17  27   0   0   0  17   0  43   0   0   9   0   0\n",
      "  27   0  11   0   0   0  10]\n",
      "svc Accuracy:  0.8291139240506329\n",
      "svc F1:  0.7898934671412319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      1.00      0.75       155\n",
      "          1       1.00      0.30      0.46        44\n",
      "          2       1.00      0.52      0.68        60\n",
      "          3       1.00      0.36      0.53        36\n",
      "          4       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.74      0.67      0.62       316\n",
      "\n",
      "[155   0   0   0   0  31  13   0   0   0  29   0  31   0   0  23   0   0\n",
      "  13   0  21   0   0   0   0]\n",
      "LR Accuracy:  0.6708860759493671\n",
      "LR F1:  0.48337270952504685\n",
      "For name:  s_hosseini\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0001-6222-792X': 8, '0000-0002-5881-6796': 8, '0000-0002-5468-1281': 6, '0000-0002-0211-6248': 1, '0000-0002-0907-9427': 1, '0000-0001-7521-7907': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_vieira\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0002-7366-6765': 60, '0000-0003-4232-9413': 5, '0000-0001-7388-6904': 2, '0000-0001-6288-2086': 1})\n",
      "['0000-0002-7366-6765']\n",
      "Total sample size after apply threshold:  60\n",
      "For name:  j_kang\n",
      "total sample size before apply threshold:  200\n",
      "Counter({'0000-0002-6350-3997': 57, '0000-0001-7311-6053': 42, '0000-0001-8995-5636': 25, '0000-0002-9181-6819': 15, '0000-0002-1412-6179': 11, '0000-0003-4788-0028': 11, '0000-0002-5262-2712': 9, '0000-0002-8467-2503': 8, '0000-0002-9425-847X': 6, '0000-0002-8660-7940': 4, '0000-0003-1610-6742': 3, '0000-0002-1841-5357': 3, '0000-0001-8894-2630': 3, '0000-0001-5013-2683': 1, '0000-0003-4200-1020': 1, '0000-0002-2603-9718': 1})\n",
      "['0000-0002-1412-6179', '0000-0002-6350-3997', '0000-0002-9181-6819', '0000-0001-7311-6053', '0000-0001-8995-5636', '0000-0003-4788-0028']\n",
      "Total sample size after apply threshold:  161\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(161, 216)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.64      0.96      0.77        57\n",
      "          2       1.00      0.13      0.24        15\n",
      "          3       0.60      0.93      0.73        42\n",
      "          4       1.00      0.28      0.44        25\n",
      "          5       1.00      0.09      0.17        11\n",
      "\n",
      "avg / total       0.70      0.65      0.56       161\n",
      "\n",
      "[ 0  1  0 10  0  0  0 55  0  2  0  0  0  2  2 11  0  0  0  3  0 39  0  0\n",
      "  0 15  0  3  7  0  0 10  0  0  0  1]\n",
      "MNB Accuracy:  0.6459627329192547\n",
      "MNB F1:  0.3896105860268862\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.27      0.40        11\n",
      "          1       0.78      0.95      0.86        57\n",
      "          2       0.75      0.40      0.52        15\n",
      "          3       0.79      0.88      0.83        42\n",
      "          4       0.62      0.60      0.61        25\n",
      "          5       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.77      0.77      0.75       161\n",
      "\n",
      "[ 3  0  1  5  2  0  0 54  0  1  2  0  1  3  6  3  2  0  0  1  1 37  3  0\n",
      "  0  9  0  1 15  0  0  2  0  0  0  9]\n",
      "svc Accuracy:  0.7701863354037267\n",
      "svc F1:  0.6870979266156878\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        11\n",
      "          1       0.66      0.98      0.79        57\n",
      "          2       0.83      0.33      0.48        15\n",
      "          3       0.75      0.93      0.83        42\n",
      "          4       1.00      0.52      0.68        25\n",
      "          5       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.80      0.73      0.70       161\n",
      "\n",
      "[ 3  1  1  6  0  0  0 56  0  1  0  0  0  5  5  5  0  0  0  3  0 39  0  0\n",
      "  0 11  0  1 13  0  0  9  0  0  0  2]\n",
      "LR Accuracy:  0.7329192546583851\n",
      "LR F1:  0.5858640611964586\n",
      "For name:  j_jensen\n",
      "total sample size before apply threshold:  388\n",
      "Counter({'0000-0002-4733-1224': 124, '0000-0002-7464-7435': 99, '0000-0003-0657-4032': 43, '0000-0001-6841-1808': 30, '0000-0002-1465-1010': 21, '0000-0003-3291-8468': 18, '0000-0002-2369-8291': 17, '0000-0003-4036-0521': 17, '0000-0001-6228-2988': 12, '0000-0002-7954-8073': 3, '0000-0001-9962-6166': 3, '0000-0003-1873-4531': 1})\n",
      "['0000-0003-0657-4032', '0000-0002-1465-1010', '0000-0002-2369-8291', '0000-0001-6841-1808', '0000-0001-6228-2988', '0000-0002-4733-1224', '0000-0003-4036-0521', '0000-0003-3291-8468', '0000-0002-7464-7435']\n",
      "Total sample size after apply threshold:  381\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(381, 984)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "381\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        43\n",
      "          1       1.00      0.19      0.32        21\n",
      "          2       0.00      0.00      0.00        17\n",
      "          3       1.00      0.77      0.87        30\n",
      "          4       1.00      0.92      0.96        12\n",
      "          5       0.57      1.00      0.72       124\n",
      "          6       1.00      0.18      0.30        17\n",
      "          7       0.00      0.00      0.00        18\n",
      "          8       0.77      0.80      0.78        99\n",
      "\n",
      "avg / total       0.71      0.69      0.63       381\n",
      "\n",
      "[ 18   0   0   0   0  21   0   0   4   0   4   0   0   0  10   0   0   7\n",
      "   0   0   0   0   0  17   0   0   0   0   0   0  23   0   6   0   0   1\n",
      "   0   0   0   0  11   1   0   0   0   0   0   0   0   0 124   0   0   0\n",
      "   0   0   0   0   0  11   3   0   3   0   0   0   0   0   9   0   0   9\n",
      "   0   0   0   0   0  20   0   0  79]\n",
      "MNB Accuracy:  0.6876640419947506\n",
      "MNB F1:  0.504424498850131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.63      0.76        43\n",
      "          1       1.00      0.67      0.80        21\n",
      "          2       1.00      0.18      0.30        17\n",
      "          3       1.00      0.83      0.91        30\n",
      "          4       1.00      0.92      0.96        12\n",
      "          5       0.88      0.87      0.87       124\n",
      "          6       1.00      0.59      0.74        17\n",
      "          7       1.00      0.39      0.56        18\n",
      "          8       0.57      0.93      0.71        99\n",
      "\n",
      "avg / total       0.85      0.78      0.77       381\n",
      "\n",
      "[ 27   0   0   0   0   2   0   0  14   0  14   0   0   0   1   0   0   6\n",
      "   0   0   3   0   0   1   0   0  13   0   0   0  25   0   1   0   0   4\n",
      "   0   0   0   0  11   0   0   0   1   0   0   0   0   0 108   0   0  16\n",
      "   0   0   0   0   0   2  10   0   5   1   0   0   0   0   1   0   7   9\n",
      "   0   0   0   0   0   7   0   0  92]\n",
      "svc Accuracy:  0.7795275590551181\n",
      "svc F1:  0.7346483785326657\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.40      0.56        43\n",
      "          1       1.00      0.38      0.55        21\n",
      "          2       0.00      0.00      0.00        17\n",
      "          3       1.00      0.70      0.82        30\n",
      "          4       1.00      0.92      0.96        12\n",
      "          5       0.62      0.95      0.75       124\n",
      "          6       1.00      0.47      0.64        17\n",
      "          7       1.00      0.06      0.11        18\n",
      "          8       0.65      0.81      0.72        99\n",
      "\n",
      "avg / total       0.73      0.69      0.65       381\n",
      "\n",
      "[ 17   0   0   0   0  18   0   0   8   0   8   0   0   0   6   0   0   7\n",
      "   0   0   0   0   0  11   0   0   6   0   0   0  21   0   6   0   0   3\n",
      "   0   0   0   0  11   0   0   0   1   0   0   0   0   0 118   0   0   6\n",
      "   0   0   0   0   0   6   8   0   3   1   0   0   0   0   6   0   1  10\n",
      "   0   0   0   0   0  19   0   0  80]\n",
      "LR Accuracy:  0.6929133858267716\n",
      "LR F1:  0.5670551824252007\n",
      "For name:  k_lai\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-8135-6030': 36, '0000-0001-9296-0882': 5, '0000-0002-0037-792X': 4, '0000-0002-3365-3927': 2, '0000-0002-4069-054X': 2, '0000-0001-8203-4252': 1, '0000-0001-7734-0941': 1, '0000-0003-1478-4996': 1})\n",
      "['0000-0001-8135-6030']\n",
      "Total sample size after apply threshold:  36\n",
      "For name:  j_gonzalez\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0001-5569-0705': 13, '0000-0003-3063-1770': 10, '0000-0002-3448-7393': 6, '0000-0002-9926-3323': 4, '0000-0002-0381-6393': 3, '0000-0002-0389-5263': 2, '0000-0003-3415-5943': 1})\n",
      "['0000-0003-3063-1770', '0000-0001-5569-0705']\n",
      "Total sample size after apply threshold:  23\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 133)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "23\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80        10\n",
      "          1       0.85      0.85      0.85        13\n",
      "\n",
      "avg / total       0.83      0.83      0.83        23\n",
      "\n",
      "[ 8  2  2 11]\n",
      "MNB Accuracy:  0.8260869565217391\n",
      "MNB F1:  0.8230769230769232\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.70      0.78        10\n",
      "          1       0.80      0.92      0.86        13\n",
      "\n",
      "avg / total       0.83      0.83      0.82        23\n",
      "\n",
      "[ 7  3  1 12]\n",
      "svc Accuracy:  0.8260869565217391\n",
      "svc F1:  0.8174603174603174\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.65      1.00      0.79        13\n",
      "\n",
      "avg / total       0.80      0.70      0.65        23\n",
      "\n",
      "[ 3  7  0 13]\n",
      "LR Accuracy:  0.6956521739130435\n",
      "LR F1:  0.6247086247086248\n",
      "For name:  m_zakaria\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-3694-3460': 10, '0000-0003-2525-0092': 8, '0000-0002-2698-615X': 5, '0000-0003-2456-6415': 1})\n",
      "['0000-0002-3694-3460']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  c_campos\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0003-1734-6924': 31, '0000-0002-7616-8518': 10, '0000-0003-1809-8272': 3, '0000-0002-2070-8618': 1, '0000-0002-4978-5449': 1, '0000-0001-6054-4243': 1, '0000-0001-8592-5384': 1})\n",
      "['0000-0002-7616-8518', '0000-0003-1734-6924']\n",
      "Total sample size after apply threshold:  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 278)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "41\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       0.79      1.00      0.89        31\n",
      "\n",
      "avg / total       0.84      0.80      0.75        41\n",
      "\n",
      "[ 2  8  0 31]\n",
      "MNB Accuracy:  0.8048780487804879\n",
      "MNB F1:  0.6095238095238096\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.97      1.00      0.98        31\n",
      "\n",
      "avg / total       0.98      0.98      0.98        41\n",
      "\n",
      "[ 9  1  0 31]\n",
      "svc Accuracy:  0.975609756097561\n",
      "svc F1:  0.9657477025898078\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.76      1.00      0.86        31\n",
      "\n",
      "avg / total       0.57      0.76      0.65        41\n",
      "\n",
      "[ 0 10  0 31]\n",
      "LR Accuracy:  0.7560975609756098\n",
      "LR F1:  0.4305555555555556\n",
      "For name:  a_gad\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-1098-9129': 17, '0000-0001-9741-2105': 10, '0000-0002-5298-5206': 1, '0000-0002-0762-0953': 1})\n",
      "['0000-0001-9741-2105', '0000-0002-1098-9129']\n",
      "Total sample size after apply threshold:  27\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(27, 111)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.89      1.00      0.94        17\n",
      "\n",
      "avg / total       0.93      0.93      0.92        27\n",
      "\n",
      "[ 8  2  0 17]\n",
      "MNB Accuracy:  0.9259259259259259\n",
      "MNB F1:  0.9166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.89      1.00      0.94        17\n",
      "\n",
      "avg / total       0.93      0.93      0.92        27\n",
      "\n",
      "[ 8  2  0 17]\n",
      "svc Accuracy:  0.9259259259259259\n",
      "svc F1:  0.9166666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.81      1.00      0.89        17\n",
      "\n",
      "avg / total       0.88      0.85      0.84        27\n",
      "\n",
      "[ 6  4  0 17]\n",
      "LR Accuracy:  0.8518518518518519\n",
      "LR F1:  0.8223684210526315\n",
      "For name:  y_zhao\n",
      "total sample size before apply threshold:  338\n",
      "Counter({'0000-0003-1215-2565': 48, '0000-0002-7916-8687': 47, '0000-0001-6783-5182': 20, '0000-0002-9408-9979': 20, '0000-0002-6541-0612': 18, '0000-0002-5455-2586': 17, '0000-0002-2903-4218': 16, '0000-0003-0302-3470': 16, '0000-0002-6184-2530': 15, '0000-0003-1035-2272': 15, '0000-0002-6923-1099': 13, '0000-0002-1442-992X': 12, '0000-0001-6747-1665': 12, '0000-0003-3618-1379': 11, '0000-0002-9231-8360': 11, '0000-0003-1384-6024': 9, '0000-0002-0278-7543': 7, '0000-0001-8541-893X': 5, '0000-0001-8986-9164': 4, '0000-0002-2944-1315': 4, '0000-0001-8970-9398': 3, '0000-0001-8925-9462': 2, '0000-0003-1254-6732': 2, '0000-0002-5866-5932': 2, '0000-0001-8808-9481': 2, '0000-0003-1815-1408': 1, '0000-0002-4148-2603': 1, '0000-0003-1490-0416': 1, '0000-0002-7761-0072': 1, '0000-0002-6806-1593': 1, '0000-0003-4188-5725': 1, '0000-0003-2289-5709': 1})\n",
      "['0000-0002-1442-992X', '0000-0002-6541-0612', '0000-0003-3618-1379', '0000-0001-6783-5182', '0000-0002-6184-2530', '0000-0001-6747-1665', '0000-0002-2903-4218', '0000-0002-5455-2586', '0000-0002-9231-8360', '0000-0002-6923-1099', '0000-0003-1035-2272', '0000-0003-1215-2565', '0000-0002-7916-8687', '0000-0003-0302-3470', '0000-0002-9408-9979']\n",
      "Total sample size after apply threshold:  291\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(291, 434)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "291\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       1.00      0.11      0.20        18\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.95      0.97        20\n",
      "          4       0.86      0.40      0.55        15\n",
      "          5       1.00      0.08      0.15        12\n",
      "          6       1.00      0.50      0.67        16\n",
      "          7       0.92      0.71      0.80        17\n",
      "          8       1.00      0.18      0.31        11\n",
      "          9       0.00      0.00      0.00        13\n",
      "         10       1.00      0.47      0.64        15\n",
      "         11       0.46      0.88      0.60        48\n",
      "         12       0.33      0.98      0.50        47\n",
      "         13       1.00      0.06      0.12        16\n",
      "         14       1.00      0.05      0.10        20\n",
      "\n",
      "avg / total       0.67      0.51      0.43       291\n",
      "\n",
      "[ 0  0  0  0  1  0  0  0  0  0  0  1 10  0  0  0  2  0  0  0  0  0  0  0\n",
      "  0  0  5 11  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0\n",
      " 19  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  6  0  0  0  0  0  0  1\n",
      "  8  0  0  0  0  0  0  0  1  0  0  0  0  0  1 10  0  0  0  0  0  0  0  0\n",
      "  8  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0 12  0  0  0  3  2  0  0\n",
      "  0  0  0  0  0  0  0  0  2  0  0  6  3  0  0  0  0  0  0  0  0  0  1  0\n",
      "  0  0  6  6  0  0  0  0  0  0  0  0  0  0  0  0  7  2  6  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 42  6  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
      " 46  0  0  0  0  0  0  0  0  0  0  0  0  0  2 13  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0 11  8  0  1]\n",
      "MNB Accuracy:  0.5051546391752577\n",
      "MNB F1:  0.37297098238274706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.42      0.53        12\n",
      "          1       0.85      0.61      0.71        18\n",
      "          2       1.00      0.45      0.62        11\n",
      "          3       1.00      0.95      0.97        20\n",
      "          4       0.78      0.47      0.58        15\n",
      "          5       0.75      0.50      0.60        12\n",
      "          6       0.94      0.94      0.94        16\n",
      "          7       0.93      0.82      0.87        17\n",
      "          8       1.00      0.55      0.71        11\n",
      "          9       1.00      0.31      0.47        13\n",
      "         10       1.00      0.67      0.80        15\n",
      "         11       0.54      0.94      0.68        48\n",
      "         12       0.68      0.94      0.79        47\n",
      "         13       0.69      0.69      0.69        16\n",
      "         14       0.86      0.60      0.71        20\n",
      "\n",
      "avg / total       0.79      0.74      0.73       291\n",
      "\n",
      "[ 5  0  0  0  1  1  0  0  0  0  0  3  2  0  0  1 11  0  0  0  0  0  0  0\n",
      "  0  0  5  1  0  0  0  0  5  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0\n",
      " 19  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  7  0  0  0  0  0  0  2\n",
      "  5  1  0  0  0  0  0  0  6  1  0  0  0  0  1  3  1  0  0  0  0  0  0  0\n",
      " 15  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0 14  0  0  0  3  0  0  0\n",
      "  0  0  0  0  1  0  0  0  6  0  0  3  1  0  0  0  0  0  0  0  1  0  1  0\n",
      "  4  0  3  2  2  0  0  2  0  0  0  0  0  0  0  0 10  0  3  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 45  2  0  1  1  0  0  0  0  0  0  0  0  0  0  1\n",
      " 44  1  0  0  0  0  0  0  0  0  0  0  0  0  3  1 11  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  7  1  0 12]\n",
      "svc Accuracy:  0.7353951890034365\n",
      "svc F1:  0.7112380616819846\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.75      0.33      0.46        18\n",
      "          2       1.00      0.36      0.53        11\n",
      "          3       1.00      1.00      1.00        20\n",
      "          4       0.88      0.47      0.61        15\n",
      "          5       0.75      0.50      0.60        12\n",
      "          6       0.93      0.88      0.90        16\n",
      "          7       0.88      0.82      0.85        17\n",
      "          8       1.00      0.45      0.62        11\n",
      "          9       1.00      0.15      0.27        13\n",
      "         10       1.00      0.60      0.75        15\n",
      "         11       0.47      0.88      0.61        48\n",
      "         12       0.52      0.98      0.68        47\n",
      "         13       0.67      0.50      0.57        16\n",
      "         14       0.60      0.15      0.24        20\n",
      "\n",
      "avg / total       0.70      0.64      0.61       291\n",
      "\n",
      "[ 0  0  0  0  1  2  0  0  0  0  0  4  5  0  0  1  6  0  0  0  0  0  0  0\n",
      "  0  0  6  5  0  0  0  0  4  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0\n",
      " 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  2\n",
      "  5  1  0  0  0  0  0  0  6  0  0  0  0  0  1  4  1  0  0  0  0  0  0  0\n",
      " 14  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0 14  0  0  0  2  1  0  0\n",
      "  0  0  0  0  0  0  1  0  5  0  0  4  1  0  0  0  0  0  0  0  0  0  2  0\n",
      "  2  0  4  3  2  0  0  2  0  0  0  0  0  0  0  0  9  0  4  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 42  5  0  1  0  0  0  0  0  0  0  0  0  0  0  1\n",
      " 46  0  0  0  0  0  0  0  0  0  0  0  0  0  2  5  8  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0 14  3  0  3]\n",
      "LR Accuracy:  0.6391752577319587\n",
      "LR F1:  0.5799033649155201\n",
      "For name:  s_hussain\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-7894-2485': 18, '0000-0002-3298-6260': 11, '0000-0002-9765-0565': 9, '0000-0001-8564-9113': 5, '0000-0001-6835-7207': 2, '0000-0001-6687-7591': 2, '0000-0001-8537-7322': 1, '0000-0002-0529-7451': 1, '0000-0002-7164-3076': 1, '0000-0003-1342-143X': 1, '0000-0001-8475-9791': 1})\n",
      "['0000-0002-3298-6260', '0000-0001-7894-2485']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 66)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        18\n",
      "\n",
      "avg / total       1.00      1.00      1.00        29\n",
      "\n",
      "[11  0  0 18]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.95      1.00      0.97        18\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[10  1  0 18]\n",
      "svc Accuracy:  0.9655172413793104\n",
      "svc F1:  0.9626769626769627\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.95      1.00      0.97        18\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[10  1  0 18]\n",
      "LR Accuracy:  0.9655172413793104\n",
      "LR F1:  0.9626769626769627\n",
      "For name:  k_scott\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-7263-6778': 11, '0000-0001-7952-0348': 3, '0000-0002-7066-887X': 1, '0000-0003-0345-5417': 1})\n",
      "['0000-0001-7263-6778']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  a_martinez\n",
      "total sample size before apply threshold:  180\n",
      "Counter({'0000-0003-1643-6506': 64, '0000-0002-2707-8110': 56, '0000-0002-4804-6687': 20, '0000-0003-4882-4044': 17, '0000-0003-0710-2336': 10, '0000-0002-4395-0511': 7, '0000-0001-5448-0140': 4, '0000-0001-9076-6197': 2})\n",
      "['0000-0003-0710-2336', '0000-0003-4882-4044', '0000-0003-1643-6506', '0000-0002-2707-8110', '0000-0002-4804-6687']\n",
      "Total sample size after apply threshold:  167\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(167, 542)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "167\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       0.00      0.00      0.00        17\n",
      "          2       0.69      1.00      0.82        64\n",
      "          3       0.91      0.93      0.92        56\n",
      "          4       1.00      0.75      0.86        20\n",
      "\n",
      "avg / total       0.75      0.80      0.74       167\n",
      "\n",
      "[ 2  0  8  0  0  0  0 13  4  0  0  0 64  0  0  0  0  4 52  0  0  0  4  1\n",
      " 15]\n",
      "MNB Accuracy:  0.7964071856287425\n",
      "MNB F1:  0.5852233593961794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      0.24      0.38        17\n",
      "          2       0.75      1.00      0.86        64\n",
      "          3       1.00      0.89      0.94        56\n",
      "          4       1.00      0.90      0.95        20\n",
      "\n",
      "avg / total       0.91      0.87      0.86       167\n",
      "\n",
      "[10  0  0  0  0  0  4 13  0  0  0  0 64  0  0  0  0  6 50  0  0  0  2  0\n",
      " 18]\n",
      "svc Accuracy:  0.874251497005988\n",
      "svc F1:  0.8261554862209343\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.00      0.00      0.00        17\n",
      "          2       0.64      1.00      0.78        64\n",
      "          3       0.96      0.86      0.91        56\n",
      "          4       1.00      0.65      0.79        20\n",
      "\n",
      "avg / total       0.75      0.77      0.73       167\n",
      "\n",
      "[ 4  0  6  0  0  0  0 15  2  0  0  0 64  0  0  0  0  8 48  0  0  0  7  0\n",
      " 13]\n",
      "LR Accuracy:  0.7724550898203593\n",
      "LR F1:  0.6090911083087798\n",
      "For name:  r_luz\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-3999-4298': 9, '0000-0002-1021-5772': 6, '0000-0003-0045-6959': 3, '0000-0003-3051-5710': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  p_tran\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0003-3283-1450': 6, '0000-0003-2405-2086': 5, '0000-0003-1735-6903': 2, '0000-0002-7319-872X': 2, '0000-0003-3438-5829': 1, '0000-0001-9788-3433': 1, '0000-0003-4619-4376': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  e_romero\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0001-9087-2790': 20, '0000-0003-1430-8412': 1, '0000-0003-1858-1264': 1, '0000-0003-3115-7572': 1})\n",
      "['0000-0001-9087-2790']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  j_stevens\n",
      "total sample size before apply threshold:  161\n",
      "Counter({'0000-0002-6348-9347': 75, '0000-0002-9867-7209': 41, '0000-0002-1013-8447': 13, '0000-0003-2375-1360': 11, '0000-0003-1601-9008': 9, '0000-0003-4674-0314': 4, '0000-0003-0182-3829': 4, '0000-0002-4661-3481': 3, '0000-0002-2234-1960': 1})\n",
      "['0000-0003-2375-1360', '0000-0002-1013-8447', '0000-0002-9867-7209', '0000-0002-6348-9347']\n",
      "Total sample size after apply threshold:  140\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 349)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "140\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       1.00      0.78      0.88        41\n",
      "          3       0.74      1.00      0.85        75\n",
      "\n",
      "avg / total       0.78      0.81      0.77       140\n",
      "\n",
      "[ 0  0  0 11  0  6  0  7  0  0 32  9  0  0  0 75]\n",
      "MNB Accuracy:  0.8071428571428572\n",
      "MNB F1:  0.5889372258135471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       1.00      0.85      0.92        13\n",
      "          2       1.00      0.76      0.86        41\n",
      "          3       0.78      1.00      0.88        75\n",
      "\n",
      "avg / total       0.88      0.85      0.83       140\n",
      "\n",
      "[ 2  0  0  9  0 11  0  2  0  0 31 10  0  0  0 75]\n",
      "svc Accuracy:  0.85\n",
      "svc F1:  0.7406657669815565\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.54      0.70        13\n",
      "          2       1.00      0.71      0.83        41\n",
      "          3       0.72      1.00      0.84        75\n",
      "\n",
      "avg / total       0.77      0.79      0.76       140\n",
      "\n",
      "[ 0  0  0 11  0  7  0  6  0  0 29 12  0  0  0 75]\n",
      "LR Accuracy:  0.7928571428571428\n",
      "LR F1:  0.5916400638467677\n",
      "For name:  l_you\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0001-7304-0474': 12, '0000-0003-3058-2884': 12, '0000-0003-1162-0064': 7, '0000-0002-4741-0715': 1})\n",
      "['0000-0001-7304-0474', '0000-0003-3058-2884']\n",
      "Total sample size after apply threshold:  24\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 63)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "24\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        12\n",
      "          1       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.88      0.83      0.83        24\n",
      "\n",
      "[12  0  4  8]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.8285714285714285\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        12\n",
      "          1       0.92      0.92      0.92        12\n",
      "\n",
      "avg / total       0.92      0.92      0.92        24\n",
      "\n",
      "[11  1  1 11]\n",
      "svc Accuracy:  0.9166666666666666\n",
      "svc F1:  0.9166666666666666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        12\n",
      "          1       0.92      0.92      0.92        12\n",
      "\n",
      "avg / total       0.92      0.92      0.92        24\n",
      "\n",
      "[11  1  1 11]\n",
      "LR Accuracy:  0.9166666666666666\n",
      "LR F1:  0.9166666666666666\n",
      "For name:  p_stevenson\n",
      "total sample size before apply threshold:  122\n",
      "Counter({'0000-0002-3520-5060': 86, '0000-0001-6780-6859': 33, '0000-0002-3232-5155': 2, '0000-0002-6616-0328': 1})\n",
      "['0000-0002-3520-5060', '0000-0001-6780-6859']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(119, 135)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "119\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99        86\n",
      "          1       0.97      0.97      0.97        33\n",
      "\n",
      "avg / total       0.98      0.98      0.98       119\n",
      "\n",
      "[85  1  1 32]\n",
      "MNB Accuracy:  0.9831932773109243\n",
      "MNB F1:  0.9790345313601128\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        86\n",
      "          1       1.00      0.94      0.97        33\n",
      "\n",
      "avg / total       0.98      0.98      0.98       119\n",
      "\n",
      "[86  0  2 31]\n",
      "svc Accuracy:  0.9831932773109243\n",
      "svc F1:  0.9786278735632183\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        86\n",
      "          1       1.00      0.85      0.92        33\n",
      "\n",
      "avg / total       0.96      0.96      0.96       119\n",
      "\n",
      "[86  0  5 28]\n",
      "LR Accuracy:  0.957983193277311\n",
      "LR F1:  0.9448920996573122\n",
      "For name:  t_kang\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0001-5939-6247': 16, '0000-0002-4589-9772': 8, '0000-0002-8444-9889': 1, '0000-0001-6570-2570': 1})\n",
      "['0000-0001-5939-6247']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  s_mohanty\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0001-6601-944X': 43, '0000-0001-9822-427X': 12, '0000-0002-2142-5572': 9, '0000-0003-4464-8434': 2, '0000-0002-1378-3775': 1})\n",
      "['0000-0001-9822-427X', '0000-0001-6601-944X']\n",
      "Total sample size after apply threshold:  55\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 168)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       0.91      1.00      0.96        43\n",
      "\n",
      "avg / total       0.93      0.93      0.92        55\n",
      "\n",
      "[ 8  4  0 43]\n",
      "MNB Accuracy:  0.9272727272727272\n",
      "MNB F1:  0.8777777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.98      1.00      0.99        43\n",
      "\n",
      "avg / total       0.98      0.98      0.98        55\n",
      "\n",
      "[11  1  0 43]\n",
      "svc Accuracy:  0.9818181818181818\n",
      "svc F1:  0.9725137431284359\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.88      1.00      0.93        43\n",
      "\n",
      "avg / total       0.90      0.89      0.88        55\n",
      "\n",
      "[ 6  6  0 43]\n",
      "LR Accuracy:  0.8909090909090909\n",
      "LR F1:  0.8007246376811594\n",
      "For name:  m_amorim\n",
      "total sample size before apply threshold:  95\n",
      "Counter({'0000-0001-8137-3295': 55, '0000-0002-4159-4023': 20, '0000-0002-4129-6659': 13, '0000-0002-3831-9602': 4, '0000-0002-6872-6671': 1, '0000-0002-0901-0614': 1, '0000-0003-1516-8407': 1})\n",
      "['0000-0002-4159-4023', '0000-0002-4129-6659', '0000-0001-8137-3295']\n",
      "Total sample size after apply threshold:  88\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 141)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.65      0.79        20\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       0.80      1.00      0.89        55\n",
      "\n",
      "avg / total       0.87      0.84      0.83        88\n",
      "\n",
      "[13  0  7  0  6  7  0  0 55]\n",
      "MNB Accuracy:  0.8409090909090909\n",
      "MNB F1:  0.7688515031469191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        20\n",
      "          1       0.91      0.77      0.83        13\n",
      "          2       0.90      1.00      0.95        55\n",
      "\n",
      "avg / total       0.93      0.92      0.92        88\n",
      "\n",
      "[16  1  3  0 10  3  0  0 55]\n",
      "svc Accuracy:  0.9204545454545454\n",
      "svc F1:  0.8901660280970626\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        20\n",
      "          1       1.00      0.38      0.56        13\n",
      "          2       0.76      1.00      0.87        55\n",
      "\n",
      "avg / total       0.85      0.81      0.78        88\n",
      "\n",
      "[11  0  9  0  5  8  0  0 55]\n",
      "LR Accuracy:  0.8068181818181818\n",
      "LR F1:  0.7104582357312864\n",
      "For name:  y_kamiya\n",
      "total sample size before apply threshold:  161\n",
      "Counter({'0000-0003-4415-520X': 113, '0000-0001-9790-9867': 42, '0000-0001-8716-2536': 5, '0000-0002-0758-0234': 1})\n",
      "['0000-0003-4415-520X', '0000-0001-9790-9867']\n",
      "Total sample size after apply threshold:  155\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(155, 609)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "155\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96       113\n",
      "          1       0.97      0.81      0.88        42\n",
      "\n",
      "avg / total       0.94      0.94      0.94       155\n",
      "\n",
      "[112   1   8  34]\n",
      "MNB Accuracy:  0.9419354838709677\n",
      "MNB F1:  0.9222451368374116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       113\n",
      "          1       1.00      0.76      0.86        42\n",
      "\n",
      "avg / total       0.94      0.94      0.93       155\n",
      "\n",
      "[113   0  10  32]\n",
      "svc Accuracy:  0.9354838709677419\n",
      "svc F1:  0.9112459917544663\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       113\n",
      "          1       1.00      0.57      0.73        42\n",
      "\n",
      "avg / total       0.90      0.88      0.87       155\n",
      "\n",
      "[113   0  18  24]\n",
      "LR Accuracy:  0.8838709677419355\n",
      "LR F1:  0.8267511177347243\n",
      "For name:  w_he\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0003-3254-1242': 20, '0000-0003-3137-8420': 16, '0000-0003-0161-3274': 7, '0000-0003-1236-3047': 5})\n",
      "['0000-0003-3254-1242', '0000-0003-3137-8420']\n",
      "Total sample size after apply threshold:  36\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 72)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        20\n",
      "          1       0.94      1.00      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[19  1  0 16]\n",
      "MNB Accuracy:  0.9722222222222222\n",
      "MNB F1:  0.9720279720279721\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        20\n",
      "          1       0.94      1.00      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[19  1  0 16]\n",
      "svc Accuracy:  0.9722222222222222\n",
      "svc F1:  0.9720279720279721\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        20\n",
      "          1       0.94      1.00      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[19  1  0 16]\n",
      "LR Accuracy:  0.9722222222222222\n",
      "LR F1:  0.9720279720279721\n",
      "For name:  t_kato\n",
      "total sample size before apply threshold:  249\n",
      "Counter({'0000-0001-7856-3952': 218, '0000-0002-0827-0051': 18, '0000-0003-1061-5888': 3, '0000-0002-9312-6272': 3, '0000-0002-1469-0685': 2, '0000-0002-7095-5676': 1, '0000-0003-3757-3243': 1, '0000-0003-4063-0042': 1, '0000-0003-4473-1131': 1, '0000-0002-6009-7962': 1})\n",
      "['0000-0002-0827-0051', '0000-0001-7856-3952']\n",
      "Total sample size after apply threshold:  236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(236, 546)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "236\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        18\n",
      "          1       0.92      0.99      0.95       218\n",
      "\n",
      "avg / total       0.85      0.91      0.88       236\n",
      "\n",
      "[  0  18   3 215]\n",
      "MNB Accuracy:  0.9110169491525424\n",
      "MNB F1:  0.47671840354767187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        18\n",
      "          1       0.92      1.00      0.96       218\n",
      "\n",
      "avg / total       0.85      0.92      0.89       236\n",
      "\n",
      "[  0  18   0 218]\n",
      "svc Accuracy:  0.923728813559322\n",
      "svc F1:  0.4801762114537445\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        18\n",
      "          1       0.92      1.00      0.96       218\n",
      "\n",
      "avg / total       0.85      0.92      0.89       236\n",
      "\n",
      "[  0  18   0 218]\n",
      "LR Accuracy:  0.923728813559322\n",
      "LR F1:  0.4801762114537445\n",
      "For name:  a_ward\n",
      "total sample size before apply threshold:  164\n",
      "Counter({'0000-0001-7945-7975': 92, '0000-0003-4102-8694': 40, '0000-0002-7000-2453': 10, '0000-0001-6948-4814': 9, '0000-0002-6376-0061': 6, '0000-0003-0038-9426': 4, '0000-0002-9774-8677': 2, '0000-0003-1321-3358': 1})\n",
      "['0000-0001-7945-7975', '0000-0002-7000-2453', '0000-0003-4102-8694']\n",
      "Total sample size after apply threshold:  142\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 376)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "142\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90        92\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.72      0.84        40\n",
      "\n",
      "avg / total       0.81      0.85      0.82       142\n",
      "\n",
      "[92  0  0 10  0  0 11  0 29]\n",
      "MNB Accuracy:  0.852112676056338\n",
      "MNB F1:  0.5793802285848946\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92        92\n",
      "          1       1.00      0.30      0.46        10\n",
      "          2       1.00      0.75      0.86        40\n",
      "\n",
      "avg / total       0.90      0.88      0.87       142\n",
      "\n",
      "[92  0  0  7  3  0 10  0 30]\n",
      "svc Accuracy:  0.8802816901408451\n",
      "svc F1:  0.7447014014178194\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        92\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.42      0.60        40\n",
      "\n",
      "avg / total       0.76      0.77      0.72       142\n",
      "\n",
      "[92  0  0 10  0  0 23  0 17]\n",
      "LR Accuracy:  0.7676056338028169\n",
      "LR F1:  0.4814724984504271\n",
      "For name:  j_chen\n",
      "total sample size before apply threshold:  1139\n",
      "Counter({'0000-0001-5077-4483': 92, '0000-0002-5756-3336': 87, '0000-0001-7858-8236': 73, '0000-0002-1752-4201': 61, '0000-0002-9220-8436': 55, '0000-0001-5859-3070': 51, '0000-0003-2996-5781': 49, '0000-0001-8807-3607': 43, '0000-0001-6527-4801': 41, '0000-0001-6879-5936': 35, '0000-0002-7253-2722': 33, '0000-0001-7336-8808': 31, '0000-0001-8634-1145': 29, '0000-0001-6491-6577': 28, '0000-0002-0662-782X': 19, '0000-0001-7381-0918': 18, '0000-0002-4429-283X': 17, '0000-0001-5168-7074': 16, '0000-0002-1591-9744': 14, '0000-0002-7409-7859': 14, '0000-0002-8021-7458': 13, '0000-0002-7530-4215': 12, '0000-0002-4114-3046': 12, '0000-0001-9970-4582': 12, '0000-0002-7000-1469': 11, '0000-0002-3850-4875': 11, '0000-0001-5648-9202': 11, '0000-0002-1038-4162': 11, '0000-0002-3671-553X': 10, '0000-0002-3329-6384': 9, '0000-0001-6661-1734': 9, '0000-0003-0326-8304': 9, '0000-0001-9202-404X': 8, '0000-0001-6321-0505': 8, '0000-0002-5323-1801': 8, '0000-0001-7942-0187': 8, '0000-0003-0339-5880': 8, '0000-0002-0708-6498': 8, '0000-0003-4599-3600': 8, '0000-0002-1071-2234': 7, '0000-0003-3158-9471': 7, '0000-0001-8446-1821': 6, '0000-0002-5684-6692': 6, '0000-0003-1403-1708': 6, '0000-0001-5637-1829': 6, '0000-0001-5507-235X': 6, '0000-0002-6497-4141': 6, '0000-0001-6109-8433': 6, '0000-0002-4801-5397': 5, '0000-0002-6664-2597': 5, '0000-0003-3987-4816': 5, '0000-0002-2424-3969': 4, '0000-0002-7107-2867': 4, '0000-0002-2454-0058': 4, '0000-0003-4188-6189': 3, '0000-0002-9964-293X': 3, '0000-0002-2926-1090': 3, '0000-0001-7547-6423': 3, '0000-0001-5205-923X': 3, '0000-0002-3124-5452': 3, '0000-0002-5042-6179': 3, '0000-0002-0963-3520': 2, '0000-0002-6981-3363': 2, '0000-0002-5258-9035': 2, '0000-0002-2481-8814': 2, '0000-0002-6989-9048': 2, '0000-0003-0447-7466': 2, '0000-0001-8714-2543': 2, '0000-0003-3767-9486': 2, '0000-0003-0320-8707': 2, '0000-0002-3764-1149': 2, '0000-0001-9100-4784': 1, '0000-0002-7226-1678': 1, '0000-0002-4923-5076': 1, '0000-0002-2315-6070': 1, '0000-0002-4833-6756': 1, '0000-0001-6234-1001': 1, '0000-0003-2844-6947': 1, '0000-0002-2745-442X': 1, '0000-0001-6075-4806': 1, '0000-0002-6387-6814': 1, '0000-0002-5433-5178': 1, '0000-0003-4612-3279': 1, '0000-0001-7299-0355': 1, '0000-0001-7962-0840': 1, '0000-0003-4693-5234': 1, '0000-0002-1758-4634': 1, '0000-0001-7360-2238': 1, '0000-0001-5636-985X': 1, '0000-0002-9320-6774': 1, '0000-0002-7808-2670': 1, '0000-0001-5302-2463': 1, '0000-0002-0934-8519': 1, '0000-0002-0024-4561': 1})\n",
      "['0000-0001-7336-8808', '0000-0001-7858-8236', '0000-0002-7253-2722', '0000-0002-9220-8436', '0000-0001-6491-6577', '0000-0002-1591-9744', '0000-0002-4429-283X', '0000-0001-5077-4483', '0000-0002-7000-1469', '0000-0002-5756-3336', '0000-0001-5168-7074', '0000-0003-2996-5781', '0000-0002-7530-4215', '0000-0002-3671-553X', '0000-0002-4114-3046', '0000-0001-8807-3607', '0000-0001-7381-0918', '0000-0002-0662-782X', '0000-0002-1752-4201', '0000-0001-6527-4801', '0000-0001-9970-4582', '0000-0002-3850-4875', '0000-0001-5648-9202', '0000-0002-1038-4162', '0000-0002-7409-7859', '0000-0002-8021-7458', '0000-0001-5859-3070', '0000-0001-6879-5936', '0000-0001-8634-1145']\n",
      "Total sample size after apply threshold:  909\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(909, 1178)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "909\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        31\n",
      "          1       0.63      0.78      0.70        73\n",
      "          2       1.00      0.67      0.80        33\n",
      "          3       1.00      0.58      0.74        55\n",
      "          4       1.00      0.57      0.73        28\n",
      "          5       0.00      0.00      0.00        14\n",
      "          6       0.00      0.00      0.00        17\n",
      "          7       0.27      0.96      0.42        92\n",
      "          8       0.00      0.00      0.00        11\n",
      "          9       0.32      0.99      0.48        87\n",
      "         10       1.00      0.06      0.12        16\n",
      "         11       0.87      0.27      0.41        49\n",
      "         12       0.00      0.00      0.00        12\n",
      "         13       0.00      0.00      0.00        10\n",
      "         14       0.00      0.00      0.00        12\n",
      "         15       0.92      0.28      0.43        43\n",
      "         16       1.00      0.11      0.20        18\n",
      "         17       0.00      0.00      0.00        19\n",
      "         18       0.96      0.75      0.84        61\n",
      "         19       1.00      0.15      0.26        41\n",
      "         20       1.00      0.25      0.40        12\n",
      "         21       0.00      0.00      0.00        11\n",
      "         22       0.00      0.00      0.00        11\n",
      "         23       0.00      0.00      0.00        11\n",
      "         24       0.00      0.00      0.00        14\n",
      "         25       0.00      0.00      0.00        13\n",
      "         26       0.48      0.27      0.35        51\n",
      "         27       1.00      0.20      0.33        35\n",
      "         28       1.00      0.45      0.62        29\n",
      "\n",
      "avg / total       0.62      0.48      0.44       909\n",
      "\n",
      "[14  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 57  0  0  0  0  0 14  0  2  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  1 22  0  0  0  0  5  0  5  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0 32  0  0  0 15  0\n",
      "  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      " 16  0  0  5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0\n",
      "  0  0  8  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  3  0  0  0  0  0  0  0  0  0 14  0  3  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0 88  0  2  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4\n",
      "  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 86  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  1  0 13  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  1  0  0  0  3  0  0  0  0  0 22  0 10  0 13  0  0  0  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  9  0  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0\n",
      "  5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  2  0  0  0  4  0  0  0  0  0 12  0 13  0  0  0  0  0 12  0  0  0  0  0\n",
      "  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0 11  0  5  0  0  0  0  0  0\n",
      "  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  3  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  4  0 11  0  0  0  0  0  0  0  0 46  0  0  0  0  0  0  0  0  0  0  0\n",
      "  4  0  0  0  0  0 26  0  3  0  2  0  0  0  0  0  0  0  6  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  6  0  3  0  0  0  0  0  0  0  0  0  0\n",
      "  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  9  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  2  0  0  0  0  0  9  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  9  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0  0  0  0  0 12  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  3  0  0  0  1  0  0  0  0  0  4  0 32  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  9  0\n",
      " 18  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  7  0  0  0  0  0\n",
      "  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 13]\n",
      "MNB Accuracy:  0.4752475247524752\n",
      "MNB F1:  0.2908727266012757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.87      0.89        31\n",
      "          1       0.70      0.84      0.76        73\n",
      "          2       1.00      0.76      0.86        33\n",
      "          3       0.50      0.95      0.65        55\n",
      "          4       1.00      0.93      0.96        28\n",
      "          5       1.00      0.64      0.78        14\n",
      "          6       1.00      0.76      0.87        17\n",
      "          7       0.72      0.85      0.78        92\n",
      "          8       0.00      0.00      0.00        11\n",
      "          9       0.85      0.93      0.89        87\n",
      "         10       1.00      1.00      1.00        16\n",
      "         11       0.71      0.65      0.68        49\n",
      "         12       0.67      0.33      0.44        12\n",
      "         13       1.00      0.70      0.82        10\n",
      "         14       0.86      0.50      0.63        12\n",
      "         15       0.82      0.72      0.77        43\n",
      "         16       1.00      0.89      0.94        18\n",
      "         17       0.93      0.68      0.79        19\n",
      "         18       0.81      0.89      0.84        61\n",
      "         19       0.56      0.56      0.56        41\n",
      "         20       1.00      1.00      1.00        12\n",
      "         21       0.80      0.73      0.76        11\n",
      "         22       0.50      0.09      0.15        11\n",
      "         23       1.00      0.64      0.78        11\n",
      "         24       1.00      0.79      0.88        14\n",
      "         25       1.00      0.69      0.82        13\n",
      "         26       0.66      0.75      0.70        51\n",
      "         27       0.94      0.49      0.64        35\n",
      "         28       1.00      0.93      0.96        29\n",
      "\n",
      "avg / total       0.79      0.77      0.77       909\n",
      "\n",
      "[27  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
      "  0  0  0  0  0  0 61  0  0  0  0  0  8  0  0  0  2  2  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  1  1 25  3  0  0  0  0  0  2  0  0  0  0\n",
      "  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 52  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  2\n",
      " 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  2  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0\n",
      "  0  0  0  1  0  0  0  0  0  0  0  0 13  1  0  0  0  1  0  0  0  0  0  0\n",
      "  0  2  0  0  0  0  0  0  0  0  0  0  4  0  1  0  0  0 78  0  1  0  0  0\n",
      "  0  0  1  0  1  1  4  0  0  1  0  0  0  0  0  0  0  0  0  8  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0\n",
      "  2  0  0  0  0  0 81  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  2\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  3  0  1  0  0  0  3  0  1  0 32  0  0  0  2  0\n",
      "  0  1  5  0  0  0  0  0  0  1  0  0  0  3  0  0  0  0  0  1  0  0  0  0\n",
      "  4  0  0  1  0  0  0  0  0  0  0  0  0  0  2  1  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  0  0  7  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  1  0  0  0  0  0  1  0  0  0  0  6  0  0  0  1  0  0  0  0  0  0  0\n",
      "  3  0  0  0  3  0  5  0  0  0  1  0  1  0  0  0  0  0 31  0  0  0  1  0\n",
      "  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0\n",
      " 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  2  0  0  0\n",
      "  0  0  0  0  0  0 13  0  2  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0  3  0  1  0  0  0  1  0  0 54  0  0  0  0  0  0  0  1  0  0  0\n",
      "  5  0  2  0  0  0  5  0  0  0  5  0  0  0  0  0  0  0 23  0  0  0  0  0\n",
      "  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 12  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  8  0  0  0  0  1  0  0  0  4  0  0  0  0  0  5  0  0\n",
      "  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  2  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  7  0  0  1  0  0\n",
      "  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 11  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  1  0  0  0  9  2  0  0  2  0  0  3  0  0  0  2  0  2  0  2  0  0\n",
      "  1  0  0  0  0  1  0  0  0  0  0  0 38  0  0  0  0  0 11  0  0  0  0  0\n",
      "  0  0  0  0  0  0  1  0  0  3  1  0  0  0  0  0  0  2 17  0  0  0  0  0\n",
      "  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 27]\n",
      "svc Accuracy:  0.7744774477447744\n",
      "svc F1:  0.7453976994249895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.94      0.92        31\n",
      "          1       0.64      0.86      0.74        73\n",
      "          2       1.00      0.82      0.90        33\n",
      "          3       0.44      0.95      0.60        55\n",
      "          4       0.96      0.93      0.95        28\n",
      "          5       1.00      0.29      0.44        14\n",
      "          6       0.93      0.82      0.87        17\n",
      "          7       0.61      0.91      0.73        92\n",
      "          8       0.00      0.00      0.00        11\n",
      "          9       0.66      0.97      0.78        87\n",
      "         10       1.00      0.62      0.77        16\n",
      "         11       0.86      0.61      0.71        49\n",
      "         12       0.33      0.08      0.13        12\n",
      "         13       1.00      0.50      0.67        10\n",
      "         14       1.00      0.25      0.40        12\n",
      "         15       0.93      0.60      0.73        43\n",
      "         16       1.00      0.56      0.71        18\n",
      "         17       0.89      0.42      0.57        19\n",
      "         18       0.75      0.87      0.80        61\n",
      "         19       0.62      0.44      0.51        41\n",
      "         20       1.00      0.50      0.67        12\n",
      "         21       1.00      0.55      0.71        11\n",
      "         22       0.00      0.00      0.00        11\n",
      "         23       1.00      0.45      0.62        11\n",
      "         24       1.00      0.29      0.44        14\n",
      "         25       1.00      0.08      0.14        13\n",
      "         26       0.54      0.61      0.57        51\n",
      "         27       0.88      0.40      0.55        35\n",
      "         28       1.00      0.90      0.95        29\n",
      "\n",
      "avg / total       0.75      0.70      0.68       909\n",
      "\n",
      "[29  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 63  0  0  0  0  0  7  0  0  0  0  2  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0  0  0  1  1 27  2  0  0  0  0  0  2  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 52  0  0  0  0  0\n",
      "  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  2\n",
      " 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  5  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0\n",
      "  0  0  0  3  0  0  0  0  0  0  0  0 14  2  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  1  0  0  4  0  1  0  0  0 84  0  1  0  0  0\n",
      "  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  1  0  8  0  0  0  0\n",
      "  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
      "  1  0  0  0  0  0 84  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  3 10  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  2  0  0  0  3  0  1  0  0  1  5  0  1  0 30  0  0  0  2  0\n",
      "  0  2  3  0  0  0  0  0  0  1  0  0  0  4  0  0  0  0  0  4  0  0  0  0\n",
      "  1  0  0  0  0  0  1  0  0  0  0  0  0  0  1  1  0  0  0  0  3  0  0  0\n",
      "  0  0  1  0  0  0  5  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  4  0  0  0  0  0  2  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0\n",
      "  3  0  0  0  4  0  5  0  0  0  3  0  4  0  0  0  0  0 26  0  0  0  0  0\n",
      "  0  0  0  0  0  1  0  0  0  0  0  4  0  0  0  1  0  1  0  0  0  0  0  0\n",
      " 10  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  5  0  0  0\n",
      "  0  0  0  0  0  0  8  3  1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0  6  0  1  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0  0  0  0\n",
      "  5  0  2  1  0  0 11  0  0  0  4  0  0  0  0  0  0  0 18  0  0  0  0  0\n",
      "  0  0  0  0  0  2  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  6  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  3  0  0  0  0  0\n",
      "  0  0  0  0  0  0  6  0  0  0  0  1  0  0  0  4  0  0  0  0  0  7  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  1  2  0  0  0  5  0  0  1  0  0\n",
      "  0  0  0  8  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  4  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  1  9  0  0  2  1  0  3  0  0  0  1  0 10  0  0  0  0\n",
      "  0  0  0  0  1  2  0  0  0  0  0  0 31  0  0  0  0  0 10  0  0  0  2  0\n",
      "  4  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  2 14  0  0  0  0  0\n",
      "  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 26]\n",
      "LR Accuracy:  0.7040704070407041\n",
      "LR F1:  0.607392654089607\n",
      "For name:  m_tseng\n",
      "total sample size before apply threshold:  141\n",
      "Counter({'0000-0002-9969-9055': 85, '0000-0002-0114-102X': 24, '0000-0001-8354-7586': 15, '0000-0003-3763-9548': 10, '0000-0002-2702-3590': 5, '0000-0001-6310-4390': 1, '0000-0001-8641-587X': 1})\n",
      "['0000-0003-3763-9548', '0000-0001-8354-7586', '0000-0002-0114-102X', '0000-0002-9969-9055']\n",
      "Total sample size after apply threshold:  134\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 152)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "134\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       1.00      0.47      0.64        15\n",
      "          2       0.69      0.83      0.75        24\n",
      "          3       0.92      0.98      0.95        85\n",
      "\n",
      "avg / total       0.90      0.88      0.87       134\n",
      "\n",
      "[ 8  0  2  0  0  7  5  3  0  0 20  4  0  0  2 83]\n",
      "MNB Accuracy:  0.8805970149253731\n",
      "MNB F1:  0.8071352337390074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.75      0.60      0.67        15\n",
      "          2       0.83      0.79      0.81        24\n",
      "          3       0.93      0.99      0.96        85\n",
      "\n",
      "avg / total       0.90      0.90      0.90       134\n",
      "\n",
      "[ 9  1  0  0  0  9  3  3  0  2 19  3  0  0  1 84]\n",
      "svc Accuracy:  0.9029850746268657\n",
      "svc F1:  0.8456364315042926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       1.00      0.27      0.42        15\n",
      "          2       0.76      0.54      0.63        24\n",
      "          3       0.81      1.00      0.89        85\n",
      "\n",
      "avg / total       0.84      0.82      0.79       134\n",
      "\n",
      "[ 8  0  1  1  0  4  3  8  0  0 13 11  0  0  0 85]\n",
      "LR Accuracy:  0.8208955223880597\n",
      "LR F1:  0.7097061760091286\n",
      "For name:  c_henderson\n",
      "total sample size before apply threshold:  107\n",
      "Counter({'0000-0002-4764-639X': 97, '0000-0002-9936-3279': 6, '0000-0001-6954-7328': 2, '0000-0002-4020-0854': 2})\n",
      "['0000-0002-4764-639X']\n",
      "Total sample size after apply threshold:  97\n",
      "For name:  j_mcdonald\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0003-1955-6052': 7, '0000-0002-7494-1466': 7, '0000-0002-8317-0069': 4, '0000-0002-7953-1458': 1, '0000-0003-4115-7875': 1, '0000-0002-6328-3752': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_ismail\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0003-3111-3588': 10, '0000-0002-5509-5735': 7, '0000-0003-1688-5096': 1, '0000-0002-0264-6476': 1, '0000-0002-1946-9007': 1, '0000-0003-2747-054X': 1, '0000-0002-7019-2146': 1, '0000-0002-1695-3119': 1, '0000-0001-7608-7884': 1})\n",
      "['0000-0003-3111-3588']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  x_xu\n",
      "total sample size before apply threshold:  408\n",
      "Counter({'0000-0002-7229-0081': 107, '0000-0002-4459-2082': 38, '0000-0002-4567-7117': 34, '0000-0002-7426-272X': 32, '0000-0003-4132-5322': 28, '0000-0002-2009-0483': 19, '0000-0003-2220-0890': 18, '0000-0001-6088-976X': 17, '0000-0002-3863-9593': 17, '0000-0002-5695-8213': 15, '0000-0001-6435-8181': 13, '0000-0003-0847-5871': 8, '0000-0003-3695-4845': 7, '0000-0003-1672-0830': 7, '0000-0002-5042-9505': 7, '0000-0002-4876-5710': 7, '0000-0002-3265-7678': 6, '0000-0003-0205-6342': 6, '0000-0003-1157-8660': 5, '0000-0002-1982-7062': 4, '0000-0001-6909-0743': 4, '0000-0002-6315-6083': 2, '0000-0003-2094-3164': 1, '0000-0003-1405-8089': 1, '0000-0001-6501-7442': 1, '0000-0002-9662-7582': 1, '0000-0003-3950-3425': 1, '0000-0001-9769-7323': 1, '0000-0003-2047-7298': 1})\n",
      "['0000-0001-6088-976X', '0000-0003-4132-5322', '0000-0001-6435-8181', '0000-0002-7229-0081', '0000-0002-3863-9593', '0000-0002-4567-7117', '0000-0002-5695-8213', '0000-0002-2009-0483', '0000-0002-7426-272X', '0000-0002-4459-2082', '0000-0003-2220-0890']\n",
      "Total sample size after apply threshold:  338\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(338, 539)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "338\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        17\n",
      "          1       1.00      0.89      0.94        28\n",
      "          2       1.00      0.69      0.82        13\n",
      "          3       0.44      1.00      0.61       107\n",
      "          4       1.00      0.12      0.21        17\n",
      "          5       1.00      0.50      0.67        34\n",
      "          6       0.00      0.00      0.00        15\n",
      "          7       1.00      0.21      0.35        19\n",
      "          8       1.00      0.66      0.79        32\n",
      "          9       0.94      0.45      0.61        38\n",
      "         10       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.67      0.60      0.54       338\n",
      "\n",
      "[  0   0   0  17   0   0   0   0   0   0   0   0  25   0   2   0   0   0\n",
      "   0   0   1   0   0   0   9   4   0   0   0   0   0   0   0   0   0   0\n",
      " 107   0   0   0   0   0   0   0   0   0   0  15   2   0   0   0   0   0\n",
      "   0   0   0   0  17   0  17   0   0   0   0   0   0   0   0  15   0   0\n",
      "   0   0   0   0   0   0   0   0  15   0   0   0   4   0   0   0   0   0\n",
      "   0  11   0   0   0   0  21   0   0   0   0   0  21   0   0   0   0   0\n",
      "  17   0   0   0   0  18   0   0   0   0   0   0   0]\n",
      "MNB Accuracy:  0.5976331360946746\n",
      "MNB F1:  0.4544884833727657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.71      0.75        17\n",
      "          1       1.00      0.86      0.92        28\n",
      "          2       1.00      0.85      0.92        13\n",
      "          3       0.65      0.97      0.78       107\n",
      "          4       1.00      0.65      0.79        17\n",
      "          5       0.96      0.76      0.85        34\n",
      "          6       1.00      0.53      0.70        15\n",
      "          7       1.00      0.89      0.94        19\n",
      "          8       1.00      0.84      0.92        32\n",
      "          9       0.82      0.71      0.76        38\n",
      "         10       0.67      0.22      0.33        18\n",
      "\n",
      "avg / total       0.84      0.80      0.80       338\n",
      "\n",
      "[ 12   0   0   3   0   0   0   0   0   1   1   0  24   0   2   0   0   0\n",
      "   0   0   2   0   0   0  11   1   0   0   0   0   0   1   0   2   0   0\n",
      " 104   0   0   0   0   0   1   0   0   0   0   6  11   0   0   0   0   0\n",
      "   0   0   0   0   8   0  26   0   0   0   0   0   0   0   0   7   0   0\n",
      "   8   0   0   0   0   0   0   0   2   0   0   0  17   0   0   0   0   0\n",
      "   0   5   0   0   0   0  27   0   0   1   0   0   9   0   0   0   0   0\n",
      "  27   1   0   0   0  12   0   1   0   0   0   1   4]\n",
      "svc Accuracy:  0.8017751479289941\n",
      "svc F1:  0.7871926680300011\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        17\n",
      "          1       1.00      0.86      0.92        28\n",
      "          2       1.00      0.77      0.87        13\n",
      "          3       0.52      1.00      0.68       107\n",
      "          4       1.00      0.41      0.58        17\n",
      "          5       1.00      0.50      0.67        34\n",
      "          6       1.00      0.27      0.42        15\n",
      "          7       1.00      0.53      0.69        19\n",
      "          8       1.00      0.78      0.88        32\n",
      "          9       0.88      0.61      0.72        38\n",
      "         10       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.78      0.70      0.68       338\n",
      "\n",
      "[  8   0   0   8   0   0   0   0   0   1   0   0  24   0   3   0   0   0\n",
      "   0   0   1   0   0   0  10   2   0   0   0   0   0   1   0   0   0   0\n",
      " 107   0   0   0   0   0   0   0   0   0   0  10   7   0   0   0   0   0\n",
      "   0   0   0   0  17   0  17   0   0   0   0   0   0   0   0  11   0   0\n",
      "   4   0   0   0   0   0   0   0   9   0   0   0  10   0   0   0   0   0\n",
      "   0   7   0   0   0   0  25   0   0   0   0   0  15   0   0   0   0   0\n",
      "  23   0   0   0   0  18   0   0   0   0   0   0   0]\n",
      "LR Accuracy:  0.6952662721893491\n",
      "LR F1:  0.6428019626670446\n",
      "For name:  f_liu\n",
      "total sample size before apply threshold:  185\n",
      "Counter({'0000-0003-3228-0943': 31, '0000-0001-6224-5167': 30, '0000-0001-9241-8161': 22, '0000-0003-3028-5927': 17, '0000-0002-1934-3674': 16, '0000-0002-5006-8965': 16, '0000-0002-2261-6899': 13, '0000-0002-8325-1213': 11, '0000-0001-6693-1981': 5, '0000-0002-8371-6316': 4, '0000-0002-1074-2601': 3, '0000-0001-7029-0312': 3, '0000-0002-7776-0222': 3, '0000-0002-1467-8328': 2, '0000-0001-8032-6681': 2, '0000-0003-2644-2416': 2, '0000-0002-2769-5012': 1, '0000-0003-1322-4997': 1, '0000-0001-8701-2984': 1, '0000-0002-6572-251X': 1, '0000-0001-5625-2969': 1})\n",
      "['0000-0003-3028-5927', '0000-0002-1934-3674', '0000-0002-8325-1213', '0000-0002-5006-8965', '0000-0002-2261-6899', '0000-0001-9241-8161', '0000-0001-6224-5167', '0000-0003-3228-0943']\n",
      "Total sample size after apply threshold:  156\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(156, 628)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.38        17\n",
      "          1       1.00      0.56      0.72        16\n",
      "          2       1.00      0.18      0.31        11\n",
      "          3       1.00      0.50      0.67        16\n",
      "          4       1.00      1.00      1.00        13\n",
      "          5       1.00      0.95      0.98        22\n",
      "          6       0.94      1.00      0.97        30\n",
      "          7       0.46      1.00      0.63        31\n",
      "\n",
      "avg / total       0.88      0.76      0.74       156\n",
      "\n",
      "[ 4  0  0  0  0  0  1 12  0  9  0  0  0  0  1  6  0  0  2  0  0  0  0  9\n",
      "  0  0  0  8  0  0  0  8  0  0  0  0 13  0  0  0  0  0  0  0  0 21  0  1\n",
      "  0  0  0  0  0  0 30  0  0  0  0  0  0  0  0 31]\n",
      "MNB Accuracy:  0.7564102564102564\n",
      "MNB F1:  0.7065563172582785\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.71      0.80        17\n",
      "          1       1.00      0.62      0.77        16\n",
      "          2       0.88      0.64      0.74        11\n",
      "          3       1.00      0.69      0.81        16\n",
      "          4       1.00      1.00      1.00        13\n",
      "          5       1.00      1.00      1.00        22\n",
      "          6       1.00      1.00      1.00        30\n",
      "          7       0.59      0.94      0.72        31\n",
      "\n",
      "avg / total       0.90      0.86      0.86       156\n",
      "\n",
      "[12  0  0  0  0  0  0  5  0 10  0  0  0  0  0  6  0  0  7  0  0  0  0  4\n",
      "  0  0  0 11  0  0  0  5  0  0  0  0 13  0  0  0  0  0  0  0  0 22  0  0\n",
      "  0  0  0  0  0  0 30  0  1  0  1  0  0  0  0 29]\n",
      "svc Accuracy:  0.8589743589743589\n",
      "svc F1:  0.8557359611635927\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.53      0.69        17\n",
      "          1       1.00      0.62      0.77        16\n",
      "          2       0.83      0.45      0.59        11\n",
      "          3       1.00      0.69      0.81        16\n",
      "          4       1.00      1.00      1.00        13\n",
      "          5       0.96      1.00      0.98        22\n",
      "          6       1.00      1.00      1.00        30\n",
      "          7       0.56      0.97      0.71        31\n",
      "\n",
      "avg / total       0.89      0.83      0.83       156\n",
      "\n",
      "[ 9  0  0  0  0  1  0  7  0 10  0  0  0  0  0  6  0  0  5  0  0  0  0  6\n",
      "  0  0  0 11  0  0  0  5  0  0  0  0 13  0  0  0  0  0  0  0  0 22  0  0\n",
      "  0  0  0  0  0  0 30  0  0  0  1  0  0  0  0 30]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.8185310876487347\n",
      "For name:  a_rego\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0003-0700-3776': 70, '0000-0002-3131-4219': 5, '0000-0003-0883-0511': 2, '0000-0002-4596-3703': 1})\n",
      "['0000-0003-0700-3776']\n",
      "Total sample size after apply threshold:  70\n",
      "For name:  s_hammad\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0003-0571-4208': 26, '0000-0003-2102-1081': 3, '0000-0002-1313-2542': 1, '0000-0003-3280-564X': 1, '0000-0001-6061-9962': 1})\n",
      "['0000-0003-0571-4208']\n",
      "Total sample size after apply threshold:  26\n",
      "For name:  k_johansson\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0003-3735-3611': 13, '0000-0002-3749-998X': 9, '0000-0001-9940-5929': 3, '0000-0002-1571-1775': 1})\n",
      "['0000-0003-3735-3611']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  m_barreto\n",
      "total sample size before apply threshold:  201\n",
      "Counter({'0000-0002-0215-4930': 181, '0000-0002-6973-7233': 9, '0000-0001-6464-548X': 7, '0000-0001-8377-616X': 3, '0000-0001-5797-8913': 1})\n",
      "['0000-0002-0215-4930']\n",
      "Total sample size after apply threshold:  181\n",
      "For name:  j_moore\n",
      "total sample size before apply threshold:  154\n",
      "Counter({'0000-0001-8451-9421': 63, '0000-0002-5486-0407': 22, '0000-0003-4750-1550': 19, '0000-0003-4059-0538': 13, '0000-0002-6028-2084': 13, '0000-0002-0053-3347': 6, '0000-0003-4028-811X': 6, '0000-0002-5496-752X': 5, '0000-0001-8245-9306': 2, '0000-0002-7273-974X': 1, '0000-0001-8503-4880': 1, '0000-0001-9039-1014': 1, '0000-0002-8698-6143': 1, '0000-0001-5682-6897': 1})\n",
      "['0000-0002-5486-0407', '0000-0003-4059-0538', '0000-0001-8451-9421', '0000-0003-4750-1550', '0000-0002-6028-2084']\n",
      "Total sample size after apply threshold:  130\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 463)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        22\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.57      1.00      0.73        63\n",
      "          3       1.00      0.16      0.27        19\n",
      "          4       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.69      0.64      0.57       130\n",
      "\n",
      "[ 9  0 13  0  0  0  0 13  0  0  0  0 63  0  0  0  0 16  3  0  0  0  5  0\n",
      "  8]\n",
      "MNB Accuracy:  0.6384615384615384\n",
      "MNB F1:  0.46872017906886454\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.59      0.74        22\n",
      "          1       1.00      0.15      0.27        13\n",
      "          2       0.68      1.00      0.81        63\n",
      "          3       1.00      0.53      0.69        19\n",
      "          4       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.84      0.77      0.74       130\n",
      "\n",
      "[13  0  9  0  0  0  2 11  0  0  0  0 63  0  0  0  0  9 10  0  0  0  1  0\n",
      " 12]\n",
      "svc Accuracy:  0.7692307692307693\n",
      "svc F1:  0.6933742579259821\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        22\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.58      1.00      0.73        63\n",
      "          3       1.00      0.21      0.35        19\n",
      "          4       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.70      0.65      0.58       130\n",
      "\n",
      "[ 8  0 14  0  0  0  0 13  0  0  0  0 63  0  0  0  0 15  4  0  0  0  4  0\n",
      "  9]\n",
      "LR Accuracy:  0.6461538461538462\n",
      "LR F1:  0.48637987560131146\n",
      "For name:  a_gray\n",
      "total sample size before apply threshold:  121\n",
      "Counter({'0000-0003-4299-2194': 107, '0000-0003-1062-7942': 5, '0000-0002-6273-0637': 5, '0000-0002-5711-4872': 3, '0000-0003-0239-7278': 1})\n",
      "['0000-0003-4299-2194']\n",
      "Total sample size after apply threshold:  107\n",
      "For name:  v_martins\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0002-2909-8502': 71, '0000-0001-7611-861X': 18, '0000-0001-7565-9641': 6, '0000-0003-2465-5880': 5, '0000-0002-8824-7328': 3, '0000-0002-0327-538X': 1})\n",
      "['0000-0002-2909-8502', '0000-0001-7611-861X']\n",
      "Total sample size after apply threshold:  89\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 349)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        71\n",
      "          1       1.00      0.72      0.84        18\n",
      "\n",
      "avg / total       0.95      0.94      0.94        89\n",
      "\n",
      "[71  0  5 13]\n",
      "MNB Accuracy:  0.9438202247191011\n",
      "MNB F1:  0.9023480359885889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        71\n",
      "          1       1.00      0.72      0.84        18\n",
      "\n",
      "avg / total       0.95      0.94      0.94        89\n",
      "\n",
      "[71  0  5 13]\n",
      "svc Accuracy:  0.9438202247191011\n",
      "svc F1:  0.9023480359885889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        71\n",
      "          1       1.00      0.39      0.56        18\n",
      "\n",
      "avg / total       0.89      0.88      0.85        89\n",
      "\n",
      "[71  0 11  7]\n",
      "LR Accuracy:  0.8764044943820225\n",
      "LR F1:  0.7440522875816994\n",
      "For name:  t_zhou\n",
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0002-3935-4637': 55, '0000-0002-7858-0047': 12, '0000-0002-8744-9083': 3, '0000-0001-7416-5594': 2, '0000-0002-5829-7279': 2, '0000-0003-2219-6385': 2})\n",
      "['0000-0002-7858-0047', '0000-0002-3935-4637']\n",
      "Total sample size after apply threshold:  67\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 314)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.83      1.00      0.91        55\n",
      "\n",
      "avg / total       0.86      0.84      0.77        67\n",
      "\n",
      "[ 1 11  0 55]\n",
      "MNB Accuracy:  0.835820895522388\n",
      "MNB F1:  0.5314685314685315\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.98      1.00      0.99        55\n",
      "\n",
      "avg / total       0.99      0.99      0.98        67\n",
      "\n",
      "[11  1  0 55]\n",
      "svc Accuracy:  0.9850746268656716\n",
      "svc F1:  0.9737563650607128\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.82      1.00      0.90        55\n",
      "\n",
      "avg / total       0.67      0.82      0.74        67\n",
      "\n",
      "[ 0 12  0 55]\n",
      "LR Accuracy:  0.8208955223880597\n",
      "LR F1:  0.4508196721311476\n",
      "For name:  s_howell\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-8141-6515': 28, '0000-0001-8184-0324': 1, '0000-0001-5311-6996': 1, '0000-0002-5126-3228': 1})\n",
      "['0000-0001-8141-6515']\n",
      "Total sample size after apply threshold:  28\n",
      "For name:  m_larsson\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0003-3584-7829': 16, '0000-0003-4164-6513': 15, '0000-0002-5795-9867': 13, '0000-0002-6755-8418': 9, '0000-0002-3226-7397': 6, '0000-0001-7368-953X': 2})\n",
      "['0000-0003-3584-7829', '0000-0002-5795-9867', '0000-0003-4164-6513']\n",
      "Total sample size after apply threshold:  44\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 106)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.81      0.72        16\n",
      "          1       1.00      0.85      0.92        13\n",
      "          2       0.62      0.53      0.57        15\n",
      "\n",
      "avg / total       0.74      0.73      0.73        44\n",
      "\n",
      "[13  0  3  0 11  2  7  0  8]\n",
      "MNB Accuracy:  0.7272727272727273\n",
      "MNB F1:  0.7367724867724869\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.56      0.72        16\n",
      "          1       1.00      0.69      0.82        13\n",
      "          2       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.86      0.75      0.75        44\n",
      "\n",
      "[ 9  0  7  0  9  4  0  0 15]\n",
      "svc Accuracy:  0.75\n",
      "svc F1:  0.7566297117516628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        16\n",
      "          1       1.00      0.77      0.87        13\n",
      "          2       0.62      1.00      0.77        15\n",
      "\n",
      "avg / total       0.87      0.80      0.80        44\n",
      "\n",
      "[10  0  6  0 10  3  0  0 15]\n",
      "LR Accuracy:  0.7954545454545454\n",
      "LR F1:  0.802675585284281\n",
      "For name:  s_morris\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0003-2551-9717': 14, '0000-0002-5334-5809': 11, '0000-0002-7023-8634': 4, '0000-0002-8056-0934': 2, '0000-0003-4866-110X': 2})\n",
      "['0000-0002-5334-5809', '0000-0003-2551-9717']\n",
      "Total sample size after apply threshold:  25\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 58)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82        11\n",
      "          1       0.86      0.86      0.86        14\n",
      "\n",
      "avg / total       0.84      0.84      0.84        25\n",
      "\n",
      "[ 9  2  2 12]\n",
      "MNB Accuracy:  0.84\n",
      "MNB F1:  0.8376623376623377\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.88      1.00      0.93        14\n",
      "\n",
      "avg / total       0.93      0.92      0.92        25\n",
      "\n",
      "[ 9  2  0 14]\n",
      "svc Accuracy:  0.92\n",
      "svc F1:  0.9166666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.82      1.00      0.90        14\n",
      "\n",
      "avg / total       0.90      0.88      0.88        25\n",
      "\n",
      "[ 8  3  0 14]\n",
      "LR Accuracy:  0.88\n",
      "LR F1:  0.8726655348047538\n",
      "For name:  s_biswas\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0001-5067-0174': 10, '0000-0002-0700-7286': 9, '0000-0002-1348-2358': 6, '0000-0003-3144-0060': 5, '0000-0001-9250-5556': 2, '0000-0003-3844-980X': 1, '0000-0001-6448-4487': 1, '0000-0001-7103-9939': 1, '0000-0002-4343-6926': 1, '0000-0001-5979-3605': 1})\n",
      "['0000-0001-5067-0174']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  s_patel\n",
      "total sample size before apply threshold:  416\n",
      "Counter({'0000-0002-9142-5172': 117, '0000-0001-7247-2013': 81, '0000-0003-0046-5513': 57, '0000-0003-0614-6951': 48, '0000-0002-2386-8940': 28, '0000-0002-0626-1899': 21, '0000-0001-6969-490X': 14, '0000-0002-1235-3458': 10, '0000-0002-4471-2996': 7, '0000-0002-5448-5926': 6, '0000-0002-6136-3556': 6, '0000-0003-1200-0254': 5, '0000-0002-4969-3317': 3, '0000-0003-1674-711X': 3, '0000-0001-9540-9957': 3, '0000-0001-9472-0188': 2, '0000-0002-2177-5038': 1, '0000-0002-8455-6545': 1, '0000-0001-7803-8920': 1, '0000-0002-3444-2179': 1, '0000-0002-6058-8382': 1})\n",
      "['0000-0002-2386-8940', '0000-0003-0046-5513', '0000-0002-1235-3458', '0000-0001-6969-490X', '0000-0002-0626-1899', '0000-0001-7247-2013', '0000-0003-0614-6951', '0000-0002-9142-5172']\n",
      "Total sample size after apply threshold:  376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(376, 1096)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "376\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        28\n",
      "          1       1.00      0.42      0.59        57\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.00      0.00      0.00        14\n",
      "          4       1.00      0.71      0.83        21\n",
      "          5       0.95      0.88      0.91        81\n",
      "          6       1.00      0.83      0.91        48\n",
      "          7       0.56      0.99      0.71       117\n",
      "\n",
      "avg / total       0.79      0.74      0.72       376\n",
      "\n",
      "[ 14   0   0   0   0   0   0  14   0  24   0   0   0   2   0  31   0   0\n",
      "   0   0   0   0   0  10   0   0   0   0   0   0   0  14   0   0   0   0\n",
      "  15   1   0   5   0   0   0   0   0  71   0  10   0   0   0   0   0   0\n",
      "  40   8   0   0   0   0   0   1   0 116]\n",
      "MNB Accuracy:  0.7446808510638298\n",
      "MNB F1:  0.5782232582232583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        28\n",
      "          1       0.83      0.61      0.71        57\n",
      "          2       1.00      0.40      0.57        10\n",
      "          3       1.00      0.21      0.35        14\n",
      "          4       1.00      0.95      0.98        21\n",
      "          5       0.97      0.80      0.88        81\n",
      "          6       1.00      0.77      0.87        48\n",
      "          7       0.62      0.97      0.76       117\n",
      "\n",
      "avg / total       0.85      0.80      0.79       376\n",
      "\n",
      "[ 22   0   0   0   0   0   0   6   0  35   0   0   0   1   0  21   0   1\n",
      "   4   0   0   0   0   5   0   1   0   3   0   0   0  10   0   0   0   0\n",
      "  20   0   0   1   0   1   0   0   0  65   0  15   0   1   0   0   0   0\n",
      "  37  10   0   3   0   0   0   1   0 113]\n",
      "svc Accuracy:  0.7952127659574468\n",
      "svc F1:  0.7493007608106113\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.61      0.76        28\n",
      "          1       1.00      0.39      0.56        57\n",
      "          2       1.00      0.20      0.33        10\n",
      "          3       1.00      0.07      0.13        14\n",
      "          4       1.00      0.71      0.83        21\n",
      "          5       0.98      0.80      0.88        81\n",
      "          6       1.00      0.77      0.87        48\n",
      "          7       0.54      0.99      0.70       117\n",
      "\n",
      "avg / total       0.85      0.73      0.72       376\n",
      "\n",
      "[ 17   0   0   0   0   0   0  11   0  22   0   0   0   0   0  35   0   0\n",
      "   2   0   0   0   0   8   0   0   0   1   0   0   0  13   0   0   0   0\n",
      "  15   0   0   6   0   0   0   0   0  65   0  16   0   0   0   0   0   0\n",
      "  37  11   0   0   0   0   0   1   0 116]\n",
      "LR Accuracy:  0.7313829787234043\n",
      "LR F1:  0.633019531794928\n",
      "For name:  m_white\n",
      "total sample size before apply threshold:  292\n",
      "Counter({'0000-0003-1543-9342': 115, '0000-0002-3617-3232': 71, '0000-0002-9826-3962': 47, '0000-0001-9472-7806': 14, '0000-0002-7399-8348': 11, '0000-0001-6719-790X': 6, '0000-0002-7655-8145': 6, '0000-0002-2760-9057': 4, '0000-0001-6817-7126': 4, '0000-0003-3271-1221': 4, '0000-0002-8611-9525': 3, '0000-0002-0238-8913': 2, '0000-0001-9912-5070': 2, '0000-0002-1861-6757': 2, '0000-0001-5022-5505': 1})\n",
      "['0000-0002-9826-3962', '0000-0002-7399-8348', '0000-0003-1543-9342', '0000-0002-3617-3232', '0000-0001-9472-7806']\n",
      "Total sample size after apply threshold:  258\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258, 768)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "258\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        47\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.67      1.00      0.80       115\n",
      "          3       0.98      0.89      0.93        71\n",
      "          4       1.00      0.14      0.25        14\n",
      "\n",
      "avg / total       0.81      0.78      0.74       258\n",
      "\n",
      "[ 21   0  25   1   0   0   0  11   0   0   0   0 115   0   0   0   0   8\n",
      "  63   0   0   0  12   0   2]\n",
      "MNB Accuracy:  0.7790697674418605\n",
      "MNB F1:  0.5210352392705333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        47\n",
      "          1       1.00      0.64      0.78        11\n",
      "          2       0.79      1.00      0.88       115\n",
      "          3       1.00      0.87      0.93        71\n",
      "          4       1.00      0.64      0.78        14\n",
      "\n",
      "avg / total       0.91      0.88      0.88       258\n",
      "\n",
      "[ 35   0  12   0   0   0   7   4   0   0   0   0 115   0   0   0   0   9\n",
      "  62   0   0   0   5   0   9]\n",
      "svc Accuracy:  0.8837209302325582\n",
      "svc F1:  0.8461982443396743\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.28      0.43        47\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.62      1.00      0.77       115\n",
      "          3       1.00      0.82      0.90        71\n",
      "          4       1.00      0.14      0.25        14\n",
      "\n",
      "avg / total       0.79      0.73      0.68       258\n",
      "\n",
      "[ 13   0  34   0   0   0   0  11   0   0   0   0 115   0   0   0   0  13\n",
      "  58   0   0   0  12   0   2]\n",
      "LR Accuracy:  0.7286821705426356\n",
      "LR F1:  0.46984496124031006\n",
      "For name:  s_sherman\n",
      "total sample size before apply threshold:  125\n",
      "Counter({'0000-0002-3079-5153': 107, '0000-0001-6708-3398': 8, '0000-0003-3667-9898': 6, '0000-0003-4903-0422': 4})\n",
      "['0000-0002-3079-5153']\n",
      "Total sample size after apply threshold:  107\n",
      "For name:  j_dai\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-7720-8032': 15, '0000-0002-1185-5165': 11, '0000-0002-0111-9009': 4, '0000-0002-7414-3659': 1})\n",
      "['0000-0002-7720-8032', '0000-0002-1185-5165']\n",
      "Total sample size after apply threshold:  26\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 45)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        15\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[15  0  1 10]\n",
      "MNB Accuracy:  0.9615384615384616\n",
      "MNB F1:  0.9600614439324117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        15\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[15  0  1 10]\n",
      "svc Accuracy:  0.9615384615384616\n",
      "svc F1:  0.9600614439324117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.88      0.85      0.84        26\n",
      "\n",
      "[15  0  4  7]\n",
      "LR Accuracy:  0.8461538461538461\n",
      "LR F1:  0.8300653594771241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For name:  m_fischer\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0002-3429-1876': 10, '0000-0001-5133-1537': 9, '0000-0002-9429-0859': 8, '0000-0002-4014-3626': 8, '0000-0002-1888-1809': 7, '0000-0002-1885-0535': 3, '0000-0002-7826-9726': 2, '0000-0003-0810-6064': 1})\n",
      "['0000-0002-3429-1876']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  y_zeng\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0001-7483-5017': 20, '0000-0002-5310-0473': 3, '0000-0002-6164-5502': 1, '0000-0003-1193-3335': 1, '0000-0002-4237-6669': 1})\n",
      "['0000-0001-7483-5017']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  j_turner\n",
      "total sample size before apply threshold:  178\n",
      "Counter({'0000-0003-0076-8434': 78, '0000-0002-2760-1071': 26, '0000-0003-2427-1430': 23, '0000-0002-7258-1639': 17, '0000-0003-4106-6295': 14, '0000-0002-0023-4275': 13, '0000-0001-7311-0313': 4, '0000-0003-0286-8949': 1, '0000-0002-4327-9385': 1, '0000-0003-0793-4159': 1})\n",
      "['0000-0002-7258-1639', '0000-0003-2427-1430', '0000-0003-0076-8434', '0000-0003-4106-6295', '0000-0002-0023-4275', '0000-0002-2760-1071']\n",
      "Total sample size after apply threshold:  171\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(171, 795)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "171\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        17\n",
      "          1       0.93      0.57      0.70        23\n",
      "          2       0.70      0.97      0.82        78\n",
      "          3       1.00      0.93      0.96        14\n",
      "          4       1.00      0.38      0.56        13\n",
      "          5       0.92      0.88      0.90        26\n",
      "\n",
      "avg / total       0.84      0.80      0.78       171\n",
      "\n",
      "[ 6  0 11  0  0  0  0 13  9  0  0  1  0  1 76  0  0  1  0  0  1 13  0  0\n",
      "  0  0  8  0  5  0  0  0  3  0  0 23]\n",
      "MNB Accuracy:  0.7953216374269005\n",
      "MNB F1:  0.743687572840833\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.87        17\n",
      "          1       1.00      0.70      0.82        23\n",
      "          2       0.81      1.00      0.90        78\n",
      "          3       1.00      0.93      0.96        14\n",
      "          4       1.00      0.69      0.82        13\n",
      "          5       0.96      0.88      0.92        26\n",
      "\n",
      "avg / total       0.91      0.89      0.89       171\n",
      "\n",
      "[13  0  4  0  0  0  0 16  6  0  0  1  0  0 78  0  0  0  0  0  1 13  0  0\n",
      "  0  0  4  0  9  0  0  0  3  0  0 23]\n",
      "svc Accuracy:  0.8888888888888888\n",
      "svc F1:  0.8808126654103665\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        17\n",
      "          1       1.00      0.52      0.69        23\n",
      "          2       0.68      1.00      0.81        78\n",
      "          3       1.00      0.93      0.96        14\n",
      "          4       1.00      0.46      0.63        13\n",
      "          5       0.95      0.73      0.83        26\n",
      "\n",
      "avg / total       0.85      0.78      0.76       171\n",
      "\n",
      "[ 5  0 12  0  0  0  0 12 10  0  0  1  0  0 78  0  0  0  0  0  1 13  0  0\n",
      "  0  0  7  0  6  0  0  0  7  0  0 19]\n",
      "LR Accuracy:  0.7777777777777778\n",
      "LR F1:  0.7281964604255463\n",
      "For name:  c_cai\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-8701-2586': 28, '0000-0001-9008-6327': 19, '0000-0002-0167-1397': 7, '0000-0002-7213-621X': 2, '0000-0002-5047-0815': 1})\n",
      "['0000-0001-9008-6327', '0000-0002-8701-2586']\n",
      "Total sample size after apply threshold:  47\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 100)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        19\n",
      "          1       1.00      0.96      0.98        28\n",
      "\n",
      "avg / total       0.98      0.98      0.98        47\n",
      "\n",
      "[19  0  1 27]\n",
      "MNB Accuracy:  0.9787234042553191\n",
      "MNB F1:  0.9780885780885781\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        28\n",
      "\n",
      "avg / total       1.00      1.00      1.00        47\n",
      "\n",
      "[19  0  0 28]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        28\n",
      "\n",
      "avg / total       1.00      1.00      1.00        47\n",
      "\n",
      "[19  0  0 28]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  f_pereira\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  86\n",
      "Counter({'0000-0001-8950-1036': 28, '0000-0002-9381-3320': 21, '0000-0003-3317-8756': 13, '0000-0003-4392-4644': 7, '0000-0003-3421-7833': 4, '0000-0003-2100-0280': 4, '0000-0002-1937-6548': 4, '0000-0002-9602-2452': 3, '0000-0001-9718-3867': 1, '0000-0002-8132-0625': 1})\n",
      "['0000-0003-3317-8756', '0000-0002-9381-3320', '0000-0001-8950-1036']\n",
      "Total sample size after apply threshold:  62\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 222)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       0.95      1.00      0.98        21\n",
      "          2       0.82      1.00      0.90        28\n",
      "\n",
      "avg / total       0.90      0.89      0.87        62\n",
      "\n",
      "[ 6  1  6  0 21  0  0  0 28]\n",
      "MNB Accuracy:  0.8870967741935484\n",
      "MNB F1:  0.8371829799555153\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.77      0.83        13\n",
      "          1       0.95      0.95      0.95        21\n",
      "          2       0.93      1.00      0.97        28\n",
      "\n",
      "avg / total       0.93      0.94      0.93        62\n",
      "\n",
      "[10  1  2  1 20  0  0  0 28]\n",
      "svc Accuracy:  0.9354838709677419\n",
      "svc F1:  0.9170771756978654\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.56        13\n",
      "          1       1.00      0.90      0.95        21\n",
      "          2       0.74      1.00      0.85        28\n",
      "\n",
      "avg / total       0.88      0.84      0.82        62\n",
      "\n",
      "[ 5  0  8  0 19  2  0  0 28]\n",
      "LR Accuracy:  0.8387096774193549\n",
      "LR F1:  0.7846801346801348\n",
      "For name:  a_vitale\n",
      "total sample size before apply threshold:  56\n",
      "Counter({'0000-0001-5586-2255': 43, '0000-0002-8682-3125': 7, '0000-0002-7339-4034': 4, '0000-0003-4980-5574': 2})\n",
      "['0000-0001-5586-2255']\n",
      "Total sample size after apply threshold:  43\n",
      "For name:  q_yang\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0002-3510-8906': 18, '0000-0001-9849-6996': 17, '0000-0003-4205-1909': 17, '0000-0001-6628-5393': 15, '0000-0002-4378-2335': 10, '0000-0003-4038-2464': 8, '0000-0002-6788-8775': 7, '0000-0003-0279-8784': 5, '0000-0001-6720-8795': 2, '0000-0001-8253-2278': 1, '0000-0002-1437-4498': 1, '0000-0003-2067-5999': 1})\n",
      "['0000-0001-9849-6996', '0000-0001-6628-5393', '0000-0002-4378-2335', '0000-0002-3510-8906', '0000-0003-4205-1909']\n",
      "Total sample size after apply threshold:  77\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 131)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.94      0.84        17\n",
      "          1       1.00      0.73      0.85        15\n",
      "          2       1.00      0.30      0.46        10\n",
      "          3       0.75      1.00      0.86        18\n",
      "          4       0.89      0.94      0.91        17\n",
      "\n",
      "avg / total       0.86      0.83      0.81        77\n",
      "\n",
      "[16  0  0  1  0  0 11  0  3  1  5  0  3  1  1  0  0  0 18  0  0  0  0  1\n",
      " 16]\n",
      "MNB Accuracy:  0.8311688311688312\n",
      "MNB F1:  0.7842452284557547\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.94      0.86        17\n",
      "          1       0.86      0.80      0.83        15\n",
      "          2       0.83      0.50      0.62        10\n",
      "          3       0.86      1.00      0.92        18\n",
      "          4       1.00      0.94      0.97        17\n",
      "\n",
      "avg / total       0.87      0.87      0.86        77\n",
      "\n",
      "[16  0  1  0  0  0 12  0  3  0  4  1  5  0  0  0  0  0 18  0  0  1  0  0\n",
      " 16]\n",
      "svc Accuracy:  0.8701298701298701\n",
      "svc F1:  0.8420449929070617\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.94      0.86        17\n",
      "          1       0.92      0.80      0.86        15\n",
      "          2       1.00      0.50      0.67        10\n",
      "          3       0.78      1.00      0.88        18\n",
      "          4       1.00      0.94      0.97        17\n",
      "\n",
      "avg / total       0.89      0.87      0.86        77\n",
      "\n",
      "[16  0  0  1  0  0 12  0  3  0  4  1  5  0  0  0  0  0 18  0  0  0  0  1\n",
      " 16]\n",
      "LR Accuracy:  0.8701298701298701\n",
      "LR F1:  0.8472840277718326\n",
      "For name:  d_xue\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0002-0748-0962': 47, '0000-0002-8429-8136': 45, '0000-0001-9904-7615': 10, '0000-0001-6132-1236': 5, '0000-0003-1938-9055': 2, '0000-0001-5285-8867': 2})\n",
      "['0000-0002-0748-0962', '0000-0002-8429-8136', '0000-0001-9904-7615']\n",
      "Total sample size after apply threshold:  102\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(102, 134)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.96      0.81        47\n",
      "          1       0.95      0.80      0.87        45\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.74      0.79      0.76       102\n",
      "\n",
      "[45  2  0  9 36  0 10  0  0]\n",
      "MNB Accuracy:  0.7941176470588235\n",
      "MNB F1:  0.5594268967762943\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.94      0.85        47\n",
      "          1       0.87      0.89      0.88        45\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.75      0.82      0.78       102\n",
      "\n",
      "[44  3  0  5 40  0  7  3  0]\n",
      "svc Accuracy:  0.8235294117647058\n",
      "svc F1:  0.577829937053238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.87      0.82        47\n",
      "          1       0.82      0.89      0.85        45\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.72      0.79      0.75       102\n",
      "\n",
      "[41  6  0  5 40  0  7  3  0]\n",
      "LR Accuracy:  0.7941176470588235\n",
      "LR F1:  0.5570212765957447\n",
      "For name:  m_sadeghi\n",
      "total sample size before apply threshold:  98\n",
      "Counter({'0000-0003-0401-3493': 54, '0000-0001-5055-4544': 37, '0000-0002-3586-3012': 3, '0000-0002-7698-5630': 3, '0000-0002-0751-1255': 1})\n",
      "['0000-0003-0401-3493', '0000-0001-5055-4544']\n",
      "Total sample size after apply threshold:  91\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 203)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "91\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        54\n",
      "          1       1.00      0.86      0.93        37\n",
      "\n",
      "avg / total       0.95      0.95      0.94        91\n",
      "\n",
      "[54  0  5 32]\n",
      "MNB Accuracy:  0.945054945054945\n",
      "MNB F1:  0.9416442221367193\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        54\n",
      "          1       1.00      0.70      0.83        37\n",
      "\n",
      "avg / total       0.90      0.88      0.87        91\n",
      "\n",
      "[54  0 11 26]\n",
      "svc Accuracy:  0.8791208791208791\n",
      "svc F1:  0.8664799253034547\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        54\n",
      "          1       1.00      0.59      0.75        37\n",
      "\n",
      "avg / total       0.87      0.84      0.82        91\n",
      "\n",
      "[54  0 15 22]\n",
      "LR Accuracy:  0.8351648351648352\n",
      "LR F1:  0.8119057461761059\n",
      "For name:  h_chang\n",
      "total sample size before apply threshold:  182\n",
      "Counter({'0000-0001-5411-6680': 55, '0000-0002-7997-4822': 39, '0000-0002-8417-8847': 22, '0000-0001-8877-1886': 18, '0000-0001-5810-7562': 11, '0000-0001-5577-2356': 9, '0000-0002-9812-8015': 6, '0000-0002-5248-3433': 5, '0000-0003-4987-5943': 4, '0000-0003-1832-8509': 4, '0000-0002-9405-2121': 2, '0000-0001-7378-8212': 2, '0000-0003-4843-1259': 1, '0000-0002-5605-6500': 1, '0000-0002-5162-103X': 1, '0000-0003-0400-3658': 1, '0000-0002-7494-0033': 1})\n",
      "['0000-0002-8417-8847', '0000-0002-7997-4822', '0000-0001-5810-7562', '0000-0001-5411-6680', '0000-0001-8877-1886']\n",
      "Total sample size after apply threshold:  145\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(145, 223)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "145\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.55      0.69        22\n",
      "          1       1.00      0.92      0.96        39\n",
      "          2       1.00      0.09      0.17        11\n",
      "          3       0.67      1.00      0.80        55\n",
      "          4       1.00      0.72      0.84        18\n",
      "\n",
      "avg / total       0.86      0.81      0.78       145\n",
      "\n",
      "[12  0  0 10  0  0 36  0  3  0  0  0  1 10  0  0  0  0 55  0  1  0  0  4\n",
      " 13]\n",
      "MNB Accuracy:  0.8068965517241379\n",
      "MNB F1:  0.6908020675659008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.73      0.82        22\n",
      "          1       0.95      0.97      0.96        39\n",
      "          2       1.00      1.00      1.00        11\n",
      "          3       0.89      0.98      0.93        55\n",
      "          4       1.00      0.89      0.94        18\n",
      "\n",
      "avg / total       0.93      0.93      0.93       145\n",
      "\n",
      "[16  0  0  6  0  0 38  0  1  0  0  0 11  0  0  1  0  0 54  0  0  2  0  0\n",
      " 16]\n",
      "svc Accuracy:  0.9310344827586207\n",
      "svc F1:  0.9309498180630745\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.64      0.76        22\n",
      "          1       0.86      0.95      0.90        39\n",
      "          2       1.00      0.36      0.53        11\n",
      "          3       0.75      1.00      0.86        55\n",
      "          4       1.00      0.56      0.71        18\n",
      "\n",
      "avg / total       0.86      0.83      0.81       145\n",
      "\n",
      "[14  0  0  8  0  0 37  0  2  0  0  2  4  5  0  0  0  0 55  0  1  4  0  3\n",
      " 10]\n",
      "LR Accuracy:  0.8275862068965517\n",
      "LR F1:  0.7532379657532097\n",
      "For name:  a_lombardi\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0002-2013-3009': 49, '0000-0001-5421-9970': 21, '0000-0002-7875-2697': 15, '0000-0002-4520-0183': 4, '0000-0002-0383-9579': 1})\n",
      "['0000-0001-5421-9970', '0000-0002-2013-3009', '0000-0002-7875-2697']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 278)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        21\n",
      "          1       0.82      1.00      0.90        49\n",
      "          2       1.00      0.73      0.85        15\n",
      "\n",
      "avg / total       0.89      0.87      0.87        85\n",
      "\n",
      "[14  7  0  0 49  0  0  4 11]\n",
      "MNB Accuracy:  0.8705882352941177\n",
      "MNB F1:  0.8484121383203952\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        21\n",
      "          1       0.92      1.00      0.96        49\n",
      "          2       1.00      0.87      0.93        15\n",
      "\n",
      "avg / total       0.96      0.95      0.95        85\n",
      "\n",
      "[19  2  0  0 49  0  0  2 13]\n",
      "svc Accuracy:  0.9529411764705882\n",
      "svc F1:  0.946451914098973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        21\n",
      "          1       0.71      1.00      0.83        49\n",
      "          2       1.00      0.47      0.64        15\n",
      "\n",
      "avg / total       0.83      0.76      0.74        85\n",
      "\n",
      "[ 9 12  0  0 49  0  0  8  7]\n",
      "LR Accuracy:  0.7647058823529411\n",
      "LR F1:  0.6889573703133025\n",
      "For name:  c_correia\n",
      "total sample size before apply threshold:  55\n",
      "Counter({'0000-0001-5564-6675': 20, '0000-0001-5481-2010': 13, '0000-0002-4979-3254': 9, '0000-0002-6996-0734': 6, '0000-0003-2482-7873': 5, '0000-0002-0527-3206': 2})\n",
      "['0000-0001-5564-6675', '0000-0001-5481-2010']\n",
      "Total sample size after apply threshold:  33\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 274)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        20\n",
      "          1       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.90      0.88      0.87        33\n",
      "\n",
      "[20  0  4  9]\n",
      "MNB Accuracy:  0.8787878787878788\n",
      "MNB F1:  0.8636363636363635\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        20\n",
      "          1       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.97      0.97      0.97        33\n",
      "\n",
      "[20  0  1 12]\n",
      "svc Accuracy:  0.9696969696969697\n",
      "svc F1:  0.9678048780487805\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        20\n",
      "          1       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.88      0.85      0.84        33\n",
      "\n",
      "[20  0  5  8]\n",
      "LR Accuracy:  0.8484848484848485\n",
      "LR F1:  0.8253968253968255\n",
      "For name:  j_you\n",
      "total sample size before apply threshold:  239\n",
      "Counter({'0000-0002-2074-6745': 75, '0000-0002-4006-8339': 71, '0000-0002-5763-7403': 56, '0000-0002-4651-9081': 28, '0000-0001-8927-1015': 9})\n",
      "['0000-0002-5763-7403', '0000-0002-4651-9081', '0000-0002-4006-8339', '0000-0002-2074-6745']\n",
      "Total sample size after apply threshold:  230\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(230, 238)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "230\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.79      0.87        56\n",
      "          1       1.00      0.89      0.94        28\n",
      "          2       0.94      0.96      0.95        71\n",
      "          3       0.85      1.00      0.92        75\n",
      "\n",
      "avg / total       0.93      0.92      0.92       230\n",
      "\n",
      "[44  0  2 10  0 25  2  1  1  0 68  2  0  0  0 75]\n",
      "MNB Accuracy:  0.9217391304347826\n",
      "MNB F1:  0.9214944262374807\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93        56\n",
      "          1       0.96      0.89      0.93        28\n",
      "          2       0.96      0.94      0.95        71\n",
      "          3       0.99      0.97      0.98        75\n",
      "\n",
      "avg / total       0.95      0.95      0.95       230\n",
      "\n",
      "[54  0  1  1  1 25  2  0  3  1 67  0  2  0  0 73]\n",
      "svc Accuracy:  0.9521739130434783\n",
      "svc F1:  0.9467951976064263\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.96      0.94        56\n",
      "          1       1.00      0.82      0.90        28\n",
      "          2       0.93      0.96      0.94        71\n",
      "          3       0.99      0.99      0.99        75\n",
      "\n",
      "avg / total       0.95      0.95      0.95       230\n",
      "\n",
      "[54  0  1  1  1 23  4  0  3  0 68  0  1  0  0 74]\n",
      "LR Accuracy:  0.9521739130434783\n",
      "LR F1:  0.9430505825518614\n",
      "For name:  c_lopez\n",
      "total sample size before apply threshold:  53\n",
      "Counter({'0000-0001-9298-2969': 34, '0000-0003-3668-7468': 12, '0000-0001-6160-632X': 3, '0000-0001-5635-4463': 2, '0000-0002-7669-6572': 1, '0000-0002-3445-4284': 1})\n",
      "['0000-0003-3668-7468', '0000-0001-9298-2969']\n",
      "Total sample size after apply threshold:  46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 103)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        12\n",
      "          1       0.83      1.00      0.91        34\n",
      "\n",
      "avg / total       0.87      0.85      0.82        46\n",
      "\n",
      "[ 5  7  0 34]\n",
      "MNB Accuracy:  0.8478260869565217\n",
      "MNB F1:  0.747450980392157\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        12\n",
      "          1       0.83      1.00      0.91        34\n",
      "\n",
      "avg / total       0.87      0.85      0.82        46\n",
      "\n",
      "[ 5  7  0 34]\n",
      "svc Accuracy:  0.8478260869565217\n",
      "svc F1:  0.747450980392157\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29        12\n",
      "          1       0.77      1.00      0.87        34\n",
      "\n",
      "avg / total       0.83      0.78      0.72        46\n",
      "\n",
      "[ 2 10  0 34]\n",
      "LR Accuracy:  0.782608695652174\n",
      "LR F1:  0.5787545787545787\n",
      "For name:  y_oh\n",
      "total sample size before apply threshold:  91\n",
      "Counter({'0000-0002-4438-8890': 55, '0000-0002-9636-3329': 17, '0000-0001-8233-1898': 14, '0000-0002-9055-6250': 2, '0000-0002-3832-6108': 1, '0000-0003-4936-7287': 1, '0000-0003-2761-7820': 1})\n",
      "['0000-0002-4438-8890', '0000-0002-9636-3329', '0000-0001-8233-1898']\n",
      "Total sample size after apply threshold:  86\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 130)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        55\n",
      "          1       1.00      0.35      0.52        17\n",
      "          2       1.00      0.14      0.25        14\n",
      "\n",
      "avg / total       0.81      0.73      0.67        86\n",
      "\n",
      "[55  0  0 11  6  0 12  0  2]\n",
      "MNB Accuracy:  0.7325581395348837\n",
      "MNB F1:  0.5329355998692383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        55\n",
      "          1       1.00      1.00      1.00        17\n",
      "          2       1.00      0.64      0.78        14\n",
      "\n",
      "avg / total       0.95      0.94      0.94        86\n",
      "\n",
      "[55  0  0  0 17  0  5  0  9]\n",
      "svc Accuracy:  0.9418604651162791\n",
      "svc F1:  0.9130434782608696\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      1.00      0.81        55\n",
      "          1       1.00      0.35      0.52        17\n",
      "          2       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.64      0.71      0.62        86\n",
      "\n",
      "[55  0  0 11  6  0 14  0  0]\n",
      "LR Accuracy:  0.7093023255813954\n",
      "LR F1:  0.4455179817498658\n",
      "For name:  s_yoon\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-8556-423X': 27, '0000-0003-3487-6863': 16, '0000-0001-8904-0292': 15, '0000-0003-1787-7282': 8, '0000-0003-1868-1054': 1, '0000-0001-7263-8036': 1, '0000-0001-8323-6462': 1, '0000-0002-5330-8784': 1, '0000-0002-8361-9815': 1, '0000-0003-2695-9589': 1, '0000-0003-1384-3405': 1})\n",
      "['0000-0001-8904-0292', '0000-0002-8556-423X', '0000-0003-3487-6863']\n",
      "Total sample size after apply threshold:  58\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(58, 69)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.87      0.87        15\n",
      "          1       0.75      0.89      0.81        27\n",
      "          2       0.73      0.50      0.59        16\n",
      "\n",
      "avg / total       0.77      0.78      0.77        58\n",
      "\n",
      "[13  1  1  1 24  2  1  7  8]\n",
      "MNB Accuracy:  0.7758620689655172\n",
      "MNB F1:  0.7576061937643859\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.85        15\n",
      "          1       0.79      0.96      0.87        27\n",
      "          2       0.86      0.75      0.80        16\n",
      "\n",
      "avg / total       0.86      0.84      0.84        58\n",
      "\n",
      "[11  3  1  0 26  1  0  4 12]\n",
      "svc Accuracy:  0.8448275862068966\n",
      "svc F1:  0.8376068376068374\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.73      0.81        15\n",
      "          1       0.74      0.96      0.84        27\n",
      "          2       0.82      0.56      0.67        16\n",
      "\n",
      "avg / total       0.81      0.79      0.79        58\n",
      "\n",
      "[11  3  1  0 26  1  1  6  9]\n",
      "LR Accuracy:  0.7931034482758621\n",
      "LR F1:  0.7733970529669455\n",
      "For name:  a_lima\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0002-1507-2264': 16, '0000-0002-9779-0584': 12, '0000-0002-3582-2640': 10, '0000-0002-2396-9880': 9, '0000-0003-2261-2801': 8, '0000-0001-6980-6553': 8, '0000-0001-8251-6286': 7, '0000-0002-3714-9904': 5, '0000-0002-1055-0554': 5, '0000-0002-9083-3377': 2, '0000-0002-4473-5311': 2, '0000-0002-4568-9126': 1})\n",
      "['0000-0002-1507-2264', '0000-0002-9779-0584', '0000-0002-3582-2640']\n",
      "Total sample size after apply threshold:  38"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 80)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        16\n",
      "          1       1.00      1.00      1.00        12\n",
      "          2       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.92      0.89      0.89        38\n",
      "\n",
      "[16  0  0  0 12  0  4  0  6]\n",
      "MNB Accuracy:  0.8947368421052632\n",
      "MNB F1:  0.8796296296296297\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        16\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       0.89      0.80      0.84        10\n",
      "\n",
      "avg / total       0.90      0.89      0.89        38\n",
      "\n",
      "[16  0  0  1 10  1  2  0  8]\n",
      "svc Accuracy:  0.8947368421052632\n",
      "svc F1:  0.8884939621781727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80        16\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.86      0.79      0.78        38\n",
      "\n",
      "[16  0  0  3  9  0  5  0  5]\n",
      "LR Accuracy:  0.7894736842105263\n",
      "LR F1:  0.7746031746031745\n",
      "For name:  h_singh\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0002-8686-2802': 23, '0000-0002-9586-8544': 7, '0000-0002-6135-1897': 7, '0000-0001-9198-8779': 3, '0000-0002-2354-6474': 2, '0000-0002-1989-9066': 1, '0000-0002-9713-6048': 1, '0000-0003-1653-232X': 1})\n",
      "['0000-0002-8686-2802']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  s_scott\n",
      "total sample size before apply threshold:  143\n",
      "Counter({'0000-0001-7510-6297': 101, '0000-0002-8290-0461': 27, '0000-0002-4597-9094': 8, '0000-0002-8480-1547': 4, '0000-0002-5830-8943': 2, '0000-0002-4754-246X': 1})\n",
      "['0000-0002-8290-0461', '0000-0001-7510-6297']\n",
      "Total sample size after apply threshold:  128\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(128, 274)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "128\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.59      0.74        27\n",
      "          1       0.90      1.00      0.95       101\n",
      "\n",
      "avg / total       0.92      0.91      0.91       128\n",
      "\n",
      "[ 16  11   0 101]\n",
      "MNB Accuracy:  0.9140625\n",
      "MNB F1:  0.8462714270116825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        27\n",
      "          1       0.92      1.00      0.96       101\n",
      "\n",
      "avg / total       0.94      0.93      0.92       128\n",
      "\n",
      "[ 18   9   0 101]\n",
      "svc Accuracy:  0.9296875\n",
      "svc F1:  0.8786729857819906\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.26      0.41        27\n",
      "          1       0.83      1.00      0.91       101\n",
      "\n",
      "avg / total       0.87      0.84      0.80       128\n",
      "\n",
      "[  7  20   0 101]\n",
      "LR Accuracy:  0.84375\n",
      "LR F1:  0.6608373078961314\n",
      "For name:  z_he\n",
      "total sample size before apply threshold:  160\n",
      "Counter({'0000-0002-6098-7893': 46, '0000-0001-6302-6556': 40, '0000-0001-9526-8816': 18, '0000-0003-3507-5013': 18, '0000-0001-6496-3971': 12, '0000-0003-1505-8750': 7, '0000-0003-3608-0244': 6, '0000-0002-3265-7539': 6, '0000-0001-8569-6008': 5, '0000-0003-3947-4011': 1, '0000-0002-8431-5274': 1})\n",
      "['0000-0001-6302-6556', '0000-0001-9526-8816', '0000-0002-6098-7893', '0000-0001-6496-3971', '0000-0003-3507-5013']\n",
      "Total sample size after apply threshold:  134\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 196)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "134\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.80      0.82        40\n",
      "          1       1.00      0.50      0.67        18\n",
      "          2       0.71      0.98      0.83        46\n",
      "          3       1.00      0.92      0.96        12\n",
      "          4       1.00      0.72      0.84        18\n",
      "\n",
      "avg / total       0.85      0.82      0.82       134\n",
      "\n",
      "[32  0  8  0  0  2  9  7  0  0  1  0 45  0  0  1  0  0 11  0  2  0  3  0\n",
      " 13]\n",
      "MNB Accuracy:  0.8208955223880597\n",
      "MNB F1:  0.8216197954247544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.93      0.88        40\n",
      "          1       0.93      0.78      0.85        18\n",
      "          2       0.88      0.91      0.89        46\n",
      "          3       1.00      0.92      0.96        12\n",
      "          4       1.00      0.89      0.94        18\n",
      "\n",
      "avg / total       0.90      0.90      0.90       134\n",
      "\n",
      "[37  0  3  0  0  3 14  1  0  0  3  1 42  0  0  1  0  0 11  0  0  0  2  0\n",
      " 16]\n",
      "svc Accuracy:  0.8955223880597015\n",
      "svc F1:  0.9041504920864991\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.88      0.82        40\n",
      "          1       0.93      0.78      0.85        18\n",
      "          2       0.84      0.93      0.89        46\n",
      "          3       1.00      0.92      0.96        12\n",
      "          4       1.00      0.67      0.80        18\n",
      "\n",
      "avg / total       0.87      0.86      0.86       134\n",
      "\n",
      "[35  0  5  0  0  3 14  1  0  0  2  1 43  0  0  1  0  0 11  0  4  0  2  0\n",
      " 12]\n",
      "LR Accuracy:  0.8582089552238806\n",
      "LR F1:  0.8630267875048638\n",
      "For name:  s_mukherjee\n",
      "total sample size before apply threshold:  125\n",
      "Counter({'0000-0002-6715-3920': 38, '0000-0003-2522-2884': 20, '0000-0002-3295-9668': 17, '0000-0001-6031-2557': 13, '0000-0002-2932-2834': 8, '0000-0002-2449-2826': 5, '0000-0002-5479-3750': 5, '0000-0002-3417-4530': 3, '0000-0001-8371-4014': 3, '0000-0002-8445-0492': 3, '0000-0003-4794-137X': 2, '0000-0001-8743-7050': 2, '0000-0003-1668-0461': 2, '0000-0003-4176-3496': 1, '0000-0001-9651-6228': 1, '0000-0001-7299-0304': 1, '0000-0002-6157-1224': 1})\n",
      "['0000-0001-6031-2557', '0000-0002-3295-9668', '0000-0002-6715-3920', '0000-0003-2522-2884']\n",
      "Total sample size after apply threshold:  88\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 435)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       1.00      0.94      0.97        17\n",
      "          2       0.75      1.00      0.85        38\n",
      "          3       1.00      0.85      0.92        20\n",
      "\n",
      "avg / total       0.89      0.85      0.83        88\n",
      "\n",
      "[ 4  0  9  0  0 16  1  0  0  0 38  0  0  0  3 17]\n",
      "MNB Accuracy:  0.8522727272727273\n",
      "MNB F1:  0.8032841770449173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       1.00      0.94      0.97        17\n",
      "          2       0.72      1.00      0.84        38\n",
      "          3       1.00      0.65      0.79        20\n",
      "\n",
      "avg / total       0.88      0.83      0.82        88\n",
      "\n",
      "[ 6  0  7  0  0 16  1  0  0  0 38  0  0  0  7 13]\n",
      "svc Accuracy:  0.8295454545454546\n",
      "svc F1:  0.8060798850272535\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       1.00      0.71      0.83        17\n",
      "          2       0.62      1.00      0.77        38\n",
      "          3       1.00      0.55      0.71        20\n",
      "\n",
      "avg / total       0.84      0.74      0.72        88\n",
      "\n",
      "[ 4  0  9  0  0 12  5  0  0  0 38  0  0  0  9 11]\n",
      "LR Accuracy:  0.7386363636363636\n",
      "LR F1:  0.6938821573055689\n",
      "For name:  j_yue\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0001-9694-7722': 25, '0000-0001-6384-5447': 24, '0000-0002-2122-9221': 9, '0000-0002-2549-9261': 2, '0000-0003-4043-0737': 2})\n",
      "['0000-0001-6384-5447', '0000-0001-9694-7722']\n",
      "Total sample size after apply threshold:  49\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 142)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        24\n",
      "          1       1.00      0.92      0.96        25\n",
      "\n",
      "avg / total       0.96      0.96      0.96        49\n",
      "\n",
      "[24  0  2 23]\n",
      "MNB Accuracy:  0.9591836734693877\n",
      "MNB F1:  0.9591666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        24\n",
      "          1       1.00      0.96      0.98        25\n",
      "\n",
      "avg / total       0.98      0.98      0.98        49\n",
      "\n",
      "[24  0  1 24]\n",
      "svc Accuracy:  0.9795918367346939\n",
      "svc F1:  0.9795918367346939\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        24\n",
      "          1       1.00      0.96      0.98        25\n",
      "\n",
      "avg / total       0.98      0.98      0.98        49\n",
      "\n",
      "[24  0  1 24]\n",
      "LR Accuracy:  0.9795918367346939\n",
      "LR F1:  0.9795918367346939\n",
      "For name:  f_dias\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0001-9841-863X': 25, '0000-0001-9945-9185': 21, '0000-0002-5123-4929': 15, '0000-0002-4993-4467': 7})\n",
      "['0000-0001-9841-863X', '0000-0001-9945-9185', '0000-0002-5123-4929']\n",
      "Total sample size after apply threshold:  61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 168)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91        25\n",
      "          1       0.95      1.00      0.98        21\n",
      "          2       1.00      0.73      0.85        15\n",
      "\n",
      "avg / total       0.93      0.92      0.92        61\n",
      "\n",
      "[24  1  0  0 21  0  4  0 11]\n",
      "MNB Accuracy:  0.9180327868852459\n",
      "MNB F1:  0.9095194698529493\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        25\n",
      "          1       1.00      1.00      1.00        21\n",
      "          2       1.00      0.80      0.89        15\n",
      "\n",
      "avg / total       0.96      0.95      0.95        61\n",
      "\n",
      "[25  0  0  0 21  0  3  0 12]\n",
      "svc Accuracy:  0.9508196721311475\n",
      "svc F1:  0.9440950384346611\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        25\n",
      "          1       1.00      1.00      1.00        21\n",
      "          2       1.00      0.73      0.85        15\n",
      "\n",
      "avg / total       0.94      0.93      0.93        61\n",
      "\n",
      "[25  0  0  0 21  0  4  0 11]\n",
      "LR Accuracy:  0.9344262295081968\n",
      "LR F1:  0.9240265906932574\n",
      "For name:  r_walker\n",
      "total sample size before apply threshold:  87\n",
      "Counter({'0000-0002-5936-1068': 25, '0000-0003-0348-2407': 16, '0000-0001-7383-7846': 15, '0000-0002-6089-8225': 11, '0000-0003-0032-9925': 10, '0000-0001-9736-3497': 7, '0000-0002-2064-4546': 2, '0000-0002-5332-3562': 1})\n",
      "['0000-0001-7383-7846', '0000-0003-0348-2407', '0000-0002-5936-1068', '0000-0003-0032-9925', '0000-0002-6089-8225']\n",
      "Total sample size after apply threshold:  77\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 508)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.53      0.70        15\n",
      "          1       1.00      0.44      0.61        16\n",
      "          2       0.52      1.00      0.68        25\n",
      "          3       1.00      0.30      0.46        10\n",
      "          4       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       0.84      0.70      0.69        77\n",
      "\n",
      "[ 8  0  7  0  0  0  7  9  0  0  0  0 25  0  0  0  0  7  3  0  0  0  0  0\n",
      " 11]\n",
      "MNB Accuracy:  0.7012987012987013\n",
      "MNB F1:  0.6901635588949466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        15\n",
      "          1       1.00      0.75      0.86        16\n",
      "          2       0.71      1.00      0.83        25\n",
      "          3       1.00      0.90      0.95        10\n",
      "          4       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       0.91      0.87      0.87        77\n",
      "\n",
      "[10  0  5  0  0  0 12  4  0  0  0  0 25  0  0  0  0  1  9  0  0  0  0  0\n",
      " 11]\n",
      "svc Accuracy:  0.8701298701298701\n",
      "svc F1:  0.8875689223057645\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.53      0.70        15\n",
      "          1       1.00      0.56      0.72        16\n",
      "          2       0.56      1.00      0.71        25\n",
      "          3       1.00      0.40      0.57        10\n",
      "          4       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       0.86      0.74      0.73        77\n",
      "\n",
      "[ 8  0  7  0  0  0  9  7  0  0  0  0 25  0  0  0  0  6  4  0  0  0  0  0\n",
      " 11]\n",
      "LR Accuracy:  0.7402597402597403\n",
      "LR F1:  0.740273291925466\n",
      "For name:  l_campos\n",
      "total sample size before apply threshold:  12\n",
      "Counter({'0000-0001-5414-8746': 10, '0000-0003-2431-3274': 1, '0000-0002-1610-7617': 1})\n",
      "['0000-0001-5414-8746']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  m_iqbal\n",
      "total sample size before apply threshold:  8\n",
      "Counter({'0000-0001-5891-9798': 3, '0000-0003-4790-3584': 2, '0000-0001-6241-7547': 2, '0000-0002-5535-0839': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_lim\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5475-4153': 27, '0000-0002-0360-6361': 23, '0000-0002-5192-0486': 20, '0000-0001-7589-5150': 15, '0000-0003-3807-4163': 13, '0000-0001-8471-5684': 6, '0000-0003-4528-8514': 6, '0000-0001-9086-5101': 5, '0000-0003-0312-9937': 5, '0000-0002-4890-0396': 4, '0000-0003-0377-9032': 3, '0000-0003-4246-6223': 3, '0000-0002-9783-9050': 1, '0000-0002-9907-0628': 1, '0000-0003-0845-9994': 1, '0000-0003-0598-4574': 1, '0000-0002-9460-5136': 1, '0000-0003-0204-4990': 1})\n",
      "['0000-0003-3807-4163', '0000-0002-5475-4153', '0000-0001-7589-5150', '0000-0002-0360-6361', '0000-0002-5192-0486']\n",
      "Total sample size after apply threshold:  98\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 128)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.56        13\n",
      "          1       0.60      1.00      0.75        27\n",
      "          2       1.00      0.80      0.89        15\n",
      "          3       1.00      0.65      0.79        23\n",
      "          4       0.76      0.80      0.78        20\n",
      "\n",
      "avg / total       0.84      0.77      0.76        98\n",
      "\n",
      "[ 5  6  0  0  2  0 27  0  0  0  0  0 12  0  3  0  8  0 15  0  0  4  0  0\n",
      " 16]\n",
      "MNB Accuracy:  0.7653061224489796\n",
      "MNB F1:  0.7528811867066038\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.81      0.96      0.88        27\n",
      "          2       1.00      0.80      0.89        15\n",
      "          3       0.78      0.91      0.84        23\n",
      "          4       0.95      0.90      0.92        20\n",
      "\n",
      "avg / total       0.89      0.87      0.87        98\n",
      "\n",
      "[ 8  3  0  2  0  0 26  0  0  1  0  0 12  3  0  0  2  0 21  0  0  1  0  1\n",
      " 18]\n",
      "svc Accuracy:  0.8673469387755102\n",
      "svc F1:  0.8590453012147927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        13\n",
      "          1       0.76      0.96      0.85        27\n",
      "          2       1.00      0.80      0.89        15\n",
      "          3       0.76      0.83      0.79        23\n",
      "          4       0.86      0.90      0.88        20\n",
      "\n",
      "avg / total       0.85      0.83      0.82        98\n",
      "\n",
      "[ 6  3  0  2  2  0 26  0  0  1  0  0 12  3  0  0  4  0 19  0  0  1  0  1\n",
      " 18]\n",
      "LR Accuracy:  0.826530612244898\n",
      "LR F1:  0.8085284599610448\n",
      "For name:  p_li\n",
      "total sample size before apply threshold:  118\n",
      "Counter({'0000-0002-5715-548X': 20, '0000-0001-9602-9550': 18, '0000-0001-9098-7598': 14, '0000-0002-5876-2177': 9, '0000-0001-5836-1069': 9, '0000-0002-2572-5935': 7, '0000-0001-9339-3111': 7, '0000-0002-4273-4577': 7, '0000-0002-4684-4909': 6, '0000-0001-8771-3369': 5, '0000-0001-7960-1025': 4, '0000-0002-5192-8509': 4, '0000-0001-5761-9435': 3, '0000-0001-7603-7852': 2, '0000-0002-9330-5713': 1, '0000-0002-7112-9974': 1, '0000-0002-9445-506X': 1})\n",
      "['0000-0001-9098-7598', '0000-0001-9602-9550', '0000-0002-5715-548X']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 200)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.79      0.85        14\n",
      "          1       1.00      0.72      0.84        18\n",
      "          2       0.74      1.00      0.85        20\n",
      "\n",
      "avg / total       0.88      0.85      0.85        52\n",
      "\n",
      "[11  0  3  1 13  4  0  0 20]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.8453091177868116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.79      0.81        14\n",
      "          1       0.89      0.94      0.92        18\n",
      "          2       0.95      0.95      0.95        20\n",
      "\n",
      "avg / total       0.90      0.90      0.90        52\n",
      "\n",
      "[11  2  1  1 17  0  1  0 19]\n",
      "svc Accuracy:  0.9038461538461539\n",
      "svc F1:  0.894577911244578\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.64      0.75        14\n",
      "          1       0.85      0.94      0.89        18\n",
      "          2       0.91      1.00      0.95        20\n",
      "\n",
      "avg / total       0.89      0.88      0.88        52\n",
      "\n",
      "[ 9  3  2  1 17  0  0  0 20]\n",
      "LR Accuracy:  0.8846153846153846\n",
      "LR F1:  0.8657059314954051\n",
      "For name:  f_andrade\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0002-3856-3816': 12, '0000-0003-1199-2837': 12, '0000-0002-4947-2346': 11, '0000-0001-6257-1712': 2})\n",
      "['0000-0002-4947-2346', '0000-0002-3856-3816', '0000-0003-1199-2837']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 79)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        11\n",
      "          1       1.00      0.83      0.91        12\n",
      "          2       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.95      0.94      0.94        35\n",
      "\n",
      "[11  0  0  2 10  0  0  0 12]\n",
      "MNB Accuracy:  0.9428571428571428\n",
      "MNB F1:  0.9419191919191919\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        12\n",
      "          2       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        35\n",
      "\n",
      "[11  0  0  0 12  0  0  0 12]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        12\n",
      "          2       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        35\n",
      "\n",
      "[11  0  0  0 12  0  0  0 12]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  c_schmitt\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0003-2143-9226': 9, '0000-0002-7646-4739': 2, '0000-0003-3829-6970': 1, '0000-0002-8527-9682': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  t_tan\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0003-1228-9449': 40, '0000-0001-6624-1593': 18, '0000-0002-7589-602X': 11, '0000-0002-8547-6328': 3, '0000-0001-5329-7192': 1})\n",
      "['0000-0002-7589-602X', '0000-0001-6624-1593', '0000-0003-1228-9449']\n",
      "Total sample size after apply threshold:  69\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 224)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        11\n",
      "          1       1.00      0.22      0.36        18\n",
      "          2       0.65      1.00      0.78        40\n",
      "\n",
      "avg / total       0.79      0.68      0.62        69\n",
      "\n",
      "[ 3  0  8  0  4 14  0  0 40]\n",
      "MNB Accuracy:  0.6811594202898551\n",
      "MNB F1:  0.525507172565996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.89      0.44      0.59        18\n",
      "          2       0.75      0.97      0.85        40\n",
      "\n",
      "avg / total       0.83      0.80      0.78        69\n",
      "\n",
      "[ 8  0  3  0  8 10  0  1 39]\n",
      "svc Accuracy:  0.7971014492753623\n",
      "svc F1:  0.7608413142356696\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       1.00      0.11      0.20        18\n",
      "          2       0.62      1.00      0.76        40\n",
      "\n",
      "avg / total       0.78      0.64      0.54        69\n",
      "\n",
      "[ 2  0  9  0  2 16  0  0 40]\n",
      "LR Accuracy:  0.6376811594202898\n",
      "LR F1:  0.4231990231990232\n",
      "For name:  h_gomes\n",
      "total sample size before apply threshold:  11\n",
      "Counter({'0000-0003-1131-7604': 7, '0000-0001-6898-2408': 2, '0000-0003-3664-4740': 1, '0000-0002-6222-9180': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_matos\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0001-6998-5133': 27, '0000-0002-9584-6636': 21, '0000-0003-1358-1054': 15, '0000-0001-7320-7107': 14, '0000-0002-5240-8070': 3, '0000-0003-4076-2459': 1, '0000-0003-1692-2205': 1})\n",
      "['0000-0003-1358-1054', '0000-0002-9584-6636', '0000-0001-7320-7107', '0000-0001-6998-5133']\n",
      "Total sample size after apply threshold:  77\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 109)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        15\n",
      "          1       1.00      0.90      0.95        21\n",
      "          2       1.00      1.00      1.00        14\n",
      "          3       0.96      1.00      0.98        27\n",
      "\n",
      "avg / total       0.98      0.97      0.97        77\n",
      "\n",
      "[15  0  0  0  1 19  0  1  0  0 14  0  0  0  0 27]\n",
      "MNB Accuracy:  0.974025974025974\n",
      "MNB F1:  0.9748900293255133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        15\n",
      "          1       0.90      0.86      0.88        21\n",
      "          2       1.00      1.00      1.00        14\n",
      "          3       0.90      0.96      0.93        27\n",
      "\n",
      "avg / total       0.94      0.94      0.93        77\n",
      "\n",
      "[14  1  0  0  0 18  0  3  0  0 14  0  0  1  0 26]\n",
      "svc Accuracy:  0.935064935064935\n",
      "svc F1:  0.943034362609636\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        15\n",
      "          1       0.95      0.90      0.93        21\n",
      "          2       1.00      0.86      0.92        14\n",
      "          3       0.87      1.00      0.93        27\n",
      "\n",
      "avg / total       0.94      0.94      0.94        77\n",
      "\n",
      "[14  1  0  0  0 19  0  2  0  0 12  2  0  0  0 27]\n",
      "LR Accuracy:  0.935064935064935\n",
      "LR F1:  0.9366144788768842\n",
      "For name:  k_ryan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  182\n",
      "Counter({'0000-0002-1059-9681': 79, '0000-0003-3670-8505': 36, '0000-0001-5304-2026': 23, '0000-0003-4563-3744': 22, '0000-0001-9149-260X': 11, '0000-0002-0582-3693': 7, '0000-0002-9454-8768': 3, '0000-0002-6057-452X': 1})\n",
      "['0000-0001-9149-260X', '0000-0003-3670-8505', '0000-0001-5304-2026', '0000-0003-4563-3744', '0000-0002-1059-9681']\n",
      "Total sample size after apply threshold:  171\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(171, 1543)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "171\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.83      0.91        36\n",
      "          2       0.00      0.00      0.00        23\n",
      "          3       1.00      0.86      0.93        22\n",
      "          4       0.64      0.99      0.78        79\n",
      "\n",
      "avg / total       0.64      0.74      0.67       171\n",
      "\n",
      "[ 0  0  0  0 11  0 30  0  0  6  0  0  0  0 23  0  0  0 19  3  0  0  1  0\n",
      " 78]\n",
      "MNB Accuracy:  0.7426900584795322\n",
      "MNB F1:  0.5231840354767183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.97      0.81      0.88        36\n",
      "          2       1.00      0.70      0.82        23\n",
      "          3       1.00      1.00      1.00        22\n",
      "          4       0.80      0.99      0.89        79\n",
      "\n",
      "avg / total       0.90      0.88      0.88       171\n",
      "\n",
      "[ 6  0  0  0  5  0 29  0  0  7  0  0 16  0  7  0  0  0 22  0  0  1  0  0\n",
      " 78]\n",
      "svc Accuracy:  0.8830409356725146\n",
      "svc F1:  0.8583093377211025\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.96      0.72      0.83        36\n",
      "          2       1.00      0.13      0.23        23\n",
      "          3       1.00      0.86      0.93        22\n",
      "          4       0.64      0.99      0.78        79\n",
      "\n",
      "avg / total       0.76      0.74      0.68       171\n",
      "\n",
      "[ 0  0  0  0 11  0 26  0  0 10  0  0  3  0 20  0  0  0 19  3  0  1  0  0\n",
      " 78]\n",
      "LR Accuracy:  0.7368421052631579\n",
      "LR F1:  0.5518229454887628\n",
      "For name:  w_zheng\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-6236-9765': 48, '0000-0003-1034-0757': 24, '0000-0003-0021-6672': 9, '0000-0003-0799-3474': 7, '0000-0002-9915-6982': 3, '0000-0002-1750-4999': 2})\n",
      "['0000-0002-6236-9765', '0000-0003-1034-0757']\n",
      "Total sample size after apply threshold:  72\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 125)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        48\n",
      "          1       1.00      0.50      0.67        24\n",
      "\n",
      "avg / total       0.87      0.83      0.81        72\n",
      "\n",
      "[48  0 12 12]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.7777777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        48\n",
      "          1       1.00      0.83      0.91        24\n",
      "\n",
      "avg / total       0.95      0.94      0.94        72\n",
      "\n",
      "[48  0  4 20]\n",
      "svc Accuracy:  0.9444444444444444\n",
      "svc F1:  0.9345454545454546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        48\n",
      "          1       1.00      0.38      0.55        24\n",
      "\n",
      "avg / total       0.84      0.79      0.76        72\n",
      "\n",
      "[48  0 15  9]\n",
      "LR Accuracy:  0.7916666666666666\n",
      "LR F1:  0.7051597051597052\n",
      "For name:  j_franco\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0002-3874-8618': 46, '0000-0001-9255-8084': 16, '0000-0002-0898-3510': 13, '0000-0002-3165-394X': 9, '0000-0002-8249-5224': 1})\n",
      "['0000-0001-9255-8084', '0000-0002-3874-8618', '0000-0002-0898-3510']\n",
      "Total sample size after apply threshold:  75\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(75, 269)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.56      0.72        16\n",
      "          1       0.77      1.00      0.87        46\n",
      "          2       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.86      0.81      0.80        75\n",
      "\n",
      "[ 9  7  0  0 46  0  0  7  6]\n",
      "MNB Accuracy:  0.8133333333333334\n",
      "MNB F1:  0.7398344918901026\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.90      1.00      0.95        46\n",
      "          2       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        75\n",
      "\n",
      "[13  3  0  0 46  0  0  2 11]\n",
      "svc Accuracy:  0.9333333333333333\n",
      "svc F1:  0.9205573330173401\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.19      0.32        16\n",
      "          1       0.68      1.00      0.81        46\n",
      "          2       1.00      0.31      0.47        13\n",
      "\n",
      "avg / total       0.80      0.71      0.64        75\n",
      "\n",
      "[ 3 13  0  0 46  0  0  9  4]\n",
      "LR Accuracy:  0.7066666666666667\n",
      "LR F1:  0.5311317509459924\n",
      "For name:  l_walker\n",
      "total sample size before apply threshold:  194\n",
      "Counter({'0000-0001-9166-3261': 107, '0000-0001-5986-5015': 42, '0000-0003-2556-8076': 29, '0000-0001-5865-7257': 12, '0000-0002-6939-9721': 2, '0000-0001-9726-1853': 1, '0000-0001-8375-8041': 1})\n",
      "['0000-0003-2556-8076', '0000-0001-9166-3261', '0000-0001-5865-7257', '0000-0001-5986-5015']\n",
      "Total sample size after apply threshold:  190\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(190, 579)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "190\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.59        29\n",
      "          1       0.73      1.00      0.85       107\n",
      "          2       1.00      0.17      0.29        12\n",
      "          3       1.00      0.71      0.83        42\n",
      "\n",
      "avg / total       0.85      0.79      0.77       190\n",
      "\n",
      "[ 12  17   0   0   0 107   0   0   0  10   2   0   0  12   0  30]\n",
      "MNB Accuracy:  0.7947368421052632\n",
      "MNB F1:  0.6375658187694242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.66      0.79        29\n",
      "          1       0.83      1.00      0.91       107\n",
      "          2       1.00      0.92      0.96        12\n",
      "          3       1.00      0.74      0.85        42\n",
      "\n",
      "avg / total       0.90      0.88      0.88       190\n",
      "\n",
      "[ 19  10   0   0   0 107   0   0   0   1  11   0   0  11   0  31]\n",
      "svc Accuracy:  0.8842105263157894\n",
      "svc F1:  0.8760707838268003\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.39        29\n",
      "          1       0.66      1.00      0.80       107\n",
      "          2       1.00      0.25      0.40        12\n",
      "          3       1.00      0.45      0.62        42\n",
      "\n",
      "avg / total       0.81      0.72      0.67       190\n",
      "\n",
      "[  7  22   0   0   0 107   0   0   0   9   3   0   0  23   0  19]\n",
      "LR Accuracy:  0.7157894736842105\n",
      "LR F1:  0.5525867928118968\n",
      "For name:  a_gordon\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0003-1676-9853': 36, '0000-0002-0419-547X': 29, '0000-0002-9352-7877': 27, '0000-0002-1807-4644': 25, '0000-0002-0648-0346': 6, '0000-0002-5731-7215': 1, '0000-0003-2643-5419': 1, '0000-0001-6480-6095': 1})\n",
      "['0000-0003-1676-9853', '0000-0002-1807-4644', '0000-0002-0419-547X', '0000-0002-9352-7877']\n",
      "Total sample size after apply threshold:  117\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 492)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        36\n",
      "          1       1.00      0.72      0.84        25\n",
      "          2       1.00      0.79      0.88        29\n",
      "          3       1.00      0.93      0.96        27\n",
      "\n",
      "avg / total       0.91      0.87      0.87       117\n",
      "\n",
      "[36  0  0  0  7 18  0  0  6  0 23  0  2  0  0 25]\n",
      "MNB Accuracy:  0.8717948717948718\n",
      "MNB F1:  0.8777373388439949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.92      0.93        36\n",
      "          1       0.83      0.76      0.79        25\n",
      "          2       0.72      0.90      0.80        29\n",
      "          3       1.00      0.85      0.92        27\n",
      "\n",
      "avg / total       0.88      0.86      0.87       117\n",
      "\n",
      "[33  0  3  0  2 19  4  0  0  3 26  0  0  1  3 23]\n",
      "svc Accuracy:  0.8632478632478633\n",
      "svc F1:  0.8603110328638497\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84        36\n",
      "          1       1.00      0.72      0.84        25\n",
      "          2       0.96      0.86      0.91        29\n",
      "          3       1.00      0.85      0.92        27\n",
      "\n",
      "avg / total       0.90      0.87      0.87       117\n",
      "\n",
      "[36  0  0  0  7 18  0  0  4  0 25  0  3  0  1 23]\n",
      "LR Accuracy:  0.8717948717948718\n",
      "LR F1:  0.8758773784355179\n",
      "For name:  z_yin\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0003-1752-644X': 12, '0000-0002-3547-0606': 12, '0000-0002-7189-895X': 6, '0000-0002-4545-1783': 6, '0000-0002-1252-7809': 5, '0000-0003-4396-0215': 4, '0000-0001-8679-5251': 3, '0000-0001-5141-1967': 1, '0000-0002-7567-9084': 1, '0000-0003-0255-4421': 1, '0000-0002-7572-1748': 1})\n",
      "['0000-0003-1752-644X', '0000-0002-3547-0606']\n",
      "Total sample size after apply threshold:  24\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 89)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "24\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        12\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        24\n",
      "\n",
      "[12  0  1 11]\n",
      "MNB Accuracy:  0.9583333333333334\n",
      "MNB F1:  0.9582608695652175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        24\n",
      "\n",
      "[12  0  0 12]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        24\n",
      "\n",
      "[12  0  0 12]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  c_gu\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0002-8527-8145': 57, '0000-0002-8152-1400': 4, '0000-0002-9294-314X': 3, '0000-0002-3571-4658': 1})\n",
      "['0000-0002-8527-8145']\n",
      "Total sample size after apply threshold:  57\n",
      "For name:  a_soto\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0002-0144-1399': 17, '0000-0001-9672-9004': 5, '0000-0002-7265-0956': 4, '0000-0002-2641-9032': 3, '0000-0001-8648-8032': 3})\n",
      "['0000-0002-0144-1399']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  h_hsieh\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0001-8302-2472': 53, '0000-0003-3201-3677': 13, '0000-0002-2583-7670': 3, '0000-0002-4483-1768': 1})\n",
      "['0000-0003-3201-3677', '0000-0001-8302-2472']\n",
      "Total sample size after apply threshold:  66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 52)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.85      1.00      0.92        53\n",
      "\n",
      "avg / total       0.88      0.86      0.83        66\n",
      "\n",
      "[ 4  9  0 53]\n",
      "MNB Accuracy:  0.8636363636363636\n",
      "MNB F1:  0.6961636828644502\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        13\n",
      "          1       0.95      1.00      0.97        53\n",
      "\n",
      "avg / total       0.96      0.95      0.95        66\n",
      "\n",
      "[10  3  0 53]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.9210211408057439\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       0.83      1.00      0.91        53\n",
      "\n",
      "avg / total       0.86      0.83      0.78        66\n",
      "\n",
      "[ 2 11  0 53]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.5863247863247864\n",
      "For name:  m_crespo\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0002-7732-7808': 20, '0000-0002-1852-2259': 12, '0000-0001-8762-7874': 9, '0000-0002-7086-9751': 8})\n",
      "['0000-0002-7732-7808', '0000-0002-1852-2259']\n",
      "Total sample size after apply threshold:  32\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 165)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        20\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        32\n",
      "\n",
      "[20  0  0 12]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        20\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97        32\n",
      "\n",
      "[20  0  1 11]\n",
      "svc Accuracy:  0.96875\n",
      "svc F1:  0.9660657476139979\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        20\n",
      "          1       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.90      0.88      0.87        32\n",
      "\n",
      "[20  0  4  8]\n",
      "LR Accuracy:  0.875\n",
      "LR F1:  0.8545454545454545\n",
      "For name:  s_phillips\n",
      "total sample size before apply threshold:  183\n",
      "Counter({'0000-0002-1956-4098': 138, '0000-0002-5694-0670': 20, '0000-0002-2549-8111': 11, '0000-0001-7157-4122': 6, '0000-0002-3720-6470': 5, '0000-0002-4230-4454': 2, '0000-0003-0858-4701': 1})\n",
      "['0000-0002-1956-4098', '0000-0002-5694-0670', '0000-0002-2549-8111']\n",
      "Total sample size after apply threshold:  169\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 282)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "169\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       138\n",
      "          1       1.00      0.60      0.75        20\n",
      "          2       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.92      0.92      0.91       169\n",
      "\n",
      "[138   0   0   8  12   0   6   0   5]\n",
      "MNB Accuracy:  0.9171597633136095\n",
      "MNB F1:  0.775574712643678\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       138\n",
      "          1       1.00      0.90      0.95        20\n",
      "          2       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.98      0.98      0.98       169\n",
      "\n",
      "[138   0   0   2  18   0   1   0  10]\n",
      "svc Accuracy:  0.9822485207100592\n",
      "svc F1:  0.9629988950871803\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       138\n",
      "          1       1.00      0.40      0.57        20\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.82      0.86      0.82       169\n",
      "\n",
      "[138   0   0  12   8   0  11   0   0]\n",
      "LR Accuracy:  0.863905325443787\n",
      "LR F1:  0.4981684981684982\n",
      "For name:  r_rodrigues\n",
      "total sample size before apply threshold:  74\n",
      "Counter({'0000-0002-7631-743X': 30, '0000-0001-8592-850X': 22, '0000-0002-7557-1815': 10, '0000-0002-5894-2506': 2, '0000-0003-4493-2654': 2, '0000-0002-0437-2798': 2, '0000-0002-7589-7807': 1, '0000-0002-4261-1147': 1, '0000-0002-5115-6991': 1, '0000-0001-5631-0970': 1, '0000-0003-3522-9844': 1, '0000-0002-9952-3834': 1})\n",
      "['0000-0002-7557-1815', '0000-0002-7631-743X', '0000-0001-8592-850X']\n",
      "Total sample size after apply threshold:  62\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 173)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       0.79      1.00      0.88        30\n",
      "          2       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       0.90      0.87      0.84        62\n",
      "\n",
      "[ 2  8  0  0 30  0  0  0 22]\n",
      "MNB Accuracy:  0.8709677419354839\n",
      "MNB F1:  0.738562091503268\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       0.91      1.00      0.95        30\n",
      "          2       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       0.96      0.95      0.95        62\n",
      "\n",
      "[ 7  3  0  0 30  0  0  0 22]\n",
      "svc Accuracy:  0.9516129032258065\n",
      "svc F1:  0.9253034547152194\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       0.79      1.00      0.88        30\n",
      "          2       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       0.90      0.87      0.84        62\n",
      "\n",
      "[ 2  8  0  0 30  0  0  0 22]\n",
      "LR Accuracy:  0.8709677419354839\n",
      "LR F1:  0.738562091503268\n",
      "For name:  a_mansour\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0003-2544-2705': 7, '0000-0002-7543-575X': 4, '0000-0001-7312-4299': 3, '0000-0001-5886-0650': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  a_lau\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-5933-9290': 21, '0000-0002-6489-204X': 8, '0000-0003-3802-828X': 4, '0000-0002-7338-7176': 2})\n",
      "['0000-0002-5933-9290']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  j_berg\n",
      "total sample size before apply threshold:  171\n",
      "Counter({'0000-0003-0157-5888': 86, '0000-0003-3022-0963': 66, '0000-0003-2360-2664': 11, '0000-0003-2126-6476': 4, '0000-0001-8583-6349': 2, '0000-0001-7947-5073': 2})\n",
      "['0000-0003-3022-0963', '0000-0003-2360-2664', '0000-0003-0157-5888']\n",
      "Total sample size after apply threshold:  163\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(163, 406)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "163\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.65      0.70        66\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.75      0.93      0.83        86\n",
      "\n",
      "avg / total       0.71      0.75      0.72       163\n",
      "\n",
      "[43  0 23  7  0  4  6  0 80]\n",
      "MNB Accuracy:  0.754601226993865\n",
      "MNB F1:  0.511311192276112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.98      0.84        66\n",
      "          1       1.00      0.18      0.31        11\n",
      "          2       0.99      0.84      0.91        86\n",
      "\n",
      "avg / total       0.89      0.85      0.84       163\n",
      "\n",
      "[65  0  1  9  2  0 14  0 72]\n",
      "svc Accuracy:  0.852760736196319\n",
      "svc F1:  0.6858361764022142\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.67      0.70        66\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.74      0.88      0.80        86\n",
      "\n",
      "avg / total       0.69      0.74      0.71       163\n",
      "\n",
      "[44  0 22  6  0  5 10  0 76]\n",
      "LR Accuracy:  0.7361963190184049\n",
      "LR F1:  0.5008818342151676\n",
      "For name:  l_wilson\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0001-8709-8968': 18, '0000-0003-4175-7125': 11, '0000-0001-6659-6001': 11, '0000-0002-3779-8277': 11, '0000-0002-3532-0309': 5, '0000-0002-8333-5660': 3})\n",
      "['0000-0001-8709-8968', '0000-0003-4175-7125', '0000-0001-6659-6001', '0000-0002-3779-8277']\n",
      "Total sample size after apply threshold:  51\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 93)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        18\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       1.00      0.82      0.90        11\n",
      "          3       0.82      0.82      0.82        11\n",
      "\n",
      "avg / total       0.88      0.86      0.86        51\n",
      "\n",
      "[18  0  0  0  2  8  0  1  1  0  9  1  2  0  0  9]\n",
      "MNB Accuracy:  0.8627450980392157\n",
      "MNB F1:  0.8595839654568795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        18\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       0.85      1.00      0.92        11\n",
      "          3       0.77      0.91      0.83        11\n",
      "\n",
      "avg / total       0.92      0.90      0.90        51\n",
      "\n",
      "[17  0  0  1  0  8  1  2  0  0 11  0  0  0  1 10]\n",
      "svc Accuracy:  0.9019607843137255\n",
      "svc F1:  0.8908834586466166\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        18\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       0.90      0.82      0.86        11\n",
      "          3       0.75      0.82      0.78        11\n",
      "\n",
      "avg / total       0.87      0.86      0.86        51\n",
      "\n",
      "[18  0  0  0  1  8  1  1  0  0  9  2  2  0  0  9]\n",
      "LR Accuracy:  0.8627450980392157\n",
      "LR F1:  0.8512334347574622\n",
      "For name:  c_park\n",
      "total sample size before apply threshold:  360\n",
      "Counter({'0000-0003-4083-8791': 106, '0000-0002-2350-9876': 69, '0000-0003-1906-1308': 45, '0000-0002-9732-361X': 40, '0000-0002-3363-5788': 35, '0000-0002-7618-9028': 16, '0000-0003-1584-6896': 14, '0000-0002-1788-045X': 11, '0000-0001-9008-1964': 10, '0000-0003-4734-214X': 9, '0000-0002-0776-3188': 2, '0000-0003-0409-8132': 1, '0000-0003-0721-272X': 1, '0000-0002-5935-8264': 1})\n",
      "['0000-0002-3363-5788', '0000-0001-9008-1964', '0000-0002-7618-9028', '0000-0002-1788-045X', '0000-0002-2350-9876', '0000-0003-4083-8791', '0000-0002-9732-361X', '0000-0003-1584-6896', '0000-0003-1906-1308']\n",
      "Total sample size after apply threshold:  346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(346, 469)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "346\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.83      0.89        35\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00        16\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.93      0.81      0.87        69\n",
      "          5       0.52      1.00      0.69       106\n",
      "          6       1.00      0.40      0.57        40\n",
      "          7       1.00      0.64      0.78        14\n",
      "          8       1.00      0.64      0.78        45\n",
      "\n",
      "avg / total       0.73      0.71      0.67       346\n",
      "\n",
      "[ 29   0   0   0   2   4   0   0   0   0   0   0   0   0  10   0   0   0\n",
      "   0   0   0   0   0  16   0   0   0   0   0   0   0   1  10   0   0   0\n",
      "   0   0   0   0  56  13   0   0   0   0   0   0   0   0 106   0   0   0\n",
      "   0   0   0   0   0  24  16   0   0   0   0   0   0   0   5   0   9   0\n",
      "   1   0   0   0   1  14   0   0  29]\n",
      "MNB Accuracy:  0.708092485549133\n",
      "MNB F1:  0.5096286095274973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.89      0.93        35\n",
      "          1       1.00      0.90      0.95        10\n",
      "          2       1.00      0.62      0.77        16\n",
      "          3       1.00      0.36      0.53        11\n",
      "          4       0.91      0.84      0.87        69\n",
      "          5       0.75      0.95      0.84       106\n",
      "          6       0.92      0.82      0.87        40\n",
      "          7       1.00      0.79      0.88        14\n",
      "          8       0.84      0.84      0.84        45\n",
      "\n",
      "avg / total       0.87      0.85      0.85       346\n",
      "\n",
      "[ 31   0   0   0   0   1   0   0   3   0   9   0   0   0   1   0   0   0\n",
      "   0   0  10   0   0   3   2   0   1   0   0   0   4   1   5   0   0   1\n",
      "   0   0   0   0  58  10   1   0   0   0   0   0   0   3 101   0   0   2\n",
      "   0   0   0   0   0   7  33   0   0   0   0   0   0   0   3   0  11   0\n",
      "   1   0   0   0   2   4   0   0  38]\n",
      "svc Accuracy:  0.8526011560693642\n",
      "svc F1:  0.8309473200008728\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.91      0.94        35\n",
      "          1       1.00      0.80      0.89        10\n",
      "          2       1.00      0.25      0.40        16\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.91      0.87      0.89        69\n",
      "          5       0.68      0.95      0.79       106\n",
      "          6       0.97      0.80      0.88        40\n",
      "          7       1.00      0.79      0.88        14\n",
      "          8       0.88      0.82      0.85        45\n",
      "\n",
      "avg / total       0.83      0.82      0.81       346\n",
      "\n",
      "[ 32   0   0   0   0   1   0   0   2   0   8   0   0   0   2   0   0   0\n",
      "   0   0   4   0   0  10   1   0   1   0   0   0   0   1  10   0   0   0\n",
      "   0   0   0   0  60   9   0   0   0   0   0   0   0   3 101   0   0   2\n",
      "   0   0   0   0   0   8  32   0   0   0   0   0   0   0   3   0  11   0\n",
      "   1   0   0   0   2   5   0   0  37]\n",
      "LR Accuracy:  0.8236994219653179\n",
      "LR F1:  0.7242664613913237\n",
      "For name:  r_thomas\n",
      "total sample size before apply threshold:  368\n",
      "Counter({'0000-0002-0518-8386': 95, '0000-0002-2340-0301': 95, '0000-0003-1448-7182': 74, '0000-0003-2062-8623': 46, '0000-0001-9251-5543': 13, '0000-0002-2970-6352': 10, '0000-0002-2165-5917': 8, '0000-0003-1282-7825': 5, '0000-0003-3588-2317': 5, '0000-0002-7286-2764': 4, '0000-0001-8784-1707': 2, '0000-0001-5256-3313': 2, '0000-0002-2069-1799': 2, '0000-0002-8745-7462': 2, '0000-0001-5296-3114': 1, '0000-0002-8872-7866': 1, '0000-0003-3473-2579': 1, '0000-0002-5362-4816': 1, '0000-0001-7194-3653': 1})\n",
      "['0000-0002-0518-8386', '0000-0003-2062-8623', '0000-0001-9251-5543', '0000-0003-1448-7182', '0000-0002-2340-0301', '0000-0002-2970-6352']\n",
      "Total sample size after apply threshold:  333\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 1474)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.94      0.76        95\n",
      "          1       1.00      0.59      0.74        46\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       1.00      0.86      0.93        74\n",
      "          4       0.83      0.91      0.86        95\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.78      0.80      0.77       333\n",
      "\n",
      "[89  0  0  0  6  0 13 27  0  0  6  0 10  0  0  0  3  0  8  0  0 64  2  0\n",
      "  9  0  0  0 86  0  9  0  0  0  1  0]\n",
      "MNB Accuracy:  0.7987987987987988\n",
      "MNB F1:  0.5492553941959328\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.99      0.79        95\n",
      "          1       1.00      0.67      0.81        46\n",
      "          2       1.00      0.46      0.63        13\n",
      "          3       1.00      0.84      0.91        74\n",
      "          4       0.99      0.86      0.92        95\n",
      "          5       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.90      0.85      0.86       333\n",
      "\n",
      "[94  0  0  0  1  0 15 31  0  0  0  0  7  0  6  0  0  0 12  0  0 62  0  0\n",
      " 13  0  0  0 82  0  1  0  0  0  0  9]\n",
      "svc Accuracy:  0.8528528528528528\n",
      "svc F1:  0.8350840232087721\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      1.00      0.75        95\n",
      "          1       1.00      0.57      0.72        46\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       1.00      0.81      0.90        74\n",
      "          4       0.95      0.87      0.91        95\n",
      "          5       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.83      0.80      0.78       333\n",
      "\n",
      "[95  0  0  0  0  0 18 26  0  0  2  0 12  0  0  0  1  0 13  0  0 60  1  0\n",
      " 12  0  0  0 83  0  9  0  0  0  0  1]\n",
      "LR Accuracy:  0.7957957957957958\n",
      "LR F1:  0.5766137000418349\n",
      "For name:  j_fonseca\n",
      "total sample size before apply threshold:  170\n",
      "Counter({'0000-0003-1432-3671': 87, '0000-0002-0887-8796': 55, '0000-0001-6477-7028': 8, '0000-0001-6703-3278': 7, '0000-0001-7173-7374': 5, '0000-0003-1206-7969': 3, '0000-0003-2549-5823': 2, '0000-0002-3679-0337': 1, '0000-0002-6073-1791': 1, '0000-0002-2136-1011': 1})\n",
      "['0000-0003-1432-3671', '0000-0002-0887-8796']\n",
      "Total sample size after apply threshold:  142\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 813)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        87\n",
      "          1       1.00      0.84      0.91        55\n",
      "\n",
      "avg / total       0.94      0.94      0.94       142\n",
      "\n",
      "[87  0  9 46]\n",
      "MNB Accuracy:  0.9366197183098591\n",
      "MNB F1:  0.9308553806200291\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95        87\n",
      "          1       0.98      0.85      0.91        55\n",
      "\n",
      "avg / total       0.94      0.94      0.94       142\n",
      "\n",
      "[86  1  8 47]\n",
      "svc Accuracy:  0.9366197183098591\n",
      "svc F1:  0.9314488011586118\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        87\n",
      "          1       1.00      0.82      0.90        55\n",
      "\n",
      "avg / total       0.94      0.93      0.93       142\n",
      "\n",
      "[87  0 10 45]\n",
      "LR Accuracy:  0.9295774647887324\n",
      "LR F1:  0.9228260869565218\n",
      "For name:  s_henderson\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0002-1076-3867': 52, '0000-0002-9032-3828': 25, '0000-0003-3019-1891': 4, '0000-0001-6389-4927': 1})\n",
      "['0000-0002-1076-3867', '0000-0002-9032-3828']\n",
      "Total sample size after apply threshold:  77\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 421)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        52\n",
      "          1       1.00      0.64      0.78        25\n",
      "\n",
      "avg / total       0.90      0.88      0.87        77\n",
      "\n",
      "[52  0  9 16]\n",
      "MNB Accuracy:  0.8831168831168831\n",
      "MNB F1:  0.8504208935894668\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        52\n",
      "          1       1.00      0.68      0.81        25\n",
      "\n",
      "avg / total       0.91      0.90      0.89        77\n",
      "\n",
      "[52  0  8 17]\n",
      "svc Accuracy:  0.8961038961038961\n",
      "svc F1:  0.8690476190476191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.83        52\n",
      "          1       1.00      0.12      0.21        25\n",
      "\n",
      "avg / total       0.80      0.71      0.63        77\n",
      "\n",
      "[52  0 22  3]\n",
      "LR Accuracy:  0.7142857142857143\n",
      "LR F1:  0.5198412698412699\n",
      "For name:  m_coelho\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0003-3288-1693': 44, '0000-0002-7312-3429': 15, '0000-0002-5716-0561': 11, '0000-0002-6542-175X': 5, '0000-0003-3312-191X': 5, '0000-0002-7429-4967': 4, '0000-0002-0392-1118': 3, '0000-0002-9169-7776': 3, '0000-0002-0197-8081': 3})\n",
      "['0000-0003-3288-1693', '0000-0002-7312-3429', '0000-0002-5716-0561']\n",
      "Total sample size after apply threshold:  70\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 223)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90        44\n",
      "          1       1.00      0.67      0.80        15\n",
      "          2       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.88      0.86      0.85        70\n",
      "\n",
      "[44  0  0  5 10  0  5  0  6]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.801280512204882\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        44\n",
      "          1       1.00      0.73      0.85        15\n",
      "          2       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.92      0.91      0.91        70\n",
      "\n",
      "[44  0  0  4 11  0  2  0  9]\n",
      "svc Accuracy:  0.9142857142857143\n",
      "svc F1:  0.8941080196399346\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.85        44\n",
      "          1       1.00      0.40      0.57        15\n",
      "          2       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.84      0.79      0.76        70\n",
      "\n",
      "[44  0  0  9  6  0  6  0  5]\n",
      "LR Accuracy:  0.7857142857142857\n",
      "LR F1:  0.6835991678224689\n",
      "For name:  j_pearson\n",
      "total sample size before apply threshold:  119\n",
      "Counter({'0000-0002-3318-5406': 65, '0000-0001-5607-4517': 41, '0000-0002-2867-2269': 6, '0000-0002-3777-1453': 4, '0000-0002-9876-7837': 2, '0000-0002-1400-5932': 1})\n",
      "['0000-0001-5607-4517', '0000-0002-3318-5406']\n",
      "Total sample size after apply threshold:  106\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 364)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "106\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        41\n",
      "          1       0.89      1.00      0.94        65\n",
      "\n",
      "avg / total       0.93      0.92      0.92       106\n",
      "\n",
      "[33  8  0 65]\n",
      "MNB Accuracy:  0.9245283018867925\n",
      "MNB F1:  0.9169604386995691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94        41\n",
      "          1       0.98      0.94      0.96        65\n",
      "\n",
      "avg / total       0.95      0.95      0.95       106\n",
      "\n",
      "[40  1  4 61]\n",
      "svc Accuracy:  0.9528301886792453\n",
      "svc F1:  0.9509031959240388\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.85        41\n",
      "          1       0.86      1.00      0.92        65\n",
      "\n",
      "avg / total       0.91      0.90      0.89       106\n",
      "\n",
      "[30 11  0 65]\n",
      "LR Accuracy:  0.8962264150943396\n",
      "LR F1:  0.8835281190690241\n",
      "For name:  z_xie\n",
      "total sample size before apply threshold:  99\n",
      "Counter({'0000-0003-2974-1825': 48, '0000-0001-5816-6159': 17, '0000-0002-8348-4455': 16, '0000-0002-1539-5100': 8, '0000-0002-4526-9746': 6, '0000-0003-0308-5233': 1, '0000-0002-3137-561X': 1, '0000-0003-2492-0592': 1, '0000-0002-6600-8190': 1})\n",
      "['0000-0003-2974-1825', '0000-0002-8348-4455', '0000-0001-5816-6159']\n",
      "Total sample size after apply threshold:  81\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 1270)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      1.00      0.79        48\n",
      "          1       1.00      0.25      0.40        16\n",
      "          2       1.00      0.18      0.30        17\n",
      "\n",
      "avg / total       0.79      0.68      0.61        81\n",
      "\n",
      "[48  0  0 12  4  0 14  0  3]\n",
      "MNB Accuracy:  0.6790123456790124\n",
      "MNB F1:  0.4956284153005464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92        48\n",
      "          1       1.00      0.94      0.97        16\n",
      "          2       0.92      0.65      0.76        17\n",
      "\n",
      "avg / total       0.91      0.90      0.90        81\n",
      "\n",
      "[47  0  1  1 15  0  6  0 11]\n",
      "svc Accuracy:  0.9012345679012346\n",
      "svc F1:  0.8826437508633412\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        48\n",
      "          1       1.00      0.50      0.67        16\n",
      "          2       1.00      0.29      0.45        17\n",
      "\n",
      "avg / total       0.83      0.75      0.72        81\n",
      "\n",
      "[48  0  0  8  8  0 12  0  5]\n",
      "LR Accuracy:  0.7530864197530864\n",
      "LR F1:  0.6495994427028909\n",
      "For name:  m_wright\n",
      "total sample size before apply threshold:  379\n",
      "Counter({'0000-0001-7133-4970': 213, '0000-0002-0541-7556': 87, '0000-0002-2650-2426': 25, '0000-0001-8036-1161': 17, '0000-0003-2731-4707': 15, '0000-0002-9348-8740': 13, '0000-0001-7121-504X': 6, '0000-0001-5522-7796': 2, '0000-0002-5731-2692': 1})\n",
      "['0000-0001-8036-1161', '0000-0001-7133-4970', '0000-0002-2650-2426', '0000-0002-9348-8740', '0000-0002-0541-7556', '0000-0003-2731-4707']\n",
      "Total sample size after apply threshold:  370\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(370, 2203)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.11        17\n",
      "          1       0.76      1.00      0.87       213\n",
      "          2       1.00      0.08      0.15        25\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.94      0.94      0.94        87\n",
      "          5       1.00      0.07      0.12        15\n",
      "\n",
      "avg / total       0.82      0.81      0.74       370\n",
      "\n",
      "[  1  16   0   0   0   0   0 213   0   0   0   0   0  18   2   0   5   0\n",
      "   0  13   0   0   0   0   0   5   0   0  82   0   0  14   0   0   0   1]\n",
      "MNB Accuracy:  0.8081081081081081\n",
      "MNB F1:  0.365440275571338\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        17\n",
      "          1       0.88      1.00      0.94       213\n",
      "          2       1.00      0.56      0.72        25\n",
      "          3       1.00      0.77      0.87        13\n",
      "          4       1.00      0.97      0.98        87\n",
      "          5       1.00      0.80      0.89        15\n",
      "\n",
      "avg / total       0.93      0.92      0.91       370\n",
      "\n",
      "[  8   9   0   0   0   0   0 213   0   0   0   0   0  11  14   0   0   0\n",
      "   0   3   0  10   0   0   0   3   0   0  84   0   0   3   0   0   0  12]\n",
      "svc Accuracy:  0.9216216216216216\n",
      "svc F1:  0.8391871168072541\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        17\n",
      "          1       0.75      1.00      0.86       213\n",
      "          2       1.00      0.32      0.48        25\n",
      "          3       1.00      0.08      0.14        13\n",
      "          4       1.00      0.86      0.93        87\n",
      "          5       1.00      0.13      0.24        15\n",
      "\n",
      "avg / total       0.81      0.81      0.76       370\n",
      "\n",
      "[  0  17   0   0   0   0   0 213   0   0   0   0   0  17   8   0   0   0\n",
      "   0  12   0   1   0   0   0  12   0   0  75   0   0  13   0   0   0   2]\n",
      "LR Accuracy:  0.8081081081081081\n",
      "LR F1:  0.4410114214035783\n",
      "For name:  j_song\n",
      "total sample size before apply threshold:  248\n",
      "Counter({'0000-0003-0224-6322': 70, '0000-0003-2434-7511': 33, '0000-0001-6303-3801': 26, '0000-0003-0420-2374': 23, '0000-0002-4379-0909': 19, '0000-0002-2736-4037': 13, '0000-0001-6623-4369': 11, '0000-0002-9971-0541': 10, '0000-0001-9223-8590': 9, '0000-0003-3053-0929': 8, '0000-0001-7886-1765': 5, '0000-0003-1265-0337': 3, '0000-0001-7350-9578': 3, '0000-0003-4262-1895': 3, '0000-0002-3863-1719': 2, '0000-0002-3463-0196': 2, '0000-0002-9252-0331': 2, '0000-0002-6631-3232': 2, '0000-0003-3160-4643': 1, '0000-0002-2932-440X': 1, '0000-0003-3497-2513': 1, '0000-0002-7357-2136': 1})\n",
      "['0000-0003-0420-2374', '0000-0001-6303-3801', '0000-0003-0224-6322', '0000-0003-2434-7511', '0000-0001-6623-4369', '0000-0002-2736-4037', '0000-0002-4379-0909', '0000-0002-9971-0541']\n",
      "Total sample size after apply threshold:  205\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(205, 264)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "205\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.48      0.59        23\n",
      "          1       0.95      0.81      0.88        26\n",
      "          2       0.73      0.99      0.84        70\n",
      "          3       0.57      1.00      0.73        33\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       1.00      0.23      0.38        13\n",
      "          6       1.00      0.74      0.85        19\n",
      "          7       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.71      0.74      0.68       205\n",
      "\n",
      "[11  0  1 11  0  0  0  0  0 21  5  0  0  0  0  0  0  0 69  1  0  0  0  0\n",
      "  0  0  0 33  0  0  0  0  1  0  0 10  0  0  0  0  1  0  6  3  0  3  0  0\n",
      "  0  0  5  0  0  0 14  0  1  1  8  0  0  0  0  0]\n",
      "MNB Accuracy:  0.7365853658536585\n",
      "MNB F1:  0.5324771978735393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.70      0.65        23\n",
      "          1       1.00      0.96      0.98        26\n",
      "          2       0.85      0.97      0.91        70\n",
      "          3       0.71      0.82      0.76        33\n",
      "          4       0.80      0.36      0.50        11\n",
      "          5       1.00      0.54      0.70        13\n",
      "          6       0.94      0.84      0.89        19\n",
      "          7       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.84      0.83      0.82       205\n",
      "\n",
      "[16  0  1  6  0  0  0  0  0 25  1  0  0  0  0  0  1  0 68  0  0  0  1  0\n",
      "  5  0  0 27  1  0  0  0  2  0  0  5  4  0  0  0  1  0  5  0  0  7  0  0\n",
      "  0  0  3  0  0  0 16  0  1  0  2  0  0  0  0  7]\n",
      "svc Accuracy:  0.8292682926829268\n",
      "svc F1:  0.7766377161193116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.57      0.58        23\n",
      "          1       1.00      0.81      0.89        26\n",
      "          2       0.66      0.99      0.79        70\n",
      "          3       0.66      0.82      0.73        33\n",
      "          4       1.00      0.09      0.17        11\n",
      "          5       1.00      0.15      0.27        13\n",
      "          6       1.00      0.68      0.81        19\n",
      "          7       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.73      0.71      0.67       205\n",
      "\n",
      "[13  0  5  5  0  0  0  0  0 21  5  0  0  0  0  0  1  0 69  0  0  0  0  0\n",
      "  5  0  1 27  0  0  0  0  1  0  0  9  1  0  0  0  1  0 10  0  0  2  0  0\n",
      "  0  0  6  0  0  0 13  0  1  0  9  0  0  0  0  0]\n",
      "LR Accuracy:  0.7121951219512195\n",
      "LR F1:  0.5294411613361082\n",
      "For name:  k_becker\n",
      "total sample size before apply threshold:  394\n",
      "Counter({'0000-0002-6794-6656': 180, '0000-0002-6391-1341': 112, '0000-0002-6801-4498': 80, '0000-0003-4231-2590': 19, '0000-0001-6317-1884': 3})\n",
      "['0000-0002-6391-1341', '0000-0002-6801-4498', '0000-0002-6794-6656', '0000-0003-4231-2590']\n",
      "Total sample size after apply threshold:  391\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(391, 1502)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96       112\n",
      "          1       0.98      0.80      0.88        80\n",
      "          2       0.84      0.99      0.91       180\n",
      "          3       1.00      0.53      0.69        19\n",
      "\n",
      "avg / total       0.93      0.91      0.91       391\n",
      "\n",
      "[104   0   8   0   0  64  16   0   0   1 179   0   0   0   9  10]\n",
      "MNB Accuracy:  0.9130434782608695\n",
      "MNB F1:  0.8621605155472151\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93       112\n",
      "          1       1.00      0.75      0.86        80\n",
      "          2       0.84      1.00      0.91       180\n",
      "          3       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       0.93      0.91      0.91       391\n",
      "\n",
      "[ 97   0  15   0   0  60  20   0   0   0 180   0   0   0   0  19]\n",
      "svc Accuracy:  0.9104859335038363\n",
      "svc F1:  0.9241912318194796\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85       112\n",
      "          1       1.00      0.69      0.81        80\n",
      "          2       0.76      1.00      0.87       180\n",
      "          3       1.00      0.89      0.94        19\n",
      "\n",
      "avg / total       0.89      0.86      0.85       391\n",
      "\n",
      "[ 83   0  29   0   0  55  25   0   0   0 180   0   0   0   2  17]\n",
      "LR Accuracy:  0.8567774936061381\n",
      "LR F1:  0.8689814814814814\n",
      "For name:  r_sinha\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0001-5497-5055': 11, '0000-0001-8488-6280': 5, '0000-0003-4645-3243': 4, '0000-0003-4185-5198': 3, '0000-0002-7231-1356': 2, '0000-0001-8918-7585': 2})\n",
      "['0000-0001-5497-5055']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  c_turner\n",
      "total sample size before apply threshold:  88\n",
      "Counter({'0000-0002-2687-932X': 33, '0000-0001-9466-1149': 32, '0000-0002-4458-9748': 14, '0000-0001-7409-4386': 5, '0000-0002-1245-0741': 4})\n",
      "['0000-0001-9466-1149', '0000-0002-2687-932X', '0000-0002-4458-9748']\n",
      "Total sample size after apply threshold:  79\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 183)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        32\n",
      "          1       0.94      0.97      0.96        33\n",
      "          2       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.96      0.96      0.96        79\n",
      "\n",
      "[31  1  0  1 32  0  0  1 13]\n",
      "MNB Accuracy:  0.9620253164556962\n",
      "MNB F1:  0.9623122811866592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.96        32\n",
      "          1       1.00      0.94      0.97        33\n",
      "          2       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.97      0.96      0.96        79\n",
      "\n",
      "[32  0  0  2 31  0  1  0 13]\n",
      "svc Accuracy:  0.9620253164556962\n",
      "svc F1:  0.9623122811866592\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        32\n",
      "          1       0.97      0.94      0.95        33\n",
      "          2       1.00      0.71      0.83        14\n",
      "\n",
      "avg / total       0.93      0.92      0.92        79\n",
      "\n",
      "[32  0  0  2 31  0  3  1 10]\n",
      "LR Accuracy:  0.9240506329113924\n",
      "LR F1:  0.9049052396878484\n",
      "For name:  y_su\n",
      "total sample size before apply threshold:  190\n",
      "Counter({'0000-0002-1771-9017': 83, '0000-0002-5390-4113': 24, '0000-0003-3537-6246': 23, '0000-0003-3398-6294': 17, '0000-0001-8434-1758': 15, '0000-0003-2660-9183': 10, '0000-0003-2193-5473': 5, '0000-0002-4293-5037': 2, '0000-0001-7557-8518': 2, '0000-0002-4643-917X': 1, '0000-0001-8528-0694': 1, '0000-0003-0790-5905': 1, '0000-0003-0355-3981': 1, '0000-0002-8201-1592': 1, '0000-0002-4172-7981': 1, '0000-0001-6544-126X': 1, '0000-0001-7622-7269': 1, '0000-0002-8466-0043': 1})\n",
      "['0000-0001-8434-1758', '0000-0003-3398-6294', '0000-0002-5390-4113', '0000-0003-3537-6246', '0000-0002-1771-9017', '0000-0003-2660-9183']\n",
      "Total sample size after apply threshold:  172\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(172, 281)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "172\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        15\n",
      "          1       1.00      0.82      0.90        17\n",
      "          2       0.50      0.04      0.08        24\n",
      "          3       1.00      0.78      0.88        23\n",
      "          4       0.60      1.00      0.75        83\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.59      0.67      0.58       172\n",
      "\n",
      "[ 0  0  1  0 14  0  0 14  0  0  3  0  0  0  1  0 23  0  0  0  0 18  5  0\n",
      "  0  0  0  0 83  0  0  0  0  0 10  0]\n",
      "MNB Accuracy:  0.6744186046511628\n",
      "MNB F1:  0.43488814759699196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.67      0.62        15\n",
      "          1       1.00      1.00      1.00        17\n",
      "          2       0.88      0.58      0.70        24\n",
      "          3       1.00      0.91      0.95        23\n",
      "          4       0.82      0.98      0.89        83\n",
      "          5       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.86      0.84      0.83       172\n",
      "\n",
      "[10  0  0  0  5  0  0 17  0  0  0  0  1  0 14  0  9  0  0  0  0 21  2  0\n",
      "  0  0  2  0 81  0  6  0  0  0  2  2]\n",
      "svc Accuracy:  0.8430232558139535\n",
      "svc F1:  0.750498112998113\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.12        15\n",
      "          1       1.00      0.88      0.94        17\n",
      "          2       0.93      0.54      0.68        24\n",
      "          3       1.00      0.78      0.88        23\n",
      "          4       0.66      0.99      0.79        83\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.77      0.75      0.70       172\n",
      "\n",
      "[ 1  0  0  0 14  0  0 15  0  0  2  0  0  0 13  0 11  0  0  0  0 18  5  0\n",
      "  0  0  1  0 82  0  0  0  0  0 10  0]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.5695049730340934\n",
      "For name:  a_popov\n",
      "total sample size before apply threshold:  135\n",
      "Counter({'0000-0002-7596-0378': 99, '0000-0002-4678-6307': 15, '0000-0001-5024-5311': 13, '0000-0003-3881-7369': 3, '0000-0003-4602-5708': 3, '0000-0002-0889-6986': 1, '0000-0003-2643-4846': 1})\n",
      "['0000-0001-5024-5311', '0000-0002-4678-6307', '0000-0002-7596-0378']\n",
      "Total sample size after apply threshold:  127\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 211)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      0.27      0.42        15\n",
      "          2       0.90      1.00      0.95        99\n",
      "\n",
      "avg / total       0.92      0.91      0.89       127\n",
      "\n",
      "[13  0  0  0  4 11  0  0 99]\n",
      "MNB Accuracy:  0.9133858267716536\n",
      "MNB F1:  0.7894736842105262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      0.80      0.89        15\n",
      "          2       0.97      1.00      0.99        99\n",
      "\n",
      "avg / total       0.98      0.98      0.98       127\n",
      "\n",
      "[13  0  0  0 12  3  0  0 99]\n",
      "svc Accuracy:  0.9763779527559056\n",
      "svc F1:  0.9579878385848536\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        13\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.82      1.00      0.90        99\n",
      "\n",
      "avg / total       0.75      0.83      0.78       127\n",
      "\n",
      "[ 7  0  6  0  0 15  0  0 99]\n",
      "LR Accuracy:  0.8346456692913385\n",
      "LR F1:  0.534703196347032\n",
      "For name:  w_liao\n",
      "total sample size before apply threshold:  79\n",
      "Counter({'0000-0001-5362-6953': 29, '0000-0001-6383-3470': 25, '0000-0002-5619-4997': 16, '0000-0002-9768-0959': 5, '0000-0001-7221-5906': 3, '0000-0002-5333-2717': 1})\n",
      "['0000-0001-5362-6953', '0000-0002-5619-4997', '0000-0001-6383-3470']\n",
      "Total sample size after apply threshold:  70\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 117)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "70\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.90      0.76        29\n",
      "          1       1.00      0.38      0.55        16\n",
      "          2       0.80      0.80      0.80        25\n",
      "\n",
      "avg / total       0.79      0.74      0.73        70\n",
      "\n",
      "[26  0  3  8  6  2  5  0 20]\n",
      "MNB Accuracy:  0.7428571428571429\n",
      "MNB F1:  0.7033868092691623\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.83      0.84        29\n",
      "          1       0.80      1.00      0.89        16\n",
      "          2       0.91      0.80      0.85        25\n",
      "\n",
      "avg / total       0.86      0.86      0.86        70\n",
      "\n",
      "[24  3  2  0 16  0  4  1 20]\n",
      "svc Accuracy:  0.8571428571428571\n",
      "svc F1:  0.8606859939446725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.86      0.82        29\n",
      "          1       0.92      0.75      0.83        16\n",
      "          2       0.80      0.80      0.80        25\n",
      "\n",
      "avg / total       0.82      0.81      0.81        70\n",
      "\n",
      "[25  1  3  2 12  2  5  0 20]\n",
      "LR Accuracy:  0.8142857142857143\n",
      "LR F1:  0.8157527793480309\n",
      "For name:  j_zhong\n",
      "total sample size before apply threshold:  280\n",
      "Counter({'0000-0002-2265-9338': 115, '0000-0002-1494-6396': 70, '0000-0003-3148-4143': 37, '0000-0002-3534-7480': 21, '0000-0003-1801-9642': 19, '0000-0001-7157-603X': 8, '0000-0002-8815-4105': 4, '0000-0002-8945-4599': 3, '0000-0002-0556-2964': 1, '0000-0003-2750-9782': 1, '0000-0001-8785-1729': 1})\n",
      "['0000-0003-3148-4143', '0000-0003-1801-9642', '0000-0002-3534-7480', '0000-0002-2265-9338', '0000-0002-1494-6396']\n",
      "Total sample size after apply threshold:  262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(262, 508)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "262\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.72        37\n",
      "          1       0.00      0.00      0.00        19\n",
      "          2       1.00      0.19      0.32        21\n",
      "          3       0.68      0.96      0.80       115\n",
      "          4       0.83      0.89      0.86        70\n",
      "\n",
      "avg / total       0.74      0.75      0.71       262\n",
      "\n",
      "[ 21   1   0  15   0   0   0   0  15   4   0   0   4  13   4   0   0   0\n",
      " 110   5   0   0   0   8  62]\n",
      "MNB Accuracy:  0.7519083969465649\n",
      "MNB F1:  0.5392823588205897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        37\n",
      "          1       0.79      0.58      0.67        19\n",
      "          2       0.90      0.43      0.58        21\n",
      "          3       0.76      0.94      0.84       115\n",
      "          4       0.91      0.84      0.87        70\n",
      "\n",
      "avg / total       0.84      0.83      0.82       262\n",
      "\n",
      "[ 30   0   0   7   0   0  11   0   7   1   0   0   9  11   1   0   3   0\n",
      " 108   4   0   0   1  10  59]\n",
      "svc Accuracy:  0.8282442748091603\n",
      "svc F1:  0.7708235184832692\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        37\n",
      "          1       1.00      0.21      0.35        19\n",
      "          2       1.00      0.19      0.32        21\n",
      "          3       0.68      0.97      0.80       115\n",
      "          4       0.88      0.86      0.87        70\n",
      "\n",
      "avg / total       0.83      0.77      0.74       262\n",
      "\n",
      "[ 23   0   0  14   0   0   4   0  12   3   0   0   4  16   1   0   0   0\n",
      " 111   4   0   0   0  10  60]\n",
      "LR Accuracy:  0.7709923664122137\n",
      "LR F1:  0.6205238244187259\n",
      "For name:  a_wheeler\n",
      "total sample size before apply threshold:  138\n",
      "Counter({'0000-0001-5230-7475': 72, '0000-0001-9288-8163': 43, '0000-0001-8617-827X': 15, '0000-0002-9926-1301': 5, '0000-0002-1120-3618': 2, '0000-0001-9755-674X': 1})\n",
      "['0000-0001-5230-7475', '0000-0001-8617-827X', '0000-0001-9288-8163']\n",
      "Total sample size after apply threshold:  130\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 334)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "130\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        72\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       1.00      0.86      0.92        43\n",
      "\n",
      "avg / total       0.76      0.84      0.79       130\n",
      "\n",
      "[72  0  0 15  0  0  6  0 37]\n",
      "MNB Accuracy:  0.8384615384615385\n",
      "MNB F1:  0.5992424242424242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        72\n",
      "          1       1.00      0.27      0.42        15\n",
      "          2       1.00      0.84      0.91        43\n",
      "\n",
      "avg / total       0.89      0.86      0.84       130\n",
      "\n",
      "[72  0  0 11  4  0  7  0 36]\n",
      "svc Accuracy:  0.8615384615384616\n",
      "svc F1:  0.7404446418437093\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.85        72\n",
      "          1       1.00      0.13      0.24        15\n",
      "          2       1.00      0.70      0.82        43\n",
      "\n",
      "avg / total       0.85      0.80      0.77       130\n",
      "\n",
      "[72  0  0 13  2  0 13  0 30]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.6347569164652164\n",
      "For name:  m_walsh\n",
      "total sample size before apply threshold:  37\n",
      "Counter({'0000-0001-5683-1151': 30, '0000-0001-8920-7419': 3, '0000-0002-1770-3314': 2, '0000-0003-0982-4105': 2})\n",
      "['0000-0001-5683-1151']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  r_figueiredo\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0002-2122-6530': 29, '0000-0001-5806-0944': 17, '0000-0002-4304-6434': 1, '0000-0002-0933-4854': 1})\n",
      "['0000-0001-5806-0944', '0000-0002-2122-6530']\n",
      "Total sample size after apply threshold:  46\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 162)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        17\n",
      "          1       0.91      1.00      0.95        29\n",
      "\n",
      "avg / total       0.94      0.93      0.93        46\n",
      "\n",
      "[14  3  0 29]\n",
      "MNB Accuracy:  0.9347826086956522\n",
      "MNB F1:  0.9270227392913801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.88      0.91        17\n",
      "          1       0.93      0.97      0.95        29\n",
      "\n",
      "avg / total       0.93      0.93      0.93        46\n",
      "\n",
      "[15  2  1 28]\n",
      "svc Accuracy:  0.9347826086956522\n",
      "svc F1:  0.9291217257318953\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.59      0.74        17\n",
      "          1       0.81      1.00      0.89        29\n",
      "\n",
      "avg / total       0.88      0.85      0.84        46\n",
      "\n",
      "[10  7  0 29]\n",
      "LR Accuracy:  0.8478260869565217\n",
      "LR F1:  0.8165242165242166\n",
      "For name:  y_lin\n",
      "total sample size before apply threshold:  785\n",
      "Counter({'0000-0003-3791-7587': 146, '0000-0001-8153-1441': 115, '0000-0003-1224-6561': 64, '0000-0002-4192-3165': 49, '0000-0002-2499-8632': 39, '0000-0001-8667-0811': 33, '0000-0002-5887-0880': 24, '0000-0001-5227-2663': 23, '0000-0002-4350-7755': 23, '0000-0003-4913-8003': 22, '0000-0001-6460-2877': 21, '0000-0003-1954-334X': 20, '0000-0001-8572-649X': 20, '0000-0001-5574-7062': 15, '0000-0002-0352-2694': 15, '0000-0002-9390-795X': 13, '0000-0001-8904-1287': 13, '0000-0003-3410-3588': 12, '0000-0003-4384-8354': 9, '0000-0001-6833-8276': 9, '0000-0002-8746-3387': 9, '0000-0002-0796-0130': 8, '0000-0002-0435-7694': 8, '0000-0001-6454-0901': 7, '0000-0002-0123-9836': 6, '0000-0001-7120-4690': 6, '0000-0001-5100-6072': 6, '0000-0003-3913-5298': 6, '0000-0003-3177-5186': 5, '0000-0003-1240-7011': 5, '0000-0003-1470-4159': 5, '0000-0001-7910-1223': 4, '0000-0003-4289-894X': 4, '0000-0002-7289-5347': 4, '0000-0003-1328-1641': 2, '0000-0002-2229-6354': 2, '0000-0002-6835-7116': 2, '0000-0001-6819-1235': 2, '0000-0003-2656-3613': 1, '0000-0002-5379-5359': 1, '0000-0003-4327-7432': 1, '0000-0001-7923-0789': 1, '0000-0002-7492-9985': 1, '0000-0002-7639-9594': 1, '0000-0002-2502-2412': 1, '0000-0001-7243-0980': 1, '0000-0002-8287-1429': 1})\n",
      "['0000-0002-9390-795X', '0000-0001-8904-1287', '0000-0002-2499-8632', '0000-0003-1954-334X', '0000-0001-8667-0811', '0000-0002-4192-3165', '0000-0001-8572-649X', '0000-0003-3791-7587', '0000-0001-5227-2663', '0000-0003-3410-3588', '0000-0002-5887-0880', '0000-0001-5574-7062', '0000-0001-8153-1441', '0000-0003-1224-6561', '0000-0002-0352-2694', '0000-0003-4913-8003', '0000-0001-6460-2877', '0000-0002-4350-7755']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 667\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(667, 786)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       1.00      0.13      0.23        39\n",
      "          3       0.00      0.00      0.00        20\n",
      "          4       0.00      0.00      0.00        33\n",
      "          5       0.82      0.82      0.82        49\n",
      "          6       0.00      0.00      0.00        20\n",
      "          7       0.53      0.97      0.69       146\n",
      "          8       1.00      0.13      0.23        23\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       0.00      0.00      0.00        24\n",
      "         11       0.00      0.00      0.00        15\n",
      "         12       0.41      1.00      0.58       115\n",
      "         13       0.82      0.77      0.79        64\n",
      "         14       0.00      0.00      0.00        15\n",
      "         15       0.00      0.00      0.00        22\n",
      "         16       0.00      0.00      0.00        21\n",
      "         17       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.42      0.53      0.41       667\n",
      "\n",
      "[  0   0   0   0   0   1   0  11   0   0   0   0   1   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  13   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   5   0   0   0   0   3   0   0   0   0  31   0   0   0   0   0\n",
      "   0   0   0   0   0   3   0   1   0   0   0   0  16   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   2   0   0   0   0  30   0   0   0   0   0\n",
      "   0   0   0   0   0  40   0   0   0   0   0   0   9   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   9   0   0   0   0   5   6   0   0   0   0\n",
      "   0   0   0   0   0   0   0 142   0   0   0   0   4   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  19   3   0   0   0   0   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0   9   0   0   0   0   0   3   0   0   0   0\n",
      "   0   0   0   0   0   1   0   3   0   0   0   0  19   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0   0   0   0  14   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 115   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  14   0   0   0   0   1  49   0   0   0   0\n",
      "   0   0   0   0   0   0   0  13   0   0   0   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   2   0   9   0   0   0   0  11   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0  18   0   0   0   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0]\n",
      "MNB Accuracy:  0.5307346326836582\n",
      "MNB F1:  0.185012880458593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82        13\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       0.92      0.59      0.72        39\n",
      "          3       0.45      0.25      0.32        20\n",
      "          4       0.77      0.73      0.75        33\n",
      "          5       0.92      0.96      0.94        49\n",
      "          6       1.00      0.55      0.71        20\n",
      "          7       0.71      0.99      0.83       146\n",
      "          8       0.95      0.78      0.86        23\n",
      "          9       0.88      0.58      0.70        12\n",
      "         10       0.76      0.54      0.63        24\n",
      "         11       0.58      0.47      0.52        15\n",
      "         12       0.73      0.92      0.82       115\n",
      "         13       0.92      0.84      0.88        64\n",
      "         14       1.00      1.00      1.00        15\n",
      "         15       0.12      0.05      0.07        22\n",
      "         16       0.90      0.86      0.88        21\n",
      "         17       0.87      0.57      0.68        23\n",
      "\n",
      "avg / total       0.79      0.78      0.77       667\n",
      "\n",
      "[  9   0   0   0   0   0   0   3   0   0   1   0   0   0   0   0   0   0\n",
      "   0   8   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23   0   1   0   0   1   0   0   1   0  12   0   0   0   0   1\n",
      "   0   0   0   5   3   1   0   3   0   1   0   1   3   0   0   1   2   0\n",
      "   0   0   0   0  24   2   0   2   0   0   0   0   4   0   0   1   0   0\n",
      "   0   0   0   0   1  47   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "   0   0   0   0   0   0  11   7   0   0   1   1   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 144   0   0   0   0   1   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0   4  18   0   0   0   0   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0   3   0   7   0   0   0   2   0   0   0   0\n",
      "   0   0   0   0   1   0   0   5   0   0  13   1   3   0   0   1   0   0\n",
      "   0   0   2   0   0   0   0   1   0   0   0   7   4   0   0   1   0   0\n",
      "   0   0   0   2   1   0   0   1   0   0   0   1 106   0   0   3   0   1\n",
      "   0   0   0   0   0   0   0  10   0   0   0   0   0  54   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15   0   0   0\n",
      "   0   0   0   3   0   1   0  10   1   0   1   1   3   1   0   1   0   0\n",
      "   0   0   0   1   0   0   0   2   0   0   0   0   0   0   0   0  18   0\n",
      "   0   0   0   0   0   0   0   2   0   0   0   0   8   0   0   0   0  13]\n",
      "svc Accuracy:  0.7841079460269865\n",
      "svc F1:  0.7154709239324248\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.95      0.46      0.62        39\n",
      "          3       0.50      0.05      0.09        20\n",
      "          4       0.78      0.76      0.77        33\n",
      "          5       0.84      0.94      0.88        49\n",
      "          6       1.00      0.45      0.62        20\n",
      "          7       0.54      0.99      0.70       146\n",
      "          8       0.88      0.30      0.45        23\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       0.85      0.46      0.59        24\n",
      "         11       0.50      0.13      0.21        15\n",
      "         12       0.66      0.96      0.78       115\n",
      "         13       0.88      0.78      0.83        64\n",
      "         14       1.00      0.87      0.93        15\n",
      "         15       0.00      0.00      0.00        22\n",
      "         16       1.00      0.29      0.44        21\n",
      "         17       0.89      0.35      0.50        23\n",
      "\n",
      "avg / total       0.69      0.68      0.63       667\n",
      "\n",
      "[  4   0   0   0   0   0   0   8   0   0   1   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  13   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  18   0   0   0   0   6   0   0   0   0  14   0   0   0   0   1\n",
      "   0   0   0   1   4   3   0   8   0   0   0   0   4   0   0   0   0   0\n",
      "   0   0   1   0  25   2   0   1   0   0   0   0   4   0   0   0   0   0\n",
      "   0   0   0   0   1  46   0   1   0   0   0   0   1   0   0   0   0   0\n",
      "   0   0   0   0   0   0   9   7   0   0   1   1   0   2   0   0   0   0\n",
      "   0   0   0   0   0   0   0 144   0   0   0   0   1   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0  15   7   0   0   0   0   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0  10   0   0   0   0   0   2   0   0   0   0\n",
      "   0   0   0   0   0   0   0   7   0   0  11   0   5   1   0   0   0   0\n",
      "   0   0   0   0   1   1   0   2   0   0   0   2   9   0   0   0   0   0\n",
      "   0   0   0   0   1   0   0   1   0   0   0   1 110   0   0   2   0   0\n",
      "   0   0   0   0   0   0   0  14   0   0   0   0   0  50   0   0   0   0\n",
      "   0   0   0   0   0   0   0   2   0   0   0   0   0   0  13   0   0   0\n",
      "   0   0   0   1   0   2   0  12   1   0   0   0   6   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0  14   0   0   0   0   0   0   0   0   6   0\n",
      "   0   0   0   0   0   0   0   2   0   0   0   0  13   0   0   0   0   8]\n",
      "LR Accuracy:  0.6806596701649176\n",
      "LR F1:  0.49391095354036924\n",
      "For name:  k_sato\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0001-6110-9171': 35, '0000-0001-5768-2442': 9, '0000-0001-6706-2175': 7, '0000-0002-3998-7012': 7, '0000-0001-9078-2541': 6, '0000-0003-4045-7796': 1})\n",
      "['0000-0001-6110-9171']\n",
      "Total sample size after apply threshold:  35\n",
      "For name:  f_ahmed\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-7464-7726': 9, '0000-0003-1294-5274': 9, '0000-0002-9839-7039': 4, '0000-0002-8444-2038': 1, '0000-0003-4100-1571': 1, '0000-0001-5256-4666': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  y_watanabe\n",
      "total sample size before apply threshold:  98\n",
      "Counter({'0000-0002-7139-4903': 80, '0000-0001-7740-1361': 11, '0000-0002-7013-3613': 2, '0000-0002-7120-3097': 2, '0000-0001-9999-0486': 1, '0000-0002-6281-9295': 1, '0000-0002-9668-3592': 1})\n",
      "['0000-0002-7139-4903', '0000-0001-7740-1361']\n",
      "Total sample size after apply threshold:  91\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 194)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "91\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        80\n",
      "          1       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.97      0.97      0.96        91\n",
      "\n",
      "[80  0  3  8]\n",
      "MNB Accuracy:  0.967032967032967\n",
      "MNB F1:  0.9118501775912173\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        80\n",
      "          1       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.97      0.97      0.96        91\n",
      "\n",
      "[80  0  3  8]\n",
      "svc Accuracy:  0.967032967032967\n",
      "svc F1:  0.9118501775912173\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        80\n",
      "          1       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.95      0.95      0.94        91\n",
      "\n",
      "[80  0  5  6]\n",
      "LR Accuracy:  0.945054945054945\n",
      "LR F1:  0.8377896613190731\n",
      "For name:  k_singh\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-3152-1119': 10, '0000-0002-9375-3233': 6, '0000-0001-8352-5897': 3, '0000-0002-4126-9618': 3, '0000-0001-7187-4782': 1, '0000-0002-5199-9331': 1, '0000-0002-2913-6644': 1})\n",
      "['0000-0003-3152-1119']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  j_mcevoy\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0001-6530-5479': 53, '0000-0003-0382-1288': 8, '0000-0001-6843-5551': 2, '0000-0001-9591-1824': 2})\n",
      "['0000-0001-6530-5479']\n",
      "Total sample size after apply threshold:  53\n",
      "For name:  g_singh\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0003-1525-3898': 13, '0000-0001-9700-3344': 11, '0000-0002-1641-5070': 6, '0000-0002-4354-269X': 2, '0000-0002-2113-4230': 1, '0000-0002-9579-6093': 1, '0000-0001-5496-6992': 1, '0000-0002-2670-9814': 1})\n",
      "['0000-0001-9700-3344', '0000-0003-1525-3898']\n",
      "Total sample size after apply threshold:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 60)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "24\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        11\n",
      "          1       0.62      1.00      0.76        13\n",
      "\n",
      "avg / total       0.79      0.67      0.61        24\n",
      "\n",
      "[ 3  8  0 13]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.5966386554621849\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        24\n",
      "\n",
      "[11  0  0 13]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        24\n",
      "\n",
      "[11  0  0 13]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  e_ford\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-7885-0019': 34, '0000-0001-5613-8509': 14, '0000-0001-7358-798X': 4, '0000-0003-0952-3660': 2})\n",
      "['0000-0002-7885-0019', '0000-0001-5613-8509']\n",
      "Total sample size after apply threshold:  48\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 81)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        34\n",
      "          1       1.00      0.64      0.78        14\n",
      "\n",
      "avg / total       0.91      0.90      0.89        48\n",
      "\n",
      "[34  0  5  9]\n",
      "MNB Accuracy:  0.8958333333333334\n",
      "MNB F1:  0.8570577724836212\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        34\n",
      "          1       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.98      0.98      0.98        48\n",
      "\n",
      "[34  0  1 13]\n",
      "svc Accuracy:  0.9791666666666666\n",
      "svc F1:  0.9742351046698873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        34\n",
      "          1       1.00      0.21      0.35        14\n",
      "\n",
      "avg / total       0.83      0.77      0.71        48\n",
      "\n",
      "[34  0 11  3]\n",
      "LR Accuracy:  0.7708333333333334\n",
      "LR F1:  0.6068503350707372\n",
      "For name:  s_chou\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0001-9237-4517': 16, '0000-0003-1155-6082': 8, '0000-0003-0787-0044': 6, '0000-0001-8081-1679': 4, '0000-0001-5512-9977': 2, '0000-0002-4121-019X': 2, '0000-0001-8163-7430': 1})\n",
      "['0000-0001-9237-4517']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  s_hughes\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0001-8227-9225': 74, '0000-0002-9409-9405': 12, '0000-0001-8360-929X': 6, '0000-0002-2264-8479': 5, '0000-0002-9778-140X': 3, '0000-0001-6340-2646': 3, '0000-0001-7689-4272': 1, '0000-0002-8187-4871': 1, '0000-0003-4542-1821': 1})\n",
      "['0000-0002-9409-9405', '0000-0001-8227-9225']\n",
      "Total sample size after apply threshold:  86\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 281)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.87      1.00      0.93        74\n",
      "\n",
      "avg / total       0.89      0.87      0.82        86\n",
      "\n",
      "[ 1 11  0 74]\n",
      "MNB Accuracy:  0.872093023255814\n",
      "MNB F1:  0.5423318819545235\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        12\n",
      "          1       0.91      1.00      0.95        74\n",
      "\n",
      "avg / total       0.93      0.92      0.90        86\n",
      "\n",
      "[ 5  7  0 74]\n",
      "svc Accuracy:  0.9186046511627907\n",
      "svc F1:  0.7715370018975332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.86      1.00      0.92        74\n",
      "\n",
      "avg / total       0.74      0.86      0.80        86\n",
      "\n",
      "[ 0 12  0 74]\n",
      "LR Accuracy:  0.8604651162790697\n",
      "LR F1:  0.46249999999999997\n",
      "For name:  m_thomas\n",
      "total sample size before apply threshold:  225\n",
      "Counter({'0000-0002-2452-981X': 69, '0000-0001-5939-1155': 52, '0000-0001-6394-8710': 24, '0000-0003-4374-1039': 18, '0000-0002-4951-9925': 14, '0000-0003-2360-255X': 13, '0000-0002-3042-0669': 10, '0000-0002-5553-5825': 8, '0000-0002-5089-5610': 4, '0000-0003-0354-8779': 4, '0000-0003-2982-0291': 3, '0000-0001-8093-4919': 3, '0000-0002-7569-6896': 1, '0000-0003-2288-1104': 1, '0000-0001-6291-6426': 1})\n",
      "['0000-0001-6394-8710', '0000-0002-3042-0669', '0000-0002-4951-9925', '0000-0003-2360-255X', '0000-0001-5939-1155', '0000-0002-2452-981X', '0000-0003-4374-1039']\n",
      "Total sample size after apply threshold:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(200, 837)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "200\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        24\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.87      0.79      0.83        52\n",
      "          5       0.55      1.00      0.71        69\n",
      "          6       1.00      0.33      0.50        18\n",
      "\n",
      "avg / total       0.70      0.69      0.64       200\n",
      "\n",
      "[12  0  0  0  0 12  0  0  0  0  0  0 10  0  0  0  9  0  1  4  0  0  0  0\n",
      "  0  4  9  0  0  0  0  0 41 11  0  0  0  0  0  0 69  0  0  0  0  0  1 11\n",
      "  6]\n",
      "MNB Accuracy:  0.685\n",
      "MNB F1:  0.4978929283277109\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        24\n",
      "          1       1.00      0.60      0.75        10\n",
      "          2       1.00      0.71      0.83        14\n",
      "          3       1.00      0.69      0.82        13\n",
      "          4       0.95      0.81      0.88        52\n",
      "          5       0.68      1.00      0.81        69\n",
      "          6       1.00      0.83      0.91        18\n",
      "\n",
      "avg / total       0.88      0.82      0.83       200\n",
      "\n",
      "[14  0  0  0  0 10  0  0  6  0  0  0  4  0  0  0 10  0  1  3  0  0  0  0\n",
      "  9  1  3  0  0  0  0  0 42 10  0  0  0  0  0  0 69  0  0  0  0  0  0  3\n",
      " 15]\n",
      "svc Accuracy:  0.825\n",
      "svc F1:  0.8184951013898382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        24\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       1.00      0.15      0.27        13\n",
      "          4       1.00      0.77      0.87        52\n",
      "          5       0.53      1.00      0.69        69\n",
      "          6       1.00      0.44      0.62        18\n",
      "\n",
      "avg / total       0.79      0.69      0.66       200\n",
      "\n",
      "[10  0  0  0  0 14  0  0  0  0  0  0 10  0  0  0  9  0  0  5  0  0  0  0\n",
      "  2  0 11  0  0  0  0  0 40 12  0  0  0  0  0  0 69  0  0  0  0  0  0 10\n",
      "  8]\n",
      "LR Accuracy:  0.69\n",
      "LR F1:  0.5446372127446296\n",
      "For name:  j_liang\n",
      "total sample size before apply threshold:  105\n",
      "Counter({'0000-0002-0264-7735': 84, '0000-0002-4532-0118': 8, '0000-0001-6055-0918': 4, '0000-0001-9439-9320': 3, '0000-0002-2773-6427': 2, '0000-0001-8252-5502': 2, '0000-0003-3994-5709': 1, '0000-0002-8210-0210': 1})\n",
      "['0000-0002-0264-7735']\n",
      "Total sample size after apply threshold:  84\n",
      "For name:  t_wu\n",
      "total sample size before apply threshold:  168\n",
      "Counter({'0000-0003-0845-4827': 68, '0000-0001-8235-5929': 34, '0000-0002-0244-3046': 11, '0000-0003-1845-1769': 11, '0000-0002-2663-2001': 11, '0000-0002-9859-4534': 10, '0000-0002-0060-4408': 7, '0000-0001-5155-6189': 7, '0000-0002-6519-469X': 3, '0000-0002-3560-8898': 2, '0000-0001-6444-598X': 2, '0000-0001-6469-9613': 1, '0000-0002-8775-597X': 1})\n",
      "['0000-0002-0244-3046', '0000-0003-0845-4827', '0000-0003-1845-1769', '0000-0001-8235-5929', '0000-0002-2663-2001', '0000-0002-9859-4534']\n",
      "Total sample size after apply threshold:  145\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(145, 363)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.59      1.00      0.74        68\n",
      "          2       1.00      0.09      0.17        11\n",
      "          3       0.96      0.79      0.87        34\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.58      0.66      0.56       145\n",
      "\n",
      "[ 0 11  0  0  0  0  0 68  0  0  0  0  0  9  1  1  0  0  0  7  0 27  0  0\n",
      "  0 11  0  0  0  0  0 10  0  0  0  0]\n",
      "MNB Accuracy:  0.6620689655172414\n",
      "MNB F1:  0.2961274738974599\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.77      1.00      0.87        68\n",
      "          2       1.00      0.55      0.71        11\n",
      "          3       1.00      0.88      0.94        34\n",
      "          4       1.00      0.45      0.62        11\n",
      "          5       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.89      0.86      0.85       145\n",
      "\n",
      "[ 8  3  0  0  0  0  0 68  0  0  0  0  0  5  6  0  0  0  0  4  0 30  0  0\n",
      "  0  6  0  0  5  0  0  2  0  0  0  8]\n",
      "svc Accuracy:  0.8620689655172413\n",
      "svc F1:  0.811861896130472\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17        11\n",
      "          1       0.59      1.00      0.74        68\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.79      0.89        34\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.66      0.68      0.59       145\n",
      "\n",
      "[ 1 10  0  0  0  0  0 68  0  0  0  0  0 11  0  0  0  0  0  7  0 27  0  0\n",
      "  0 11  0  0  0  0  0  8  0  0  0  2]\n",
      "LR Accuracy:  0.6758620689655173\n",
      "LR F1:  0.35473588342440804\n",
      "For name:  b_ahmed\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0001-6021-1414': 10, '0000-0001-9110-4136': 6, '0000-0002-6707-822X': 4, '0000-0002-4840-6945': 3})\n",
      "['0000-0001-6021-1414']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  m_takahashi\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-3799-2256': 41, '0000-0001-7273-1660': 11, '0000-0003-3233-6783': 1, '0000-0001-6141-0554': 1})\n",
      "['0000-0002-3799-2256', '0000-0001-7273-1660']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 154)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        41\n",
      "          1       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.90      0.88      0.87        52\n",
      "\n",
      "[41  0  6  5]\n",
      "MNB Accuracy:  0.8846153846153846\n",
      "MNB F1:  0.7784090909090909\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        41\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.93      0.92      0.92        52\n",
      "\n",
      "[41  0  4  7]\n",
      "svc Accuracy:  0.9230769230769231\n",
      "svc F1:  0.8656330749354005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        41\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.62      0.79      0.70        52\n",
      "\n",
      "[41  0 11  0]\n",
      "LR Accuracy:  0.7884615384615384\n",
      "LR F1:  0.44086021505376344\n",
      "For name:  i_lee\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-2588-1444': 41, '0000-0002-0098-392X': 16, '0000-0003-0520-4435': 7, '0000-0001-6057-7176': 5, '0000-0003-1923-0917': 1, '0000-0003-3760-4257': 1, '0000-0001-8167-7168': 1, '0000-0002-9103-0955': 1})\n",
      "['0000-0002-0098-392X', '0000-0002-2588-1444']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 82)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        16\n",
      "          1       0.87      1.00      0.93        41\n",
      "\n",
      "avg / total       0.91      0.89      0.89        57\n",
      "\n",
      "[10  6  0 41]\n",
      "MNB Accuracy:  0.8947368421052632\n",
      "MNB F1:  0.8505244755244756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        16\n",
      "          1       0.91      1.00      0.95        41\n",
      "\n",
      "avg / total       0.94      0.93      0.93        57\n",
      "\n",
      "[12  4  0 41]\n",
      "svc Accuracy:  0.9298245614035088\n",
      "svc F1:  0.9053156146179402\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        16\n",
      "          1       0.84      1.00      0.91        41\n",
      "\n",
      "avg / total       0.88      0.86      0.84        57\n",
      "\n",
      "[ 8  8  0 41]\n",
      "LR Accuracy:  0.8596491228070176\n",
      "LR F1:  0.7888888888888889\n",
      "For name:  a_figueiredo\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-9105-9619': 79, '0000-0002-3239-3190': 19, '0000-0001-6956-0514': 16, '0000-0001-8156-7700': 14, '0000-0001-8386-8216': 9, '0000-0001-7039-5341': 6, '0000-0003-2329-2854': 3, '0000-0003-0487-8956': 3, '0000-0002-8555-8649': 1})\n",
      "['0000-0001-6956-0514', '0000-0001-8156-7700', '0000-0002-9105-9619', '0000-0002-3239-3190']\n",
      "Total sample size after apply threshold:  128\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(128, 232)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "128\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        16\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       0.86      1.00      0.92        79\n",
      "          3       1.00      0.95      0.97        19\n",
      "\n",
      "avg / total       0.91      0.90      0.89       128\n",
      "\n",
      "[ 8  0  8  0  0 10  4  0  0  0 79  0  0  0  1 18]\n",
      "MNB Accuracy:  0.8984375\n",
      "MNB F1:  0.849237395290027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        16\n",
      "          1       1.00      0.93      0.96        14\n",
      "          2       0.96      1.00      0.98        79\n",
      "          3       1.00      0.95      0.97        19\n",
      "\n",
      "avg / total       0.98      0.98      0.98       128\n",
      "\n",
      "[15  0  1  0  0 13  1  0  0  0 79  0  0  0  1 18]\n",
      "svc Accuracy:  0.9765625\n",
      "svc F1:  0.971261082761784\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        16\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       0.81      1.00      0.89        79\n",
      "          3       1.00      0.84      0.91        19\n",
      "\n",
      "avg / total       0.88      0.85      0.84       128\n",
      "\n",
      "[ 8  0  8  0  0  6  8  0  0  0 79  0  0  0  3 16]\n",
      "LR Accuracy:  0.8515625\n",
      "LR F1:  0.7684019370460048\n",
      "For name:  s_clark\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0001-5907-9671': 12, '0000-0002-7488-3438': 9, '0000-0001-7328-0726': 8, '0000-0002-6183-491X': 4, '0000-0001-8394-8355': 3, '0000-0003-4090-6002': 1, '0000-0002-2072-7499': 1, '0000-0002-7633-3376': 1})\n",
      "['0000-0001-5907-9671']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  a_schmid\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-5196-151X': 28, '0000-0001-7759-0211': 19, '0000-0001-6483-8759': 10, '0000-0002-0141-0971': 4})\n",
      "['0000-0001-7759-0211', '0000-0001-6483-8759', '0000-0002-5196-151X']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 195)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        19\n",
      "          1       1.00      0.40      0.57        10\n",
      "          2       0.90      1.00      0.95        28\n",
      "\n",
      "avg / total       0.91      0.89      0.88        57\n",
      "\n",
      "[19  0  0  3  4  3  0  0 28]\n",
      "MNB Accuracy:  0.8947368421052632\n",
      "MNB F1:  0.8158034606980452\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        19\n",
      "          1       1.00      0.80      0.89        10\n",
      "          2       1.00      1.00      1.00        28\n",
      "\n",
      "avg / total       0.97      0.96      0.96        57\n",
      "\n",
      "[19  0  0  2  8  0  0  0 28]\n",
      "svc Accuracy:  0.9649122807017544\n",
      "svc F1:  0.9462962962962963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        19\n",
      "          1       1.00      0.20      0.33        10\n",
      "          2       0.74      1.00      0.85        28\n",
      "\n",
      "avg / total       0.87      0.82      0.79        57\n",
      "\n",
      "[17  0  2  0  2  8  0  0 28]\n",
      "LR Accuracy:  0.8245614035087719\n",
      "LR F1:  0.7087542087542088\n",
      "For name:  k_cheung\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0002-6759-4961': 9, '0000-0002-8348-1561': 4, '0000-0003-4107-7840': 2, '0000-0001-7648-4556': 1})"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_ma\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-1897-7069': 69, '0000-0002-2029-7943': 42, '0000-0002-1810-8357': 9, '0000-0002-0232-8590': 6, '0000-0001-8581-2216': 3, '0000-0002-2704-3540': 2, '0000-0001-8087-0249': 1, '0000-0001-6361-9706': 1, '0000-0002-7995-2041': 1, '0000-0003-4846-9513': 1, '0000-0002-8992-1177': 1})\n",
      "['0000-0002-2029-7943', '0000-0002-1897-7069']\n",
      "Total sample size after apply threshold:  111\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 212)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        42\n",
      "          1       0.95      1.00      0.97        69\n",
      "\n",
      "avg / total       0.97      0.96      0.96       111\n",
      "\n",
      "[38  4  0 69]\n",
      "MNB Accuracy:  0.963963963963964\n",
      "MNB F1:  0.9609154929577466\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        42\n",
      "          1       0.96      1.00      0.98        69\n",
      "\n",
      "avg / total       0.97      0.97      0.97       111\n",
      "\n",
      "[39  3  0 69]\n",
      "svc Accuracy:  0.972972972972973\n",
      "svc F1:  0.9708431836091411\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        42\n",
      "          1       0.91      1.00      0.95        69\n",
      "\n",
      "avg / total       0.94      0.94      0.94       111\n",
      "\n",
      "[35  7  0 69]\n",
      "LR Accuracy:  0.9369369369369369\n",
      "LR F1:  0.9304075235109718\n",
      "For name:  m_marino\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0001-9155-6378': 14, '0000-0002-0045-0234': 11, '0000-0002-7470-7493': 11, '0000-0001-7443-3472': 9, '0000-0003-2031-1191': 8, '0000-0003-1226-6036': 7, '0000-0002-4323-3061': 5, '0000-0002-8672-0310': 3, '0000-0003-4651-6128': 1})\n",
      "['0000-0001-9155-6378', '0000-0002-0045-0234', '0000-0002-7470-7493']\n",
      "Total sample size after apply threshold:  36\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 158)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      1.00      0.78        14\n",
      "          1       1.00      0.27      0.43        11\n",
      "          2       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       0.86      0.78      0.74        36\n",
      "\n",
      "[14  0  0  8  3  0  0  0 11]\n",
      "MNB Accuracy:  0.7777777777777778\n",
      "MNB F1:  0.7354497354497355\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       0.85      1.00      0.92        11\n",
      "          2       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.95      0.94      0.94        36\n",
      "\n",
      "[14  0  0  0 11  0  0  2  9]\n",
      "svc Accuracy:  0.9444444444444444\n",
      "svc F1:  0.9388888888888888\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        14\n",
      "          1       0.89      0.73      0.80        11\n",
      "          2       0.83      0.91      0.87        11\n",
      "\n",
      "avg / total       0.89      0.89      0.89        36\n",
      "\n",
      "[14  0  0  1  8  2  0  1 10]\n",
      "LR Accuracy:  0.8888888888888888\n",
      "LR F1:  0.8783608195902048\n",
      "For name:  a_kirby\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0002-2440-9316': 26, '0000-0001-5663-2961': 25, '0000-0002-6928-668X': 9, '0000-0003-0395-6684': 4})\n",
      "['0000-0002-2440-9316', '0000-0001-5663-2961']\n",
      "Total sample size after apply threshold:  51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 127)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        26\n",
      "          1       0.93      1.00      0.96        25\n",
      "\n",
      "avg / total       0.96      0.96      0.96        51\n",
      "\n",
      "[24  2  0 25]\n",
      "MNB Accuracy:  0.9607843137254902\n",
      "MNB F1:  0.9607692307692308\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        26\n",
      "          1       1.00      1.00      1.00        25\n",
      "\n",
      "avg / total       1.00      1.00      1.00        51\n",
      "\n",
      "[26  0  0 25]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        26\n",
      "          1       1.00      1.00      1.00        25\n",
      "\n",
      "avg / total       1.00      1.00      1.00        51\n",
      "\n",
      "[26  0  0 25]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  d_roberts\n",
      "total sample size before apply threshold:  105\n",
      "Counter({'0000-0002-2481-2981': 47, '0000-0001-6111-6291': 20, '0000-0003-0261-691X': 14, '0000-0002-0668-2001': 12, '0000-0001-7175-7754': 10, '0000-0003-0264-921X': 1, '0000-0002-0780-7056': 1})\n",
      "['0000-0001-7175-7754', '0000-0001-6111-6291', '0000-0003-0261-691X', '0000-0002-2481-2981', '0000-0002-0668-2001']\n",
      "Total sample size after apply threshold:  103\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 305)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        10\n",
      "          1       1.00      0.85      0.92        20\n",
      "          2       1.00      0.79      0.88        14\n",
      "          3       0.66      1.00      0.80        47\n",
      "          4       1.00      0.25      0.40        12\n",
      "\n",
      "avg / total       0.85      0.77      0.73       103\n",
      "\n",
      "[ 1  0  0  9  0  0 17  0  3  0  0  0 11  3  0  0  0  0 47  0  0  0  0  9\n",
      "  3]\n",
      "MNB Accuracy:  0.7669902912621359\n",
      "MNB F1:  0.6354694540457253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       1.00      0.85      0.92        20\n",
      "          2       1.00      0.86      0.92        14\n",
      "          3       0.77      1.00      0.87        47\n",
      "          4       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.90      0.86      0.86       103\n",
      "\n",
      "[ 4  0  0  6  0  0 17  0  3  0  0  0 12  2  0  0  0  0 47  0  0  0  0  3\n",
      "  9]\n",
      "svc Accuracy:  0.8640776699029126\n",
      "svc F1:  0.8281875281875282\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        10\n",
      "          1       1.00      0.70      0.82        20\n",
      "          2       1.00      0.79      0.88        14\n",
      "          3       0.63      1.00      0.77        47\n",
      "          4       1.00      0.17      0.29        12\n",
      "\n",
      "avg / total       0.83      0.73      0.68       103\n",
      "\n",
      "[ 1  0  0  9  0  0 14  0  6  0  0  0 11  3  0  0  0  0 47  0  0  0  0 10\n",
      "  2]\n",
      "LR Accuracy:  0.7281553398058253\n",
      "LR F1:  0.5883107365151724\n",
      "For name:  b_thompson\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0002-5885-0652': 65, '0000-0002-5358-0796': 8, '0000-0002-2302-0886': 7, '0000-0002-3845-824X': 3})\n",
      "['0000-0002-5885-0652']\n",
      "Total sample size after apply threshold:  65\n",
      "For name:  j_blanco\n",
      "total sample size before apply threshold:  362\n",
      "Counter({'0000-0003-0264-4136': 102, '0000-0002-2225-0217': 91, '0000-0001-8142-0450': 74, '0000-0003-3765-0640': 41, '0000-0003-0647-3856': 40, '0000-0002-5071-4760': 7, '0000-0002-6524-4335': 5, '0000-0002-7351-5342': 1, '0000-0003-0191-2063': 1})\n",
      "['0000-0003-0264-4136', '0000-0003-0647-3856', '0000-0002-2225-0217', '0000-0003-3765-0640', '0000-0001-8142-0450']\n",
      "Total sample size after apply threshold:  348\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(348, 922)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       102\n",
      "          1       1.00      0.95      0.97        40\n",
      "          2       1.00      0.98      0.99        91\n",
      "          3       1.00      0.61      0.76        41\n",
      "          4       0.94      0.99      0.96        74\n",
      "\n",
      "avg / total       0.94      0.94      0.93       348\n",
      "\n",
      "[101   0   0   0   1   2  38   0   0   0   2   0  89   0   0  12   0   0\n",
      "  25   4   1   0   0   0  73]\n",
      "MNB Accuracy:  0.9367816091954023\n",
      "MNB F1:  0.9199063509589825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       102\n",
      "          1       1.00      0.95      0.97        40\n",
      "          2       1.00      0.97      0.98        91\n",
      "          3       1.00      0.93      0.96        41\n",
      "          4       1.00      0.97      0.99        74\n",
      "\n",
      "avg / total       0.97      0.97      0.97       348\n",
      "\n",
      "[102   0   0   0   0   2  38   0   0   0   3   0  88   0   0   3   0   0\n",
      "  38   0   2   0   0   0  72]\n",
      "svc Accuracy:  0.9712643678160919\n",
      "svc F1:  0.971839382435751\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       102\n",
      "          1       1.00      0.95      0.97        40\n",
      "          2       0.90      0.99      0.94        91\n",
      "          3       1.00      0.71      0.83        41\n",
      "          4       0.97      0.96      0.97        74\n",
      "\n",
      "avg / total       0.94      0.94      0.94       348\n",
      "\n",
      "[99  0  3  0  0  2 38  0  0  0  0  0 90  0  1  5  0  6 29  1  2  0  1  0\n",
      " 71]\n",
      "LR Accuracy:  0.9396551724137931\n",
      "LR F1:  0.9308364634617439\n",
      "For name:  x_cai\n",
      "total sample size before apply threshold:  79\n",
      "Counter({'0000-0001-8933-7133': 32, '0000-0002-5654-7414': 31, '0000-0003-4907-154X': 9, '0000-0003-3706-4414': 4, '0000-0003-0222-553X': 2, '0000-0001-5238-6193': 1})\n",
      "['0000-0002-5654-7414', '0000-0001-8933-7133']\n",
      "Total sample size after apply threshold:  63\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 93)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        31\n",
      "          1       1.00      0.84      0.92        32\n",
      "\n",
      "avg / total       0.93      0.92      0.92        63\n",
      "\n",
      "[31  0  5 27]\n",
      "MNB Accuracy:  0.9206349206349206\n",
      "MNB F1:  0.9203136858082469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        31\n",
      "          1       0.94      1.00      0.97        32\n",
      "\n",
      "avg / total       0.97      0.97      0.97        63\n",
      "\n",
      "[29  2  0 32]\n",
      "svc Accuracy:  0.9682539682539683\n",
      "svc F1:  0.9681818181818181\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       1.00      1.00      1.00        32\n",
      "\n",
      "avg / total       1.00      1.00      1.00        63\n",
      "\n",
      "[31  0  0 32]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  r_menezes\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0003-0552-8480': 15, '0000-0002-6612-3543': 6, '0000-0003-3109-9683': 5, '0000-0003-4316-2168': 2, '0000-0002-4842-641X': 1})\n",
      "['0000-0003-0552-8480']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  s_tsang\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0003-0788-4905': 6, '0000-0002-9862-8503': 5, '0000-0001-6099-6696': 5, '0000-0002-2232-9814': 4})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_king\n",
      "total sample size before apply threshold:  218\n",
      "Counter({'0000-0001-8349-9270': 145, '0000-0002-6078-2601': 65, '0000-0002-0892-1301': 4, '0000-0003-1157-5734': 2, '0000-0002-6641-237X': 2})\n",
      "['0000-0002-6078-2601', '0000-0001-8349-9270']\n",
      "Total sample size after apply threshold:  210\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(210, 774)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "210\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97        65\n",
      "          1       0.99      0.98      0.99       145\n",
      "\n",
      "avg / total       0.98      0.98      0.98       210\n",
      "\n",
      "[ 64   1   3 142]\n",
      "MNB Accuracy:  0.9809523809523809\n",
      "MNB F1:  0.9779040404040403\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        65\n",
      "          1       0.95      1.00      0.97       145\n",
      "\n",
      "avg / total       0.96      0.96      0.96       210\n",
      "\n",
      "[ 57   8   0 145]\n",
      "svc Accuracy:  0.9619047619047619\n",
      "svc F1:  0.953790295962152\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        65\n",
      "          1       0.90      1.00      0.94       145\n",
      "\n",
      "avg / total       0.93      0.92      0.92       210\n",
      "\n",
      "[ 48  17   0 145]\n",
      "LR Accuracy:  0.919047619047619\n",
      "LR F1:  0.8970914646450088\n",
      "For name:  h_kobayashi\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0003-4965-0883': 16, '0000-0002-8460-587X': 9, '0000-0001-9091-3521': 2, '0000-0002-8956-0375': 1})\n",
      "['0000-0003-4965-0883']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  k_yang\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0002-9128-9166': 19, '0000-0002-3162-7709': 14, '0000-0001-5968-6738': 12, '0000-0003-0047-2238': 10, '0000-0002-9691-0636': 6, '0000-0002-0587-3201': 5, '0000-0002-0809-2371': 1, '0000-0002-3398-9332': 1, '0000-0001-7963-4337': 1, '0000-0002-8224-5161': 1})\n",
      "['0000-0002-3162-7709', '0000-0002-9128-9166', '0000-0001-5968-6738', '0000-0003-0047-2238']\n",
      "Total sample size after apply threshold:  55\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 117)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.93      0.81        14\n",
      "          1       0.77      0.89      0.83        19\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.85      0.82      0.82        55\n",
      "\n",
      "[13  1  0  0  2 17  0  0  0  3  9  0  3  1  0  6]\n",
      "MNB Accuracy:  0.8181818181818182\n",
      "MNB F1:  0.8122277874564461\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.93      0.87        14\n",
      "          1       0.90      0.95      0.92        19\n",
      "          2       1.00      0.92      0.96        12\n",
      "          3       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.92      0.91      0.91        55\n",
      "\n",
      "[13  1  0  0  1 18  0  0  0  1 11  0  2  0  0  8]\n",
      "svc Accuracy:  0.9090909090909091\n",
      "svc F1:  0.9087885544407283\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.86      0.83        14\n",
      "          1       0.69      0.95      0.80        19\n",
      "          2       1.00      0.67      0.80        12\n",
      "          3       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.84      0.80      0.80        55\n",
      "\n",
      "[12  2  0  0  1 18  0  0  0  4  8  0  2  2  0  6]\n",
      "LR Accuracy:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "LR F1:  0.794396551724138\n",
      "For name:  b_zheng\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0002-7682-6648': 82, '0000-0002-3272-843X': 5, '0000-0003-1551-0970': 2, '0000-0002-2044-2848': 1})\n",
      "['0000-0002-7682-6648']\n",
      "Total sample size after apply threshold:  82\n",
      "For name:  f_xu\n",
      "total sample size before apply threshold:  94\n",
      "Counter({'0000-0003-4351-0222': 29, '0000-0002-8465-5834': 22, '0000-0001-5239-4572': 19, '0000-0001-7958-3787': 12, '0000-0002-0245-057X': 5, '0000-0002-8166-0275': 4, '0000-0003-1600-6346': 2, '0000-0002-2598-2528': 1})\n",
      "['0000-0001-7958-3787', '0000-0001-5239-4572', '0000-0003-4351-0222', '0000-0002-8465-5834']\n",
      "Total sample size after apply threshold:  82\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 133)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.88      0.74      0.80        19\n",
      "          2       0.73      0.93      0.82        29\n",
      "          3       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       0.88      0.85      0.85        82\n",
      "\n",
      "[ 7  0  5  0  0 14  5  0  0  2 27  0  0  0  0 22]\n",
      "MNB Accuracy:  0.8536585365853658\n",
      "MNB F1:  0.8387559808612439\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        12\n",
      "          1       0.94      0.79      0.86        19\n",
      "          2       0.82      0.97      0.89        29\n",
      "          3       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       0.92      0.91      0.91        82\n",
      "\n",
      "[10  0  2  0  0 15  4  0  0  1 28  0  0  0  0 22]\n",
      "svc Accuracy:  0.9146341463414634\n",
      "svc F1:  0.9137806637806638\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.93      0.68      0.79        19\n",
      "          2       0.70      0.97      0.81        29\n",
      "          3       1.00      1.00      1.00        22\n",
      "\n",
      "avg / total       0.88      0.84      0.84        82\n",
      "\n",
      "[ 6  0  6  0  0 13  6  0  0  1 28  0  0  0  0 22]\n",
      "LR Accuracy:  0.8414634146341463\n",
      "LR F1:  0.8165349143610013\n",
      "For name:  r_day\n",
      "total sample size before apply threshold:  202\n",
      "Counter({'0000-0002-6045-6937': 149, '0000-0003-3442-2298': 39, '0000-0003-1766-4068': 6, '0000-0001-5913-2292': 5, '0000-0002-6155-5910': 2, '0000-0003-1467-3196': 1})\n",
      "['0000-0002-6045-6937', '0000-0003-3442-2298']\n",
      "Total sample size after apply threshold:  188\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(188, 374)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "188\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       149\n",
      "          1       1.00      0.59      0.74        39\n",
      "\n",
      "avg / total       0.92      0.91      0.91       188\n",
      "\n",
      "[149   0  16  23]\n",
      "MNB Accuracy:  0.9148936170212766\n",
      "MNB F1:  0.8454900349291145\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       149\n",
      "          1       1.00      0.62      0.76        39\n",
      "\n",
      "avg / total       0.93      0.92      0.91       188\n",
      "\n",
      "[149   0  15  24]\n",
      "svc Accuracy:  0.9202127659574468\n",
      "svc F1:  0.856990719610528\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       149\n",
      "          1       1.00      0.21      0.34        39\n",
      "\n",
      "avg / total       0.86      0.84      0.79       188\n",
      "\n",
      "[149   0  31   8]\n",
      "LR Accuracy:  0.8351063829787234\n",
      "LR F1:  0.6231003039513677\n",
      "For name:  j_young\n",
      "total sample size before apply threshold:  267\n",
      "Counter({'0000-0002-1514-1522': 124, '0000-0003-4182-341X': 40, '0000-0003-3849-3392': 30, '0000-0002-1294-942X': 23, '0000-0002-2711-9701': 17, '0000-0001-7219-7824': 16, '0000-0003-4886-9517': 10, '0000-0003-1745-2401': 4, '0000-0001-9791-2513': 2, '0000-0001-6583-7643': 1})\n",
      "['0000-0003-3849-3392', '0000-0002-1294-942X', '0000-0001-7219-7824', '0000-0003-4182-341X', '0000-0002-2711-9701', '0000-0003-4886-9517', '0000-0002-1514-1522']\n",
      "Total sample size after apply threshold:  260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(260, 977)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "260\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        30\n",
      "          1       1.00      0.26      0.41        23\n",
      "          2       1.00      0.06      0.12        16\n",
      "          3       1.00      0.65      0.79        40\n",
      "          4       1.00      0.06      0.11        17\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.58      1.00      0.74       124\n",
      "\n",
      "avg / total       0.76      0.66      0.60       260\n",
      "\n",
      "[ 14   0   0   0   0   0  16   0   6   0   0   0   0  17   0   0   1   0\n",
      "   0   0  15   0   0   0  26   0   0  14   0   0   0   0   1   0  16   0\n",
      "   0   0   0   0   0  10   0   0   0   0   0   0 124]\n",
      "MNB Accuracy:  0.6615384615384615\n",
      "MNB F1:  0.40069841938865414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.63      0.78        30\n",
      "          1       1.00      0.52      0.69        23\n",
      "          2       1.00      0.69      0.81        16\n",
      "          3       0.97      0.75      0.85        40\n",
      "          4       1.00      0.71      0.83        17\n",
      "          5       1.00      0.70      0.82        10\n",
      "          6       0.74      1.00      0.85       124\n",
      "\n",
      "avg / total       0.87      0.83      0.82       260\n",
      "\n",
      "[ 19   0   0   0   0   0  11   0  12   0   0   0   0  11   0   0  11   0\n",
      "   0   0   5   0   0   0  30   0   0  10   0   0   0   0  12   0   5   0\n",
      "   0   0   1   0   7   2   0   0   0   0   0   0 124]\n",
      "svc Accuracy:  0.8269230769230769\n",
      "svc F1:  0.8030772020429074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        30\n",
      "          1       1.00      0.26      0.41        23\n",
      "          2       1.00      0.06      0.12        16\n",
      "          3       1.00      0.53      0.69        40\n",
      "          4       1.00      0.12      0.21        17\n",
      "          5       1.00      0.10      0.18        10\n",
      "          6       0.57      1.00      0.73       124\n",
      "\n",
      "avg / total       0.80      0.64      0.58       260\n",
      "\n",
      "[ 12   0   0   0   0   0  18   0   6   0   0   0   0  17   0   0   1   0\n",
      "   0   0  15   0   0   0  21   0   0  19   0   0   0   0   2   0  15   0\n",
      "   0   0   0   0   1   9   0   0   0   0   0   0 124]\n",
      "LR Accuracy:  0.6423076923076924\n",
      "LR F1:  0.4158586498206706\n",
      "For name:  c_black\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-0424-4593': 29, '0000-0003-2022-0337': 4, '0000-0003-2934-108X': 4, '0000-0002-1541-106X': 2, '0000-0001-8382-298X': 2})\n",
      "['0000-0002-0424-4593']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  s_joseph\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0003-4596-1270': 13, '0000-0002-4741-7183': 5, '0000-0003-1023-0718': 1, '0000-0002-9163-3027': 1})\n",
      "['0000-0003-4596-1270']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  z_fan\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0002-9312-2271': 13, '0000-0001-5385-9626': 13, '0000-0001-9492-5722': 6, '0000-0003-4623-6783': 4, '0000-0002-7818-153X': 1, '0000-0002-2145-2458': 1})\n",
      "['0000-0002-9312-2271', '0000-0001-5385-9626']\n",
      "Total sample size after apply threshold:  26\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 112)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        26\n",
      "\n",
      "[13  0  0 13]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        26\n",
      "\n",
      "[13  0  0 13]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        26\n",
      "\n",
      "[13  0  0 13]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  j_matos\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0002-3754-3709': 12, '0000-0002-0505-8282': 5, '0000-0001-9917-6126': 4, '0000-0003-1335-0635': 3, '0000-0003-0570-7913': 1})\n",
      "['0000-0002-3754-3709']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  l_santos\n",
      "total sample size before apply threshold:  172\n",
      "Counter({'0000-0003-3040-0358': 55, '0000-0002-2712-0622': 32, '0000-0002-7013-8852': 15, '0000-0002-1915-6780': 13, '0000-0001-5166-530X': 11, '0000-0003-0986-9880': 10, '0000-0002-0694-733X': 9, '0000-0001-8366-1557': 5, '0000-0001-8906-9976': 5, '0000-0002-4453-5766': 4, '0000-0001-7551-5605': 3, '0000-0003-0458-427X': 3, '0000-0001-5915-1186': 2, '0000-0001-9172-6429': 1, '0000-0003-0568-917X': 1, '0000-0002-2221-6692': 1, '0000-0002-7992-7487': 1, '0000-0003-4466-1129': 1})\n",
      "['0000-0003-3040-0358', '0000-0002-1915-6780', '0000-0002-7013-8852', '0000-0003-0986-9880', '0000-0001-5166-530X', '0000-0002-2712-0622']\n",
      "Total sample size after apply threshold:  136\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(136, 206)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.85        55\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       1.00      0.40      0.57        15\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.82      0.90        11\n",
      "          5       0.79      0.94      0.86        32\n",
      "\n",
      "avg / total       0.77      0.79      0.75       136\n",
      "\n",
      "[55  0  0  0  0  0  5  8  0  0  0  0  4  0  6  0  0  5  7  0  0  0  0  3\n",
      "  2  0  0  0  9  0  2  0  0  0  0 30]\n",
      "MNB Accuracy:  0.7941176470588235\n",
      "MNB F1:  0.6561050061050061\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        55\n",
      "          1       0.89      0.62      0.73        13\n",
      "          2       0.86      0.80      0.83        15\n",
      "          3       1.00      0.40      0.57        10\n",
      "          4       1.00      0.82      0.90        11\n",
      "          5       0.97      0.88      0.92        32\n",
      "\n",
      "avg / total       0.87      0.85      0.84       136\n",
      "\n",
      "[55  0  0  0  0  0  5  8  0  0  0  0  2  1 12  0  0  0  4  0  1  4  0  1\n",
      "  2  0  0  0  9  0  3  0  1  0  0 28]\n",
      "svc Accuracy:  0.8529411764705882\n",
      "svc F1:  0.802889360916495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      1.00      0.81        55\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       0.90      0.60      0.72        15\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.73      0.84        11\n",
      "          5       0.97      0.88      0.92        32\n",
      "\n",
      "avg / total       0.78      0.79      0.76       136\n",
      "\n",
      "[55  0  0  0  0  0  5  8  0  0  0  0  6  0  9  0  0  0  9  0  0  0  0  1\n",
      "  3  0  0  0  8  0  3  0  1  0  0 28]\n",
      "LR Accuracy:  0.7941176470588235\n",
      "LR F1:  0.6751443902266113\n",
      "For name:  g_taylor\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-0817-2785': 22, '0000-0002-6925-7571': 12, '0000-0002-0988-7168': 4, '0000-0003-4787-9844': 2, '0000-0002-3611-5286': 2, '0000-0002-3773-2390': 1, '0000-0002-2916-4645': 1})\n",
      "['0000-0002-6925-7571', '0000-0002-0817-2785']\n",
      "Total sample size after apply threshold:  34\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 131)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        12\n",
      "          1       0.92      1.00      0.96        22\n",
      "\n",
      "avg / total       0.95      0.94      0.94        34\n",
      "\n",
      "[10  2  0 22]\n",
      "MNB Accuracy:  0.9411764705882353\n",
      "MNB F1:  0.9328063241106719\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        12\n",
      "          1       0.92      1.00      0.96        22\n",
      "\n",
      "avg / total       0.95      0.94      0.94        34\n",
      "\n",
      "[10  2  0 22]\n",
      "svc Accuracy:  0.9411764705882353\n",
      "svc F1:  0.9328063241106719\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.73      1.00      0.85        22\n",
      "\n",
      "avg / total       0.83      0.76      0.72        34\n",
      "\n",
      "[ 4  8  0 22]\n",
      "LR Accuracy:  0.7647058823529411\n",
      "LR F1:  0.673076923076923\n",
      "For name:  x_yang\n",
      "total sample size before apply threshold:  164\n",
      "Counter({'0000-0001-5207-4210': 40, '0000-0002-2036-1220': 32, '0000-0003-3454-3604': 13, '0000-0003-0437-2015': 12, '0000-0002-1142-3100': 10, '0000-0002-7398-4229': 7, '0000-0002-5118-7755': 6, '0000-0002-5083-1799': 6, '0000-0002-4862-7422': 6, '0000-0003-2642-4963': 4, '0000-0002-1375-4800': 4, '0000-0001-8231-5556': 3, '0000-0002-5095-6735': 3, '0000-0003-0219-0023': 3, '0000-0002-2686-745X': 2, '0000-0002-9462-7992': 2, '0000-0002-5871-7894': 1, '0000-0002-5948-2353': 1, '0000-0001-6136-3575': 1, '0000-0003-4097-6318': 1, '0000-0002-1689-2002': 1, '0000-0003-0081-0938': 1, '0000-0003-0073-0823': 1, '0000-0001-7501-1378': 1, '0000-0002-5583-4032': 1, '0000-0002-4617-0713': 1, '0000-0001-6710-0012': 1})\n",
      "['0000-0002-2036-1220', '0000-0002-1142-3100', '0000-0003-0437-2015', '0000-0003-3454-3604', '0000-0001-5207-4210']\n",
      "Total sample size after apply threshold:  107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 379)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "107\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.81      0.79        32\n",
      "          1       1.00      0.10      0.18        10\n",
      "          2       1.00      0.50      0.67        12\n",
      "          3       1.00      0.62      0.76        13\n",
      "          4       0.64      0.93      0.76        40\n",
      "\n",
      "avg / total       0.79      0.73      0.70       107\n",
      "\n",
      "[26  0  0  0  6  1  1  0  0  8  0  0  6  0  6  4  0  0  8  1  3  0  0  0\n",
      " 37]\n",
      "MNB Accuracy:  0.7289719626168224\n",
      "MNB F1:  0.630674087816945\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.81      0.84        32\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      1.00      1.00        12\n",
      "          3       1.00      0.77      0.87        13\n",
      "          4       0.79      0.95      0.86        40\n",
      "\n",
      "avg / total       0.88      0.87      0.87       107\n",
      "\n",
      "[26  0  0  0  6  0  7  0  0  3  0  0 12  0  0  2  0  0 10  1  2  0  0  0\n",
      " 38]\n",
      "svc Accuracy:  0.8691588785046729\n",
      "svc F1:  0.8790881340423458\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.75      0.83        32\n",
      "          1       1.00      0.40      0.57        10\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       1.00      0.54      0.70        13\n",
      "          4       0.66      1.00      0.79        40\n",
      "\n",
      "avg / total       0.85      0.79      0.78       107\n",
      "\n",
      "[24  0  0  0  8  0  4  0  0  6  0  0  9  0  3  2  0  0  7  4  0  0  0  0\n",
      " 40]\n",
      "LR Accuracy:  0.7850467289719626\n",
      "LR F1:  0.7496473686777545\n",
      "For name:  s_bianchi\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0002-1365-9408': 19, '0000-0001-7290-8489': 10, '0000-0001-7673-3030': 6, '0000-0003-3731-5463': 5, '0000-0003-2292-4303': 2, '0000-0002-4622-4240': 1, '0000-0002-9384-846X': 1, '0000-0002-6979-3622': 1})\n",
      "['0000-0002-1365-9408', '0000-0001-7290-8489']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 103)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        19\n",
      "          1       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.84      0.79      0.76        29\n",
      "\n",
      "[19  0  6  4]\n",
      "MNB Accuracy:  0.7931034482758621\n",
      "MNB F1:  0.7175324675324676\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.95      0.88        19\n",
      "          1       0.86      0.60      0.71        10\n",
      "\n",
      "avg / total       0.83      0.83      0.82        29\n",
      "\n",
      "[18  1  4  6]\n",
      "svc Accuracy:  0.8275862068965517\n",
      "svc F1:  0.7919655667144907\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.83        19\n",
      "          1       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.81      0.72      0.66        29\n",
      "\n",
      "[19  0  8  2]\n",
      "LR Accuracy:  0.7241379310344828\n",
      "LR F1:  0.5797101449275363\n",
      "For name:  a_morales\n",
      "total sample size before apply threshold:  77\n",
      "Counter({'0000-0001-8702-2269': 47, '0000-0002-1526-3327': 19, '0000-0002-9518-3166': 9, '0000-0003-2081-6018': 1, '0000-0003-3656-2497': 1})\n",
      "['0000-0001-8702-2269', '0000-0002-1526-3327']\n",
      "Total sample size after apply threshold:  66\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 157)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        47\n",
      "          1       1.00      0.79      0.88        19\n",
      "\n",
      "avg / total       0.94      0.94      0.94        66\n",
      "\n",
      "[47  0  4 15]\n",
      "MNB Accuracy:  0.9393939393939394\n",
      "MNB F1:  0.9207683073229291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        47\n",
      "          1       1.00      0.79      0.88        19\n",
      "\n",
      "avg / total       0.94      0.94      0.94        66\n",
      "\n",
      "[47  0  4 15]\n",
      "svc Accuracy:  0.9393939393939394\n",
      "svc F1:  0.9207683073229291\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        47\n",
      "          1       1.00      0.63      0.77        19\n",
      "\n",
      "avg / total       0.91      0.89      0.89        66\n",
      "\n",
      "[47  0  7 12]\n",
      "LR Accuracy:  0.8939393939393939\n",
      "LR F1:  0.8524433088470138\n",
      "For name:  p_wong\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0002-6360-849X': 13, '0000-0003-1592-4823': 8, '0000-0001-7935-7245': 7, '0000-0003-4982-8127': 3, '0000-0003-4645-0384': 3, '0000-0003-3804-3041': 1, '0000-0002-8171-3242': 1})\n",
      "['0000-0002-6360-849X']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  a_cooper\n",
      "total sample size before apply threshold:  265\n",
      "Counter({'0000-0001-6709-7343': 112, '0000-0001-6050-3863': 72, '0000-0002-5897-2107': 23, '0000-0003-1025-0268': 16, '0000-0003-3975-3897': 15, '0000-0003-4588-2513': 12, '0000-0003-4097-5569': 4, '0000-0002-0815-0084': 4, '0000-0001-6027-8272': 3, '0000-0002-8305-8587': 2, '0000-0002-7328-4361': 1, '0000-0001-8763-8530': 1})\n",
      "['0000-0002-5897-2107', '0000-0001-6709-7343', '0000-0003-3975-3897', '0000-0003-4588-2513', '0000-0001-6050-3863', '0000-0003-1025-0268']\n",
      "Total sample size after apply threshold:  250\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(250, 883)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "250\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.22      0.36        23\n",
      "          1       0.61      1.00      0.76       112\n",
      "          2       1.00      0.07      0.12        15\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.98      0.75      0.85        72\n",
      "          5       1.00      0.31      0.48        16\n",
      "\n",
      "avg / total       0.77      0.71      0.65       250\n",
      "\n",
      "[  5  18   0   0   0   0   0 112   0   0   0   0   0  14   1   0   0   0\n",
      "   0  12   0   0   0   0   0  18   0   0  54   0   0  10   0   0   1   5]\n",
      "MNB Accuracy:  0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB F1:  0.4275806318129152\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        23\n",
      "          1       0.67      1.00      0.80       112\n",
      "          2       1.00      0.47      0.64        15\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       1.00      0.68      0.81        72\n",
      "          5       1.00      0.62      0.77        16\n",
      "\n",
      "avg / total       0.80      0.78      0.76       250\n",
      "\n",
      "[ 17   6   0   0   0   0   0 112   0   0   0   0   0   8   7   0   0   0\n",
      "   0  12   0   0   0   0   0  23   0   0  49   0   0   6   0   0   0  10]\n",
      "svc Accuracy:  0.78\n",
      "svc F1:  0.6447298574131418\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.26      0.41        23\n",
      "          1       0.58      1.00      0.73       112\n",
      "          2       1.00      0.07      0.12        15\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       1.00      0.64      0.78        72\n",
      "          5       1.00      0.25      0.40        16\n",
      "\n",
      "avg / total       0.76      0.68      0.62       250\n",
      "\n",
      "[  6  17   0   0   0   0   0 112   0   0   0   0   0  14   1   0   0   0\n",
      "   0  12   0   0   0   0   0  26   0   0  46   0   0  12   0   0   0   4]\n",
      "LR Accuracy:  0.676\n",
      "LR F1:  0.4088133916509375\n",
      "For name:  j_nguyen\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0002-8578-7396': 20, '0000-0002-4747-5383': 2, '0000-0003-3574-6278': 1, '0000-0003-0778-3776': 1, '0000-0003-3394-7412': 1, '0000-0002-8410-7395': 1, '0000-0001-5755-5814': 1})\n",
      "['0000-0002-8578-7396']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  t_lang\n",
      "total sample size before apply threshold:  107\n",
      "Counter({'0000-0002-3720-8038': 83, '0000-0002-7482-7727': 11, '0000-0003-4206-8743': 7, '0000-0001-9619-6762': 6})\n",
      "['0000-0002-3720-8038', '0000-0002-7482-7727']\n",
      "Total sample size after apply threshold:  94\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 327)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "94\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93        83\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.78      0.87      0.82        94\n",
      "\n",
      "[82  1 11  0]\n",
      "MNB Accuracy:  0.8723404255319149\n",
      "MNB F1:  0.4659090909090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        83\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.78      0.88      0.83        94\n",
      "\n",
      "[83  0 11  0]\n",
      "svc Accuracy:  0.8829787234042553\n",
      "svc F1:  0.4689265536723164\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        83\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.78      0.88      0.83        94\n",
      "\n",
      "[83  0 11  0]\n",
      "LR Accuracy:  0.8829787234042553\n",
      "LR F1:  0.4689265536723164\n",
      "For name:  s_russo\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0003-3589-3040': 33, '0000-0002-9699-4681': 10, '0000-0001-9137-9391': 1, '0000-0002-5490-3155': 1})\n",
      "['0000-0003-3589-3040', '0000-0002-9699-4681']\n",
      "Total sample size after apply threshold:  43\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(43, 80)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        33\n",
      "          1       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.94      0.93      0.93        43\n",
      "\n",
      "[33  0  3  7]\n",
      "MNB Accuracy:  0.9302325581395349\n",
      "MNB F1:  0.8900255754475703\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        33\n",
      "          1       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        43\n",
      "\n",
      "[33  0  0 10]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        33\n",
      "          1       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.84      0.79      0.72        43\n",
      "\n",
      "[33  0  9  1]\n",
      "LR Accuracy:  0.7906976744186046\n",
      "LR F1:  0.5309090909090909\n",
      "For name:  r_arora\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0002-5799-3619': 41, '0000-0002-2613-4539': 9, '0000-0002-4549-3860': 8, '0000-0001-6447-5628': 6})\n",
      "['0000-0002-5799-3619']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  c_porter\n",
      "total sample size before apply threshold:  157\n",
      "Counter({'0000-0003-3474-7551': 131, '0000-0001-8636-4515': 19, '0000-0001-8774-0180': 6, '0000-0002-4541-064X': 1})\n",
      "['0000-0001-8636-4515', '0000-0003-3474-7551']\n",
      "Total sample size after apply threshold:  150\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(150, 302)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "150\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        19\n",
      "          1       0.92      1.00      0.96       131\n",
      "\n",
      "avg / total       0.93      0.93      0.91       150\n",
      "\n",
      "[  8  11   0 131]\n",
      "MNB Accuracy:  0.9266666666666666\n",
      "MNB F1:  0.7761497761497762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        19\n",
      "          1       0.96      1.00      0.98       131\n",
      "\n",
      "avg / total       0.96      0.96      0.96       150\n",
      "\n",
      "[ 13   6   0 131]\n",
      "svc Accuracy:  0.96\n",
      "svc F1:  0.8950559701492538\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        19\n",
      "          1       0.87      1.00      0.93       131\n",
      "\n",
      "avg / total       0.76      0.87      0.81       150\n",
      "\n",
      "[  0  19   0 131]\n",
      "LR Accuracy:  0.8733333333333333\n",
      "LR F1:  0.46619217081850534\n",
      "For name:  m_moore\n",
      "total sample size before apply threshold:  112\n",
      "Counter({'0000-0002-5127-4509': 45, '0000-0003-3074-6631': 38, '0000-0002-7853-5756': 18, '0000-0003-4768-5329': 7, '0000-0002-7914-0166': 4})\n",
      "['0000-0002-7853-5756', '0000-0003-3074-6631', '0000-0002-5127-4509']\n",
      "Total sample size after apply threshold:  101\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 410)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "101\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        18\n",
      "          1       1.00      0.87      0.93        38\n",
      "          2       0.80      1.00      0.89        45\n",
      "\n",
      "avg / total       0.91      0.89      0.89       101\n",
      "\n",
      "[12  0  6  0 33  5  0  0 45]\n",
      "MNB Accuracy:  0.8910891089108911\n",
      "MNB F1:  0.8735555245665411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.72      0.84        18\n",
      "          1       0.82      0.95      0.88        38\n",
      "          2       0.93      0.91      0.92        45\n",
      "\n",
      "avg / total       0.90      0.89      0.89       101\n",
      "\n",
      "[13  4  1  0 36  2  0  4 41]\n",
      "svc Accuracy:  0.8910891089108911\n",
      "svc F1:  0.8793689241713004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.61      0.76        18\n",
      "          1       1.00      0.87      0.93        38\n",
      "          2       0.79      1.00      0.88        45\n",
      "\n",
      "avg / total       0.91      0.88      0.88       101\n",
      "\n",
      "[11  0  7  0 33  5  0  0 45]\n",
      "LR Accuracy:  0.8811881188118812\n",
      "LR F1:  0.8568503652067919\n",
      "For name:  c_johnson\n",
      "total sample size before apply threshold:  300\n",
      "Counter({'0000-0002-6864-6604': 114, '0000-0002-9719-3771': 47, '0000-0001-9616-6205': 44, '0000-0002-9511-905X': 21, '0000-0001-9190-8441': 18, '0000-0003-3892-7082': 16, '0000-0003-4428-3594': 14, '0000-0002-2298-7462': 12, '0000-0001-9079-813X': 5, '0000-0001-9616-5755': 2, '0000-0003-1954-5142': 2, '0000-0003-2192-3616': 1, '0000-0002-7390-9720': 1, '0000-0002-6679-833X': 1, '0000-0002-6616-4441': 1, '0000-0003-2733-3326': 1})\n",
      "['0000-0002-9511-905X', '0000-0001-9616-6205', '0000-0003-3892-7082', '0000-0002-2298-7462', '0000-0002-6864-6604', '0000-0001-9190-8441', '0000-0002-9719-3771', '0000-0003-4428-3594']\n",
      "Total sample size after apply threshold:  286\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(286, 747)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "286\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.05      0.09        21\n",
      "          1       0.80      0.36      0.50        44\n",
      "          2       0.00      0.00      0.00        16\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.49      1.00      0.66       114\n",
      "          5       1.00      0.33      0.50        18\n",
      "          6       1.00      0.60      0.75        47\n",
      "          7       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.62      0.58      0.50       286\n",
      "\n",
      "[  1   0   0   0  20   0   0   0   0  16   0   0  28   0   0   0   0   4\n",
      "   0   0  12   0   0   0   0   0   0   0  12   0   0   0   0   0   0   0\n",
      " 114   0   0   0   0   0   0   0  12   6   0   0   0   0   0   0  19   0\n",
      "  28   0   0   0   0   0  14   0   0   0]\n",
      "MNB Accuracy:  0.5769230769230769\n",
      "MNB F1:  0.3123056653491436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.55        21\n",
      "          1       0.52      0.73      0.61        44\n",
      "          2       1.00      0.19      0.32        16\n",
      "          3       1.00      0.92      0.96        12\n",
      "          4       0.76      0.96      0.85       114\n",
      "          5       1.00      0.78      0.88        18\n",
      "          6       0.87      0.72      0.79        47\n",
      "          7       1.00      0.36      0.53        14\n",
      "\n",
      "avg / total       0.81      0.76      0.74       286\n",
      "\n",
      "[  8   8   0   0   4   0   1   0   0  32   0   0  12   0   0   0   0   6\n",
      "   3   0   7   0   0   0   0   1   0  11   0   0   0   0   0   3   0   0\n",
      " 110   0   1   0   0   0   0   0   4  14   0   0   0   5   0   0   8   0\n",
      "  34   0   0   6   0   0   0   0   3   5]\n",
      "svc Accuracy:  0.7587412587412588\n",
      "svc F1:  0.6843741841978285\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.38        21\n",
      "          1       1.00      0.36      0.53        44\n",
      "          2       1.00      0.06      0.12        16\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       0.52      1.00      0.68       114\n",
      "          5       1.00      0.44      0.62        18\n",
      "          6       1.00      0.66      0.79        47\n",
      "          7       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.76      0.63      0.59       286\n",
      "\n",
      "[  5   0   0   0  16   0   0   0   0  16   0   0  28   0   0   0   0   0\n",
      "   1   0  15   0   0   0   0   0   0   6   6   0   0   0   0   0   0   0\n",
      " 114   0   0   0   0   0   0   0  10   8   0   0   0   0   0   0  16   0\n",
      "  31   0   0   0   0   0  14   0   0   0]\n",
      "LR Accuracy:  0.6328671328671329\n",
      "LR F1:  0.4746504422975011\n",
      "For name:  e_henry\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-5648-8696': 18, '0000-0002-2547-3467': 10, '0000-0002-3884-2612': 2, '0000-0003-3178-2749': 1})\n",
      "['0000-0002-5648-8696', '0000-0002-2547-3467']\n",
      "Total sample size after apply threshold:  28\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 103)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        18\n",
      "          1       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.88      0.86      0.85        28\n",
      "\n",
      "[18  0  4  6]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        18\n",
      "          1       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.97      0.96      0.96        28\n",
      "\n",
      "[17  1  0 10]\n",
      "svc Accuracy:  0.9642857142857143\n",
      "svc F1:  0.9619047619047618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80        18\n",
      "          1       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.79      0.68      0.58        28\n",
      "\n",
      "[18  0  9  1]\n",
      "LR Accuracy:  0.6785714285714286\n",
      "LR F1:  0.49090909090909096\n",
      "For name:  x_xie\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-2701-8660': 13, '0000-0002-1964-4370': 6, '0000-0003-2988-3065': 2, '0000-0002-6796-8521': 1, '0000-0002-3103-3724': 1, '0000-0002-7970-2974': 1})\n",
      "['0000-0002-2701-8660']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  x_jin\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0002-1550-2199': 27, '0000-0003-2454-1621': 11, '0000-0002-2809-7882': 11, '0000-0003-4293-8665': 9, '0000-0001-7339-2920': 2, '0000-0001-6742-1799': 1, '0000-0003-3033-758X': 1})\n",
      "['0000-0002-1550-2199', '0000-0003-2454-1621', '0000-0002-2809-7882']\n",
      "Total sample size after apply threshold:  49\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 112)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        27\n",
      "          1       0.85      1.00      0.92        11\n",
      "          2       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.97      0.96      0.96        49\n",
      "\n",
      "[26  1  0  0 11  0  0  1 10]\n",
      "MNB Accuracy:  0.9591836734693877\n",
      "MNB F1:  0.9500598981731058\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        27\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.98      0.98      0.98        49\n",
      "\n",
      "[26  0  1  0 11  0  0  0 11]\n",
      "svc Accuracy:  0.9795918367346939\n",
      "svc F1:  0.979217938200711\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        27\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.96      0.96      0.96        49\n",
      "\n",
      "[27  0  0  0 11  0  2  0  9]\n",
      "LR Accuracy:  0.9591836734693877\n",
      "LR F1:  0.9547619047619048\n",
      "For name:  s_singh\n",
      "total sample size before apply threshold:  344\n",
      "Counter({'0000-0003-0912-941X': 70, '0000-0003-3454-2089': 61, '0000-0001-6545-583X': 40, '0000-0003-1033-2546': 19, '0000-0001-9115-3296': 18, '0000-0002-3656-2596': 15, '0000-0002-3482-7001': 14, '0000-0002-9391-0155': 13, '0000-0001-9984-5385': 11, '0000-0002-1028-6255': 9, '0000-0001-6820-9896': 9, '0000-0002-0900-8370': 7, '0000-0003-4404-6089': 6, '0000-0002-8730-524X': 5, '0000-0002-8114-1539': 5, '0000-0001-6521-0998': 5, '0000-0002-8524-0809': 4, '0000-0001-5482-9744': 3, '0000-0001-9505-4842': 3, '0000-0002-5154-3318': 2, '0000-0002-4038-5924': 2, '0000-0001-5545-7831': 2, '0000-0002-1878-8516': 2, '0000-0003-1914-4955': 2, '0000-0001-5361-4303': 2, '0000-0002-4897-8812': 2, '0000-0001-5935-3829': 2, '0000-0003-3562-6807': 1, '0000-0001-9826-2508': 1, '0000-0001-5985-5781': 1, '0000-0002-0193-9349': 1, '0000-0001-9754-1724': 1, '0000-0003-4805-7383': 1, '0000-0002-0022-6240': 1, '0000-0001-7509-3115': 1, '0000-0001-5412-2888': 1, '0000-0001-9669-3531': 1, '0000-0001-9338-1209': 1})\n",
      "['0000-0002-9391-0155', '0000-0002-3656-2596', '0000-0001-9115-3296', '0000-0002-3482-7001', '0000-0003-3454-2089', '0000-0003-0912-941X', '0000-0001-9984-5385', '0000-0001-6545-583X', '0000-0003-1033-2546']\n",
      "Total sample size after apply threshold:  261\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(261, 509)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "261\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       1.00      0.80      0.89        15\n",
      "          2       1.00      0.50      0.67        18\n",
      "          3       1.00      0.29      0.44        14\n",
      "          4       0.98      0.79      0.87        61\n",
      "          5       0.51      1.00      0.67        70\n",
      "          6       1.00      0.36      0.53        11\n",
      "          7       0.86      0.75      0.80        40\n",
      "          8       1.00      0.53      0.69        19\n",
      "\n",
      "avg / total       0.79      0.72      0.70       261\n",
      "\n",
      "[ 0  0  0  0  0 13  0  0  0  0 12  0  0  0  3  0  0  0  0  0  9  0  0  6\n",
      "  0  3  0  0  0  0  4  0  9  0  1  0  0  0  0  0 48 12  0  1  0  0  0  0\n",
      "  0  0 70  0  0  0  0  0  0  0  0  7  4  0  0  0  0  0  0  0 10  0 30  0\n",
      "  0  0  0  0  1  8  0  0 10]\n",
      "MNB Accuracy:  0.7164750957854407\n",
      "MNB F1:  0.6187547446168136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.14        13\n",
      "          1       1.00      0.80      0.89        15\n",
      "          2       1.00      0.94      0.97        18\n",
      "          3       0.92      0.79      0.85        14\n",
      "          4       1.00      0.80      0.89        61\n",
      "          5       0.56      0.99      0.71        70\n",
      "          6       1.00      0.45      0.62        11\n",
      "          7       0.97      0.70      0.81        40\n",
      "          8       1.00      0.63      0.77        19\n",
      "\n",
      "avg / total       0.87      0.78      0.78       261\n",
      "\n",
      "[ 1  0  0  0  0 12  0  0  0  0 12  0  0  0  3  0  0  0  0  0 17  0  0  1\n",
      "  0  0  0  0  0  0 11  0  3  0  0  0  0  0  0  0 49 11  0  1  0  0  0  0\n",
      "  1  0 69  0  0  0  0  0  0  0  0  6  5  0  0  0  0  0  0  0 12  0 28  0\n",
      "  0  0  0  0  0  7  0  0 12]\n",
      "svc Accuracy:  0.7816091954022989\n",
      "svc F1:  0.7402628330787505\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       1.00      0.80      0.89        15\n",
      "          2       1.00      0.78      0.88        18\n",
      "          3       1.00      0.64      0.78        14\n",
      "          4       0.96      0.79      0.86        61\n",
      "          5       0.53      1.00      0.69        70\n",
      "          6       1.00      0.45      0.62        11\n",
      "          7       0.96      0.65      0.78        40\n",
      "          8       1.00      0.63      0.77        19\n",
      "\n",
      "avg / total       0.81      0.75      0.74       261\n",
      "\n",
      "[ 0  0  0  0  1 12  0  0  0  0 12  0  0  0  3  0  0  0  0  0 14  0  0  4\n",
      "  0  0  0  0  0  0  9  0  5  0  0  0  0  0  0  0 48 12  0  1  0  0  0  0\n",
      "  0  0 70  0  0  0  0  0  0  0  0  6  5  0  0  0  0  0  0  0 14  0 26  0\n",
      "  0  0  0  0  1  6  0  0 12]\n",
      "LR Accuracy:  0.7509578544061303\n",
      "LR F1:  0.6977494119676436\n",
      "For name:  m_reid\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0003-4005-9384': 55, '0000-0002-4101-0921': 5, '0000-0002-0397-2556': 1, '0000-0002-3948-9347': 1})\n",
      "['0000-0003-4005-9384']\n",
      "Total sample size after apply threshold:  55\n",
      "For name:  m_wallace\n",
      "total sample size before apply threshold:  144\n",
      "Counter({'0000-0002-0166-906X': 57, '0000-0001-6894-4903': 52, '0000-0002-5692-8313': 30, '0000-0001-5407-8653': 3, '0000-0002-8318-7952': 2})\n",
      "['0000-0002-0166-906X', '0000-0002-5692-8313', '0000-0001-6894-4903']\n",
      "Total sample size after apply threshold:  139\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 201)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90        57\n",
      "          1       1.00      0.53      0.70        30\n",
      "          2       0.76      0.85      0.80        52\n",
      "\n",
      "avg / total       0.85      0.83      0.82       139\n",
      "\n",
      "[55  0  2  2 16 12  8  0 44]\n",
      "MNB Accuracy:  0.8273381294964028\n",
      "MNB F1:  0.7990971727251129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.95      0.87        57\n",
      "          1       1.00      0.77      0.87        30\n",
      "          2       0.88      0.83      0.85        52\n",
      "\n",
      "avg / total       0.87      0.86      0.86       139\n",
      "\n",
      "[54  0  3  4 23  3  9  0 43]\n",
      "svc Accuracy:  0.8633093525179856\n",
      "svc F1:  0.8634591395840742\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      1.00      0.81        57\n",
      "          1       1.00      0.47      0.64        30\n",
      "          2       0.98      0.77      0.86        52\n",
      "\n",
      "avg / total       0.86      0.80      0.79       139\n",
      "\n",
      "[57  0  0 15 14  1 12  0 40]\n",
      "LR Accuracy:  0.7985611510791367\n",
      "LR F1:  0.7683631094749832\n",
      "For name:  y_zhang\n",
      "total sample size before apply threshold:  1244\n",
      "Counter({'0000-0001-8642-4071': 104, '0000-0002-3254-8965': 64, '0000-0001-7307-9408': 56, '0000-0002-9956-3879': 48, '0000-0003-2932-4159': 48, '0000-0003-2317-2190': 45, '0000-0003-2753-7601': 37, '0000-0001-6118-6695': 31, '0000-0002-6460-6779': 29, '0000-0002-1079-4137': 28, '0000-0001-8357-5544': 28, '0000-0002-2663-1279': 27, '0000-0002-8457-5922': 27, '0000-0002-1239-3441': 26, '0000-0003-1148-949X': 26, '0000-0001-7436-9757': 23, '0000-0002-0045-0808': 22, '0000-0002-3859-3839': 22, '0000-0001-6777-3487': 22, '0000-0002-8448-3059': 21, '0000-0003-0592-9153': 21, '0000-0003-4698-5645': 20, '0000-0002-2832-2277': 20, '0000-0003-4082-5026': 20, '0000-0001-7433-1820': 17, '0000-0002-7339-8342': 16, '0000-0002-7926-9904': 14, '0000-0002-8270-1067': 14, '0000-0002-9548-0021': 14, '0000-0001-6577-5235': 14, '0000-0002-6035-8536': 14, '0000-0003-2212-1527': 13, '0000-0003-2560-3927': 13, '0000-0001-6751-9294': 12, '0000-0003-2351-5579': 11, '0000-0002-4405-4268': 9, '0000-0001-7882-5692': 9, '0000-0002-4477-7570': 8, '0000-0002-2559-3741': 8, '0000-0001-8759-0194': 7, '0000-0003-2968-0081': 7, '0000-0001-5562-9090': 7, '0000-0002-2614-5975': 7, '0000-0001-5734-0709': 7, '0000-0002-9263-6262': 7, '0000-0003-0022-1201': 6, '0000-0002-1990-9439': 6, '0000-0002-5765-0923': 6, '0000-0002-5715-2182': 5, '0000-0002-4762-6639': 5, '0000-0003-1204-8717': 5, '0000-0003-0614-2096': 5, '0000-0001-8938-1927': 5, '0000-0002-6764-3567': 5, '0000-0003-0522-6300': 5, '0000-0002-6201-7970': 5, '0000-0001-8286-300X': 5, '0000-0001-9983-5451': 5, '0000-0001-9321-9228': 4, '0000-0002-7422-8206': 4, '0000-0001-9157-5544': 4, '0000-0001-8702-909X': 4, '0000-0001-8915-1769': 4, '0000-0003-0919-2224': 4, '0000-0002-6893-2053': 4, '0000-0001-8537-8181': 4, '0000-0002-7468-2409': 4, '0000-0003-3531-0052': 4, '0000-0001-5996-5438': 4, '0000-0002-0814-2965': 4, '0000-0003-1011-3001': 4, '0000-0003-4355-9755': 4, '0000-0002-4870-1493': 4, '0000-0002-9731-5943': 3, '0000-0002-3562-2323': 3, '0000-0003-0757-1837': 3, '0000-0003-4353-593X': 3, '0000-0003-4638-0056': 3, '0000-0003-1608-4467': 3, '0000-0003-1620-3825': 2, '0000-0002-9738-5343': 2, '0000-0001-9126-4922': 2, '0000-0002-1634-5017': 2, '0000-0001-9934-7925': 2, '0000-0003-3709-7144': 2, '0000-0001-7636-7368': 2, '0000-0002-8663-5001': 2, '0000-0002-8754-8938': 2, '0000-0002-1084-9994': 2, '0000-0001-8474-5947': 2, '0000-0002-1483-9021': 2, '0000-0002-8121-3678': 2, '0000-0002-0238-0719': 2, '0000-0003-1174-6599': 2, '0000-0003-0182-4215': 1, '0000-0002-9318-0324': 1, '0000-0003-3770-0046': 1, '0000-0001-7783-8336': 1, '0000-0003-4267-0144': 1, '0000-0003-2179-3698': 1, '0000-0002-7484-8800': 1, '0000-0002-5254-6764': 1, '0000-0003-0859-9735': 1, '0000-0002-4087-420X': 1, '0000-0003-2158-6541': 1, '0000-0002-2684-7395': 1, '0000-0002-8123-7805': 1, '0000-0002-5901-4242': 1, '0000-0003-0397-7143': 1, '0000-0003-1614-1943': 1, '0000-0001-9588-2314': 1, '0000-0002-1259-020X': 1, '0000-0002-7175-6150': 1, '0000-0002-7627-488X': 1, '0000-0002-3873-4574': 1, '0000-0003-2903-2287': 1, '0000-0003-4114-7183': 1, '0000-0001-8738-1851': 1, '0000-0002-1566-098X': 1})\n",
      "['0000-0002-0045-0808', '0000-0002-7926-9904', '0000-0002-8448-3059', '0000-0003-4698-5645', '0000-0003-2212-1527', '0000-0002-3859-3839', '0000-0002-3254-8965', '0000-0001-7307-9408', '0000-0001-6777-3487', '0000-0002-1239-3441', '0000-0002-1079-4137', '0000-0002-9956-3879', '0000-0002-8270-1067', '0000-0001-6751-9294', '0000-0003-2932-4159', '0000-0002-2663-1279', '0000-0003-1148-949X', '0000-0003-2317-2190', '0000-0001-7436-9757', '0000-0001-8357-5544', '0000-0001-8642-4071', '0000-0002-9548-0021', '0000-0001-7433-1820', '0000-0003-2351-5579', '0000-0002-7339-8342', '0000-0001-6118-6695', '0000-0002-8457-5922', '0000-0001-6577-5235', '0000-0003-2560-3927', '0000-0002-2832-2277', '0000-0003-0592-9153', '0000-0002-6460-6779', '0000-0003-2753-7601', '0000-0002-6035-8536', '0000-0003-4082-5026']\n",
      "Total sample size after apply threshold:  967\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(967, 1103)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "967\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        22\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       1.00      0.05      0.09        21\n",
      "          3       0.00      0.00      0.00        20\n",
      "          4       0.00      0.00      0.00        13\n",
      "          5       0.00      0.00      0.00        22\n",
      "          6       0.48      0.64      0.55        64\n",
      "          7       0.73      0.48      0.58        56\n",
      "          8       1.00      0.09      0.17        22\n",
      "          9       1.00      0.12      0.21        26\n",
      "         10       1.00      0.39      0.56        28\n",
      "         11       0.81      0.79      0.80        48\n",
      "         12       0.00      0.00      0.00        14\n",
      "         13       0.00      0.00      0.00        12\n",
      "         14       0.86      0.40      0.54        48\n",
      "         15       1.00      0.37      0.54        27\n",
      "         16       0.00      0.00      0.00        26\n",
      "         17       0.73      0.18      0.29        45\n",
      "         18       1.00      0.22      0.36        23\n",
      "         19       1.00      0.68      0.81        28\n",
      "         20       0.16      0.97      0.28       104\n",
      "         21       0.00      0.00      0.00        14\n",
      "         22       0.00      0.00      0.00        17\n",
      "         23       0.00      0.00      0.00        11\n",
      "         24       1.00      0.06      0.12        16\n",
      "         25       0.82      0.29      0.43        31\n",
      "         26       1.00      0.59      0.74        27\n",
      "         27       0.00      0.00      0.00        14\n",
      "         28       0.00      0.00      0.00        13\n",
      "         29       1.00      0.75      0.86        20\n",
      "         30       1.00      0.19      0.32        21\n",
      "         31       1.00      0.41      0.59        29\n",
      "         32       1.00      0.22      0.36        37\n",
      "         33       1.00      0.14      0.25        14\n",
      "         34       1.00      0.20      0.33        20\n",
      "\n",
      "avg / total       0.63      0.38      0.37       967\n",
      "\n",
      "[11  0  0 ...  0  0  4]\n",
      "MNB Accuracy:  0.3795243019648397\n",
      "MNB F1:  0.29794269227576686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        22\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       0.88      0.67      0.76        21\n",
      "          3       0.71      0.25      0.37        20\n",
      "          4       1.00      1.00      1.00        13\n",
      "          5       0.56      0.23      0.32        22\n",
      "          6       0.52      0.73      0.61        64\n",
      "          7       0.61      0.70      0.65        56\n",
      "          8       1.00      0.77      0.87        22\n",
      "          9       0.78      0.96      0.86        26\n",
      "         10       1.00      0.86      0.92        28\n",
      "         11       0.95      0.88      0.91        48\n",
      "         12       0.90      0.64      0.75        14\n",
      "         13       0.86      0.50      0.63        12\n",
      "         14       0.69      0.85      0.77        48\n",
      "         15       1.00      0.74      0.85        27\n",
      "         16       0.76      0.85      0.80        26\n",
      "         17       0.42      0.56      0.48        45\n",
      "         18       1.00      0.83      0.90        23\n",
      "         19       0.96      0.79      0.86        28\n",
      "         20       0.67      0.83      0.74       104\n",
      "         21       1.00      0.36      0.53        14\n",
      "         22       0.79      0.65      0.71        17\n",
      "         23       1.00      0.27      0.43        11\n",
      "         24       1.00      0.75      0.86        16\n",
      "         25       0.83      0.94      0.88        31\n",
      "         26       1.00      0.85      0.92        27\n",
      "         27       0.82      0.64      0.72        14\n",
      "         28       0.91      0.77      0.83        13\n",
      "         29       1.00      0.85      0.92        20\n",
      "         30       1.00      0.86      0.92        21\n",
      "         31       1.00      0.90      0.95        29\n",
      "         32       0.49      0.70      0.58        37\n",
      "         33       1.00      0.93      0.96        14\n",
      "         34       0.90      0.90      0.90        20\n",
      "\n",
      "avg / total       0.79      0.76      0.76       967\n",
      "\n",
      "[22  0  0 ...  0  0 18]\n",
      "svc Accuracy:  0.7580144777662875\n",
      "svc F1:  0.7695908488274678\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        22\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       1.00      0.67      0.80        21\n",
      "          3       0.50      0.15      0.23        20\n",
      "          4       1.00      1.00      1.00        13\n",
      "          5       1.00      0.18      0.31        22\n",
      "          6       0.49      0.77      0.60        64\n",
      "          7       0.64      0.66      0.65        56\n",
      "          8       1.00      0.68      0.81        22\n",
      "          9       0.74      0.77      0.75        26\n",
      "         10       1.00      0.86      0.92        28\n",
      "         11       0.73      0.85      0.79        48\n",
      "         12       0.00      0.00      0.00        14\n",
      "         13       1.00      0.42      0.59        12\n",
      "         14       0.62      0.81      0.70        48\n",
      "         15       0.95      0.70      0.81        27\n",
      "         16       0.70      0.54      0.61        26\n",
      "         17       0.46      0.49      0.47        45\n",
      "         18       1.00      0.74      0.85        23\n",
      "         19       1.00      0.75      0.86        28\n",
      "         20       0.48      0.89      0.62       104\n",
      "         21       1.00      0.07      0.13        14\n",
      "         22       1.00      0.53      0.69        17\n",
      "         23       0.00      0.00      0.00        11\n",
      "         24       1.00      0.56      0.72        16\n",
      "         25       0.68      0.90      0.78        31\n",
      "         26       0.96      0.85      0.90        27\n",
      "         27       0.80      0.29      0.42        14\n",
      "         28       1.00      0.54      0.70        13\n",
      "         29       1.00      0.90      0.95        20\n",
      "         30       1.00      0.71      0.83        21\n",
      "         31       1.00      0.90      0.95        29\n",
      "         32       0.54      0.57      0.55        37\n",
      "         33       1.00      0.93      0.96        14\n",
      "         34       0.90      0.95      0.93        20\n",
      "\n",
      "avg / total       0.74      0.70      0.69       967\n",
      "\n",
      "[22  0  0 ...  0  0 19]\n",
      "LR Accuracy:  0.6980351602895554\n",
      "LR F1:  0.6760845704602897\n",
      "For name:  m_young\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0003-0450-5375': 51, '0000-0002-9615-9002': 27, '0000-0002-7263-6505': 9, '0000-0001-5168-9416': 8, '0000-0001-8479-9910': 4, '0000-0002-1262-5935': 2})\n",
      "['0000-0002-9615-9002', '0000-0003-0450-5375']\n",
      "Total sample size after apply threshold:  78\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 197)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.59      0.74        27\n",
      "          1       0.82      1.00      0.90        51\n",
      "\n",
      "avg / total       0.88      0.86      0.85        78\n",
      "\n",
      "[16 11  0 51]\n",
      "MNB Accuracy:  0.8589743589743589\n",
      "MNB F1:  0.8234204568841326\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.78      0.86        27\n",
      "          1       0.89      0.98      0.93        51\n",
      "\n",
      "avg / total       0.91      0.91      0.91        78\n",
      "\n",
      "[21  6  1 50]\n",
      "svc Accuracy:  0.9102564102564102\n",
      "svc F1:  0.8958611481975969\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.48      0.65        27\n",
      "          1       0.78      1.00      0.88        51\n",
      "\n",
      "avg / total       0.86      0.82      0.80        78\n",
      "\n",
      "[13 14  0 51]\n",
      "LR Accuracy:  0.8205128205128205\n",
      "LR F1:  0.7646551724137931\n",
      "For name:  s_saraf\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-8384-9370': 38, '0000-0002-0569-1213': 13, '0000-0003-3905-0542': 2, '0000-0002-4180-0931': 1})\n",
      "['0000-0002-0569-1213', '0000-0002-8384-9370']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 39)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.88      1.00      0.94        38\n",
      "\n",
      "avg / total       0.91      0.90      0.89        51\n",
      "\n",
      "[ 8  5  0 38]\n",
      "MNB Accuracy:  0.9019607843137255\n",
      "MNB F1:  0.8500881834215168\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        13\n",
      "          1       0.93      1.00      0.96        38\n",
      "\n",
      "avg / total       0.95      0.94      0.94        51\n",
      "\n",
      "[10  3  0 38]\n",
      "svc Accuracy:  0.9411764705882353\n",
      "svc F1:  0.9157952669235003\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.81      1.00      0.89        38\n",
      "\n",
      "avg / total       0.86      0.82      0.79        51\n",
      "\n",
      "[ 4  9  0 38]\n",
      "LR Accuracy:  0.8235294117647058\n",
      "LR F1:  0.6823529411764706\n",
      "For name:  r_pinto\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0002-1667-7871': 36, '0000-0002-2775-860X': 21, '0000-0001-5600-2396': 8, '0000-0002-6429-2087': 8, '0000-0003-0058-8652': 6, '0000-0002-4068-7391': 2, '0000-0001-9402-5775': 2, '0000-0002-1251-5007': 1, '0000-0002-4512-5566': 1})\n",
      "['0000-0002-1667-7871', '0000-0002-2775-860X']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 174)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        36\n",
      "          1       1.00      0.90      0.95        21\n",
      "\n",
      "avg / total       0.97      0.96      0.96        57\n",
      "\n",
      "[36  0  2 19]\n",
      "MNB Accuracy:  0.9649122807017544\n",
      "MNB F1:  0.9614864864864865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        36\n",
      "          1       1.00      0.81      0.89        21\n",
      "\n",
      "avg / total       0.94      0.93      0.93        57\n",
      "\n",
      "[36  0  4 17]\n",
      "svc Accuracy:  0.9298245614035088\n",
      "svc F1:  0.9210526315789473\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        36\n",
      "          1       1.00      0.76      0.86        21\n",
      "\n",
      "avg / total       0.92      0.91      0.91        57\n",
      "\n",
      "[36  0  5 16]\n",
      "LR Accuracy:  0.9122807017543859\n",
      "LR F1:  0.8999648999648999\n",
      "For name:  m_brito\n",
      "total sample size before apply threshold:  86\n",
      "Counter({'0000-0002-8493-4649': 51, '0000-0001-6394-658X': 31, '0000-0002-8973-104X': 2, '0000-0001-9689-7040': 1, '0000-0002-1779-4535': 1})\n",
      "['0000-0002-8493-4649', '0000-0001-6394-658X']\n",
      "Total sample size after apply threshold:  82\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 169)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93        51\n",
      "          1       0.96      0.77      0.86        31\n",
      "\n",
      "avg / total       0.91      0.90      0.90        82\n",
      "\n",
      "[50  1  7 24]\n",
      "MNB Accuracy:  0.9024390243902439\n",
      "MNB F1:  0.8915343915343915\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.92      0.95        51\n",
      "          1       0.88      0.97      0.92        31\n",
      "\n",
      "avg / total       0.94      0.94      0.94        82\n",
      "\n",
      "[47  4  1 30]\n",
      "svc Accuracy:  0.9390243902439024\n",
      "svc F1:  0.9362859362859361\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91        51\n",
      "          1       0.96      0.71      0.81        31\n",
      "\n",
      "avg / total       0.89      0.88      0.87        82\n",
      "\n",
      "[50  1  9 22]\n",
      "LR Accuracy:  0.8780487804878049\n",
      "LR F1:  0.8619528619528619\n",
      "For name:  s_goel\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-7485-5392': 16, '0000-0003-2866-790X': 7, '0000-0001-7886-9441': 4, '0000-0002-8694-332X': 3, '0000-0002-9739-4178': 1})\n",
      "['0000-0001-7485-5392']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  y_park\n",
      "total sample size before apply threshold:  627\n",
      "Counter({'0000-0002-6281-489X': 171, '0000-0002-5879-6879': 78, '0000-0002-3671-6364': 67, '0000-0002-9553-8561': 56, '0000-0003-1191-7335': 35, '0000-0002-8288-9450': 32, '0000-0002-8808-4530': 28, '0000-0002-1310-148X': 28, '0000-0002-5466-2339': 22, '0000-0001-8336-8051': 20, '0000-0003-3652-591X': 16, '0000-0001-8583-4335': 15, '0000-0001-8495-9224': 14, '0000-0001-7025-8945': 13, '0000-0002-1959-0843': 9, '0000-0002-7574-4165': 7, '0000-0003-1997-6444': 6, '0000-0002-8536-0835': 3, '0000-0001-6587-6562': 3, '0000-0002-1702-0986': 1, '0000-0002-2801-2674': 1, '0000-0001-5110-5716': 1, '0000-0002-3019-5748': 1})\n",
      "['0000-0001-7025-8945', '0000-0002-5466-2339', '0000-0003-3652-591X', '0000-0002-3671-6364', '0000-0002-8808-4530', '0000-0003-1191-7335', '0000-0002-5879-6879', '0000-0001-8495-9224', '0000-0002-8288-9450', '0000-0001-8336-8051', '0000-0001-8583-4335', '0000-0002-1310-148X', '0000-0002-6281-489X', '0000-0002-9553-8561']\n",
      "Total sample size after apply threshold:  595\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(595, 1039)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.00      0.00      0.00        22\n",
      "          2       0.00      0.00      0.00        16\n",
      "          3       0.37      0.90      0.52        67\n",
      "          4       0.00      0.00      0.00        28\n",
      "          5       1.00      0.40      0.57        35\n",
      "          6       0.62      0.88      0.73        78\n",
      "          7       0.00      0.00      0.00        14\n",
      "          8       1.00      0.25      0.40        32\n",
      "          9       1.00      0.05      0.10        20\n",
      "         10       0.00      0.00      0.00        15\n",
      "         11       1.00      0.54      0.70        28\n",
      "         12       0.72      0.99      0.84       171\n",
      "         13       0.68      0.57      0.62        56\n",
      "\n",
      "avg / total       0.59      0.62      0.54       595\n",
      "\n",
      "[  0   0   0   2   0   0   3   0   0   0   0   0   7   1   0   0   0  13\n",
      "   0   0   2   0   0   0   0   0   5   2   0   0   0  14   0   0   2   0\n",
      "   0   0   0   0   0   0   0   0   0  60   0   0   1   0   0   0   0   0\n",
      "   3   3   0   0   0  14   0   0   7   0   0   0   0   0   2   5   0   0\n",
      "   0   1   0  14   1   0   0   0   0   0  19   0   0   0   0   5   0   0\n",
      "  69   0   0   0   0   0   4   0   0   0   0  10   0   0   4   0   0   0\n",
      "   0   0   0   0   0   0   0  15   0   0   9   0   8   0   0   0   0   0\n",
      "   0   0   0   9   0   0   4   0   0   1   0   0   2   4   0   0   0   1\n",
      "   0   0   0   0   0   0   0   0  14   0   0   0   0   2   0   0   1   0\n",
      "   0   0   0  15  10   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      " 170   0   0   0   0  16   0   0   8   0   0   0   0   0   0  32]\n",
      "MNB Accuracy:  0.6201680672268908\n",
      "MNB F1:  0.31938674290540836\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82        13\n",
      "          1       0.88      0.32      0.47        22\n",
      "          2       1.00      1.00      1.00        16\n",
      "          3       0.78      0.85      0.81        67\n",
      "          4       0.52      0.39      0.45        28\n",
      "          5       1.00      0.91      0.96        35\n",
      "          6       0.88      0.88      0.88        78\n",
      "          7       0.83      0.36      0.50        14\n",
      "          8       0.75      0.66      0.70        32\n",
      "          9       0.85      0.55      0.67        20\n",
      "         10       1.00      0.47      0.64        15\n",
      "         11       1.00      0.93      0.96        28\n",
      "         12       0.85      1.00      0.92       171\n",
      "         13       0.61      0.82      0.70        56\n",
      "\n",
      "avg / total       0.83      0.82      0.81       595\n",
      "\n",
      "[  9   0   0   0   1   0   0   0   0   0   0   0   3   0   0   7   0   2\n",
      "   2   0   0   0   0   0   0   0   6   5   0   0  16   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  57   1   0   0   0   0   0   0   0\n",
      "   3   6   0   0   0   2  11   0   4   0   1   2   0   0   2   6   0   0\n",
      "   0   0   0  32   0   0   0   0   0   0   3   0   0   0   0   3   2   0\n",
      "  69   0   0   0   0   0   2   2   0   1   0   2   2   0   2   5   1   0\n",
      "   0   0   0   1   0   0   0   3   1   0   0   1  21   0   0   0   0   6\n",
      "   0   0   0   1   1   0   1   0   0  11   0   0   2   4   0   0   0   0\n",
      "   0   0   0   0   0   0   7   0   8   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  26   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 171   0   0   0   0   3   0   0   2   0   5   0   0   0   0  46]\n",
      "svc Accuracy:  0.8201680672268907\n",
      "svc F1:  0.7477004356839466\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       0.00      0.00      0.00        22\n",
      "          2       1.00      0.88      0.93        16\n",
      "          3       0.66      0.87      0.75        67\n",
      "          4       0.57      0.14      0.23        28\n",
      "          5       1.00      0.46      0.63        35\n",
      "          6       0.80      0.90      0.85        78\n",
      "          7       1.00      0.07      0.13        14\n",
      "          8       0.76      0.59      0.67        32\n",
      "          9       1.00      0.35      0.52        20\n",
      "         10       0.00      0.00      0.00        15\n",
      "         11       1.00      0.79      0.88        28\n",
      "         12       0.69      1.00      0.81       171\n",
      "         13       0.57      0.77      0.66        56\n",
      "\n",
      "avg / total       0.71      0.72      0.67       595\n",
      "\n",
      "[  4   0   0   0   2   0   1   0   0   0   0   0   6   0   0   0   0   6\n",
      "   1   0   1   0   0   0   0   0   9   5   0   0  14   1   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   0  58   0   0   1   0   0   0   0   0\n",
      "   4   4   0   0   0   0   4   0   5   0   0   0   0   0   7  12   0   0\n",
      "   0   0   0  16   0   0   0   0   0   0  19   0   0   0   0   3   0   0\n",
      "  70   0   0   0   0   0   5   0   0   0   0   2   0   0   3   1   4   0\n",
      "   0   0   3   1   0   0   0   7   0   0   1   0  19   0   0   0   0   5\n",
      "   0   0   0   3   0   0   2   0   0   7   0   0   4   4   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  15   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  22   6   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 171   0   0   0   0   8   0   0   3   0   2   0   0   0   0  43]\n",
      "LR Accuracy:  0.7210084033613445\n",
      "LR F1:  0.5375791932337595\n",
      "For name:  p_melo\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0003-0590-0684': 14, '0000-0002-4486-0200': 6, '0000-0002-3892-4140': 5, '0000-0002-4117-239X': 3})\n",
      "['0000-0003-0590-0684']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  c_lemos\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-9803-9584': 21, '0000-0003-3182-6289': 14, '0000-0001-8273-489X': 9, '0000-0002-3372-6719': 4, '0000-0003-3468-4191': 4})\n",
      "['0000-0003-3182-6289', '0000-0001-9803-9584']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 124)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       1.00      1.00      1.00        21\n",
      "\n",
      "avg / total       1.00      1.00      1.00        35\n",
      "\n",
      "[14  0  0 21]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       1.00      1.00      1.00        21\n",
      "\n",
      "avg / total       1.00      1.00      1.00        35\n",
      "\n",
      "[14  0  0 21]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.91      1.00      0.95        21\n",
      "\n",
      "avg / total       0.95      0.94      0.94        35\n",
      "\n",
      "[12  2  0 21]\n",
      "LR Accuracy:  0.9428571428571428\n",
      "LR F1:  0.9388111888111887\n",
      "For name:  b_liu\n",
      "total sample size before apply threshold:  298\n",
      "Counter({'0000-0002-0956-2777': 97, '0000-0002-8662-0512': 24, '0000-0002-0787-5825': 18, '0000-0001-6052-8411': 15, '0000-0001-9992-9319': 14, '0000-0002-5836-2333': 14, '0000-0002-8676-4794': 12, '0000-0003-0122-3866': 11, '0000-0002-4948-2835': 10, '0000-0003-2211-5557': 10, '0000-0003-3060-3120': 9, '0000-0001-8211-6303': 8, '0000-0002-9318-1335': 8, '0000-0001-6655-1866': 7, '0000-0002-4511-6926': 6, '0000-0002-7257-2441': 5, '0000-0001-8806-820X': 5, '0000-0002-8550-1722': 3, '0000-0002-7347-1941': 3, '0000-0001-6221-1047': 3, '0000-0003-4532-3658': 3, '0000-0002-9539-2005': 2, '0000-0003-2529-0123': 2, '0000-0002-8318-9667': 2, '0000-0002-6825-3536': 2, '0000-0002-9495-6809': 2, '0000-0002-1677-2772': 1, '0000-0002-5272-3425': 1, '0000-0002-7543-1054': 1})\n",
      "['0000-0003-0122-3866', '0000-0001-6052-8411', '0000-0002-0787-5825', '0000-0002-8662-0512', '0000-0001-9992-9319', '0000-0002-4948-2835', '0000-0002-0956-2777', '0000-0003-2211-5557', '0000-0002-5836-2333', '0000-0002-8676-4794']\n",
      "Total sample size after apply threshold:  225\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(225, 465)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.13      0.24        15\n",
      "          2       1.00      0.50      0.67        18\n",
      "          3       1.00      0.62      0.77        24\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.51      1.00      0.67        97\n",
      "          7       1.00      0.10      0.18        10\n",
      "          8       0.00      0.00      0.00        14\n",
      "          9       1.00      0.50      0.67        12\n",
      "\n",
      "avg / total       0.57      0.58      0.48       225\n",
      "\n",
      "[ 0  0  0  0  0  0 11  0  0  0  0  2  0  0  0  0 13  0  0  0  0  0  9  0\n",
      "  0  0  9  0  0  0  0  0  0 15  0  0  9  0  0  0  0  0  0  0  0  0 14  0\n",
      "  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0 97  0  0  0  0  0\n",
      "  0  0  0  0  9  1  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0\n",
      "  6  0  0  6]\n",
      "MNB Accuracy:  0.5777777777777777\n",
      "MNB F1:  0.3190956678845952\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       1.00      0.80      0.89        15\n",
      "          2       1.00      0.78      0.88        18\n",
      "          3       0.95      0.83      0.89        24\n",
      "          4       1.00      0.36      0.53        14\n",
      "          5       1.00      0.40      0.57        10\n",
      "          6       0.70      0.98      0.82        97\n",
      "          7       1.00      0.70      0.82        10\n",
      "          8       0.83      0.71      0.77        14\n",
      "          9       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.86      0.81      0.80       225\n",
      "\n",
      "[ 5  0  0  0  0  0  6  0  0  0  0 12  0  0  0  0  3  0  0  0  0  0 14  0\n",
      "  0  0  4  0  0  0  0  0  0 20  0  0  3  0  1  0  0  0  0  0  5  0  9  0\n",
      "  0  0  0  0  0  0  0  4  6  0  0  0  0  0  0  1  0  0 95  0  1  0  0  0\n",
      "  0  0  0  0  3  7  0  0  0  0  0  0  0  0  4  0 10  0  0  0  0  0  0  0\n",
      "  2  0  0 10]\n",
      "svc Accuracy:  0.8088888888888889\n",
      "svc F1:  0.7696338746007797\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.47      0.64        15\n",
      "          2       1.00      0.56      0.71        18\n",
      "          3       0.95      0.83      0.89        24\n",
      "          4       0.75      0.21      0.33        14\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.57      0.99      0.72        97\n",
      "          7       1.00      0.50      0.67        10\n",
      "          8       1.00      0.21      0.35        14\n",
      "          9       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.70      0.67      0.62       225\n",
      "\n",
      "[ 0  0  0  0  0  0 11  0  0  0  0  7  0  0  0  0  8  0  0  0  0  0 10  0\n",
      "  0  0  8  0  0  0  0  0  0 20  0  0  4  0  0  0  0  0  0  0  3  0 11  0\n",
      "  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  1  0  0 96  0  0  0  0  0\n",
      "  0  0  0  0  5  5  0  0  0  0  0  0  0  0 11  0  3  0  0  0  0  0  1  0\n",
      "  4  0  0  7]\n",
      "LR Accuracy:  0.6711111111111111\n",
      "LR F1:  0.5053849823158777\n",
      "For name:  k_turner\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0002-8152-6017': 42, '0000-0003-3714-5118': 11, '0000-0002-3867-2684': 5, '0000-0001-8982-0301': 3, '0000-0002-1163-2201': 1})\n",
      "['0000-0002-8152-6017', '0000-0003-3714-5118']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 156)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        42\n",
      "          1       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.96      0.96      0.96        53\n",
      "\n",
      "[42  0  2  9]\n",
      "MNB Accuracy:  0.9622641509433962\n",
      "MNB F1:  0.9383720930232559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        42\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.98      0.98      0.98        53\n",
      "\n",
      "[42  0  1 10]\n",
      "svc Accuracy:  0.9811320754716981\n",
      "svc F1:  0.9703081232492996\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        42\n",
      "          1       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.92      0.91      0.89        53\n",
      "\n",
      "[42  0  5  6]\n",
      "LR Accuracy:  0.9056603773584906\n",
      "LR F1:  0.8248512888301387\n",
      "For name:  r_rao\n",
      "total sample size before apply threshold:  94\n",
      "Counter({'0000-0002-5776-8366': 52, '0000-0002-0262-5122': 14, '0000-0002-2285-6788': 12, '0000-0002-1475-3893': 9, '0000-0002-6415-0185': 7})\n",
      "['0000-0002-2285-6788', '0000-0002-5776-8366', '0000-0002-0262-5122']\n",
      "Total sample size after apply threshold:  78\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 130)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.71      1.00      0.83        52\n",
      "          2       1.00      0.07      0.13        14\n",
      "\n",
      "avg / total       0.81      0.73      0.66        78\n",
      "\n",
      "[ 4  8  0  0 52  0  0 13  1]\n",
      "MNB Accuracy:  0.7307692307692307\n",
      "MNB F1:  0.4884444444444444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.78      1.00      0.87        52\n",
      "          2       1.00      0.29      0.44        14\n",
      "\n",
      "avg / total       0.85      0.81      0.78        78\n",
      "\n",
      "[ 7  5  0  0 52  0  0 10  4]\n",
      "svc Accuracy:  0.8076923076923077\n",
      "svc F1:  0.6850787098465118\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        12\n",
      "          1       0.71      1.00      0.83        52\n",
      "          2       1.00      0.14      0.25        14\n",
      "\n",
      "avg / total       0.81      0.73      0.66        78\n",
      "\n",
      "[ 3  9  0  0 52  0  0 12  2]\n",
      "LR Accuracy:  0.7307692307692307\n",
      "LR F1:  0.494\n",
      "For name:  b_barker\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-3439-4517': 21, '0000-0001-6932-479X': 8, '0000-0001-9327-7057': 5, '0000-0001-5732-9550': 1})\n",
      "['0000-0002-3439-4517']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  a_wright\n",
      "total sample size before apply threshold:  149\n",
      "Counter({'0000-0002-2369-0601': 67, '0000-0002-3172-5253': 31, '0000-0002-4866-5699': 21, '0000-0002-8718-8143': 13, '0000-0002-0373-5219': 11, '0000-0003-0721-7854': 4, '0000-0001-6442-5583': 1, '0000-0001-8428-890X': 1})\n",
      "['0000-0002-2369-0601', '0000-0002-8718-8143', '0000-0002-4866-5699', '0000-0002-3172-5253', '0000-0002-0373-5219']\n",
      "Total sample size after apply threshold:  143\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(143, 358)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      1.00      0.81        67\n",
      "          1       1.00      0.31      0.47        13\n",
      "          2       1.00      0.81      0.89        21\n",
      "          3       0.96      0.74      0.84        31\n",
      "          4       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.77      0.78      0.74       143\n",
      "\n",
      "[67  0  0  0  0  8  4  0  1  0  4  0 17  0  0  8  0  0 23  0 11  0  0  0\n",
      "  0]\n",
      "MNB Accuracy:  0.7762237762237763\n",
      "MNB F1:  0.6027619851768459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        67\n",
      "          1       1.00      0.38      0.56        13\n",
      "          2       1.00      0.81      0.89        21\n",
      "          3       0.89      0.81      0.85        31\n",
      "          4       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.88      0.85      0.84       143\n",
      "\n",
      "[67  0  0  0  0  7  5  0  1  0  2  0 17  2  0  6  0  0 25  0  3  0  0  0\n",
      "  8]\n",
      "svc Accuracy:  0.8531468531468531\n",
      "svc F1:  0.8042868470611557\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      1.00      0.80        67\n",
      "          1       1.00      0.31      0.47        13\n",
      "          2       1.00      0.81      0.89        21\n",
      "          3       0.95      0.65      0.77        31\n",
      "          4       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.76      0.76      0.71       143\n",
      "\n",
      "[67  0  0  0  0  8  4  0  1  0  4  0 17  0  0 11  0  0 20  0 11  0  0  0\n",
      "  0]\n",
      "LR Accuracy:  0.7552447552447552\n",
      "LR F1:  0.5864349788498395\n",
      "For name:  z_ma\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0002-5426-0997': 36, '0000-0002-2391-4943': 18, '0000-0002-4429-5213': 15, '0000-0003-1186-9396': 12, '0000-0003-0257-5695': 11, '0000-0002-1629-7764': 9, '0000-0002-3164-6117': 5, '0000-0002-7276-2229': 4, '0000-0002-7120-9106': 1})\n",
      "['0000-0002-5426-0997', '0000-0002-4429-5213', '0000-0002-2391-4943', '0000-0003-0257-5695', '0000-0003-1186-9396']\n",
      "Total sample size after apply threshold:  92\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(92, 145)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "92\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      1.00      0.77        36\n",
      "          1       1.00      0.80      0.89        15\n",
      "          2       1.00      0.56      0.71        18\n",
      "          3       1.00      0.36      0.53        11\n",
      "          4       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.85      0.76      0.75        92\n",
      "\n",
      "[36  0  0  0  0  3 12  0  0  0  8  0 10  0  0  7  0  0  4  0  4  0  0  0\n",
      "  8]\n",
      "MNB Accuracy:  0.7608695652173914\n",
      "MNB F1:  0.7404930766632895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        36\n",
      "          1       1.00      0.87      0.93        15\n",
      "          2       1.00      0.94      0.97        18\n",
      "          3       1.00      0.73      0.84        11\n",
      "          4       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.93      0.91      0.91        92\n",
      "\n",
      "[36  0  0  0  0  2 13  0  0  0  1  0 17  0  0  3  0  0  8  0  2  0  0  0\n",
      " 10]\n",
      "svc Accuracy:  0.9130434782608695\n",
      "svc F1:  0.9102392344497607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      1.00      0.81        36\n",
      "          1       1.00      0.87      0.93        15\n",
      "          2       1.00      0.72      0.84        18\n",
      "          3       1.00      0.45      0.62        11\n",
      "          4       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.87      0.82      0.81        92\n",
      "\n",
      "[36  0  0  0  0  2 13  0  0  0  5  0 13  0  0  6  0  0  5  0  4  0  0  0\n",
      "  8]\n",
      "LR Accuracy:  0.8152173913043478\n",
      "LR F1:  0.8002539740071454\n",
      "For name:  s_bose\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0001-7310-9881': 16, '0000-0003-2397-4740': 6, '0000-0002-6569-4643': 5, '0000-0003-0137-4322': 1})\n",
      "['0000-0001-7310-9881']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  j_dyer\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-7220-6062': 44, '0000-0002-3275-8612': 13, '0000-0002-7570-9941': 3, '0000-0001-6215-0053': 1})\n",
      "['0000-0002-3275-8612', '0000-0002-7220-6062']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 134)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.98      1.00      0.99        44\n",
      "\n",
      "avg / total       0.98      0.98      0.98        57\n",
      "\n",
      "[12  1  0 44]\n",
      "MNB Accuracy:  0.9824561403508771\n",
      "MNB F1:  0.9743820224719102\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.98      1.00      0.99        44\n",
      "\n",
      "avg / total       0.98      0.98      0.98        57\n",
      "\n",
      "[12  1  0 44]\n",
      "svc Accuracy:  0.9824561403508771\n",
      "svc F1:  0.9743820224719102\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        13\n",
      "          1       0.80      1.00      0.89        44\n",
      "\n",
      "avg / total       0.85      0.81      0.75        57\n",
      "\n",
      "[ 2 11  0 44]\n",
      "LR Accuracy:  0.8070175438596491\n",
      "LR F1:  0.5777777777777778\n",
      "For name:  f_blanco\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0003-2545-4319': 55, '0000-0003-4332-434X': 38, '0000-0002-9929-6707': 16, '0000-0002-8380-8472': 14, '0000-0003-1283-8313': 5})\n",
      "['0000-0003-4332-434X', '0000-0002-8380-8472', '0000-0002-9929-6707', '0000-0003-2545-4319']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 123\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(123, 1030)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        38\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       1.00      0.19      0.32        16\n",
      "          3       0.74      1.00      0.85        55\n",
      "\n",
      "avg / total       0.89      0.85      0.82       123\n",
      "\n",
      "[36  0  0  2  0 10  0  4  0  0  3 13  0  0  0 55]\n",
      "MNB Accuracy:  0.8455284552845529\n",
      "MNB F1:  0.7437022395712727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        38\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       1.00      0.69      0.81        16\n",
      "          3       0.86      1.00      0.92        55\n",
      "\n",
      "avg / total       0.94      0.93      0.92       123\n",
      "\n",
      "[36  0  0  2  0 12  0  2  0  0 11  5  0  0  0 55]\n",
      "svc Accuracy:  0.926829268292683\n",
      "svc F1:  0.9088086146909677\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        38\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       1.00      0.19      0.32        16\n",
      "          3       0.74      1.00      0.85        55\n",
      "\n",
      "avg / total       0.89      0.85      0.82       123\n",
      "\n",
      "[36  0  0  2  0 10  0  4  0  0  3 13  0  0  0 55]\n",
      "LR Accuracy:  0.8455284552845529\n",
      "LR F1:  0.7437022395712727\n",
      "For name:  s_ferreira\n",
      "total sample size before apply threshold:  70\n",
      "Counter({'0000-0001-7159-2769': 20, '0000-0001-8308-2862': 17, '0000-0001-7486-5056': 10, '0000-0001-6475-5742': 6, '0000-0001-8174-0200': 6, '0000-0002-9969-2507': 2, '0000-0002-2519-8979': 2, '0000-0002-9209-7772': 2, '0000-0001-7469-3186': 2, '0000-0001-7698-6599': 2, '0000-0002-3527-1623': 1})\n",
      "['0000-0001-8308-2862', '0000-0001-7486-5056', '0000-0001-7159-2769']\n",
      "Total sample size after apply threshold:  47\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 93)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        17\n",
      "          1       1.00      0.20      0.33        10\n",
      "          2       0.77      1.00      0.87        20\n",
      "\n",
      "avg / total       0.86      0.83      0.78        47\n",
      "\n",
      "[17  0  0  2  2  6  0  0 20]\n",
      "MNB Accuracy:  0.8297872340425532\n",
      "MNB F1:  0.7157809983896941\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        17\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       0.91      1.00      0.95        20\n",
      "\n",
      "avg / total       0.96      0.96      0.96        47\n",
      "\n",
      "[15  0  2  0 10  0  0  0 20]\n",
      "svc Accuracy:  0.9574468085106383\n",
      "svc F1:  0.9632936507936508\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        17\n",
      "          1       1.00      0.40      0.57        10\n",
      "          2       0.74      1.00      0.85        20\n",
      "\n",
      "avg / total       0.89      0.85      0.83        47\n",
      "\n",
      "[16  0  1  0  4  6  0  0 20]\n",
      "LR Accuracy:  0.851063829787234\n",
      "LR F1:  0.7973964569709251\n",
      "For name:  j_ren\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0002-7978-8093': 38, '0000-0002-4161-1292': 30, '0000-0003-2806-7226': 17, '0000-0001-6116-3194': 6, '0000-0001-7461-0491': 6, '0000-0003-2711-2048': 4, '0000-0002-6905-2824': 1})\n",
      "['0000-0002-7978-8093', '0000-0003-2806-7226', '0000-0002-4161-1292']\n",
      "Total sample size after apply threshold:  85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 80)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.84        38\n",
      "          1       0.80      0.24      0.36        17\n",
      "          2       0.96      0.90      0.93        30\n",
      "\n",
      "avg / total       0.83      0.81      0.78        85\n",
      "\n",
      "[38  0  0 12  4  1  2  1 27]\n",
      "MNB Accuracy:  0.8117647058823529\n",
      "MNB F1:  0.7130384302798095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89        38\n",
      "          1       0.85      0.65      0.73        17\n",
      "          2       0.93      0.90      0.92        30\n",
      "\n",
      "avg / total       0.87      0.87      0.87        85\n",
      "\n",
      "[36  1  1  5 11  1  2  1 27]\n",
      "svc Accuracy:  0.8705882352941177\n",
      "svc F1:  0.8458254865034526\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        38\n",
      "          1       1.00      0.35      0.52        17\n",
      "          2       0.90      0.93      0.92        30\n",
      "\n",
      "avg / total       0.87      0.85      0.82        85\n",
      "\n",
      "[38  0  0  8  6  3  2  0 28]\n",
      "LR Accuracy:  0.8470588235294118\n",
      "LR F1:  0.7744976158508622\n",
      "For name:  j_muller\n",
      "total sample size before apply threshold:  113\n",
      "Counter({'0000-0001-6009-7471': 58, '0000-0002-7682-559X': 42, '0000-0002-1046-2968': 12, '0000-0002-0855-3852': 1})\n",
      "['0000-0002-7682-559X', '0000-0002-1046-2968', '0000-0001-6009-7471']\n",
      "Total sample size after apply threshold:  112\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(112, 775)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        42\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.76      1.00      0.87        58\n",
      "\n",
      "avg / total       0.77      0.84      0.79       112\n",
      "\n",
      "[36  0  6  0  0 12  0  0 58]\n",
      "MNB Accuracy:  0.8392857142857143\n",
      "MNB F1:  0.596249521622656\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        42\n",
      "          1       1.00      0.33      0.50        12\n",
      "          2       0.87      1.00      0.93        58\n",
      "\n",
      "avg / total       0.93      0.92      0.90       112\n",
      "\n",
      "[41  0  1  0  4  8  0  0 58]\n",
      "svc Accuracy:  0.9196428571428571\n",
      "svc F1:  0.8053172690763052\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        42\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.77      1.00      0.87        58\n",
      "\n",
      "avg / total       0.78      0.85      0.80       112\n",
      "\n",
      "[37  0  5  0  0 12  0  0 58]\n",
      "LR Accuracy:  0.8482142857142857\n",
      "LR F1:  0.6029631039624377\n",
      "For name:  h_tanaka\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-4378-5747': 21, '0000-0003-1511-8557': 4, '0000-0002-3153-8802': 1, '0000-0002-1760-691X': 1, '0000-0001-8622-7422': 1})\n",
      "['0000-0002-4378-5747']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  j_pierce\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-7107-4766': 24, '0000-0002-2861-0519': 10, '0000-0002-4241-838X': 3, '0000-0002-4241-993X': 1, '0000-0002-2558-8184': 1})\n",
      "['0000-0002-7107-4766', '0000-0002-2861-0519']\n",
      "Total sample size after apply threshold:  34\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 51)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        24\n",
      "          1       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.90      0.88      0.87        34\n",
      "\n",
      "[24  0  4  6]\n",
      "MNB Accuracy:  0.8823529411764706\n",
      "MNB F1:  0.8365384615384615\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        24\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        34\n",
      "\n",
      "[24  0  1  9]\n",
      "svc Accuracy:  0.9705882352941176\n",
      "svc F1:  0.9634801288936627\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        24\n",
      "          1       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.90      0.88      0.87        34\n",
      "\n",
      "[24  0  4  6]\n",
      "LR Accuracy:  0.8823529411764706\n",
      "LR F1:  0.8365384615384615\n",
      "For name:  j_guerrero\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0001-6729-585X': 10, '0000-0001-5209-2267': 2, '0000-0001-5236-4592': 2, '0000-0003-1442-9302': 1})\n",
      "['0000-0001-6729-585X']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  r_coelho\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0001-5790-8616': 12, '0000-0002-1127-1661': 7, '0000-0002-9340-3612': 4, '0000-0003-3813-5157': 3})\n",
      "['0000-0001-5790-8616']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  a_masi\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-0361-0950': 20, '0000-0002-7163-3978': 17, '0000-0001-9822-9767': 1, '0000-0002-9695-6634': 1})\n",
      "['0000-0002-0361-0950', '0000-0002-7163-3978']\n",
      "Total sample size after apply threshold:  37\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 182)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        20\n",
      "          1       1.00      1.00      1.00        17\n",
      "\n",
      "avg / total       1.00      1.00      1.00        37\n",
      "\n",
      "[20  0  0 17]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        20\n",
      "          1       1.00      1.00      1.00        17\n",
      "\n",
      "avg / total       1.00      1.00      1.00        37\n",
      "\n",
      "[20  0  0 17]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        20\n",
      "          1       1.00      0.94      0.97        17\n",
      "\n",
      "avg / total       0.97      0.97      0.97        37\n",
      "\n",
      "[20  0  1 16]\n",
      "LR Accuracy:  0.972972972972973\n",
      "LR F1:  0.9726533628972653\n",
      "For name:  b_jackson\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-4917-1199': 14, '0000-0001-6313-0812': 10, '0000-0002-7127-1735': 4, '0000-0001-6405-8111': 1})\n",
      "['0000-0001-6313-0812', '0000-0002-4917-1199']\n",
      "Total sample size after apply threshold:  24\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 70)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "24\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.78      1.00      0.88        14\n",
      "\n",
      "avg / total       0.87      0.83      0.82        24\n",
      "\n",
      "[ 6  4  0 14]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.8125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.88      1.00      0.93        14\n",
      "\n",
      "avg / total       0.93      0.92      0.91        24\n",
      "\n",
      "[ 8  2  0 14]\n",
      "svc Accuracy:  0.9166666666666666\n",
      "svc F1:  0.9111111111111112\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.74      1.00      0.85        14\n",
      "\n",
      "avg / total       0.85      0.79      0.77        24\n",
      "\n",
      "[ 5  5  0 14]\n",
      "LR Accuracy:  0.7916666666666666\n",
      "LR F1:  0.7575757575757576\n",
      "For name:  a_jha\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-8061-5085': 11, '0000-0001-9185-2249': 10, '0000-0002-6305-0721': 9, '0000-0002-6852-1641': 8, '0000-0001-9660-4308': 1})\n",
      "['0000-0001-9185-2249', '0000-0002-8061-5085']\n",
      "Total sample size after apply threshold:  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 37)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "21\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.96      0.95      0.95        21\n",
      "\n",
      "[ 9  1  0 11]\n",
      "MNB Accuracy:  0.9523809523809523\n",
      "MNB F1:  0.9519450800915332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.85      1.00      0.92        11\n",
      "\n",
      "avg / total       0.92      0.90      0.90        21\n",
      "\n",
      "[ 8  2  0 11]\n",
      "svc Accuracy:  0.9047619047619048\n",
      "svc F1:  0.9027777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.85      1.00      0.92        11\n",
      "\n",
      "avg / total       0.92      0.90      0.90        21\n",
      "\n",
      "[ 8  2  0 11]\n",
      "LR Accuracy:  0.9047619047619048\n",
      "LR F1:  0.9027777777777778\n",
      "For name:  m_mosquera\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0003-2248-3050': 25, '0000-0002-5528-0535': 17, '0000-0003-4823-6154': 12, '0000-0002-4632-0195': 6})\n",
      "['0000-0003-4823-6154', '0000-0003-2248-3050', '0000-0002-5528-0535']\n",
      "Total sample size after apply threshold:  54\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 188)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       0.83      0.96      0.89        25\n",
      "          2       0.94      0.88      0.91        17\n",
      "\n",
      "avg / total       0.90      0.89      0.89        54\n",
      "\n",
      "[ 9  3  0  0 24  1  0  2 15]\n",
      "MNB Accuracy:  0.8888888888888888\n",
      "MNB F1:  0.8850408850408851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       0.78      1.00      0.88        25\n",
      "          2       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.90      0.87      0.87        54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 8  4  0  0 25  0  0  3 14]\n",
      "svc Accuracy:  0.8703703703703703\n",
      "svc F1:  0.8601395963025844\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.68      1.00      0.81        25\n",
      "          2       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.85      0.78      0.76        54\n",
      "\n",
      "[ 4  8  0  0 25  0  0  4 13]\n",
      "LR Accuracy:  0.7777777777777778\n",
      "LR F1:  0.7243727598566307\n",
      "For name:  a_silva\n",
      "total sample size before apply threshold:  786\n",
      "Counter({'0000-0003-2861-8286': 158, '0000-0001-5525-0494': 156, '0000-0002-8984-8600': 74, '0000-0001-5790-5116': 41, '0000-0002-7524-9914': 39, '0000-0002-7802-8690': 39, '0000-0003-4968-5138': 30, '0000-0002-7713-1813': 22, '0000-0002-9968-3707': 18, '0000-0002-6332-5182': 16, '0000-0002-5668-7134': 16, '0000-0001-5554-7714': 14, '0000-0002-4839-8279': 14, '0000-0002-1112-1209': 11, '0000-0003-0423-2514': 10, '0000-0002-4386-5851': 10, '0000-0002-9679-8357': 10, '0000-0003-3786-2889': 10, '0000-0002-1673-2164': 10, '0000-0001-7604-792X': 8, '0000-0002-1840-1473': 8, '0000-0003-0393-1655': 7, '0000-0003-4212-5955': 7, '0000-0002-0067-0288': 5, '0000-0002-0634-0546': 5, '0000-0003-2002-4774': 4, '0000-0001-5470-9523': 4, '0000-0002-4364-4979': 4, '0000-0002-5388-1732': 3, '0000-0001-5203-5908': 3, '0000-0001-7231-7021': 3, '0000-0002-5334-0047': 3, '0000-0002-1718-0744': 2, '0000-0003-0384-4447': 2, '0000-0002-2100-7223': 2, '0000-0003-4504-0607': 2, '0000-0003-3576-9023': 2, '0000-0002-3403-5792': 2, '0000-0003-2092-801X': 1, '0000-0002-9595-0038': 1, '0000-0003-4734-6538': 1, '0000-0001-6365-1407': 1, '0000-0002-5842-643X': 1, '0000-0002-8363-0109': 1, '0000-0002-7029-1048': 1, '0000-0002-4904-7470': 1, '0000-0002-3254-2598': 1, '0000-0002-5957-2711': 1, '0000-0002-1724-7777': 1, '0000-0001-6939-8430': 1})\n",
      "['0000-0002-7524-9914', '0000-0002-9968-3707', '0000-0001-5554-7714', '0000-0003-0423-2514', '0000-0002-4386-5851', '0000-0002-9679-8357', '0000-0001-5525-0494', '0000-0003-2861-8286', '0000-0002-8984-8600', '0000-0002-7713-1813', '0000-0003-3786-2889', '0000-0002-1673-2164', '0000-0002-6332-5182', '0000-0003-4968-5138', '0000-0001-5790-5116', '0000-0002-7802-8690', '0000-0002-4839-8279', '0000-0002-1112-1209', '0000-0002-5668-7134']\n",
      "Total sample size after apply threshold:  698\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(698, 1345)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "698\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.49      0.66        39\n",
      "          1       1.00      0.11      0.20        18\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.64      0.94      0.76       156\n",
      "          7       0.47      0.99      0.64       158\n",
      "          8       0.99      0.93      0.96        74\n",
      "          9       1.00      0.23      0.37        22\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       0.00      0.00      0.00        10\n",
      "         12       0.00      0.00      0.00        16\n",
      "         13       1.00      0.27      0.42        30\n",
      "         14       0.83      0.24      0.38        41\n",
      "         15       1.00      0.51      0.68        39\n",
      "         16       0.00      0.00      0.00        14\n",
      "         17       0.00      0.00      0.00        11\n",
      "         18       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.61      0.62      0.55       698\n",
      "\n",
      "[ 19   0   0   0   0   0   2  18   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   2   0   0   0   0  12   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   2  12   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   4   6   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 147   7   0   0   0   0\n",
      "   0   0   2   0   0   0   0   0   0   0   0   0   0   2 156   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5  69   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5  12   0\n",
      "   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   8\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   5  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   3  19   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0\n",
      "   0   0  13  18   0   0   0   0   0   0  10   0   0   0   0   0   0   0\n",
      "   0   0   0   0  18   1   0   0   0   0   0   0  20   0   0   0   0   0\n",
      "   0   0   0   0   4  10   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  14   2   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "MNB Accuracy:  0.6246418338108882\n",
      "MNB F1:  0.2662094775596462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        39\n",
      "          1       1.00      0.50      0.67        18\n",
      "          2       0.83      0.36      0.50        14\n",
      "          3       1.00      0.70      0.82        10\n",
      "          4       0.88      0.70      0.78        10\n",
      "          5       1.00      0.70      0.82        10\n",
      "          6       0.66      0.96      0.78       156\n",
      "          7       0.75      0.94      0.83       158\n",
      "          8       1.00      0.92      0.96        74\n",
      "          9       1.00      0.82      0.90        22\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       1.00      0.10      0.18        10\n",
      "         12       1.00      0.62      0.77        16\n",
      "         13       1.00      0.73      0.85        30\n",
      "         14       0.83      0.59      0.69        41\n",
      "         15       1.00      0.87      0.93        39\n",
      "         16       1.00      0.64      0.78        14\n",
      "         17       1.00      0.64      0.78        11\n",
      "         18       1.00      0.44      0.61        16\n",
      "\n",
      "avg / total       0.84      0.81      0.79       698\n",
      "\n",
      "[ 30   0   0   0   0   0   4   5   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   9   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   5   0   0   0   2   7   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   7   0   0   1   2   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   7   0   0   3   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   7   3   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   1   0 149   1   0   0   0   0\n",
      "   0   0   5   0   0   0   0   0   0   1   0   0   0   8 149   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4  68   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   0\n",
      "  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   6\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4\n",
      "   5   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   3   3   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   5   3   0   0   0   0   0  22   0   0   0   0   0   0   0   0   0\n",
      "   0   0  12   5   0   0   0   0   0   0  24   0   0   0   0   0   0   0\n",
      "   0   0   0   2   3   0   0   0   0   0   0   0  34   0   0   0   0   0\n",
      "   0   0   0   0   2   3   0   0   0   0   0   0   0   0   9   0   0   0\n",
      "   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   7   0\n",
      "   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0\n",
      "   7]\n",
      "svc Accuracy:  0.8065902578796562\n",
      "svc F1:  0.7113222526710175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        39\n",
      "          1       1.00      0.28      0.43        18\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       1.00      0.40      0.57        10\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.53      0.96      0.68       156\n",
      "          7       0.63      0.92      0.75       158\n",
      "          8       1.00      0.88      0.94        74\n",
      "          9       1.00      0.23      0.37        22\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       0.00      0.00      0.00        10\n",
      "         12       1.00      0.06      0.12        16\n",
      "         13       1.00      0.63      0.78        30\n",
      "         14       0.78      0.34      0.47        41\n",
      "         15       1.00      0.79      0.89        39\n",
      "         16       1.00      0.36      0.53        14\n",
      "         17       1.00      0.55      0.71        11\n",
      "         18       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.70      0.68      0.63       698\n",
      "\n",
      "[ 25   0   0   0   0   0   4  10   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   5   0   0   0   0  13   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   4  10   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   4   0   0   2   4   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   5   5   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   6   4   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 150   2   0   0   0   0\n",
      "   0   0   4   0   0   0   0   0   0   0   0   0   0  12 146   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   5  65   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  11   6   0\n",
      "   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   6\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4\n",
      "   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  11   4   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   7   4   0   0   0   0   0  19   0   0   0   0   0   0   0   0   0\n",
      "   0   0  19   8   0   0   0   0   0   0  14   0   0   0   0   0   0   0\n",
      "   0   0   0   3   5   0   0   0   0   0   0   0  31   0   0   0   0   0\n",
      "   0   0   0   0   3   6   0   0   0   0   0   0   0   0   5   0   0   0\n",
      "   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   6   0\n",
      "   0   0   0   0   0   0  16   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "LR Accuracy:  0.6819484240687679\n",
      "LR F1:  0.4217233306949375\n",
      "For name:  m_guerra\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0001-6286-4048': 8, '0000-0003-1970-7439': 4, '0000-0002-3655-9004': 3, '0000-0003-3863-8520': 3})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_suzuki\n",
      "total sample size before apply threshold:  82\n",
      "Counter({'0000-0003-4682-5086': 39, '0000-0002-8150-140X': 15, '0000-0003-4600-2506': 14, '0000-0002-8555-5448': 9, '0000-0001-5371-6385': 5})\n",
      "['0000-0003-4682-5086', '0000-0003-4600-2506', '0000-0002-8150-140X']\n",
      "Total sample size after apply threshold:  68\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(68, 199)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.97      0.86        39\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       0.92      0.80      0.86        15\n",
      "\n",
      "avg / total       0.85      0.82      0.81        68\n",
      "\n",
      "[38  0  1  8  6  0  3  0 12]\n",
      "MNB Accuracy:  0.8235294117647058\n",
      "MNB F1:  0.7735930735930735\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        39\n",
      "          1       1.00      0.79      0.88        14\n",
      "          2       1.00      0.87      0.93        15\n",
      "\n",
      "avg / total       0.93      0.93      0.92        68\n",
      "\n",
      "[39  0  0  3 11  0  2  0 13]\n",
      "svc Accuracy:  0.9264705882352942\n",
      "svc F1:  0.9161101549053358\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84        39\n",
      "          1       1.00      0.29      0.44        14\n",
      "          2       1.00      0.67      0.80        15\n",
      "\n",
      "avg / total       0.84      0.78      0.75        68\n",
      "\n",
      "[39  0  0 10  4  0  5  0 10]\n",
      "LR Accuracy:  0.7794117647058824\n",
      "LR F1:  0.6943847072879331\n",
      "For name:  m_cohen\n",
      "total sample size before apply threshold:  251\n",
      "Counter({'0000-0003-2038-6070': 103, '0000-0002-1879-3593': 69, '0000-0002-6090-2394': 46, '0000-0001-6731-4053': 13, '0000-0003-3183-2558': 8, '0000-0002-1548-2773': 4, '0000-0001-6362-6148': 4, '0000-0002-5876-6565': 3, '0000-0002-1372-680X': 1})\n",
      "['0000-0001-6731-4053', '0000-0003-2038-6070', '0000-0002-6090-2394', '0000-0002-1879-3593']\n",
      "Total sample size after apply threshold:  231\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(231, 865)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "231\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.74      0.97      0.84       103\n",
      "          2       0.97      0.65      0.78        46\n",
      "          3       0.89      0.84      0.87        69\n",
      "\n",
      "avg / total       0.79      0.81      0.79       231\n",
      "\n",
      "[  0  12   0   1   0 100   1   2   0  12  30   4   0  11   0  58]\n",
      "MNB Accuracy:  0.8138528138528138\n",
      "MNB F1:  0.6213071388664013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.73      0.99      0.84       103\n",
      "          2       0.97      0.72      0.82        46\n",
      "          3       1.00      0.83      0.90        69\n",
      "\n",
      "avg / total       0.82      0.83      0.81       231\n",
      "\n",
      "[  0  13   0   0   0 102   1   0   0  13  33   0   0  12   0  57]\n",
      "svc Accuracy:  0.8311688311688312\n",
      "svc F1:  0.6423170194003527\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.67      1.00      0.80       103\n",
      "          2       1.00      0.54      0.70        46\n",
      "          3       1.00      0.77      0.87        69\n",
      "\n",
      "avg / total       0.80      0.78      0.76       231\n",
      "\n",
      "[  0  13   0   0   0 103   0   0   0  21  25   0   0  16   0  53]\n",
      "LR Accuracy:  0.7835497835497836\n",
      "LR F1:  0.5944413277822673\n",
      "For name:  m_kobayashi\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-6657-1928': 33, '0000-0003-0219-9108': 9, '0000-0002-6554-8400': 4, '0000-0001-8116-0505': 2, '0000-0002-4001-3581': 2, '0000-0001-6539-7326': 1})\n",
      "['0000-0002-6657-1928']\n",
      "Total sample size after apply threshold:  33\n",
      "For name:  s_wright\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0001-9973-9697': 44, '0000-0002-8593-6056': 10, '0000-0002-1502-131X': 5, '0000-0003-1034-8054': 2})\n",
      "['0000-0001-9973-9697', '0000-0002-8593-6056']\n",
      "Total sample size after apply threshold:  54\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 208)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        44\n",
      "          1       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.96      0.96      0.96        54\n",
      "\n",
      "[44  0  2  8]\n",
      "MNB Accuracy:  0.9629629629629629\n",
      "MNB F1:  0.9333333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        44\n",
      "          1       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        54\n",
      "\n",
      "[44  0  0 10]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90        44\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.66      0.81      0.73        54\n",
      "\n",
      "[44  0 10  0]\n",
      "LR Accuracy:  0.8148148148148148\n",
      "LR F1:  0.44897959183673464\n",
      "For name:  a_mills\n",
      "total sample size before apply threshold:  169\n",
      "Counter({'0000-0001-9863-9950': 115, '0000-0003-4880-7332': 34, '0000-0002-6997-5581': 15, '0000-0002-6893-3857': 3, '0000-0003-4932-8413': 1, '0000-0002-9065-0458': 1})\n",
      "['0000-0001-9863-9950', '0000-0002-6997-5581', '0000-0003-4880-7332']\n",
      "Total sample size after apply threshold:  164\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(164, 555)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "164\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       115\n",
      "          1       1.00      0.20      0.33        15\n",
      "          2       1.00      0.44      0.61        34\n",
      "\n",
      "avg / total       0.85      0.81      0.78       164\n",
      "\n",
      "[115   0   0  12   3   0  19   0  15]\n",
      "MNB Accuracy:  0.8109756097560976\n",
      "MNB F1:  0.6089347616441213\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       115\n",
      "          1       1.00      0.40      0.57        15\n",
      "          2       1.00      0.65      0.79        34\n",
      "\n",
      "avg / total       0.89      0.87      0.86       164\n",
      "\n",
      "[115   0   0   9   6   0  12   0  22]\n",
      "svc Accuracy:  0.8719512195121951\n",
      "svc F1:  0.7578258394991463\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83       115\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       1.00      0.06      0.11        34\n",
      "\n",
      "avg / total       0.71      0.71      0.61       164\n",
      "\n",
      "[115   0   0  15   0   0  32   0   2]\n",
      "LR Accuracy:  0.7134146341463414\n",
      "LR F1:  0.3138120069528012\n",
      "For name:  c_west\n",
      "total sample size before apply threshold:  181\n",
      "Counter({'0000-0002-0839-3449': 155, '0000-0001-7595-6777': 20, '0000-0001-7649-9600': 3, '0000-0002-1149-3723': 2, '0000-0002-3799-4462': 1})\n",
      "['0000-0002-0839-3449', '0000-0001-7595-6777']\n",
      "Total sample size after apply threshold:  175\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 515)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       155\n",
      "          1       1.00      0.35      0.52        20\n",
      "\n",
      "avg / total       0.93      0.93      0.91       175\n",
      "\n",
      "[155   0  13   7]\n",
      "MNB Accuracy:  0.9257142857142857\n",
      "MNB F1:  0.7391354202499714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98       155\n",
      "          1       1.00      0.75      0.86        20\n",
      "\n",
      "avg / total       0.97      0.97      0.97       175\n",
      "\n",
      "[155   0   5  15]\n",
      "svc Accuracy:  0.9714285714285714\n",
      "svc F1:  0.9206349206349206\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       155\n",
      "          1       1.00      0.10      0.18        20\n",
      "\n",
      "avg / total       0.91      0.90      0.86       175\n",
      "\n",
      "[155   0  18   2]\n",
      "LR Accuracy:  0.8971428571428571\n",
      "LR F1:  0.563470066518847\n",
      "For name:  a_marino\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0002-1709-538X': 7, '0000-0002-0528-4925': 6, '0000-0003-0308-859X': 1, '0000-0001-8751-8811': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_jiang\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0002-8280-6029': 54, '0000-0002-7533-3753': 28, '0000-0002-3816-4639': 19, '0000-0001-5857-8540': 1})\n",
      "['0000-0002-8280-6029', '0000-0002-3816-4639', '0000-0002-7533-3753']\n",
      "Total sample size after apply threshold:  101\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 239)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "101\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      1.00      0.82        54\n",
      "          1       1.00      0.32      0.48        19\n",
      "          2       0.88      0.54      0.67        28\n",
      "\n",
      "avg / total       0.80      0.74      0.71       101\n",
      "\n",
      "[54  0  0 11  6  2 13  0 15]\n",
      "MNB Accuracy:  0.7425742574257426\n",
      "MNB F1:  0.654949494949495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.95        54\n",
      "          1       0.93      0.74      0.82        19\n",
      "          2       0.84      0.93      0.88        28\n",
      "\n",
      "avg / total       0.91      0.91      0.91       101\n",
      "\n",
      "[52  0  2  2 14  3  1  1 26]\n",
      "svc Accuracy:  0.9108910891089109\n",
      "svc F1:  0.8863379281116893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92        54\n",
      "          1       0.92      0.58      0.71        19\n",
      "          2       0.92      0.82      0.87        28\n",
      "\n",
      "avg / total       0.88      0.87      0.86       101\n",
      "\n",
      "[54  0  0  6 11  2  4  1 23]\n",
      "LR Accuracy:  0.8712871287128713\n",
      "LR F1:  0.8309520616482869\n",
      "For name:  t_becker\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0002-4117-8249': 12, '0000-0002-5656-4564': 5, '0000-0003-3432-783X': 3, '0000-0002-5193-4044': 1})\n",
      "['0000-0002-4117-8249']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  s_pedersen\n",
      "total sample size before apply threshold:  322\n",
      "Counter({'0000-0002-7838-8063': 166, '0000-0002-3044-7714': 80, '0000-0002-6500-9263': 40, '0000-0002-4786-6464': 21, '0000-0001-8055-3251': 11, '0000-0002-8566-7693': 1, '0000-0002-4355-1764': 1, '0000-0002-3822-5075': 1, '0000-0001-8017-4227': 1})\n",
      "['0000-0002-7838-8063', '0000-0002-3044-7714', '0000-0002-4786-6464', '0000-0001-8055-3251', '0000-0002-6500-9263']\n",
      "Total sample size after apply threshold:  318\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(318, 547)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "318\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       166\n",
      "          1       0.97      0.93      0.95        80\n",
      "          2       1.00      0.57      0.73        21\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.85      0.92        40\n",
      "\n",
      "avg / total       0.88      0.90      0.88       318\n",
      "\n",
      "[166   0   0   0   0   6  74   0   0   0   9   0  12   0   0  11   0   0\n",
      "   0   0   4   2   0   0  34]\n",
      "MNB Accuracy:  0.89937106918239\n",
      "MNB F1:  0.7024073333465599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.98       166\n",
      "          1       0.85      0.96      0.90        80\n",
      "          2       1.00      0.62      0.76        21\n",
      "          3       1.00      0.55      0.71        11\n",
      "          4       1.00      0.95      0.97        40\n",
      "\n",
      "avg / total       0.94      0.94      0.93       318\n",
      "\n",
      "[164   2   0   0   0   3  77   0   0   0   1   7  13   0   0   2   3   0\n",
      "   6   0   0   2   0   0  38]\n",
      "svc Accuracy:  0.9371069182389937\n",
      "svc F1:  0.8643444962330411\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       166\n",
      "          1       0.98      0.81      0.89        80\n",
      "          2       1.00      0.57      0.73        21\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.80      0.89        40\n",
      "\n",
      "avg / total       0.86      0.86      0.85       318\n",
      "\n",
      "[166   0   0   0   0  15  65   0   0   0   9   0  12   0   0  11   0   0\n",
      "   0   0   7   1   0   0  32]\n",
      "LR Accuracy:  0.8647798742138365\n",
      "LR F1:  0.6788546219650168\n",
      "For name:  a_ali\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0003-0437-8919': 15, '0000-0002-7224-6654': 11, '0000-0001-7913-8544': 9, '0000-0002-4370-007X': 6, '0000-0003-2444-8400': 6, '0000-0003-0552-7322': 6, '0000-0001-5267-2608': 2, '0000-0001-9966-2917': 1, '0000-0001-9673-0080': 1, '0000-0001-6199-0034': 1, '0000-0002-7864-8240': 1, '0000-0003-3030-3371': 1, '0000-0003-4467-5387': 1, '0000-0002-6554-3378': 1})\n",
      "['0000-0003-0437-8919', '0000-0002-7224-6654']\n",
      "Total sample size after apply threshold:  26\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 46)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        15\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[15  0  1 10]\n",
      "MNB Accuracy:  0.9615384615384616\n",
      "MNB F1:  0.9600614439324117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        15\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[15  0  1 10]\n",
      "svc Accuracy:  0.9615384615384616\n",
      "svc F1:  0.9600614439324117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        15\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15  0  1 10]\n",
      "LR Accuracy:  0.9615384615384616\n",
      "LR F1:  0.9600614439324117\n",
      "For name:  k_jones\n",
      "total sample size before apply threshold:  607\n",
      "Counter({'0000-0001-7108-9776': 331, '0000-0002-0294-0851': 74, '0000-0001-8923-2999': 55, '0000-0001-8398-2190': 32, '0000-0003-4764-7031': 29, '0000-0002-7380-9797': 18, '0000-0001-9136-0877': 15, '0000-0002-7216-2506': 13, '0000-0003-3815-5713': 9, '0000-0002-8819-8992': 6, '0000-0002-7127-1612': 4, '0000-0002-0242-7097': 4, '0000-0002-6916-8640': 4, '0000-0001-5692-653X': 3, '0000-0002-9982-8742': 3, '0000-0002-0478-8021': 2, '0000-0001-9373-0982': 1, '0000-0001-7335-1379': 1, '0000-0001-6553-8897': 1, '0000-0002-1552-7847': 1, '0000-0001-9115-4192': 1})\n",
      "['0000-0002-7380-9797', '0000-0001-8923-2999', '0000-0002-7216-2506', '0000-0003-4764-7031', '0000-0001-7108-9776', '0000-0001-9136-0877', '0000-0002-0294-0851', '0000-0001-8398-2190']\n",
      "Total sample size after apply threshold:  567\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(567, 928)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.22      0.36        18\n",
      "          1       1.00      0.60      0.75        55\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.00      0.00      0.00        29\n",
      "          4       0.72      1.00      0.84       331\n",
      "          5       1.00      0.20      0.33        15\n",
      "          6       0.96      0.73      0.83        74\n",
      "          7       1.00      0.34      0.51        32\n",
      "\n",
      "avg / total       0.76      0.77      0.72       567\n",
      "\n",
      "[  4   0   0   0  14   0   0   0   0  33   0   0  22   0   0   0   0   0\n",
      "   0   0  13   0   0   0   0   0   0   0  28   0   1   0   0   0   0   0\n",
      " 331   0   0   0   0   0   0   0  11   3   1   0   0   0   0   0  20   0\n",
      "  54   0   0   0   0   0  21   0   0  11]\n",
      "MNB Accuracy:  0.7689594356261023\n",
      "MNB F1:  0.453285266475995\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        18\n",
      "          1       1.00      0.73      0.84        55\n",
      "          2       1.00      0.38      0.56        13\n",
      "          3       1.00      0.48      0.65        29\n",
      "          4       0.83      1.00      0.91       331\n",
      "          5       1.00      0.87      0.93        15\n",
      "          6       0.97      0.80      0.87        74\n",
      "          7       1.00      0.66      0.79        32\n",
      "\n",
      "avg / total       0.90      0.88      0.87       567\n",
      "\n",
      "[ 16   0   0   0   2   0   0   0   0  40   0   0  15   0   0   0   0   0\n",
      "   5   0   8   0   0   0   0   0   0  14  14   0   1   0   0   0   0   0\n",
      " 330   0   1   0   0   0   0   0   2  13   0   0   0   0   0   0  15   0\n",
      "  59   0   0   0   0   0  11   0   0  21]\n",
      "svc Accuracy:  0.8783068783068783\n",
      "svc F1:  0.8114614774283686\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29        18\n",
      "          1       1.00      0.55      0.71        55\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       1.00      0.10      0.19        29\n",
      "          4       0.70      1.00      0.83       331\n",
      "          5       1.00      0.53      0.70        15\n",
      "          6       1.00      0.58      0.74        74\n",
      "          7       1.00      0.31      0.48        32\n",
      "\n",
      "avg / total       0.80      0.75      0.71       567\n",
      "\n",
      "[  3   0   0   0  15   0   0   0   0  30   0   0  25   0   0   0   0   0\n",
      "   0   0  13   0   0   0   0   0   0   3  26   0   0   0   0   0   0   0\n",
      " 331   0   0   0   0   0   0   0   7   8   0   0   0   0   0   0  31   0\n",
      "  43   0   0   0   0   0  22   0   0  10]\n",
      "LR Accuracy:  0.7548500881834215\n",
      "LR F1:  0.48905611751953426\n",
      "For name:  m_becker\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0001-9890-8815': 32, '0000-0002-9235-0547': 24, '0000-0001-7233-6361': 3, '0000-0003-1187-1699': 3, '0000-0001-6526-1525': 2, '0000-0003-3450-5579': 2, '0000-0002-1751-1056': 1})\n",
      "['0000-0001-9890-8815', '0000-0002-9235-0547']\n",
      "Total sample size after apply threshold:  56\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 240)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        32\n",
      "          1       1.00      0.96      0.98        24\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "[32  0  1 23]\n",
      "MNB Accuracy:  0.9821428571428571\n",
      "MNB F1:  0.9816693944353518\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        32\n",
      "          1       1.00      0.96      0.98        24\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "[32  0  1 23]\n",
      "svc Accuracy:  0.9821428571428571\n",
      "svc F1:  0.9816693944353518\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.96        32\n",
      "          1       1.00      0.88      0.93        24\n",
      "\n",
      "avg / total       0.95      0.95      0.95        56\n",
      "\n",
      "[32  0  3 21]\n",
      "LR Accuracy:  0.9464285714285714\n",
      "LR F1:  0.9442786069651742\n",
      "For name:  c_marshall\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0003-4186-0368': 32, '0000-0002-7571-5700': 29, '0000-0001-5901-2004': 28, '0000-0002-1285-7648': 6, '0000-0002-8227-2354': 6, '0000-0001-6669-3231': 3, '0000-0002-7397-6472': 1, '0000-0002-0592-7716': 1})\n",
      "['0000-0001-5901-2004', '0000-0003-4186-0368', '0000-0002-7571-5700']\n",
      "Total sample size after apply threshold:  89\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 255)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        28\n",
      "          1       0.94      0.97      0.95        32\n",
      "          2       0.97      1.00      0.98        29\n",
      "\n",
      "avg / total       0.97      0.97      0.97        89\n",
      "\n",
      "[26  2  0  0 31  1  0  0 29]\n",
      "MNB Accuracy:  0.9662921348314607\n",
      "MNB F1:  0.9666199880889147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        28\n",
      "          1       0.91      1.00      0.96        32\n",
      "          2       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       0.97      0.97      0.97        89\n",
      "\n",
      "[25  3  0  0 32  0  0  0 29]\n",
      "svc Accuracy:  0.9662921348314607\n",
      "svc F1:  0.9662067023373698\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        28\n",
      "          1       0.86      1.00      0.93        32\n",
      "          2       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       0.95      0.94      0.94        89\n",
      "\n",
      "[23  5  0  0 32  0  0  0 29]\n",
      "LR Accuracy:  0.9438202247191011\n",
      "LR F1:  0.9431656720659278\n",
      "For name:  s_rafiq\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0003-4873-4540': 23, '0000-0002-9295-3065': 9, '0000-0003-4821-5783': 1})\n",
      "['0000-0003-4873-4540']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  h_liang\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0003-0186-3126': 30, '0000-0001-7633-286X': 27, '0000-0002-3430-9167': 15, '0000-0001-9097-7357': 12, '0000-0001-9496-406X': 10, '0000-0001-5523-6799': 3, '0000-0001-9044-0509': 3, '0000-0002-2950-8559': 2, '0000-0003-1779-9552': 1, '0000-0002-9045-9717': 1})\n",
      "['0000-0002-3430-9167', '0000-0001-7633-286X', '0000-0003-0186-3126', '0000-0001-9496-406X', '0000-0001-9097-7357']\n",
      "Total sample size after apply threshold:  94\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 168)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "94\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        15\n",
      "          1       0.74      0.85      0.79        27\n",
      "          2       0.71      1.00      0.83        30\n",
      "          3       1.00      0.50      0.67        10\n",
      "          4       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.83      0.79      0.77        94\n",
      "\n",
      "[ 6  7  2  0  0  0 23  4  0  0  0  0 30  0  0  0  1  4  5  0  0  0  2  0\n",
      " 10]\n",
      "MNB Accuracy:  0.7872340425531915\n",
      "MNB F1:  0.7547245857590685\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.73      0.81        15\n",
      "          1       0.73      1.00      0.84        27\n",
      "          2       0.97      0.97      0.97        30\n",
      "          3       1.00      0.50      0.67        10\n",
      "          4       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.90      0.87      0.87        94\n",
      "\n",
      "[11  4  0  0  0  0 27  0  0  0  0  1 29  0  0  0  5  0  5  0  1  0  1  0\n",
      " 10]\n",
      "svc Accuracy:  0.8723404255319149\n",
      "svc F1:  0.8401978114478114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        15\n",
      "          1       0.70      0.85      0.77        27\n",
      "          2       0.72      0.97      0.83        30\n",
      "          3       1.00      0.50      0.67        10\n",
      "          4       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.83      0.78      0.76        94\n",
      "\n",
      "[ 6  7  2  0  0  0 23  4  0  0  0  1 29  0  0  0  2  3  5  0  0  0  2  0\n",
      " 10]\n",
      "LR Accuracy:  0.776595744680851\n",
      "LR F1:  0.7484848484848485\n",
      "For name:  c_davis\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0002-5045-0507': 34, '0000-0002-3971-3505': 2, '0000-0003-0866-7822': 2, '0000-0002-0024-2742': 2, '0000-0002-3274-5707': 2, '0000-0001-6205-9719': 1})\n",
      "['0000-0002-5045-0507']\n",
      "Total sample size after apply threshold:  34\n",
      "For name:  e_hall\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0001-5999-5020': 49, '0000-0002-5306-082X': 34, '0000-0002-9477-8619': 24, '0000-0002-9206-4436': 4, '0000-0002-2815-6651': 2, '0000-0003-0244-7458': 2})\n",
      "['0000-0001-5999-5020', '0000-0002-9477-8619', '0000-0002-5306-082X']\n",
      "Total sample size after apply threshold:  107\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 514)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.88        49\n",
      "          1       1.00      0.79      0.88        24\n",
      "          2       0.91      0.88      0.90        34\n",
      "\n",
      "avg / total       0.90      0.89      0.89       107\n",
      "\n",
      "[46  0  3  5 19  0  4  0 30]\n",
      "MNB Accuracy:  0.8878504672897196\n",
      "MNB F1:  0.8879529009692148\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        49\n",
      "          1       1.00      0.83      0.91        24\n",
      "          2       1.00      0.88      0.94        34\n",
      "\n",
      "avg / total       0.94      0.93      0.93       107\n",
      "\n",
      "[49  0  0  4 20  0  4  0 30]\n",
      "svc Accuracy:  0.9252336448598131\n",
      "svc F1:  0.9237064036592338\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      1.00      0.81        49\n",
      "          1       1.00      0.46      0.63        24\n",
      "          2       1.00      0.71      0.83        34\n",
      "\n",
      "avg / total       0.85      0.79      0.77       107\n",
      "\n",
      "[49  0  0 13 11  0 10  0 24]\n",
      "LR Accuracy:  0.7850467289719626\n",
      "LR F1:  0.7553583302799604\n",
      "For name:  g_volpe\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-9993-5348': 15, '0000-0001-5057-1846': 14, '0000-0002-3916-5393': 1, '0000-0003-0760-4627': 1})\n",
      "['0000-0001-9993-5348', '0000-0001-5057-1846']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 69)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.87      0.74        15\n",
      "          1       0.78      0.50      0.61        14\n",
      "\n",
      "avg / total       0.71      0.69      0.68        29\n",
      "\n",
      "[13  2  7  7]\n",
      "MNB Accuracy:  0.6896551724137931\n",
      "MNB F1:  0.675776397515528\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.80      0.77        15\n",
      "          1       0.77      0.71      0.74        14\n",
      "\n",
      "avg / total       0.76      0.76      0.76        29\n",
      "\n",
      "[12  3  4 10]\n",
      "svc Accuracy:  0.7586206896551724\n",
      "svc F1:  0.7574671445639188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.73      0.69        15\n",
      "          1       0.67      0.57      0.62        14\n",
      "\n",
      "avg / total       0.66      0.66      0.65        29\n",
      "\n",
      "[11  4  6  8]\n",
      "LR Accuracy:  0.6551724137931034\n",
      "LR F1:  0.6514423076923077\n",
      "For name:  r_lewis\n",
      "total sample size before apply threshold:  427\n",
      "Counter({'0000-0003-3470-923X': 185, '0000-0002-2002-4339': 175, '0000-0003-4044-9104': 41, '0000-0002-4598-7553': 7, '0000-0003-1395-3276': 6, '0000-0003-1859-0021': 4, '0000-0001-9929-2629': 3, '0000-0001-6642-5771': 3, '0000-0002-2680-6235': 1, '0000-0002-6644-6385': 1, '0000-0003-1046-811X': 1})\n",
      "['0000-0002-2002-4339', '0000-0003-3470-923X', '0000-0003-4044-9104']\n",
      "Total sample size after apply threshold:  401\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(401, 900)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97       175\n",
      "          1       0.89      1.00      0.94       185\n",
      "          2       1.00      0.63      0.78        41\n",
      "\n",
      "avg / total       0.95      0.94      0.94       401\n",
      "\n",
      "[167   8   0   0 185   0   1  14  26]\n",
      "MNB Accuracy:  0.942643391521197\n",
      "MNB F1:  0.8979192956500297\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96       175\n",
      "          1       0.88      1.00      0.93       185\n",
      "          2       1.00      0.68      0.81        41\n",
      "\n",
      "avg / total       0.94      0.94      0.93       401\n",
      "\n",
      "[162  13   0   0 185   0   0  13  28]\n",
      "svc Accuracy:  0.9351620947630923\n",
      "svc F1:  0.9024539898620662\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95       175\n",
      "          1       0.83      1.00      0.91       185\n",
      "          2       1.00      0.51      0.68        41\n",
      "\n",
      "avg / total       0.92      0.91      0.90       401\n",
      "\n",
      "[158  17   0   0 185   0   0  20  21]\n",
      "LR Accuracy:  0.9077306733167082\n",
      "LR F1:  0.8451530709595225\n",
      "For name:  c_rodriguez\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0001-6697-1692': 23, '0000-0002-4042-4313': 18, '0000-0003-2289-4239': 1, '0000-0003-3927-6883': 1})\n",
      "['0000-0002-4042-4313', '0000-0001-6697-1692']\n",
      "Total sample size after apply threshold:  41\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 93)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "41\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       1.00      1.00      1.00        23\n",
      "\n",
      "avg / total       1.00      1.00      1.00        41\n",
      "\n",
      "[18  0  0 23]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        18\n",
      "          1       0.96      1.00      0.98        23\n",
      "\n",
      "avg / total       0.98      0.98      0.98        41\n",
      "\n",
      "[17  1  0 23]\n",
      "svc Accuracy:  0.975609756097561\n",
      "svc F1:  0.9750759878419453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        18\n",
      "          1       0.96      1.00      0.98        23\n",
      "\n",
      "avg / total       0.98      0.98      0.98        41\n",
      "\n",
      "[17  1  0 23]\n",
      "LR Accuracy:  0.975609756097561\n",
      "LR F1:  0.9750759878419453\n",
      "For name:  p_hall\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0001-6015-7841': 11, '0000-0001-9218-6233': 9, '0000-0002-4239-4226': 1, '0000-0002-8214-0351': 1})\n",
      "['0000-0001-6015-7841']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  r_srivastava\n",
      "total sample size before apply threshold:  184\n",
      "Counter({'0000-0002-0065-4069': 144, '0000-0003-3112-4252': 22, '0000-0002-6703-9642': 7, '0000-0001-9328-146X': 6, '0000-0002-0165-1556': 3, '0000-0002-9965-851X': 2})\n",
      "['0000-0002-0065-4069', '0000-0003-3112-4252']\n",
      "Total sample size after apply threshold:  166\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(166, 508)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "166\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       144\n",
      "          1       0.00      0.00      0.00        22\n",
      "\n",
      "avg / total       0.75      0.87      0.81       166\n",
      "\n",
      "[144   0  22   0]\n",
      "MNB Accuracy:  0.8674698795180723\n",
      "MNB F1:  0.46451612903225803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       144\n",
      "          1       0.00      0.00      0.00        22\n",
      "\n",
      "avg / total       0.75      0.87      0.81       166\n",
      "\n",
      "[144   0  22   0]\n",
      "svc Accuracy:  0.8674698795180723\n",
      "svc F1:  0.46451612903225803\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       144\n",
      "          1       0.00      0.00      0.00        22\n",
      "\n",
      "avg / total       0.75      0.87      0.81       166\n",
      "\n",
      "[144   0  22   0]\n",
      "LR Accuracy:  0.8674698795180723\n",
      "LR F1:  0.46451612903225803\n",
      "For name:  a_macedo\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-2613-4838': 18, '0000-0003-3436-2010': 8, '0000-0002-6854-9855': 2, '0000-0001-6985-4520': 1})\n",
      "['0000-0002-2613-4838']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  m_schultz\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0003-3458-1811': 16, '0000-0002-7689-6531': 16, '0000-0003-3455-774X': 4, '0000-0001-7967-5147': 4})\n",
      "['0000-0003-3458-1811', '0000-0002-7689-6531']\n",
      "Total sample size after apply threshold:  32\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 161)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.84        16\n",
      "          1       1.00      0.62      0.77        16\n",
      "\n",
      "avg / total       0.86      0.81      0.81        32\n",
      "\n",
      "[16  0  6 10]\n",
      "MNB Accuracy:  0.8125\n",
      "MNB F1:  0.805668016194332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00        32\n",
      "\n",
      "[16  0  0 16]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        16\n",
      "          1       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        32\n",
      "\n",
      "[16  0  1 15]\n",
      "LR Accuracy:  0.96875\n",
      "LR F1:  0.9687194525904204\n",
      "For name:  s_jacobs\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0002-6199-5748': 9, '0000-0002-9959-5627': 8, '0000-0003-4674-4817': 2, '0000-0002-9382-1646': 1, '0000-0002-8103-1700': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_hong\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0002-1058-3073': 23, '0000-0001-7745-9205': 7, '0000-0002-5118-620X': 1, '0000-0002-7397-1671': 1})\n",
      "['0000-0002-1058-3073']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  r_mohan\n",
      "total sample size before apply threshold:  7\n",
      "Counter({'0000-0001-5335-6631': 4, '0000-0002-1857-4200': 1, '0000-0002-2286-7081': 1, '0000-0002-9943-484X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_hill\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0003-0394-6048': 16, '0000-0002-2801-0505': 14, '0000-0002-7601-5802': 13, '0000-0002-4623-1563': 12, '0000-0001-6080-8712': 11, '0000-0001-9577-1622': 9, '0000-0002-1923-5673': 7, '0000-0001-7996-7887': 7, '0000-0001-5533-1139': 1})\n",
      "['0000-0002-2801-0505', '0000-0003-0394-6048', '0000-0001-6080-8712', '0000-0002-7601-5802', '0000-0002-4623-1563']\n",
      "Total sample size after apply threshold:  66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 207)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.56      0.88      0.68        16\n",
      "          2       1.00      0.91      0.95        11\n",
      "          3       0.56      0.38      0.45        13\n",
      "          4       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.81      0.77      0.77        66\n",
      "\n",
      "[13  1  0  0  0  0 14  0  2  0  0  1 10  0  0  0  8  0  5  0  0  1  0  2\n",
      "  9]\n",
      "MNB Accuracy:  0.7727272727272727\n",
      "MNB F1:  0.7819918112601039\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       1.00      0.88      0.93        16\n",
      "          2       1.00      0.91      0.95        11\n",
      "          3       0.65      1.00      0.79        13\n",
      "          4       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.93      0.89      0.90        66\n",
      "\n",
      "[13  0  0  1  0  0 14  0  2  0  0  0 10  1  0  0  0  0 13  0  0  0  0  3\n",
      "  9]\n",
      "svc Accuracy:  0.8939393939393939\n",
      "svc F1:  0.8987397787397787\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.64      0.88      0.74        16\n",
      "          2       1.00      0.91      0.95        11\n",
      "          3       0.58      0.54      0.56        13\n",
      "          4       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.83      0.80      0.81        66\n",
      "\n",
      "[13  0  0  1  0  0 14  0  2  0  0  1 10  0  0  0  6  0  7  0  0  1  0  2\n",
      "  9]\n",
      "LR Accuracy:  0.803030303030303\n",
      "LR F1:  0.8138657755499861\n",
      "For name:  q_shen\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-1491-5434': 36, '0000-0001-5579-036X': 9, '0000-0003-0968-8051': 7, '0000-0002-4621-4659': 3, '0000-0002-3111-2019': 1, '0000-0001-8767-6852': 1})\n",
      "['0000-0002-1491-5434']\n",
      "Total sample size after apply threshold:  36\n",
      "For name:  l_schmidt\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0002-3206-6659': 6, '0000-0002-9518-1734': 5, '0000-0001-7565-1455': 1, '0000-0002-3472-4635': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_qin\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-3323-8846': 30, '0000-0002-8127-4753': 7, '0000-0001-9437-6292': 4, '0000-0002-3591-4959': 1})\n",
      "['0000-0002-3323-8846']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  a_fabbri\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0003-2603-9715': 53, '0000-0003-0097-6348': 5, '0000-0003-2340-9338': 4, '0000-0002-3520-2417': 2})\n",
      "['0000-0003-2603-9715']\n",
      "Total sample size after apply threshold:  53\n",
      "For name:  l_robinson\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0003-0209-2503': 61, '0000-0002-9016-648X': 13, '0000-0001-6811-0140': 8, '0000-0003-1972-4204': 6, '0000-0001-9287-6082': 3, '0000-0001-9544-5923': 1, '0000-0002-2236-0651': 1})\n",
      "['0000-0002-9016-648X', '0000-0003-0209-2503']\n",
      "Total sample size after apply threshold:  74\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(74, 224)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.08      0.13        13\n",
      "          1       0.83      0.98      0.90        61\n",
      "\n",
      "avg / total       0.77      0.82      0.77        74\n",
      "\n",
      "[ 1 12  1 60]\n",
      "MNB Accuracy:  0.8243243243243243\n",
      "MNB F1:  0.5177944862155389\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.23      0.38        13\n",
      "          1       0.86      1.00      0.92        61\n",
      "\n",
      "avg / total       0.88      0.86      0.83        74\n",
      "\n",
      "[ 3 10  0 61]\n",
      "svc Accuracy:  0.8648648648648649\n",
      "svc F1:  0.6496212121212122\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.82      1.00      0.90        61\n",
      "\n",
      "avg / total       0.68      0.82      0.74        74\n",
      "\n",
      "[ 0 13  0 61]\n",
      "LR Accuracy:  0.8243243243243243\n",
      "LR F1:  0.45185185185185184\n",
      "For name:  r_gross\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0001-5884-3607': 38, '0000-0003-4524-7552': 23, '0000-0003-0311-3003': 10})\n",
      "['0000-0003-4524-7552', '0000-0001-5884-3607', '0000-0003-0311-3003']\n",
      "Total sample size after apply threshold:  71\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 322)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.90        23\n",
      "          1       0.73      1.00      0.84        38\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.72      0.80      0.75        71\n",
      "\n",
      "[19  4  0  0 38  0  0 10  0]\n",
      "MNB Accuracy:  0.8028169014084507\n",
      "MNB F1:  0.583068783068783\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.90        23\n",
      "          1       0.83      1.00      0.90        38\n",
      "          2       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.91      0.89      0.88        71\n",
      "\n",
      "[19  4  0  0 38  0  0  4  6]\n",
      "svc Accuracy:  0.8873239436619719\n",
      "svc F1:  0.8531746031746031\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.61      0.76        23\n",
      "          1       0.67      1.00      0.80        38\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.68      0.73      0.67        71\n",
      "\n",
      "[14  9  0  0 38  0  0 10  0]\n",
      "LR Accuracy:  0.7323943661971831\n",
      "LR F1:  0.518918918918919\n",
      "For name:  j_ahn\n",
      "total sample size before apply threshold:  130\n",
      "Counter({'0000-0002-8135-7719': 69, '0000-0002-0177-0192': 26, '0000-0001-9341-009X': 14, '0000-0002-0394-9217': 6, '0000-0001-6928-4038': 4, '0000-0001-5097-2316': 3, '0000-0002-1431-6351': 3, '0000-0002-1050-8575': 1, '0000-0003-1733-1394': 1, '0000-0003-1807-035X': 1, '0000-0003-3625-9906': 1, '0000-0002-4530-0512': 1})\n",
      "['0000-0002-0177-0192', '0000-0001-9341-009X', '0000-0002-8135-7719']\n",
      "Total sample size after apply threshold:  109\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(109, 274)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "109\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        26\n",
      "          1       0.50      0.07      0.12        14\n",
      "          2       0.66      0.99      0.79        69\n",
      "\n",
      "avg / total       0.72      0.67      0.58       109\n",
      "\n",
      "[ 4  0 22  0  1 13  0  1 68]\n",
      "MNB Accuracy:  0.6697247706422018\n",
      "MNB F1:  0.3941214470284238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.58      0.68        26\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       0.83      0.97      0.89        69\n",
      "\n",
      "avg / total       0.85      0.84      0.84       109\n",
      "\n",
      "[15  0 11  1 10  3  2  0 67]\n",
      "svc Accuracy:  0.8440366972477065\n",
      "svc F1:  0.8028282828282828\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.12      0.21        26\n",
      "          1       1.00      0.21      0.35        14\n",
      "          2       0.67      1.00      0.80        69\n",
      "\n",
      "avg / total       0.79      0.69      0.60       109\n",
      "\n",
      "[ 3  0 23  0  3 11  0  0 69]\n",
      "LR Accuracy:  0.6880733944954128\n",
      "LR F1:  0.45405443653002503\n",
      "For name:  j_john\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0003-3654-5099': 16, '0000-0001-8452-0676': 11, '0000-0001-6831-6501': 5, '0000-0002-6411-8927': 4, '0000-0002-6636-3440': 3, '0000-0003-3343-8677': 2, '0000-0003-2696-277X': 1, '0000-0003-2551-2320': 1})\n",
      "['0000-0003-3654-5099', '0000-0001-8452-0676']\n",
      "Total sample size after apply threshold:  27\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 114)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        16\n",
      "          1       1.00      0.64      0.78        11\n",
      "\n",
      "avg / total       0.88      0.85      0.84        27\n",
      "\n",
      "[16  0  4  7]\n",
      "MNB Accuracy:  0.8518518518518519\n",
      "MNB F1:  0.8333333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.94      0.88        16\n",
      "          1       0.89      0.73      0.80        11\n",
      "\n",
      "avg / total       0.86      0.85      0.85        27\n",
      "\n",
      "[15  1  3  8]\n",
      "svc Accuracy:  0.8518518518518519\n",
      "svc F1:  0.8411764705882352\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.84        16\n",
      "          1       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.84      0.78      0.75        27\n",
      "\n",
      "[16  0  6  5]\n",
      "LR Accuracy:  0.7777777777777778\n",
      "LR F1:  0.7335526315789473\n",
      "For name:  d_lloyd\n",
      "total sample size before apply threshold:  157\n",
      "Counter({'0000-0002-0824-9682': 104, '0000-0003-0658-8995': 50, '0000-0003-3589-7383': 1, '0000-0003-1759-6106': 1, '0000-0003-1497-6808': 1})\n",
      "['0000-0003-0658-8995', '0000-0002-0824-9682']\n",
      "Total sample size after apply threshold:  154\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(154, 262)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "154\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        50\n",
      "          1       0.95      1.00      0.97       104\n",
      "\n",
      "avg / total       0.96      0.96      0.96       154\n",
      "\n",
      "[ 44   6   0 104]\n",
      "MNB Accuracy:  0.961038961038961\n",
      "MNB F1:  0.9540664147941937\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        50\n",
      "          1       0.92      1.00      0.96       104\n",
      "\n",
      "avg / total       0.95      0.94      0.94       154\n",
      "\n",
      "[ 41   9   0 104]\n",
      "svc Accuracy:  0.9415584415584416\n",
      "svc F1:  0.9298121233605104\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        50\n",
      "          1       0.87      1.00      0.93       104\n",
      "\n",
      "avg / total       0.91      0.90      0.90       154\n",
      "\n",
      "[ 35  15   0 104]\n",
      "LR Accuracy:  0.9025974025974026\n",
      "LR F1:  0.8781324188868372\n",
      "For name:  a_mohammadi\n",
      "total sample size before apply threshold:  8\n",
      "Counter({'0000-0002-8345-8206': 3, '0000-0001-7845-1707': 2, '0000-0001-7491-6423': 1, '0000-0003-4272-2733': 1, '0000-0002-8477-0939': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_dean\n",
      "total sample size before apply threshold:  189\n",
      "Counter({'0000-0002-4512-9065': 174, '0000-0002-5688-703X': 10, '0000-0002-8599-773X': 2, '0000-0002-2279-3393': 2, '0000-0003-4793-6511': 1})\n",
      "['0000-0002-5688-703X', '0000-0002-4512-9065']\n",
      "Total sample size after apply threshold:  184\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(184, 290)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "184\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.97      1.00      0.99       174\n",
      "\n",
      "avg / total       0.97      0.97      0.97       184\n",
      "\n",
      "[  5   5   0 174]\n",
      "MNB Accuracy:  0.9728260869565217\n",
      "MNB F1:  0.826251180358829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.98      1.00      0.99       174\n",
      "\n",
      "avg / total       0.98      0.98      0.98       184\n",
      "\n",
      "[  6   4   0 174]\n",
      "svc Accuracy:  0.9782608695652174\n",
      "svc F1:  0.8693181818181818\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.95      1.00      0.97       174\n",
      "\n",
      "avg / total       0.89      0.95      0.92       184\n",
      "\n",
      "[  0  10   0 174]\n",
      "LR Accuracy:  0.9456521739130435\n",
      "LR F1:  0.4860335195530726\n",
      "For name:  s_chang\n",
      "total sample size before apply threshold:  592\n",
      "Counter({'0000-0001-6505-4139': 322, '0000-0002-5620-0867': 61, '0000-0003-3751-1720': 37, '0000-0002-6164-0875': 28, '0000-0002-7624-439X': 22, '0000-0002-2663-5042': 20, '0000-0002-5015-8178': 19, '0000-0003-1523-7986': 15, '0000-0003-4160-7549': 12, '0000-0002-2564-2945': 11, '0000-0003-1488-1649': 11, '0000-0002-0558-0038': 8, '0000-0003-0880-2385': 7, '0000-0002-2163-3910': 6, '0000-0003-1095-4505': 2, '0000-0003-2821-7095': 2, '0000-0003-2929-1510': 2, '0000-0001-9347-3592': 2, '0000-0002-2262-0396': 1, '0000-0001-6364-2404': 1, '0000-0001-7038-6170': 1, '0000-0003-0723-3192': 1, '0000-0002-1267-7591': 1})\n",
      "['0000-0002-5015-8178', '0000-0001-6505-4139', '0000-0002-2564-2945', '0000-0003-1488-1649', '0000-0003-1523-7986', '0000-0003-3751-1720', '0000-0002-6164-0875', '0000-0002-5620-0867', '0000-0002-2663-5042', '0000-0003-4160-7549', '0000-0002-7624-439X']\n",
      "Total sample size after apply threshold:  558\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(558, 456)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.35        19\n",
      "          1       0.67      0.99      0.80       322\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.67      0.11      0.19        37\n",
      "          6       0.00      0.00      0.00        28\n",
      "          7       0.86      0.97      0.91        61\n",
      "          8       0.00      0.00      0.00        20\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       0.00      0.00      0.00        22\n",
      "\n",
      "avg / total       0.56      0.69      0.58       558\n",
      "\n",
      "[  4  14   0   0   0   1   0   0   0   0   0   0 319   0   0   0   0   0\n",
      "   3   0   0   0   0   9   0   0   0   0   0   2   0   0   0   0  11   0\n",
      "   0   0   0   0   0   0   0   0   0  15   0   0   0   0   0   0   0   0\n",
      "   0   0  33   0   0   0   4   0   0   0   0   0   0  28   0   0   0   0\n",
      "   0   0   0   0   0   0   2   0   0   0   0   0  59   0   0   0   0  20\n",
      "   0   0   0   0   0   0   0   0   0   0  11   0   0   0   1   0   0   0\n",
      "   0   0   0  17   0   0   0   0   0   5   0   0   0]\n",
      "MNB Accuracy:  0.6917562724014337\n",
      "MNB F1:  0.20346084325589217\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        19\n",
      "          1       0.79      0.99      0.88       322\n",
      "          2       1.00      1.00      1.00        11\n",
      "          3       0.40      0.18      0.25        11\n",
      "          4       1.00      0.27      0.42        15\n",
      "          5       0.84      0.70      0.76        37\n",
      "          6       0.75      0.11      0.19        28\n",
      "          7       0.94      0.95      0.94        61\n",
      "          8       1.00      0.65      0.79        20\n",
      "          9       1.00      0.75      0.86        12\n",
      "         10       0.90      0.41      0.56        22\n",
      "\n",
      "avg / total       0.83      0.83      0.80       558\n",
      "\n",
      "[  8  10   0   0   0   1   0   0   0   0   0   0 318   0   2   0   1   1\n",
      "   0   0   0   0   0   0  11   0   0   0   0   0   0   0   0   0   8   0\n",
      "   2   0   1   0   0   0   0   0   0  10   0   0   4   1   0   0   0   0\n",
      "   0   0  11   0   0   0  26   0   0   0   0   0   0  24   0   1   0   0\n",
      "   3   0   0   0   0   0   2   0   0   0   0   0  58   0   0   1   0   7\n",
      "   0   0   0   0   0   0  13   0   0   0   3   0   0   0   0   0   0   0\n",
      "   9   0   0   8   0   0   0   1   0   4   0   0   9]\n",
      "svc Accuracy:  0.8261648745519713\n",
      "svc F1:  0.6587391120211787\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        19\n",
      "          1       0.71      1.00      0.83       322\n",
      "          2       1.00      1.00      1.00        11\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.89      0.46      0.61        37\n",
      "          6       1.00      0.04      0.07        28\n",
      "          7       0.94      0.95      0.94        61\n",
      "          8       1.00      0.50      0.67        20\n",
      "          9       1.00      0.08      0.15        12\n",
      "         10       0.00      0.00      0.00        22\n",
      "\n",
      "avg / total       0.70      0.75      0.67       558\n",
      "\n",
      "[  0  18   0   0   0   1   0   0   0   0   0   0 322   0   0   0   0   0\n",
      "   0   0   0   0   0   0  11   0   0   0   0   0   0   0   0   0  10   0\n",
      "   0   0   1   0   0   0   0   0   0  15   0   0   0   0   0   0   0   0\n",
      "   0   0  20   0   0   0  17   0   0   0   0   0   0  27   0   0   0   0\n",
      "   1   0   0   0   0   0   3   0   0   0   0   0  58   0   0   0   0  10\n",
      "   0   0   0   0   0   0  10   0   0   0  11   0   0   0   0   0   0   0\n",
      "   1   0   0  18   0   0   0   0   0   4   0   0   0]\n",
      "LR Accuracy:  0.7526881720430108\n",
      "LR F1:  0.38814613936435105\n",
      "For name:  m_conte\n",
      "total sample size before apply threshold:  118\n",
      "Counter({'0000-0001-9405-7339': 48, '0000-0001-8558-2051': 23, '0000-0002-3622-1476': 21, '0000-0002-1399-0344': 16, '0000-0001-7377-163X': 9, '0000-0002-1770-8561': 1})\n",
      "['0000-0001-9405-7339', '0000-0002-3622-1476', '0000-0002-1399-0344', '0000-0001-8558-2051']\n",
      "Total sample size after apply threshold:  108\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(108, 495)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "108\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        48\n",
      "          1       1.00      1.00      1.00        21\n",
      "          2       1.00      0.38      0.55        16\n",
      "          3       1.00      0.78      0.88        23\n",
      "\n",
      "avg / total       0.89      0.86      0.85       108\n",
      "\n",
      "[48  0  0  0  0 21  0  0 10  0  6  0  5  0  0 18]\n",
      "MNB Accuracy:  0.8611111111111112\n",
      "MNB F1:  0.8220920477018039\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        48\n",
      "          1       1.00      1.00      1.00        21\n",
      "          2       1.00      0.94      0.97        16\n",
      "          3       1.00      0.74      0.85        23\n",
      "\n",
      "avg / total       0.94      0.94      0.93       108\n",
      "\n",
      "[48  0  0  0  0 21  0  0  1  0 15  0  6  0  0 17]\n",
      "svc Accuracy:  0.9351851851851852\n",
      "svc F1:  0.9374451926088319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82        48\n",
      "          1       1.00      0.95      0.98        21\n",
      "          2       1.00      0.31      0.48        16\n",
      "          3       1.00      0.61      0.76        23\n",
      "\n",
      "avg / total       0.86      0.81      0.79       108\n",
      "\n",
      "[48  0  0  0  1 20  0  0 11  0  5  0  9  0  0 14]\n",
      "LR Accuracy:  0.8055555555555556\n",
      "LR F1:  0.7572674523894036\n",
      "For name:  i_wilson\n",
      "total sample size before apply threshold:  220\n",
      "Counter({'0000-0002-0246-738X': 102, '0000-0001-8996-1518': 85, '0000-0001-6893-2873': 27, '0000-0002-9620-7000': 3, '0000-0003-4236-5561': 2, '0000-0001-6670-9328': 1})\n",
      "['0000-0001-8996-1518', '0000-0002-0246-738X', '0000-0001-6893-2873']\n",
      "Total sample size after apply threshold:  214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(214, 693)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "214\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.89      0.93        85\n",
      "          1       0.80      1.00      0.89       102\n",
      "          2       1.00      0.30      0.46        27\n",
      "\n",
      "avg / total       0.89      0.87      0.85       214\n",
      "\n",
      "[ 76   9   0   0 102   0   3  16   8]\n",
      "MNB Accuracy:  0.8691588785046729\n",
      "MNB F1:  0.7582672732528949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.88      0.93        85\n",
      "          1       0.81      1.00      0.89       102\n",
      "          2       1.00      0.44      0.62        27\n",
      "\n",
      "avg / total       0.90      0.88      0.87       214\n",
      "\n",
      "[ 75  10   0   0 102   0   1  14  12]\n",
      "svc Accuracy:  0.883177570093458\n",
      "svc F1:  0.813932825374473\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        85\n",
      "          1       0.74      1.00      0.85       102\n",
      "          2       1.00      0.15      0.26        27\n",
      "\n",
      "avg / total       0.88      0.83      0.80       214\n",
      "\n",
      "[ 72  13   0   0 102   0   0  23   4]\n",
      "LR Accuracy:  0.8317757009345794\n",
      "LR F1:  0.6750873227861106\n",
      "For name:  h_yoo\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0001-6186-3262': 11, '0000-0001-9677-0947': 4, '0000-0001-9819-3135': 3, '0000-0002-8039-9482': 3, '0000-0003-3810-1811': 1})\n",
      "['0000-0001-6186-3262']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  d_das\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-3833-1169': 8, '0000-0002-7153-4726': 7, '0000-0002-1643-6621': 1, '0000-0002-2548-2734': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_carr\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-9476-2166': 26, '0000-0002-8175-5303': 4, '0000-0003-1503-015X': 3, '0000-0003-1435-307X': 1})\n",
      "['0000-0002-9476-2166']\n",
      "Total sample size after apply threshold:  26\n",
      "For name:  s_sahu\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0002-9529-3939': 7, '0000-0002-7328-6471': 6, '0000-0001-9010-4572': 2, '0000-0003-2133-4694': 1, '0000-0002-4742-9870': 1, '0000-0002-8500-9711': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_tsai\n",
      "total sample size before apply threshold:  110\n",
      "Counter({'0000-0002-2962-8913': 48, '0000-0002-2862-7572': 37, '0000-0003-4277-1885': 12, '0000-0002-8597-4132': 5, '0000-0002-6216-8672': 5, '0000-0002-9314-5940': 1, '0000-0001-9556-5642': 1, '0000-0001-8246-7779': 1})\n",
      "['0000-0003-4277-1885', '0000-0002-2962-8913', '0000-0002-2862-7572']\n",
      "Total sample size after apply threshold:  97\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(97, 78)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.94      0.98      0.96        48\n",
      "          2       0.93      1.00      0.96        37\n",
      "\n",
      "avg / total       0.94      0.94      0.93        97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 7  3  2  0 47  1  0  0 37]\n",
      "MNB Accuracy:  0.9381443298969072\n",
      "MNB F1:  0.8856882465905023\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.75      0.82        12\n",
      "          1       0.94      0.96      0.95        48\n",
      "          2       0.97      1.00      0.99        37\n",
      "\n",
      "avg / total       0.95      0.95      0.95        97\n",
      "\n",
      "[ 9  3  0  1 46  1  0  0 37]\n",
      "svc Accuracy:  0.9484536082474226\n",
      "svc F1:  0.9177673643653025\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       0.94      0.96      0.95        48\n",
      "          2       0.93      1.00      0.96        37\n",
      "\n",
      "avg / total       0.94      0.94      0.93        97\n",
      "\n",
      "[ 8  3  1  0 46  2  0  0 37]\n",
      "LR Accuracy:  0.9381443298969072\n",
      "LR F1:  0.903164189762128\n",
      "For name:  m_vitale\n",
      "total sample size before apply threshold:  217\n",
      "Counter({'0000-0002-3261-6868': 98, '0000-0001-5372-7885': 63, '0000-0003-2084-2718': 35, '0000-0002-6740-2472': 12, '0000-0002-3652-7029': 7, '0000-0001-9951-4674': 2})\n",
      "['0000-0002-3261-6868', '0000-0003-2084-2718', '0000-0001-5372-7885', '0000-0002-6740-2472']\n",
      "Total sample size after apply threshold:  208\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(208, 570)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "208\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        98\n",
      "          1       1.00      0.66      0.79        35\n",
      "          2       1.00      0.98      0.99        63\n",
      "          3       1.00      0.42      0.59        12\n",
      "\n",
      "avg / total       0.92      0.90      0.90       208\n",
      "\n",
      "[98  0  0  0 12 23  0  0  1  0 62  0  7  0  0  5]\n",
      "MNB Accuracy:  0.9038461538461539\n",
      "MNB F1:  0.8201865374502292\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        98\n",
      "          1       1.00      0.80      0.89        35\n",
      "          2       1.00      0.94      0.97        63\n",
      "          3       1.00      0.50      0.67        12\n",
      "\n",
      "avg / total       0.93      0.92      0.91       208\n",
      "\n",
      "[98  0  0  0  7 28  0  0  4  0 59  0  6  0  0  6]\n",
      "svc Accuracy:  0.9182692307692307\n",
      "svc F1:  0.8607391159342209\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        98\n",
      "          1       1.00      0.46      0.63        35\n",
      "          2       1.00      0.92      0.96        63\n",
      "          3       1.00      0.42      0.59        12\n",
      "\n",
      "avg / total       0.89      0.85      0.84       208\n",
      "\n",
      "[98  0  0  0 19 16  0  0  5  0 58  0  7  0  0  5]\n",
      "LR Accuracy:  0.8509615384615384\n",
      "LR F1:  0.7594500209520587\n",
      "For name:  r_castro\n",
      "total sample size before apply threshold:  116\n",
      "Counter({'0000-0002-0959-7363': 43, '0000-0002-7417-0091': 35, '0000-0002-1329-965X': 11, '0000-0002-1263-9034': 6, '0000-0002-4381-3605': 5, '0000-0002-0701-2528': 4, '0000-0002-8054-1469': 3, '0000-0001-6873-9854': 3, '0000-0002-9337-062X': 2, '0000-0002-4698-7993': 2, '0000-0002-3769-7660': 1, '0000-0002-7289-9081': 1})\n",
      "['0000-0002-0959-7363', '0000-0002-1329-965X', '0000-0002-7417-0091']\n",
      "Total sample size after apply threshold:  89\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 200)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95        43\n",
      "          1       1.00      0.36      0.53        11\n",
      "          2       0.88      1.00      0.93        35\n",
      "\n",
      "avg / total       0.92      0.91      0.89        89\n",
      "\n",
      "[42  0  1  3  4  4  0  0 35]\n",
      "MNB Accuracy:  0.9101123595505618\n",
      "MNB F1:  0.8070707070707069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        43\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       1.00      1.00      1.00        35\n",
      "\n",
      "avg / total       1.00      1.00      1.00        89\n",
      "\n",
      "[43  0  0  0 11  0  0  0 35]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        43\n",
      "          1       1.00      0.27      0.43        11\n",
      "          2       1.00      0.97      0.99        35\n",
      "\n",
      "avg / total       0.92      0.90      0.88        89\n",
      "\n",
      "[43  0  0  8  3  0  1  0 34]\n",
      "LR Accuracy:  0.898876404494382\n",
      "LR F1:  0.7731139442809923\n",
      "For name:  a_hassan\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-9509-9266': 7, '0000-0002-7719-0805': 4, '0000-0001-9346-3765': 2, '0000-0001-8842-1798': 1, '0000-0002-1853-7987': 1, '0000-0002-5574-8791': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  w_martin\n",
      "total sample size before apply threshold:  259\n",
      "Counter({'0000-0003-1478-6449': 180, '0000-0002-2749-3365': 60, '0000-0002-9947-4374': 18, '0000-0002-8952-3072': 1})\n",
      "['0000-0003-1478-6449', '0000-0002-2749-3365', '0000-0002-9947-4374']\n",
      "Total sample size after apply threshold:  258\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(258, 609)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "258\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       180\n",
      "          1       1.00      0.68      0.81        60\n",
      "          2       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.81      0.86      0.82       258\n",
      "\n",
      "[180   0   0  19  41   0  18   0   0]\n",
      "MNB Accuracy:  0.8565891472868217\n",
      "MNB F1:  0.5728940652251623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       180\n",
      "          1       0.98      0.73      0.84        60\n",
      "          2       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.82      0.87      0.83       258\n",
      "\n",
      "[180   0   0  16  44   0  17   1   0]\n",
      "svc Accuracy:  0.8682170542635659\n",
      "svc F1:  0.584708590815461\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88       180\n",
      "          1       1.00      0.45      0.62        60\n",
      "          2       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.78      0.80      0.76       258\n",
      "\n",
      "[180   0   0  33  27   0  18   0   0]\n",
      "LR Accuracy:  0.8023255813953488\n",
      "LR F1:  0.498867354643846\n",
      "For name:  a_krishnan\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0002-9173-7811': 41, '0000-0002-7489-9229': 3, '0000-0002-7980-4110': 1, '0000-0002-9677-9092': 1})\n",
      "['0000-0002-9173-7811']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  l_tavares\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0001-8671-6285': 18, '0000-0001-9487-7978': 7, '0000-0001-8438-7887': 7, '0000-0002-1432-524X': 7, '0000-0003-3190-0194': 2})\n",
      "['0000-0001-8671-6285']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  t_murakami\n",
      "total sample size before apply threshold:  63\n",
      "Counter({'0000-0002-0314-8807': 59, '0000-0002-2661-2633': 2, '0000-0001-7924-8073': 1, '0000-0002-0754-2879': 1})\n",
      "['0000-0002-0314-8807']\n",
      "Total sample size after apply threshold:  59\n",
      "For name:  x_xiao\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-3987-8668': 11, '0000-0002-9753-6586': 8, '0000-0003-1749-4230': 7, '0000-0002-0240-0038': 5})\n",
      "['0000-0002-3987-8668']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  j_davies\n",
      "total sample size before apply threshold:  122\n",
      "Counter({'0000-0001-6660-4032': 55, '0000-0001-5888-664X': 14, '0000-0001-7415-6129': 10, '0000-0003-4035-6047': 9, '0000-0002-4108-4357': 8, '0000-0002-1694-5370': 7, '0000-0002-7415-3638': 6, '0000-0002-9482-1066': 4, '0000-0002-9409-8605': 2, '0000-0001-9832-7412': 2, '0000-0003-4664-6862': 2, '0000-0002-8235-5782': 1, '0000-0002-5883-2526': 1, '0000-0002-4986-8594': 1})\n",
      "['0000-0001-6660-4032', '0000-0001-7415-6129', '0000-0001-5888-664X']\n",
      "Total sample size after apply threshold:  79\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 229)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        55\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.07      0.13        14\n",
      "\n",
      "avg / total       0.67      0.71      0.60        79\n",
      "\n",
      "[55  0  0 10  0  0 13  0  1]\n",
      "MNB Accuracy:  0.7088607594936709\n",
      "MNB F1:  0.32013366750208855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        55\n",
      "          1       1.00      0.20      0.33        10\n",
      "          2       1.00      0.21      0.35        14\n",
      "\n",
      "avg / total       0.82      0.76      0.70        79\n",
      "\n",
      "[55  0  0  8  2  0 11  0  3]\n",
      "svc Accuracy:  0.759493670886076\n",
      "svc F1:  0.5129958960328317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82        55\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.48      0.70      0.57        79\n",
      "\n",
      "[55  0  0 10  0  0 14  0  0]\n",
      "LR Accuracy:  0.6962025316455697\n",
      "LR F1:  0.2736318407960199\n",
      "For name:  a_schmidt\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0002-1090-8165': 51, '0000-0002-3925-9429': 14, '0000-0003-1327-0424': 12, '0000-0002-1185-3012': 9, '0000-0001-8946-1310': 1, '0000-0002-9963-7786': 1, '0000-0002-6448-6367': 1, '0000-0001-6144-9950': 1})\n",
      "['0000-0003-1327-0424', '0000-0002-1090-8165', '0000-0002-3925-9429']\n",
      "Total sample size after apply threshold:  77\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 242)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.91      1.00      0.95        51\n",
      "          2       1.00      0.71      0.83        14\n",
      "\n",
      "avg / total       0.94      0.94      0.93        77\n",
      "\n",
      "[11  1  0  0 51  0  0  4 10]\n",
      "MNB Accuracy:  0.935064935064935\n",
      "MNB F1:  0.9143753668337172\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.94      1.00      0.97        51\n",
      "          2       1.00      0.86      0.92        14\n",
      "\n",
      "avg / total       0.96      0.96      0.96        77\n",
      "\n",
      "[11  1  0  0 51  0  0  2 12]\n",
      "svc Accuracy:  0.961038961038961\n",
      "svc F1:  0.9503424112119764\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.81      1.00      0.89        51\n",
      "          2       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.87      0.84      0.83        77\n",
      "\n",
      "[ 7  5  0  0 51  0  0  7  7]\n",
      "LR Accuracy:  0.8441558441558441\n",
      "LR F1:  0.7660818713450293\n",
      "For name:  j_nieto\n",
      "total sample size before apply threshold:  56\n",
      "Counter({'0000-0002-0086-252X': 32, '0000-0002-5655-3320': 13, '0000-0001-9075-7100': 4, '0000-0003-2465-3033': 4, '0000-0002-4303-1574': 3})\n",
      "['0000-0002-0086-252X', '0000-0002-5655-3320']\n",
      "Total sample size after apply threshold:  45\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 87)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        32\n",
      "          1       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n",
      "[32  0  1 12]\n",
      "MNB Accuracy:  0.9777777777777777\n",
      "MNB F1:  0.9723076923076923\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        32\n",
      "          1       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n",
      "[32  0  1 12]\n",
      "svc Accuracy:  0.9777777777777777\n",
      "svc F1:  0.9723076923076923\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.96        32\n",
      "          1       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        45\n",
      "\n",
      "[32  0  3 10]\n",
      "LR Accuracy:  0.9333333333333333\n",
      "LR F1:  0.9123945489941597\n",
      "For name:  s_hasan\n",
      "total sample size before apply threshold:  12\n",
      "Counter({'0000-0002-9089-5367': 4, '0000-0002-0158-703X': 2, '0000-0002-7269-094X': 2, '0000-0001-5589-8741': 1, '0000-0001-7789-2842': 1, '0000-0003-4271-395X': 1, '0000-0001-6832-9150': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_teixeira\n",
      "total sample size before apply threshold:  313\n",
      "Counter({'0000-0003-4124-6237': 149, '0000-0002-5676-6174': 51, '0000-0002-4896-5982': 48, '0000-0001-9355-2143': 17, '0000-0002-9466-7951': 17, '0000-0002-6944-3008': 13, '0000-0001-7456-5192': 7, '0000-0002-3338-8588': 4, '0000-0003-3989-9474': 3, '0000-0002-2228-2673': 2, '0000-0003-1205-3233': 2})\n",
      "['0000-0002-4896-5982', '0000-0002-5676-6174', '0000-0001-9355-2143', '0000-0002-6944-3008', '0000-0003-4124-6237', '0000-0002-9466-7951']\n",
      "Total sample size after apply threshold:  295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 1580)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "295\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        48\n",
      "          1       0.98      0.96      0.97        51\n",
      "          2       1.00      0.12      0.21        17\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.67      1.00      0.80       149\n",
      "          5       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.73      0.75      0.68       295\n",
      "\n",
      "[ 20   1   0   0  27   0   0  49   0   0   2   0   0   0   2   0  15   0\n",
      "   0   0   0   0  13   0   0   0   0   0 149   0   0   0   0   0  17   0]\n",
      "MNB Accuracy:  0.7457627118644068\n",
      "MNB F1:  0.42835565140454923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.85      0.90        48\n",
      "          1       1.00      0.96      0.98        51\n",
      "          2       1.00      0.71      0.83        17\n",
      "          3       1.00      0.46      0.63        13\n",
      "          4       0.86      1.00      0.93       149\n",
      "          5       1.00      0.71      0.83        17\n",
      "\n",
      "avg / total       0.92      0.91      0.91       295\n",
      "\n",
      "[ 41   0   0   0   7   0   0  49   0   0   2   0   0   0  12   0   5   0\n",
      "   2   0   0   6   5   0   0   0   0   0 149   0   0   0   0   0   5  12]\n",
      "svc Accuracy:  0.911864406779661\n",
      "svc F1:  0.8488860167949571\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        48\n",
      "          1       1.00      0.94      0.97        51\n",
      "          2       1.00      0.29      0.45        17\n",
      "          3       1.00      0.15      0.27        13\n",
      "          4       0.71      1.00      0.83       149\n",
      "          5       1.00      0.29      0.45        17\n",
      "\n",
      "avg / total       0.85      0.79      0.76       295\n",
      "\n",
      "[ 24   0   0   0  24   0   0  48   0   0   3   0   0   0   5   0  12   0\n",
      "   0   0   0   2  11   0   0   0   0   0 149   0   0   0   0   0  12   5]\n",
      "LR Accuracy:  0.7898305084745763\n",
      "LR F1:  0.6066498316498317\n",
      "For name:  j_koh\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0002-1814-5051': 40, '0000-0001-6542-0493': 9, '0000-0002-6617-1449': 7, '0000-0002-1293-1932': 5, '0000-0002-3678-4789': 1})\n",
      "['0000-0002-1814-5051']\n",
      "Total sample size after apply threshold:  40\n",
      "For name:  m_amin\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0002-7822-1124': 4, '0000-0003-0404-2040': 2, '0000-0001-5617-1579': 2, '0000-0002-9701-7102': 2, '0000-0002-3602-5555': 2, '0000-0002-5630-069X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_cho\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-8629-8500': 21, '0000-0003-0861-523X': 17, '0000-0003-0623-5647': 8, '0000-0002-8267-3801': 7, '0000-0002-1737-5701': 7, '0000-0003-1897-1166': 6, '0000-0003-2651-6403': 3, '0000-0002-9799-1538': 2, '0000-0001-7443-167X': 1, '0000-0003-1634-7482': 1})\n",
      "['0000-0002-8629-8500', '0000-0003-0861-523X']\n",
      "Total sample size after apply threshold:  38\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 68)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.98        21\n",
      "          1       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.98      0.97      0.97        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20  1  0 17]\n",
      "MNB Accuracy:  0.9736842105263158\n",
      "MNB F1:  0.9735191637630662\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.98        21\n",
      "          1       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.98      0.97      0.97        38\n",
      "\n",
      "[20  1  0 17]\n",
      "svc Accuracy:  0.9736842105263158\n",
      "svc F1:  0.9735191637630662\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        21\n",
      "          1       0.94      0.94      0.94        17\n",
      "\n",
      "avg / total       0.95      0.95      0.95        38\n",
      "\n",
      "[20  1  1 16]\n",
      "LR Accuracy:  0.9473684210526315\n",
      "LR F1:  0.9467787114845938\n",
      "For name:  s_lam\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0003-3294-6637': 69, '0000-0001-7468-1142': 6, '0000-0002-5318-1760': 5, '0000-0002-2982-9192': 3, '0000-0002-1888-1067': 3, '0000-0001-7943-5004': 3, '0000-0002-1471-5176': 1})\n",
      "['0000-0003-3294-6637']\n",
      "Total sample size after apply threshold:  69\n",
      "For name:  t_tran\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-4686-8601': 38, '0000-0002-5132-6495': 8, '0000-0001-6531-8907': 3, '0000-0002-9557-3340': 2, '0000-0002-3355-7951': 1, '0000-0002-0853-2226': 1, '0000-0002-7489-3126': 1})\n",
      "['0000-0002-4686-8601']\n",
      "Total sample size after apply threshold:  38\n",
      "For name:  c_su\n",
      "total sample size before apply threshold:  297\n",
      "Counter({'0000-0003-3604-7858': 140, '0000-0001-8392-7108': 89, '0000-0002-5211-3520': 27, '0000-0001-9295-7587': 12, '0000-0002-9483-4510': 12, '0000-0001-5428-0878': 6, '0000-0003-2504-0466': 5, '0000-0002-7624-1607': 4, '0000-0002-1035-4238': 1, '0000-0003-4580-9607': 1})\n",
      "['0000-0003-3604-7858', '0000-0002-5211-3520', '0000-0001-8392-7108', '0000-0001-9295-7587', '0000-0002-9483-4510']\n",
      "Total sample size after apply threshold:  280\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(280, 422)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84       140\n",
      "          1       1.00      0.41      0.58        27\n",
      "          2       1.00      0.84      0.91        89\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.78      0.81      0.77       280\n",
      "\n",
      "[140   0   0   0   0  16  11   0   0   0  14   0  75   0   0  12   0   0\n",
      "   0   0  12   0   0   0   0]\n",
      "MNB Accuracy:  0.8071428571428572\n",
      "MNB F1:  0.4663809736111858\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       140\n",
      "          1       0.90      0.67      0.77        27\n",
      "          2       0.94      0.90      0.92        89\n",
      "          3       1.00      0.33      0.50        12\n",
      "          4       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.90      0.89      0.88       280\n",
      "\n",
      "[139   0   1   0   0   5  18   4   0   0   9   0  80   0   0   6   2   0\n",
      "   4   0   3   0   0   0   9]\n",
      "svc Accuracy:  0.8928571428571429\n",
      "svc F1:  0.7926340670321858\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86       140\n",
      "          1       1.00      0.56      0.71        27\n",
      "          2       0.99      0.87      0.92        89\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       1.00      0.25      0.40        12\n",
      "\n",
      "avg / total       0.83      0.84      0.81       280\n",
      "\n",
      "[140   0   0   0   0  11  15   1   0   0  12   0  77   0   0  12   0   0\n",
      "   0   0   9   0   0   0   3]\n",
      "LR Accuracy:  0.8392857142857143\n",
      "LR F1:  0.5801277867545332\n",
      "For name:  s_george\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0002-8807-0737': 31, '0000-0002-0859-0215': 29, '0000-0002-0444-5870': 11, '0000-0001-6534-3846': 6, '0000-0001-9843-4816': 1})\n",
      "['0000-0002-0859-0215', '0000-0002-8807-0737', '0000-0002-0444-5870']\n",
      "Total sample size after apply threshold:  71\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 164)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.97      0.86        29\n",
      "          1       0.94      1.00      0.97        31\n",
      "          2       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.88      0.86      0.82        71\n",
      "\n",
      "[28  1  0  0 31  0  8  1  2]\n",
      "MNB Accuracy:  0.8591549295774648\n",
      "MNB F1:  0.7126602564102565\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        29\n",
      "          1       1.00      1.00      1.00        31\n",
      "          2       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.99      0.99      0.99        71\n",
      "\n",
      "[29  0  0  0 31  0  1  0 10]\n",
      "svc Accuracy:  0.9859154929577465\n",
      "svc F1:  0.9784772666128599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.97      0.88        29\n",
      "          1       0.94      1.00      0.97        31\n",
      "          2       1.00      0.27      0.43        11\n",
      "\n",
      "avg / total       0.89      0.87      0.85        71\n",
      "\n",
      "[28  1  0  0 31  0  7  1  3]\n",
      "LR Accuracy:  0.8732394366197183\n",
      "LR F1:  0.7574404761904762\n",
      "For name:  j_hong\n",
      "total sample size before apply threshold:  143\n",
      "Counter({'0000-0002-2476-3737': 29, '0000-0002-4592-7083': 26, '0000-0002-2891-5785': 20, '0000-0001-9467-6463': 16, '0000-0001-9912-633X': 12, '0000-0003-2212-2861': 12, '0000-0002-9915-8072': 8, '0000-0003-0617-9307': 6, '0000-0001-7979-5966': 5, '0000-0002-0109-5975': 5, '0000-0001-5172-6889': 4})\n",
      "['0000-0001-9912-633X', '0000-0002-2891-5785', '0000-0003-2212-2861', '0000-0002-2476-3737', '0000-0001-9467-6463', '0000-0002-4592-7083']\n",
      "Total sample size after apply threshold:  115\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(115, 153)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "115\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       1.00      0.60      0.75        20\n",
      "          2       1.00      0.17      0.29        12\n",
      "          3       0.58      1.00      0.73        29\n",
      "          4       1.00      0.69      0.81        16\n",
      "          5       0.81      1.00      0.90        26\n",
      "\n",
      "avg / total       0.85      0.77      0.74       115\n",
      "\n",
      "[ 8  0  0  0  0  4  0 12  0  8  0  0  0  0  2 10  0  0  0  0  0 29  0  0\n",
      "  0  0  0  3 11  2  0  0  0  0  0 26]\n",
      "MNB Accuracy:  0.7652173913043478\n",
      "MNB F1:  0.7135430066428174\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.76      0.80      0.78        20\n",
      "          2       0.80      0.67      0.73        12\n",
      "          3       0.97      0.97      0.97        29\n",
      "          4       0.89      1.00      0.94        16\n",
      "          5       1.00      1.00      1.00        26\n",
      "\n",
      "avg / total       0.91      0.91      0.91       115\n",
      "\n",
      "[11  0  0  0  1  0  0 16  2  1  1  0  0  4  8  0  0  0  0  1  0 28  0  0\n",
      "  0  0  0  0 16  0  0  0  0  0  0 26]\n",
      "svc Accuracy:  0.9130434782608695\n",
      "svc F1:  0.8951626638747928\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.75      0.75      0.75        20\n",
      "          2       0.67      0.33      0.44        12\n",
      "          3       0.81      1.00      0.89        29\n",
      "          4       0.93      0.88      0.90        16\n",
      "          5       0.96      1.00      0.98        26\n",
      "\n",
      "avg / total       0.86      0.86      0.85       115\n",
      "\n",
      "[11  0  0  0  1  0  0 15  2  3  0  0  0  5  4  3  0  0  0  0  0 29  0  0\n",
      "  0  0  0  1 14  1  0  0  0  0  0 26]\n",
      "LR Accuracy:  0.8608695652173913\n",
      "LR F1:  0.8212719596343138\n",
      "For name:  p_baptista\n",
      "total sample size before apply threshold:  114\n",
      "Counter({'0000-0001-5255-7095': 73, '0000-0001-6331-3731': 30, '0000-0003-1559-9151': 4, '0000-0003-1433-6456': 4, '0000-0001-7651-4700': 3})\n",
      "['0000-0001-5255-7095', '0000-0001-6331-3731']\n",
      "Total sample size after apply threshold:  103\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 190)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        73\n",
      "          1       1.00      0.93      0.97        30\n",
      "\n",
      "avg / total       0.98      0.98      0.98       103\n",
      "\n",
      "[73  0  2 28]\n",
      "MNB Accuracy:  0.9805825242718447\n",
      "MNB F1:  0.9760018639328985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        73\n",
      "          1       1.00      0.90      0.95        30\n",
      "\n",
      "avg / total       0.97      0.97      0.97       103\n",
      "\n",
      "[73  0  3 27]\n",
      "svc Accuracy:  0.970873786407767\n",
      "svc F1:  0.963617096432356\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        73\n",
      "          1       1.00      0.60      0.75        30\n",
      "\n",
      "avg / total       0.90      0.88      0.87       103\n",
      "\n",
      "[73  0 12 18]\n",
      "LR Accuracy:  0.883495145631068\n",
      "LR F1:  0.8370253164556961\n",
      "For name:  p_thompson\n",
      "total sample size before apply threshold:  148\n",
      "Counter({'0000-0002-5910-7625': 69, '0000-0002-2268-9748': 48, '0000-0001-6195-3284': 10, '0000-0001-7562-6049': 8, '0000-0002-4688-3414': 6, '0000-0002-6851-8899': 3, '0000-0002-5278-9045': 2, '0000-0002-9161-167X': 1, '0000-0002-3141-3567': 1})\n",
      "['0000-0001-6195-3284', '0000-0002-2268-9748', '0000-0002-5910-7625']\n",
      "Total sample size after apply threshold:  127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 434)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.95      0.73      0.82        48\n",
      "          2       0.76      0.99      0.86        69\n",
      "\n",
      "avg / total       0.77      0.81      0.78       127\n",
      "\n",
      "[ 0  1  9  0 35 13  0  1 68]\n",
      "MNB Accuracy:  0.8110236220472441\n",
      "MNB F1:  0.5596251079047971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.97      0.81      0.89        48\n",
      "          2       0.83      1.00      0.91        69\n",
      "\n",
      "avg / total       0.90      0.88      0.87       127\n",
      "\n",
      "[ 4  1  5  0 39  9  0  0 69]\n",
      "svc Accuracy:  0.8818897637795275\n",
      "svc F1:  0.7885623148781044\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.69      0.81        48\n",
      "          2       0.73      1.00      0.85        69\n",
      "\n",
      "avg / total       0.78      0.80      0.77       127\n",
      "\n",
      "[ 0  0 10  0 33 15  0  0 69]\n",
      "LR Accuracy:  0.8031496062992126\n",
      "LR F1:  0.5538135272286602\n",
      "For name:  a_castro\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0001-7526-6717': 39, '0000-0002-8311-0840': 17, '0000-0003-0428-9174': 15, '0000-0002-9253-7926': 14, '0000-0001-6964-6879': 13, '0000-0003-4035-3444': 11, '0000-0003-0524-156X': 7, '0000-0003-3052-6225': 4, '0000-0003-0328-1381': 3, '0000-0002-8025-4945': 2, '0000-0003-3327-967X': 1})\n",
      "['0000-0002-8311-0840', '0000-0001-6964-6879', '0000-0002-9253-7926', '0000-0003-4035-3444', '0000-0003-0428-9174', '0000-0001-7526-6717']\n",
      "Total sample size after apply threshold:  109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 284)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "109\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        17\n",
      "          1       1.00      0.69      0.82        13\n",
      "          2       1.00      0.29      0.44        14\n",
      "          3       1.00      0.45      0.62        11\n",
      "          4       1.00      0.20      0.33        15\n",
      "          5       0.53      1.00      0.70        39\n",
      "\n",
      "avg / total       0.83      0.69      0.66       109\n",
      "\n",
      "[15  0  0  0  0  2  0  9  0  0  0  4  0  0  4  0  0 10  0  0  0  5  0  6\n",
      "  0  0  0  0  3 12  0  0  0  0  0 39]\n",
      "MNB Accuracy:  0.6880733944954128\n",
      "MNB F1:  0.6424813612313612\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        17\n",
      "          1       1.00      0.85      0.92        13\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       1.00      0.82      0.90        11\n",
      "          4       0.46      0.40      0.43        15\n",
      "          5       0.73      0.97      0.84        39\n",
      "\n",
      "avg / total       0.83      0.81      0.80       109\n",
      "\n",
      "[15  0  0  0  0  2  0 11  0  0  1  1  0  0  9  0  4  1  0  0  0  9  1  1\n",
      "  0  0  0  0  6  9  0  0  0  0  1 38]\n",
      "svc Accuracy:  0.8073394495412844\n",
      "svc F1:  0.800085271009184\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        17\n",
      "          1       1.00      0.69      0.82        13\n",
      "          2       0.75      0.21      0.33        14\n",
      "          3       1.00      0.64      0.78        11\n",
      "          4       1.00      0.20      0.33        15\n",
      "          5       0.55      1.00      0.71        39\n",
      "\n",
      "avg / total       0.81      0.70      0.66       109\n",
      "\n",
      "[15  0  0  0  0  2  0  9  1  0  0  3  0  0  3  0  0 11  0  0  0  7  0  4\n",
      "  0  0  0  0  3 12  0  0  0  0  0 39]\n",
      "LR Accuracy:  0.6972477064220184\n",
      "LR F1:  0.6515361952861952\n",
      "For name:  j_zhang\n",
      "total sample size before apply threshold:  965\n",
      "Counter({'0000-0002-4319-4285': 188, '0000-0002-6601-9180': 58, '0000-0003-2493-5209': 58, '0000-0003-3373-9621': 57, '0000-0002-0889-7057': 40, '0000-0001-8041-1608': 28, '0000-0002-9831-6796': 24, '0000-0002-1905-8750': 24, '0000-0002-9231-0844': 21, '0000-0002-7737-0785': 20, '0000-0002-5822-2226': 20, '0000-0002-5108-2072': 19, '0000-0002-1138-2556': 19, '0000-0002-8798-7316': 18, '0000-0002-2195-2997': 18, '0000-0003-3460-0867': 16, '0000-0003-4649-6526': 16, '0000-0001-5903-6487': 15, '0000-0002-1041-793X': 14, '0000-0001-8683-509X': 14, '0000-0002-7068-5135': 14, '0000-0002-9405-9024': 12, '0000-0001-9803-7140': 11, '0000-0002-8344-5907': 10, '0000-0003-1338-8887': 9, '0000-0003-0391-7298': 9, '0000-0002-1221-3033': 9, '0000-0003-3812-3850': 9, '0000-0002-6457-0235': 8, '0000-0003-1572-8339': 8, '0000-0001-8828-114X': 8, '0000-0001-5289-6062': 8, '0000-0001-8970-4466': 7, '0000-0003-1113-6264': 7, '0000-0003-3526-4586': 7, '0000-0002-1559-1240': 6, '0000-0003-3099-6665': 6, '0000-0002-2540-2749': 6, '0000-0002-0912-1197': 5, '0000-0002-0906-0099': 5, '0000-0003-0589-6267': 5, '0000-0001-9732-798X': 5, '0000-0002-3163-6808': 5, '0000-0002-9976-1605': 5, '0000-0002-4758-0394': 5, '0000-0002-1225-6703': 4, '0000-0001-9697-6689': 4, '0000-0001-7869-8005': 4, '0000-0002-7959-2701': 4, '0000-0003-2725-1259': 4, '0000-0001-7533-998X': 4, '0000-0002-0841-1096': 3, '0000-0002-3267-542X': 3, '0000-0001-9275-5790': 3, '0000-0002-6078-4404': 3, '0000-0002-0437-9834': 3, '0000-0002-6196-8694': 3, '0000-0003-2799-9347': 2, '0000-0002-2282-8146': 2, '0000-0001-9143-2869': 2, '0000-0002-1624-9535': 2, '0000-0002-1161-5460': 2, '0000-0003-3195-9882': 2, '0000-0002-3731-4594': 2, '0000-0001-7238-4021': 2, '0000-0002-7937-1474': 2, '0000-0001-6516-0302': 2, '0000-0002-2261-7605': 2, '0000-0001-8385-2003': 2, '0000-0002-9478-8243': 2, '0000-0001-9777-7956': 2, '0000-0002-5785-2090': 2, '0000-0003-1386-6447': 2, '0000-0002-3063-2039': 2, '0000-0002-7841-3767': 1, '0000-0002-2257-1803': 1, '0000-0002-3412-7769': 1, '0000-0002-6358-0255': 1, '0000-0001-9408-138X': 1, '0000-0002-1994-8374': 1, '0000-0002-3574-8401': 1, '0000-0001-7612-8498': 1, '0000-0002-2114-173X': 1, '0000-0001-7228-6202': 1, '0000-0002-0946-5520': 1, '0000-0002-1397-5224': 1, '0000-0002-2222-3024': 1})\n",
      "['0000-0002-9831-6796', '0000-0002-9405-9024', '0000-0001-5903-6487', '0000-0001-8041-1608', '0000-0002-8798-7316', '0000-0003-3460-0867', '0000-0002-7737-0785', '0000-0002-8344-5907', '0000-0002-9231-0844', '0000-0002-4319-4285', '0000-0002-2195-2997', '0000-0002-1905-8750', '0000-0002-6601-9180', '0000-0003-4649-6526', '0000-0002-5108-2072', '0000-0002-1041-793X', '0000-0002-5822-2226', '0000-0002-1138-2556', '0000-0001-8683-509X', '0000-0002-7068-5135', '0000-0003-3373-9621', '0000-0003-2493-5209', '0000-0002-0889-7057', '0000-0001-9803-7140']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 734\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(734, 830)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "734\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.34        24\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        15\n",
      "          3       0.96      0.86      0.91        28\n",
      "          4       0.00      0.00      0.00        18\n",
      "          5       0.00      0.00      0.00        16\n",
      "          6       0.00      0.00      0.00        20\n",
      "          7       0.00      0.00      0.00        10\n",
      "          8       1.00      0.10      0.17        21\n",
      "          9       0.40      1.00      0.57       188\n",
      "         10       1.00      0.22      0.36        18\n",
      "         11       1.00      0.29      0.45        24\n",
      "         12       0.61      0.98      0.75        58\n",
      "         13       0.00      0.00      0.00        16\n",
      "         14       0.00      0.00      0.00        19\n",
      "         15       0.00      0.00      0.00        14\n",
      "         16       0.00      0.00      0.00        20\n",
      "         17       0.00      0.00      0.00        19\n",
      "         18       0.00      0.00      0.00        14\n",
      "         19       0.00      0.00      0.00        14\n",
      "         20       0.91      0.70      0.79        57\n",
      "         21       1.00      0.84      0.92        58\n",
      "         22       1.00      0.80      0.89        40\n",
      "         23       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.51      0.56      0.46       734\n",
      "\n",
      "[  5   0   0   0   0   0   0   0   0  16   0   0   3   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0\n",
      "   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  11   0   0   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  24   0   0   0   0   0   2   0   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  12   0   0   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  15   0   0   5   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6   0   0\n",
      "   3   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   2  17   0   0   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 188   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   4   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  15   0   7   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1   0   0  57   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0\n",
      "   1   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  17   0   0   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   9   0   0   5   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "   0   0   0  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  13   0   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  17   0   0   0   0   0   0   0   0   0   0  40   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0\n",
      "   0   0   1  49   0   0   0   0   0   0   0   0   0   0   0   8   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  32   0   0   0   0   0   0   0\n",
      "   0   0   0  10   0   0   1   0   0   0   0   0   0   0   0   0   0   0]\n",
      "MNB Accuracy:  0.555858310626703\n",
      "MNB F1:  0.2565084662866566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.88      0.91        24\n",
      "          1       1.00      0.67      0.80        12\n",
      "          2       0.67      0.53      0.59        15\n",
      "          3       0.93      0.93      0.93        28\n",
      "          4       0.86      0.33      0.48        18\n",
      "          5       0.93      0.81      0.87        16\n",
      "          6       0.86      0.95      0.90        20\n",
      "          7       1.00      0.90      0.95        10\n",
      "          8       0.95      0.86      0.90        21\n",
      "          9       0.67      0.97      0.79       188\n",
      "         10       0.94      0.89      0.91        18\n",
      "         11       0.93      0.58      0.72        24\n",
      "         12       1.00      0.97      0.98        58\n",
      "         13       0.56      0.31      0.40        16\n",
      "         14       0.93      0.74      0.82        19\n",
      "         15       0.81      0.93      0.87        14\n",
      "         16       1.00      0.35      0.52        20\n",
      "         17       0.77      0.53      0.62        19\n",
      "         18       0.89      0.57      0.70        14\n",
      "         19       1.00      0.86      0.92        14\n",
      "         20       0.88      0.81      0.84        57\n",
      "         21       1.00      0.95      0.97        58\n",
      "         22       1.00      0.95      0.97        40\n",
      "         23       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.86      0.83      0.83       734\n",
      "\n",
      "[ 21   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   8   0   0   0   0   0   0   1   1   0   0\n",
      "   0   2   0   0   0   0   0   0   0   0   0   0   0   0   8   0   0   0\n",
      "   0   0   0   6   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "   0   0   0  26   0   0   0   0   0   0   1   0   0   0   0   0   0   1\n",
      "   0   0   0   0   0   0   0   0   0   0   6   0   0   0   0  12   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13\n",
      "   0   0   0   1   0   0   0   1   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  19   0   0   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0\n",
      "   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "   0   0  18   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   1   0   1   0   0   0   0 183   0   0   0   0   0   0   0   0\n",
      "   1   0   2   0   0   0   0   0   0   0   0   0   0   0   0   2  16   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "   0   0   0   7   0  14   0   0   0   1   0   1   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1   0   0  56   0   0   0   0   1\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   7   0   0\n",
      "   0   5   0   1   0   0   0   0   2   0   0   0   0   0   0   0   0   1\n",
      "   0   0   0   4   0   0   0   0  14   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0  13   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0  12   0   0\n",
      "   0   0   0   0   7   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "   0   0   0   8   0   0   0   0   0   0   0  10   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   6   0   0   0   0   0   0   0   0\n",
      "   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0\n",
      "   0   0   0   0   0   0   0  12   0   0   0   0   0   0   2   0   0   0\n",
      "   1   0   0   6   0   1   0   1   0   0   0   0   0   0  46   0   0   0\n",
      "   0   0   0   0   0   0   1   0   0   2   0   0   0   0   0   0   0   0\n",
      "   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   2   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0\n",
      "   0   0   0   4   0   0   0   0   0   0   0   0   0   0   1   0   0   6]\n",
      "svc Accuracy:  0.832425068119891\n",
      "svc F1:  0.7954914315708854\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.79      0.86        24\n",
      "          1       1.00      0.42      0.59        12\n",
      "          2       0.71      0.33      0.45        15\n",
      "          3       0.93      0.89      0.91        28\n",
      "          4       0.00      0.00      0.00        18\n",
      "          5       1.00      0.25      0.40        16\n",
      "          6       0.80      0.60      0.69        20\n",
      "          7       1.00      0.60      0.75        10\n",
      "          8       1.00      0.71      0.83        21\n",
      "          9       0.53      1.00      0.69       188\n",
      "         10       1.00      0.61      0.76        18\n",
      "         11       0.94      0.62      0.75        24\n",
      "         12       0.85      0.98      0.91        58\n",
      "         13       0.00      0.00      0.00        16\n",
      "         14       1.00      0.58      0.73        19\n",
      "         15       1.00      0.64      0.78        14\n",
      "         16       0.00      0.00      0.00        20\n",
      "         17       0.78      0.37      0.50        19\n",
      "         18       0.00      0.00      0.00        14\n",
      "         19       1.00      0.50      0.67        14\n",
      "         20       0.83      0.79      0.81        57\n",
      "         21       1.00      0.88      0.94        58\n",
      "         22       1.00      0.90      0.95        40\n",
      "         23       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.74      0.73      0.69       734\n",
      "\n",
      "[ 19   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   0   0   5   0   0   0   0   0   0   0   6   0   0\n",
      "   0   0   0   0   0   0   0   0   1   0   0   0   0   0   5   0   0   0\n",
      "   0   0   0   7   0   0   1   0   0   0   0   0   0   0   2   0   0   0\n",
      "   0   0   0  25   0   0   0   0   0   1   0   0   1   0   0   0   0   1\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4\n",
      "   0   0   0   8   0   0   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  12   0   0   6   0   0   2   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   6   0   2   0   0\n",
      "   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0\n",
      "   0   0  15   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 188   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7  11   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "   0   0   0   7   0  15   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1   0   0  57   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0  11   0   0\n",
      "   1   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   8   0   0   0   0  11   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   9   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0  19   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "   0   0   0  11   0   0   0   0   0   0   0   7   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7   0   0\n",
      "   0   0   0   0   0   0   0   7   0   0   0   0   0   0   2   0   0   0\n",
      "   1   0   0   8   0   1   0   0   0   0   0   0   0   0  45   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   7   0   0   0   0   0   0   0   0\n",
      "   0   0   0  51   0   0   0   0   0   0   0   0   0   0   0   4   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  36   0   0   0   0   0   0   0\n",
      "   0   0   0   3   0   0   1   0   0   0   0   0   0   0   1   0   0   6]\n",
      "LR Accuracy:  0.7275204359673024\n",
      "LR F1:  0.6115112964878504\n",
      "For name:  j_rodrigues\n",
      "total sample size before apply threshold:  264\n",
      "Counter({'0000-0002-9347-5026': 39, '0000-0002-1418-7860': 34, '0000-0002-3950-528X': 24, '0000-0001-6143-2139': 23, '0000-0001-8657-3800': 20, '0000-0002-5605-656X': 19, '0000-0003-1889-4914': 16, '0000-0001-9796-3193': 13, '0000-0002-9756-1124': 12, '0000-0001-7006-3048': 12, '0000-0001-9187-8094': 9, '0000-0002-4279-6188': 7, '0000-0002-8621-5410': 6, '0000-0003-0424-3248': 5, '0000-0002-3562-6025': 5, '0000-0002-3217-2320': 4, '0000-0003-4552-1953': 3, '0000-0002-3387-2652': 3, '0000-0002-4031-8000': 3, '0000-0002-8315-8553': 2, '0000-0003-2187-9408': 2, '0000-0002-2793-8192': 1, '0000-0002-4790-7959': 1, '0000-0002-6446-6462': 1})\n",
      "['0000-0002-9756-1124', '0000-0001-6143-2139', '0000-0002-5605-656X', '0000-0003-1889-4914', '0000-0001-8657-3800', '0000-0002-3950-528X', '0000-0002-1418-7860', '0000-0002-9347-5026', '0000-0001-7006-3048', '0000-0001-9796-3193']\n",
      "Total sample size after apply threshold:  212\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(212, 530)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "212\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        12\n",
      "          1       1.00      0.96      0.98        23\n",
      "          2       1.00      0.63      0.77        19\n",
      "          3       1.00      1.00      1.00        16\n",
      "          4       1.00      0.55      0.71        20\n",
      "          5       0.96      0.92      0.94        24\n",
      "          6       0.79      0.97      0.87        34\n",
      "          7       0.54      1.00      0.70        39\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.82      0.80      0.78       212\n",
      "\n",
      "[ 5  0  0  0  0  0  4  3  0  0  0 22  0  0  0  0  0  1  0  0  0  0 12  0\n",
      "  0  0  0  7  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0 11  0  1  8\n",
      "  0  0  0  0  0  0  0 22  2  0  0  0  0  0  0  0  0  1 33  0  0  0  0  0\n",
      "  0  0  0  0  0 39  0  0  0  0  0  0  0  0  2 10  0  0  0  0  0  0  0  0\n",
      "  0  4  0  9]\n",
      "MNB Accuracy:  0.7971698113207547\n",
      "MNB F1:  0.7375359825919418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       1.00      0.96      0.98        23\n",
      "          2       0.94      0.79      0.86        19\n",
      "          3       1.00      1.00      1.00        16\n",
      "          4       1.00      0.75      0.86        20\n",
      "          5       1.00      0.79      0.88        24\n",
      "          6       1.00      0.94      0.97        34\n",
      "          7       0.63      1.00      0.77        39\n",
      "          8       1.00      0.75      0.86        12\n",
      "          9       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.93      0.89      0.89       212\n",
      "\n",
      "[11  0  0  0  0  0  0  1  0  0  0 22  0  0  0  0  0  1  0  0  0  0 15  0\n",
      "  0  0  0  4  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0 15  0  0  5\n",
      "  0  0  0  0  1  0  0 19  0  4  0  0  0  0  0  0  0  0 32  2  0  0  0  0\n",
      "  0  0  0  0  0 39  0  0  0  0  0  0  0  0  0  3  9  0  0  0  0  0  0  0\n",
      "  0  3  0 10]\n",
      "svc Accuracy:  0.8867924528301887\n",
      "svc F1:  0.9000988433380389\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       1.00      0.87      0.93        23\n",
      "          2       0.93      0.68      0.79        19\n",
      "          3       1.00      1.00      1.00        16\n",
      "          4       1.00      0.55      0.71        20\n",
      "          5       1.00      0.79      0.88        24\n",
      "          6       0.97      0.94      0.96        34\n",
      "          7       0.48      1.00      0.64        39\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.84      0.79      0.78       212\n",
      "\n",
      "[ 8  0  0  0  0  0  0  4  0  0  0 20  0  0  0  0  0  3  0  0  0  0 13  0\n",
      "  0  0  0  6  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0 11  0  1  8\n",
      "  0  0  0  0  1  0  0 19  0  4  0  0  0  0  0  0  0  0 32  2  0  0  0  0\n",
      "  0  0  0  0  0 39  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  0\n",
      "  0  4  0  9]\n",
      "LR Accuracy:  0.7877358490566038\n",
      "LR F1:  0.7529543493558106\n",
      "For name:  s_watson\n",
      "total sample size before apply threshold:  117\n",
      "Counter({'0000-0001-6699-1765': 45, '0000-0002-2558-3367': 38, '0000-0002-9818-7429': 12, '0000-0002-9643-5580': 8, '0000-0002-9042-2391': 6, '0000-0001-6063-7327': 4, '0000-0002-8112-9687': 4})\n",
      "['0000-0002-2558-3367', '0000-0002-9818-7429', '0000-0001-6699-1765']\n",
      "Total sample size after apply threshold:  95\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 193)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "95\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        38\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       0.88      1.00      0.94        45\n",
      "\n",
      "avg / total       0.94      0.94      0.94        95\n",
      "\n",
      "[35  0  3  0  9  3  0  0 45]\n",
      "MNB Accuracy:  0.9368421052631579\n",
      "MNB F1:  0.9178489889106327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        38\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       0.87      1.00      0.93        45\n",
      "\n",
      "avg / total       0.94      0.93      0.93        95\n",
      "\n",
      "[34  0  4  0  9  3  0  0 45]\n",
      "svc Accuracy:  0.9263157894736842\n",
      "svc F1:  0.9098074510445645\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        38\n",
      "          1       1.00      0.67      0.80        12\n",
      "          2       0.83      1.00      0.91        45\n",
      "\n",
      "avg / total       0.92      0.91      0.90        95\n",
      "\n",
      "[33  0  5  0  8  4  0  0 45]\n",
      "LR Accuracy:  0.9052631578947369\n",
      "LR F1:  0.8795561246265472\n",
      "For name:  c_barros\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0003-4666-5000': 16, '0000-0003-3244-7467': 13, '0000-0003-2330-398X': 2, '0000-0002-5863-2874': 2, '0000-0003-2236-4553': 1})\n",
      "['0000-0003-3244-7467', '0000-0003-4666-5000']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 189)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        13\n",
      "          1       0.94      0.94      0.94        16\n",
      "\n",
      "avg / total       0.93      0.93      0.93        29\n",
      "\n",
      "[12  1  1 15]\n",
      "MNB Accuracy:  0.9310344827586207\n",
      "MNB F1:  0.9302884615384616\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        13\n",
      "          1       0.84      1.00      0.91        16\n",
      "\n",
      "avg / total       0.91      0.90      0.89        29\n",
      "\n",
      "[10  3  0 16]\n",
      "svc Accuracy:  0.896551724137931\n",
      "svc F1:  0.8919254658385094\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82        13\n",
      "          1       0.80      1.00      0.89        16\n",
      "\n",
      "avg / total       0.89      0.86      0.86        29\n",
      "\n",
      "[ 9  4  0 16]\n",
      "LR Accuracy:  0.8620689655172413\n",
      "LR F1:  0.8535353535353536\n",
      "For name:  f_cardoso\n",
      "total sample size before apply threshold:  178\n",
      "Counter({'0000-0002-6692-2249': 139, '0000-0002-0068-9974': 18, '0000-0002-4391-1336': 9, '0000-0002-7042-1287': 7, '0000-0003-2249-9407': 5})\n",
      "['0000-0002-6692-2249', '0000-0002-0068-9974']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 157\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(157, 794)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "157\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.96       139\n",
      "          1       1.00      0.28      0.43        18\n",
      "\n",
      "avg / total       0.92      0.92      0.90       157\n",
      "\n",
      "[139   0  13   5]\n",
      "MNB Accuracy:  0.9171974522292994\n",
      "MNB F1:  0.695054534588376\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       139\n",
      "          1       1.00      0.56      0.71        18\n",
      "\n",
      "avg / total       0.95      0.95      0.94       157\n",
      "\n",
      "[139   0   8  10]\n",
      "svc Accuracy:  0.9490445859872612\n",
      "svc F1:  0.8431568431568432\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       139\n",
      "          1       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.78      0.89      0.83       157\n",
      "\n",
      "[139   0  18   0]\n",
      "LR Accuracy:  0.8853503184713376\n",
      "LR F1:  0.4695945945945946\n",
      "For name:  m_pinto\n",
      "total sample size before apply threshold:  201\n",
      "Counter({'0000-0002-4676-1409': 79, '0000-0002-8521-2904': 23, '0000-0002-8122-7084': 15, '0000-0001-9778-2093': 14, '0000-0003-3061-9632': 14, '0000-0003-4684-4797': 14, '0000-0003-3462-7277': 10, '0000-0001-9730-5772': 8, '0000-0002-5928-6483': 7, '0000-0001-9663-8399': 5, '0000-0001-6370-3051': 4, '0000-0001-6835-2561': 3, '0000-0002-6337-3459': 2, '0000-0002-5376-742X': 2, '0000-0002-9890-6657': 1})\n",
      "['0000-0002-8122-7084', '0000-0001-9778-2093', '0000-0002-4676-1409', '0000-0003-3061-9632', '0000-0003-3462-7277', '0000-0003-4684-4797', '0000-0002-8521-2904']\n",
      "Total sample size after apply threshold:  169\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 396)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "169\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        15\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       0.59      1.00      0.75        79\n",
      "          3       1.00      0.07      0.13        14\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       1.00      0.43      0.60        14\n",
      "          6       1.00      0.39      0.56        23\n",
      "\n",
      "avg / total       0.75      0.68      0.62       169\n",
      "\n",
      "[ 6  0  9  0  0  0  0  0 14  0  0  0  0  0  0  0 79  0  0  0  0  0  0 13\n",
      "  1  0  0  0  0  0 10  0  0  0  0  0  0  8  0  0  6  0  0  0 14  0  0  0\n",
      "  9]\n",
      "MNB Accuracy:  0.6804733727810651\n",
      "MNB F1:  0.5160778462328327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        15\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       0.81      1.00      0.89        79\n",
      "          3       1.00      0.93      0.96        14\n",
      "          4       1.00      0.80      0.89        10\n",
      "          5       1.00      0.86      0.92        14\n",
      "          6       1.00      0.65      0.79        23\n",
      "\n",
      "avg / total       0.91      0.89      0.88       169\n",
      "\n",
      "[ 9  0  6  0  0  0  0  0 14  0  0  0  0  0  0  0 79  0  0  0  0  0  0  1\n",
      " 13  0  0  0  0  0  2  0  8  0  0  0  0  2  0  0 12  0  0  0  8  0  0  0\n",
      " 15]\n",
      "svc Accuracy:  0.8875739644970414\n",
      "svc F1:  0.8867225466244201\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        15\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       0.61      1.00      0.76        79\n",
      "          3       1.00      0.29      0.44        14\n",
      "          4       1.00      0.10      0.18        10\n",
      "          5       1.00      0.43      0.60        14\n",
      "          6       1.00      0.35      0.52        23\n",
      "\n",
      "avg / total       0.82      0.70      0.66       169\n",
      "\n",
      "[ 7  0  8  0  0  0  0  0 14  0  0  0  0  0  0  0 79  0  0  0  0  0  0 10\n",
      "  4  0  0  0  0  0  9  0  1  0  0  0  0  8  0  0  6  0  0  0 15  0  0  0\n",
      "  8]\n",
      "LR Accuracy:  0.7041420118343196\n",
      "LR F1:  0.5911958113571016\n",
      "For name:  j_cuevas\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0003-2049-3554': 40, '0000-0001-7421-0682': 29, '0000-0001-6327-1404': 6, '0000-0002-6815-3383': 3})\n",
      "['0000-0001-7421-0682', '0000-0003-2049-3554']\n",
      "Total sample size after apply threshold:  69\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 178)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93        29\n",
      "          1       0.91      1.00      0.95        40\n",
      "\n",
      "avg / total       0.95      0.94      0.94        69\n",
      "\n",
      "[25  4  0 40]\n",
      "MNB Accuracy:  0.9420289855072463\n",
      "MNB F1:  0.9391534391534391\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        29\n",
      "          1       1.00      1.00      1.00        40\n",
      "\n",
      "avg / total       1.00      1.00      1.00        69\n",
      "\n",
      "[29  0  0 40]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        29\n",
      "          1       0.95      1.00      0.98        40\n",
      "\n",
      "avg / total       0.97      0.97      0.97        69\n",
      "\n",
      "[27  2  0 40]\n",
      "LR Accuracy:  0.9710144927536232\n",
      "LR F1:  0.9699477351916377\n",
      "For name:  j_chang\n",
      "total sample size before apply threshold:  360\n",
      "Counter({'0000-0001-5726-9797': 85, '0000-0002-8423-5987': 38, '0000-0002-6596-931X': 33, '0000-0002-0890-9302': 31, '0000-0002-3880-3787': 29, '0000-0002-2717-0101': 23, '0000-0001-5582-0928': 17, '0000-0002-4655-1516': 17, '0000-0002-6477-6938': 15, '0000-0003-3773-182X': 12, '0000-0001-8651-2602': 11, '0000-0001-5039-2186': 9, '0000-0001-7843-2688': 9, '0000-0002-6711-1739': 8, '0000-0002-3974-8089': 5, '0000-0001-7449-4080': 4, '0000-0003-3469-9553': 4, '0000-0001-5241-8175': 3, '0000-0002-3811-1254': 2, '0000-0003-4633-587X': 2, '0000-0003-2613-7585': 1, '0000-0003-0041-4804': 1, '0000-0002-4296-4065': 1})\n",
      "['0000-0001-5726-9797', '0000-0003-3773-182X', '0000-0001-5582-0928', '0000-0002-2717-0101', '0000-0002-6596-931X', '0000-0002-6477-6938', '0000-0002-3880-3787', '0000-0002-0890-9302', '0000-0002-8423-5987', '0000-0002-4655-1516', '0000-0001-8651-2602']\n",
      "Total sample size after apply threshold:  311\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(311, 457)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "311\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      1.00      0.58        85\n",
      "          1       1.00      0.50      0.67        12\n",
      "          2       1.00      0.35      0.52        17\n",
      "          3       1.00      0.17      0.30        23\n",
      "          4       0.95      0.55      0.69        33\n",
      "          5       1.00      0.07      0.12        15\n",
      "          6       0.79      0.79      0.79        29\n",
      "          7       1.00      0.55      0.71        31\n",
      "          8       0.92      0.29      0.44        38\n",
      "          9       1.00      0.53      0.69        17\n",
      "         10       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.77      0.58      0.55       311\n",
      "\n",
      "[85  0  0  0  0  0  0  0  0  0  0  4  6  0  0  0  0  2  0  0  0  0 10  0\n",
      "  6  0  0  0  1  0  0  0  0 19  0  0  4  0  0  0  0  0  0  0 15  0  0  0\n",
      " 18  0  0  0  0  0  0 14  0  0  0  0  1  0  0  0  0  0  6  0  0  0  0  0\n",
      " 23  0  0  0  0 11  0  0  0  1  0  1 17  1  0  0 27  0  0  0  0  0  0  0\n",
      " 11  0  0  8  0  0  0  0  0  0  0  0  9  0  9  0  0  0  0  0  2  0  0  0\n",
      "  0]\n",
      "MNB Accuracy:  0.5787781350482315\n",
      "MNB F1:  0.5014508216163021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.89      0.92        85\n",
      "          1       1.00      1.00      1.00        12\n",
      "          2       0.93      0.82      0.87        17\n",
      "          3       0.91      0.87      0.89        23\n",
      "          4       0.97      0.88      0.92        33\n",
      "          5       0.91      0.67      0.77        15\n",
      "          6       0.93      0.97      0.95        29\n",
      "          7       0.78      0.90      0.84        31\n",
      "          8       0.62      0.82      0.70        38\n",
      "          9       1.00      0.88      0.94        17\n",
      "         10       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.89      0.87      0.88       311\n",
      "\n",
      "[76  0  0  0  0  1  0  0  8  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0\n",
      " 14  0  0  0  1  2  0  0  0  1  0  0 20  0  0  0  0  2  0  0  0  0  0  0\n",
      " 29  0  0  1  3  0  0  2  0  0  0  0 10  0  0  3  0  0  0  0  0  0  0  0\n",
      " 28  1  0  0  0  0  0  1  0  0  0  0 28  2  0  0  2  0  0  2  1  0  0  2\n",
      " 31  0  0  0  0  0  0  0  0  0  2  0 15  0  0  0  0  0  0  0  1  0  1  0\n",
      "  9]\n",
      "svc Accuracy:  0.8745980707395499\n",
      "svc F1:  0.8814941928907012\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.95      0.90        85\n",
      "          1       1.00      1.00      1.00        12\n",
      "          2       0.93      0.76      0.84        17\n",
      "          3       0.85      0.74      0.79        23\n",
      "          4       0.91      0.88      0.89        33\n",
      "          5       1.00      0.60      0.75        15\n",
      "          6       0.87      0.90      0.88        29\n",
      "          7       0.72      0.90      0.80        31\n",
      "          8       0.65      0.68      0.67        38\n",
      "          9       1.00      0.71      0.83        17\n",
      "         10       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.85      0.84      0.84       311\n",
      "\n",
      "[81  0  0  0  0  0  0  0  4  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0\n",
      " 13  0  0  0  2  2  0  0  0  3  0  0 17  1  0  0  0  2  0  0  2  0  0  0\n",
      " 29  0  0  0  2  0  0  2  0  0  0  0  9  0  0  4  0  0  0  0  0  1  0  0\n",
      " 26  2  0  0  0  0  0  1  0  1  0  0 28  1  0  0  7  0  0  2  1  0  0  2\n",
      " 26  0  0  0  0  0  0  0  0  0  5  0 12  0  0  0  0  0  0  0  2  0  1  0\n",
      "  8]\n",
      "LR Accuracy:  0.8392282958199357\n",
      "LR F1:  0.8354026466427414\n",
      "For name:  a_dias\n",
      "total sample size before apply threshold:  90\n",
      "Counter({'0000-0003-3641-3248': 19, '0000-0001-7048-7991': 14, '0000-0002-2651-6270': 13, '0000-0001-6895-372X': 13, '0000-0002-0865-0257': 11, '0000-0003-3197-9146': 6, '0000-0001-8881-3564': 4, '0000-0002-5111-0774': 3, '0000-0002-6057-9531': 2, '0000-0003-1921-0510': 2, '0000-0003-0060-2872': 1, '0000-0002-6210-8872': 1, '0000-0002-6667-1961': 1})\n",
      "['0000-0002-0865-0257', '0000-0003-3641-3248', '0000-0002-2651-6270', '0000-0001-7048-7991', '0000-0001-6895-372X']\n",
      "Total sample size after apply threshold:  70\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 215)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "70\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.55      0.67        11\n",
      "          1       0.58      0.95      0.72        19\n",
      "          2       1.00      0.77      0.87        13\n",
      "          3       0.88      1.00      0.93        14\n",
      "          4       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.84      0.77      0.77        70\n",
      "\n",
      "[ 6  4  0  1  0  0 18  0  1  0  1  2 10  0  0  0  0  0 14  0  0  7  0  0\n",
      "  6]\n",
      "MNB Accuracy:  0.7714285714285715\n",
      "MNB F1:  0.7642288329519451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82        11\n",
      "          1       0.67      0.95      0.78        19\n",
      "          2       1.00      0.85      0.92        13\n",
      "          3       1.00      0.93      0.96        14\n",
      "          4       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.88      0.84      0.85        70\n",
      "\n",
      "[ 9  2  0  0  0  1 18  0  0  0  1  1 11  0  0  0  1  0 13  0  0  5  0  0\n",
      "  8]\n",
      "svc Accuracy:  0.8428571428571429\n",
      "svc F1:  0.8484649810736767\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.55      0.67        11\n",
      "          1       0.58      1.00      0.73        19\n",
      "          2       1.00      0.77      0.87        13\n",
      "          3       1.00      1.00      1.00        14\n",
      "          4       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.86      0.79      0.78        70\n",
      "\n",
      "[ 6  5  0  0  0  0 19  0  0  0  1  2 10  0  0  0  0  0 14  0  0  7  0  0\n",
      "  6]\n",
      "LR Accuracy:  0.7857142857142857\n",
      "LR F1:  0.7797160124391246\n",
      "For name:  j_choi\n",
      "total sample size before apply threshold:  441\n",
      "Counter({'0000-0002-2775-3315': 98, '0000-0002-8439-6035': 42, '0000-0003-0018-8712': 25, '0000-0003-2379-2226': 23, '0000-0001-9760-9514': 21, '0000-0002-7491-6711': 21, '0000-0003-2206-4593': 20, '0000-0002-4850-8204': 19, '0000-0003-4897-3277': 15, '0000-0003-3257-2508': 15, '0000-0001-5408-9029': 14, '0000-0002-1161-6586': 13, '0000-0002-9663-4790': 13, '0000-0001-7348-9861': 12, '0000-0002-7532-5315': 10, '0000-0002-9210-9681': 10, '0000-0003-4805-7930': 9, '0000-0001-6121-5804': 8, '0000-0002-3864-9521': 7, '0000-0001-9302-7840': 6, '0000-0003-2891-8086': 4, '0000-0003-3179-6892': 4, '0000-0001-7938-8420': 3, '0000-0001-6336-6462': 3, '0000-0003-3284-9407': 3, '0000-0001-5007-7469': 2, '0000-0002-3280-1991': 2, '0000-0002-2894-3364': 2, '0000-0003-3940-8663': 2, '0000-0002-5086-7345': 2, '0000-0001-8047-9821': 2, '0000-0002-6639-8002': 1, '0000-0002-0723-5035': 1, '0000-0002-8328-4082': 1, '0000-0002-4663-3263': 1, '0000-0001-8023-084X': 1, '0000-0002-3863-4442': 1, '0000-0003-2578-1213': 1, '0000-0003-3554-7033': 1, '0000-0003-1060-0096': 1, '0000-0003-2277-1095': 1, '0000-0003-3155-3196': 1})\n",
      "['0000-0003-4897-3277', '0000-0003-0018-8712', '0000-0003-2379-2226', '0000-0002-1161-6586', '0000-0002-8439-6035', '0000-0001-9760-9514', '0000-0002-7532-5315', '0000-0002-7491-6711', '0000-0003-3257-2508', '0000-0002-9663-4790', '0000-0003-2206-4593', '0000-0002-2775-3315', '0000-0001-5408-9029', '0000-0002-4850-8204', '0000-0001-7348-9861', '0000-0002-9210-9681']\n",
      "Total sample size after apply threshold:  371\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(371, 620)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        15\n",
      "          1       1.00      0.08      0.15        25\n",
      "          2       1.00      0.09      0.16        23\n",
      "          3       0.00      0.00      0.00        13\n",
      "          4       0.97      0.86      0.91        42\n",
      "          5       0.00      0.00      0.00        21\n",
      "          6       1.00      0.10      0.18        10\n",
      "          7       0.00      0.00      0.00        21\n",
      "          8       0.00      0.00      0.00        15\n",
      "          9       0.00      0.00      0.00        13\n",
      "         10       0.00      0.00      0.00        20\n",
      "         11       0.31      1.00      0.47        98\n",
      "         12       0.00      0.00      0.00        14\n",
      "         13       1.00      0.58      0.73        19\n",
      "         14       0.00      0.00      0.00        12\n",
      "         15       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.40      0.40      0.29       371\n",
      "\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  2  0  0  0  0  0  0\n",
      "  0  0  0 23  0  0  0  0  0  0  2  0  1  0  0  0  0  0  0 20  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0 36  0  0  0\n",
      "  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0\n",
      "  0  0  0  0  0  0  1  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 98  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  8  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]\n",
      "MNB Accuracy:  0.40431266846361186\n",
      "MNB F1:  0.1629363265618413\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.53      0.64        15\n",
      "          1       0.41      0.52      0.46        25\n",
      "          2       0.40      0.83      0.54        23\n",
      "          3       0.75      0.23      0.35        13\n",
      "          4       1.00      0.93      0.96        42\n",
      "          5       0.56      0.43      0.49        21\n",
      "          6       0.88      0.70      0.78        10\n",
      "          7       0.33      0.24      0.28        21\n",
      "          8       0.75      0.40      0.52        15\n",
      "          9       0.57      0.31      0.40        13\n",
      "         10       0.72      0.65      0.68        20\n",
      "         11       0.65      0.92      0.76        98\n",
      "         12       0.50      0.14      0.22        14\n",
      "         13       1.00      0.84      0.91        19\n",
      "         14       1.00      0.25      0.40        12\n",
      "         15       0.80      0.40      0.53        10\n",
      "\n",
      "avg / total       0.68      0.65      0.63       371\n",
      "\n",
      "[ 8  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  1  1  0  2  0  2\n",
      "  0  0  2  4  0  0  0  0  2  0 19  0  0  0  0  0  0  0  0  2  0  0  0  0\n",
      "  0  2  0  3  0  0  0  3  1  0  0  4  0  0  0  0  0  0  1  0 39  0  0  0\n",
      "  0  0  0  2  0  0  0  0  0  4  0  0  0  9  1  0  0  0  0  7  0  0  0  0\n",
      "  0  0  1  0  0  1  7  0  0  0  0  1  0  0  0  0  0  5  1  0  0  1  0  5\n",
      "  0  0  1  7  1  0  0  0  0  2  1  0  0  2  0  0  6  1  0  2  0  0  0  1\n",
      "  0  1  1  0  0  1  0  0  0  4  0  5  1  0  0  0  0  2  1  0  0  0  0  0\n",
      "  1  0 13  3  0  0  0  0  0  2  5  0  0  0  0  1  0  0  0 90  0  0  0  0\n",
      "  0  1  0  0  0  0  0  4  0  1  1  5  2  0  0  0  0  0  2  0  0  0  0  0\n",
      "  0  0  0  1  0 16  0  0  0  0  6  0  0  0  0  0  0  1  1  1  0  0  3  0\n",
      "  0  0  1  0  0  0  0  0  0  0  0  5  0  0  0  4]\n",
      "svc Accuracy:  0.6495956873315364\n",
      "svc F1:  0.5582642670429905\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.20      0.32        15\n",
      "          1       0.48      0.40      0.43        25\n",
      "          2       0.67      0.70      0.68        23\n",
      "          3       0.75      0.23      0.35        13\n",
      "          4       0.91      0.95      0.93        42\n",
      "          5       0.50      0.19      0.28        21\n",
      "          6       0.80      0.40      0.53        10\n",
      "          7       0.67      0.19      0.30        21\n",
      "          8       0.62      0.33      0.43        15\n",
      "          9       0.00      0.00      0.00        13\n",
      "         10       0.65      0.55      0.59        20\n",
      "         11       0.48      1.00      0.64        98\n",
      "         12       0.50      0.21      0.30        14\n",
      "         13       1.00      0.79      0.88        19\n",
      "         14       1.00      0.17      0.29        12\n",
      "         15       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.61      0.59      0.53       371\n",
      "\n",
      "[ 3  0  7  0  0  0  0  0  0  0  0  5  0  0  0  0  0 10  0  0  0  1  0  0\n",
      "  1  0  3 10  0  0  0  0  1  0 16  0  0  0  0  0  0  0  0  6  0  0  0  0\n",
      "  0  2  0  3  0  0  0  2  0  0  0  6  0  0  0  0  0  0  0  0 40  0  0  0\n",
      "  0  0  0  2  0  0  0  0  0  2  0  0  0  4  1  0  0  0  0 14  0  0  0  0\n",
      "  0  0  1  0  0  0  4  0  0  0  0  5  0  0  0  0  0  3  0  0  0  1  0  4\n",
      "  0  0  1 11  1  0  0  0  0  1  0  0  0  1  0  0  5  0  1  7  0  0  0  0\n",
      "  0  1  0  0  0  1  0  0  0  0  0  9  2  0  0  0  0  2  0  0  0  0  0  0\n",
      "  1  0 11  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 98  0  0  0  0\n",
      "  0  0  0  0  1  0  0  0  0  1  1  8  3  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  3  0 15  0  0  0  0  0  0  0  0  0  0  1  0  0  9  0  0  2  0\n",
      "  0  0  0  1  2  0  0  0  0  0  0  7  0  0  0  0]\n",
      "LR Accuracy:  0.5876010781671159\n",
      "LR F1:  0.43514186573132413\n",
      "For name:  m_ahmed\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0002-4729-9068': 12, '0000-0002-1921-0724': 3, '0000-0002-4863-0402': 3, '0000-0002-4612-1815': 2, '0000-0002-3514-1327': 2, '0000-0002-7745-7522': 1, '0000-0002-9073-4969': 1, '0000-0002-3217-9688': 1, '0000-0002-2237-8456': 1, '0000-0001-7117-1032': 1})\n",
      "['0000-0002-4729-9068']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  j_jo\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0001-9721-7641': 7, '0000-0001-8939-1623': 4, '0000-0002-6080-7493': 1, '0000-0002-5366-7605': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  n_dawson\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-6607-9976': 14, '0000-0003-0123-897X': 14, '0000-0001-5389-8692': 2, '0000-0002-2658-8960': 1})\n",
      "['0000-0002-6607-9976', '0000-0003-0123-897X']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 91)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.93      1.00      0.97        14\n",
      "\n",
      "avg / total       0.97      0.96      0.96        28\n",
      "\n",
      "[13  1  0 14]\n",
      "MNB Accuracy:  0.9642857142857143\n",
      "MNB F1:  0.9642401021711366\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.93      1.00      0.97        14\n",
      "\n",
      "avg / total       0.97      0.96      0.96        28\n",
      "\n",
      "[13  1  0 14]\n",
      "svc Accuracy:  0.9642857142857143\n",
      "svc F1:  0.9642401021711366\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.93      1.00      0.97        14\n",
      "\n",
      "avg / total       0.97      0.96      0.96        28\n",
      "\n",
      "[13  1  0 14]\n",
      "LR Accuracy:  0.9642857142857143\n",
      "LR F1:  0.9642401021711366\n",
      "For name:  j_barbosa\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-1854-1572': 11, '0000-0001-5879-9458': 9, '0000-0002-8664-8152': 9, '0000-0003-4135-2347': 3, '0000-0002-7259-2901': 1, '0000-0002-7828-2912': 1, '0000-0001-7869-5533': 1})\n",
      "['0000-0002-1854-1572']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  e_o'connor\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0001-6727-6499': 8, '0000-0002-7810-1915': 5, '0000-0002-6961-6108': 3, '0000-0002-2971-6921': 1, '0000-0002-8228-796X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_zheng\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0001-5839-1305': 31, '0000-0002-7463-0289': 11, '0000-0002-0657-7914': 3, '0000-0002-6562-870X': 1})\n",
      "['0000-0001-5839-1305', '0000-0002-7463-0289']\n",
      "Total sample size after apply threshold:  42\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 114)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        31\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.54      0.74      0.63        42\n",
      "\n",
      "[31  0 11  0]\n",
      "MNB Accuracy:  0.7380952380952381\n",
      "MNB F1:  0.4246575342465754\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        31\n",
      "          1       1.00      0.09      0.17        11\n",
      "\n",
      "avg / total       0.82      0.76      0.68        42\n",
      "\n",
      "[31  0 10  1]\n",
      "svc Accuracy:  0.7619047619047619\n",
      "svc F1:  0.513888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        31\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.54      0.74      0.63        42\n",
      "\n",
      "[31  0 11  0]\n",
      "LR Accuracy:  0.7380952380952381\n",
      "LR F1:  0.4246575342465754\n",
      "For name:  r_hall\n",
      "total sample size before apply threshold:  144\n",
      "Counter({'0000-0002-8318-8728': 92, '0000-0001-5504-6717': 41, '0000-0002-4908-8168': 6, '0000-0002-5460-0090': 3, '0000-0002-7743-630X': 2})\n",
      "['0000-0002-8318-8728', '0000-0001-5504-6717']\n",
      "Total sample size after apply threshold:  133\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 351)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96        92\n",
      "          1       0.97      0.83      0.89        41\n",
      "\n",
      "avg / total       0.94      0.94      0.94       133\n",
      "\n",
      "[91  1  7 34]\n",
      "MNB Accuracy:  0.9398496240601504\n",
      "MNB F1:  0.9263157894736842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        92\n",
      "          1       1.00      0.80      0.89        41\n",
      "\n",
      "avg / total       0.94      0.94      0.94       133\n",
      "\n",
      "[92  0  8 33]\n",
      "svc Accuracy:  0.9398496240601504\n",
      "svc F1:  0.9251126126126126\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90        92\n",
      "          1       1.00      0.49      0.66        41\n",
      "\n",
      "avg / total       0.87      0.84      0.82       133\n",
      "\n",
      "[92  0 21 20]\n",
      "LR Accuracy:  0.8421052631578947\n",
      "LR F1:  0.7766493402638945\n",
      "For name:  d_hwang\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0002-2487-2255': 40, '0000-0002-9684-3998': 9, '0000-0001-5275-0354': 2, '0000-0001-6899-1769': 1})\n",
      "['0000-0002-2487-2255']\n",
      "Total sample size after apply threshold:  40\n",
      "For name:  c_shen\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0002-0747-217X': 56, '0000-0003-2833-2771': 22, '0000-0002-2517-3472': 7, '0000-0001-7392-056X': 6, '0000-0002-5052-7762': 5, '0000-0002-0619-1309': 3, '0000-0001-8635-3429': 3, '0000-0002-3218-0689': 3, '0000-0002-3855-7360': 2, '0000-0003-1645-8211': 1, '0000-0002-0685-1901': 1, '0000-0002-9466-3838': 1, '0000-0002-5093-7657': 1})\n",
      "['0000-0003-2833-2771', '0000-0002-0747-217X']\n",
      "Total sample size after apply threshold:  78\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 203)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        22\n",
      "          1       0.80      1.00      0.89        56\n",
      "\n",
      "avg / total       0.86      0.82      0.79        78\n",
      "\n",
      "[ 8 14  0 56]\n",
      "MNB Accuracy:  0.8205128205128205\n",
      "MNB F1:  0.7111111111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        22\n",
      "          1       0.92      1.00      0.96        56\n",
      "\n",
      "avg / total       0.94      0.94      0.93        78\n",
      "\n",
      "[17  5  0 56]\n",
      "svc Accuracy:  0.9358974358974359\n",
      "svc F1:  0.9145299145299145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.23      0.37        22\n",
      "          1       0.77      1.00      0.87        56\n",
      "\n",
      "avg / total       0.83      0.78      0.73        78\n",
      "\n",
      "[ 5 17  0 56]\n",
      "LR Accuracy:  0.782051282051282\n",
      "LR F1:  0.6192937123169682\n",
      "For name:  v_lopes\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0003-1599-2180': 20, '0000-0003-2278-8559': 3, '0000-0003-2079-4170': 2, '0000-0001-8276-4490': 1})\n",
      "['0000-0003-1599-2180']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  m_quintana\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0003-3601-0262': 29, '0000-0002-7036-8658': 17, '0000-0002-3808-8189': 16, '0000-0002-7934-4361': 3, '0000-0001-6190-3324': 2, '0000-0002-2677-6179': 1})\n",
      "['0000-0002-3808-8189', '0000-0002-7036-8658', '0000-0003-3601-0262']\n",
      "Total sample size after apply threshold:  62\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 194)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       1.00      1.00      1.00        17\n",
      "          2       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       1.00      1.00      1.00        62\n",
      "\n",
      "[16  0  0  0 17  0  0  0 29]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       1.00      1.00      1.00        17\n",
      "          2       1.00      1.00      1.00        29\n",
      "\n",
      "avg / total       1.00      1.00      1.00        62\n",
      "\n",
      "[16  0  0  0 17  0  0  0 29]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        16\n",
      "          1       1.00      0.71      0.83        17\n",
      "          2       0.83      1.00      0.91        29\n",
      "\n",
      "avg / total       0.92      0.90      0.90        62\n",
      "\n",
      "[15  0  1  0 12  5  0  0 29]\n",
      "LR Accuracy:  0.9032258064516129\n",
      "LR F1:  0.9005260474601409\n",
      "For name:  j_nunes\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0001-6739-0304': 44, '0000-0001-6560-1518': 6, '0000-0003-0109-8268': 3, '0000-0002-0164-249X': 3, '0000-0002-9988-2060': 2, '0000-0002-3741-9513': 2, '0000-0002-9693-2827': 1, '0000-0003-4917-6771': 1})\n",
      "['0000-0001-6739-0304']\n",
      "Total sample size after apply threshold:  44\n",
      "For name:  z_nagy\n",
      "total sample size before apply threshold:  110\n",
      "Counter({'0000-0001-9756-5427': 57, '0000-0002-6700-4829': 50, '0000-0003-4196-2874': 1, '0000-0002-6014-3228': 1, '0000-0002-6493-5601': 1})\n",
      "['0000-0002-6700-4829', '0000-0001-9756-5427']\n",
      "Total sample size after apply threshold:  107\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(107, 362)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "107\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.90      0.92        50\n",
      "          1       0.92      0.95      0.93        57\n",
      "\n",
      "avg / total       0.93      0.93      0.93       107\n",
      "\n",
      "[45  5  3 54]\n",
      "MNB Accuracy:  0.9252336448598131\n",
      "MNB F1:  0.924700914848698\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        50\n",
      "          1       0.85      1.00      0.92        57\n",
      "\n",
      "avg / total       0.92      0.91      0.91       107\n",
      "\n",
      "[40 10  0 57]\n",
      "svc Accuracy:  0.9065420560747663\n",
      "svc F1:  0.9041218637992832\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        50\n",
      "          1       0.81      1.00      0.90        57\n",
      "\n",
      "avg / total       0.90      0.88      0.88       107\n",
      "\n",
      "[37 13  0 57]\n",
      "LR Accuracy:  0.8785046728971962\n",
      "LR F1:  0.8741062539596343\n",
      "For name:  e_brown\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0002-5995-834X': 28, '0000-0002-8438-6136': 8, '0000-0002-0209-3293': 8, '0000-0003-1411-5792': 7, '0000-0002-2641-1890': 6, '0000-0002-2762-2489': 5, '0000-0003-3806-5339': 4, '0000-0002-1575-2606': 2, '0000-0002-6611-5770': 1, '0000-0002-1398-5721': 1, '0000-0001-7523-0685': 1})\n",
      "['0000-0002-5995-834X']\n",
      "Total sample size after apply threshold:  28\n",
      "For name:  j_nielsen\n",
      "total sample size before apply threshold:  913\n",
      "Counter({'0000-0002-9955-6003': 487, '0000-0001-5568-2916': 105, '0000-0001-9414-1653': 104, '0000-0002-8747-6938': 57, '0000-0002-2831-7718': 39, '0000-0002-2854-8188': 35, '0000-0003-2228-5994': 24, '0000-0002-2058-3579': 23, '0000-0003-1730-3094': 13, '0000-0001-8521-7353': 9, '0000-0002-5211-948X': 8, '0000-0002-8112-8449': 6, '0000-0002-3418-4907': 2, '0000-0002-4760-3875': 1})\n",
      "['0000-0001-9414-1653', '0000-0002-2831-7718', '0000-0003-2228-5994', '0000-0002-9955-6003', '0000-0002-2854-8188', '0000-0002-8747-6938', '0000-0003-1730-3094', '0000-0002-2058-3579', '0000-0001-5568-2916']\n",
      "Total sample size after apply threshold:  887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(887, 1729)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "887\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.68      0.81       104\n",
      "          1       1.00      0.08      0.14        39\n",
      "          2       0.00      0.00      0.00        24\n",
      "          3       0.67      1.00      0.80       487\n",
      "          4       0.00      0.00      0.00        35\n",
      "          5       1.00      0.11      0.19        57\n",
      "          6       0.00      0.00      0.00        13\n",
      "          7       0.00      0.00      0.00        23\n",
      "          8       0.97      0.71      0.82       105\n",
      "\n",
      "avg / total       0.71      0.72      0.65       887\n",
      "\n",
      "[ 71   0   0  32   0   0   0   0   1   0   3   0  36   0   0   0   0   0\n",
      "   1   0   0  23   0   0   0   0   0   0   0   0 486   0   0   0   0   1\n",
      "   0   0   0  35   0   0   0   0   0   0   0   0  51   0   6   0   0   0\n",
      "   0   0   0  13   0   0   0   0   0   0   0   0  23   0   0   0   0   0\n",
      "   0   0   0  30   0   0   0   0  75]\n",
      "MNB Accuracy:  0.7226606538895152\n",
      "MNB F1:  0.30707438273227744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.80      0.87       104\n",
      "          1       1.00      0.54      0.70        39\n",
      "          2       1.00      0.46      0.63        24\n",
      "          3       0.81      0.99      0.89       487\n",
      "          4       1.00      0.46      0.63        35\n",
      "          5       0.86      0.67      0.75        57\n",
      "          6       1.00      0.85      0.92        13\n",
      "          7       1.00      0.70      0.82        23\n",
      "          8       1.00      0.82      0.90       105\n",
      "\n",
      "avg / total       0.88      0.86      0.85       887\n",
      "\n",
      "[ 83   0   0  21   0   0   0   0   0   0  21   0  18   0   0   0   0   0\n",
      "   1   0  11  10   0   2   0   0   0   3   0   0 482   0   2   0   0   0\n",
      "   0   0   0  17  16   2   0   0   0   0   0   0  19   0  38   0   0   0\n",
      "   0   0   0   2   0   0  11   0   0   0   0   0   7   0   0   0  16   0\n",
      "   0   0   0  19   0   0   0   0  86]\n",
      "svc Accuracy:  0.8613303269447576\n",
      "svc F1:  0.7895837055808141\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.63      0.76       104\n",
      "          1       1.00      0.10      0.19        39\n",
      "          2       1.00      0.17      0.29        24\n",
      "          3       0.67      0.99      0.80       487\n",
      "          4       0.00      0.00      0.00        35\n",
      "          5       0.77      0.30      0.43        57\n",
      "          6       0.00      0.00      0.00        13\n",
      "          7       1.00      0.22      0.36        23\n",
      "          8       0.98      0.57      0.72       105\n",
      "\n",
      "avg / total       0.74      0.72      0.67       887\n",
      "\n",
      "[ 66   0   0  38   0   0   0   0   0   0   4   0  35   0   0   0   0   0\n",
      "   1   0   4  18   0   1   0   0   0   2   0   0 483   0   2   0   0   0\n",
      "   0   0   0  32   0   2   0   0   1   0   0   0  40   0  17   0   0   0\n",
      "   0   0   0  13   0   0   0   0   0   0   0   0  18   0   0   0   5   0\n",
      "   0   0   0  45   0   0   0   0  60]\n",
      "LR Accuracy:  0.7204058624577226\n",
      "LR F1:  0.3937986880112343\n",
      "For name:  w_choi\n",
      "total sample size before apply threshold:  118\n",
      "Counter({'0000-0003-1801-9386': 79, '0000-0002-7896-7655': 16, '0000-0002-6623-3806': 7, '0000-0002-4203-0457': 6, '0000-0001-8038-5876': 3, '0000-0002-7183-3400': 3, '0000-0003-4233-0174': 2, '0000-0001-5171-2890': 2})\n",
      "['0000-0003-1801-9386', '0000-0002-7896-7655']\n",
      "Total sample size after apply threshold:  95\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 118)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "95\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        79\n",
      "          1       1.00      0.44      0.61        16\n",
      "\n",
      "avg / total       0.91      0.91      0.89        95\n",
      "\n",
      "[79  0  9  7]\n",
      "MNB Accuracy:  0.9052631578947369\n",
      "MNB F1:  0.7774017183025255\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        79\n",
      "          1       1.00      0.69      0.81        16\n",
      "\n",
      "avg / total       0.95      0.95      0.94        95\n",
      "\n",
      "[79  0  5 11]\n",
      "svc Accuracy:  0.9473684210526315\n",
      "svc F1:  0.8920699840945239\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        79\n",
      "          1       1.00      0.12      0.22        16\n",
      "\n",
      "avg / total       0.87      0.85      0.80        95\n",
      "\n",
      "[79  0 14  2]\n",
      "LR Accuracy:  0.8526315789473684\n",
      "LR F1:  0.5704134366925064\n",
      "For name:  d_tavares\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0002-3196-7922': 4, '0000-0002-6811-9572': 3, '0000-0002-6807-8504': 3, '0000-0002-3358-9443': 2, '0000-0003-4646-5914': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  l_alves\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0001-6245-775X': 14, '0000-0001-5855-2754': 11, '0000-0001-5369-5019': 9, '0000-0002-1972-2658': 5, '0000-0002-7938-9850': 4, '0000-0002-7531-3648': 2, '0000-0002-8944-1851': 2, '0000-0001-8069-6527': 1, '0000-0003-4650-3140': 1, '0000-0002-8400-6148': 1, '0000-0001-6659-6431': 1})\n",
      "['0000-0001-5855-2754', '0000-0001-6245-775X']\n",
      "Total sample size after apply threshold:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 92)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.93      1.00      0.97        14\n",
      "\n",
      "avg / total       0.96      0.96      0.96        25\n",
      "\n",
      "[10  1  0 14]\n",
      "MNB Accuracy:  0.96\n",
      "MNB F1:  0.9589490968801313\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.93      1.00      0.97        14\n",
      "\n",
      "avg / total       0.96      0.96      0.96        25\n",
      "\n",
      "[10  1  0 14]\n",
      "svc Accuracy:  0.96\n",
      "svc F1:  0.9589490968801313\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.88      1.00      0.93        14\n",
      "\n",
      "avg / total       0.93      0.92      0.92        25\n",
      "\n",
      "[ 9  2  0 14]\n",
      "LR Accuracy:  0.92\n",
      "LR F1:  0.9166666666666667\n",
      "For name:  s_chan\n",
      "total sample size before apply threshold:  176\n",
      "Counter({'0000-0001-8238-798X': 76, '0000-0002-9554-7273': 27, '0000-0002-3270-0525': 19, '0000-0003-0274-7258': 11, '0000-0001-6322-2821': 11, '0000-0002-1568-0489': 11, '0000-0001-8322-7443': 9, '0000-0002-8524-229X': 5, '0000-0002-7707-656X': 3, '0000-0001-5326-2758': 2, '0000-0003-0488-1207': 1, '0000-0002-5193-7560': 1})\n",
      "['0000-0002-3270-0525', '0000-0003-0274-7258', '0000-0002-9554-7273', '0000-0001-8238-798X', '0000-0001-6322-2821', '0000-0002-1568-0489']\n",
      "Total sample size after apply threshold:  155\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(155, 280)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "155\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.37      0.54        19\n",
      "          1       1.00      0.27      0.43        11\n",
      "          2       1.00      0.56      0.71        27\n",
      "          3       0.60      1.00      0.75        76\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       1.00      0.36      0.53        11\n",
      "\n",
      "avg / total       0.73      0.68      0.63       155\n",
      "\n",
      "[ 7  0  0 12  0  0  0  3  0  8  0  0  0  0 15 12  0  0  0  0  0 76  0  0\n",
      "  0  0  0 11  0  0  0  0  0  7  0  4]\n",
      "MNB Accuracy:  0.6774193548387096\n",
      "MNB F1:  0.49452121036279445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91        19\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       1.00      0.78      0.88        27\n",
      "          3       0.84      1.00      0.92        76\n",
      "          4       0.86      0.55      0.67        11\n",
      "          5       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.91      0.90      0.90       155\n",
      "\n",
      "[16  0  0  3  0  0  0 11  0  0  0  0  0  0 21  5  1  0  0  0  0 76  0  0\n",
      "  0  0  0  5  6  0  0  0  0  1  0 10]\n",
      "svc Accuracy:  0.9032258064516129\n",
      "svc F1:  0.8873326639892904\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.37      0.54        19\n",
      "          1       1.00      0.45      0.62        11\n",
      "          2       1.00      0.63      0.77        27\n",
      "          3       0.63      1.00      0.78        76\n",
      "          4       1.00      0.18      0.31        11\n",
      "          5       1.00      0.36      0.53        11\n",
      "\n",
      "avg / total       0.82      0.72      0.68       155\n",
      "\n",
      "[ 7  0  0 12  0  0  0  5  0  6  0  0  0  0 17 10  0  0  0  0  0 76  0  0\n",
      "  0  0  0  9  2  0  0  0  0  7  0  4]\n",
      "LR Accuracy:  0.7161290322580646\n",
      "LR F1:  0.5921207760493474\n",
      "For name:  b_ferreira\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-8565-3101': 10, '0000-0002-6781-2236': 6, '0000-0003-2156-2988': 6, '0000-0002-0221-3160': 3, '0000-0003-1388-5015': 3, '0000-0002-5612-5385': 1})\n",
      "['0000-0002-8565-3101']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  r_neves\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-4866-5215': 19, '0000-0001-6571-5697': 3, '0000-0003-3819-1714': 2, '0000-0003-2032-9308': 1})\n",
      "['0000-0003-4866-5215']\n",
      "Total sample size after apply threshold:  19\n",
      "For name:  m_cardoso\n",
      "total sample size before apply threshold:  105\n",
      "Counter({'0000-0003-0973-3908': 38, '0000-0002-8137-3700': 24, '0000-0003-2102-1225': 16, '0000-0001-7766-7557': 6, '0000-0001-5124-0432': 5, '0000-0001-8676-1115': 4, '0000-0002-3633-1659': 3, '0000-0002-7578-4052': 2, '0000-0002-9132-9703': 2, '0000-0003-4725-2996': 2, '0000-0003-2447-6882': 1, '0000-0003-0150-7359': 1, '0000-0002-8405-7471': 1})\n",
      "['0000-0002-8137-3700', '0000-0003-2102-1225', '0000-0003-0973-3908']\n",
      "Total sample size after apply threshold:  78\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 271)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.88      0.89        24\n",
      "          1       1.00      0.12      0.22        16\n",
      "          2       0.72      1.00      0.84        38\n",
      "\n",
      "avg / total       0.84      0.78      0.73        78\n",
      "\n",
      "[21  0  3  2  2 12  0  0 38]\n",
      "MNB Accuracy:  0.782051282051282\n",
      "MNB F1:  0.6503346928878844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        24\n",
      "          1       1.00      0.69      0.81        16\n",
      "          2       0.81      1.00      0.89        38\n",
      "\n",
      "avg / total       0.91      0.88      0.88        78\n",
      "\n",
      "[20  0  4  0 11  5  0  0 38]\n",
      "svc Accuracy:  0.8846153846153846\n",
      "svc F1:  0.8726744569881824\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.75      0.84        24\n",
      "          1       1.00      0.12      0.22        16\n",
      "          2       0.67      1.00      0.80        38\n",
      "\n",
      "avg / total       0.82      0.74      0.69        78\n",
      "\n",
      "[18  0  6  1  2 13  0  0 38]\n",
      "LR Accuracy:  0.7435897435897436\n",
      "LR F1:  0.6198105081826012\n",
      "For name:  c_shao\n",
      "total sample size before apply threshold:  96\n",
      "Counter({'0000-0003-2618-9342': 61, '0000-0002-6953-2203': 23, '0000-0001-8260-4761': 9, '0000-0002-8691-5177': 3})\n",
      "['0000-0002-6953-2203', '0000-0003-2618-9342']\n",
      "Total sample size after apply threshold:  84\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(84, 145)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "84\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.39      0.56        23\n",
      "          1       0.81      1.00      0.90        61\n",
      "\n",
      "avg / total       0.86      0.83      0.81        84\n",
      "\n",
      "[ 9 14  0 61]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.7297794117647058\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.90        23\n",
      "          1       0.94      1.00      0.97        61\n",
      "\n",
      "avg / total       0.96      0.95      0.95        84\n",
      "\n",
      "[19  4  0 61]\n",
      "svc Accuracy:  0.9523809523809523\n",
      "svc F1:  0.9365079365079365\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        23\n",
      "          1       0.80      1.00      0.89        61\n",
      "\n",
      "avg / total       0.86      0.82      0.79        84\n",
      "\n",
      "[ 8 15  0 61]\n",
      "LR Accuracy:  0.8214285714285714\n",
      "LR F1:  0.703319990581587\n",
      "For name:  h_yeo\n",
      "total sample size before apply threshold:  10\n",
      "Counter({'0000-0003-2219-3483': 3, '0000-0003-2629-4353': 2, '0000-0002-2684-0978': 2, '0000-0002-1779-069X': 2, '0000-0002-8403-5790': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_goodman\n",
      "total sample size before apply threshold:  100\n",
      "Counter({'0000-0002-5810-1272': 57, '0000-0001-8932-624X': 41, '0000-0003-3880-7822': 1, '0000-0003-1779-4698': 1})\n",
      "['0000-0002-5810-1272', '0000-0001-8932-624X']\n",
      "Total sample size after apply threshold:  98\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 254)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        57\n",
      "          1       1.00      0.78      0.88        41\n",
      "\n",
      "avg / total       0.92      0.91      0.91        98\n",
      "\n",
      "[57  0  9 32]\n",
      "MNB Accuracy:  0.9081632653061225\n",
      "MNB F1:  0.901770798529903\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        57\n",
      "          1       1.00      0.83      0.91        41\n",
      "\n",
      "avg / total       0.94      0.93      0.93        98\n",
      "\n",
      "[57  0  7 34]\n",
      "svc Accuracy:  0.9285714285714286\n",
      "svc F1:  0.9244077134986226\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        57\n",
      "          1       1.00      0.61      0.76        41\n",
      "\n",
      "avg / total       0.87      0.84      0.83        98\n",
      "\n",
      "[57  0 16 25]\n",
      "LR Accuracy:  0.8367346938775511\n",
      "LR F1:  0.8172494172494171\n",
      "For name:  r_dias\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0002-9214-2166': 15, '0000-0001-7921-405X': 7, '0000-0002-6804-7409': 3, '0000-0003-1503-998X': 1})\n",
      "['0000-0002-9214-2166']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  s_sengupta\n",
      "total sample size before apply threshold:  149\n",
      "Counter({'0000-0003-3357-1216': 64, '0000-0002-6365-1770': 31, '0000-0001-7441-5856': 31, '0000-0001-8187-3396': 9, '0000-0002-9665-0088': 7, '0000-0001-7452-979X': 6, '0000-0002-5933-4430': 1})\n",
      "['0000-0002-6365-1770', '0000-0001-7441-5856', '0000-0003-3357-1216']\n",
      "Total sample size after apply threshold:  126\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(126, 327)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        31\n",
      "          1       1.00      0.71      0.83        31\n",
      "          2       0.79      1.00      0.88        64\n",
      "\n",
      "avg / total       0.89      0.87      0.86       126\n",
      "\n",
      "[23  0  8  0 22  9  0  0 64]\n",
      "MNB Accuracy:  0.8650793650793651\n",
      "MNB F1:  0.8549330505955967\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        31\n",
      "          1       0.96      0.74      0.84        31\n",
      "          2       0.85      1.00      0.92        64\n",
      "\n",
      "avg / total       0.92      0.90      0.90       126\n",
      "\n",
      "[27  1  3  0 23  8  0  0 64]\n",
      "svc Accuracy:  0.9047619047619048\n",
      "svc F1:  0.896087142824925\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.73        31\n",
      "          1       1.00      0.61      0.76        31\n",
      "          2       0.72      1.00      0.84        64\n",
      "\n",
      "avg / total       0.86      0.80      0.79       126\n",
      "\n",
      "[18  0 13  0 19 12  0  0 64]\n",
      "LR Accuracy:  0.8015873015873016\n",
      "LR F1:  0.7770983949135211\n",
      "For name:  y_jung\n",
      "total sample size before apply threshold:  180\n",
      "Counter({'0000-0002-9686-3120': 85, '0000-0003-2098-8143': 39, '0000-0002-2011-1459': 18, '0000-0002-0781-3608': 9, '0000-0003-0357-9508': 9, '0000-0002-9785-0348': 5, '0000-0002-1743-5049': 4, '0000-0003-0169-2865': 4, '0000-0002-8871-1979': 3, '0000-0002-4778-4629': 2, '0000-0001-6615-6401': 1, '0000-0001-7924-6967': 1})\n",
      "['0000-0002-2011-1459', '0000-0002-9686-3120', '0000-0003-2098-8143']\n",
      "Total sample size after apply threshold:  142\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 1266)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "142\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        18\n",
      "          1       0.69      0.99      0.82        85\n",
      "          2       0.86      0.46      0.60        39\n",
      "\n",
      "avg / total       0.65      0.72      0.65       142\n",
      "\n",
      "[ 0 16  2  0 84  1  0 21 18]\n",
      "MNB Accuracy:  0.7183098591549296\n",
      "MNB F1:  0.4718446601941748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.78      0.85        18\n",
      "          1       0.93      0.99      0.96        85\n",
      "          2       0.95      0.90      0.92        39\n",
      "\n",
      "avg / total       0.94      0.94      0.94       142\n",
      "\n",
      "[14  3  1  0 84  1  1  3 35]\n",
      "svc Accuracy:  0.9366197183098591\n",
      "svc F1:  0.909845826687932\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.22      0.36        18\n",
      "          1       0.78      1.00      0.88        85\n",
      "          2       0.97      0.72      0.82        39\n",
      "\n",
      "avg / total       0.86      0.82      0.80       142\n",
      "\n",
      "[ 4 13  1  0 85  0  0 11 28]\n",
      "LR Accuracy:  0.823943661971831\n",
      "LR F1:  0.6878181450649613\n",
      "For name:  c_franco\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0003-1958-3851': 28, '0000-0003-2288-1518': 18, '0000-0002-2861-3883': 17, '0000-0003-2729-4064': 1})\n",
      "['0000-0003-2288-1518', '0000-0002-2861-3883', '0000-0003-1958-3851']\n",
      "Total sample size after apply threshold:  63\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 230)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        18\n",
      "          1       1.00      0.35      0.52        17\n",
      "          2       0.67      1.00      0.80        28\n",
      "\n",
      "avg / total       0.85      0.78      0.76        63\n",
      "\n",
      "[15  0  3  0  6 11  0  0 28]\n",
      "MNB Accuracy:  0.7777777777777778\n",
      "MNB F1:  0.7436100131752306\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       0.94      0.94      0.94        17\n",
      "          2       0.96      0.96      0.96        28\n",
      "\n",
      "avg / total       0.97      0.97      0.97        63\n",
      "\n",
      "[18  0  0  0 16  1  0  1 27]\n",
      "svc Accuracy:  0.9682539682539683\n",
      "svc F1:  0.9684873949579832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        18\n",
      "          1       1.00      0.65      0.79        17\n",
      "          2       0.76      1.00      0.86        28\n",
      "\n",
      "avg / total       0.89      0.86      0.85        63\n",
      "\n",
      "[15  0  3  0 11  6  0  0 28]\n",
      "LR Accuracy:  0.8571428571428571\n",
      "LR F1:  0.8521145521145521\n",
      "For name:  v_wong\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0001-6751-7942': 14, '0000-0002-2951-8108': 12, '0000-0001-9356-7556': 8, '0000-0003-2844-3789': 1})\n",
      "['0000-0001-6751-7942', '0000-0002-2951-8108']\n",
      "Total sample size after apply threshold:  26\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 76)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.86      1.00      0.92        12\n",
      "\n",
      "avg / total       0.93      0.92      0.92        26\n",
      "\n",
      "[12  2  0 12]\n",
      "MNB Accuracy:  0.9230769230769231\n",
      "MNB F1:  0.923076923076923\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        14\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[14  0  1 11]\n",
      "svc Accuracy:  0.9615384615384616\n",
      "svc F1:  0.9610194902548725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        14\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[14  0  1 11]\n",
      "LR Accuracy:  0.9615384615384616\n",
      "LR F1:  0.9610194902548725\n",
      "For name:  j_feng\n",
      "total sample size before apply threshold:  147\n",
      "Counter({'0000-0003-4762-7532': 102, '0000-0003-1944-718X': 13, '0000-0002-9410-7508': 13, '0000-0002-7141-5823': 12, '0000-0002-5683-849X': 3, '0000-0002-2894-4324': 2, '0000-0002-8662-2198': 1, '0000-0002-6974-2956': 1})\n",
      "['0000-0003-1944-718X', '0000-0003-4762-7532', '0000-0002-7141-5823', '0000-0002-9410-7508']\n",
      "Total sample size after apply threshold:  140\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 175)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "140\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.56        13\n",
      "          1       0.78      1.00      0.88       102\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       0.60      0.23      0.33        13\n",
      "\n",
      "avg / total       0.72      0.79      0.72       140\n",
      "\n",
      "[  5   6   0   2   0 102   0   0   0  12   0   0   0  10   0   3]\n",
      "MNB Accuracy:  0.7857142857142857\n",
      "MNB F1:  0.4420498084291188\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.90      1.00      0.95       102\n",
      "          2       0.86      0.50      0.63        12\n",
      "          3       0.75      0.69      0.72        13\n",
      "\n",
      "avg / total       0.89      0.89      0.88       140\n",
      "\n",
      "[  8   3   0   2   0 102   0   0   0   5   6   1   0   3   1   9]\n",
      "svc Accuracy:  0.8928571428571429\n",
      "svc F1:  0.7655802296438771\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.14        13\n",
      "          1       0.75      1.00      0.86       102\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       1.00      0.23      0.38        13\n",
      "\n",
      "avg / total       0.73      0.76      0.67       140\n",
      "\n",
      "[  1  12   0   0   0 102   0   0   0  12   0   0   0  10   0   3]\n",
      "LR Accuracy:  0.7571428571428571\n",
      "LR F1:  0.34375\n",
      "For name:  s_murugesan\n",
      "total sample size before apply threshold:  7\n",
      "Counter({'0000-0003-0154-2859': 3, '0000-0001-8386-6536': 2, '0000-0003-3045-3513': 1, '0000-0003-4264-1984': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_camacho\n",
      "total sample size before apply threshold:  139\n",
      "Counter({'0000-0002-2507-9814': 81, '0000-0003-3182-5227': 33, '0000-0002-8095-4167': 17, '0000-0001-7528-558X': 8})\n",
      "['0000-0002-8095-4167', '0000-0002-2507-9814', '0000-0003-3182-5227']\n",
      "Total sample size after apply threshold:  131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(131, 252)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.65      0.79        17\n",
      "          1       0.92      1.00      0.96        81\n",
      "          2       1.00      0.97      0.98        33\n",
      "\n",
      "avg / total       0.95      0.95      0.94       131\n",
      "\n",
      "[11  6  0  0 81  0  0  1 32]\n",
      "MNB Accuracy:  0.9465648854961832\n",
      "MNB F1:  0.909636517328825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        17\n",
      "          1       0.95      1.00      0.98        81\n",
      "          2       1.00      0.94      0.97        33\n",
      "\n",
      "avg / total       0.97      0.97      0.97       131\n",
      "\n",
      "[15  2  0  0 81  0  0  2 31]\n",
      "svc Accuracy:  0.9694656488549618\n",
      "svc F1:  0.9607178714859437\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        17\n",
      "          1       0.83      1.00      0.91        81\n",
      "          2       1.00      0.82      0.90        33\n",
      "\n",
      "avg / total       0.89      0.87      0.85       131\n",
      "\n",
      "[ 6 11  0  0 81  0  0  6 27]\n",
      "LR Accuracy:  0.8702290076335878\n",
      "LR F1:  0.7755890211318922\n",
      "For name:  b_moreno\n",
      "total sample size before apply threshold:  8\n",
      "Counter({'0000-0001-5799-9802': 6, '0000-0002-8881-4329': 1, '0000-0002-1530-4977': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_andersen\n",
      "total sample size before apply threshold:  129\n",
      "Counter({'0000-0003-1710-1628': 40, '0000-0001-5613-5236': 19, '0000-0001-6300-9086': 19, '0000-0002-8067-3074': 18, '0000-0003-4528-2120': 15, '0000-0001-8902-8162': 6, '0000-0002-6062-7740': 5, '0000-0003-2444-6210': 4, '0000-0003-1402-8162': 2, '0000-0002-4089-4884': 1})\n",
      "['0000-0003-1710-1628', '0000-0001-5613-5236', '0000-0002-8067-3074', '0000-0003-4528-2120', '0000-0001-6300-9086']\n",
      "Total sample size after apply threshold:  111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 380)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      1.00      0.73        40\n",
      "          1       1.00      0.42      0.59        19\n",
      "          2       1.00      0.78      0.88        18\n",
      "          3       1.00      0.47      0.64        15\n",
      "          4       1.00      0.68      0.81        19\n",
      "\n",
      "avg / total       0.85      0.74      0.73       111\n",
      "\n",
      "[40  0  0  0  0 11  8  0  0  0  4  0 14  0  0  8  0  0  7  0  6  0  0  0\n",
      " 13]\n",
      "MNB Accuracy:  0.7387387387387387\n",
      "MNB F1:  0.7300802366169339\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        40\n",
      "          1       0.81      0.68      0.74        19\n",
      "          2       1.00      0.78      0.88        18\n",
      "          3       1.00      0.73      0.85        15\n",
      "          4       1.00      0.74      0.85        19\n",
      "\n",
      "avg / total       0.86      0.83      0.83       111\n",
      "\n",
      "[40  0  0  0  0  6 13  0  0  0  3  1 14  0  0  2  2  0 11  0  5  0  0  0\n",
      " 14]\n",
      "svc Accuracy:  0.8288288288288288\n",
      "svc F1:  0.8291658341658342\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      1.00      0.73        40\n",
      "          1       1.00      0.42      0.59        19\n",
      "          2       1.00      0.78      0.88        18\n",
      "          3       1.00      0.33      0.50        15\n",
      "          4       1.00      0.74      0.85        19\n",
      "\n",
      "avg / total       0.85      0.73      0.72       111\n",
      "\n",
      "[40  0  0  0  0 11  8  0  0  0  4  0 14  0  0 10  0  0  5  0  5  0  0  0\n",
      " 14]\n",
      "LR Accuracy:  0.7297297297297297\n",
      "LR F1:  0.7086700336700338\n",
      "For name:  j_bell\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0003-1455-3274': 15, '0000-0002-1926-7501': 10, '0000-0001-5480-7975': 5, '0000-0002-0233-9708': 3, '0000-0002-6145-5821': 1})\n",
      "['0000-0002-1926-7501', '0000-0003-1455-3274']\n",
      "Total sample size after apply threshold:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 109)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.96      0.96      0.96        25\n",
      "\n",
      "[ 9  1  0 15]\n",
      "MNB Accuracy:  0.96\n",
      "MNB F1:  0.9575551782682513\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.96      0.96      0.96        25\n",
      "\n",
      "[ 9  1  0 15]\n",
      "svc Accuracy:  0.96\n",
      "svc F1:  0.9575551782682513\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.79      1.00      0.88        15\n",
      "\n",
      "avg / total       0.87      0.84      0.83        25\n",
      "\n",
      "[ 6  4  0 15]\n",
      "LR Accuracy:  0.84\n",
      "LR F1:  0.8161764705882353\n",
      "For name:  m_bull\n",
      "total sample size before apply threshold:  5\n",
      "Counter({'0000-0002-4804-9992': 3, '0000-0002-9388-0021': 1, '0000-0002-2324-1195': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_gandhi\n",
      "total sample size before apply threshold:  9\n",
      "Counter({'0000-0002-9759-1745': 4, '0000-0002-3650-3780': 2, '0000-0002-6867-1447': 2, '0000-0002-6762-0867': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_yang\n",
      "total sample size before apply threshold:  514\n",
      "Counter({'0000-0002-4328-8716': 71, '0000-0002-3476-3802': 53, '0000-0001-6312-3719': 48, '0000-0003-4082-420X': 42, '0000-0002-0352-3144': 41, '0000-0001-9138-3075': 32, '0000-0001-8558-062X': 25, '0000-0003-0475-8399': 18, '0000-0001-5990-1346': 17, '0000-0002-2792-6247': 17, '0000-0002-6238-2871': 17, '0000-0003-0561-2340': 15, '0000-0001-8144-8496': 13, '0000-0001-8109-4974': 13, '0000-0002-9147-3879': 12, '0000-0002-8613-3597': 12, '0000-0002-0521-4230': 11, '0000-0003-4927-4814': 10, '0000-0002-5542-7576': 6, '0000-0003-0760-9209': 5, '0000-0002-0487-0420': 5, '0000-0002-3527-6600': 5, '0000-0003-1163-321X': 3, '0000-0003-3368-3082': 3, '0000-0002-5527-6819': 3, '0000-0002-6815-3316': 3, '0000-0003-3456-0455': 2, '0000-0001-5463-6926': 2, '0000-0001-6067-7505': 2, '0000-0002-9579-4426': 2, '0000-0002-2196-6854': 2, '0000-0002-5682-8531': 1, '0000-0002-1380-9533': 1, '0000-0001-7768-4066': 1, '0000-0001-5615-2693': 1})\n",
      "['0000-0002-3476-3802', '0000-0003-0561-2340', '0000-0001-8144-8496', '0000-0002-0352-3144', '0000-0002-4328-8716', '0000-0001-8109-4974', '0000-0002-9147-3879', '0000-0002-8613-3597', '0000-0003-4082-420X', '0000-0001-5990-1346', '0000-0003-4927-4814', '0000-0002-0521-4230', '0000-0001-9138-3075', '0000-0001-8558-062X', '0000-0001-6312-3719', '0000-0003-0475-8399', '0000-0002-2792-6247', '0000-0002-6238-2871']\n",
      "Total sample size after apply threshold:  467\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(467, 419)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "467\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.83      0.64        53\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.82      0.22      0.35        41\n",
      "          4       0.34      0.97      0.50        71\n",
      "          5       1.00      0.46      0.63        13\n",
      "          6       1.00      0.75      0.86        12\n",
      "          7       0.00      0.00      0.00        12\n",
      "          8       0.60      0.07      0.13        42\n",
      "          9       0.00      0.00      0.00        17\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       1.00      0.09      0.17        11\n",
      "         12       0.68      0.88      0.77        32\n",
      "         13       1.00      0.68      0.81        25\n",
      "         14       0.52      0.79      0.63        48\n",
      "         15       0.87      0.72      0.79        18\n",
      "         16       1.00      0.06      0.11        17\n",
      "         17       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.54      0.51      0.43       467\n",
      "\n",
      "[44  0  0  0  8  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 15  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  8  0  0  0  0  0  0  0\n",
      "  0  0  2  0  0  0  6  0  0  9 14  0  0  0  2  0  0  0  0  0 10  0  0  0\n",
      "  1  0  0  0 69  0  0  0  0  0  0  0  0  0  1  0  0  0  2  0  0  0  2  6\n",
      "  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  1  0  9  0  0  0  0  0\n",
      "  0  0  0  2  0  0  5  0  0  0  2  0  0  0  0  0  0  0  0  0  5  0  0  0\n",
      "  3  0  0  0 27  0  0  0  3  0  0  0  2  0  7  0  0  0  6  0  0  1  5  0\n",
      "  0  0  0  0  0  0  0  0  5  0  0  0  2  0  0  1  5  0  0  0  0  0  0  0\n",
      "  0  0  2  0  0  0  0  0  0  0  8  0  0  0  0  0  0  1  2  0  0  0  0  0\n",
      "  2  0  0  0  2  0  0  0  0  0  0  0 28  0  0  0  0  0  0  0  0  0  3  0\n",
      "  0  0  0  0  0  0  5 17  0  0  0  0  1  0  0  0  9  0  0  0  0  0  0  0\n",
      "  0  0 38  0  0  0  1  0  0  0  3  0  0  0  0  0  0  0  0  0  1 13  0  0\n",
      "  4  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  1  0  4  0  0  0 11  0\n",
      "  0  0  0  0  0  0  0  0  2  0  0  0]\n",
      "MNB Accuracy:  0.5096359743040685\n",
      "MNB F1:  0.3542828894322264\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.79      0.82        53\n",
      "          1       1.00      0.40      0.57        15\n",
      "          2       1.00      0.08      0.14        13\n",
      "          3       0.37      0.63      0.46        41\n",
      "          4       0.84      0.92      0.88        71\n",
      "          5       1.00      0.92      0.96        13\n",
      "          6       0.90      0.75      0.82        12\n",
      "          7       1.00      0.50      0.67        12\n",
      "          8       0.47      0.64      0.55        42\n",
      "          9       1.00      0.65      0.79        17\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       1.00      0.64      0.78        11\n",
      "         12       0.83      0.94      0.88        32\n",
      "         13       1.00      0.96      0.98        25\n",
      "         14       0.60      0.79      0.68        48\n",
      "         15       0.84      0.89      0.86        18\n",
      "         16       0.92      0.71      0.80        17\n",
      "         17       1.00      0.18      0.30        17\n",
      "\n",
      "avg / total       0.77      0.72      0.71       467\n",
      "\n",
      "[42  0  0  5  0  0  0  0  3  0  0  0  1  0  2  0  0  0  0  6  0  7  0  0\n",
      "  0  0  2  0  0  0  0  0  0  0  0  0  1  0  1  5  2  0  0  0  2  0  0  0\n",
      "  0  0  1  0  1  0  2  0  0 26  1  0  0  0  5  0  0  0  0  0  7  0  0  0\n",
      "  0  0  0  3 65  0  0  0  2  0  0  0  0  0  1  0  0  0  0  0  0  1  0 12\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0\n",
      "  0  0  0  3  0  0  1  0  0  4  0  0  0  6  0  0  0  0  0  0  1  0  0  0\n",
      "  1  0  0  6  1  0  0  0 27  0  0  0  2  0  5  0  0  0  0  0  0  1  0  0\n",
      "  0  0  3 11  1  0  0  0  1  0  0  0  1  0  0  2  4  0  0  0  0  0  0  0\n",
      "  0  0  3  0  0  0  0  0  0  3  0  0  0  0  0  0  0  7  1  0  0  0  0  0\n",
      "  0  0  0  1  0  0  0  0  1  0  0  0 30  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  1 24  0  0  0  0  1  0  0  2  3  0  0  0  4  0  0  0\n",
      "  0  0 38  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0 16  0  0\n",
      "  0  0  0  0  1  0  0  0  2  0  0  0  0  0  2  0 12  0  1  0  0  4  0  0\n",
      "  0  0  6  0  0  0  1  0  2  0  0  3]\n",
      "svc Accuracy:  0.7173447537473233\n",
      "svc F1:  0.6632096227104523\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.83      0.79        53\n",
      "          1       1.00      0.27      0.42        15\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.33      0.51      0.40        41\n",
      "          4       0.74      0.92      0.82        71\n",
      "          5       1.00      0.85      0.92        13\n",
      "          6       1.00      0.75      0.86        12\n",
      "          7       1.00      0.33      0.50        12\n",
      "          8       0.43      0.48      0.45        42\n",
      "          9       1.00      0.35      0.52        17\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       1.00      0.55      0.71        11\n",
      "         12       0.76      0.97      0.85        32\n",
      "         13       1.00      0.92      0.96        25\n",
      "         14       0.51      0.81      0.62        48\n",
      "         15       0.85      0.94      0.89        18\n",
      "         16       0.78      0.41      0.54        17\n",
      "         17       1.00      0.12      0.21        17\n",
      "\n",
      "avg / total       0.69      0.66      0.64       467\n",
      "\n",
      "[44  0  0  3  1  0  0  0  3  0  0  0  1  0  1  0  0  0  0  4  0  9  0  0\n",
      "  0  0  2  0  0  0  0  0  0  0  0  0  1  0  0  2  4  0  0  0  2  0  0  0\n",
      "  0  0  3  0  1  0  3  0  0 21  2  0  0  0  5  0  0  0  0  0 10  0  0  0\n",
      "  0  0  0  2 65  0  0  0  1  0  0  0  0  0  3  0  0  0  1  0  0  1  0 11\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0\n",
      "  0  0  0  3  0  0  2  0  0  1  2  0  0  4  0  0  0  0  1  0  1  0  1  0\n",
      "  2  0  0  6  4  0  0  0 20  0  0  0  2  0  8  0  0  0  1  0  0  2  0  0\n",
      "  0  0  3  6  0  0  1  0  4  0  0  0  1  0  0  2  4  0  0  0  0  0  0  0\n",
      "  0  0  3  0  0  0  0  0  0  4  0  0  0  0  0  0  0  6  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  1  0  0  0 31  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  2 23  0  0  0  0  1  0  0  1  4  0  0  0  3  0  0  0\n",
      "  0  0 39  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 17  0  0\n",
      "  0  0  0  4  2  0  0  0  1  0  0  0  1  0  2  0  7  0  2  0  0  4  0  0\n",
      "  0  0  5  0  0  0  1  0  3  0  0  2]\n",
      "LR Accuracy:  0.6616702355460385\n",
      "LR F1:  0.5814806222791485\n",
      "For name:  s_paul\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0002-9693-2915': 23, '0000-0001-7560-5512': 8, '0000-0003-1274-6670': 7, '0000-0002-8813-0437': 5, '0000-0003-4104-9209': 4, '0000-0002-7077-8235': 4, '0000-0001-9601-9109': 1})\n",
      "['0000-0002-9693-2915']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  l_roberts\n",
      "total sample size before apply threshold:  363\n",
      "Counter({'0000-0003-4270-253X': 206, '0000-0001-7885-8574': 120, '0000-0002-1455-5248': 18, '0000-0003-0085-9213': 14, '0000-0003-3892-2900': 3, '0000-0002-0329-8389': 2})\n",
      "['0000-0003-4270-253X', '0000-0003-0085-9213', '0000-0002-1455-5248', '0000-0001-7885-8574']\n",
      "Total sample size after apply threshold:  358\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(358, 743)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "358\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87       206\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.00      0.00      0.00        18\n",
      "          3       1.00      0.76      0.86       120\n",
      "\n",
      "avg / total       0.78      0.83      0.79       358\n",
      "\n",
      "[206   0   0   0  14   0   0   0  18   0   0   0  29   0   0  91]\n",
      "MNB Accuracy:  0.8296089385474861\n",
      "MNB F1:  0.4333987956273859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       206\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       1.00      0.67      0.80        18\n",
      "          3       0.98      0.81      0.89       120\n",
      "\n",
      "avg / total       0.86      0.88      0.86       358\n",
      "\n",
      "[206   0   0   0  14   0   0   0   4   0  12   2  23   0   0  97]\n",
      "svc Accuracy:  0.8798882681564246\n",
      "svc F1:  0.6488342556472829\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86       206\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.00      0.00      0.00        18\n",
      "          3       1.00      0.70      0.82       120\n",
      "\n",
      "avg / total       0.77      0.81      0.77       358\n",
      "\n",
      "[206   0   0   0  14   0   0   0  18   0   0   0  36   0   0  84]\n",
      "LR Accuracy:  0.8100558659217877\n",
      "LR F1:  0.42046568627450975\n",
      "For name:  s_keating\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-8324-3694': 28, '0000-0002-3356-3542': 14, '0000-0001-5357-2721': 10, '0000-0003-3685-2849': 1, '0000-0002-6817-925X': 1})\n",
      "['0000-0002-3356-3542', '0000-0002-8324-3694', '0000-0001-5357-2721']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 381)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.85      1.00      0.92        28\n",
      "          2       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.92      0.90      0.90        52\n",
      "\n",
      "[12  2  0  0 28  0  0  3  7]\n",
      "MNB Accuracy:  0.9038461538461539\n",
      "MNB F1:  0.888213040575625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.85      1.00      0.92        28\n",
      "          2       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.92      0.90      0.90        52\n",
      "\n",
      "[12  2  0  0 28  0  0  3  7]\n",
      "svc Accuracy:  0.9038461538461539\n",
      "svc F1:  0.888213040575625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        14\n",
      "          1       0.70      1.00      0.82        28\n",
      "          2       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.84      0.77      0.75        52\n",
      "\n",
      "[ 6  8  0  0 28  0  0  4  6]\n",
      "LR Accuracy:  0.7692307692307693\n",
      "LR F1:  0.7245098039215686\n",
      "For name:  a_bennett\n",
      "total sample size before apply threshold:  56\n",
      "Counter({'0000-0003-3829-0309': 51, '0000-0001-8895-6418': 2, '0000-0001-7448-8182': 1, '0000-0003-4194-9741': 1, '0000-0001-6968-9465': 1})\n",
      "['0000-0003-3829-0309']\n",
      "Total sample size after apply threshold:  51\n",
      "For name:  a_aggarwal\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0003-3096-3206': 10, '0000-0002-1755-8807': 6, '0000-0002-6696-0296': 5, '0000-0003-0458-5619': 1})\n",
      "['0000-0003-3096-3206']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  i_moura\n",
      "total sample size before apply threshold:  203\n",
      "Counter({'0000-0003-0971-4977': 149, '0000-0002-2977-0354': 48, '0000-0002-3019-7196': 5, '0000-0001-7859-1881': 1})\n",
      "['0000-0002-2977-0354', '0000-0003-0971-4977']\n",
      "Total sample size after apply threshold:  197\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(197, 548)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "197\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        48\n",
      "          1       0.94      1.00      0.97       149\n",
      "\n",
      "avg / total       0.96      0.95      0.95       197\n",
      "\n",
      "[ 39   9   0 149]\n",
      "MNB Accuracy:  0.9543147208121827\n",
      "MNB F1:  0.9336178816129395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        48\n",
      "          1       0.97      1.00      0.98       149\n",
      "\n",
      "avg / total       0.98      0.97      0.97       197\n",
      "\n",
      "[ 43   5   0 149]\n",
      "svc Accuracy:  0.9746192893401016\n",
      "svc F1:  0.9642766474449642\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.48      0.65        48\n",
      "          1       0.86      1.00      0.92       149\n",
      "\n",
      "avg / total       0.89      0.87      0.86       197\n",
      "\n",
      "[ 23  25   0 149]\n",
      "LR Accuracy:  0.8730964467005076\n",
      "LR F1:  0.7852439715693542\n",
      "For name:  d_teixeira\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0003-1799-1675': 13, '0000-0002-2162-1450': 12, '0000-0003-2110-4725': 1, '0000-0001-8172-7911': 1})\n",
      "['0000-0003-1799-1675', '0000-0002-2162-1450']\n",
      "Total sample size after apply threshold:  25\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 84)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        25\n",
      "\n",
      "[13  0  0 12]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        25\n",
      "\n",
      "[13  0  0 12]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        25\n",
      "\n",
      "[13  0  0 12]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  c_klein\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0003-3522-9182': 47, '0000-0002-8230-8038': 21, '0000-0003-2991-1791': 11, '0000-0002-7580-8536': 11, '0000-0001-9736-5994': 9, '0000-0003-1305-0114': 5, '0000-0002-7406-4010': 2})\n",
      "['0000-0003-2991-1791', '0000-0003-3522-9182', '0000-0002-7580-8536', '0000-0002-8230-8038']\n",
      "Total sample size after apply threshold:  90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(90, 224)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "90\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.70      1.00      0.82        47\n",
      "          2       1.00      0.64      0.78        11\n",
      "          3       1.00      0.76      0.86        21\n",
      "\n",
      "avg / total       0.72      0.78      0.73        90\n",
      "\n",
      "[ 0 11  0  0  0 47  0  0  0  4  7  0  0  5  0 16]\n",
      "MNB Accuracy:  0.7777777777777778\n",
      "MNB F1:  0.6168010115378536\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.73      1.00      0.85        47\n",
      "          2       1.00      1.00      1.00        11\n",
      "          3       1.00      0.71      0.83        21\n",
      "\n",
      "avg / total       0.74      0.81      0.76        90\n",
      "\n",
      "[ 0 11  0  0  0 47  0  0  0  0 11  0  0  6  0 15]\n",
      "svc Accuracy:  0.8111111111111111\n",
      "svc F1:  0.670045045045045\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.62      1.00      0.76        47\n",
      "          2       1.00      0.36      0.53        11\n",
      "          3       1.00      0.48      0.65        21\n",
      "\n",
      "avg / total       0.68      0.68      0.61        90\n",
      "\n",
      "[ 0 11  0  0  0 47  0  0  0  7  4  0  0 11  0 10]\n",
      "LR Accuracy:  0.6777777777777778\n",
      "LR F1:  0.4856805664830842\n",
      "For name:  m_andersson\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0001-7582-8791': 40, '0000-0002-7928-8216': 27, '0000-0003-4279-6572': 26, '0000-0002-4921-1461': 15, '0000-0002-3364-6647': 14, '0000-0002-1450-8046': 11, '0000-0002-7267-8377': 9, '0000-0003-3699-138X': 8, '0000-0003-0619-1074': 1, '0000-0001-5057-4908': 1})\n",
      "['0000-0002-1450-8046', '0000-0003-4279-6572', '0000-0001-7582-8791', '0000-0002-3364-6647', '0000-0002-4921-1461', '0000-0002-7928-8216']\n",
      "Total sample size after apply threshold:  133\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 423)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        11\n",
      "          1       1.00      0.69      0.82        26\n",
      "          2       0.59      1.00      0.74        40\n",
      "          3       1.00      0.57      0.73        14\n",
      "          4       1.00      0.67      0.80        15\n",
      "          5       0.88      0.81      0.85        27\n",
      "\n",
      "avg / total       0.85      0.77      0.77       133\n",
      "\n",
      "[ 4  0  7  0  0  0  0 18  6  0  0  2  0  0 40  0  0  0  0  0  5  8  0  1\n",
      "  0  0  5  0 10  0  0  0  5  0  0 22]\n",
      "MNB Accuracy:  0.7669172932330827\n",
      "MNB F1:  0.7442804109470775\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.96      0.88      0.92        26\n",
      "          2       0.75      1.00      0.86        40\n",
      "          3       1.00      0.79      0.88        14\n",
      "          4       1.00      0.80      0.89        15\n",
      "          5       0.92      0.85      0.88        27\n",
      "\n",
      "avg / total       0.90      0.88      0.88       133\n",
      "\n",
      "[ 8  1  1  0  0  1  0 23  3  0  0  0  0  0 40  0  0  0  0  0  2 11  0  1\n",
      "  0  0  3  0 12  0  0  0  4  0  0 23]\n",
      "svc Accuracy:  0.8796992481203008\n",
      "svc F1:  0.8793040984042682\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       1.00      0.58      0.73        26\n",
      "          2       0.56      1.00      0.72        40\n",
      "          3       1.00      0.64      0.78        14\n",
      "          4       1.00      0.67      0.80        15\n",
      "          5       0.87      0.74      0.80        27\n",
      "\n",
      "avg / total       0.84      0.74      0.75       133\n",
      "\n",
      "[ 5  0  6  0  0  0  0 15  9  0  0  2  0  0 40  0  0  0  0  0  4  9  0  1\n",
      "  0  0  5  0 10  0  0  0  7  0  0 20]\n",
      "LR Accuracy:  0.7443609022556391\n",
      "LR F1:  0.7433394555743442\n",
      "For name:  h_shi\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0001-8421-0002': 5, '0000-0003-1920-5914': 4, '0000-0002-9523-7742': 4, '0000-0003-0713-4688': 4, '0000-0001-6269-742X': 2, '0000-0003-3831-6898': 1, '0000-0001-6482-8403': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_howard\n",
      "total sample size before apply threshold:  79\n",
      "Counter({'0000-0001-9516-9551': 31, '0000-0001-9141-5751': 28, '0000-0002-4907-4292': 19, '0000-0003-3333-9783': 1})\n",
      "['0000-0001-9141-5751', '0000-0002-4907-4292', '0000-0001-9516-9551']\n",
      "Total sample size after apply threshold:  78\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 162)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.79      0.81        28\n",
      "          1       1.00      0.47      0.64        19\n",
      "          2       0.63      0.87      0.73        31\n",
      "\n",
      "avg / total       0.80      0.74      0.74        78\n",
      "\n",
      "[22  0  6  0  9 10  4  0 27]\n",
      "MNB Accuracy:  0.7435897435897436\n",
      "MNB F1:  0.7291338958005625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        28\n",
      "          1       1.00      0.58      0.73        19\n",
      "          2       0.67      1.00      0.81        31\n",
      "\n",
      "avg / total       0.87      0.81      0.81        78\n",
      "\n",
      "[21  0  7  0 11  8  0  0 31]\n",
      "svc Accuracy:  0.8076923076923077\n",
      "svc F1:  0.7985569985569986\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        28\n",
      "          1       1.00      0.32      0.48        19\n",
      "          2       0.58      1.00      0.74        31\n",
      "\n",
      "avg / total       0.84      0.72      0.70        78\n",
      "\n",
      "[19  0  9  0  6 13  0  0 31]\n",
      "LR Accuracy:  0.717948717948718\n",
      "LR F1:  0.6755352921310368\n",
      "For name:  j_thomsen\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-9336-5695': 18, '0000-0003-2143-8274': 8, '0000-0002-7368-6133': 1, '0000-0002-8275-4847': 1})\n",
      "['0000-0002-9336-5695']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  v_gupta\n",
      "total sample size before apply threshold:  238\n",
      "Counter({'0000-0002-8850-0485': 63, '0000-0002-6139-1346': 38, '0000-0002-1348-3545': 30, '0000-0002-9190-1757': 26, '0000-0003-4639-3316': 22, '0000-0001-6987-2550': 14, '0000-0002-6157-3705': 14, '0000-0002-1518-6624': 8, '0000-0002-2089-027X': 6, '0000-0003-2809-2966': 5, '0000-0003-1567-1037': 3, '0000-0001-7184-4663': 3, '0000-0003-1565-5918': 3, '0000-0003-2824-3402': 1, '0000-0001-6804-3830': 1, '0000-0001-6955-9134': 1})\n",
      "['0000-0001-6987-2550', '0000-0003-4639-3316', '0000-0002-6157-3705', '0000-0002-8850-0485', '0000-0002-1348-3545', '0000-0002-9190-1757', '0000-0002-6139-1346']\n",
      "Total sample size after apply threshold:  207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(207, 407)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.90      0.41      0.56        22\n",
      "          2       1.00      0.36      0.53        14\n",
      "          3       0.52      0.98      0.68        63\n",
      "          4       1.00      0.87      0.93        30\n",
      "          5       1.00      0.46      0.63        26\n",
      "          6       0.97      0.89      0.93        38\n",
      "\n",
      "avg / total       0.77      0.71      0.69       207\n",
      "\n",
      "[ 0  0  0 14  0  0  0  0  9  0 13  0  0  0  0  0  5  9  0  0  0  0  1  0\n",
      " 62  0  0  0  0  0  0  4 26  0  0  0  0  0 13  0 12  1  0  0  0  4  0  0\n",
      " 34]\n",
      "MNB Accuracy:  0.714975845410628\n",
      "MNB F1:  0.6088273851496121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        14\n",
      "          1       0.79      0.50      0.61        22\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       0.66      0.98      0.79        63\n",
      "          4       1.00      0.83      0.91        30\n",
      "          5       0.91      0.77      0.83        26\n",
      "          6       1.00      0.89      0.94        38\n",
      "\n",
      "avg / total       0.86      0.82      0.82       207\n",
      "\n",
      "[ 9  0  0  5  0  0  0  0 11  0 10  0  1  0  0  1  9  3  0  1  0  0  1  0\n",
      " 62  0  0  0  0  1  0  4 25  0  0  0  0  0  6  0 20  0  0  0  0  4  0  0\n",
      " 34]\n",
      "svc Accuracy:  0.821256038647343\n",
      "svc F1:  0.8075723009259426\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.91      0.45      0.61        22\n",
      "          2       1.00      0.50      0.67        14\n",
      "          3       0.56      0.98      0.71        63\n",
      "          4       0.93      0.87      0.90        30\n",
      "          5       1.00      0.58      0.73        26\n",
      "          6       1.00      0.92      0.96        38\n",
      "\n",
      "avg / total       0.78      0.75      0.72       207\n",
      "\n",
      "[ 0  0  0 14  0  0  0  0 10  0 10  2  0  0  0  0  7  7  0  0  0  0  1  0\n",
      " 62  0  0  0  0  0  0  4 26  0  0  0  0  0 11  0 15  0  0  0  0  3  0  0\n",
      " 35]\n",
      "LR Accuracy:  0.748792270531401\n",
      "LR F1:  0.6532191573840479\n",
      "For name:  j_manning\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-7613-4732': 8, '0000-0002-6077-4169': 6, '0000-0002-3572-8005': 1, '0000-0003-2257-6556': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_wood\n",
      "total sample size before apply threshold:  97\n",
      "Counter({'0000-0002-9495-6892': 82, '0000-0002-1694-3295': 11, '0000-0002-7906-3324': 2, '0000-0002-3476-395X': 1, '0000-0001-6389-1048': 1})\n",
      "['0000-0002-9495-6892', '0000-0002-1694-3295']\n",
      "Total sample size after apply threshold:  93\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(93, 338)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        82\n",
      "          1       1.00      0.09      0.17        11\n",
      "\n",
      "avg / total       0.90      0.89      0.85        93\n",
      "\n",
      "[82  0 10  1]\n",
      "MNB Accuracy:  0.8924731182795699\n",
      "MNB F1:  0.5545977011494253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        82\n",
      "          1       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.94      0.94      0.92        93\n",
      "\n",
      "[82  0  6  5]\n",
      "svc Accuracy:  0.9354838709677419\n",
      "svc F1:  0.7948529411764707\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        82\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.78      0.88      0.83        93\n",
      "\n",
      "[82  0 11  0]\n",
      "LR Accuracy:  0.8817204301075269\n",
      "LR F1:  0.4685714285714285\n",
      "For name:  y_ding\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0003-1352-1000': 21, '0000-0002-6823-4722': 21, '0000-0001-7772-6449': 19, '0000-0002-8845-4618': 15, '0000-0001-7461-0213': 8, '0000-0001-8161-2743': 7, '0000-0003-4761-5486': 4, '0000-0003-0465-7870': 4, '0000-0003-1176-6397': 3, '0000-0001-8312-8672': 2, '0000-0002-9713-5694': 1, '0000-0002-0010-8279': 1})\n",
      "['0000-0003-1352-1000', '0000-0002-6823-4722', '0000-0002-8845-4618', '0000-0001-7772-6449']\n",
      "Total sample size after apply threshold:  76\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(76, 185)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "76\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.71      0.81        21\n",
      "          1       0.91      1.00      0.95        21\n",
      "          2       1.00      1.00      1.00        15\n",
      "          3       0.82      0.95      0.88        19\n",
      "\n",
      "avg / total       0.91      0.91      0.90        76\n",
      "\n",
      "[15  2  0  4  0 21  0  0  0  0 15  0  1  0  0 18]\n",
      "MNB Accuracy:  0.9078947368421053\n",
      "MNB F1:  0.9108512614610176\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        21\n",
      "          1       1.00      0.95      0.98        21\n",
      "          2       1.00      1.00      1.00        15\n",
      "          3       0.90      0.95      0.92        19\n",
      "\n",
      "avg / total       0.96      0.96      0.96        76\n",
      "\n",
      "[20  0  0  1  0 20  0  1  0  0 15  0  1  0  0 18]\n",
      "svc Accuracy:  0.9605263157894737\n",
      "svc F1:  0.9627669078888592\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.95      0.89        21\n",
      "          1       1.00      0.86      0.92        21\n",
      "          2       1.00      1.00      1.00        15\n",
      "          3       0.89      0.89      0.89        19\n",
      "\n",
      "avg / total       0.93      0.92      0.92        76\n",
      "\n",
      "[20  0  0  1  2 18  0  1  0  0 15  0  2  0  0 17]\n",
      "LR Accuracy:  0.9210526315789473\n",
      "LR F1:  0.9266756635177688\n",
      "For name:  j_rasmussen\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0002-3543-690X': 15, '0000-0001-6997-3773': 9, '0000-0003-2898-1771': 6, '0000-0002-8389-6935': 1, '0000-0003-3426-551X': 1, '0000-0003-3257-5653': 1})\n",
      "['0000-0002-3543-690X']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  n_lee\n",
      "total sample size before apply threshold:  108\n",
      "Counter({'0000-0002-5011-7499': 74, '0000-0002-6663-0713': 20, '0000-0003-2628-6599': 12, '0000-0001-8009-2694': 1, '0000-0002-2756-1102': 1})\n",
      "['0000-0003-2628-6599', '0000-0002-5011-7499', '0000-0002-6663-0713']\n",
      "Total sample size after apply threshold:  106\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 186)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "106\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       0.95      1.00      0.97        74\n",
      "          2       1.00      0.95      0.97        20\n",
      "\n",
      "avg / total       0.96      0.96      0.96       106\n",
      "\n",
      "[ 9  3  0  0 74  0  0  1 19]\n",
      "MNB Accuracy:  0.9622641509433962\n",
      "MNB F1:  0.9350620140093824\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        12\n",
      "          1       0.96      1.00      0.98        74\n",
      "          2       1.00      0.95      0.97        20\n",
      "\n",
      "avg / total       0.97      0.97      0.97       106\n",
      "\n",
      "[10  2  0  0 74  0  0  1 19]\n",
      "svc Accuracy:  0.9716981132075472\n",
      "svc F1:  0.9545274445936697\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.87      1.00      0.93        74\n",
      "          2       1.00      0.75      0.86        20\n",
      "\n",
      "avg / total       0.91      0.90      0.89       106\n",
      "\n",
      "[ 6  6  0  0 74  0  0  5 15]\n",
      "LR Accuracy:  0.8962264150943396\n",
      "LR F1:  0.818209044624139\n",
      "For name:  a_oliveira\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  302\n",
      "Counter({'0000-0001-9103-6532': 41, '0000-0003-2186-8100': 24, '0000-0002-6714-5939': 24, '0000-0002-0107-9940': 24, '0000-0001-8012-4203': 20, '0000-0001-8638-5594': 20, '0000-0003-3787-9138': 12, '0000-0003-2790-6294': 12, '0000-0001-6837-5739': 10, '0000-0001-5445-1032': 8, '0000-0001-8753-4950': 8, '0000-0002-7898-5503': 7, '0000-0003-4516-6904': 6, '0000-0003-3162-250X': 6, '0000-0002-0330-3643': 5, '0000-0003-1554-4687': 5, '0000-0003-0402-2971': 5, '0000-0003-4158-6098': 5, '0000-0002-0747-7835': 4, '0000-0002-6477-5345': 4, '0000-0002-0841-4844': 4, '0000-0002-0685-2963': 4, '0000-0001-5526-8109': 4, '0000-0001-5611-6385': 3, '0000-0002-2308-9904': 3, '0000-0001-9287-0959': 3, '0000-0001-6532-1700': 3, '0000-0003-0593-4665': 3, '0000-0002-6859-084X': 3, '0000-0002-2220-5862': 2, '0000-0001-9605-6276': 2, '0000-0001-9955-0915': 2, '0000-0003-1202-7748': 2, '0000-0002-5614-229X': 2, '0000-0003-1214-8240': 2, '0000-0001-8144-4583': 1, '0000-0002-7284-9359': 1, '0000-0001-5098-3939': 1, '0000-0001-6422-9486': 1, '0000-0002-3070-1604': 1, '0000-0001-7690-7037': 1, '0000-0002-8453-1719': 1, '0000-0002-2977-6000': 1, '0000-0002-7537-0984': 1, '0000-0003-2763-9501': 1})\n",
      "['0000-0003-3787-9138', '0000-0001-8012-4203', '0000-0001-8638-5594', '0000-0003-2186-8100', '0000-0003-2790-6294', '0000-0001-6837-5739', '0000-0002-6714-5939', '0000-0002-0107-9940', '0000-0001-9103-6532']\n",
      "Total sample size after apply threshold:  187\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(187, 409)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "187\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       1.00      0.75      0.86        20\n",
      "          2       1.00      0.55      0.71        20\n",
      "          3       0.96      1.00      0.98        24\n",
      "          4       1.00      0.17      0.29        12\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.92      1.00      0.96        24\n",
      "          7       1.00      0.92      0.96        24\n",
      "          8       0.48      1.00      0.65        41\n",
      "\n",
      "avg / total       0.75      0.74      0.70       187\n",
      "\n",
      "[ 0  0  0  0  0  0  0  0 12  0 15  0  0  0  0  0  0  5  0  0 11  1  0  0\n",
      "  0  0  8  0  0  0 24  0  0  0  0  0  0  0  0  0  2  0  0  0 10  0  0  0\n",
      "  0  0  0  2  0  8  0  0  0  0  0  0 24  0  0  0  0  0  0  0  0  0 22  2\n",
      "  0  0  0  0  0  0  0  0 41]\n",
      "MNB Accuracy:  0.7433155080213903\n",
      "MNB F1:  0.5993686032684102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        12\n",
      "          1       1.00      0.90      0.95        20\n",
      "          2       0.93      0.65      0.76        20\n",
      "          3       1.00      0.96      0.98        24\n",
      "          4       1.00      0.58      0.74        12\n",
      "          5       1.00      0.90      0.95        10\n",
      "          6       1.00      0.96      0.98        24\n",
      "          7       1.00      0.92      0.96        24\n",
      "          8       0.66      0.98      0.78        41\n",
      "\n",
      "avg / total       0.92      0.88      0.89       187\n",
      "\n",
      "[10  0  0  0  0  0  0  0  2  0 18  0  0  0  0  0  0  2  0  0 13  0  0  0\n",
      "  0  0  7  0  0  0 23  0  0  0  0  1  0  0  0  0  7  0  0  0  5  0  0  0\n",
      "  0  0  9  0  0  1  0  0  0  0  0  0 23  0  1  0  0  0  0  0  0  0 22  2\n",
      "  0  0  1  0  0  0  0  0 40]\n",
      "svc Accuracy:  0.8823529411764706\n",
      "svc F1:  0.8892953346603935\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       1.00      0.90      0.95        20\n",
      "          2       1.00      0.60      0.75        20\n",
      "          3       0.96      1.00      0.98        24\n",
      "          4       1.00      0.42      0.59        12\n",
      "          5       1.00      0.60      0.75        10\n",
      "          6       0.96      0.96      0.96        24\n",
      "          7       1.00      0.88      0.93        24\n",
      "          8       0.57      1.00      0.73        41\n",
      "\n",
      "avg / total       0.90      0.82      0.82       187\n",
      "\n",
      "[ 4  0  0  0  0  0  0  0  8  0 18  0  0  0  0  0  0  2  0  0 12  1  0  0\n",
      "  0  0  7  0  0  0 24  0  0  0  0  0  0  0  0  0  5  0  0  0  7  0  0  0\n",
      "  0  0  6  1  0  3  0  0  0  0  0  0 23  0  1  0  0  0  0  0  0  0 21  3\n",
      "  0  0  0  0  0  0  0  0 41]\n",
      "LR Accuracy:  0.8235294117647058\n",
      "LR F1:  0.7925028817095331\n",
      "For name:  h_yin\n",
      "total sample size before apply threshold:  130\n",
      "Counter({'0000-0002-9762-4818': 69, '0000-0001-7693-377X': 32, '0000-0002-0720-5311': 13, '0000-0002-0810-1696': 5, '0000-0001-6553-0887': 5, '0000-0003-1765-496X': 4, '0000-0002-1175-4516': 1, '0000-0002-0682-6781': 1})\n",
      "['0000-0002-9762-4818', '0000-0001-7693-377X', '0000-0002-0720-5311']\n",
      "Total sample size after apply threshold:  114\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 301)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "114\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.99      0.84        69\n",
      "          1       0.95      0.62      0.75        32\n",
      "          2       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.71      0.77      0.72       114\n",
      "\n",
      "[68  1  0 12 20  0 13  0  0]\n",
      "MNB Accuracy:  0.7719298245614035\n",
      "MNB F1:  0.5314077179905272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.97      0.86        69\n",
      "          1       0.95      0.62      0.75        32\n",
      "          2       0.83      0.38      0.53        13\n",
      "\n",
      "avg / total       0.83      0.81      0.79       114\n",
      "\n",
      "[67  1  1 12 20  0  8  0  5]\n",
      "svc Accuracy:  0.8070175438596491\n",
      "svc F1:  0.7133357098600395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.83        69\n",
      "          1       1.00      0.44      0.61        32\n",
      "          2       1.00      0.15      0.27        13\n",
      "\n",
      "avg / total       0.82      0.75      0.70       114\n",
      "\n",
      "[69  0  0 18 14  0 11  0  2]\n",
      "LR Accuracy:  0.7456140350877193\n",
      "LR F1:  0.5672365414099337\n",
      "For name:  k_brown\n",
      "total sample size before apply threshold:  231\n",
      "Counter({'0000-0003-2434-0037': 89, '0000-0002-0729-4959': 61, '0000-0003-3382-5546': 33, '0000-0002-6803-5336': 12, '0000-0003-2472-5754': 9, '0000-0001-7716-1425': 7, '0000-0001-9428-9420': 6, '0000-0002-1047-4328': 3, '0000-0001-6836-1572': 3, '0000-0001-8350-5888': 2, '0000-0001-7766-6810': 1, '0000-0002-0201-0558': 1, '0000-0002-2358-8578': 1, '0000-0002-9093-8742': 1, '0000-0001-5348-7893': 1, '0000-0001-5748-5123': 1})\n",
      "['0000-0003-2434-0037', '0000-0003-3382-5546', '0000-0002-0729-4959', '0000-0002-6803-5336']\n",
      "Total sample size after apply threshold:  195\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(195, 534)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "195\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91        89\n",
      "          1       1.00      0.79      0.88        33\n",
      "          2       0.95      0.87      0.91        61\n",
      "          3       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.91      0.90      0.90       195\n",
      "\n",
      "[88  0  1  0  7 26  0  0  8  0 53  0  2  0  2  8]\n",
      "MNB Accuracy:  0.8974358974358975\n",
      "MNB F1:  0.8736388332579141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95        89\n",
      "          1       1.00      0.82      0.90        33\n",
      "          2       0.79      1.00      0.88        61\n",
      "          3       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.93      0.91      0.91       195\n",
      "\n",
      "[81  0  8  0  1 27  5  0  0  0 61  0  0  0  3  9]\n",
      "svc Accuracy:  0.9128205128205128\n",
      "svc F1:  0.8971423123024954\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.96      0.89        89\n",
      "          1       1.00      0.73      0.84        33\n",
      "          2       0.89      0.89      0.89        61\n",
      "          3       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.88      0.87      0.87       195\n",
      "\n",
      "[85  0  4  0  8 24  1  0  7  0 54  0  3  0  2  7]\n",
      "LR Accuracy:  0.8717948717948718\n",
      "LR F1:  0.837402484181766\n",
      "For name:  s_hong\n",
      "total sample size before apply threshold:  383\n",
      "Counter({'0000-0002-8344-6774': 102, '0000-0002-8888-6007': 84, '0000-0002-0300-1944': 83, '0000-0002-6305-8731': 27, '0000-0001-7291-1020': 19, '0000-0002-0324-2414': 15, '0000-0003-3031-2753': 12, '0000-0003-2401-6368': 12, '0000-0002-2667-1983': 10, '0000-0003-4926-1044': 3, '0000-0002-0020-6215': 3, '0000-0002-8473-919X': 2, '0000-0002-4800-636X': 2, '0000-0001-8722-3124': 1, '0000-0002-6905-7932': 1, '0000-0002-3755-3683': 1, '0000-0002-2498-7546': 1, '0000-0002-9470-5700': 1, '0000-0003-1119-4456': 1, '0000-0001-5049-8810': 1, '0000-0003-0721-4012': 1, '0000-0003-4989-292X': 1})\n",
      "['0000-0002-8888-6007', '0000-0003-3031-2753', '0000-0002-2667-1983', '0000-0002-8344-6774', '0000-0001-7291-1020', '0000-0002-0324-2414', '0000-0003-2401-6368', '0000-0002-6305-8731', '0000-0002-0300-1944']\n",
      "Total sample size after apply threshold:  364\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(364, 476)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        84\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.64      0.99      0.78       102\n",
      "          4       0.00      0.00      0.00        19\n",
      "          5       0.00      0.00      0.00        15\n",
      "          6       0.00      0.00      0.00        12\n",
      "          7       1.00      0.48      0.65        27\n",
      "          8       0.57      0.89      0.70        83\n",
      "\n",
      "avg / total       0.62      0.70      0.63       364\n",
      "\n",
      "[ 65   0   0  10   0   0   0   0   9   0   0   0   2   0   0   0   0  10\n",
      "   0   0   0   4   0   0   0   0   6   0   0   0 101   0   0   0   0   1\n",
      "   0   0   0  10   0   0   0   0   9   0   0   0  10   0   0   0   0   5\n",
      "   0   0   0   5   0   0   0   0   7   0   0   0   6   0   0   0  13   8\n",
      "   0   0   0   9   0   0   0   0  74]\n",
      "MNB Accuracy:  0.695054945054945\n",
      "MNB F1:  0.33339102321627334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.93      0.84        84\n",
      "          1       0.89      0.67      0.76        12\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.90      0.95      0.92       102\n",
      "          4       0.75      0.47      0.58        19\n",
      "          5       0.50      0.13      0.21        15\n",
      "          6       1.00      0.83      0.91        12\n",
      "          7       0.96      0.81      0.88        27\n",
      "          8       0.73      0.84      0.78        83\n",
      "\n",
      "avg / total       0.79      0.81      0.79       364\n",
      "\n",
      "[78  0  0  1  1  0  0  0  4  2  8  0  0  0  0  0  0  2  6  0  0  0  0  0\n",
      "  0  0  4  3  0  0 97  0  0  0  0  2  2  0  0  3  9  0  0  0  5  2  1  0\n",
      "  5  0  2  0  0  5  1  0  0  0  0  1 10  0  0  1  0  0  0  0  0  0 22  4\n",
      "  7  0  0  2  2  1  0  1 70]\n",
      "svc Accuracy:  0.8131868131868132\n",
      "svc F1:  0.654089917148031\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.93      0.80        84\n",
      "          1       0.75      0.25      0.38        12\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.82      0.96      0.88       102\n",
      "          4       1.00      0.21      0.35        19\n",
      "          5       0.00      0.00      0.00        15\n",
      "          6       1.00      0.58      0.74        12\n",
      "          7       0.96      0.81      0.88        27\n",
      "          8       0.73      0.84      0.78        83\n",
      "\n",
      "avg / total       0.74      0.77      0.73       364\n",
      "\n",
      "[78  0  0  2  0  0  0  0  4  4  3  0  1  0  0  0  0  4  6  0  0  1  0  0\n",
      "  0  0  3  3  0  0 98  0  0  0  0  1  4  0  0  7  4  0  0  0  4  1  1  0\n",
      "  6  0  0  0  0  7  4  0  0  0  0  0  7  1  0  2  0  0  0  0  0  0 22  3\n",
      "  8  0  0  5  0  0  0  0 70]\n",
      "LR Accuracy:  0.7747252747252747\n",
      "LR F1:  0.5343108546078557\n",
      "For name:  l_zhou\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0001-5973-7873': 16, '0000-0003-2800-5981': 10, '0000-0001-9014-6350': 8, '0000-0001-8900-2835': 6, '0000-0002-0393-4787': 4, '0000-0001-9032-0910': 3, '0000-0002-0133-3048': 1, '0000-0001-8554-0900': 1})\n",
      "['0000-0001-5973-7873', '0000-0003-2800-5981']\n",
      "Total sample size after apply threshold:  26\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 58)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        16\n",
      "          1       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.97      0.96      0.96        26\n",
      "\n",
      "[15  1  0 10]\n",
      "MNB Accuracy:  0.9615384615384616\n",
      "MNB F1:  0.9600614439324117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        26\n",
      "\n",
      "[16  0  0 10]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        16\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[16  0  1  9]\n",
      "LR Accuracy:  0.9615384615384616\n",
      "LR F1:  0.9585326953748007\n",
      "For name:  h_jiang\n",
      "total sample size before apply threshold:  135\n",
      "Counter({'0000-0002-2975-7977': 52, '0000-0002-5778-4008': 16, '0000-0002-1947-4420': 15, '0000-0002-4388-6548': 13, '0000-0003-0561-5058': 10, '0000-0002-1156-9046': 8, '0000-0001-9892-4292': 4, '0000-0002-4577-2886': 4, '0000-0003-3187-2023': 3, '0000-0002-5840-007X': 3, '0000-0003-4173-8565': 3, '0000-0002-7827-0719': 1, '0000-0002-0962-902X': 1, '0000-0003-0951-0624': 1, '0000-0001-6460-408X': 1})\n",
      "['0000-0002-4388-6548', '0000-0002-1947-4420', '0000-0003-0561-5058', '0000-0002-5778-4008', '0000-0002-2975-7977']\n",
      "Total sample size after apply threshold:  106\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 191)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "106\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       1.00      0.07      0.12        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       1.00      0.69      0.81        16\n",
      "          4       0.55      1.00      0.71        52\n",
      "\n",
      "avg / total       0.56      0.60      0.49       106\n",
      "\n",
      "[ 0  0  0  0 13  0  1  0  0 14  0  0  0  0 10  0  0  0 11  5  0  0  0  0\n",
      " 52]\n",
      "MNB Accuracy:  0.6037735849056604\n",
      "MNB F1:  0.33042871638762045\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.77      0.83        13\n",
      "          1       0.86      0.40      0.55        15\n",
      "          2       0.67      0.60      0.63        10\n",
      "          3       1.00      0.88      0.93        16\n",
      "          4       0.74      0.92      0.82        52\n",
      "\n",
      "avg / total       0.81      0.79      0.78       106\n",
      "\n",
      "[10  0  0  0  3  0  6  1  0  8  0  0  6  0  4  0  0  0 14  2  1  1  2  0\n",
      " 48]\n",
      "svc Accuracy:  0.7924528301886793\n",
      "svc F1:  0.7528425960004909\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.54      0.67        13\n",
      "          1       1.00      0.07      0.12        15\n",
      "          2       1.00      0.30      0.46        10\n",
      "          3       1.00      0.56      0.72        16\n",
      "          4       0.60      0.98      0.74        52\n",
      "\n",
      "avg / total       0.79      0.67      0.62       106\n",
      "\n",
      "[ 7  0  0  0  6  0  1  0  0 14  0  0  3  0  7  0  0  0  9  7  1  0  0  0\n",
      " 51]\n",
      "LR Accuracy:  0.6698113207547169\n",
      "LR F1:  0.5435461351300768\n",
      "For name:  a_lewis\n",
      "total sample size before apply threshold:  98\n",
      "Counter({'0000-0002-4075-3651': 41, '0000-0002-2519-7976': 37, '0000-0002-7986-0956': 8, '0000-0002-0756-7320': 6, '0000-0002-4195-1035': 4, '0000-0001-5373-7231': 1, '0000-0003-4737-2525': 1})\n",
      "['0000-0002-2519-7976', '0000-0002-4075-3651']\n",
      "Total sample size after apply threshold:  78\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(78, 207)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        37\n",
      "          1       0.93      0.93      0.93        41\n",
      "\n",
      "avg / total       0.92      0.92      0.92        78\n",
      "\n",
      "[34  3  3 38]\n",
      "MNB Accuracy:  0.9230769230769231\n",
      "MNB F1:  0.922874093605801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        37\n",
      "          1       0.93      0.93      0.93        41\n",
      "\n",
      "avg / total       0.92      0.92      0.92        78\n",
      "\n",
      "[34  3  3 38]\n",
      "svc Accuracy:  0.9230769230769231\n",
      "svc F1:  0.922874093605801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.89      0.90        37\n",
      "          1       0.90      0.93      0.92        41\n",
      "\n",
      "avg / total       0.91      0.91      0.91        78\n",
      "\n",
      "[33  4  3 38]\n",
      "LR Accuracy:  0.9102564102564102\n",
      "LR F1:  0.9098861198217527\n",
      "For name:  c_meyer\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0001-7599-3973': 34, '0000-0002-9877-1393': 29, '0000-0003-1334-2512': 27, '0000-0002-7214-9598': 18, '0000-0002-2268-3055': 14, '0000-0003-0851-2767': 6, '0000-0001-9958-8913': 5, '0000-0002-3166-3101': 3})\n",
      "['0000-0002-9877-1393', '0000-0001-7599-3973', '0000-0003-1334-2512', '0000-0002-7214-9598', '0000-0002-2268-3055']\n",
      "Total sample size after apply threshold:  122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(122, 806)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "122\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        29\n",
      "          1       1.00      0.97      0.99        34\n",
      "          2       0.92      0.89      0.91        27\n",
      "          3       1.00      0.94      0.97        18\n",
      "          4       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       0.96      0.96      0.96       122\n",
      "\n",
      "[29  0  0  0  0  0 33  1  0  0  3  0 24  0  0  0  0  1 17  0  0  0  0  0\n",
      " 14]\n",
      "MNB Accuracy:  0.9590163934426229\n",
      "MNB F1:  0.9625966495567763\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        29\n",
      "          1       1.00      0.97      0.99        34\n",
      "          2       0.93      1.00      0.96        27\n",
      "          3       1.00      0.94      0.97        18\n",
      "          4       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       0.98      0.98      0.98       122\n",
      "\n",
      "[29  0  0  0  0  0 33  1  0  0  0  0 27  0  0  0  0  1 17  0  0  0  0  0\n",
      " 14]\n",
      "svc Accuracy:  0.9836065573770492\n",
      "svc F1:  0.9841577825159915\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        29\n",
      "          1       1.00      0.97      0.99        34\n",
      "          2       0.86      0.89      0.87        27\n",
      "          3       1.00      0.83      0.91        18\n",
      "          4       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       0.95      0.94      0.94       122\n",
      "\n",
      "[29  0  0  0  0  0 33  1  0  0  3  0 24  0  0  0  0  3 15  0  0  0  0  0\n",
      " 14]\n",
      "LR Accuracy:  0.9426229508196722\n",
      "LR F1:  0.9435424961630001\n",
      "For name:  a_islam\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0003-3375-9817': 5, '0000-0001-9060-7970': 4, '0000-0002-2139-7508': 3, '0000-0003-1561-0680': 2, '0000-0002-7274-0855': 1, '0000-0002-9902-0639': 1, '0000-0001-8270-5968': 1, '0000-0001-9608-0823': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  k_fujita\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-3821-8393': 16, '0000-0002-6902-9085': 10, '0000-0002-2518-2125': 6, '0000-0002-1477-5187': 5, '0000-0001-7556-4714': 3, '0000-0002-1900-5325': 1, '0000-0002-1744-3583': 1})\n",
      "['0000-0002-6902-9085', '0000-0002-3821-8393']\n",
      "Total sample size after apply threshold:  26\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 52)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.94      1.00      0.97        16\n",
      "\n",
      "avg / total       0.96      0.96      0.96        26\n",
      "\n",
      "[ 9  1  0 16]\n",
      "MNB Accuracy:  0.9615384615384616\n",
      "MNB F1:  0.9585326953748007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00        26\n",
      "\n",
      "[10  0  0 16]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.89      1.00      0.94        16\n",
      "\n",
      "avg / total       0.93      0.92      0.92        26\n",
      "\n",
      "[ 8  2  0 16]\n",
      "LR Accuracy:  0.9230769230769231\n",
      "LR F1:  0.9150326797385622\n",
      "For name:  a_khan\n",
      "total sample size before apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "Counter({'0000-0001-8640-8530': 59, '0000-0002-2571-3600': 24, '0000-0001-5129-756X': 19, '0000-0002-0760-8647': 14, '0000-0003-3490-799X': 13, '0000-0003-3655-2854': 12, '0000-0003-0254-3546': 11, '0000-0002-0751-0930': 9, '0000-0001-5955-3783': 9, '0000-0002-9325-6640': 8, '0000-0002-8748-1841': 7, '0000-0002-8748-4065': 5, '0000-0003-4057-8053': 5, '0000-0002-3806-5956': 5, '0000-0002-5796-6573': 4, '0000-0002-6655-129X': 3, '0000-0001-6079-0567': 3, '0000-0002-0007-2536': 3, '0000-0001-9293-3999': 2, '0000-0002-3746-5034': 2, '0000-0002-2048-225X': 2, '0000-0001-9338-9323': 2, '0000-0002-7524-6270': 1, '0000-0003-3340-3036': 1, '0000-0003-1562-2577': 1, '0000-0001-7763-1490': 1, '0000-0002-0338-8325': 1})\n",
      "['0000-0003-3490-799X', '0000-0001-5129-756X', '0000-0002-0760-8647', '0000-0003-3655-2854', '0000-0003-0254-3546', '0000-0001-8640-8530', '0000-0002-2571-3600']\n",
      "Total sample size after apply threshold:  152\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(152, 365)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "152\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.14        13\n",
      "          1       1.00      0.53      0.69        19\n",
      "          2       1.00      0.29      0.44        14\n",
      "          3       1.00      0.25      0.40        12\n",
      "          4       1.00      0.27      0.43        11\n",
      "          5       0.54      1.00      0.70        59\n",
      "          6       0.81      0.71      0.76        24\n",
      "\n",
      "avg / total       0.79      0.64      0.59       152\n",
      "\n",
      "[ 1  0  0  0  0  8  4  0 10  0  0  0  9  0  0  0  4  0  0 10  0  0  0  0\n",
      "  3  0  9  0  0  0  0  0  3  8  0  0  0  0  0  0 59  0  0  0  0  0  0  7\n",
      " 17]\n",
      "MNB Accuracy:  0.6381578947368421\n",
      "MNB F1:  0.5084726565590529\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.31      0.42        13\n",
      "          1       0.93      0.68      0.79        19\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       1.00      0.67      0.80        12\n",
      "          4       1.00      0.64      0.78        11\n",
      "          5       0.69      1.00      0.82        59\n",
      "          6       0.83      0.79      0.81        24\n",
      "\n",
      "avg / total       0.82      0.78      0.77       152\n",
      "\n",
      "[ 4  0  0  0  0  5  4  0 13  0  0  0  6  0  0  1  9  0  0  4  0  0  0  0\n",
      "  8  0  4  0  0  0  0  0  7  4  0  0  0  0  0  0 59  0  2  0  0  0  0  3\n",
      " 19]\n",
      "svc Accuracy:  0.7828947368421053\n",
      "svc F1:  0.7424675679471434\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.15      0.25        13\n",
      "          1       1.00      0.53      0.69        19\n",
      "          2       1.00      0.36      0.53        14\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       1.00      0.55      0.71        11\n",
      "          5       0.55      1.00      0.71        59\n",
      "          6       0.93      0.58      0.72        24\n",
      "\n",
      "avg / total       0.79      0.67      0.65       152\n",
      "\n",
      "[ 2  0  0  0  0 10  1  0 10  0  0  0  9  0  0  0  5  0  0  9  0  0  0  0\n",
      "  6  0  6  0  0  0  0  0  6  5  0  0  0  0  0  0 59  0  1  0  0  0  0  9\n",
      " 14]\n",
      "LR Accuracy:  0.6710526315789473\n",
      "LR F1:  0.6096160104197164\n",
      "For name:  a_kim\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-4074-0516': 8, '0000-0001-8263-6528': 6, '0000-0003-2861-8366': 2, '0000-0003-4101-6642': 2, '0000-0003-1861-3801': 2, '0000-0002-8733-6046': 2, '0000-0002-8390-0041': 1, '0000-0001-8484-5892': 1, '0000-0003-1539-1246': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_martinez\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0002-6681-4950': 29, '0000-0003-2180-4537': 28, '0000-0002-6289-4586': 3, '0000-0003-0260-2366': 3, '0000-0003-2166-1097': 2, '0000-0002-4386-3290': 1, '0000-0001-9645-5058': 1, '0000-0003-0741-2940': 1, '0000-0003-2137-8048': 1})\n",
      "['0000-0002-6681-4950', '0000-0003-2180-4537']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 433)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        29\n",
      "          1       1.00      0.86      0.92        28\n",
      "\n",
      "avg / total       0.94      0.93      0.93        57\n",
      "\n",
      "[29  0  4 24]\n",
      "MNB Accuracy:  0.9298245614035088\n",
      "MNB F1:  0.9292803970223324\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        29\n",
      "          1       0.93      1.00      0.97        28\n",
      "\n",
      "avg / total       0.97      0.96      0.96        57\n",
      "\n",
      "[27  2  0 28]\n",
      "svc Accuracy:  0.9649122807017544\n",
      "svc F1:  0.9649014778325123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        29\n",
      "          1       0.93      0.93      0.93        28\n",
      "\n",
      "avg / total       0.93      0.93      0.93        57\n",
      "\n",
      "[27  2  2 26]\n",
      "LR Accuracy:  0.9298245614035088\n",
      "LR F1:  0.9298029556650247\n",
      "For name:  m_aslam\n",
      "total sample size before apply threshold:  55\n",
      "Counter({'0000-0003-1361-5357': 29, '0000-0002-8529-4217': 17, '0000-0001-8812-6887': 4, '0000-0001-9418-3714': 4, '0000-0003-2498-3526': 1})\n",
      "['0000-0003-1361-5357', '0000-0002-8529-4217']\n",
      "Total sample size after apply threshold:  46\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 147)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        29\n",
      "          1       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.96      0.96      0.96        46\n",
      "\n",
      "[29  0  2 15]\n",
      "MNB Accuracy:  0.9565217391304348\n",
      "MNB F1:  0.9520833333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        29\n",
      "          1       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.96      0.96      0.96        46\n",
      "\n",
      "[29  0  2 15]\n",
      "svc Accuracy:  0.9565217391304348\n",
      "svc F1:  0.9520833333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        29\n",
      "          1       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.92      0.91      0.91        46\n",
      "\n",
      "[29  0  4 13]\n",
      "LR Accuracy:  0.9130434782608695\n",
      "LR F1:  0.9010752688172042\n",
      "For name:  j_wolf\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0003-3112-6602': 56, '0000-0003-4129-8221': 3, '0000-0002-7825-3118': 3, '0000-0002-1437-982X': 2, '0000-0002-7458-2002': 1})\n",
      "['0000-0003-3112-6602']\n",
      "Total sample size after apply threshold:  56\n",
      "For name:  s_agrawal\n",
      "total sample size before apply threshold:  30\n",
      "Counter({'0000-0002-2806-1943': 20, '0000-0001-6295-6954': 6, '0000-0003-3214-786X': 2, '0000-0002-5524-6206': 2})\n",
      "['0000-0002-2806-1943']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  a_othman\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0002-0092-5594': 22, '0000-0002-3827-8695': 13, '0000-0002-2437-8564': 3, '0000-0002-3708-985X': 1, '0000-0002-3982-3157': 1})\n",
      "['0000-0002-3827-8695', '0000-0002-0092-5594']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 160)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.96      1.00      0.98        22\n",
      "\n",
      "avg / total       0.97      0.97      0.97        35\n",
      "\n",
      "[12  1  0 22]\n",
      "MNB Accuracy:  0.9714285714285714\n",
      "MNB F1:  0.9688888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.96      1.00      0.98        22\n",
      "\n",
      "avg / total       0.97      0.97      0.97        35\n",
      "\n",
      "[12  1  0 22]\n",
      "svc Accuracy:  0.9714285714285714\n",
      "svc F1:  0.9688888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82        13\n",
      "          1       0.85      1.00      0.92        22\n",
      "\n",
      "avg / total       0.90      0.89      0.88        35\n",
      "\n",
      "[ 9  4  0 22]\n",
      "LR Accuracy:  0.8857142857142857\n",
      "LR F1:  0.8674242424242424\n",
      "For name:  k_evans\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-6856-8423': 16, '0000-0002-9819-1049': 9, '0000-0001-6981-7703': 3, '0000-0003-2850-7674': 1})\n",
      "['0000-0002-6856-8423']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  k_yoo\n",
      "total sample size before apply threshold:  10\n",
      "Counter({'0000-0002-5213-4575': 7, '0000-0001-7952-7902': 1, '0000-0002-6186-7535': 1, '0000-0002-5539-345X': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_turner\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0002-3754-6459': 27, '0000-0003-1603-7994': 26, '0000-0002-3447-7662': 5, '0000-0002-0249-4513': 4, '0000-0002-8891-9155': 3, '0000-0002-7369-8791': 3, '0000-0002-2891-2664': 2, '0000-0001-6802-1703': 1})\n",
      "['0000-0002-3754-6459', '0000-0003-1603-7994']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 108)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        27\n",
      "          1       1.00      0.96      0.98        26\n",
      "\n",
      "avg / total       0.98      0.98      0.98        53\n",
      "\n",
      "[27  0  1 25]\n",
      "MNB Accuracy:  0.9811320754716981\n",
      "MNB F1:  0.9811051693404634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        27\n",
      "          1       1.00      0.88      0.94        26\n",
      "\n",
      "avg / total       0.95      0.94      0.94        53\n",
      "\n",
      "[27  0  3 23]\n",
      "svc Accuracy:  0.9433962264150944\n",
      "svc F1:  0.9430719656283566\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        27\n",
      "          1       1.00      0.88      0.94        26\n",
      "\n",
      "avg / total       0.95      0.94      0.94        53\n",
      "\n",
      "[27  0  3 23]\n",
      "LR Accuracy:  0.9433962264150944\n",
      "LR F1:  0.9430719656283566\n",
      "For name:  j_king\n",
      "total sample size before apply threshold:  75\n",
      "Counter({'0000-0003-0596-4506': 21, '0000-0002-8174-9173': 20, '0000-0003-4530-9987': 20, '0000-0002-6048-8277': 7, '0000-0003-2171-8321': 5, '0000-0003-4947-0241': 1, '0000-0003-0494-153X': 1})\n",
      "['0000-0002-8174-9173', '0000-0003-4530-9987', '0000-0003-0596-4506']\n",
      "Total sample size after apply threshold:  61\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 2671)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        20\n",
      "          1       0.83      0.75      0.79        20\n",
      "          2       0.82      0.86      0.84        21\n",
      "\n",
      "avg / total       0.87      0.87      0.87        61\n",
      "\n",
      "[20  0  0  1 15  4  0  3 18]\n",
      "MNB Accuracy:  0.8688524590163934\n",
      "MNB F1:  0.8674309142112229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        20\n",
      "          1       0.77      1.00      0.87        20\n",
      "          2       1.00      0.86      0.92        21\n",
      "\n",
      "avg / total       0.92      0.90      0.90        61\n",
      "\n",
      "[17  3  0  0 20  0  0  3 18]\n",
      "svc Accuracy:  0.9016393442622951\n",
      "svc F1:  0.9038536864623822\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        20\n",
      "          1       0.79      0.75      0.77        20\n",
      "          2       0.78      0.86      0.82        21\n",
      "\n",
      "avg / total       0.86      0.85      0.85        61\n",
      "\n",
      "[19  1  0  0 15  5  0  3 18]\n",
      "LR Accuracy:  0.8524590163934426\n",
      "LR F1:  0.853923853923854\n",
      "For name:  b_shen\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0003-2899-1531': 29, '0000-0002-5237-6144': 4, '0000-0003-3287-9438': 2, '0000-0001-9687-9010': 1})\n",
      "['0000-0003-2899-1531']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  s_mishra\n",
      "total sample size before apply threshold:  116\n",
      "Counter({'0000-0001-8492-5470': 29, '0000-0003-4091-3018': 24, '0000-0001-6080-4148': 16, '0000-0002-0403-6575': 16, '0000-0003-3511-8319': 8, '0000-0002-3080-9754': 5, '0000-0003-3899-0495': 5, '0000-0001-8151-2988': 3, '0000-0002-1016-0206': 3, '0000-0003-2049-3618': 2, '0000-0003-1003-9884': 2, '0000-0001-6634-1877': 1, '0000-0003-2846-4221': 1, '0000-0002-5202-2645': 1})\n",
      "['0000-0001-8492-5470', '0000-0001-6080-4148', '0000-0002-0403-6575', '0000-0003-4091-3018']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 240)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93        29\n",
      "          1       1.00      0.75      0.86        16\n",
      "          2       1.00      1.00      1.00        16\n",
      "          3       0.92      1.00      0.96        24\n",
      "\n",
      "avg / total       0.95      0.94      0.94        85\n",
      "\n",
      "[28  0  0  1  3 12  0  1  0  0 16  0  0  0  0 24]\n",
      "MNB Accuracy:  0.9411764705882353\n",
      "MNB F1:  0.9376190476190476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        29\n",
      "          1       1.00      0.88      0.93        16\n",
      "          2       1.00      1.00      1.00        16\n",
      "          3       1.00      1.00      1.00        24\n",
      "\n",
      "avg / total       0.98      0.98      0.98        85\n",
      "\n",
      "[29  0  0  0  2 14  0  0  0  0 16  0  0  0  0 24]\n",
      "svc Accuracy:  0.9764705882352941\n",
      "svc F1:  0.975\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89        29\n",
      "          1       1.00      0.62      0.77        16\n",
      "          2       1.00      1.00      1.00        16\n",
      "          3       0.96      0.92      0.94        24\n",
      "\n",
      "avg / total       0.92      0.91      0.90        85\n",
      "\n",
      "[29  0  0  0  5 10  0  1  0  0 16  0  2  0  0 22]\n",
      "LR Accuracy:  0.9058823529411765\n",
      "LR F1:  0.8994271685761048\n",
      "For name:  c_o'connor\n",
      "total sample size before apply threshold:  10\n",
      "Counter({'0000-0001-8134-075X': 4, '0000-0002-3541-708X': 2, '0000-0002-7638-9804': 2, '0000-0002-8359-7759': 1, '0000-0002-1670-3937': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  e_svensson\n",
      "total sample size before apply threshold:  87\n",
      "Counter({'0000-0001-9006-016X': 56, '0000-0001-6706-6336': 23, '0000-0002-4349-849X': 7, '0000-0002-5565-3266': 1})\n",
      "['0000-0001-6706-6336', '0000-0001-9006-016X']\n",
      "Total sample size after apply threshold:  79\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 183)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.61      0.76        23\n",
      "          1       0.86      1.00      0.93        56\n",
      "\n",
      "avg / total       0.90      0.89      0.88        79\n",
      "\n",
      "[14  9  0 56]\n",
      "MNB Accuracy:  0.8860759493670886\n",
      "MNB F1:  0.8411882957337503\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        23\n",
      "          1       0.92      1.00      0.96        56\n",
      "\n",
      "avg / total       0.94      0.94      0.93        79\n",
      "\n",
      "[18  5  0 56]\n",
      "svc Accuracy:  0.9367088607594937\n",
      "svc F1:  0.9176568688763811\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.22      0.36        23\n",
      "          1       0.76      1.00      0.86        56\n",
      "\n",
      "avg / total       0.83      0.77      0.71        79\n",
      "\n",
      "[ 5 18  0 56]\n",
      "LR Accuracy:  0.7721518987341772\n",
      "LR F1:  0.6093406593406594\n",
      "For name:  o_ahmed\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-8129-0289': 23, '0000-0002-3204-381X': 18, '0000-0002-2854-2552': 3, '0000-0002-1439-0076': 3, '0000-0002-6519-6564': 1})\n",
      "['0000-0002-3204-381X', '0000-0001-8129-0289']\n",
      "Total sample size after apply threshold:  41\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 83)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "41\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        18\n",
      "          1       0.85      1.00      0.92        23\n",
      "\n",
      "avg / total       0.92      0.90      0.90        41\n",
      "\n",
      "[14  4  0 23]\n",
      "MNB Accuracy:  0.9024390243902439\n",
      "MNB F1:  0.8975000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        18\n",
      "          1       0.85      1.00      0.92        23\n",
      "\n",
      "avg / total       0.92      0.90      0.90        41\n",
      "\n",
      "[14  4  0 23]\n",
      "svc Accuracy:  0.9024390243902439\n",
      "svc F1:  0.8975000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        18\n",
      "          1       0.85      1.00      0.92        23\n",
      "\n",
      "avg / total       0.92      0.90      0.90        41\n",
      "\n",
      "[14  4  0 23]\n",
      "LR Accuracy:  0.9024390243902439\n",
      "LR F1:  0.8975000000000001\n",
      "For name:  t_shimada\n",
      "total sample size before apply threshold:  144\n",
      "Counter({'0000-0002-5791-0000': 111, '0000-0002-8361-0730': 26, '0000-0002-1685-6781': 4, '0000-0001-6647-5541': 3})\n",
      "['0000-0002-5791-0000', '0000-0002-8361-0730']\n",
      "Total sample size after apply threshold:  137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(137, 311)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "137\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       111\n",
      "          1       0.96      0.88      0.92        26\n",
      "\n",
      "avg / total       0.97      0.97      0.97       137\n",
      "\n",
      "[110   1   3  23]\n",
      "MNB Accuracy:  0.9708029197080292\n",
      "MNB F1:  0.9510714285714286\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99       111\n",
      "          1       1.00      0.88      0.94        26\n",
      "\n",
      "avg / total       0.98      0.98      0.98       137\n",
      "\n",
      "[111   0   3  23]\n",
      "svc Accuracy:  0.9781021897810219\n",
      "svc F1:  0.9627210884353741\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96       111\n",
      "          1       1.00      0.65      0.79        26\n",
      "\n",
      "avg / total       0.94      0.93      0.93       137\n",
      "\n",
      "[111   0   9  17]\n",
      "LR Accuracy:  0.9343065693430657\n",
      "LR F1:  0.8758683177287829\n",
      "For name:  a_watts\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0003-4299-2717': 14, '0000-0002-8385-1091': 9, '0000-0003-0623-4601': 1, '0000-0003-3480-582X': 1})\n",
      "['0000-0003-4299-2717']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  b_oliveira\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0002-7710-4284': 22, '0000-0002-7687-4746': 17, '0000-0002-6767-6596': 13, '0000-0001-7712-0025': 6, '0000-0002-4817-6385': 2})\n",
      "['0000-0002-6767-6596', '0000-0002-7710-4284', '0000-0002-7687-4746']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 112)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.77      0.80        13\n",
      "          1       0.84      0.95      0.89        22\n",
      "          2       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.89      0.88      0.88        52\n",
      "\n",
      "[10  3  0  1 21  0  1  1 15]\n",
      "MNB Accuracy:  0.8846153846153846\n",
      "MNB F1:  0.8770390070921986\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.69      0.78        13\n",
      "          1       0.78      0.95      0.86        22\n",
      "          2       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.88      0.87      0.86        52\n",
      "\n",
      "[ 9  4  0  1 21  0  0  2 15]\n",
      "svc Accuracy:  0.8653846153846154\n",
      "svc F1:  0.859083850931677\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.76      1.00      0.86        22\n",
      "          2       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.90      0.87      0.86        52\n",
      "\n",
      "[ 8  5  0  0 22  0  0  2 15]\n",
      "LR Accuracy:  0.8653846153846154\n",
      "LR F1:  0.8540499533146592\n",
      "For name:  t_ito\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0001-7443-3157': 34, '0000-0003-4516-9283': 17, '0000-0003-0686-8129': 5, '0000-0002-4237-3564': 4, '0000-0003-1971-4313': 3, '0000-0001-9873-099X': 3, '0000-0003-1279-228X': 1, '0000-0001-6015-9302': 1, '0000-0002-9274-7050': 1})\n",
      "['0000-0003-4516-9283', '0000-0001-7443-3157']\n",
      "Total sample size after apply threshold:  51\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 104)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        17\n",
      "          1       0.94      1.00      0.97        34\n",
      "\n",
      "avg / total       0.96      0.96      0.96        51\n",
      "\n",
      "[15  2  0 34]\n",
      "MNB Accuracy:  0.9607843137254902\n",
      "MNB F1:  0.9544642857142858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        17\n",
      "          1       0.92      1.00      0.96        34\n",
      "\n",
      "avg / total       0.95      0.94      0.94        51\n",
      "\n",
      "[14  3  0 34]\n",
      "svc Accuracy:  0.9411764705882353\n",
      "svc F1:  0.9304861426624262\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.65      0.79        17\n",
      "          1       0.85      1.00      0.92        34\n",
      "\n",
      "avg / total       0.90      0.88      0.87        51\n",
      "\n",
      "[11  6  0 34]\n",
      "LR Accuracy:  0.8823529411764706\n",
      "LR F1:  0.8523166023166023\n",
      "For name:  t_jackson\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0001-6351-2773': 23, '0000-0001-6749-9959': 9, '0000-0003-1669-6666': 6, '0000-0003-3214-3973': 3, '0000-0001-8404-4251': 2, '0000-0002-0248-2627': 2, '0000-0002-5489-6020': 1, '0000-0003-2387-6411': 1})\n",
      "['0000-0001-6351-2773']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  m_romero\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0003-0578-1099': 21, '0000-0003-4582-7397': 4, '0000-0003-1563-8149': 2, '0000-0001-6682-7025': 2})\n",
      "['0000-0003-0578-1099']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  j_west\n",
      "total sample size before apply threshold:  198\n",
      "Counter({'0000-0002-1135-9356': 125, '0000-0002-6004-0202': 41, '0000-0002-7252-8651': 13, '0000-0002-5211-2405': 7, '0000-0001-8369-0075': 4, '0000-0002-4118-0322': 4, '0000-0003-0021-9638': 2, '0000-0001-7340-2885': 1, '0000-0002-6268-9750': 1})\n",
      "['0000-0002-7252-8651', '0000-0002-1135-9356', '0000-0002-6004-0202']\n",
      "Total sample size after apply threshold:  179\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(179, 382)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "179\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.86      0.99      0.92       125\n",
      "          2       0.97      0.80      0.88        41\n",
      "\n",
      "avg / total       0.82      0.88      0.84       179\n",
      "\n",
      "[  0  13   0   0 124   1   0   8  33]\n",
      "MNB Accuracy:  0.8770949720670391\n",
      "MNB F1:  0.5995061728395062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        13\n",
      "          1       0.91      1.00      0.95       125\n",
      "          2       1.00      0.85      0.92        41\n",
      "\n",
      "avg / total       0.94      0.93      0.93       179\n",
      "\n",
      "[  7   6   0   0 125   0   0   6  35]\n",
      "svc Accuracy:  0.9329608938547486\n",
      "svc F1:  0.8584170349537966\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.81      1.00      0.90       125\n",
      "          2       1.00      0.61      0.76        41\n",
      "\n",
      "avg / total       0.80      0.84      0.80       179\n",
      "\n",
      "[  0  13   0   0 125   0   0  16  25]\n",
      "LR Accuracy:  0.8379888268156425\n",
      "LR F1:  0.5512110350820028\n",
      "For name:  c_guo\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0001-9253-3469': 2, '0000-0002-0432-8121': 2, '0000-0002-4000-8141': 1, '0000-0003-2182-3287': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_hansen\n",
      "total sample size before apply threshold:  252\n",
      "Counter({'0000-0001-5372-4828': 55, '0000-0002-8087-8731': 40, '0000-0002-4663-8742': 29, '0000-0001-7114-8051': 27, '0000-0003-3333-2856': 24, '0000-0002-8619-1519': 17, '0000-0002-2607-461X': 16, '0000-0002-5695-6728': 11, '0000-0002-1582-7866': 6, '0000-0003-1684-8578': 6, '0000-0002-1940-0616': 5, '0000-0003-3083-4850': 4, '0000-0001-7879-2106': 4, '0000-0002-3621-1809': 4, '0000-0001-9681-2393': 2, '0000-0002-7589-0074': 1, '0000-0001-9611-8131': 1})\n",
      "['0000-0001-5372-4828', '0000-0002-8619-1519', '0000-0002-5695-6728', '0000-0003-3333-2856', '0000-0002-4663-8742', '0000-0001-7114-8051', '0000-0002-2607-461X', '0000-0002-8087-8731']\n",
      "Total sample size after apply threshold:  219\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(219, 631)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "219\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67        55\n",
      "          1       1.00      0.35      0.52        17\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       1.00      0.62      0.77        24\n",
      "          4       0.92      0.83      0.87        29\n",
      "          5       1.00      0.74      0.85        27\n",
      "          6       1.00      0.69      0.81        16\n",
      "          7       1.00      0.80      0.89        40\n",
      "\n",
      "avg / total       0.82      0.74      0.74       219\n",
      "\n",
      "[55  0  0  0  0  0  0  0 11  6  0  0  0  0  0  0 10  0  0  0  1  0  0  0\n",
      "  9  0  0 15  0  0  0  0  5  0  0  0 24  0  0  0  7  0  0  0  0 20  0  0\n",
      "  5  0  0  0  0  0 11  0  7  0  0  0  1  0  0 32]\n",
      "MNB Accuracy:  0.7442922374429224\n",
      "MNB F1:  0.6736495516501044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      1.00      0.78        55\n",
      "          1       1.00      0.76      0.87        17\n",
      "          2       1.00      0.73      0.84        11\n",
      "          3       1.00      0.79      0.88        24\n",
      "          4       1.00      0.83      0.91        29\n",
      "          5       1.00      0.81      0.90        27\n",
      "          6       1.00      0.88      0.93        16\n",
      "          7       1.00      0.82      0.90        40\n",
      "\n",
      "avg / total       0.91      0.86      0.87       219\n",
      "\n",
      "[55  0  0  0  0  0  0  0  4 13  0  0  0  0  0  0  3  0  8  0  0  0  0  0\n",
      "  5  0  0 19  0  0  0  0  5  0  0  0 24  0  0  0  5  0  0  0  0 22  0  0\n",
      "  2  0  0  0  0  0 14  0  7  0  0  0  0  0  0 33]\n",
      "svc Accuracy:  0.8584474885844748\n",
      "svc F1:  0.8767121484293925\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      1.00      0.69        55\n",
      "          1       1.00      0.59      0.74        17\n",
      "          2       1.00      0.09      0.17        11\n",
      "          3       1.00      0.62      0.77        24\n",
      "          4       0.96      0.79      0.87        29\n",
      "          5       1.00      0.74      0.85        27\n",
      "          6       1.00      0.75      0.86        16\n",
      "          7       1.00      0.80      0.89        40\n",
      "\n",
      "avg / total       0.87      0.77      0.77       219\n",
      "\n",
      "[55  0  0  0  0  0  0  0  7 10  0  0  0  0  0  0 10  0  1  0  0  0  0  0\n",
      "  9  0  0 15  0  0  0  0  6  0  0  0 23  0  0  0  7  0  0  0  0 20  0  0\n",
      "  4  0  0  0  0  0 12  0  7  0  0  0  1  0  0 32]\n",
      "LR Accuracy:  0.7671232876712328\n",
      "LR F1:  0.7286447850948804\n",
      "For name:  x_qian\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0003-1627-288X': 16, '0000-0003-2487-8785': 2, '0000-0002-4119-2913': 1, '0000-0002-8199-6502': 1})\n",
      "['0000-0003-1627-288X']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  m_wagner\n",
      "total sample size before apply threshold:  314\n",
      "Counter({'0000-0002-9778-7684': 141, '0000-0003-2589-6440': 98, '0000-0003-3421-4763': 16, '0000-0002-9831-9110': 15, '0000-0002-4402-3234': 15, '0000-0003-3967-9527': 10, '0000-0002-7367-5629': 8, '0000-0001-9742-0471': 5, '0000-0001-7609-9172': 3, '0000-0001-6501-839X': 2, '0000-0002-6924-7226': 1})\n",
      "['0000-0003-3967-9527', '0000-0002-9831-9110', '0000-0002-9778-7684', '0000-0003-3421-4763', '0000-0003-2589-6440', '0000-0002-4402-3234']\n",
      "Total sample size after apply threshold:  295\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 1456)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.47      0.64        15\n",
      "          2       0.75      1.00      0.85       141\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.98      0.99      0.98        98\n",
      "          5       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.73      0.83      0.77       295\n",
      "\n",
      "[  0   0  10   0   0   0   0   7   8   0   0   0   0   0 141   0   0   0\n",
      "   0   0  16   0   0   0   0   0   1   0  97   0   0   0  13   0   2   0]\n",
      "MNB Accuracy:  0.8305084745762712\n",
      "MNB F1:  0.4126134440855253\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       1.00      0.87      0.93        15\n",
      "          2       0.85      1.00      0.92       141\n",
      "          3       1.00      0.44      0.61        16\n",
      "          4       1.00      0.98      0.99        98\n",
      "          5       1.00      0.73      0.85        15\n",
      "\n",
      "avg / total       0.93      0.92      0.90       295\n",
      "\n",
      "[  2   0   8   0   0   0   0  13   2   0   0   0   0   0 141   0   0   0\n",
      "   0   0   9   7   0   0   0   0   2   0  96   0   0   0   4   0   0  11]\n",
      "svc Accuracy:  0.9152542372881356\n",
      "svc F1:  0.7708352928543842\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.47      0.64        15\n",
      "          2       0.73      1.00      0.84       141\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       1.00      0.94      0.97        98\n",
      "          5       1.00      0.20      0.33        15\n",
      "\n",
      "avg / total       0.78      0.82      0.77       295\n",
      "\n",
      "[  0   0  10   0   0   0   0   7   8   0   0   0   0   0 141   0   0   0\n",
      "   0   0  16   0   0   0   0   0   6   0  92   0   0   0  12   0   0   3]\n",
      "LR Accuracy:  0.823728813559322\n",
      "LR F1:  0.463738233262343\n",
      "For name:  d_campos\n",
      "total sample size before apply threshold:  49\n",
      "Counter({'0000-0003-1982-3288': 36, '0000-0002-3448-2111': 8, '0000-0003-0174-6640': 4, '0000-0003-0762-7124': 1})\n",
      "['0000-0003-1982-3288']\n",
      "Total sample size after apply threshold:  36\n",
      "For name:  r_clark\n",
      "total sample size before apply threshold:  152\n",
      "Counter({'0000-0002-7291-8553': 77, '0000-0002-6807-5426': 60, '0000-0002-1194-5048': 9, '0000-0002-3534-698X': 3, '0000-0003-4368-5145': 2, '0000-0001-6779-3736': 1})\n",
      "['0000-0002-7291-8553', '0000-0002-6807-5426']\n",
      "Total sample size after apply threshold:  137\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(137, 288)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98        77\n",
      "          1       0.98      0.97      0.97        60\n",
      "\n",
      "avg / total       0.98      0.98      0.98       137\n",
      "\n",
      "[76  1  2 58]\n",
      "MNB Accuracy:  0.9781021897810219\n",
      "MNB F1:  0.9777175386283545\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98        77\n",
      "          1       0.98      0.97      0.97        60\n",
      "\n",
      "avg / total       0.98      0.98      0.98       137\n",
      "\n",
      "[76  1  2 58]\n",
      "svc Accuracy:  0.9781021897810219\n",
      "svc F1:  0.9777175386283545\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        77\n",
      "          1       1.00      0.90      0.95        60\n",
      "\n",
      "avg / total       0.96      0.96      0.96       137\n",
      "\n",
      "[77  0  6 54]\n",
      "LR Accuracy:  0.9562043795620438\n",
      "LR F1:  0.9549342105263159\n",
      "For name:  b_zhou\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-1535-6283': 13, '0000-0003-2846-1813': 2, '0000-0003-2634-1527': 1, '0000-0001-9774-2737': 1, '0000-0003-1560-4950': 1, '0000-0003-0638-2428': 1, '0000-0003-4421-9787': 1})\n",
      "['0000-0002-1535-6283']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  x_yan\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0002-6114-5743': 44, '0000-0001-8547-4210': 18, '0000-0003-3973-3669': 14, '0000-0002-7528-5771': 12, '0000-0001-9327-5756': 7, '0000-0003-2091-6967': 6, '0000-0001-8221-9345': 3, '0000-0001-5026-0239': 3, '0000-0001-5606-0158': 2, '0000-0002-8292-130X': 1, '0000-0002-1300-5498': 1})\n",
      "['0000-0001-8547-4210', '0000-0003-3973-3669', '0000-0002-7528-5771', '0000-0002-6114-5743']\n",
      "Total sample size after apply threshold:  88\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 128)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        18\n",
      "          1       0.92      0.79      0.85        14\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       0.71      1.00      0.83        44\n",
      "\n",
      "avg / total       0.71      0.78      0.73        88\n",
      "\n",
      "[14  1  0  3  0 11  0  3  0  0  0 12  0  0  0 44]\n",
      "MNB Accuracy:  0.7840909090909091\n",
      "MNB F1:  0.6378356313497824\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        18\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       0.89      0.67      0.76        12\n",
      "          3       0.83      0.98      0.90        44\n",
      "\n",
      "avg / total       0.90      0.89      0.88        88\n",
      "\n",
      "[15  0  0  3  0 12  0  2  0  0  8  4  0  0  1 43]\n",
      "svc Accuracy:  0.8863636363636364\n",
      "svc F1:  0.8724764818514819\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        18\n",
      "          1       1.00      0.86      0.92        14\n",
      "          2       1.00      0.08      0.15        12\n",
      "          3       0.73      1.00      0.85        44\n",
      "\n",
      "avg / total       0.87      0.82      0.78        88\n",
      "\n",
      "[15  0  0  3  0 12  0  2  0  0  1 11  0  0  0 44]\n",
      "LR Accuracy:  0.8181818181818182\n",
      "LR F1:  0.7080419580419579\n",
      "For name:  x_li\n",
      "total sample size before apply threshold:  867\n",
      "Counter({'0000-0002-5555-9034': 244, '0000-0002-5981-2762': 71, '0000-0002-4044-2888': 67, '0000-0001-6508-8355': 51, '0000-0001-8791-7505': 30, '0000-0002-4115-3287': 30, '0000-0002-2497-020X': 26, '0000-0002-6200-1178': 26, '0000-0002-7844-8417': 22, '0000-0003-1359-5130': 21, '0000-0002-4793-0550': 20, '0000-0001-8718-2780': 18, '0000-0002-4446-2480': 16, '0000-0003-1568-1999': 14, '0000-0001-9814-0383': 13, '0000-0002-7646-1132': 13, '0000-0003-0724-0982': 12, '0000-0002-2510-2236': 11, '0000-0002-3828-0971': 10, '0000-0002-4675-5367': 10, '0000-0002-6646-0929': 8, '0000-0002-4350-3375': 7, '0000-0002-7939-5150': 7, '0000-0001-7038-5119': 6, '0000-0002-9121-7883': 5, '0000-0002-4828-4183': 5, '0000-0001-8184-3197': 5, '0000-0001-6449-1505': 5, '0000-0003-0606-434X': 5, '0000-0003-0220-9003': 5, '0000-0002-0046-2016': 5, '0000-0001-7111-8485': 4, '0000-0002-4230-5676': 4, '0000-0002-6007-5149': 4, '0000-0003-4514-0149': 4, '0000-0003-1117-9619': 4, '0000-0003-2999-9818': 3, '0000-0001-7073-7532': 3, '0000-0002-0986-6682': 3, '0000-0003-1382-3295': 3, '0000-0003-3882-7073': 3, '0000-0002-4842-5054': 3, '0000-0003-1990-0159': 3, '0000-0002-7270-3376': 3, '0000-0003-0493-417X': 2, '0000-0001-8662-0865': 2, '0000-0003-3050-8529': 2, '0000-0003-3272-5180': 2, '0000-0002-3428-3569': 2, '0000-0002-5263-7017': 2, '0000-0001-9790-5663': 2, '0000-0003-2747-644X': 2, '0000-0002-1959-2160': 2, '0000-0002-0377-2925': 2, '0000-0003-3951-9646': 2, '0000-0002-2397-6079': 1, '0000-0001-7458-8263': 1, '0000-0002-7671-6326': 1, '0000-0003-0191-9484': 1, '0000-0002-0220-8310': 1, '0000-0002-6433-2085': 1, '0000-0002-8669-6314': 1, '0000-0001-5580-5605': 1, '0000-0001-8088-2338': 1, '0000-0002-6093-1099': 1, '0000-0002-1708-4314': 1, '0000-0002-3919-2658': 1, '0000-0001-7420-6253': 1})\n",
      "['0000-0002-4446-2480', '0000-0001-9814-0383', '0000-0002-7646-1132', '0000-0003-1568-1999', '0000-0002-5555-9034', '0000-0001-8791-7505', '0000-0002-3828-0971', '0000-0003-0724-0982', '0000-0002-4044-2888', '0000-0002-7844-8417', '0000-0002-4793-0550', '0000-0001-8718-2780', '0000-0002-4675-5367', '0000-0002-2497-020X', '0000-0002-4115-3287', '0000-0002-6200-1178', '0000-0003-1359-5130', '0000-0002-5981-2762', '0000-0002-2510-2236', '0000-0001-6508-8355']\n",
      "Total sample size after apply threshold:  725\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(725, 614)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.12        16\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       1.00      0.15      0.27        13\n",
      "          3       0.00      0.00      0.00        14\n",
      "          4       0.45      1.00      0.62       244\n",
      "          5       1.00      0.37      0.54        30\n",
      "          6       0.00      0.00      0.00        10\n",
      "          7       0.00      0.00      0.00        12\n",
      "          8       0.56      0.37      0.45        67\n",
      "          9       1.00      0.05      0.09        22\n",
      "         10       1.00      0.25      0.40        20\n",
      "         11       0.00      0.00      0.00        18\n",
      "         12       0.00      0.00      0.00        10\n",
      "         13       1.00      0.54      0.70        26\n",
      "         14       1.00      0.33      0.50        30\n",
      "         15       1.00      0.38      0.56        26\n",
      "         16       0.00      0.00      0.00        21\n",
      "         17       1.00      0.52      0.69        71\n",
      "         18       0.00      0.00      0.00        11\n",
      "         19       0.89      0.78      0.83        51\n",
      "\n",
      "avg / total       0.62      0.55      0.48       725\n",
      "\n",
      "[  1   0   0   0  15   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  10   0   0   0   3   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   2   0  11   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  13   0   0   0   1   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 244   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18  11   0   0\n",
      "   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  10   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "   0   0  41   0   0   0  25   0   0   0   0   0   0   0   0   0   0   1\n",
      "   0   0   0   0  18   0   0   0   1   1   0   0   0   0   0   0   0   0\n",
      "   0   2   0   0   0   0  14   0   0   0   1   0   5   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  18   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  12   0   0   0   0   0\n",
      "   0   0   0  14   0   0   0   0   0   0   0   0   0   0  17   0   0   0\n",
      "   3   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0  11   0\n",
      "   0   0   5   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0\n",
      "  20   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  31   0   0   0   2   0   0   0   0   0   0   0   0  37   0   1\n",
      "   0   0   0   0  11   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  10   0   0   0   1   0   0   0   0   0   0   0\n",
      "   0   0   0  40]\n",
      "MNB Accuracy:  0.5517241379310345\n",
      "MNB F1:  0.28738237993435767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.88      0.90        16\n",
      "          1       1.00      0.54      0.70        13\n",
      "          2       1.00      0.92      0.96        13\n",
      "          3       0.75      0.21      0.33        14\n",
      "          4       0.79      0.96      0.87       244\n",
      "          5       0.95      0.70      0.81        30\n",
      "          6       0.75      0.30      0.43        10\n",
      "          7       1.00      0.42      0.59        12\n",
      "          8       0.63      0.79      0.70        67\n",
      "          9       0.75      0.82      0.78        22\n",
      "         10       1.00      0.90      0.95        20\n",
      "         11       0.88      0.83      0.86        18\n",
      "         12       1.00      0.70      0.82        10\n",
      "         13       0.96      0.88      0.92        26\n",
      "         14       0.87      0.67      0.75        30\n",
      "         15       0.96      0.85      0.90        26\n",
      "         16       1.00      0.71      0.83        21\n",
      "         17       0.75      0.68      0.71        71\n",
      "         18       1.00      1.00      1.00        11\n",
      "         19       0.98      0.90      0.94        51\n",
      "\n",
      "avg / total       0.84      0.82      0.82       725\n",
      "\n",
      "[ 14   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   7   0   0   3   0   0   0   2   0   0   0   0   0   0   0\n",
      "   0   1   0   0   0   0  12   0   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   3   5   0   0   0   5   0   0   0\n",
      "   0   0   0   0   0   1   0   0   0   0   0   0 235   0   0   0   3   0\n",
      "   0   0   0   0   1   0   0   5   0   0   0   0   0   0   2  21   0   0\n",
      "   5   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   4   0\n",
      "   3   0   2   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "   3   0   0   5   1   2   0   0   0   0   0   0   0   1   0   0   1   0\n",
      "   0   0   6   0   0   0  53   2   0   1   0   0   1   0   0   3   0   0\n",
      "   0   0   0   0   2   0   0   0   2  18   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   2   0   0   0   0   0  18   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   2   0   0   0   1   0   0  15   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0\n",
      "   7   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0\n",
      "   0   0   0  23   0   0   0   1   0   0   0   0   0   0   3   1   0   0\n",
      "   5   0   0   0   0   1  20   0   0   0   0   0   0   0   0   0   1   0\n",
      "   0   0   2   1   0   0   0   0   0  22   0   0   0   0   0   0   0   0\n",
      "   3   0   0   0   2   0   0   0   0   0   0   0  15   1   0   0   0   0\n",
      "   0   1  17   0   0   0   1   1   0   1   0   0   1   0   0  48   0   1\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  11   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   1   0  46]\n",
      "svc Accuracy:  0.8220689655172414\n",
      "svc F1:  0.7877576062245316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.55        16\n",
      "          1       1.00      0.23      0.38        13\n",
      "          2       1.00      0.69      0.82        13\n",
      "          3       0.00      0.00      0.00        14\n",
      "          4       0.62      0.99      0.76       244\n",
      "          5       0.90      0.63      0.75        30\n",
      "          6       0.00      0.00      0.00        10\n",
      "          7       1.00      0.17      0.29        12\n",
      "          8       0.61      0.69      0.65        67\n",
      "          9       0.86      0.82      0.84        22\n",
      "         10       1.00      0.80      0.89        20\n",
      "         11       1.00      0.44      0.62        18\n",
      "         12       0.00      0.00      0.00        10\n",
      "         13       0.96      0.88      0.92        26\n",
      "         14       0.88      0.50      0.64        30\n",
      "         15       0.95      0.69      0.80        26\n",
      "         16       1.00      0.38      0.55        21\n",
      "         17       0.79      0.59      0.68        71\n",
      "         18       1.00      0.73      0.84        11\n",
      "         19       0.93      0.84      0.89        51\n",
      "\n",
      "avg / total       0.75      0.73      0.70       725\n",
      "\n",
      "[  6   0   0   0   9   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   3   0   0   6   0   0   0   2   0   0   0   0   0   0   0\n",
      "   0   2   0   0   0   0   9   0   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  11   0   0   0   3   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 242   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   2   0   0   0   0   0   0   8  19   0   0\n",
      "   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0\n",
      "   0   0   3   0   0   0   0   0   0   1   0   0   0   1   0   0   0   0\n",
      "   8   0   0   2   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  16   0   0   0  46   1   0   0   0   0   1   0   0   3   0   0\n",
      "   0   0   0   0   1   0   0   0   1  18   0   0   0   0   0   0   0   1\n",
      "   0   1   0   0   0   0   3   0   0   0   1   0  16   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   8   0   0   0   1   0   0   8   0   0\n",
      "   0   0   0   1   0   0   0   0   0   0   9   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   0   0   0   0   2   0   0   0   0   0\n",
      "   0   0   0  23   0   0   0   1   0   0   0   0   0   0   8   2   0   0\n",
      "   4   0   0   0   0   1  15   0   0   0   0   0   0   0   0   0   3   0\n",
      "   0   0   3   2   0   0   0   0   0  18   0   0   0   0   0   0   0   0\n",
      "  12   0   0   0   1   0   0   0   0   0   0   0   8   0   0   0   0   0\n",
      "   0   0  24   0   0   0   3   0   0   0   0   0   1   0   0  42   0   1\n",
      "   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   8   0   0   0   0   0   7   0   0   0   1   0   0   0   0   0   0   0\n",
      "   0   0   0  43]\n",
      "LR Accuracy:  0.7255172413793104\n",
      "LR F1:  0.5919788169853946\n",
      "For name:  j_burton\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0003-1176-7592': 34, '0000-0003-2817-7353': 6, '0000-0001-5267-1277': 4, '0000-0002-3205-8819': 2})\n",
      "['0000-0003-1176-7592']\n",
      "Total sample size after apply threshold:  34\n",
      "For name:  x_feng\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0001-6894-7979': 37, '0000-0002-3212-3051': 25, '0000-0002-9057-1549': 17, '0000-0002-6920-1519': 9, '0000-0002-9523-6096': 8, '0000-0002-0443-0628': 2, '0000-0002-9473-2848': 2, '0000-0003-1945-1605': 1, '0000-0001-8226-3389': 1})\n",
      "['0000-0002-3212-3051', '0000-0001-6894-7979', '0000-0002-9057-1549']\n",
      "Total sample size after apply threshold:  79\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 100)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.80      0.85        25\n",
      "          1       0.82      0.86      0.84        37\n",
      "          2       0.83      0.88      0.86        17\n",
      "\n",
      "avg / total       0.85      0.85      0.85        79\n",
      "\n",
      "[20  5  0  2 32  3  0  2 15]\n",
      "MNB Accuracy:  0.8481012658227848\n",
      "MNB F1:  0.8501039833626619\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.80      0.85        25\n",
      "          1       0.79      0.89      0.84        37\n",
      "          2       0.87      0.76      0.81        17\n",
      "\n",
      "avg / total       0.84      0.84      0.84        79\n",
      "\n",
      "[20  5  0  2 33  2  0  4 13]\n",
      "svc Accuracy:  0.8354430379746836\n",
      "svc F1:  0.8330022892539725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.68      0.77        25\n",
      "          1       0.74      0.92      0.82        37\n",
      "          2       0.93      0.76      0.84        17\n",
      "\n",
      "avg / total       0.83      0.81      0.81        79\n",
      "\n",
      "[17  8  0  2 34  1  0  4 13]\n",
      "LR Accuracy:  0.810126582278481\n",
      "LR F1:  0.8102380195267874\n",
      "For name:  w_hussein\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0001-5392-1880': 18, '0000-0002-7416-4521': 13, '0000-0001-5928-6240': 1, '0000-0002-7589-7479': 1})\n",
      "['0000-0001-5392-1880', '0000-0002-7416-4521']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(31, 77)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "31\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        18\n",
      "          1       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.87      0.84      0.83        31\n",
      "\n",
      "[18  0  5  8]\n",
      "MNB Accuracy:  0.8387096774193549\n",
      "MNB F1:  0.8199767711962835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        18\n",
      "          1       0.93      1.00      0.96        13\n",
      "\n",
      "avg / total       0.97      0.97      0.97        31\n",
      "\n",
      "[17  1  0 13]\n",
      "svc Accuracy:  0.967741935483871\n",
      "svc F1:  0.9671957671957672\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        18\n",
      "          1       1.00      0.54      0.70        13\n",
      "\n",
      "avg / total       0.85      0.81      0.79        31\n",
      "\n",
      "[18  0  6  7]\n",
      "LR Accuracy:  0.8064516129032258\n",
      "LR F1:  0.7785714285714286\n",
      "For name:  c_santos\n",
      "total sample size before apply threshold:  293\n",
      "Counter({'0000-0002-0405-3500': 68, '0000-0003-4129-6381': 41, '0000-0001-6074-7825': 38, '0000-0002-7014-8014': 37, '0000-0002-7109-1101': 25, '0000-0002-4575-1807': 22, '0000-0003-4681-0941': 17, '0000-0002-6725-8925': 10, '0000-0003-0023-7203': 9, '0000-0003-4380-7990': 8, '0000-0002-8567-0032': 4, '0000-0001-6315-7433': 3, '0000-0002-4751-2180': 3, '0000-0001-5693-9795': 2, '0000-0001-9198-2668': 2, '0000-0002-0938-523X': 1, '0000-0001-7927-9718': 1, '0000-0001-5181-2461': 1, '0000-0001-5577-0799': 1})\n",
      "['0000-0003-4129-6381', '0000-0002-6725-8925', '0000-0002-7109-1101', '0000-0002-7014-8014', '0000-0001-6074-7825', '0000-0002-0405-3500', '0000-0003-4681-0941', '0000-0002-4575-1807']\n",
      "Total sample size after apply threshold:  258\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(258, 589)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.88      0.84        41\n",
      "          1       1.00      0.50      0.67        10\n",
      "          2       1.00      0.52      0.68        25\n",
      "          3       0.94      0.89      0.92        37\n",
      "          4       0.97      0.97      0.97        38\n",
      "          5       0.68      1.00      0.81        68\n",
      "          6       1.00      0.12      0.21        17\n",
      "          7       1.00      0.91      0.95        22\n",
      "\n",
      "avg / total       0.87      0.83      0.81       258\n",
      "\n",
      "[36  0  0  0  1  4  0  0  0  5  0  0  0  5  0  0  5  0 13  0  0  7  0  0\n",
      "  1  0  0 33  0  3  0  0  0  0  0  0 37  1  0  0  0  0  0  0  0 68  0  0\n",
      "  2  0  0  2  0 11  2  0  1  0  0  0  0  1  0 20]\n",
      "MNB Accuracy:  0.8294573643410853\n",
      "MNB F1:  0.756358556274407\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.88      0.84        41\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       0.94      0.68      0.79        25\n",
      "          3       0.89      0.86      0.88        37\n",
      "          4       0.97      0.97      0.97        38\n",
      "          5       0.85      0.99      0.91        68\n",
      "          6       0.87      0.76      0.81        17\n",
      "          7       1.00      0.91      0.95        22\n",
      "\n",
      "avg / total       0.89      0.89      0.89       258\n",
      "\n",
      "[36  0  1  0  1  3  0  0  0  7  0  0  0  3  0  0  6  0 17  0  0  2  0  0\n",
      "  1  0  0 32  0  2  2  0  0  0  0  0 37  1  0  0  0  0  0  1  0 67  0  0\n",
      "  1  0  0  3  0  0 13  0  1  0  0  0  0  1  0 20]\n",
      "svc Accuracy:  0.8875968992248062\n",
      "svc F1:  0.8722848132542029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.90      0.88        41\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.68      0.81        25\n",
      "          3       0.89      0.92      0.91        37\n",
      "          4       0.97      0.97      0.97        38\n",
      "          5       0.78      1.00      0.88        68\n",
      "          6       1.00      0.47      0.64        17\n",
      "          7       1.00      0.91      0.95        22\n",
      "\n",
      "avg / total       0.90      0.88      0.88       258\n",
      "\n",
      "[37  0  0  0  1  3  0  0  0  7  0  0  0  3  0  0  4  0 17  0  0  4  0  0\n",
      "  1  0  0 34  0  2  0  0  0  0  0  0 37  1  0  0  0  0  0  0  0 68  0  0\n",
      "  0  0  0  4  0  5  8  0  1  0  0  0  0  1  0 20]\n",
      "LR Accuracy:  0.8837209302325582\n",
      "LR F1:  0.8580195983316926\n",
      "For name:  j_figueroa\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0003-3036-6604': 51, '0000-0003-4769-8736': 3, '0000-0002-7457-0650': 3, '0000-0002-3403-1484': 2})\n",
      "['0000-0003-3036-6604']\n",
      "Total sample size after apply threshold:  51\n",
      "For name:  w_cui\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0003-2245-6052': 7, '0000-0002-6324-5772': 4, '0000-0001-7281-3471': 1, '0000-0002-6938-9582': 1, '0000-0003-4875-4285': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_moreira\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0003-4517-244X': 18, '0000-0003-1961-7281': 4, '0000-0003-0605-8003': 2, '0000-0002-8257-5785': 1, '0000-0002-4801-2225': 1})\n",
      "['0000-0003-4517-244X']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  m_graham\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0002-7290-1217': 34, '0000-0003-4983-4949': 27, '0000-0002-4170-1095': 2, '0000-0003-0708-7957': 1})\n",
      "['0000-0002-7290-1217', '0000-0003-4983-4949']\n",
      "Total sample size after apply threshold:  61\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 161)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        34\n",
      "          1       1.00      0.78      0.88        27\n",
      "\n",
      "avg / total       0.92      0.90      0.90        61\n",
      "\n",
      "[34  0  6 21]\n",
      "MNB Accuracy:  0.9016393442622951\n",
      "MNB F1:  0.8969594594594594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        34\n",
      "          1       1.00      0.78      0.88        27\n",
      "\n",
      "avg / total       0.92      0.90      0.90        61\n",
      "\n",
      "[34  0  6 21]\n",
      "svc Accuracy:  0.9016393442622951\n",
      "svc F1:  0.8969594594594594\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        34\n",
      "          1       1.00      0.78      0.88        27\n",
      "\n",
      "avg / total       0.92      0.90      0.90        61\n",
      "\n",
      "[34  0  6 21]\n",
      "LR Accuracy:  0.9016393442622951\n",
      "LR F1:  0.8969594594594594\n",
      "For name:  g_dias\n",
      "total sample size before apply threshold:  9\n",
      "Counter({'0000-0002-3774-6661': 5, '0000-0001-8548-1146': 2, '0000-0001-7291-6569': 1, '0000-0002-0524-1239': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  h_yoshida\n",
      "total sample size before apply threshold:  72\n",
      "Counter({'0000-0001-6890-4397': 38, '0000-0002-2540-0225': 19, '0000-0001-6360-5988': 13, '0000-0002-7283-8617': 2})\n",
      "['0000-0002-2540-0225', '0000-0001-6360-5988', '0000-0001-6890-4397']\n",
      "Total sample size after apply threshold:  70\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(70, 129)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "70\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.58      0.71        19\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       0.73      1.00      0.84        38\n",
      "\n",
      "avg / total       0.83      0.79      0.77        70\n",
      "\n",
      "[11  0  8  1  6  6  0  0 38]\n",
      "MNB Accuracy:  0.7857142857142857\n",
      "MNB F1:  0.7285669370559015\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.90        19\n",
      "          1       1.00      0.69      0.82        13\n",
      "          2       1.00      1.00      1.00        38\n",
      "\n",
      "avg / total       0.95      0.94      0.94        70\n",
      "\n",
      "[19  0  0  4  9  0  0  0 38]\n",
      "svc Accuracy:  0.9428571428571428\n",
      "svc F1:  0.9076479076479075\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.68      0.79        19\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       0.76      1.00      0.86        38\n",
      "\n",
      "avg / total       0.85      0.81      0.80        70\n",
      "\n",
      "[13  0  6  1  6  6  0  0 38]\n",
      "LR Accuracy:  0.8142857142857143\n",
      "LR F1:  0.7610313662945242\n",
      "For name:  m_branco\n",
      "total sample size before apply threshold:  56\n",
      "Counter({'0000-0001-9447-1548': 21, '0000-0002-8140-1257': 18, '0000-0003-4439-1923': 12, '0000-0001-5238-1069': 5})\n",
      "['0000-0002-8140-1257', '0000-0001-9447-1548', '0000-0003-4439-1923']\n",
      "Total sample size after apply threshold:  51\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 147)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        18\n",
      "          1       0.91      1.00      0.95        21\n",
      "          2       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.91      0.90      0.89        51\n",
      "\n",
      "[18  0  0  0 21  0  3  2  7]\n",
      "MNB Accuracy:  0.9019607843137255\n",
      "MNB F1:  0.8714881609618451\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        18\n",
      "          1       0.95      1.00      0.98        21\n",
      "          2       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        51\n",
      "\n",
      "[18  0  0  0 21  0  1  1 10]\n",
      "svc Accuracy:  0.9607843137254902\n",
      "svc F1:  0.9529360227034647\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        18\n",
      "          1       0.75      1.00      0.86        21\n",
      "          2       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.88      0.84      0.81        51\n",
      "\n",
      "[18  0  0  0 21  0  1  7  4]\n",
      "LR Accuracy:  0.8431372549019608\n",
      "LR F1:  0.7767052767052767\n",
      "For name:  k_chong\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0003-2587-1323': 28, '0000-0002-7350-597X': 4, '0000-0003-4754-8957': 4, '0000-0003-0786-842X': 3})\n",
      "['0000-0003-2587-1323']\n",
      "Total sample size after apply threshold:  28\n",
      "For name:  j_kumar\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0002-9754-3305': 9, '0000-0002-4153-1495': 3, '0000-0002-0159-0546': 2, '0000-0001-9666-8280': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  a_shenoy\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0001-6228-9303': 24, '0000-0003-4306-7582': 3, '0000-0001-8639-2751': 3, '0000-0003-4200-8599': 2, '0000-0003-4611-9333': 1})\n",
      "['0000-0001-6228-9303']\n",
      "Total sample size after apply threshold:  24\n",
      "For name:  h_yang\n",
      "total sample size before apply threshold:  417\n",
      "Counter({'0000-0002-8482-6031': 65, '0000-0003-3459-4516': 45, '0000-0003-3864-9895': 44, '0000-0002-7056-3648': 40, '0000-0003-3602-9772': 34, '0000-0001-6483-2373': 31, '0000-0002-6707-8481': 18, '0000-0002-0470-676X': 15, '0000-0002-1711-363X': 15, '0000-0002-2965-4353': 13, '0000-0001-5298-2462': 11, '0000-0002-4287-0026': 11, '0000-0002-0762-7194': 10, '0000-0003-4647-1388': 6, '0000-0002-0435-6763': 5, '0000-0003-3325-1378': 5, '0000-0001-5779-1833': 5, '0000-0002-9187-1367': 5, '0000-0001-8061-6179': 4, '0000-0003-1445-3468': 3, '0000-0002-9596-4907': 3, '0000-0003-4265-7492': 3, '0000-0001-7255-9653': 3, '0000-0003-0445-2824': 3, '0000-0001-9644-6207': 2, '0000-0003-1139-2751': 2, '0000-0002-2060-8991': 2, '0000-0002-4690-8503': 2, '0000-0002-3471-8235': 2, '0000-0003-0727-0874': 1, '0000-0001-5117-5394': 1, '0000-0001-6436-3036': 1, '0000-0003-1943-8857': 1, '0000-0002-2628-4676': 1, '0000-0002-4732-1990': 1, '0000-0001-5140-9664': 1, '0000-0002-2252-2606': 1, '0000-0003-4825-2867': 1, '0000-0003-2326-7317': 1})\n",
      "['0000-0002-2965-4353', '0000-0001-5298-2462', '0000-0002-7056-3648', '0000-0003-3459-4516', '0000-0002-0762-7194', '0000-0003-3602-9772', '0000-0002-6707-8481', '0000-0003-3864-9895', '0000-0002-8482-6031', '0000-0001-6483-2373', '0000-0002-0470-676X', '0000-0002-4287-0026', '0000-0002-1711-363X']\n",
      "Total sample size after apply threshold:  352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(352, 565)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "352\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.84      0.90      0.87        40\n",
      "          3       0.97      0.73      0.84        45\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.77      1.00      0.87        34\n",
      "          6       1.00      0.50      0.67        18\n",
      "          7       0.72      0.95      0.82        44\n",
      "          8       0.50      0.97      0.66        65\n",
      "          9       0.97      1.00      0.98        31\n",
      "         10       0.00      0.00      0.00        15\n",
      "         11       1.00      0.27      0.43        11\n",
      "         12       1.00      0.13      0.24        15\n",
      "\n",
      "avg / total       0.69      0.72      0.66       352\n",
      "\n",
      "[ 0  0  0  0  0  0  0  3 10  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0\n",
      "  0  0  0  0 36  0  0  1  0  0  2  1  0  0  0  0  0  0 33  0  0  0  1 11\n",
      "  0  0  0  0  0  0  1  0  0  0  0  1  8  0  0  0  0  0  0  0  0  0 34  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  9  0  9  0  0  0  0  0  0  0  0  0\n",
      "  0  0 42  2  0  0  0  0  0  0  1  1  0  0  0  0 63  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 31  0  0  0  0  0  5  0  0  9  0  0  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  8  0  0  3  0  0  0  0  0  0  0  0  0 13  0  0  0\n",
      "  2]\n",
      "MNB Accuracy:  0.71875\n",
      "MNB F1:  0.48993433831265165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.14        13\n",
      "          1       0.82      0.82      0.82        11\n",
      "          2       0.74      0.93      0.82        40\n",
      "          3       0.80      0.73      0.77        45\n",
      "          4       0.89      0.80      0.84        10\n",
      "          5       1.00      0.94      0.97        34\n",
      "          6       1.00      0.67      0.80        18\n",
      "          7       0.95      0.86      0.90        44\n",
      "          8       0.59      0.94      0.73        65\n",
      "          9       1.00      0.97      0.98        31\n",
      "         10       1.00      0.33      0.50        15\n",
      "         11       1.00      0.91      0.95        11\n",
      "         12       1.00      0.53      0.70        15\n",
      "\n",
      "avg / total       0.86      0.81      0.80       352\n",
      "\n",
      "[ 1  0  0  4  1  0  0  1  6  0  0  0  0  0  9  0  0  0  0  0  1  1  0  0\n",
      "  0  0  0  0 37  0  0  0  0  0  3  0  0  0  0  0  1  0 33  0  0  0  0 11\n",
      "  0  0  0  0  0  0  0  0  8  0  0  0  2  0  0  0  0  0  0  1  0  0 32  0\n",
      "  0  1  0  0  0  0  0  0  0  0  0  0 12  0  6  0  0  0  0  0  1  0  1  0\n",
      "  0  0 38  4  0  0  0  0  0  0  1  3  0  0  0  0 61  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0 30  0  0  0  0  0 10  0  0  0  0  0  0  0  5  0  0  0\n",
      "  0  0  0  0  0  0  0  1  0  0 10  0  0  0  0  0  0  0  0  0  7  0  0  0\n",
      "  8]\n",
      "svc Accuracy:  0.8068181818181818\n",
      "svc F1:  0.763469026246507\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       0.73      0.90      0.81        40\n",
      "          3       0.94      0.76      0.84        45\n",
      "          4       1.00      0.50      0.67        10\n",
      "          5       0.97      0.88      0.92        34\n",
      "          6       1.00      0.61      0.76        18\n",
      "          7       0.89      0.93      0.91        44\n",
      "          8       0.53      0.97      0.69        65\n",
      "          9       0.97      1.00      0.98        31\n",
      "         10       1.00      0.20      0.33        15\n",
      "         11       1.00      0.73      0.84        11\n",
      "         12       1.00      0.33      0.50        15\n",
      "\n",
      "avg / total       0.82      0.78      0.76       352\n",
      "\n",
      "[ 0  0  0  1  0  0  0  3  9  0  0  0  0  0  8  0  0  0  0  0  2  1  0  0\n",
      "  0  0  0  0 36  0  0  0  0  0  4  0  0  0  0  0  0  0 34  0  0  0  0 11\n",
      "  0  0  0  0  0  0  1  0  5  0  0  0  4  0  0  0  0  0  0  2  0  0 30  0\n",
      "  0  2  0  0  0  0  0  0  0  0  0  0 11  0  7  0  0  0  0  0  0  0  0  0\n",
      "  0  0 41  3  0  0  0  0  0  0  1  1  0  0  0  0 63  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 31  0  0  0  0  0  9  0  0  1  0  0  1  1  3  0  0  0\n",
      "  0  0  0  0  0  0  0  3  0  0  8  0  0  0  0  0  0  0  0  0 10  0  0  0\n",
      "  5]\n",
      "LR Accuracy:  0.78125\n",
      "LR F1:  0.699858904718028\n",
      "For name:  m_magnusson\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0003-1710-5936': 24, '0000-0002-6565-4027': 22, '0000-0002-3141-8544': 10, '0000-0002-7574-1095': 7, '0000-0002-8049-2142': 3, '0000-0001-5388-6608': 1})\n",
      "['0000-0002-3141-8544', '0000-0002-6565-4027', '0000-0003-1710-5936']\n",
      "Total sample size after apply threshold:  56\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 180)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.81      0.95      0.88        22\n",
      "          2       0.96      0.96      0.96        24\n",
      "\n",
      "avg / total       0.91      0.89      0.89        56\n",
      "\n",
      "[ 6  4  0  0 21  1  0  1 23]\n",
      "MNB Accuracy:  0.8928571428571429\n",
      "MNB F1:  0.8611111111111112\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.88      1.00      0.94        22\n",
      "          2       1.00      0.96      0.98        24\n",
      "\n",
      "avg / total       0.95      0.95      0.95        56\n",
      "\n",
      "[ 8  2  0  0 22  0  0  1 23]\n",
      "svc Accuracy:  0.9464285714285714\n",
      "svc F1:  0.9345941686367217\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.81      1.00      0.90        22\n",
      "          2       0.96      0.96      0.96        24\n",
      "\n",
      "avg / total       0.91      0.89      0.88        56\n",
      "\n",
      "[ 5  4  1  0 22  0  0  1 23]\n",
      "LR Accuracy:  0.8928571428571429\n",
      "LR F1:  0.8409863945578232\n",
      "For name:  m_foster\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0001-9645-7491': 43, '0000-0002-4524-141X': 43, '0000-0001-6392-7418': 6, '0000-0002-4453-7788': 5, '0000-0002-3100-0885': 3, '0000-0003-2257-4825': 3})\n",
      "['0000-0001-9645-7491', '0000-0002-4524-141X']\n",
      "Total sample size after apply threshold:  86\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 161)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98        43\n",
      "          1       0.98      0.98      0.98        43\n",
      "\n",
      "avg / total       0.98      0.98      0.98        86\n",
      "\n",
      "[42  1  1 42]\n",
      "MNB Accuracy:  0.9767441860465116\n",
      "MNB F1:  0.9767441860465116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        43\n",
      "          1       1.00      0.95      0.98        43\n",
      "\n",
      "avg / total       0.98      0.98      0.98        86\n",
      "\n",
      "[43  0  2 41]\n",
      "svc Accuracy:  0.9767441860465116\n",
      "svc F1:  0.9767316017316018\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        43\n",
      "          1       1.00      0.95      0.98        43\n",
      "\n",
      "avg / total       0.98      0.98      0.98        86\n",
      "\n",
      "[43  0  2 41]\n",
      "LR Accuracy:  0.9767441860465116\n",
      "LR F1:  0.9767316017316018\n",
      "For name:  j_lynch\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-1227-2252': 7, '0000-0003-0889-2616': 6, '0000-0003-3624-2741': 4, '0000-0003-0108-2127': 2, '0000-0002-4094-3738': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_boyle\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-9404-6901': 10, '0000-0002-5687-9857': 1, '0000-0002-3616-1637': 1, '0000-0001-6173-6765': 1, '0000-0002-6330-6870': 1})\n",
      "['0000-0002-9404-6901']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  r_turner\n",
      "total sample size before apply threshold:  147\n",
      "Counter({'0000-0001-5055-9644': 58, '0000-0001-7534-2935': 44, '0000-0003-4278-8302': 19, '0000-0001-5523-0645': 15, '0000-0002-0393-8593': 7, '0000-0002-9263-0776': 2, '0000-0002-3938-5513': 1, '0000-0003-0853-5360': 1})\n",
      "['0000-0001-7534-2935', '0000-0001-5055-9644', '0000-0001-5523-0645', '0000-0003-4278-8302']\n",
      "Total sample size after apply threshold:  136\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(136, 446)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.66      0.79        44\n",
      "          1       0.71      1.00      0.83        58\n",
      "          2       1.00      0.67      0.80        15\n",
      "          3       1.00      0.79      0.88        19\n",
      "\n",
      "avg / total       0.88      0.82      0.82       136\n",
      "\n",
      "[29 15  0  0  0 58  0  0  0  5 10  0  0  4  0 15]\n",
      "MNB Accuracy:  0.8235294117647058\n",
      "MNB F1:  0.8263612294232762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.73      0.82        44\n",
      "          1       0.79      0.98      0.88        58\n",
      "          2       1.00      0.80      0.89        15\n",
      "          3       1.00      0.95      0.97        19\n",
      "\n",
      "avg / total       0.89      0.88      0.87       136\n",
      "\n",
      "[32 12  0  0  1 57  0  0  1  2 12  0  0  1  0 18]\n",
      "svc Accuracy:  0.875\n",
      "svc F1:  0.8898244398244399\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        44\n",
      "          1       0.68      1.00      0.81        58\n",
      "          2       1.00      0.60      0.75        15\n",
      "          3       1.00      0.74      0.85        19\n",
      "\n",
      "avg / total       0.86      0.80      0.80       136\n",
      "\n",
      "[28 16  0  0  0 58  0  0  0  6  9  0  0  5  0 14]\n",
      "LR Accuracy:  0.8014705882352942\n",
      "LR F1:  0.7968628593628593\n",
      "For name:  s_brooks\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-8437-9788': 32, '0000-0002-4592-4974': 16, '0000-0002-5701-0125': 7, '0000-0001-6377-1644': 3})\n",
      "['0000-0002-8437-9788', '0000-0002-4592-4974']\n",
      "Total sample size after apply threshold:  48\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 179)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        32\n",
      "          1       1.00      0.62      0.77        16\n",
      "\n",
      "avg / total       0.89      0.88      0.87        48\n",
      "\n",
      "[32  0  6 10]\n",
      "MNB Accuracy:  0.875\n",
      "MNB F1:  0.8417582417582418\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        32\n",
      "          1       1.00      0.62      0.77        16\n",
      "\n",
      "avg / total       0.89      0.88      0.87        48\n",
      "\n",
      "[32  0  6 10]\n",
      "svc Accuracy:  0.875\n",
      "svc F1:  0.8417582417582418\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        32\n",
      "          1       1.00      0.38      0.55        16\n",
      "\n",
      "avg / total       0.84      0.79      0.76        48\n",
      "\n",
      "[32  0 10  6]\n",
      "LR Accuracy:  0.7916666666666666\n",
      "LR F1:  0.7051597051597052\n",
      "For name:  p_moreira\n",
      "total sample size before apply threshold:  217\n",
      "Counter({'0000-0001-5177-6747': 133, '0000-0002-7035-7799': 68, '0000-0002-2800-3903': 6, '0000-0002-5454-7971': 4, '0000-0003-0452-6790': 2, '0000-0002-0004-851X': 2, '0000-0001-7247-6815': 1, '0000-0001-6919-0904': 1})\n",
      "['0000-0001-5177-6747', '0000-0002-7035-7799']\n",
      "Total sample size after apply threshold:  201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(201, 1355)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "201\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       133\n",
      "          1       0.98      0.94      0.96        68\n",
      "\n",
      "avg / total       0.98      0.98      0.97       201\n",
      "\n",
      "[132   1   4  64]\n",
      "MNB Accuracy:  0.9751243781094527\n",
      "MNB F1:  0.9719093272213992\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       133\n",
      "          1       1.00      1.00      1.00        68\n",
      "\n",
      "avg / total       1.00      1.00      1.00       201\n",
      "\n",
      "[133   0   0  68]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       133\n",
      "          1       1.00      0.93      0.96        68\n",
      "\n",
      "avg / total       0.98      0.98      0.97       201\n",
      "\n",
      "[133   0   5  63]\n",
      "LR Accuracy:  0.9751243781094527\n",
      "LR F1:  0.9716909382834287\n",
      "For name:  s_mukhopadhyay\n",
      "total sample size before apply threshold:  119\n",
      "Counter({'0000-0001-8033-5748': 49, '0000-0001-9660-2599': 37, '0000-0003-1242-9958': 18, '0000-0003-4790-3090': 8, '0000-0002-1838-2815': 5, '0000-0002-4056-2185': 1, '0000-0002-6290-6380': 1})\n",
      "['0000-0003-1242-9958', '0000-0001-8033-5748', '0000-0001-9660-2599']\n",
      "Total sample size after apply threshold:  104\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(104, 189)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "104\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.22      0.36        18\n",
      "          1       0.73      0.94      0.82        49\n",
      "          2       0.84      0.84      0.84        37\n",
      "\n",
      "avg / total       0.82      0.78      0.75       104\n",
      "\n",
      "[ 4 11  3  0 46  3  0  6 31]\n",
      "MNB Accuracy:  0.7788461538461539\n",
      "MNB F1:  0.6743009243009243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.72      0.84        18\n",
      "          1       1.00      0.92      0.96        49\n",
      "          2       0.80      1.00      0.89        37\n",
      "\n",
      "avg / total       0.93      0.91      0.91       104\n",
      "\n",
      "[13  0  5  0 45  4  0  0 37]\n",
      "svc Accuracy:  0.9134615384615384\n",
      "svc F1:  0.8959075836634113\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        18\n",
      "          1       1.00      0.92      0.96        49\n",
      "          2       0.74      1.00      0.85        37\n",
      "\n",
      "avg / total       0.91      0.88      0.87       104\n",
      "\n",
      "[ 9  0  9  0 45  4  0  0 37]\n",
      "LR Accuracy:  0.875\n",
      "LR F1:  0.8248960626069944\n",
      "For name:  a_hudson\n",
      "total sample size before apply threshold:  129\n",
      "Counter({'0000-0003-1105-7646': 86, '0000-0002-0192-776X': 15, '0000-0003-1849-9666': 13, '0000-0001-7292-5406': 6, '0000-0001-6436-2025': 5, '0000-0001-9016-6917': 4})\n",
      "['0000-0002-0192-776X', '0000-0003-1849-9666', '0000-0003-1105-7646']\n",
      "Total sample size after apply threshold:  114\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(114, 243)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "114\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.85        15\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.83      1.00      0.91        86\n",
      "\n",
      "avg / total       0.76      0.85      0.80       114\n",
      "\n",
      "[11  0  4  0  0 13  0  0 86]\n",
      "MNB Accuracy:  0.8508771929824561\n",
      "MNB F1:  0.5854022520689187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       1.00      0.54      0.70        13\n",
      "          2       0.91      1.00      0.95        86\n",
      "\n",
      "avg / total       0.93      0.92      0.91       114\n",
      "\n",
      "[12  0  3  0  7  6  0  0 86]\n",
      "svc Accuracy:  0.9210526315789473\n",
      "svc F1:  0.846388377327604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        15\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.82      1.00      0.90        86\n",
      "\n",
      "avg / total       0.75      0.83      0.78       114\n",
      "\n",
      "[ 9  0  6  0  0 13  0  0 86]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.5501745200698079\n",
      "For name:  d_thomas\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0001-8832-5907': 17, '0000-0002-8141-3362': 11, '0000-0002-8278-5934': 10, '0000-0002-1307-6042': 6, '0000-0002-7976-4956': 6, '0000-0002-1053-129X': 5, '0000-0001-9415-5991': 4, '0000-0001-6867-5504': 2, '0000-0003-4295-9765': 1})\n",
      "['0000-0002-8278-5934', '0000-0001-8832-5907', '0000-0002-8141-3362']\n",
      "Total sample size after apply threshold:  38\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 75)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.81      1.00      0.89        17\n",
      "          2       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.91      0.89      0.89        38\n",
      "\n",
      "[ 8  2  0  0 17  0  0  2  9]\n",
      "MNB Accuracy:  0.8947368421052632\n",
      "MNB F1:  0.894541910331384\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.81      1.00      0.89        17\n",
      "          2       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.91      0.89      0.89        38\n",
      "\n",
      "[ 8  2  0  0 17  0  0  2  9]\n",
      "svc Accuracy:  0.8947368421052632\n",
      "svc F1:  0.894541910331384\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.74      1.00      0.85        17\n",
      "          2       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.88      0.84      0.84        38\n",
      "\n",
      "[ 6  4  0  0 17  0  0  2  9]\n",
      "LR Accuracy:  0.8421052631578947\n",
      "LR F1:  0.8333333333333334\n",
      "For name:  w_smith\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-4610-998X': 37, '0000-0003-2108-3899': 11, '0000-0002-5785-6489': 6, '0000-0001-9640-1172': 4, '0000-0003-1749-023X': 1, '0000-0001-6611-0817': 1, '0000-0002-8814-015X': 1})\n",
      "['0000-0002-4610-998X', '0000-0003-2108-3899']\n",
      "Total sample size after apply threshold:  48\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 169)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95        37\n",
      "          1       0.89      0.73      0.80        11\n",
      "\n",
      "avg / total       0.92      0.92      0.91        48\n",
      "\n",
      "[36  1  3  8]\n",
      "MNB Accuracy:  0.9166666666666666\n",
      "MNB F1:  0.8736842105263157\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        37\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.98      0.98      0.98        48\n",
      "\n",
      "[37  0  1 10]\n",
      "svc Accuracy:  0.9791666666666666\n",
      "svc F1:  0.9695238095238095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        37\n",
      "          1       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.91      0.90      0.88        48\n",
      "\n",
      "[37  0  5  6]\n",
      "LR Accuracy:  0.8958333333333334\n",
      "LR F1:  0.821295606850335\n",
      "For name:  l_martin\n",
      "total sample size before apply threshold:  253\n",
      "Counter({'0000-0001-8702-9946': 105, '0000-0003-4352-0914': 55, '0000-0002-5887-4937': 36, '0000-0003-1919-8646': 14, '0000-0001-7241-7110': 12, '0000-0002-1231-7932': 11, '0000-0002-0594-4516': 7, '0000-0002-5330-5700': 6, '0000-0003-1889-2513': 4, '0000-0002-4770-2849': 1, '0000-0001-9731-8071': 1, '0000-0001-9371-3402': 1})\n",
      "['0000-0001-7241-7110', '0000-0002-1231-7932', '0000-0002-5887-4937', '0000-0003-1919-8646', '0000-0001-8702-9946', '0000-0003-4352-0914']\n",
      "Total sample size after apply threshold:  233\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(233, 1160)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       1.00      0.64      0.78        11\n",
      "          2       1.00      0.39      0.56        36\n",
      "          3       0.00      0.00      0.00        14\n",
      "          4       0.66      1.00      0.79       105\n",
      "          5       0.98      0.93      0.95        55\n",
      "\n",
      "avg / total       0.73      0.76      0.71       233\n",
      "\n",
      "[  0   0   0   0  12   0   0   7   0   0   4   0   0   0  14   0  21   1\n",
      "   0   0   0   0  14   0   0   0   0   0 105   0   0   0   0   0   4  51]\n",
      "MNB Accuracy:  0.759656652360515\n",
      "MNB F1:  0.5139169393339733\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       1.00      0.64      0.78        11\n",
      "          2       1.00      0.78      0.88        36\n",
      "          3       1.00      0.79      0.88        14\n",
      "          4       0.81      1.00      0.89       105\n",
      "          5       1.00      0.93      0.96        55\n",
      "\n",
      "avg / total       0.91      0.89      0.89       233\n",
      "\n",
      "[  6   0   0   0   6   0   0   7   0   0   4   0   0   0  28   0   8   0\n",
      "   0   0   0  11   3   0   0   0   0   0 105   0   0   0   0   0   4  51]\n",
      "svc Accuracy:  0.8927038626609443\n",
      "svc F1:  0.8425542694440727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       1.00      0.64      0.78        11\n",
      "          2       1.00      0.36      0.53        36\n",
      "          3       1.00      0.50      0.67        14\n",
      "          4       0.62      1.00      0.77       105\n",
      "          5       0.97      0.65      0.78        55\n",
      "\n",
      "avg / total       0.77      0.72      0.69       233\n",
      "\n",
      "[  0   0   0   0  12   0   0   7   0   0   4   0   0   0  13   0  22   1\n",
      "   0   0   0   7   7   0   0   0   0   0 105   0   0   0   0   0  19  36]\n",
      "LR Accuracy:  0.721030042918455\n",
      "LR F1:  0.5873481237764685\n",
      "For name:  c_garcia\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0003-2825-1701': 46, '0000-0002-7583-5585': 37, '0000-0002-4400-9141': 13, '0000-0001-5260-5093': 8, '0000-0001-5138-6191': 1, '0000-0001-7997-9837': 1})\n",
      "['0000-0002-7583-5585', '0000-0003-2825-1701', '0000-0002-4400-9141']\n",
      "Total sample size after apply threshold:  96\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(96, 250)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "96\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.89      0.92        37\n",
      "          1       0.84      1.00      0.91        46\n",
      "          2       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.90      0.89      0.88        96\n",
      "\n",
      "[33  4  0  0 46  0  2  5  6]\n",
      "MNB Accuracy:  0.8854166666666666\n",
      "MNB F1:  0.8197122343813329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        37\n",
      "          1       0.87      1.00      0.93        46\n",
      "          2       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        96\n",
      "\n",
      "[33  4  0  0 46  0  0  3 10]\n",
      "svc Accuracy:  0.9270833333333334\n",
      "svc F1:  0.9139050965137923\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        37\n",
      "          1       0.72      1.00      0.84        46\n",
      "          2       1.00      0.15      0.27        13\n",
      "\n",
      "avg / total       0.87      0.81      0.78        96\n",
      "\n",
      "[30  7  0  0 46  0  0 11  2]\n",
      "LR Accuracy:  0.8125\n",
      "LR F1:  0.6661842303633349\n",
      "For name:  g_huang\n",
      "total sample size before apply threshold:  160\n",
      "Counter({'0000-0001-7004-826X': 52, '0000-0003-2965-0341': 31, '0000-0002-0001-888X': 22, '0000-0002-8391-4013': 17, '0000-0003-2170-0084': 16, '0000-0002-2249-1248': 9, '0000-0003-2518-8145': 6, '0000-0003-1695-1153': 2, '0000-0003-1073-4967': 2, '0000-0002-7597-9386': 2, '0000-0001-7780-7409': 1})\n",
      "['0000-0003-2965-0341', '0000-0003-2170-0084', '0000-0001-7004-826X', '0000-0002-0001-888X', '0000-0002-8391-4013']\n",
      "Total sample size after apply threshold:  138\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(138, 299)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "138\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.65      0.78        31\n",
      "          1       1.00      0.31      0.48        16\n",
      "          2       0.61      1.00      0.76        52\n",
      "          3       1.00      0.77      0.87        22\n",
      "          4       1.00      0.65      0.79        17\n",
      "\n",
      "avg / total       0.85      0.76      0.75       138\n",
      "\n",
      "[20  0 11  0  0  0  5 11  0  0  0  0 52  0  0  0  0  5 17  0  0  0  6  0\n",
      " 11]\n",
      "MNB Accuracy:  0.7608695652173914\n",
      "MNB F1:  0.7354274893562142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        31\n",
      "          1       1.00      0.75      0.86        16\n",
      "          2       0.96      1.00      0.98        52\n",
      "          3       1.00      0.91      0.95        22\n",
      "          4       1.00      0.94      0.97        17\n",
      "\n",
      "avg / total       0.95      0.95      0.95       138\n",
      "\n",
      "[31  0  0  0  0  2 12  2  0  0  0  0 52  0  0  2  0  0 20  0  1  0  0  0\n",
      " 16]\n",
      "svc Accuracy:  0.9492753623188406\n",
      "svc F1:  0.9371451978041672\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        31\n",
      "          1       1.00      0.62      0.77        16\n",
      "          2       0.87      1.00      0.93        52\n",
      "          3       1.00      0.73      0.84        22\n",
      "          4       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.91      0.89      0.89       138\n",
      "\n",
      "[31  0  0  0  0  2 10  4  0  0  0  0 52  0  0  2  0  4 16  0  3  0  0  0\n",
      " 14]\n",
      "LR Accuracy:  0.8913043478260869\n",
      "LR F1:  0.8683367984098773\n",
      "For name:  j_huber\n",
      "total sample size before apply threshold:  96\n",
      "Counter({'0000-0001-7243-8958': 59, '0000-0002-4790-7633': 21, '0000-0003-1046-2754': 14, '0000-0003-0073-0321': 2})\n",
      "['0000-0001-7243-8958', '0000-0003-1046-2754', '0000-0002-4790-7633']\n",
      "Total sample size after apply threshold:  94\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 232)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "94\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        59\n",
      "          1       1.00      0.07      0.13        14\n",
      "          2       1.00      0.62      0.76        21\n",
      "\n",
      "avg / total       0.84      0.78      0.72        94\n",
      "\n",
      "[59  0  0 13  1  0  8  0 13]\n",
      "MNB Accuracy:  0.776595744680851\n",
      "MNB F1:  0.5823200263318756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        59\n",
      "          1       1.00      0.64      0.78        14\n",
      "          2       1.00      0.62      0.76        21\n",
      "\n",
      "avg / total       0.89      0.86      0.85        94\n",
      "\n",
      "[59  0  0  5  9  0  8  0 13]\n",
      "svc Accuracy:  0.8617021276595744\n",
      "svc F1:  0.8160259789279136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      1.00      0.82        59\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       1.00      0.43      0.60        21\n",
      "\n",
      "avg / total       0.66      0.72      0.65        94\n",
      "\n",
      "[59  0  0 14  0  0 12  0  9]\n",
      "LR Accuracy:  0.723404255319149\n",
      "LR F1:  0.4731481481481481\n",
      "For name:  j_qin\n",
      "total sample size before apply threshold:  96\n",
      "Counter({'0000-0002-8559-616X': 48, '0000-0003-2448-8058': 38, '0000-0002-8186-5705': 4, '0000-0001-6271-068X': 3, '0000-0002-9166-3533': 3})\n",
      "['0000-0003-2448-8058', '0000-0002-8559-616X']\n",
      "Total sample size after apply threshold:  86\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 87)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.84      0.90        38\n",
      "          1       0.89      0.98      0.93        48\n",
      "\n",
      "avg / total       0.92      0.92      0.92        86\n",
      "\n",
      "[32  6  1 47]\n",
      "MNB Accuracy:  0.9186046511627907\n",
      "MNB F1:  0.9160507600055781\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        38\n",
      "          1       1.00      0.94      0.97        48\n",
      "\n",
      "avg / total       0.97      0.97      0.97        86\n",
      "\n",
      "[38  0  3 45]\n",
      "svc Accuracy:  0.9651162790697675\n",
      "svc F1:  0.9648836259697837\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96        38\n",
      "          1       0.96      0.98      0.97        48\n",
      "\n",
      "avg / total       0.97      0.97      0.97        86\n",
      "\n",
      "[36  2  1 47]\n",
      "LR Accuracy:  0.9651162790697675\n",
      "LR F1:  0.9645360824742267\n",
      "For name:  t_ho\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0002-3489-3594': 68, '0000-0003-0914-306X': 13, '0000-0003-1412-711X': 2})\n",
      "['0000-0002-3489-3594', '0000-0003-0914-306X']\n",
      "Total sample size after apply threshold:  81\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 294)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        68\n",
      "          1       1.00      0.31      0.47        13\n",
      "\n",
      "avg / total       0.90      0.89      0.86        81\n",
      "\n",
      "[68  0  9  4]\n",
      "MNB Accuracy:  0.8888888888888888\n",
      "MNB F1:  0.7042596348884381\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        68\n",
      "          1       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.98      0.98      0.97        81\n",
      "\n",
      "[68  0  2 11]\n",
      "svc Accuracy:  0.9753086419753086\n",
      "svc F1:  0.951086956521739\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        68\n",
      "          1       1.00      0.08      0.14        13\n",
      "\n",
      "avg / total       0.87      0.85      0.79        81\n",
      "\n",
      "[68  0 12  1]\n",
      "LR Accuracy:  0.8518518518518519\n",
      "LR F1:  0.5308880308880308\n",
      "For name:  c_keller\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0003-0529-3490': 10, '0000-0001-7400-9428': 2, '0000-0001-7915-7622': 2, '0000-0003-2505-7487': 1})\n",
      "['0000-0003-0529-3490']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  m_maia\n",
      "total sample size before apply threshold:  99\n",
      "Counter({'0000-0002-7034-8091': 88, '0000-0002-1716-6205': 6, '0000-0003-4383-3822': 3, '0000-0001-6395-1469': 1, '0000-0001-6688-2745': 1})\n",
      "['0000-0002-7034-8091']\n",
      "Total sample size after apply threshold:  88\n",
      "For name:  p_bates\n",
      "total sample size before apply threshold:  154\n",
      "Counter({'0000-0001-6861-5421': 87, '0000-0002-3918-5976': 49, '0000-0002-1291-3363': 17, '0000-0001-9192-9963': 1})\n",
      "['0000-0002-1291-3363', '0000-0002-3918-5976', '0000-0001-6861-5421']\n",
      "Total sample size after apply threshold:  153\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(153, 444)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        17\n",
      "          1       1.00      0.80      0.89        49\n",
      "          2       0.80      1.00      0.89        87\n",
      "\n",
      "avg / total       0.89      0.86      0.84       153\n",
      "\n",
      "[ 5  0 12  0 39 10  0  0 87]\n",
      "MNB Accuracy:  0.8562091503267973\n",
      "MNB F1:  0.7428880643166358\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        17\n",
      "          1       1.00      0.78      0.87        49\n",
      "          2       0.81      1.00      0.90        87\n",
      "\n",
      "avg / total       0.89      0.87      0.86       153\n",
      "\n",
      "[ 8  0  9  0 38 11  0  0 87]\n",
      "svc Accuracy:  0.869281045751634\n",
      "svc F1:  0.8034901449618833\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.30        17\n",
      "          1       1.00      0.61      0.76        49\n",
      "          2       0.72      1.00      0.84        87\n",
      "\n",
      "avg / total       0.84      0.78      0.75       153\n",
      "\n",
      "[ 3  0 14  0 30 19  0  0 87]\n",
      "LR Accuracy:  0.7843137254901961\n",
      "LR F1:  0.6333577936770012\n",
      "For name:  s_chow\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0001-9471-4722': 21, '0000-0002-3600-0497': 6, '0000-0003-0544-6928': 1, '0000-0002-4392-3863': 1})\n",
      "['0000-0001-9471-4722']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  m_simon\n",
      "total sample size before apply threshold:  66\n",
      "Counter({'0000-0003-3655-6329': 44, '0000-0003-2349-7219': 12, '0000-0003-0611-495X': 5, '0000-0002-1509-2847': 3, '0000-0003-3080-3675': 1, '0000-0002-0065-6486': 1})\n",
      "['0000-0003-3655-6329', '0000-0003-2349-7219']\n",
      "Total sample size after apply threshold:  56\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 195)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        44\n",
      "          1       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.88      0.86      0.83        56\n",
      "\n",
      "[44  0  8  4]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.7083333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        44\n",
      "          1       1.00      0.42      0.59        12\n",
      "\n",
      "avg / total       0.89      0.88      0.85        56\n",
      "\n",
      "[44  0  7  5]\n",
      "svc Accuracy:  0.875\n",
      "svc F1:  0.7572755417956656\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        44\n",
      "          1       1.00      0.08      0.15        12\n",
      "\n",
      "avg / total       0.84      0.80      0.73        56\n",
      "\n",
      "[44  0 11  1]\n",
      "LR Accuracy:  0.8035714285714286\n",
      "LR F1:  0.5213675213675214\n",
      "For name:  s_kar\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0002-9411-2091': 20, '0000-0002-3788-372X': 7, '0000-0002-5032-4770': 4, '0000-0003-3702-6207': 3, '0000-0002-0498-812X': 2})\n",
      "['0000-0002-9411-2091']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  d_vlachos\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0002-6795-8403': 80, '0000-0003-3740-2575': 19, '0000-0002-0430-2386': 1, '0000-0001-7225-2862': 1})\n",
      "['0000-0002-6795-8403', '0000-0003-3740-2575']\n",
      "Total sample size after apply threshold:  99\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(99, 133)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        80\n",
      "          1       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       1.00      1.00      1.00        99\n",
      "\n",
      "[80  0  0 19]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        80\n",
      "          1       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       1.00      1.00      1.00        99\n",
      "\n",
      "[80  0  0 19]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        80\n",
      "          1       1.00      0.63      0.77        19\n",
      "\n",
      "avg / total       0.93      0.93      0.92        99\n",
      "\n",
      "[80  0  7 12]\n",
      "LR Accuracy:  0.9292929292929293\n",
      "LR F1:  0.866138690361213\n",
      "For name:  e_law\n",
      "total sample size before apply threshold:  12\n",
      "Counter({'0000-0002-4021-2150': 5, '0000-0001-5089-6341': 3, '0000-0003-4456-1259': 3, '0000-0001-5591-7316': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_ribeiro\n",
      "total sample size before apply threshold:  134\n",
      "Counter({'0000-0001-8906-0189': 25, '0000-0002-5964-5001': 17, '0000-0001-5693-7861': 16, '0000-0001-6422-3279': 13, '0000-0001-9365-6057': 12, '0000-0001-6357-8115': 10, '0000-0002-7434-4813': 7, '0000-0002-9350-6419': 7, '0000-0003-4529-7832': 5, '0000-0003-1167-5559': 5, '0000-0001-9538-821X': 5, '0000-0001-7350-8751': 4, '0000-0003-3373-3246': 3, '0000-0003-4684-1262': 2, '0000-0001-9575-008X': 1, '0000-0003-1704-1362': 1, '0000-0002-6071-6479': 1})\n",
      "['0000-0001-6422-3279', '0000-0001-6357-8115', '0000-0001-8906-0189', '0000-0002-5964-5001', '0000-0001-5693-7861', '0000-0001-9365-6057']\n",
      "Total sample size after apply threshold:  93\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(93, 383)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      0.60      0.75        10\n",
      "          2       0.60      1.00      0.75        25\n",
      "          3       1.00      0.71      0.83        17\n",
      "          4       0.92      0.75      0.83        16\n",
      "          5       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.88      0.81      0.81        93\n",
      "\n",
      "[13  0  0  0  0  0  0  6  4  0  0  0  0  0 25  0  0  0  0  0  5 12  0  0\n",
      "  0  0  4  0 12  0  0  0  4  0  1  7]\n",
      "MNB Accuracy:  0.8064516129032258\n",
      "MNB F1:  0.8147138626287798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       0.62      1.00      0.77        25\n",
      "          3       1.00      0.65      0.79        17\n",
      "          4       0.92      0.75      0.83        16\n",
      "          5       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.89      0.83      0.83        93\n",
      "\n",
      "[13  0  0  0  0  0  0  7  3  0  0  0  0  0 25  0  0  0  0  0  6 11  0  0\n",
      "  0  0  4  0 12  0  0  0  2  0  1  9]\n",
      "svc Accuracy:  0.8279569892473119\n",
      "svc F1:  0.8438672551248616\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       1.00      0.60      0.75        10\n",
      "          2       0.54      1.00      0.70        25\n",
      "          3       1.00      0.59      0.74        17\n",
      "          4       1.00      0.75      0.86        16\n",
      "          5       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.88      0.77      0.78        93\n",
      "\n",
      "[12  0  1  0  0  0  0  6  4  0  0  0  0  0 25  0  0  0  0  0  7 10  0  0\n",
      "  0  0  4  0 12  0  0  0  5  0  0  7]\n",
      "LR Accuracy:  0.7741935483870968\n",
      "LR F1:  0.7914918425432385\n",
      "For name:  r_king\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0001-7208-4387': 39, '0000-0002-3550-4255': 19, '0000-0003-1312-5593': 8, '0000-0001-7495-6599': 2, '0000-0002-7926-3764': 1})\n",
      "['0000-0001-7208-4387', '0000-0002-3550-4255']\n",
      "Total sample size after apply threshold:  58\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(58, 151)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86        39\n",
      "          1       1.00      0.32      0.48        19\n",
      "\n",
      "avg / total       0.83      0.78      0.73        58\n",
      "\n",
      "[39  0 13  6]\n",
      "MNB Accuracy:  0.7758620689655172\n",
      "MNB F1:  0.6685714285714285\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        39\n",
      "          1       1.00      0.68      0.81        19\n",
      "\n",
      "avg / total       0.91      0.90      0.89        58\n",
      "\n",
      "[39  0  6 13]\n",
      "svc Accuracy:  0.896551724137931\n",
      "svc F1:  0.8705357142857144\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84        39\n",
      "          1       1.00      0.21      0.35        19\n",
      "\n",
      "avg / total       0.81      0.74      0.68        58\n",
      "\n",
      "[39  0 15  4]\n",
      "LR Accuracy:  0.7413793103448276\n",
      "LR F1:  0.5932678821879382\n",
      "For name:  o_nielsen\n",
      "total sample size before apply threshold:  212\n",
      "Counter({'0000-0003-4612-8635': 142, '0000-0003-3535-7862': 54, '0000-0002-0088-3937': 15, '0000-0001-8839-8671': 1})\n",
      "['0000-0003-4612-8635', '0000-0002-0088-3937', '0000-0003-3535-7862']\n",
      "Total sample size after apply threshold:  211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(211, 308)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97       142\n",
      "          1       1.00      0.73      0.85        15\n",
      "          2       0.96      0.94      0.95        54\n",
      "\n",
      "avg / total       0.96      0.96      0.96       211\n",
      "\n",
      "[140   0   2   4  11   0   3   0  51]\n",
      "MNB Accuracy:  0.957345971563981\n",
      "MNB F1:  0.9227610018930394\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       142\n",
      "          1       1.00      0.73      0.85        15\n",
      "          2       1.00      0.93      0.96        54\n",
      "\n",
      "avg / total       0.96      0.96      0.96       211\n",
      "\n",
      "[142   0   0   4  11   0   4   0  50]\n",
      "svc Accuracy:  0.9620853080568721\n",
      "svc F1:  0.9267650158061116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       142\n",
      "          1       1.00      0.60      0.75        15\n",
      "          2       1.00      0.70      0.83        54\n",
      "\n",
      "avg / total       0.91      0.90      0.89       211\n",
      "\n",
      "[142   0   0   6   9   0  16   0  38]\n",
      "LR Accuracy:  0.8957345971563981\n",
      "LR F1:  0.8347305105617125\n",
      "For name:  j_moreno\n",
      "total sample size before apply threshold:  138\n",
      "Counter({'0000-0003-0087-4659': 44, '0000-0002-8887-6087': 30, '0000-0002-7646-9345': 22, '0000-0001-9561-7764': 21, '0000-0002-3729-9523': 9, '0000-0002-0555-9888': 5, '0000-0002-3684-3726': 4, '0000-0001-6499-1120': 3})\n",
      "['0000-0002-8887-6087', '0000-0001-9561-7764', '0000-0002-7646-9345', '0000-0003-0087-4659']\n",
      "Total sample size after apply threshold:  117\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 398)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        30\n",
      "          1       1.00      0.90      0.95        21\n",
      "          2       1.00      1.00      1.00        22\n",
      "          3       0.85      1.00      0.92        44\n",
      "\n",
      "avg / total       0.94      0.93      0.93       117\n",
      "\n",
      "[24  0  0  6  0 19  0  2  0  0 22  0  0  0  0 44]\n",
      "MNB Accuracy:  0.9316239316239316\n",
      "MNB F1:  0.9388888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.87      0.84        30\n",
      "          1       1.00      0.90      0.95        21\n",
      "          2       1.00      0.95      0.98        22\n",
      "          3       0.89      0.91      0.90        44\n",
      "\n",
      "avg / total       0.91      0.91      0.91       117\n",
      "\n",
      "[26  0  0  4  1 19  0  1  1  0 21  0  4  0  0 40]\n",
      "svc Accuracy:  0.905982905982906\n",
      "svc F1:  0.9160825669900622\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        30\n",
      "          1       1.00      0.81      0.89        21\n",
      "          2       1.00      0.95      0.98        22\n",
      "          3       0.76      1.00      0.86        44\n",
      "\n",
      "avg / total       0.91      0.88      0.88       117\n",
      "\n",
      "[21  0  0  9  0 17  0  4  0  0 21  1  0  0  0 44]\n",
      "LR Accuracy:  0.8803418803418803\n",
      "LR F1:  0.889438884488924\n",
      "For name:  f_yu\n",
      "total sample size before apply threshold:  78\n",
      "Counter({'0000-0001-9306-1731': 30, '0000-0003-0268-199X': 23, '0000-0002-5221-281X': 7, '0000-0001-5808-9376': 6, '0000-0002-8140-8344': 5, '0000-0003-3859-4839': 5, '0000-0002-0358-2793': 2})\n",
      "['0000-0001-9306-1731', '0000-0003-0268-199X']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 156)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.95        30\n",
      "          1       0.95      0.91      0.93        23\n",
      "\n",
      "avg / total       0.94      0.94      0.94        53\n",
      "\n",
      "[29  1  2 21]\n",
      "MNB Accuracy:  0.9433962264150944\n",
      "MNB F1:  0.9420765027322404\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94        30\n",
      "          1       0.95      0.87      0.91        23\n",
      "\n",
      "avg / total       0.93      0.92      0.92        53\n",
      "\n",
      "[29  1  3 20]\n",
      "svc Accuracy:  0.9245283018867925\n",
      "svc F1:  0.9222873900293254\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92        30\n",
      "          1       0.95      0.83      0.88        23\n",
      "\n",
      "avg / total       0.91      0.91      0.90        53\n",
      "\n",
      "[29  1  4 19]\n",
      "LR Accuracy:  0.9056603773584906\n",
      "LR F1:  0.9021779254337394\n",
      "For name:  f_esposito\n",
      "total sample size before apply threshold:  342\n",
      "Counter({'0000-0002-5099-9786': 92, '0000-0003-1051-5924': 91, '0000-0001-9340-6875': 53, '0000-0002-4420-2611': 44, '0000-0003-2550-0805': 26, '0000-0001-9725-7977': 25, '0000-0001-7781-2558': 7, '0000-0003-0586-5866': 2, '0000-0001-9962-1648': 1, '0000-0002-1075-3239': 1})\n",
      "['0000-0003-2550-0805', '0000-0001-9340-6875', '0000-0002-4420-2611', '0000-0002-5099-9786', '0000-0001-9725-7977', '0000-0003-1051-5924']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 331\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(331, 1340)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "331\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        26\n",
      "          1       1.00      0.92      0.96        53\n",
      "          2       1.00      0.89      0.94        44\n",
      "          3       0.96      1.00      0.98        92\n",
      "          4       1.00      0.76      0.86        25\n",
      "          5       0.85      0.99      0.91        91\n",
      "\n",
      "avg / total       0.95      0.94      0.94       331\n",
      "\n",
      "[22  0  0  1  0  3  0 49  0  1  0  3  0  0 39  1  0  4  0  0  0 92  0  0\n",
      "  0  0  0  0 19  6  0  0  0  1  0 90]\n",
      "MNB Accuracy:  0.9395770392749244\n",
      "MNB F1:  0.9288792280307937\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        26\n",
      "          1       1.00      0.94      0.97        53\n",
      "          2       1.00      0.98      0.99        44\n",
      "          3       0.92      1.00      0.96        92\n",
      "          4       1.00      0.96      0.98        25\n",
      "          5       0.99      0.98      0.98        91\n",
      "\n",
      "avg / total       0.97      0.97      0.97       331\n",
      "\n",
      "[24  0  0  1  0  1  0 50  0  3  0  0  0  0 43  1  0  0  0  0  0 92  0  0\n",
      "  0  0  0  1 24  0  0  0  0  2  0 89]\n",
      "svc Accuracy:  0.972809667673716\n",
      "svc F1:  0.9734550196611452\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        26\n",
      "          1       1.00      0.91      0.95        53\n",
      "          2       1.00      0.89      0.94        44\n",
      "          3       0.83      1.00      0.91        92\n",
      "          4       1.00      0.96      0.98        25\n",
      "          5       0.99      0.96      0.97        91\n",
      "\n",
      "avg / total       0.95      0.94      0.94       331\n",
      "\n",
      "[21  0  0  4  0  1  0 48  0  5  0  0  0  0 39  5  0  0  0  0  0 92  0  0\n",
      "  0  0  0  1 24  0  0  0  0  4  0 87]\n",
      "LR Accuracy:  0.9395770392749244\n",
      "LR F1:  0.9403223206089438\n",
      "For name:  p_miranda\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0002-6793-8111': 37, '0000-0002-2890-0268': 14, '0000-0002-6418-3614': 7, '0000-0003-4348-110X': 6, '0000-0001-6496-697X': 3, '0000-0002-4288-9456': 1, '0000-0002-3249-0193': 1})\n",
      "['0000-0002-6793-8111', '0000-0002-2890-0268']\n",
      "Total sample size after apply threshold:  51\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 129)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        37\n",
      "          1       1.00      0.43      0.60        14\n",
      "\n",
      "avg / total       0.87      0.84      0.82        51\n",
      "\n",
      "[37  0  8  6]\n",
      "MNB Accuracy:  0.8431372549019608\n",
      "MNB F1:  0.751219512195122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90        37\n",
      "          1       0.88      0.50      0.64        14\n",
      "\n",
      "avg / total       0.85      0.84      0.83        51\n",
      "\n",
      "[36  1  7  7]\n",
      "svc Accuracy:  0.8431372549019608\n",
      "svc F1:  0.7681818181818182\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        37\n",
      "          1       1.00      0.07      0.13        14\n",
      "\n",
      "avg / total       0.81      0.75      0.65        51\n",
      "\n",
      "[37  0 13  1]\n",
      "LR Accuracy:  0.7450980392156863\n",
      "LR F1:  0.4919540229885057\n",
      "For name:  s_yang\n",
      "total sample size before apply threshold:  611\n",
      "Counter({'0000-0002-6469-8415': 108, '0000-0003-1301-3030': 94, '0000-0002-8835-5302': 43, '0000-0001-6795-8879': 36, '0000-0003-1751-4975': 33, '0000-0002-8572-4977': 31, '0000-0002-9394-9148': 26, '0000-0002-9879-0164': 25, '0000-0001-7892-7648': 21, '0000-0002-1726-0576': 20, '0000-0001-5684-6388': 19, '0000-0002-6888-7993': 17, '0000-0001-9170-2566': 17, '0000-0003-1809-2938': 14, '0000-0001-9282-2041': 14, '0000-0003-3408-2019': 12, '0000-0002-8244-3002': 12, '0000-0001-9947-2822': 10, '0000-0002-4409-3160': 10, '0000-0002-0281-5858': 9, '0000-0002-2068-7618': 5, '0000-0001-6129-627X': 5, '0000-0002-8200-9898': 5, '0000-0001-8727-7528': 5, '0000-0001-7727-9669': 4, '0000-0002-8002-5800': 4, '0000-0001-7222-4917': 3, '0000-0002-5990-8529': 2, '0000-0003-0338-4268': 2, '0000-0002-6880-8861': 1, '0000-0001-7207-4082': 1, '0000-0001-7522-1463': 1, '0000-0003-3742-9989': 1, '0000-0002-3888-3211': 1})\n",
      "['0000-0002-6888-7993', '0000-0001-9947-2822', '0000-0003-1751-4975', '0000-0002-6469-8415', '0000-0003-3408-2019', '0000-0003-1809-2938', '0000-0003-1301-3030', '0000-0001-9282-2041', '0000-0002-8572-4977', '0000-0002-9394-9148', '0000-0002-4409-3160', '0000-0001-5684-6388', '0000-0001-7892-7648', '0000-0001-9170-2566', '0000-0002-8244-3002', '0000-0001-6795-8879', '0000-0002-9879-0164', '0000-0002-8835-5302', '0000-0002-1726-0576']\n",
      "Total sample size after apply threshold:  562\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(562, 632)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        17\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.68      0.64      0.66        33\n",
      "          3       0.39      0.97      0.56       108\n",
      "          4       0.00      0.00      0.00        12\n",
      "          5       1.00      0.07      0.13        14\n",
      "          6       0.65      0.99      0.78        94\n",
      "          7       1.00      0.43      0.60        14\n",
      "          8       0.90      0.29      0.44        31\n",
      "          9       1.00      0.23      0.38        26\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       1.00      0.79      0.88        19\n",
      "         12       0.58      0.67      0.62        21\n",
      "         13       1.00      0.29      0.45        17\n",
      "         14       0.00      0.00      0.00        12\n",
      "         15       1.00      0.33      0.50        36\n",
      "         16       1.00      0.20      0.33        25\n",
      "         17       1.00      0.67      0.81        43\n",
      "         18       1.00      0.30      0.46        20\n",
      "\n",
      "avg / total       0.68      0.58      0.53       562\n",
      "\n",
      "[  0   0   0  14   0   0   3   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  21   9   0   0   2   0   0   0   0   0   1   0   0   0\n",
      "   0   0   0   0   0   0 105   0   0   3   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   1   7   0   0   4   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   6   5   0   1   0   0   0   0   0   0   2\n",
      "   0   0   0   0   0   0   0   0   0   1   0   0  93   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   5   0   0   3   6   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  15   0   0   7   0   9   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  17   0   0   3   0   0\n",
      "   6   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0\n",
      "   0   0   0   0   7   0   0   0   0   0   0   0   0   0   4   0   0   0\n",
      "   0   0   0   0  15   0   0   0   0   0   0   0   0   0   3   4   0   0\n",
      "   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   7   0\n",
      "   0   5   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   9\n",
      "   0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  20   0   0   4   0   0   0   0   0   0   0   0  12   0   0   0   0   0\n",
      "   0  11   0   0   8   0   1   0   0   0   0   0   0   0   5   0   0   0\n",
      "   0   0   9   0   0   5   0   0   0   0   0   0   0   0   0   0  29   0\n",
      "   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   6]\n",
      "MNB Accuracy:  0.5818505338078291\n",
      "MNB F1:  0.40026289453946545\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        17\n",
      "          1       1.00      0.50      0.67        10\n",
      "          2       0.83      0.91      0.87        33\n",
      "          3       0.54      0.91      0.68       108\n",
      "          4       1.00      0.58      0.74        12\n",
      "          5       1.00      0.79      0.88        14\n",
      "          6       0.94      0.90      0.92        94\n",
      "          7       1.00      0.79      0.88        14\n",
      "          8       0.77      0.65      0.70        31\n",
      "          9       0.95      0.77      0.85        26\n",
      "         10       0.60      0.30      0.40        10\n",
      "         11       1.00      0.95      0.97        19\n",
      "         12       0.68      0.71      0.70        21\n",
      "         13       1.00      0.82      0.90        17\n",
      "         14       0.70      0.58      0.64        12\n",
      "         15       0.82      0.64      0.72        36\n",
      "         16       0.78      0.56      0.65        25\n",
      "         17       0.95      0.81      0.88        43\n",
      "         18       1.00      0.85      0.92        20\n",
      "\n",
      "avg / total       0.83      0.78      0.78       562\n",
      "\n",
      "[ 6  0  0  8  0  0  1  0  1  0  0  0  0  0  0  1  0  0  0  0  5  0  5  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 30  1  0  0  0  0  0  1\n",
      "  0  0  1  0  0  0  0  0  0  0  0  0 98  0  0  2  0  0  0  0  0  0  0  3\n",
      "  4  1  0  0  0  0  1  4  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  2  0 11  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  9  0  0\n",
      " 85  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0 11  0  0  0\n",
      "  0  0  0  0  0  0  2  0  0  0  1  8  0  0  0  0 20  0  0  0  0  0  0  0\n",
      "  2  0  0  0  0  0  6  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  2  0  0  0  0  0  0  3  0  5  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0 18  0  0  0  0  0  0  0  0  0  3  1  0  0  0  0  0  0  2  0\n",
      " 15  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0 14  0  0  1\n",
      "  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0\n",
      " 10  0  0  2  0  1  0  0  0  0  0  0 23  0  0  0  0  0  1  6  0  0  0  0\n",
      "  4  0  0  0  0  0  0  0 14  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 35  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 17]\n",
      "svc Accuracy:  0.7811387900355872\n",
      "svc F1:  0.7624299199237548\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.11        17\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.74      0.76      0.75        33\n",
      "          3       0.47      0.94      0.62       108\n",
      "          4       1.00      0.17      0.29        12\n",
      "          5       1.00      0.71      0.83        14\n",
      "          6       0.91      0.91      0.91        94\n",
      "          7       1.00      0.71      0.83        14\n",
      "          8       0.82      0.58      0.68        31\n",
      "          9       0.93      0.50      0.65        26\n",
      "         10       1.00      0.20      0.33        10\n",
      "         11       1.00      0.89      0.94        19\n",
      "         12       0.67      0.67      0.67        21\n",
      "         13       1.00      0.65      0.79        17\n",
      "         14       0.67      0.17      0.27        12\n",
      "         15       0.80      0.67      0.73        36\n",
      "         16       0.76      0.64      0.70        25\n",
      "         17       0.97      0.79      0.87        43\n",
      "         18       1.00      0.85      0.92        20\n",
      "\n",
      "avg / total       0.79      0.72      0.70       562\n",
      "\n",
      "[  1   0   0  13   0   0   1   0   0   0   0   0   0   0   0   1   0   1\n",
      "   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  25   6   0   0   0   0   1   0   0   0   1   0   0   0\n",
      "   0   0   0   0   0   0 101   0   0   1   0   0   0   0   0   0   0   1\n",
      "   4   1   0   0   0   0   1   8   2   0   0   0   0   0   0   0   0   0\n",
      "   0   0   1   0   0   0   0   1   3   0  10   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   7   0   0  86   0   0   0   0   0\n",
      "   0   0   0   1   0   0   0   0   0   0   3   0   0   0  10   0   1   0\n",
      "   0   0   0   0   0   0   0   0   0   0   1  11   0   0   0   0  18   0\n",
      "   0   0   0   0   0   0   1   0   0   0   0   0  13   0   0   0   0   0\n",
      "  13   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0\n",
      "   0   0   2   0   6   0   0   0   0   0   0   0   0   0   2   0   0   0\n",
      "   0   0   0   0  17   0   0   0   0   0   0   0   0   0   4   3   0   0\n",
      "   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   3   0\n",
      "   0   0   0   1   0   0   0   0  11   0   0   2   0   0   0   0   0   9\n",
      "   0   0   1   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0\n",
      "  10   0   0   2   0   0   0   0   0   0   0   0  24   0   0   0   0   0\n",
      "   2   3   0   0   2   0   2   0   0   0   0   0   0   0  16   0   0   0\n",
      "   0   0   7   0   0   2   0   0   0   0   0   0   0   0   0   0  34   0\n",
      "   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  17]\n",
      "LR Accuracy:  0.7170818505338078\n",
      "LR F1:  0.6253190243970358\n",
      "For name:  d_huang\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0002-6192-259X': 20, '0000-0003-2048-4500': 15, '0000-0002-1497-1284': 2, '0000-0002-0658-8752': 1})\n",
      "['0000-0002-6192-259X', '0000-0003-2048-4500']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 94)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        20\n",
      "          1       1.00      0.47      0.64        15\n",
      "\n",
      "avg / total       0.84      0.77      0.75        35\n",
      "\n",
      "[20  0  8  7]\n",
      "MNB Accuracy:  0.7714285714285715\n",
      "MNB F1:  0.7348484848484849\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        20\n",
      "          1       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        35\n",
      "\n",
      "[20  0  0 15]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        20\n",
      "          1       1.00      0.47      0.64        15\n",
      "\n",
      "avg / total       0.84      0.77      0.75        35\n",
      "\n",
      "[20  0  8  7]\n",
      "LR Accuracy:  0.7714285714285715\n",
      "LR F1:  0.7348484848484849\n",
      "For name:  h_kuo\n",
      "total sample size before apply threshold:  144\n",
      "Counter({'0000-0002-3295-2984': 98, '0000-0003-1336-1203': 26, '0000-0001-6752-2231': 16, '0000-0002-0349-6983': 2, '0000-0001-9102-5104': 1, '0000-0002-0573-2636': 1})\n",
      "['0000-0003-1336-1203', '0000-0001-6752-2231', '0000-0002-3295-2984']\n",
      "Total sample size after apply threshold:  140\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 154)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "140\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        26\n",
      "          1       0.86      0.38      0.52        16\n",
      "          2       0.81      0.99      0.89        98\n",
      "\n",
      "avg / total       0.85      0.83      0.81       140\n",
      "\n",
      "[13  0 13  0  6 10  0  1 97]\n",
      "MNB Accuracy:  0.8285714285714286\n",
      "MNB F1:  0.6927713513273943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.92      0.94        26\n",
      "          1       1.00      0.88      0.93        16\n",
      "          2       0.96      0.99      0.97        98\n",
      "\n",
      "avg / total       0.96      0.96      0.96       140\n",
      "\n",
      "[24  0  2  0 14  2  1  0 97]\n",
      "svc Accuracy:  0.9642857142857143\n",
      "svc F1:  0.9497947252602884\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.51        26\n",
      "          1       1.00      0.38      0.55        16\n",
      "          2       0.78      1.00      0.88        98\n",
      "\n",
      "avg / total       0.85      0.81      0.77       140\n",
      "\n",
      "[ 9  0 17  0  6 10  0  0 98]\n",
      "LR Accuracy:  0.8071428571428572\n",
      "LR F1:  0.6462213421854677\n",
      "For name:  a_santoro\n",
      "total sample size before apply threshold:  189\n",
      "Counter({'0000-0002-0798-6816': 83, '0000-0003-1709-9492': 58, '0000-0002-5086-1453': 21, '0000-0003-2503-8219': 10, '0000-0002-1014-197X': 9, '0000-0002-6193-2050': 8})\n",
      "['0000-0003-1709-9492', '0000-0002-5086-1453', '0000-0003-2503-8219', '0000-0002-0798-6816']\n",
      "Total sample size after apply threshold:  172\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(172, 717)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "172\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        58\n",
      "          1       1.00      1.00      1.00        21\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.77      1.00      0.87        83\n",
      "\n",
      "avg / total       0.83      0.85      0.83       172\n",
      "\n",
      "[43  0  0 15  0 21  0  0  0  0  0 10  0  0  0 83]\n",
      "MNB Accuracy:  0.8546511627906976\n",
      "MNB F1:  0.6801487740397076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94        58\n",
      "          1       1.00      1.00      1.00        21\n",
      "          2       1.00      0.60      0.75        10\n",
      "          3       0.99      0.98      0.98        83\n",
      "\n",
      "avg / total       0.96      0.96      0.96       172\n",
      "\n",
      "[57  0  0  1  0 21  0  0  4  0  6  0  2  0  0 81]\n",
      "svc Accuracy:  0.9593023255813954\n",
      "svc F1:  0.9184917355371901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.86      0.92        58\n",
      "          1       1.00      1.00      1.00        21\n",
      "          2       1.00      0.20      0.33        10\n",
      "          3       0.85      1.00      0.92        83\n",
      "\n",
      "avg / total       0.92      0.91      0.89       172\n",
      "\n",
      "[50  0  0  8  0 21  0  0  1  0  2  7  0  0  0 83]\n",
      "LR Accuracy:  0.9069767441860465\n",
      "LR F1:  0.7919728994542721\n",
      "For name:  q_lu\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-2804-0827': 22, '0000-0002-4261-5121': 5, '0000-0002-4514-0969': 4, '0000-0002-7952-2332': 3, '0000-0001-6234-4384': 1})\n",
      "['0000-0002-2804-0827']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  s_kumar\n",
      "total sample size before apply threshold:  419\n",
      "Counter({'0000-0003-4326-5941': 130, '0000-0002-4003-4411': 42, '0000-0003-2405-3791': 25, '0000-0003-0658-8709': 21, '0000-0001-8373-105X': 19, '0000-0001-5902-6641': 18, '0000-0001-5940-9490': 14, '0000-0003-0562-2645': 13, '0000-0003-2130-7493': 13, '0000-0003-0423-2880': 9, '0000-0001-9905-4831': 9, '0000-0002-5082-8602': 8, '0000-0002-1457-5804': 8, '0000-0001-9261-2263': 8, '0000-0002-0605-6908': 7, '0000-0001-5396-5509': 7, '0000-0002-6701-6889': 6, '0000-0002-5474-8095': 4, '0000-0002-0384-1580': 4, '0000-0003-2920-8924': 4, '0000-0003-3514-8999': 4, '0000-0001-9673-5842': 4, '0000-0001-6511-5309': 4, '0000-0002-2358-2344': 4, '0000-0002-4405-4444': 3, '0000-0003-2685-9940': 3, '0000-0002-4044-7005': 3, '0000-0001-6594-9266': 3, '0000-0001-5223-1466': 2, '0000-0001-8407-3562': 2, '0000-0001-9132-1202': 2, '0000-0002-9054-2123': 2, '0000-0002-6772-7250': 2, '0000-0001-6680-718X': 1, '0000-0001-9525-4836': 1, '0000-0001-7070-057X': 1, '0000-0002-6425-278X': 1, '0000-0003-0832-4811': 1, '0000-0002-5838-3994': 1, '0000-0002-2284-4576': 1, '0000-0001-6221-4512': 1, '0000-0001-9411-3863': 1, '0000-0002-0951-4214': 1, '0000-0003-3389-5368': 1, '0000-0002-4190-620X': 1})\n",
      "['0000-0001-8373-105X', '0000-0001-5940-9490', '0000-0003-4326-5941', '0000-0003-2405-3791', '0000-0002-4003-4411', '0000-0003-0658-8709', '0000-0003-0562-2645', '0000-0001-5902-6641', '0000-0003-2130-7493']\n",
      "Total sample size after apply threshold:  295\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(295, 666)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "295\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.11      0.19        19\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.58      1.00      0.74       130\n",
      "          3       0.93      0.52      0.67        25\n",
      "          4       1.00      0.71      0.83        42\n",
      "          5       0.93      0.67      0.78        21\n",
      "          6       1.00      0.54      0.70        13\n",
      "          7       1.00      0.06      0.11        18\n",
      "          8       1.00      0.23      0.38        13\n",
      "\n",
      "avg / total       0.76      0.68      0.62       295\n",
      "\n",
      "[  2   0  17   0   0   0   0   0   0   0   0  13   1   0   0   0   0   0\n",
      "   0   0 130   0   0   0   0   0   0   0   0  11  13   0   1   0   0   0\n",
      "   0   0  12   0  30   0   0   0   0   0   0   7   0   0  14   0   0   0\n",
      "   0   0   6   0   0   0   7   0   0   0   0  17   0   0   0   0   1   0\n",
      "   0   0  10   0   0   0   0   0   3]\n",
      "MNB Accuracy:  0.6779661016949152\n",
      "MNB F1:  0.48722900394412744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91        19\n",
      "          1       1.00      0.57      0.73        14\n",
      "          2       0.76      1.00      0.87       130\n",
      "          3       0.89      0.64      0.74        25\n",
      "          4       1.00      0.79      0.88        42\n",
      "          5       1.00      0.86      0.92        21\n",
      "          6       1.00      0.69      0.82        13\n",
      "          7       1.00      0.67      0.80        18\n",
      "          8       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.89      0.86      0.85       295\n",
      "\n",
      "[ 16   0   3   0   0   0   0   0   0   0   8   5   1   0   0   0   0   0\n",
      "   0   0 130   0   0   0   0   0   0   0   0   9  16   0   0   0   0   0\n",
      "   0   0   9   0  33   0   0   0   0   0   0   2   1   0  18   0   0   0\n",
      "   0   0   4   0   0   0   9   0   0   0   0   6   0   0   0   0  12   0\n",
      "   0   0   2   0   0   0   0   0  11]\n",
      "svc Accuracy:  0.8576271186440678\n",
      "svc F1:  0.8433707291846827\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        19\n",
      "          1       1.00      0.43      0.60        14\n",
      "          2       0.60      1.00      0.75       130\n",
      "          3       0.92      0.48      0.63        25\n",
      "          4       1.00      0.52      0.69        42\n",
      "          5       0.90      0.43      0.58        21\n",
      "          6       1.00      0.62      0.76        13\n",
      "          7       1.00      0.33      0.50        18\n",
      "          8       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.81      0.71      0.68       295\n",
      "\n",
      "[  6   0  13   0   0   0   0   0   0   0   6   7   1   0   0   0   0   0\n",
      "   0   0 130   0   0   0   0   0   0   0   0  12  12   0   1   0   0   0\n",
      "   0   0  20   0  22   0   0   0   0   0   0  12   0   0   9   0   0   0\n",
      "   0   0   5   0   0   0   8   0   0   0   0  12   0   0   0   0   6   0\n",
      "   0   0   4   0   0   0   0   0   9]\n",
      "LR Accuracy:  0.7050847457627119\n",
      "LR F1:  0.6459370974612357\n",
      "For name:  s_rocha\n",
      "total sample size before apply threshold:  139\n",
      "Counter({'0000-0002-2413-4981': 47, '0000-0003-4196-2217': 41, '0000-0002-0396-3019': 36, '0000-0002-9705-1511': 8, '0000-0002-4686-2410': 5, '0000-0002-1324-5707': 2})\n",
      "['0000-0002-2413-4981', '0000-0003-4196-2217', '0000-0002-0396-3019']\n",
      "Total sample size after apply threshold:  124\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(124, 236)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "124\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98        47\n",
      "          1       0.89      1.00      0.94        41\n",
      "          2       0.97      0.83      0.90        36\n",
      "\n",
      "avg / total       0.95      0.94      0.94       124\n",
      "\n",
      "[46  0  1  0 41  0  1  5 30]\n",
      "MNB Accuracy:  0.9435483870967742\n",
      "MNB F1:  0.9389248426490681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        47\n",
      "          1       1.00      1.00      1.00        41\n",
      "          2       1.00      0.83      0.91        36\n",
      "\n",
      "avg / total       0.96      0.95      0.95       124\n",
      "\n",
      "[47  0  0  0 41  0  6  0 30]\n",
      "svc Accuracy:  0.9516129032258065\n",
      "svc F1:  0.9496969696969697\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        47\n",
      "          1       1.00      1.00      1.00        41\n",
      "          2       1.00      0.81      0.89        36\n",
      "\n",
      "avg / total       0.95      0.94      0.94       124\n",
      "\n",
      "[47  0  0  0 41  0  7  0 29]\n",
      "LR Accuracy:  0.9435483870967742\n",
      "LR F1:  0.941000253871541\n",
      "For name:  t_han\n",
      "total sample size before apply threshold:  53\n",
      "Counter({'0000-0002-9063-4052': 42, '0000-0002-3095-7714': 8, '0000-0003-3535-8582': 2, '0000-0003-1404-1578': 1})\n",
      "['0000-0002-9063-4052']\n",
      "Total sample size after apply threshold:  42\n",
      "For name:  m_sandberg\n",
      "total sample size before apply threshold:  59\n",
      "Counter({'0000-0002-4812-0103': 39, '0000-0001-5486-7556': 9, '0000-0002-8915-8730': 7, '0000-0003-0809-0656': 2, '0000-0001-9495-3571': 2})\n",
      "['0000-0002-4812-0103']\n",
      "Total sample size after apply threshold:  39\n",
      "For name:  j_marshall\n",
      "total sample size before apply threshold:  80\n",
      "Counter({'0000-0003-1361-2869': 28, '0000-0002-8344-2589': 16, '0000-0002-0494-2295': 11, '0000-0001-5491-2919': 10, '0000-0002-2784-1817': 8, '0000-0002-5829-9688': 5, '0000-0001-7617-4101': 1, '0000-0002-7864-803X': 1})\n",
      "['0000-0001-5491-2919', '0000-0002-0494-2295', '0000-0002-8344-2589', '0000-0003-1361-2869']\n",
      "Total sample size after apply threshold:  65\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 249)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       1.00      0.27      0.43        11\n",
      "          2       0.93      0.81      0.87        16\n",
      "          3       0.64      1.00      0.78        28\n",
      "\n",
      "avg / total       0.83      0.74      0.71        65\n",
      "\n",
      "[ 4  0  1  5  0  3  0  8  0  0 13  3  0  0  0 28]\n",
      "MNB Accuracy:  0.7384615384615385\n",
      "MNB F1:  0.6611111111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       1.00      0.88      0.93        16\n",
      "          3       0.78      1.00      0.88        28\n",
      "\n",
      "avg / total       0.90      0.88      0.88        65\n",
      "\n",
      "[ 7  0  0  3  0  8  0  3  0  0 14  2  0  0  0 28]\n",
      "svc Accuracy:  0.8769230769230769\n",
      "svc F1:  0.8684920020639835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       1.00      0.69      0.81        16\n",
      "          3       0.57      1.00      0.73        28\n",
      "\n",
      "avg / total       0.82      0.68      0.63        65\n",
      "\n",
      "[ 4  0  0  6  0  1  0 10  0  0 11  5  0  0  0 28]\n",
      "LR Accuracy:  0.676923076923077\n",
      "LR F1:  0.5700456950456951\n",
      "For name:  f_bianchi\n",
      "total sample size before apply threshold:  131\n",
      "Counter({'0000-0002-3459-9301': 54, '0000-0001-7880-5624': 37, '0000-0002-2863-1598': 16, '0000-0003-2996-3604': 12, '0000-0001-5197-5279': 11, '0000-0002-7145-3846': 1})\n",
      "['0000-0001-7880-5624', '0000-0002-2863-1598', '0000-0003-2996-3604', '0000-0002-3459-9301', '0000-0001-5197-5279']\n",
      "Total sample size after apply threshold:  130\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 669)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "130\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        37\n",
      "          1       1.00      0.81      0.90        16\n",
      "          2       1.00      0.92      0.96        12\n",
      "          3       0.90      0.96      0.93        54\n",
      "          4       1.00      0.27      0.43        11\n",
      "\n",
      "avg / total       0.91      0.89      0.88       130\n",
      "\n",
      "[37  0  0  0  0  1 13  0  2  0  0  0 11  1  0  2  0  0 52  0  5  0  0  3\n",
      "  3]\n",
      "MNB Accuracy:  0.8923076923076924\n",
      "MNB F1:  0.8225310689602935\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        37\n",
      "          1       1.00      0.88      0.93        16\n",
      "          2       1.00      0.92      0.96        12\n",
      "          3       0.87      1.00      0.93        54\n",
      "          4       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.95      0.94      0.94       130\n",
      "\n",
      "[34  0  0  3  0  0 14  0  2  0  0  0 11  1  0  0  0  0 54  0  0  0  0  2\n",
      "  9]\n",
      "svc Accuracy:  0.9384615384615385\n",
      "svc F1:  0.9357272068191257\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        37\n",
      "          1       1.00      0.62      0.77        16\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       0.74      1.00      0.85        54\n",
      "          4       1.00      0.27      0.43        11\n",
      "\n",
      "avg / total       0.89      0.85      0.84       130\n",
      "\n",
      "[34  0  0  3  0  0 10  0  6  0  0  0 10  2  0  0  0  0 54  0  0  0  0  8\n",
      "  3]\n",
      "LR Accuracy:  0.8538461538461538\n",
      "LR F1:  0.7830066573107495\n",
      "For name:  c_liu\n",
      "total sample size before apply threshold:  681\n",
      "Counter({'0000-0003-3622-9707': 63, '0000-0001-7016-8990': 58, '0000-0003-2336-4731': 56, '0000-0001-8816-4832': 51, '0000-0002-0703-0742': 46, '0000-0002-6109-5707': 29, '0000-0002-2521-924X': 29, '0000-0001-7433-2081': 27, '0000-0002-5723-177X': 25, '0000-0001-8063-7906': 23, '0000-0001-5546-3852': 19, '0000-0001-9918-1638': 18, '0000-0001-7888-9725': 17, '0000-0002-5323-6733': 16, '0000-0003-3410-445X': 16, '0000-0003-1882-3892': 16, '0000-0002-3151-7956': 16, '0000-0001-7343-3884': 14, '0000-0002-6202-0993': 13, '0000-0001-7364-8412': 12, '0000-0002-8582-912X': 11, '0000-0002-4693-5667': 11, '0000-0001-8918-5627': 10, '0000-0002-6439-8754': 10, '0000-0002-6650-6245': 7, '0000-0003-1028-2454': 7, '0000-0001-7954-0736': 5, '0000-0002-9780-9062': 5, '0000-0002-6257-0389': 5, '0000-0002-2106-202X': 4, '0000-0002-2145-5034': 4, '0000-0002-5586-4776': 3, '0000-0002-9210-2754': 3, '0000-0003-2544-7215': 3, '0000-0001-6049-2615': 3, '0000-0003-1975-3988': 2, '0000-0003-2352-5734': 2, '0000-0003-3283-028X': 2, '0000-0002-4230-9159': 2, '0000-0002-8997-5941': 2, '0000-0001-5352-1326': 2, '0000-0001-6526-5024': 2, '0000-0002-1797-3920': 1, '0000-0001-5886-5785': 1, '0000-0001-9657-7717': 1, '0000-0001-7023-6578': 1, '0000-0001-5095-8039': 1, '0000-0002-4035-8686': 1, '0000-0002-7263-5289': 1, '0000-0003-1196-7447': 1, '0000-0002-2834-9461': 1, '0000-0002-8345-8847': 1, '0000-0002-9954-3755': 1, '0000-0002-5717-3370': 1})\n",
      "['0000-0001-7343-3884', '0000-0002-5723-177X', '0000-0001-7016-8990', '0000-0002-8582-912X', '0000-0002-5323-6733', '0000-0001-5546-3852', '0000-0002-6109-5707', '0000-0001-7888-9725', '0000-0002-0703-0742', '0000-0003-3622-9707', '0000-0002-6202-0993', '0000-0002-4693-5667', '0000-0001-7364-8412', '0000-0001-9918-1638', '0000-0001-8816-4832', '0000-0001-7433-2081', '0000-0001-8918-5627', '0000-0002-2521-924X', '0000-0001-8063-7906', '0000-0002-6439-8754', '0000-0003-2336-4731', '0000-0003-3410-445X', '0000-0003-1882-3892', '0000-0002-3151-7956']\n",
      "Total sample size after apply threshold:  606\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(606, 1534)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "606\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.44        14\n",
      "          1       1.00      0.32      0.48        25\n",
      "          2       0.66      0.86      0.75        58\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.19      0.32        16\n",
      "          5       0.00      0.00      0.00        19\n",
      "          6       1.00      0.24      0.39        29\n",
      "          7       0.00      0.00      0.00        17\n",
      "          8       0.97      0.76      0.85        46\n",
      "          9       0.25      0.97      0.40        63\n",
      "         10       0.00      0.00      0.00        13\n",
      "         11       0.00      0.00      0.00        11\n",
      "         12       1.00      0.42      0.59        12\n",
      "         13       0.00      0.00      0.00        18\n",
      "         14       0.51      0.82      0.63        51\n",
      "         15       0.67      0.07      0.13        27\n",
      "         16       0.00      0.00      0.00        10\n",
      "         17       0.93      0.97      0.95        29\n",
      "         18       0.83      0.22      0.34        23\n",
      "         19       0.00      0.00      0.00        10\n",
      "         20       0.47      0.80      0.60        56\n",
      "         21       0.00      0.00      0.00        16\n",
      "         22       0.00      0.00      0.00        16\n",
      "         23       1.00      0.56      0.72        16\n",
      "\n",
      "avg / total       0.54      0.50      0.44       606\n",
      "\n",
      "[ 4  0  0  0  0  0  0  0  0  4  0  0  0  0  3  0  0  0  0  0  3  0  0  0\n",
      "  0  8  0  0  0  0  0  0  0 15  0  0  0  0  1  0  0  0  0  0  1  0  0  0\n",
      "  0  0 50  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  2  0  0  0  0  0  0  4  0  0  0  0  4  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  3  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  2  0  0  0  0  0  0 11  0  0  0  0  1  0  0  0  0  0  5  0  0  0\n",
      "  0  0  7  0  0  0  7  0  0  9  0  0  0  0  0  0  0  0  0  0  6  0  0  0\n",
      "  0  0  2  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  6  0  0  0\n",
      "  0  0  0  0  0  0  0  0 35  8  0  0  0  0  2  0  0  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 61  0  0  0  0  0  0  0  0  0  0  2  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  2  0  0  5  0  2  0  0  0  0  0  3  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 10  0  0  0  0  6  0  0  0  0  0  2  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  9  0  0  0  0 42  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 14  0  0  0  0  8  2  0  1  0  0  2  0  0  0\n",
      "  0  0  2  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  4  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 28  0  0  0  0  0  0\n",
      "  0  0  2  0  0  0  0  0  0  3  0  0  0  0  9  1  0  0  5  0  3  0  0  0\n",
      "  0  0  1  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0 45  0  0  0\n",
      "  0  0  1  0  0  0  0  0  0  5  0  0  0  0  1  0  0  0  0  0  9  0  0  0\n",
      "  0  0  7  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  1  2  0  0  0  0  2  0  0  0  0  0  2  0  0  9]\n",
      "MNB Accuracy:  0.5016501650165016\n",
      "MNB F1:  0.3165438616097174\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.93      0.90        14\n",
      "          1       0.91      0.80      0.85        25\n",
      "          2       0.95      0.93      0.94        58\n",
      "          3       0.57      0.36      0.44        11\n",
      "          4       0.71      0.62      0.67        16\n",
      "          5       0.76      0.68      0.72        19\n",
      "          6       0.62      0.90      0.73        29\n",
      "          7       0.59      0.59      0.59        17\n",
      "          8       0.86      0.80      0.83        46\n",
      "          9       0.80      0.90      0.85        63\n",
      "         10       0.00      0.00      0.00        13\n",
      "         11       1.00      0.91      0.95        11\n",
      "         12       1.00      0.83      0.91        12\n",
      "         13       0.67      0.56      0.61        18\n",
      "         14       0.52      0.94      0.67        51\n",
      "         15       0.81      0.48      0.60        27\n",
      "         16       1.00      0.40      0.57        10\n",
      "         17       1.00      0.97      0.98        29\n",
      "         18       0.59      0.57      0.58        23\n",
      "         19       1.00      0.20      0.33        10\n",
      "         20       0.84      0.88      0.86        56\n",
      "         21       0.62      0.50      0.55        16\n",
      "         22       0.50      0.38      0.43        16\n",
      "         23       0.79      0.94      0.86        16\n",
      "\n",
      "avg / total       0.77      0.76      0.75       606\n",
      "\n",
      "[13  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "  0 20  0  0  1  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0\n",
      "  0  0 54  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0\n",
      "  0  1  0  4  0  0  0  0  0  0  0  0  0  0  2  0  0  0  3  0  0  1  0  0\n",
      "  0  1  0  0 10  0  1  0  0  0  0  0  0  1  1  0  0  0  0  0  2  0  0  0\n",
      "  0  0  0  0  1 13  0  0  0  0  0  0  0  0  2  1  0  0  1  0  1  0  0  0\n",
      "  0  0  0  0  0  0 26  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0\n",
      "  1  0  0  0  1  0  0 10  2  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  1  0  0  1  0 37  0  0  0  0  0  4  0  0  0  1  0  0  1  0  1\n",
      "  0  0  0  0  0  1  3  0  0 57  0  0  0  1  0  0  0  0  0  0  0  0  1  0\n",
      "  0  0  0  0  0  0  1  0  0  9  0  0  0  0  1  0  0  0  1  0  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 10  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 10  0  2  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  1  0  0  0  0 10  5  0  0  0  0  0  0  1  0  1\n",
      "  0  0  0  0  0  0  0  0  1  0  0  0  0  1 48  0  0  0  1  0  0  0  0  0\n",
      "  0  0  0  0  0  1  0  3  0  0  0  0  0  0  7 13  0  0  1  0  0  2  0  0\n",
      "  0  0  0  0  1  0  2  0  0  0  0  0  0  0  1  0  4  0  0  0  2  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 28  0  0  0  0  0  0\n",
      "  0  0  0  0  0  1  0  0  0  0  0  0  0  0  6  1  0  0 13  0  0  0  0  2\n",
      "  1  0  0  0  0  0  2  1  0  0  0  0  0  0  2  0  0  0  0  2  2  0  0  0\n",
      "  0  0  0  0  0  1  2  0  0  3  0  0  0  0  0  0  0  0  0  0 49  0  1  0\n",
      "  0  0  0  2  0  0  0  1  2  0  0  0  0  1  0  1  0  0  1  0  0  8  0  0\n",
      "  0  0  3  0  0  0  3  1  0  2  0  0  0  0  0  0  0  0  0  0  1  0  6  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 15]\n",
      "svc Accuracy:  0.759075907590759\n",
      "svc F1:  0.6845213165068621\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.93      0.90        14\n",
      "          1       0.85      0.68      0.76        25\n",
      "          2       0.80      0.95      0.87        58\n",
      "          3       1.00      0.09      0.17        11\n",
      "          4       0.82      0.56      0.67        16\n",
      "          5       0.83      0.53      0.65        19\n",
      "          6       0.61      0.79      0.69        29\n",
      "          7       0.38      0.18      0.24        17\n",
      "          8       0.56      0.83      0.67        46\n",
      "          9       0.71      0.94      0.81        63\n",
      "         10       0.00      0.00      0.00        13\n",
      "         11       1.00      0.73      0.84        11\n",
      "         12       1.00      0.83      0.91        12\n",
      "         13       0.50      0.22      0.31        18\n",
      "         14       0.43      0.92      0.59        51\n",
      "         15       0.69      0.33      0.45        27\n",
      "         16       1.00      0.10      0.18        10\n",
      "         17       1.00      0.97      0.98        29\n",
      "         18       0.50      0.39      0.44        23\n",
      "         19       0.00      0.00      0.00        10\n",
      "         20       0.85      0.91      0.88        56\n",
      "         21       1.00      0.31      0.48        16\n",
      "         22       0.50      0.06      0.11        16\n",
      "         23       0.74      0.88      0.80        16\n",
      "\n",
      "avg / total       0.69      0.68      0.65       606\n",
      "\n",
      "[13  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0 17  0  0  1  0  0  0  2  0  0  0  0  0  4  0  0  0  0  0  1  0  0  0\n",
      "  0  0 55  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0\n",
      "  0  1  0  1  0  0  0  0  2  0  0  0  0  0  3  0  0  0  3  0  1  0  0  0\n",
      "  0  1  0  0  9  0  1  0  1  2  0  0  0  1  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  1  0  1 10  0  0  0  2  0  0  0  0  3  1  0  0  0  0  0  0  0  1\n",
      "  0  0  3  0  0  0 23  0  1  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0\n",
      "  1  0  1  0  0  0  0  3  5  0  0  0  0  2  3  1  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  0  0  1  0 38  0  0  0  0  0  5  0  0  0  1  0  0  0  0  1\n",
      "  0  0  0  0  0  1  2  0  0 59  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 10  0  0  0  0  1  0  0  0  1  0  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  1  0  0  8  0  0  2  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 10  0  2  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  4  1  0  0  0  4  8  0  0  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0  3  0  0  0  0  0 47  0  0  0  1  0  0  0  0  0\n",
      "  0  0  0  0  0  1  0  2  5  0  0  0  0  0  8  9  0  0  2  0  0  0  0  0\n",
      "  0  0  2  0  0  0  2  0  0  0  0  0  0  0  3  0  1  0  0  0  2  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 28  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  1  1  0  0  0  0  0  9  1  0  0  9  0  0  0  0  2\n",
      "  1  0  1  0  0  0  3  0  1  2  0  0  0  0  2  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  1  0  0  4  0  0  0  0  0  0  0  0  0  0 51  0  0  0\n",
      "  0  1  0  0  0  0  1  0  4  0  0  0  0  0  3  1  0  0  1  0  0  5  0  0\n",
      "  0  0  6  0  0  0  3  1  0  3  0  0  0  0  2  0  0  0  0  0  0  0  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0 14]\n",
      "LR Accuracy:  0.6848184818481848\n",
      "LR F1:  0.5568539903768365\n",
      "For name:  d_sanders\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0001-5593-1564': 8, '0000-0003-2383-8693': 6, '0000-0002-6523-783X': 1, '0000-0001-6265-6249': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_brito\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0001-9128-2557': 28, '0000-0001-5214-9681': 11, '0000-0002-8488-6472': 8, '0000-0002-7807-3053': 2, '0000-0003-3633-6422': 2})\n",
      "['0000-0001-5214-9681', '0000-0001-9128-2557']\n",
      "Total sample size after apply threshold:  39\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 163)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.90      1.00      0.95        28\n",
      "\n",
      "avg / total       0.93      0.92      0.92        39\n",
      "\n",
      "[ 8  3  0 28]\n",
      "MNB Accuracy:  0.9230769230769231\n",
      "MNB F1:  0.8956289027653881\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.90      1.00      0.95        28\n",
      "\n",
      "avg / total       0.93      0.92      0.92        39\n",
      "\n",
      "[ 8  3  0 28]\n",
      "svc Accuracy:  0.9230769230769231\n",
      "svc F1:  0.8956289027653881\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        11\n",
      "          1       0.80      1.00      0.89        28\n",
      "\n",
      "avg / total       0.86      0.82      0.79        39\n",
      "\n",
      "[ 4  7  0 28]\n",
      "LR Accuracy:  0.8205128205128205\n",
      "LR F1:  0.7111111111111111\n",
      "For name:  w_chang\n",
      "total sample size before apply threshold:  91\n",
      "Counter({'0000-0003-0116-1386': 50, '0000-0003-2283-1377': 23, '0000-0003-4880-6006': 14, '0000-0002-6155-8644': 2, '0000-0002-5268-290X': 1, '0000-0002-7437-4211': 1})\n",
      "['0000-0003-2283-1377', '0000-0003-4880-6006', '0000-0003-0116-1386']\n",
      "Total sample size after apply threshold:  87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(87, 148)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "87\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.91      0.86        23\n",
      "          1       0.50      0.07      0.12        14\n",
      "          2       0.85      1.00      0.92        50\n",
      "\n",
      "avg / total       0.78      0.83      0.77        87\n",
      "\n",
      "[21  1  1  5  1  8  0  0 50]\n",
      "MNB Accuracy:  0.8275862068965517\n",
      "MNB F1:  0.6331913499344691\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.87      0.87        23\n",
      "          1       0.92      0.79      0.85        14\n",
      "          2       0.96      1.00      0.98        50\n",
      "\n",
      "avg / total       0.93      0.93      0.93        87\n",
      "\n",
      "[20  1  2  3 11  0  0  0 50]\n",
      "svc Accuracy:  0.9310344827586207\n",
      "svc F1:  0.8987037401359652\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.78      0.82        23\n",
      "          1       0.75      0.21      0.33        14\n",
      "          2       0.81      1.00      0.89        50\n",
      "\n",
      "avg / total       0.81      0.82      0.78        87\n",
      "\n",
      "[18  1  4  3  3  8  0  0 50]\n",
      "LR Accuracy:  0.8160919540229885\n",
      "LR F1:  0.6814574314574315\n",
      "For name:  a_murray\n",
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0002-4094-962X': 32, '0000-0002-0929-9315': 14, '0000-0001-7143-287X': 9, '0000-0001-6762-588X': 7, '0000-0001-5014-1096': 7, '0000-0001-7047-8139': 4, '0000-0001-9648-2902': 3})\n",
      "['0000-0002-4094-962X', '0000-0002-0929-9315']\n",
      "Total sample size after apply threshold:  46\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 146)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        32\n",
      "          1       1.00      0.07      0.13        14\n",
      "\n",
      "avg / total       0.80      0.72      0.62        46\n",
      "\n",
      "[32  0 13  1]\n",
      "MNB Accuracy:  0.717391304347826\n",
      "MNB F1:  0.4822510822510822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.84        32\n",
      "          1       1.00      0.14      0.25        14\n",
      "\n",
      "avg / total       0.81      0.74      0.66        46\n",
      "\n",
      "[32  0 12  2]\n",
      "svc Accuracy:  0.7391304347826086\n",
      "svc F1:  0.5460526315789473\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82        32\n",
      "          1       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.48      0.70      0.57        46\n",
      "\n",
      "[32  0 14  0]\n",
      "LR Accuracy:  0.6956521739130435\n",
      "LR F1:  0.41025641025641024\n",
      "For name:  b_cao\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-9462-496X': 39, '0000-0003-3588-972X': 14, '0000-0003-3401-6900': 4, '0000-0003-4443-2326': 1})\n",
      "['0000-0002-9462-496X', '0000-0003-3588-972X']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 100)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        39\n",
      "          1       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.89      0.87      0.85        53\n",
      "\n",
      "[39  0  7  7]\n",
      "MNB Accuracy:  0.8679245283018868\n",
      "MNB F1:  0.792156862745098\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        39\n",
      "          1       1.00      0.64      0.78        14\n",
      "\n",
      "avg / total       0.92      0.91      0.90        53\n",
      "\n",
      "[39  0  5  9]\n",
      "svc Accuracy:  0.9056603773584906\n",
      "svc F1:  0.8611838658983761\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        39\n",
      "          1       1.00      0.29      0.44        14\n",
      "\n",
      "avg / total       0.85      0.81      0.77        53\n",
      "\n",
      "[39  0 10  4]\n",
      "LR Accuracy:  0.8113207547169812\n",
      "LR F1:  0.6654040404040404\n",
      "For name:  k_sohn\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-3237-044X': 17, '0000-0001-8941-1188': 12, '0000-0001-9791-2126': 1, '0000-0002-7270-7094': 1})\n",
      "['0000-0002-3237-044X', '0000-0001-8941-1188']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 130)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        17\n",
      "          1       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.87      0.83      0.82        29\n",
      "\n",
      "[17  0  5  7]\n",
      "MNB Accuracy:  0.8275862068965517\n",
      "MNB F1:  0.8043184885290149\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        17\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[17  0  1 11]\n",
      "svc Accuracy:  0.9655172413793104\n",
      "svc F1:  0.9639751552795031\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        17\n",
      "          1       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.87      0.83      0.82        29\n",
      "\n",
      "[17  0  5  7]\n",
      "LR Accuracy:  0.8275862068965517\n",
      "LR F1:  0.8043184885290149\n",
      "For name:  m_bennett\n",
      "total sample size before apply threshold:  208\n",
      "Counter({'0000-0002-2565-1825': 110, '0000-0002-8369-8349': 90, '0000-0002-3063-8844': 7, '0000-0001-9914-3850': 1})\n",
      "['0000-0002-2565-1825', '0000-0002-8369-8349']\n",
      "Total sample size after apply threshold:  200\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(200, 476)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91       110\n",
      "          1       0.99      0.77      0.86        90\n",
      "\n",
      "avg / total       0.90      0.89      0.89       200\n",
      "\n",
      "[109   1  21  69]\n",
      "MNB Accuracy:  0.89\n",
      "MNB F1:  0.8854166666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95       110\n",
      "          1       0.90      0.99      0.94        90\n",
      "\n",
      "avg / total       0.95      0.94      0.95       200\n",
      "\n",
      "[100  10   1  89]\n",
      "svc Accuracy:  0.945\n",
      "svc F1:  0.9448331201885705\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.93      0.90       110\n",
      "          1       0.90      0.83      0.87        90\n",
      "\n",
      "avg / total       0.89      0.89      0.88       200\n",
      "\n",
      "[102   8  15  75]\n",
      "LR Accuracy:  0.885\n",
      "LR F1:  0.8828652186091518\n",
      "For name:  a_sharma\n",
      "total sample size before apply threshold:  223\n",
      "Counter({'0000-0002-2653-0806': 85, '0000-0003-3349-4417': 23, '0000-0002-7668-3501': 14, '0000-0002-0172-5033': 12, '0000-0003-2264-2007': 10, '0000-0003-0553-4039': 9, '0000-0001-6906-190X': 9, '0000-0002-7029-9867': 8, '0000-0002-7442-8494': 8, '0000-0003-3281-2081': 6, '0000-0001-6539-9970': 6, '0000-0001-5061-9731': 5, '0000-0002-6201-7639': 5, '0000-0002-4117-8775': 4, '0000-0002-8458-9216': 3, '0000-0002-5251-9045': 3, '0000-0001-7570-852X': 2, '0000-0002-1655-5997': 2, '0000-0002-4374-4259': 2, '0000-0003-4841-0108': 2, '0000-0002-6862-136X': 2, '0000-0002-4342-6656': 1, '0000-0003-4433-4355': 1, '0000-0002-7170-1627': 1})\n",
      "['0000-0003-3349-4417', '0000-0002-0172-5033', '0000-0002-7668-3501', '0000-0002-2653-0806', '0000-0003-2264-2007']\n",
      "Total sample size after apply threshold:  144\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(144, 223)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "144\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        23\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       1.00      0.93      0.96        14\n",
      "          3       0.75      1.00      0.85        85\n",
      "          4       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.77      0.80      0.74       144\n",
      "\n",
      "[16  0  0  7  0  0  0  0 12  0  0  0 13  1  0  0  0  0 85  0  0  0  0  9\n",
      "  1]\n",
      "MNB Accuracy:  0.7986111111111112\n",
      "MNB F1:  0.563913064415577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.90        23\n",
      "          1       1.00      0.42      0.59        12\n",
      "          2       1.00      0.93      0.96        14\n",
      "          3       0.86      1.00      0.92        85\n",
      "          4       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.92      0.90      0.89       144\n",
      "\n",
      "[19  0  0  4  0  0  5  0  7  0  0  0 13  1  0  0  0  0 85  0  0  0  0  2\n",
      "  8]\n",
      "svc Accuracy:  0.9027777777777778\n",
      "svc F1:  0.853752418841933\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.52      0.69        23\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       1.00      0.86      0.92        14\n",
      "          3       0.71      1.00      0.83        85\n",
      "          4       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.75      0.76      0.70       144\n",
      "\n",
      "[12  0  0 11  0  0  0  0 12  0  0  0 12  2  0  0  0  0 85  0  0  0  0  9\n",
      "  1]\n",
      "LR Accuracy:  0.7638888888888888\n",
      "LR F1:  0.5247885447885448\n",
      "For name:  z_wei\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0001-8747-2251': 11, '0000-0002-4446-6502': 11, '0000-0003-2687-0293': 8, '0000-0001-6948-7572': 7, '0000-0001-8558-4639': 5, '0000-0002-2311-9800': 4, '0000-0001-7436-6409': 4, '0000-0002-8694-1260': 2, '0000-0002-9670-4752': 2})\n",
      "['0000-0001-8747-2251', '0000-0002-4446-6502']\n",
      "Total sample size after apply threshold:  22\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 79)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "22\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91        11\n",
      "          1       0.91      0.91      0.91        11\n",
      "\n",
      "avg / total       0.91      0.91      0.91        22\n",
      "\n",
      "[10  1  1 10]\n",
      "MNB Accuracy:  0.9090909090909091\n",
      "MNB F1:  0.9090909090909091\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "[10  1  0 11]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.9544513457556936\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.91      0.87        11\n",
      "          1       0.90      0.82      0.86        11\n",
      "\n",
      "avg / total       0.87      0.86      0.86        22\n",
      "\n",
      "[10  1  2  9]\n",
      "LR Accuracy:  0.8636363636363636\n",
      "LR F1:  0.8633540372670807\n",
      "For name:  x_gu\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-9373-987X': 23, '0000-0002-8521-3667': 13, '0000-0003-2266-5516': 7, '0000-0002-0437-5606': 5, '0000-0003-2641-1740': 5, '0000-0001-8299-6451': 4, '0000-0003-3803-3951': 4})\n",
      "['0000-0002-8521-3667', '0000-0002-9373-987X']\n",
      "Total sample size after apply threshold:  36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 83)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.96      1.00      0.98        23\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[12  1  0 23]\n",
      "MNB Accuracy:  0.9722222222222222\n",
      "MNB F1:  0.9693617021276596\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.96      1.00      0.98        23\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[12  1  0 23]\n",
      "svc Accuracy:  0.9722222222222222\n",
      "svc F1:  0.9693617021276596\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.82      1.00      0.90        23\n",
      "\n",
      "avg / total       0.89      0.86      0.85        36\n",
      "\n",
      "[ 8  5  0 23]\n",
      "LR Accuracy:  0.8611111111111112\n",
      "LR F1:  0.8319327731092437\n",
      "For name:  l_yang\n",
      "total sample size before apply threshold:  193\n",
      "Counter({'0000-0002-3756-8789': 48, '0000-0002-4351-2503': 30, '0000-0002-8654-4927': 23, '0000-0002-5964-3233': 23, '0000-0002-1698-6666': 11, '0000-0002-3681-2874': 9, '0000-0002-0192-4323': 8, '0000-0002-5392-558X': 8, '0000-0002-3294-0879': 6, '0000-0002-5421-9249': 5, '0000-0003-3894-873X': 5, '0000-0003-1057-9194': 5, '0000-0001-6573-6359': 2, '0000-0002-9937-1383': 2, '0000-0001-7965-2674': 2, '0000-0001-6497-1680': 2, '0000-0003-4294-9233': 1, '0000-0001-5709-6566': 1, '0000-0002-0639-0973': 1, '0000-0001-5396-7280': 1})\n",
      "['0000-0002-8654-4927', '0000-0002-4351-2503', '0000-0002-5964-3233', '0000-0002-1698-6666', '0000-0002-3756-8789']\n",
      "Total sample size after apply threshold:  135\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(135, 263)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.72        23\n",
      "          1       1.00      0.80      0.89        30\n",
      "          2       1.00      0.91      0.95        23\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       0.62      1.00      0.77        48\n",
      "\n",
      "avg / total       0.78      0.79      0.76       135\n",
      "\n",
      "[13  0  0  0 10  0 24  0  0  6  0  0 21  0  2  0  0  0  0 11  0  0  0  0\n",
      " 48]\n",
      "MNB Accuracy:  0.7851851851851852\n",
      "MNB F1:  0.6667313131313131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        23\n",
      "          1       1.00      0.77      0.87        30\n",
      "          2       1.00      0.83      0.90        23\n",
      "          3       1.00      0.82      0.90        11\n",
      "          4       0.71      1.00      0.83        48\n",
      "\n",
      "avg / total       0.90      0.85      0.85       135\n",
      "\n",
      "[16  0  0  0  7  0 23  0  0  7  0  0 19  0  4  0  0  0  9  2  0  0  0  0\n",
      " 48]\n",
      "svc Accuracy:  0.8518518518518519\n",
      "svc F1:  0.8641570920946327\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.52      0.69        23\n",
      "          1       1.00      0.77      0.87        30\n",
      "          2       1.00      0.83      0.90        23\n",
      "          3       1.00      0.09      0.17        11\n",
      "          4       0.60      1.00      0.75        48\n",
      "\n",
      "avg / total       0.86      0.76      0.74       135\n",
      "\n",
      "[12  0  0  0 11  0 23  0  0  7  0  0 19  0  4  0  0  0  1 10  0  0  0  0\n",
      " 48]\n",
      "LR Accuracy:  0.762962962962963\n",
      "LR F1:  0.6750134770889488\n",
      "For name:  h_hassan\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0002-6035-0040': 9, '0000-0002-2815-7996': 5, '0000-0002-9567-0896': 3, '0000-0001-5167-8063': 2, '0000-0002-6166-1342': 1, '0000-0001-7274-9414': 1, '0000-0003-0359-1208': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  f_chen\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0002-2191-0930': 8, '0000-0002-9646-3338': 8, '0000-0002-8004-1720': 6, '0000-0002-7251-1956': 6, '0000-0003-0013-479X': 5, '0000-0002-6366-5064': 2, '0000-0002-9193-5412': 1, '0000-0001-9942-8872': 1, '0000-0002-4346-6906': 1, '0000-0002-1963-6784': 1, '0000-0003-2077-3812': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  g_rossi\n",
      "total sample size before apply threshold:  245\n",
      "Counter({'0000-0001-8377-2898': 86, '0000-0002-5588-1306': 85, '0000-0001-6916-2049': 24, '0000-0003-3519-2420': 19, '0000-0001-9688-9454': 14, '0000-0002-5102-5019': 10, '0000-0003-0984-3197': 3, '0000-0002-9926-115X': 2, '0000-0002-9761-6754': 1, '0000-0002-5572-1759': 1})\n",
      "['0000-0003-3519-2420', '0000-0002-5102-5019', '0000-0002-5588-1306', '0000-0001-9688-9454', '0000-0001-8377-2898', '0000-0001-6916-2049']\n",
      "Total sample size after apply threshold:  238\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(238, 1083)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        19\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.82      1.00      0.90        85\n",
      "          3       1.00      0.29      0.44        14\n",
      "          4       0.82      0.97      0.89        86\n",
      "          5       1.00      0.67      0.80        24\n",
      "\n",
      "avg / total       0.83      0.84      0.81       238\n",
      "\n",
      "[13  0  4  0  2  0  0  0  3  0  7  0  0  0 85  0  0  0  0  0  6  4  4  0\n",
      "  0  0  3  0 83  0  0  0  3  0  5 16]\n",
      "MNB Accuracy:  0.8445378151260504\n",
      "MNB F1:  0.640685979779117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        19\n",
      "          1       1.00      0.40      0.57        10\n",
      "          2       0.99      0.89      0.94        85\n",
      "          3       1.00      0.71      0.83        14\n",
      "          4       0.77      1.00      0.87        86\n",
      "          5       1.00      0.88      0.93        24\n",
      "\n",
      "avg / total       0.91      0.89      0.88       238\n",
      "\n",
      "[14  0  0  0  5  0  0  4  0  0  6  0  0  0 76  0  9  0  0  0  1 10  3  0\n",
      "  0  0  0  0 86  0  0  0  0  0  3 21]\n",
      "svc Accuracy:  0.8865546218487395\n",
      "svc F1:  0.8322564267008711\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        19\n",
      "          1       1.00      0.20      0.33        10\n",
      "          2       1.00      0.89      0.94        85\n",
      "          3       1.00      0.36      0.53        14\n",
      "          4       0.68      1.00      0.81        86\n",
      "          5       1.00      0.67      0.80        24\n",
      "\n",
      "avg / total       0.89      0.83      0.82       238\n",
      "\n",
      "[13  0  0  0  6  0  0  2  0  0  8  0  0  0 76  0  9  0  0  0  0  5  9  0\n",
      "  0  0  0  0 86  0  0  0  0  0  8 16]\n",
      "LR Accuracy:  0.8319327731092437\n",
      "LR F1:  0.7045948760676644\n",
      "For name:  s_patil\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0001-8454-589X': 17, '0000-0001-6167-2511': 16, '0000-0001-8562-8670': 7, '0000-0003-4952-3120': 5, '0000-0002-0950-549X': 5, '0000-0003-3898-3594': 5, '0000-0002-9278-5786': 4, '0000-0002-1597-855X': 3, '0000-0002-9812-1972': 2, '0000-0001-8502-0884': 1})\n",
      "['0000-0001-8454-589X', '0000-0001-6167-2511']\n",
      "Total sample size after apply threshold:  33\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 45)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        17\n",
      "          1       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00        33\n",
      "\n",
      "[17  0  0 16]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        17\n",
      "          1       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        33\n",
      "\n",
      "[17  0  1 15]\n",
      "svc Accuracy:  0.9696969696969697\n",
      "svc F1:  0.9695852534562213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        17\n",
      "          1       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        33\n",
      "\n",
      "[17  0  1 15]\n",
      "LR Accuracy:  0.9696969696969697\n",
      "LR F1:  0.9695852534562213\n",
      "For name:  m_kelly\n",
      "total sample size before apply threshold:  97\n",
      "Counter({'0000-0002-6380-1150': 19, '0000-0002-1735-3342': 17, '0000-0001-7963-2139': 16, '0000-0001-6221-7406': 12, '0000-0003-3114-8780': 11, '0000-0003-1799-055X': 10, '0000-0003-3210-0295': 4, '0000-0002-6541-2992': 3, '0000-0002-2029-5841': 2, '0000-0003-2882-4450': 1, '0000-0003-0900-0691': 1, '0000-0002-0995-2425': 1})\n",
      "['0000-0001-7963-2139', '0000-0003-3114-8780', '0000-0003-1799-055X', '0000-0001-6221-7406', '0000-0002-1735-3342', '0000-0002-6380-1150']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 320)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       1.00      0.40      0.57        10\n",
      "          3       1.00      0.25      0.40        12\n",
      "          4       0.78      0.82      0.80        17\n",
      "          5       0.45      0.79      0.58        19\n",
      "\n",
      "avg / total       0.83      0.74      0.73        85\n",
      "\n",
      "[16  0  0  0  0  0  0 11  0  0  0  0  0  0  4  0  0  6  0  0  0  3  0  9\n",
      "  0  0  0  0 14  3  0  0  0  0  4 15]\n",
      "MNB Accuracy:  0.7411764705882353\n",
      "MNB F1:  0.7247252747252747\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       1.00      0.70      0.82        10\n",
      "          3       1.00      0.83      0.91        12\n",
      "          4       1.00      0.65      0.79        17\n",
      "          5       0.63      1.00      0.78        19\n",
      "\n",
      "avg / total       0.92      0.87      0.87        85\n",
      "\n",
      "[16  0  0  0  0  0  0 11  0  0  0  0  0  0  7  0  0  3  0  0  0 10  0  2\n",
      "  0  0  0  0 11  6  0  0  0  0  0 19]\n",
      "svc Accuracy:  0.8705882352941177\n",
      "svc F1:  0.8823074684419222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       1.00      0.40      0.57        10\n",
      "          3       1.00      0.25      0.40        12\n",
      "          4       0.80      0.71      0.75        17\n",
      "          5       0.44      0.84      0.58        19\n",
      "\n",
      "avg / total       0.84      0.73      0.72        85\n",
      "\n",
      "[16  0  0  0  0  0  0 11  0  0  0  0  0  0  4  0  0  6  0  0  0  3  0  9\n",
      "  0  0  0  0 12  5  0  0  0  0  3 16]\n",
      "LR Accuracy:  0.7294117647058823\n",
      "LR F1:  0.7172077922077923\n",
      "For name:  m_cheung\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0001-7144-618X': 8, '0000-0002-2764-2113': 2, '0000-0002-8076-0725': 2, '0000-0002-0021-3802': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_weaver\n",
      "total sample size before apply threshold:  7\n",
      "Counter({'0000-0001-7394-2443': 4, '0000-0001-6733-7554': 1, '0000-0003-3361-2946': 1, '0000-0002-5556-4757': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_chien\n",
      "total sample size before apply threshold:  157\n",
      "Counter({'0000-0002-6690-6038': 71, '0000-0001-9806-486X': 60, '0000-0001-8704-0336': 25, '0000-0002-5532-1018': 1})\n",
      "['0000-0001-9806-486X', '0000-0001-8704-0336', '0000-0002-6690-6038']\n",
      "Total sample size after apply threshold:  156\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(156, 164)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "156\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.83      0.85        60\n",
      "          1       1.00      0.80      0.89        25\n",
      "          2       0.87      0.97      0.92        71\n",
      "\n",
      "avg / total       0.90      0.89      0.89       156\n",
      "\n",
      "[50  0 10  5 20  0  2  0 69]\n",
      "MNB Accuracy:  0.8910256410256411\n",
      "MNB F1:  0.8878632478632479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89        60\n",
      "          1       1.00      0.92      0.96        25\n",
      "          2       0.95      0.87      0.91        71\n",
      "\n",
      "avg / total       0.92      0.91      0.91       156\n",
      "\n",
      "[57  0  3  2 23  0  9  0 62]\n",
      "svc Accuracy:  0.9102564102564102\n",
      "svc F1:  0.9202410130718954\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.90      0.85        60\n",
      "          1       1.00      0.72      0.84        25\n",
      "          2       0.92      0.92      0.92        71\n",
      "\n",
      "avg / total       0.89      0.88      0.88       156\n",
      "\n",
      "[54  0  6  7 18  0  6  0 65]\n",
      "LR Accuracy:  0.8782051282051282\n",
      "LR F1:  0.8676986536198207\n",
      "For name:  s_yun\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0001-7737-4746': 76, '0000-0002-1498-3701': 24, '0000-0002-3774-0622': 1, '0000-0002-9510-5133': 1})\n",
      "['0000-0001-7737-4746', '0000-0002-1498-3701']\n",
      "Total sample size after apply threshold:  100\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 71)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "100\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92        76\n",
      "          1       1.00      0.42      0.59        24\n",
      "\n",
      "avg / total       0.88      0.86      0.84       100\n",
      "\n",
      "[76  0 14 10]\n",
      "MNB Accuracy:  0.86\n",
      "MNB F1:  0.7519489723600283\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.93      0.92        76\n",
      "          1       0.76      0.67      0.71        24\n",
      "\n",
      "avg / total       0.87      0.87      0.87       100\n",
      "\n",
      "[71  5  8 16]\n",
      "svc Accuracy:  0.87\n",
      "svc F1:  0.8136200716845878\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        76\n",
      "          1       1.00      0.50      0.67        24\n",
      "\n",
      "avg / total       0.90      0.88      0.86       100\n",
      "\n",
      "[76  0 12 12]\n",
      "LR Accuracy:  0.88\n",
      "LR F1:  0.7967479674796747\n",
      "For name:  s_jung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0002-3174-8965': 57, '0000-0002-3566-5649': 9, '0000-0003-3670-1952': 4, '0000-0003-4864-8175': 1, '0000-0002-8196-1748': 1, '0000-0001-7266-1084': 1, '0000-0002-3884-4335': 1, '0000-0002-5194-7339': 1, '0000-0001-6389-2315': 1})\n",
      "['0000-0002-3174-8965']\n",
      "Total sample size after apply threshold:  57\n",
      "For name:  e_gomes\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0002-6941-4872': 20, '0000-0001-6378-6942': 8, '0000-0002-4238-3738': 8, '0000-0001-8528-8741': 2, '0000-0002-0636-6041': 2})\n",
      "['0000-0002-6941-4872']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  t_yamaguchi\n",
      "total sample size before apply threshold:  62\n",
      "Counter({'0000-0003-4590-8592': 30, '0000-0001-9043-4408': 15, '0000-0003-0214-4983': 7, '0000-0002-7533-430X': 6, '0000-0002-5063-9924': 2, '0000-0001-8454-1995': 1, '0000-0001-5341-4184': 1})\n",
      "['0000-0001-9043-4408', '0000-0003-4590-8592']\n",
      "Total sample size after apply threshold:  45\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 51)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        15\n",
      "          1       0.94      1.00      0.97        30\n",
      "\n",
      "avg / total       0.96      0.96      0.95        45\n",
      "\n",
      "[13  2  0 30]\n",
      "MNB Accuracy:  0.9555555555555556\n",
      "MNB F1:  0.9481566820276498\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        15\n",
      "          1       0.94      1.00      0.97        30\n",
      "\n",
      "avg / total       0.96      0.96      0.95        45\n",
      "\n",
      "[13  2  0 30]\n",
      "svc Accuracy:  0.9555555555555556\n",
      "svc F1:  0.9481566820276498\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.85        15\n",
      "          1       0.88      1.00      0.94        30\n",
      "\n",
      "avg / total       0.92      0.91      0.91        45\n",
      "\n",
      "[11  4  0 30]\n",
      "LR Accuracy:  0.9111111111111111\n",
      "LR F1:  0.891826923076923\n",
      "For name:  p_oliveira\n",
      "total sample size before apply threshold:  358\n",
      "Counter({'0000-0002-4989-5699': 71, '0000-0002-5201-9948': 71, '0000-0003-0307-354X': 55, '0000-0001-9519-4044': 50, '0000-0002-2470-0795': 40, '0000-0002-0938-152X': 20, '0000-0003-3161-8367': 16, '0000-0001-8478-7135': 8, '0000-0002-4989-2113': 7, '0000-0002-3078-2950': 7, '0000-0002-1850-6670': 5, '0000-0001-7217-5705': 2, '0000-0002-4460-9489': 2, '0000-0002-3898-2623': 1, '0000-0002-5799-390X': 1, '0000-0003-3123-4259': 1, '0000-0001-9843-7558': 1})\n",
      "['0000-0003-3161-8367', '0000-0001-9519-4044', '0000-0002-4989-5699', '0000-0002-0938-152X', '0000-0002-5201-9948', '0000-0003-0307-354X', '0000-0002-2470-0795']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size after apply threshold:  323\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(323, 693)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "323\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        16\n",
      "          1       0.78      0.98      0.87        50\n",
      "          2       0.72      0.97      0.83        71\n",
      "          3       1.00      0.65      0.79        20\n",
      "          4       0.78      0.92      0.84        71\n",
      "          5       0.94      0.82      0.87        55\n",
      "          6       1.00      0.40      0.57        40\n",
      "\n",
      "avg / total       0.85      0.81      0.79       323\n",
      "\n",
      "[ 4  2  5  0  5  0  0  0 49  1  0  0  0  0  0  2 69  0  0  0  0  0  2  0\n",
      " 13  4  1  0  0  2  4  0 65  0  0  0  1  4  0  5 45  0  0  5 13  0  4  2\n",
      " 16]\n",
      "MNB Accuracy:  0.8080495356037152\n",
      "MNB F1:  0.7386933648267939\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.81        16\n",
      "          1       0.92      0.92      0.92        50\n",
      "          2       0.97      0.97      0.97        71\n",
      "          3       0.94      0.85      0.89        20\n",
      "          4       0.84      0.96      0.89        71\n",
      "          5       0.88      0.89      0.88        55\n",
      "          6       0.86      0.78      0.82        40\n",
      "\n",
      "avg / total       0.90      0.90      0.90       323\n",
      "\n",
      "[11  0  0  0  2  2  1  0 46  0  0  1  0  3  0  2 69  0  0  0  0  0  0  0\n",
      " 17  2  1  0  0  0  1  1 68  1  0  0  0  0  0  5 49  1  0  2  1  0  3  3\n",
      " 31]\n",
      "svc Accuracy:  0.9009287925696594\n",
      "svc F1:  0.8849702630725611\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.44      0.61        16\n",
      "          1       0.89      0.96      0.92        50\n",
      "          2       0.97      0.97      0.97        71\n",
      "          3       1.00      0.70      0.82        20\n",
      "          4       0.72      0.96      0.82        71\n",
      "          5       0.86      0.87      0.86        55\n",
      "          6       0.93      0.62      0.75        40\n",
      "\n",
      "avg / total       0.88      0.86      0.86       323\n",
      "\n",
      "[ 7  0  0  0  5  3  1  0 48  0  0  1  0  1  0  2 69  0  0  0  0  0  1  0\n",
      " 14  4  1  0  0  0  1  0 68  2  0  0  0  0  0  7 48  0  0  3  1  0  9  2\n",
      " 25]\n",
      "LR Accuracy:  0.8637770897832817\n",
      "LR F1:  0.823215559822106\n",
      "For name:  r_torres\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0002-9109-4035': 17, '0000-0001-8030-5522': 7, '0000-0002-4041-270X': 7, '0000-0002-3777-8671': 4, '0000-0002-8205-8518': 2, '0000-0001-7090-7925': 2, '0000-0001-9606-0398': 1})\n",
      "['0000-0002-9109-4035']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  a_esteves\n",
      "total sample size before apply threshold:  63\n",
      "Counter({'0000-0002-7983-5742': 22, '0000-0001-8403-2015': 19, '0000-0003-2239-2976': 11, '0000-0002-7837-5983': 4, '0000-0002-9614-0635': 4, '0000-0001-6769-1844': 3})\n",
      "['0000-0003-2239-2976', '0000-0001-8403-2015', '0000-0002-7983-5742']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 105)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.95      1.00      0.97        19\n",
      "          2       0.96      1.00      0.98        22\n",
      "\n",
      "avg / total       0.96      0.96      0.96        52\n",
      "\n",
      "[ 9  1  1  0 19  0  0  0 22]\n",
      "MNB Accuracy:  0.9615384615384616\n",
      "MNB F1:  0.9507122507122507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       1.00      1.00      1.00        19\n",
      "          2       0.96      1.00      0.98        22\n",
      "\n",
      "avg / total       0.98      0.98      0.98        52\n",
      "\n",
      "[10  0  1  0 19  0  0  0 22]\n",
      "svc Accuracy:  0.9807692307692307\n",
      "svc F1:  0.9767195767195767\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       1.00      1.00      1.00        19\n",
      "          2       0.92      1.00      0.96        22\n",
      "\n",
      "avg / total       0.96      0.96      0.96        52\n",
      "\n",
      "[ 9  0  2  0 19  0  0  0 22]\n",
      "LR Accuracy:  0.9615384615384616\n",
      "LR F1:  0.9521739130434783\n",
      "For name:  l_stevens\n",
      "total sample size before apply threshold:  77\n",
      "Counter({'0000-0003-3372-3419': 49, '0000-0003-3847-5979': 26, '0000-0002-6075-8273': 1, '0000-0002-1345-6520': 1})\n",
      "['0000-0003-3372-3419', '0000-0003-3847-5979']\n",
      "Total sample size after apply threshold:  75\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(75, 168)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.91        49\n",
      "          1       0.95      0.69      0.80        26\n",
      "\n",
      "avg / total       0.89      0.88      0.87        75\n",
      "\n",
      "[48  1  8 18]\n",
      "MNB Accuracy:  0.88\n",
      "MNB F1:  0.8571428571428571\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        49\n",
      "          1       1.00      0.69      0.82        26\n",
      "\n",
      "avg / total       0.91      0.89      0.89        75\n",
      "\n",
      "[49  0  8 18]\n",
      "svc Accuracy:  0.8933333333333333\n",
      "svc F1:  0.8713550600343053\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        49\n",
      "          1       1.00      0.58      0.73        26\n",
      "\n",
      "avg / total       0.88      0.85      0.84        75\n",
      "\n",
      "[49  0 11 15]\n",
      "LR Accuracy:  0.8533333333333334\n",
      "LR F1:  0.815394942940255\n",
      "For name:  a_chang\n",
      "total sample size before apply threshold:  178\n",
      "Counter({'0000-0001-9506-0425': 74, '0000-0002-6877-5510': 72, '0000-0001-7309-9687': 19, '0000-0002-8416-359X': 5, '0000-0001-7096-7151': 4, '0000-0002-5694-0136': 4})\n",
      "['0000-0001-7309-9687', '0000-0001-9506-0425', '0000-0002-6877-5510']\n",
      "Total sample size after apply threshold:  165\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(165, 662)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "165\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.63      0.77        19\n",
      "          1       0.82      0.89      0.86        74\n",
      "          2       0.89      0.90      0.90        72\n",
      "\n",
      "avg / total       0.87      0.87      0.86       165\n",
      "\n",
      "[12  7  0  0 66  8  0  7 65]\n",
      "MNB Accuracy:  0.8666666666666667\n",
      "MNB F1:  0.8426293765559616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91        19\n",
      "          1       0.87      0.82      0.85        74\n",
      "          2       0.84      0.92      0.87        72\n",
      "\n",
      "avg / total       0.87      0.87      0.87       165\n",
      "\n",
      "[16  3  0  0 61 13  0  6 66]\n",
      "svc Accuracy:  0.8666666666666667\n",
      "svc F1:  0.8785600406461334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.63      0.77        19\n",
      "          1       0.85      0.82      0.84        74\n",
      "          2       0.80      0.90      0.85        72\n",
      "\n",
      "avg / total       0.85      0.84      0.83       165\n",
      "\n",
      "[12  4  3  0 61 13  0  7 65]\n",
      "LR Accuracy:  0.8363636363636363\n",
      "LR F1:  0.8198277297858801\n",
      "For name:  l_song\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0003-0585-8519': 38, '0000-0003-1691-9583': 15, '0000-0002-0400-8283': 3, '0000-0003-2454-1576': 1, '0000-0002-7299-5719': 1})\n",
      "['0000-0003-1691-9583', '0000-0003-0585-8519']\n",
      "Total sample size after apply threshold:  53\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(53, 134)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       0.93      1.00      0.96        38\n",
      "\n",
      "avg / total       0.95      0.94      0.94        53\n",
      "\n",
      "[12  3  0 38]\n",
      "MNB Accuracy:  0.9433962264150944\n",
      "MNB F1:  0.9254571026722926\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       0.93      1.00      0.96        38\n",
      "\n",
      "avg / total       0.95      0.94      0.94        53\n",
      "\n",
      "[12  3  0 38]\n",
      "svc Accuracy:  0.9433962264150944\n",
      "svc F1:  0.9254571026722926\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       0.93      1.00      0.96        38\n",
      "\n",
      "avg / total       0.95      0.94      0.94        53\n",
      "\n",
      "[12  3  0 38]\n",
      "LR Accuracy:  0.9433962264150944\n",
      "LR F1:  0.9254571026722926\n",
      "For name:  j_delgado\n",
      "total sample size before apply threshold:  123\n",
      "Counter({'0000-0002-5157-4376': 85, '0000-0002-6948-8062': 26, '0000-0003-4074-981X': 6, '0000-0002-8075-4704': 3, '0000-0002-0166-5464': 2, '0000-0002-1026-4523': 1})\n",
      "['0000-0002-6948-8062', '0000-0002-5157-4376']\n",
      "Total sample size after apply threshold:  111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 583)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.54      0.68        26\n",
      "          1       0.88      0.99      0.93        85\n",
      "\n",
      "avg / total       0.89      0.88      0.87       111\n",
      "\n",
      "[14 12  1 84]\n",
      "MNB Accuracy:  0.8828828828828829\n",
      "MNB F1:  0.8055518124242016\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89        26\n",
      "          1       0.94      1.00      0.97        85\n",
      "\n",
      "avg / total       0.96      0.95      0.95       111\n",
      "\n",
      "[21  5  0 85]\n",
      "svc Accuracy:  0.954954954954955\n",
      "svc F1:  0.9325227963525835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27        26\n",
      "          1       0.79      1.00      0.89        85\n",
      "\n",
      "avg / total       0.84      0.80      0.74       111\n",
      "\n",
      "[ 4 22  0 85]\n",
      "LR Accuracy:  0.8018018018018018\n",
      "LR F1:  0.5760416666666667\n",
      "For name:  p_jensen\n",
      "total sample size before apply threshold:  319\n",
      "Counter({'0000-0003-2387-0650': 98, '0000-0003-1648-7186': 65, '0000-0001-6524-7723': 55, '0000-0003-4359-848X': 28, '0000-0001-7058-6930': 17, '0000-0003-4718-1630': 16, '0000-0002-9819-1516': 14, '0000-0002-8856-2395': 12, '0000-0001-8792-7711': 11, '0000-0002-5248-0523': 1, '0000-0002-9588-3189': 1, '0000-0002-9297-2098': 1})\n",
      "['0000-0003-4359-848X', '0000-0002-9819-1516', '0000-0003-2387-0650', '0000-0001-8792-7711', '0000-0003-4718-1630', '0000-0001-6524-7723', '0000-0002-8856-2395', '0000-0003-1648-7186', '0000-0001-7058-6930']\n",
      "Total sample size after apply threshold:  316\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(316, 944)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        28\n",
      "          1       1.00      0.36      0.53        14\n",
      "          2       0.69      1.00      0.82        98\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.25      0.40        16\n",
      "          5       0.98      0.87      0.92        55\n",
      "          6       1.00      0.33      0.50        12\n",
      "          7       0.79      0.97      0.87        65\n",
      "          8       1.00      0.53      0.69        17\n",
      "\n",
      "avg / total       0.82      0.80      0.77       316\n",
      "\n",
      "[23  0  4  0  0  0  0  1  0  0  5  9  0  0  0  0  0  0  0  0 98  0  0  0\n",
      "  0  0  0  0  0  8  0  0  1  0  2  0  0  0  8  0  4  0  0  4  0  0  0  3\n",
      "  0  0 48  0  4  0  0  0  7  0  0  0  4  1  0  0  0  2  0  0  0  0 63  0\n",
      "  0  0  3  0  0  0  0  5  9]\n",
      "MNB Accuracy:  0.8037974683544303\n",
      "MNB F1:  0.6254770414533413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        28\n",
      "          1       1.00      0.71      0.83        14\n",
      "          2       0.69      1.00      0.82        98\n",
      "          3       1.00      0.36      0.53        11\n",
      "          4       1.00      0.69      0.81        16\n",
      "          5       1.00      0.80      0.89        55\n",
      "          6       1.00      0.67      0.80        12\n",
      "          7       1.00      0.88      0.93        65\n",
      "          8       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.90      0.86      0.86       316\n",
      "\n",
      "[25  0  3  0  0  0  0  0  0  0 10  4  0  0  0  0  0  0  0  0 98  0  0  0\n",
      "  0  0  0  0  0  7  4  0  0  0  0  0  0  0  5  0 11  0  0  0  0  0  0 11\n",
      "  0  0 44  0  0  0  0  0  4  0  0  0  8  0  0  0  0  8  0  0  0  0 57  0\n",
      "  0  0  2  0  0  0  0  0 15]\n",
      "svc Accuracy:  0.8607594936708861\n",
      "svc F1:  0.8335954992178143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        28\n",
      "          1       1.00      0.36      0.53        14\n",
      "          2       0.59      1.00      0.74        98\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.50      0.67        16\n",
      "          5       1.00      0.75      0.85        55\n",
      "          6       1.00      0.50      0.67        12\n",
      "          7       1.00      0.86      0.93        65\n",
      "          8       1.00      0.59      0.74        17\n",
      "\n",
      "avg / total       0.84      0.78      0.77       316\n",
      "\n",
      "[23  0  5  0  0  0  0  0  0  0  5  9  0  0  0  0  0  0  0  0 98  0  0  0\n",
      "  0  0  0  0  0 11  0  0  0  0  0  0  0  0  8  0  8  0  0  0  0  0  0 14\n",
      "  0  0 41  0  0  0  0  0  6  0  0  0  6  0  0  0  0  9  0  0  0  0 56  0\n",
      "  0  0  7  0  0  0  0  0 10]\n",
      "LR Accuracy:  0.7816455696202531\n",
      "LR F1:  0.6690844211942586\n",
      "For name:  t_allen\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0002-3911-7914': 17, '0000-0002-3512-9475': 14, '0000-0002-0667-6138': 10, '0000-0002-2372-7259': 3, '0000-0002-1107-1416': 2, '0000-0002-2972-7911': 1, '0000-0002-1252-6056': 1})\n",
      "['0000-0002-3512-9475', '0000-0002-0667-6138', '0000-0002-3911-7914']\n",
      "Total sample size after apply threshold:  41\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 78)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "41\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        14\n",
      "          1       1.00      0.50      0.67        10\n",
      "          2       0.73      0.94      0.82        17\n",
      "\n",
      "avg / total       0.86      0.83      0.82        41\n",
      "\n",
      "[13  0  1  0  5  5  1  0 16]\n",
      "MNB Accuracy:  0.8292682926829268\n",
      "MNB F1:  0.8052503052503054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        14\n",
      "          1       0.88      0.70      0.78        10\n",
      "          2       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.88      0.85      0.85        41\n",
      "\n",
      "[14  0  0  3  7  0  2  1 14]\n",
      "svc Accuracy:  0.8536585365853658\n",
      "svc F1:  0.8431628109047463\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        14\n",
      "          1       1.00      0.50      0.67        10\n",
      "          2       0.88      0.88      0.88        17\n",
      "\n",
      "avg / total       0.86      0.83      0.82        41\n",
      "\n",
      "[14  0  0  3  5  2  2  0 15]\n",
      "LR Accuracy:  0.8292682926829268\n",
      "LR F1:  0.7991681521093286\n",
      "For name:  j_sullivan\n",
      "total sample size before apply threshold:  79\n",
      "Counter({'0000-0003-1457-2950': 26, '0000-0001-5445-708X': 17, '0000-0003-4489-4926': 14, '0000-0003-3209-0218': 9, '0000-0001-6732-0699': 7, '0000-0002-5952-3805': 2, '0000-0003-2906-2232': 1, '0000-0002-7279-4319': 1, '0000-0002-3746-3047': 1, '0000-0002-5441-4343': 1})\n",
      "['0000-0003-4489-4926', '0000-0001-5445-708X', '0000-0003-1457-2950']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 175)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        14\n",
      "          1       0.93      0.76      0.84        17\n",
      "          2       0.78      0.96      0.86        26\n",
      "\n",
      "avg / total       0.88      0.86      0.86        57\n",
      "\n",
      "[11  0  3  0 13  4  0  1 25]\n",
      "MNB Accuracy:  0.8596491228070176\n",
      "MNB F1:  0.860259547645532\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       1.00      0.76      0.87        17\n",
      "          2       0.81      1.00      0.90        26\n",
      "\n",
      "avg / total       0.91      0.89      0.89        57\n",
      "\n",
      "[12  0  2  0 13  4  0  0 26]\n",
      "svc Accuracy:  0.8947368421052632\n",
      "svc F1:  0.8954317712938402\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        14\n",
      "          1       1.00      0.71      0.83        17\n",
      "          2       0.76      1.00      0.87        26\n",
      "\n",
      "avg / total       0.89      0.86      0.86        57\n",
      "\n",
      "[11  0  3  0 12  5  0  0 26]\n",
      "LR Accuracy:  0.8596491228070176\n",
      "LR F1:  0.8580842911877394\n",
      "For name:  s_rogers\n",
      "total sample size before apply threshold:  224\n",
      "Counter({'0000-0002-5989-6142': 200, '0000-0003-3578-4477': 9, '0000-0003-1139-4730': 8, '0000-0002-3432-5044': 3, '0000-0003-0516-7929': 2, '0000-0001-9974-7152': 1, '0000-0002-0809-2726': 1})\n",
      "['0000-0002-5989-6142']\n",
      "Total sample size after apply threshold:  200\n",
      "For name:  h_yoon\n",
      "total sample size before apply threshold:  72\n",
      "Counter({'0000-0002-5403-1617': 34, '0000-0003-2180-4940': 10, '0000-0002-7139-0419': 7, '0000-0002-7552-0479': 6, '0000-0003-3087-8853': 5, '0000-0002-9597-6342': 4, '0000-0002-6211-7680': 3, '0000-0002-8553-0152': 1, '0000-0001-7547-0320': 1, '0000-0003-3524-8762': 1})\n",
      "['0000-0002-5403-1617', '0000-0003-2180-4940']\n",
      "Total sample size after apply threshold:  44\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 55)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        34\n",
      "          1       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.90      0.89      0.87        44\n",
      "\n",
      "[34  0  5  5]\n",
      "MNB Accuracy:  0.8863636363636364\n",
      "MNB F1:  0.7990867579908676\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        34\n",
      "          1       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.96      0.95      0.95        44\n",
      "\n",
      "[34  0  2  8]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.9301587301587302\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        34\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.60      0.77      0.67        44\n",
      "\n",
      "[34  0 10  0]\n",
      "LR Accuracy:  0.7727272727272727\n",
      "LR F1:  0.4358974358974359\n",
      "For name:  a_young\n",
      "total sample size before apply threshold:  442\n",
      "Counter({'0000-0002-1202-6297': 138, '0000-0001-5702-4220': 78, '0000-0002-4163-6772': 54, '0000-0002-9367-9213': 38, '0000-0002-7288-3469': 31, '0000-0001-8551-5078': 25, '0000-0003-3969-3249': 22, '0000-0002-0077-137X': 22, '0000-0001-6251-0944': 20, '0000-0002-8486-0643': 8, '0000-0002-8127-7380': 2, '0000-0002-1994-9211': 1, '0000-0002-1486-5561': 1, '0000-0001-6800-1454': 1, '0000-0003-4822-6335': 1})\n",
      "['0000-0001-6251-0944', '0000-0001-8551-5078', '0000-0002-4163-6772', '0000-0002-7288-3469', '0000-0002-1202-6297', '0000-0001-5702-4220', '0000-0003-3969-3249', '0000-0002-0077-137X', '0000-0002-9367-9213']\n",
      "Total sample size after apply threshold:  428\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(428, 915)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "428\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        20\n",
      "          1       1.00      0.32      0.48        25\n",
      "          2       0.85      0.52      0.64        54\n",
      "          3       1.00      0.39      0.56        31\n",
      "          4       0.51      1.00      0.68       138\n",
      "          5       0.99      0.85      0.91        78\n",
      "          6       1.00      0.59      0.74        22\n",
      "          7       0.00      0.00      0.00        22\n",
      "          8       1.00      0.63      0.77        38\n",
      "\n",
      "avg / total       0.77      0.68      0.65       428\n",
      "\n",
      "[  2   0   0   0  18   0   0   0   0   0   8   0   0  17   0   0   0   0\n",
      "   0   0  28   0  26   0   0   0   0   0   0   0  12  19   0   0   0   0\n",
      "   0   0   0   0 138   0   0   0   0   0   0   0   0  12  66   0   0   0\n",
      "   0   0   0   0   9   0  13   0   0   0   0   5   0  17   0   0   0   0\n",
      "   0   0   0   0  13   1   0   0  24]\n",
      "MNB Accuracy:  0.6799065420560748\n",
      "MNB F1:  0.552668062159228\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.65      0.79        20\n",
      "          1       1.00      0.72      0.84        25\n",
      "          2       0.87      0.72      0.79        54\n",
      "          3       1.00      0.65      0.78        31\n",
      "          4       0.64      0.99      0.78       138\n",
      "          5       0.99      0.86      0.92        78\n",
      "          6       1.00      0.86      0.93        22\n",
      "          7       1.00      0.14      0.24        22\n",
      "          8       0.97      0.79      0.87        38\n",
      "\n",
      "avg / total       0.86      0.81      0.80       428\n",
      "\n",
      "[ 13   0   0   0   6   0   0   0   1   0  18   0   0   7   0   0   0   0\n",
      "   0   0  39   0  15   0   0   0   0   0   0   0  20  11   0   0   0   0\n",
      "   0   0   1   0 136   1   0   0   0   0   0   0   0  11  67   0   0   0\n",
      "   0   0   0   0   3   0  19   0   0   0   0   5   0  14   0   0   3   0\n",
      "   0   0   0   0   8   0   0   0  30]\n",
      "svc Accuracy:  0.8060747663551402\n",
      "svc F1:  0.7700947706602874\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        20\n",
      "          1       1.00      0.52      0.68        25\n",
      "          2       0.85      0.54      0.66        54\n",
      "          3       1.00      0.42      0.59        31\n",
      "          4       0.52      1.00      0.68       138\n",
      "          5       1.00      0.79      0.89        78\n",
      "          6       1.00      0.68      0.81        22\n",
      "          7       0.00      0.00      0.00        22\n",
      "          8       1.00      0.55      0.71        38\n",
      "\n",
      "avg / total       0.78      0.69      0.67       428\n",
      "\n",
      "[  5   0   0   0  15   0   0   0   0   0  13   0   0  12   0   0   0   0\n",
      "   0   0  29   0  25   0   0   0   0   0   0   0  13  18   0   0   0   0\n",
      "   0   0   0   0 138   0   0   0   0   0   0   0   0  16  62   0   0   0\n",
      "   0   0   0   0   7   0  15   0   0   0   0   5   0  17   0   0   0   0\n",
      "   0   0   0   0  17   0   0   0  21]\n",
      "LR Accuracy:  0.6915887850467289\n",
      "LR F1:  0.6030515059104165\n",
      "For name:  m_richardson\n",
      "total sample size before apply threshold:  175\n",
      "Counter({'0000-0001-5672-9552': 166, '0000-0002-1650-0064': 5, '0000-0002-7390-9480': 3, '0000-0003-2694-5486': 1})\n",
      "['0000-0001-5672-9552']\n",
      "Total sample size after apply threshold:  166\n",
      "For name:  c_ryan\n",
      "total sample size before apply threshold:  159\n",
      "Counter({'0000-0003-2158-9427': 71, '0000-0003-1915-546X': 29, '0000-0003-2750-9854': 17, '0000-0001-5864-4325': 15, '0000-0003-2891-3912': 14, '0000-0002-1802-0128': 9, '0000-0003-0986-6110': 2, '0000-0002-9674-3946': 1, '0000-0002-6455-936X': 1})\n",
      "['0000-0001-5864-4325', '0000-0003-1915-546X', '0000-0003-2750-9854', '0000-0003-2158-9427', '0000-0003-2891-3912']\n",
      "Total sample size after apply threshold:  146\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 358)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "146\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        15\n",
      "          1       1.00      0.62      0.77        29\n",
      "          2       1.00      0.29      0.45        17\n",
      "          3       0.63      1.00      0.77        71\n",
      "          4       1.00      0.71      0.83        14\n",
      "\n",
      "avg / total       0.72      0.71      0.66       146\n",
      "\n",
      "[ 0  0  0 15  0  0 18  0 11  0  0  0  5 12  0  0  0  0 71  0  0  0  0  4\n",
      " 10]\n",
      "MNB Accuracy:  0.7123287671232876\n",
      "MNB F1:  0.5651150730244161\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        15\n",
      "          1       1.00      0.69      0.82        29\n",
      "          2       1.00      0.47      0.64        17\n",
      "          3       0.70      1.00      0.83        71\n",
      "          4       1.00      0.86      0.92        14\n",
      "\n",
      "avg / total       0.86      0.79      0.78       146\n",
      "\n",
      "[ 5  0  0 10  0  0 20  0  9  0  0  0  8  9  0  0  0  0 71  0  0  0  0  2\n",
      " 12]\n",
      "svc Accuracy:  0.7945205479452054\n",
      "svc F1:  0.740996969807601\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        15\n",
      "          1       1.00      0.62      0.77        29\n",
      "          2       1.00      0.29      0.45        17\n",
      "          3       0.62      1.00      0.76        71\n",
      "          4       1.00      0.57      0.73        14\n",
      "\n",
      "avg / total       0.71      0.70      0.65       146\n",
      "\n",
      "[ 0  0  0 15  0  0 18  0 11  0  0  0  5 12  0  0  0  0 71  0  0  0  0  6\n",
      "  8]\n",
      "LR Accuracy:  0.6986301369863014\n",
      "LR F1:  0.5422432977683492\n",
      "For name:  l_jensen\n",
      "total sample size before apply threshold:  275\n",
      "Counter({'0000-0001-7885-715X': 140, '0000-0002-0267-8312': 37, '0000-0003-3199-1743': 37, '0000-0002-0020-1537': 28, '0000-0002-1446-2084': 22, '0000-0003-2338-357X': 8, '0000-0001-9059-5869': 1, '0000-0003-2786-5920': 1, '0000-0002-1648-3970': 1})\n",
      "['0000-0002-0020-1537', '0000-0002-1446-2084', '0000-0001-7885-715X', '0000-0002-0267-8312', '0000-0003-3199-1743']\n",
      "Total sample size after apply threshold:  264\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(264, 879)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "264\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        28\n",
      "          1       1.00      0.09      0.17        22\n",
      "          2       0.67      0.99      0.80       140\n",
      "          3       0.94      0.46      0.62        37\n",
      "          4       1.00      0.54      0.70        37\n",
      "\n",
      "avg / total       0.81      0.73      0.70       264\n",
      "\n",
      "[ 15   0  13   0   0   0   2  20   0   0   0   0 139   1   0   0   0  20\n",
      "  17   0   0   0  17   0  20]\n",
      "MNB Accuracy:  0.7310606060606061\n",
      "MNB F1:  0.5961677788005151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        28\n",
      "          1       1.00      0.68      0.81        22\n",
      "          2       0.81      1.00      0.90       140\n",
      "          3       1.00      0.78      0.88        37\n",
      "          4       1.00      0.78      0.88        37\n",
      "\n",
      "avg / total       0.90      0.88      0.88       264\n",
      "\n",
      "[ 19   0   9   0   0   0  15   7   0   0   0   0 140   0   0   0   0   8\n",
      "  29   0   0   0   8   0  29]\n",
      "svc Accuracy:  0.8787878787878788\n",
      "svc F1:  0.8548666208240677\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        28\n",
      "          1       1.00      0.05      0.09        22\n",
      "          2       0.65      1.00      0.78       140\n",
      "          3       1.00      0.41      0.58        37\n",
      "          4       1.00      0.51      0.68        37\n",
      "\n",
      "avg / total       0.81      0.71      0.66       264\n",
      "\n",
      "[ 12   0  16   0   0   0   1  21   0   0   0   0 140   0   0   0   0  22\n",
      "  15   0   0   0  18   0  19]\n",
      "LR Accuracy:  0.7083333333333334\n",
      "LR F1:  0.5453529505447663\n",
      "For name:  h_ferreira\n",
      "total sample size before apply threshold:  135\n",
      "Counter({'0000-0003-3611-6040': 53, '0000-0002-3261-3712': 22, '0000-0002-3770-9393': 16, '0000-0001-9143-504X': 13, '0000-0002-4323-3942': 12, '0000-0003-0834-2956': 12, '0000-0002-8895-2422': 7})\n",
      "['0000-0003-3611-6040', '0000-0001-9143-504X', '0000-0002-4323-3942', '0000-0002-3770-9393', '0000-0002-3261-3712', '0000-0003-0834-2956']\n",
      "Total sample size after apply threshold:  128\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(128, 462)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "128\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80        53\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       1.00      0.50      0.67        12\n",
      "          3       1.00      1.00      1.00        16\n",
      "          4       1.00      0.64      0.78        22\n",
      "          5       1.00      0.42      0.59        12\n",
      "\n",
      "avg / total       0.86      0.80      0.79       128\n",
      "\n",
      "[53  0  0  0  0  0  5  8  0  0  0  0  6  0  6  0  0  0  0  0  0 16  0  0\n",
      "  8  0  0  0 14  0  7  0  0  0  0  5]\n",
      "MNB Accuracy:  0.796875\n",
      "MNB F1:  0.7662691339161927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        53\n",
      "          1       1.00      0.85      0.92        13\n",
      "          2       1.00      0.67      0.80        12\n",
      "          3       1.00      1.00      1.00        16\n",
      "          4       1.00      0.86      0.93        22\n",
      "          5       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.92      0.91      0.90       128\n",
      "\n",
      "[53  0  0  0  0  0  2 11  0  0  0  0  4  0  8  0  0  0  0  0  0 16  0  0\n",
      "  3  0  0  0 19  0  3  0  0  0  0  9]\n",
      "svc Accuracy:  0.90625\n",
      "svc F1:  0.8998239794746615\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      1.00      0.77        53\n",
      "          1       1.00      0.54      0.70        13\n",
      "          2       1.00      0.50      0.67        12\n",
      "          3       1.00      1.00      1.00        16\n",
      "          4       1.00      0.55      0.71        22\n",
      "          5       1.00      0.25      0.40        12\n",
      "\n",
      "avg / total       0.85      0.76      0.74       128\n",
      "\n",
      "[53  0  0  0  0  0  6  7  0  0  0  0  6  0  6  0  0  0  0  0  0 16  0  0\n",
      " 10  0  0  0 12  0  9  0  0  0  0  3]\n",
      "LR Accuracy:  0.7578125\n",
      "LR F1:  0.7077119412241782\n",
      "For name:  a_mahmoud\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0003-2459-5195': 19, '0000-0002-4716-7524': 15, '0000-0001-8905-9196': 7, '0000-0003-2959-0692': 4, '0000-0002-8703-841X': 3})\n",
      "['0000-0002-4716-7524', '0000-0003-2459-5195']\n",
      "Total sample size after apply threshold:  34\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 51)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       0.86      1.00      0.93        19\n",
      "\n",
      "avg / total       0.92      0.91      0.91        34\n",
      "\n",
      "[12  3  0 19]\n",
      "MNB Accuracy:  0.9117647058823529\n",
      "MNB F1:  0.9078590785907859\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        15\n",
      "          1       0.95      0.95      0.95        19\n",
      "\n",
      "avg / total       0.94      0.94      0.94        34\n",
      "\n",
      "[14  1  1 18]\n",
      "svc Accuracy:  0.9411764705882353\n",
      "svc F1:  0.9403508771929825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.85        15\n",
      "          1       0.83      1.00      0.90        19\n",
      "\n",
      "avg / total       0.90      0.88      0.88        34\n",
      "\n",
      "[11  4  0 19]\n",
      "LR Accuracy:  0.8823529411764706\n",
      "LR F1:  0.8754578754578753\n",
      "For name:  y_liao\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0002-4434-3780': 42, '0000-0001-9496-4190': 21, '0000-0002-9384-336X': 15, '0000-0002-8217-8202': 13, '0000-0002-0399-0201': 13, '0000-0002-4360-7932': 7, '0000-0001-5658-8948': 2, '0000-0002-4401-8275': 1, '0000-0002-2107-918X': 1})\n",
      "['0000-0002-9384-336X', '0000-0001-9496-4190', '0000-0002-8217-8202', '0000-0002-0399-0201', '0000-0002-4434-3780']\n",
      "Total sample size after apply threshold:  104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(104, 184)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "104\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       0.78      0.33      0.47        21\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       1.00      0.23      0.38        13\n",
      "          4       0.58      1.00      0.74        42\n",
      "\n",
      "avg / total       0.79      0.69      0.66       104\n",
      "\n",
      "[12  0  0  0  3  0  7  0  0 14  0  0  8  0  5  0  2  0  3  8  0  0  0  0\n",
      " 42]\n",
      "MNB Accuracy:  0.6923076923076923\n",
      "MNB F1:  0.6458604845446951\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       0.83      0.71      0.77        21\n",
      "          2       1.00      0.85      0.92        13\n",
      "          3       1.00      0.69      0.82        13\n",
      "          4       0.76      0.93      0.84        42\n",
      "\n",
      "avg / total       0.87      0.86      0.86       104\n",
      "\n",
      "[15  0  0  0  0  0 15  0  0  6  0  0 11  0  2  0  0  0  9  4  0  3  0  0\n",
      " 39]\n",
      "svc Accuracy:  0.8557692307692307\n",
      "svc F1:  0.8685577862997217\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       1.00      0.52      0.69        21\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       1.00      0.46      0.63        13\n",
      "          4       0.63      1.00      0.77        42\n",
      "\n",
      "avg / total       0.85      0.76      0.75       104\n",
      "\n",
      "[12  0  0  0  3  0 11  0  0 10  0  0  8  0  5  0  0  0  6  7  0  0  0  0\n",
      " 42]\n",
      "LR Accuracy:  0.7596153846153846\n",
      "LR F1:  0.7481029599993869\n",
      "For name:  m_svensson\n",
      "total sample size before apply threshold:  142\n",
      "Counter({'0000-0003-1179-7003': 40, '0000-0003-1695-7934': 35, '0000-0002-8304-1398': 20, '0000-0003-1113-7478': 18, '0000-0003-4972-4416': 17, '0000-0001-8077-9824': 12})\n",
      "['0000-0001-8077-9824', '0000-0002-8304-1398', '0000-0003-4972-4416', '0000-0003-1695-7934', '0000-0003-1113-7478', '0000-0003-1179-7003']\n",
      "Total sample size after apply threshold:  142\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(142, 429)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "142\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.94      0.80      0.86        20\n",
      "          2       1.00      0.29      0.45        17\n",
      "          3       0.91      0.83      0.87        35\n",
      "          4       1.00      0.11      0.20        18\n",
      "          5       0.50      1.00      0.67        40\n",
      "\n",
      "avg / total       0.83      0.69      0.66       142\n",
      "\n",
      "[ 6  0  0  0  0  6  0 16  0  0  0  4  0  0  5  2  0 10  0  0  0 29  0  6\n",
      "  0  1  0  1  2 14  0  0  0  0  0 40]\n",
      "MNB Accuracy:  0.6901408450704225\n",
      "MNB F1:  0.6197358824224496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       0.89      0.85      0.87        20\n",
      "          2       1.00      0.71      0.83        17\n",
      "          3       0.62      1.00      0.77        35\n",
      "          4       0.88      0.39      0.54        18\n",
      "          5       0.97      0.93      0.95        40\n",
      "\n",
      "avg / total       0.87      0.82      0.82       142\n",
      "\n",
      "[ 9  0  0  2  0  1  0 17  0  3  0  0  0  1 12  4  0  0  0  0  0 35  0  0\n",
      "  0  1  0 10  7  0  0  0  0  2  1 37]\n",
      "svc Accuracy:  0.823943661971831\n",
      "svc F1:  0.8021556987074229\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.89      0.80      0.84        20\n",
      "          2       1.00      0.53      0.69        17\n",
      "          3       0.56      0.94      0.70        35\n",
      "          4       1.00      0.28      0.43        18\n",
      "          5       0.84      0.93      0.88        40\n",
      "\n",
      "avg / total       0.83      0.75      0.74       142\n",
      "\n",
      "[ 7  0  0  3  0  2  0 16  0  4  0  0  0  1  9  7  0  0  0  0  0 33  0  2\n",
      "  0  1  0  9  5  3  0  0  0  3  0 37]\n",
      "LR Accuracy:  0.7535211267605634\n",
      "LR F1:  0.7148529516585412\n",
      "For name:  p_tsai\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-8650-647X': 31, '0000-0002-3095-3991': 14, '0000-0003-4681-0685': 12, '0000-0001-8217-6285': 9, '0000-0003-1274-574X': 4, '0000-0003-2809-0733': 2, '0000-0003-0005-1476': 1})\n",
      "['0000-0002-3095-3991', '0000-0002-8650-647X', '0000-0003-4681-0685']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 102)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        14\n",
      "          1       0.82      1.00      0.90        31\n",
      "          2       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.90      0.88      0.86        57\n",
      "\n",
      "[ 7  7  0  0 31  0  0  0 12]\n",
      "MNB Accuracy:  0.8771929824561403\n",
      "MNB F1:  0.8550724637681159\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.94      1.00      0.97        31\n",
      "          2       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.97      0.96      0.96        57\n",
      "\n",
      "[12  2  0  0 31  0  0  0 12]\n",
      "svc Accuracy:  0.9649122807017544\n",
      "svc F1:  0.9639423076923076\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.44        14\n",
      "          1       0.72      1.00      0.84        31\n",
      "          2       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.85      0.79      0.76        57\n",
      "\n",
      "[ 4 10  0  0 31  0  0  2 10]\n",
      "LR Accuracy:  0.7894736842105263\n",
      "LR F1:  0.7304577304577305\n",
      "For name:  r_berry\n",
      "total sample size before apply threshold:  85\n",
      "Counter({'0000-0002-7162-5046': 49, '0000-0002-6140-1583': 28, '0000-0002-1861-6722': 4, '0000-0002-4272-9858': 4})\n",
      "['0000-0002-6140-1583', '0000-0002-7162-5046']\n",
      "Total sample size after apply threshold: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 191)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        28\n",
      "          1       0.98      1.00      0.99        49\n",
      "\n",
      "avg / total       0.99      0.99      0.99        77\n",
      "\n",
      "[27  1  0 49]\n",
      "MNB Accuracy:  0.987012987012987\n",
      "MNB F1:  0.9858585858585859\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        28\n",
      "          1       0.96      1.00      0.98        49\n",
      "\n",
      "avg / total       0.98      0.97      0.97        77\n",
      "\n",
      "[26  2  0 49]\n",
      "svc Accuracy:  0.974025974025974\n",
      "svc F1:  0.9714814814814815\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        28\n",
      "          1       0.84      1.00      0.92        49\n",
      "\n",
      "avg / total       0.90      0.88      0.88        77\n",
      "\n",
      "[19  9  0 49]\n",
      "LR Accuracy:  0.8831168831168831\n",
      "LR F1:  0.862199244382581\n",
      "For name:  j_kwok\n",
      "total sample size before apply threshold:  100\n",
      "Counter({'0000-0001-9574-6195': 76, '0000-0002-9798-9083': 23, '0000-0001-7444-6935': 1})\n",
      "['0000-0001-9574-6195', '0000-0002-9798-9083']\n",
      "Total sample size after apply threshold:  99\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(99, 883)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92        76\n",
      "          1       0.92      0.48      0.63        23\n",
      "\n",
      "avg / total       0.87      0.87      0.85        99\n",
      "\n",
      "[75  1 12 11]\n",
      "MNB Accuracy:  0.8686868686868687\n",
      "MNB F1:  0.7744084136722174\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        76\n",
      "          1       1.00      0.91      0.95        23\n",
      "\n",
      "avg / total       0.98      0.98      0.98        99\n",
      "\n",
      "[76  0  2 21]\n",
      "svc Accuracy:  0.9797979797979798\n",
      "svc F1:  0.9707792207792207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        76\n",
      "          1       1.00      0.26      0.41        23\n",
      "\n",
      "avg / total       0.86      0.83      0.79        99\n",
      "\n",
      "[76  0 17  6]\n",
      "LR Accuracy:  0.8282828282828283\n",
      "LR F1:  0.6566006937359722\n",
      "For name:  m_schneider\n",
      "total sample size before apply threshold:  367\n",
      "Counter({'0000-0001-9645-1938': 110, '0000-0002-9570-3491': 91, '0000-0002-9260-7357': 56, '0000-0001-7190-3379': 34, '0000-0002-7114-2060': 29, '0000-0002-1223-1266': 14, '0000-0001-7147-8915': 10, '0000-0002-3842-2618': 10, '0000-0003-1488-4743': 8, '0000-0001-7534-5431': 2, '0000-0001-9846-7132': 2, '0000-0002-4918-1389': 1})\n",
      "['0000-0002-9570-3491', '0000-0002-9260-7357', '0000-0001-9645-1938', '0000-0001-7190-3379', '0000-0001-7147-8915', '0000-0002-3842-2618', '0000-0002-7114-2060', '0000-0002-1223-1266']\n",
      "Total sample size after apply threshold:  354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(354, 1357)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "354\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.86      0.86        91\n",
      "          1       1.00      0.71      0.83        56\n",
      "          2       0.50      0.97      0.66       110\n",
      "          3       1.00      0.06      0.11        34\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       1.00      0.21      0.34        29\n",
      "          7       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.71      0.66      0.60       354\n",
      "\n",
      "[ 78   0  13   0   0   0   0   0   2  40  14   0   0   0   0   0   3   0\n",
      " 107   0   0   0   0   0   0   0  32   2   0   0   0   0   0   0  10   0\n",
      "   0   0   0   0   1   0   9   0   0   0   0   0   5   0  18   0   0   0\n",
      "   6   0   2   0  12   0   0   0   0   0]\n",
      "MNB Accuracy:  0.6581920903954802\n",
      "MNB F1:  0.35036324786324785\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        91\n",
      "          1       1.00      0.71      0.83        56\n",
      "          2       0.54      1.00      0.70       110\n",
      "          3       1.00      0.35      0.52        34\n",
      "          4       1.00      0.80      0.89        10\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       1.00      0.24      0.39        29\n",
      "          7       1.00      0.57      0.73        14\n",
      "\n",
      "avg / total       0.83      0.73      0.72       354\n",
      "\n",
      "[ 74   0  17   0   0   0   0   0   0  40  16   0   0   0   0   0   0   0\n",
      " 110   0   0   0   0   0   0   0  22  12   0   0   0   0   0   0   2   0\n",
      "   8   0   0   0   0   0  10   0   0   0   0   0   0   0  22   0   0   0\n",
      "   7   0   0   0   6   0   0   0   0   8]\n",
      "svc Accuracy:  0.731638418079096\n",
      "svc F1:  0.6194381705251271\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.80      0.88        91\n",
      "          1       1.00      0.68      0.81        56\n",
      "          2       0.47      1.00      0.64       110\n",
      "          3       1.00      0.03      0.06        34\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       1.00      0.21      0.34        29\n",
      "          7       1.00      0.14      0.25        14\n",
      "\n",
      "avg / total       0.78      0.65      0.60       354\n",
      "\n",
      "[ 73   0  18   0   0   0   0   0   1  38  17   0   0   0   0   0   0   0\n",
      " 110   0   0   0   0   0   0   0  33   1   0   0   0   0   0   0  10   0\n",
      "   0   0   0   0   0   0  10   0   0   0   0   0   0   0  23   0   0   0\n",
      "   6   0   0   0  12   0   0   0   0   2]\n",
      "LR Accuracy:  0.6497175141242938\n",
      "LR F1:  0.3730948175069973\n",
      "For name:  k_wood\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-8774-8112': 17, '0000-0001-9170-6129': 4, '0000-0002-1020-7860': 3})\n",
      "['0000-0002-8774-8112']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  c_viegas\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0002-1545-6479': 26, '0000-0002-8796-5037': 21, '0000-0003-1394-0731': 19, '0000-0002-5765-3665': 1})\n",
      "['0000-0002-1545-6479', '0000-0002-8796-5037', '0000-0003-1394-0731']\n",
      "Total sample size after apply threshold:  66\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 133)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        26\n",
      "          1       0.95      1.00      0.98        21\n",
      "          2       1.00      0.84      0.91        19\n",
      "\n",
      "avg / total       0.96      0.95      0.95        66\n",
      "\n",
      "[26  0  0  0 21  0  2  1 16]\n",
      "MNB Accuracy:  0.9545454545454546\n",
      "MNB F1:  0.9513309544317297\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        26\n",
      "          1       0.95      1.00      0.98        21\n",
      "          2       0.94      0.89      0.92        19\n",
      "\n",
      "avg / total       0.95      0.95      0.95        66\n",
      "\n",
      "[25  0  1  0 21  0  1  1 17]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.952400522167964\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        26\n",
      "          1       0.95      1.00      0.98        21\n",
      "          2       1.00      0.84      0.91        19\n",
      "\n",
      "avg / total       0.96      0.95      0.95        66\n",
      "\n",
      "[26  0  0  0 21  0  2  1 16]\n",
      "LR Accuracy:  0.9545454545454546\n",
      "LR F1:  0.9513309544317297\n",
      "For name:  r_d'souza\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0002-1505-5173': 67, '0000-0002-9724-4540': 9, '0000-0001-9028-1990': 6, '0000-0001-7887-5016': 1})\n",
      "['0000-0002-1505-5173']\n",
      "Total sample size after apply threshold:  67\n",
      "For name:  s_shim\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0001-8043-2257': 14, '0000-0003-4143-7383': 10, '0000-0001-5203-6038': 10, '0000-0002-5188-688X': 7})\n",
      "['0000-0001-8043-2257', '0000-0003-4143-7383', '0000-0001-5203-6038']\n",
      "Total sample size after apply threshold:  34\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 63)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80        14\n",
      "          1       1.00      0.40      0.57        10\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.86      0.79      0.78        34\n",
      "\n",
      "[14  0  0  6  4  0  1  0  9]\n",
      "MNB Accuracy:  0.7941176470588235\n",
      "MNB F1:  0.7729323308270676\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        14\n",
      "          1       1.00      0.90      0.95        10\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        34\n",
      "\n",
      "[14  0  0  1  9  0  0  0 10]\n",
      "svc Accuracy:  0.9705882352941176\n",
      "svc F1:  0.9709618874773139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        14\n",
      "          1       1.00      0.60      0.75        10\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.91      0.88      0.88        34\n",
      "\n",
      "[14  0  0  4  6  0  0  0 10]\n",
      "LR Accuracy:  0.8823529411764706\n",
      "LR F1:  0.875\n",
      "For name:  j_herrero\n",
      "total sample size before apply threshold:  105\n",
      "Counter({'0000-0003-1986-3482': 51, '0000-0001-7313-717X': 46, '0000-0002-0146-2464': 6, '0000-0001-8501-1187': 2})\n",
      "['0000-0003-1986-3482', '0000-0001-7313-717X']\n",
      "Total sample size after apply threshold:  97\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(97, 1023)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        51\n",
      "          1       1.00      0.72      0.84        46\n",
      "\n",
      "avg / total       0.89      0.87      0.86        97\n",
      "\n",
      "[51  0 13 33]\n",
      "MNB Accuracy:  0.865979381443299\n",
      "MNB F1:  0.8611997798569069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        51\n",
      "          1       0.96      1.00      0.98        46\n",
      "\n",
      "avg / total       0.98      0.98      0.98        97\n",
      "\n",
      "[49  2  0 46]\n",
      "svc Accuracy:  0.979381443298969\n",
      "svc F1:  0.9793617021276595\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98        51\n",
      "          1       0.98      0.98      0.98        46\n",
      "\n",
      "avg / total       0.98      0.98      0.98        97\n",
      "\n",
      "[50  1  1 45]\n",
      "LR Accuracy:  0.979381443298969\n",
      "LR F1:  0.9793265132139812\n",
      "For name:  m_acosta\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0002-5018-339X': 24, '0000-0003-4827-7271': 17, '0000-0003-0611-6672': 4, '0000-0001-9504-883X': 2})\n",
      "['0000-0003-4827-7271', '0000-0002-5018-339X']\n",
      "Total sample size after apply threshold:  41\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 141)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "41\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        17\n",
      "          1       0.92      1.00      0.96        24\n",
      "\n",
      "avg / total       0.95      0.95      0.95        41\n",
      "\n",
      "[15  2  0 24]\n",
      "MNB Accuracy:  0.9512195121951219\n",
      "MNB F1:  0.94875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        17\n",
      "          1       0.96      0.96      0.96        24\n",
      "\n",
      "avg / total       0.95      0.95      0.95        41\n",
      "\n",
      "[16  1  1 23]\n",
      "svc Accuracy:  0.9512195121951219\n",
      "svc F1:  0.9497549019607843\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.87        17\n",
      "          1       0.86      1.00      0.92        24\n",
      "\n",
      "avg / total       0.92      0.90      0.90        41\n",
      "\n",
      "[13  4  0 24]\n",
      "LR Accuracy:  0.9024390243902439\n",
      "LR F1:  0.8948717948717948\n",
      "For name:  a_chan\n",
      "total sample size before apply threshold:  249\n",
      "Counter({'0000-0003-1551-3995': 218, '0000-0002-2886-2513': 10, '0000-0002-1771-163X': 7, '0000-0003-3553-7249': 5, '0000-0003-2267-4949': 4, '0000-0001-6953-0120': 3, '0000-0001-7216-191X': 1, '0000-0002-5788-333X': 1})\n",
      "['0000-0003-1551-3995', '0000-0002-2886-2513']\n",
      "Total sample size after apply threshold:  228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(228, 512)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "228\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       218\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.91      0.96      0.93       228\n",
      "\n",
      "[218   0  10   0]\n",
      "MNB Accuracy:  0.956140350877193\n",
      "MNB F1:  0.4887892376681614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99       218\n",
      "          1       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97       228\n",
      "\n",
      "[218   0   6   4]\n",
      "svc Accuracy:  0.9736842105263158\n",
      "svc F1:  0.7789269553975438\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       218\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.91      0.96      0.93       228\n",
      "\n",
      "[218   0  10   0]\n",
      "LR Accuracy:  0.956140350877193\n",
      "LR F1:  0.4887892376681614\n",
      "For name:  p_kelly\n",
      "total sample size before apply threshold:  55\n",
      "Counter({'0000-0003-0500-1865': 27, '0000-0001-9040-1868': 11, '0000-0001-8933-2367': 6, '0000-0003-4338-6225': 5, '0000-0002-7490-5772': 5, '0000-0002-8813-8877': 1})\n",
      "['0000-0001-9040-1868', '0000-0003-0500-1865']\n",
      "Total sample size after apply threshold:  38\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(38, 100)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       0.82      1.00      0.90        27\n",
      "\n",
      "avg / total       0.87      0.84      0.82        38\n",
      "\n",
      "[ 5  6  0 27]\n",
      "MNB Accuracy:  0.8421052631578947\n",
      "MNB F1:  0.7625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.87      1.00      0.93        27\n",
      "\n",
      "avg / total       0.91      0.89      0.89        38\n",
      "\n",
      "[ 7  4  0 27]\n",
      "svc Accuracy:  0.8947368421052632\n",
      "svc F1:  0.8544061302681992\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        11\n",
      "          1       0.77      1.00      0.87        27\n",
      "\n",
      "avg / total       0.84      0.79      0.74        38\n",
      "\n",
      "[ 3  8  0 27]\n",
      "LR Accuracy:  0.7894736842105263\n",
      "LR F1:  0.6497695852534563\n",
      "For name:  j_weiner\n",
      "total sample size before apply threshold:  61\n",
      "Counter({'0000-0002-3352-2847': 35, '0000-0002-0736-7943': 15, '0000-0001-5810-5807': 10, '0000-0002-8099-760X': 1})\n",
      "['0000-0002-3352-2847', '0000-0002-0736-7943', '0000-0001-5810-5807']\n",
      "Total sample size after apply threshold:  60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 187)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "60\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      1.00      0.74        35\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.34      0.58      0.43        60\n",
      "\n",
      "[35  0  0 15  0  0 10  0  0]\n",
      "MNB Accuracy:  0.5833333333333334\n",
      "MNB F1:  0.24561403508771928\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      1.00      0.78        35\n",
      "          1       1.00      0.33      0.50        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.62      0.67      0.58        60\n",
      "\n",
      "[35  0  0 10  5  0 10  0  0]\n",
      "svc Accuracy:  0.6666666666666666\n",
      "svc F1:  0.4259259259259259\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      1.00      0.74        35\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.34      0.58      0.43        60\n",
      "\n",
      "[35  0  0 15  0  0 10  0  0]\n",
      "LR Accuracy:  0.5833333333333334\n",
      "LR F1:  0.24561403508771928\n",
      "For name:  b_yu\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-1258-4168': 9, '0000-0002-0531-2236': 8, '0000-0002-7259-8190': 5, '0000-0001-6013-5220': 1, '0000-0001-7266-4197': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  s_lucas\n",
      "total sample size before apply threshold:  96\n",
      "Counter({'0000-0002-8713-2457': 64, '0000-0003-1287-7996': 19, '0000-0002-5555-5594': 10, '0000-0002-3409-2033': 2, '0000-0003-3059-7453': 1})\n",
      "['0000-0002-8713-2457', '0000-0002-5555-5594', '0000-0003-1287-7996']\n",
      "Total sample size after apply threshold:  93\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(93, 249)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93        64\n",
      "          1       1.00      0.20      0.33        10\n",
      "          2       1.00      0.95      0.97        19\n",
      "\n",
      "avg / total       0.92      0.90      0.88        93\n",
      "\n",
      "[64  0  0  8  2  0  1  0 18]\n",
      "MNB Accuracy:  0.9032258064516129\n",
      "MNB F1:  0.7468709585497907\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        64\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.95      0.97        19\n",
      "\n",
      "avg / total       0.96      0.96      0.95        93\n",
      "\n",
      "[64  0  0  3  7  0  1  0 18]\n",
      "svc Accuracy:  0.956989247311828\n",
      "svc F1:  0.9220664514782162\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        64\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       1.00      0.53      0.69        19\n",
      "\n",
      "avg / total       0.73      0.80      0.74        93\n",
      "\n",
      "[64  0  0 10  0  0  9  0 10]\n",
      "LR Accuracy:  0.7956989247311828\n",
      "LR F1:  0.5201344905778403\n",
      "For name:  e_davis\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0002-3529-098X': 17, '0000-0001-5413-5398': 2, '0000-0002-4731-1602': 1, '0000-0002-4925-1447': 1})\n",
      "['0000-0002-3529-098X']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  z_yu\n",
      "total sample size before apply threshold:  135\n",
      "Counter({'0000-0002-2979-9608': 62, '0000-0002-6165-8522': 24, '0000-0003-4420-5836': 12, '0000-0002-9152-6491': 11, '0000-0002-1401-2294': 9, '0000-0002-5797-5373': 7, '0000-0001-5828-2635': 4, '0000-0002-8762-999X': 2, '0000-0001-5913-9646': 2, '0000-0002-2311-4030': 1, '0000-0001-6348-5293': 1})\n",
      "['0000-0002-6165-8522', '0000-0002-2979-9608', '0000-0002-9152-6491', '0000-0003-4420-5836']\n",
      "Total sample size after apply threshold:  109\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 159)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        24\n",
      "          1       0.76      1.00      0.86        62\n",
      "          2       1.00      0.18      0.31        11\n",
      "          3       1.00      0.50      0.67        12\n",
      "\n",
      "avg / total       0.86      0.82      0.79       109\n",
      "\n",
      "[19  5  0  0  0 62  0  0  0  9  2  0  0  6  0  6]\n",
      "MNB Accuracy:  0.8165137614678899\n",
      "MNB F1:  0.6797977539256609\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.83      0.87        24\n",
      "          1       0.85      0.97      0.90        62\n",
      "          2       1.00      0.73      0.84        11\n",
      "          3       0.88      0.58      0.70        12\n",
      "\n",
      "avg / total       0.88      0.87      0.87       109\n",
      "\n",
      "[20  4  0  0  2 60  0  0  0  2  8  1  0  5  0  7]\n",
      "svc Accuracy:  0.8715596330275229\n",
      "svc F1:  0.8284815299117358\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        24\n",
      "          1       0.72      1.00      0.84        62\n",
      "          2       1.00      0.36      0.53        11\n",
      "          3       1.00      0.42      0.59        12\n",
      "\n",
      "avg / total       0.84      0.78      0.76       109\n",
      "\n",
      "[14 10  0  0  0 62  0  0  0  7  4  0  0  7  0  5]\n",
      "LR Accuracy:  0.7798165137614679\n",
      "LR F1:  0.674062142637994\n",
      "For name:  c_pan\n",
      "total sample size before apply threshold:  161\n",
      "Counter({'0000-0002-2652-5134': 66, '0000-0002-6654-9309': 33, '0000-0001-8700-583X': 23, '0000-0001-6327-9692': 15, '0000-0003-0108-3138': 11, '0000-0002-1031-7488': 7, '0000-0002-0089-7482': 6})\n",
      "['0000-0002-6654-9309', '0000-0001-8700-583X', '0000-0003-0108-3138', '0000-0002-2652-5134', '0000-0001-6327-9692']\n",
      "Total sample size after apply threshold:  148\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(148, 144)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.33      0.46        33\n",
      "          1       1.00      0.30      0.47        23\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.54      0.98      0.70        66\n",
      "          4       1.00      0.40      0.57        15\n",
      "\n",
      "avg / total       0.66      0.60      0.54       148\n",
      "\n",
      "[11  0  0 22  0  0  7  0 16  0  3  0  0  8  0  1  0  0 65  0  0  0  0  9\n",
      "  6]\n",
      "MNB Accuracy:  0.6013513513513513\n",
      "MNB F1:  0.4390706605222735\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.52      0.60        33\n",
      "          1       0.81      0.74      0.77        23\n",
      "          2       1.00      0.36      0.53        11\n",
      "          3       0.70      0.94      0.81        66\n",
      "          4       1.00      0.73      0.85        15\n",
      "\n",
      "avg / total       0.77      0.75      0.74       148\n",
      "\n",
      "[17  1  0 15  0  0 17  0  6  0  5  0  4  2  0  2  2  0 62  0  0  1  0  3\n",
      " 11]\n",
      "svc Accuracy:  0.75\n",
      "svc F1:  0.7107800970958864\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.36      0.48        33\n",
      "          1       0.83      0.65      0.73        23\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.58      0.94      0.72        66\n",
      "          4       1.00      0.40      0.57        15\n",
      "\n",
      "avg / total       0.65      0.64      0.60       148\n",
      "\n",
      "[12  1  0 20  0  1 15  0  7  0  2  0  0  9  0  2  2  0 62  0  0  0  0  9\n",
      "  6]\n",
      "LR Accuracy:  0.6418918918918919\n",
      "LR F1:  0.49997977885641787\n",
      "For name:  x_cao\n",
      "total sample size before apply threshold:  74\n",
      "Counter({'0000-0002-3004-7518': 25, '0000-0001-7222-5450': 14, '0000-0002-3476-9833': 12, '0000-0002-4782-853X': 11, '0000-0001-7571-6482': 10, '0000-0002-6771-0571': 1, '0000-0001-8124-7491': 1})\n",
      "['0000-0001-7571-6482', '0000-0002-3004-7518', '0000-0001-7222-5450', '0000-0002-4782-853X', '0000-0002-3476-9833']\n",
      "Total sample size after apply threshold:  72\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 269)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        10\n",
      "          1       0.51      1.00      0.68        25\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       1.00      0.18      0.31        11\n",
      "          4       0.88      0.58      0.70        12\n",
      "\n",
      "avg / total       0.81      0.65      0.63        72\n",
      "\n",
      "[ 4  6  0  0  0  0 25  0  0  0  0  4  9  0  1  0  9  0  2  0  0  5  0  0\n",
      "  7]\n",
      "MNB Accuracy:  0.6527777777777778\n",
      "MNB F1:  0.6074810500897458\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       0.93      1.00      0.96        25\n",
      "          2       1.00      0.93      0.96        14\n",
      "          3       1.00      1.00      1.00        11\n",
      "          4       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97        72\n",
      "\n",
      "[10  0  0  0  0  0 25  0  0  0  0  1 13  0  0  0  0  0 11  0  0  1  0  0\n",
      " 11]\n",
      "svc Accuracy:  0.9722222222222222\n",
      "svc F1:  0.9762046327263718\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.66      1.00      0.79        25\n",
      "          2       1.00      0.86      0.92        14\n",
      "          3       1.00      0.45      0.62        11\n",
      "          4       0.91      0.83      0.87        12\n",
      "\n",
      "avg / total       0.87      0.81      0.80        72\n",
      "\n",
      "[ 6  3  0  0  1  0 25  0  0  0  0  2 12  0  0  0  6  0  5  0  0  2  0  0\n",
      " 10]\n",
      "LR Accuracy:  0.8055555555555556\n",
      "LR F1:  0.7922585868238041\n",
      "For name:  j_yoo\n",
      "total sample size before apply threshold:  112\n",
      "Counter({'0000-0001-8378-1583': 41, '0000-0001-7120-8464': 19, '0000-0002-3924-6919': 15, '0000-0002-3150-1727': 9, '0000-0002-5488-7925': 7, '0000-0001-7119-5421': 6, '0000-0003-3881-1995': 5, '0000-0003-2611-3399': 5, '0000-0002-0259-6237': 2, '0000-0003-0639-3944': 1, '0000-0002-2330-4053': 1, '0000-0002-9508-0757': 1})\n",
      "['0000-0001-7120-8464', '0000-0002-3924-6919', '0000-0001-8378-1583']\n",
      "Total sample size after apply threshold:  75\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(75, 77)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      0.53      0.70        15\n",
      "          2       0.85      1.00      0.92        41\n",
      "\n",
      "avg / total       0.92      0.91      0.90        75\n",
      "\n",
      "[19  0  0  0  8  7  0  0 41]\n",
      "MNB Accuracy:  0.9066666666666666\n",
      "MNB F1:  0.8723334961732617\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      0.87      0.93        15\n",
      "          2       0.95      1.00      0.98        41\n",
      "\n",
      "avg / total       0.97      0.97      0.97        75\n",
      "\n",
      "[19  0  0  0 13  2  0  0 41]\n",
      "svc Accuracy:  0.9733333333333334\n",
      "svc F1:  0.9682539682539684\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        19\n",
      "          1       1.00      0.53      0.70        15\n",
      "          2       0.82      1.00      0.90        41\n",
      "\n",
      "avg / total       0.90      0.88      0.87        75\n",
      "\n",
      "[17  0  2  0  8  7  0  0 41]\n",
      "LR Accuracy:  0.88\n",
      "LR F1:  0.8470651731521297\n",
      "For name:  l_wong\n",
      "total sample size before apply threshold:  131\n",
      "Counter({'0000-0003-1241-5441': 66, '0000-0002-4005-7330': 38, '0000-0002-7437-123X': 16, '0000-0003-0569-3398': 4, '0000-0001-8449-4973': 4, '0000-0001-8653-2734': 3})\n",
      "['0000-0003-1241-5441', '0000-0002-7437-123X', '0000-0002-4005-7330']\n",
      "Total sample size after apply threshold:  120\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(120, 329)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "120\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        66\n",
      "          1       1.00      0.19      0.32        16\n",
      "          2       1.00      0.79      0.88        38\n",
      "\n",
      "avg / total       0.87      0.82      0.80       120\n",
      "\n",
      "[66  0  0 13  3  0  8  0 30]\n",
      "MNB Accuracy:  0.825\n",
      "MNB F1:  0.6869625042999656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        66\n",
      "          1       1.00      0.75      0.86        16\n",
      "          2       1.00      0.79      0.88        38\n",
      "\n",
      "avg / total       0.92      0.90      0.90       120\n",
      "\n",
      "[66  0  0  4 12  0  8  0 30]\n",
      "svc Accuracy:  0.9\n",
      "svc F1:  0.8853874883286648\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82        66\n",
      "          1       1.00      0.12      0.22        16\n",
      "          2       1.00      0.63      0.77        38\n",
      "\n",
      "avg / total       0.84      0.77      0.73       120\n",
      "\n",
      "[66  0  0 14  2  0 14  0 24]\n",
      "LR Accuracy:  0.7666666666666667\n",
      "LR F1:  0.6071385902031062\n",
      "For name:  h_chen\n",
      "total sample size before apply threshold:  986\n",
      "Counter({'0000-0001-5108-8338': 147, '0000-0002-5799-6705': 93, '0000-0003-0708-6073': 73, '0000-0001-6758-1995': 49, '0000-0001-5051-9896': 40, '0000-0003-0676-4610': 40, '0000-0002-7748-4440': 39, '0000-0001-6883-3752': 36, '0000-0003-3191-0093': 28, '0000-0002-0753-6161': 25, '0000-0002-5958-9361': 24, '0000-0001-9751-5729': 22, '0000-0002-3319-5743': 21, '0000-0001-5972-2778': 20, '0000-0001-9477-5541': 20, '0000-0002-7823-3272': 19, '0000-0003-1158-5510': 19, '0000-0003-4876-634X': 18, '0000-0002-7480-9940': 16, '0000-0003-2014-7571': 16, '0000-0002-9510-4923': 15, '0000-0002-4074-5838': 15, '0000-0003-4053-7147': 14, '0000-0002-9835-5138': 12, '0000-0001-6208-1481': 12, '0000-0003-1663-1598': 10, '0000-0001-7897-9851': 9, '0000-0003-0676-3079': 9, '0000-0002-4292-0441': 9, '0000-0001-6315-9850': 8, '0000-0002-3800-5013': 8, '0000-0002-3722-5399': 8, '0000-0002-5037-4559': 7, '0000-0002-0595-3420': 7, '0000-0002-8795-1911': 6, '0000-0003-4060-9489': 6, '0000-0001-7900-3391': 6, '0000-0002-2883-4627': 5, '0000-0002-0310-0088': 5, '0000-0002-7516-9092': 4, '0000-0003-3111-9824': 4, '0000-0003-1997-5476': 3, '0000-0002-5498-5621': 3, '0000-0002-9330-5473': 3, '0000-0002-5905-8050': 2, '0000-0002-1724-8649': 2, '0000-0003-1211-3259': 2, '0000-0001-9998-1205': 2, '0000-0001-9644-8202': 2, '0000-0002-5662-5945': 2, '0000-0001-7775-8571': 1, '0000-0001-6260-1117': 1, '0000-0002-5266-9975': 1, '0000-0002-6181-5292': 1, '0000-0003-2117-7385': 1, '0000-0002-1124-0312': 1, '0000-0002-4796-8452': 1, '0000-0001-8234-1535': 1, '0000-0001-6171-1162': 1, '0000-0002-2456-5271': 1, '0000-0002-4242-216X': 1, '0000-0002-8400-3780': 1, '0000-0002-0978-1806': 1, '0000-0002-9840-4876': 1, '0000-0001-6524-1292': 1, '0000-0002-5378-2697': 1, '0000-0003-1613-468X': 1, '0000-0002-0457-9895': 1, '0000-0002-2121-1822': 1, '0000-0002-4425-3128': 1, '0000-0002-7431-6046': 1})\n",
      "['0000-0002-7480-9940', '0000-0001-5972-2778', '0000-0003-4876-634X', '0000-0002-9835-5138', '0000-0002-7748-4440', '0000-0001-6883-3752', '0000-0001-9477-5541', '0000-0002-0753-6161', '0000-0003-1663-1598', '0000-0002-7823-3272', '0000-0003-3191-0093', '0000-0001-5051-9896', '0000-0003-0708-6073', '0000-0003-0676-4610', '0000-0002-9510-4923', '0000-0002-5799-6705', '0000-0003-4053-7147', '0000-0001-6208-1481', '0000-0001-5108-8338', '0000-0003-2014-7571', '0000-0002-3319-5743', '0000-0002-4074-5838', '0000-0002-5958-9361', '0000-0001-6758-1995', '0000-0001-9751-5729', '0000-0003-1158-5510']\n",
      "Total sample size after apply threshold:  843\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(843, 1655)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "843\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.00      0.00      0.00        20\n",
      "          2       0.00      0.00      0.00        18\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.96      0.59      0.73        39\n",
      "          5       1.00      0.69      0.82        36\n",
      "          6       0.00      0.00      0.00        20\n",
      "          7       0.00      0.00      0.00        25\n",
      "          8       0.00      0.00      0.00        10\n",
      "          9       1.00      0.05      0.10        19\n",
      "         10       0.00      0.00      0.00        28\n",
      "         11       1.00      0.40      0.57        40\n",
      "         12       0.90      0.71      0.79        73\n",
      "         13       1.00      0.25      0.40        40\n",
      "         14       1.00      0.20      0.33        15\n",
      "         15       0.41      0.86      0.55        93\n",
      "         16       0.00      0.00      0.00        14\n",
      "         17       0.00      0.00      0.00        12\n",
      "         18       0.33      1.00      0.49       147\n",
      "         19       0.00      0.00      0.00        16\n",
      "         20       1.00      0.52      0.69        21\n",
      "         21       0.00      0.00      0.00        15\n",
      "         22       1.00      0.21      0.34        24\n",
      "         23       0.98      0.90      0.94        49\n",
      "         24       0.00      0.00      0.00        22\n",
      "         25       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.51      0.49      0.42       843\n",
      "\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   3   0   0\n",
      "  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  14   0   0   6   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   2   0   0   5   0   0  11   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  12   0   0   0   0   0   0   0   0   0   0   0\n",
      "  23   0   0   0   0   0   0   0   0   0   0   7   0   0   9   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  11   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  20   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15\n",
      "   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0   0   9   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   6   0   0\n",
      "  12   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "   0   0   0   0   0  25   0   0   2   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  16   0   0   0  12   0   0  12   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  52   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   1  10   0   0   0   0  29   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   3   2   0   0   9   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  80   0   0  13   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 147   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  16   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0\n",
      "  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  12   0   0   3   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  19   0   0   0\n",
      "   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   5   0   0   0   0  44   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  13   0   0   9   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1\n",
      "   0   0  17   0   0   0   0   0   0   0]\n",
      "MNB Accuracy:  0.49466192170818507\n",
      "MNB F1:  0.26015021166958185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.44      0.47        16\n",
      "          1       0.61      0.70      0.65        20\n",
      "          2       0.85      0.61      0.71        18\n",
      "          3       1.00      0.58      0.74        12\n",
      "          4       0.94      0.79      0.86        39\n",
      "          5       1.00      0.89      0.94        36\n",
      "          6       0.91      0.50      0.65        20\n",
      "          7       0.54      0.60      0.57        25\n",
      "          8       1.00      0.20      0.33        10\n",
      "          9       0.89      0.89      0.89        19\n",
      "         10       0.67      0.57      0.62        28\n",
      "         11       0.70      0.70      0.70        40\n",
      "         12       0.93      0.93      0.93        73\n",
      "         13       0.89      0.85      0.87        40\n",
      "         14       1.00      0.73      0.85        15\n",
      "         15       0.58      0.83      0.68        93\n",
      "         16       0.92      0.86      0.89        14\n",
      "         17       0.90      0.75      0.82        12\n",
      "         18       0.76      0.98      0.85       147\n",
      "         19       1.00      0.81      0.90        16\n",
      "         20       1.00      0.95      0.98        21\n",
      "         21       0.80      0.53      0.64        15\n",
      "         22       1.00      0.88      0.93        24\n",
      "         23       1.00      0.94      0.97        49\n",
      "         24       0.75      0.27      0.40        22\n",
      "         25       1.00      0.58      0.73        19\n",
      "\n",
      "avg / total       0.82      0.79      0.79       843\n",
      "\n",
      "[  7   0   0   0   0   0   0   3   0   0   0   1   0   0   0   3   0   0\n",
      "   2   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0\n",
      "   1   2   0   0   0   3   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "  11   0   0   0   0   0   0   0   0   0   1   0   0   4   0   0   1   0\n",
      "   0   0   0   0   0   0   0   0   0   7   0   0   0   0   0   0   0   0\n",
      "   0   0   0   1   0   0   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "  31   0   0   3   0   0   1   1   0   0   0   2   0   0   1   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  32   0   0   0   0   0   0   0   0\n",
      "   0   2   0   0   2   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "  10   0   0   0   0   0   0   0   0   2   1   0   6   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  15   0   0   0   4   0   0   0   5\n",
      "   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "   2   0   0   0   0   0   0   4   0   0   4   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0  17   0   0   0   0   0   1   0   0\n",
      "   0   0   0   0   0   0   0   0   0   2   1   0   1   0   0   0   0   0\n",
      "  16   0   0   0   0   8   0   0   0   0   0   0   0   0   0   0   1   1\n",
      "   0   0   1   0   0   1   0   1   1  28   0   0   0   6   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  68   2   0   0   0   0   3   0   0   0   0   0   0   0   0   1   0   0\n",
      "   0   0   0   0   0   0   0   0   1  34   0   0   0   1   3   0   0   0\n",
      "   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  11   1   0   0   2   0   0   0   0   0   0   0   2   2   1   0   0   0\n",
      "   0   1   0   0   3   2   0   0   0  77   0   0   2   0   0   2   0   0\n",
      "   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  12   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   0   9   2   0   0   0   0   0   0   0\n",
      "   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   0\n",
      " 144   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   1   0   0   2  13   0   0   0   0   0   0   1   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  20   0   0   0   0   0   1   1   0   0   0   0   0   1   0   0   1   0\n",
      "   0   0   0   2   0   0   1   0   0   8   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   1   0   0   2   0   0   0\n",
      "  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "   0   1   0   0   1   0   0   0   0  46   0   0   0   0   0   0   0   0\n",
      "   0   3   0   1   1   2   0   0   0   8   0   0   1   0   0   0   0   0\n",
      "   6   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0\n",
      "   0   0   5   0   0   0   0   0   0  11]\n",
      "svc Accuracy:  0.7947805456702254\n",
      "svc F1:  0.752349276549096\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.58      0.55      0.56        20\n",
      "          2       0.71      0.28      0.40        18\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       0.87      0.85      0.86        39\n",
      "          5       1.00      0.81      0.89        36\n",
      "          6       1.00      0.30      0.46        20\n",
      "          7       0.67      0.40      0.50        25\n",
      "          8       0.00      0.00      0.00        10\n",
      "          9       0.89      0.84      0.86        19\n",
      "         10       0.76      0.57      0.65        28\n",
      "         11       0.60      0.78      0.67        40\n",
      "         12       0.78      0.82      0.80        73\n",
      "         13       0.88      0.53      0.66        40\n",
      "         14       1.00      0.27      0.42        15\n",
      "         15       0.65      0.82      0.72        93\n",
      "         16       1.00      0.43      0.60        14\n",
      "         17       1.00      0.42      0.59        12\n",
      "         18       0.51      0.99      0.67       147\n",
      "         19       1.00      0.56      0.72        16\n",
      "         20       0.95      0.86      0.90        21\n",
      "         21       0.71      0.33      0.45        15\n",
      "         22       1.00      0.83      0.91        24\n",
      "         23       1.00      0.94      0.97        49\n",
      "         24       1.00      0.18      0.31        22\n",
      "         25       0.80      0.42      0.55        19\n",
      "\n",
      "avg / total       0.75      0.70      0.68       843\n",
      "\n",
      "[  0   0   0   0   0   0   0   2   0   0   0   3   1   0   0   2   0   0\n",
      "   7   0   1   0   0   0   0   0   0  11   0   0   0   0   0   0   0   0\n",
      "   0   2   0   0   0   6   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "   5   0   0   0   0   0   0   0   0   1   2   0   0   5   0   0   5   0\n",
      "   0   0   0   0   0   0   0   0   0   6   0   0   0   0   0   0   0   0\n",
      "   0   0   0   1   0   0   5   0   0   0   0   0   0   0   0   0   0   0\n",
      "  33   0   0   0   0   0   0   3   0   0   0   2   0   0   1   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  29   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   6   0   0   0   0   0   1   0   0   0   0   0  11   0   0   0   0   0\n",
      "   0   2   0   0   0   0   1   0   0  10   0   0   1   5   0   0   0   4\n",
      "   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1   0   0   9   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  16   0   0   1   0   0   0   0   0\n",
      "   2   0   0   0   0   0   0   0   0   2   1   0   2   0   0   0   0   0\n",
      "  16   0   0   0   0   5   0   0   2   0   0   0   0   0   0   0   0   1\n",
      "   0   0   2   0   0   0   0   1   0  31   0   0   0   4   0   0   1   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  60   1   0   0   0   0  12   0   0   0   0   0   0   0   0   1   0   0\n",
      "   0   0   0   0   0   0   0   0   4  21   0   0   0   0  14   0   0   0\n",
      "   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   4   0   0   0  10   0   0   0   0   0   0   0   0   2   1   0   0   0\n",
      "   0   0   0   0   2   3   0   0   0  76   0   0   7   0   0   2   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "   6   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   2   1   0   0   0   5   4   0   0   0   0   0   0   0\n",
      "   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
      " 145   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   7   9   0   0   0   0   0   0   1   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
      "  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2\n",
      "   0   0   0   6   0   0   2   0   0   5   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0\n",
      "  20   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "   0   0   0   0   2   0   0   0   0  46   0   0   0   0   0   0   0   0\n",
      "   0   3   0   1   2   2   0   0   0   5   0   0   5   0   0   0   0   0\n",
      "   4   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0\n",
      "   0   0   7   0   0   0   0   0   0   8]\n",
      "LR Accuracy:  0.6998813760379596\n",
      "LR F1:  0.6080322034861434\n",
      "For name:  c_huang\n",
      "total sample size before apply threshold:  425\n",
      "Counter({'0000-0002-6557-211X': 117, '0000-0002-5234-4986': 48, '0000-0001-5357-0451': 36, '0000-0001-9521-5650': 33, '0000-0002-5824-3318': 17, '0000-0002-1486-741X': 15, '0000-0002-1956-6229': 14, '0000-0003-1019-784X': 14, '0000-0001-9993-8004': 13, '0000-0001-8736-9545': 10, '0000-0002-0266-3233': 9, '0000-0002-4390-6502': 9, '0000-0002-1941-1200': 8, '0000-0001-6052-0663': 8, '0000-0002-4704-548X': 8, '0000-0002-8062-8708': 8, '0000-0001-6946-2105': 7, '0000-0002-9174-7542': 7, '0000-0002-9769-8075': 5, '0000-0003-4187-2967': 4, '0000-0002-9020-305X': 4, '0000-0003-2981-4537': 4, '0000-0003-3905-8915': 3, '0000-0003-3331-181X': 2, '0000-0001-5958-5849': 2, '0000-0003-3445-4353': 2, '0000-0001-7266-3610': 2, '0000-0003-4378-4776': 2, '0000-0002-2921-4294': 2, '0000-0001-7865-1020': 1, '0000-0001-9824-5716': 1, '0000-0001-7392-6363': 1, '0000-0002-1366-5170': 1, '0000-0002-0425-8311': 1, '0000-0002-4803-1477': 1, '0000-0002-0972-6444': 1, '0000-0001-5179-0872': 1, '0000-0003-1446-6787': 1, '0000-0003-3527-2789': 1, '0000-0002-6987-0536': 1, '0000-0003-0055-9798': 1})\n",
      "['0000-0001-5357-0451', '0000-0001-9993-8004', '0000-0001-8736-9545', '0000-0002-1486-741X', '0000-0002-6557-211X', '0000-0002-5234-4986', '0000-0002-5824-3318', '0000-0002-1956-6229', '0000-0003-1019-784X', '0000-0001-9521-5650']\n",
      "Total sample size after apply threshold:  317\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(317, 636)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.24        36\n",
      "          1       1.00      0.38      0.56        13\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       1.00      0.13      0.24        15\n",
      "          4       0.45      0.98      0.62       117\n",
      "          5       0.88      0.44      0.58        48\n",
      "          6       1.00      0.06      0.11        17\n",
      "          7       0.00      0.00      0.00        14\n",
      "          8       0.00      0.00      0.00        14\n",
      "          9       1.00      0.79      0.88        33\n",
      "\n",
      "avg / total       0.66      0.55      0.48       317\n",
      "\n",
      "[  5   0   0   0  30   1   0   0   0   0   0   5   0   0   8   0   0   0\n",
      "   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   2  13   0\n",
      "   0   0   0   0   0   0   0   0 115   2   0   0   0   0   0   0   0   0\n",
      "  27  21   0   0   0   0   0   0   0   0  16   0   1   0   0   0   0   0\n",
      "   0   0  14   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0\n",
      "   0   0   0   0   7   0   0   0   0  26]\n",
      "MNB Accuracy:  0.5520504731861199\n",
      "MNB F1:  0.3230498580519044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.81      0.76        36\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       1.00      0.80      0.89        10\n",
      "          3       1.00      0.80      0.89        15\n",
      "          4       0.77      0.96      0.85       117\n",
      "          5       0.91      0.81      0.86        48\n",
      "          6       0.86      0.35      0.50        17\n",
      "          7       0.78      1.00      0.88        14\n",
      "          8       1.00      0.29      0.44        14\n",
      "          9       0.96      0.79      0.87        33\n",
      "\n",
      "avg / total       0.85      0.83      0.82       317\n",
      "\n",
      "[ 29   0   0   0   7   0   0   0   0   0   0  12   0   0   1   0   0   0\n",
      "   0   0   0   0   8   0   1   0   1   0   0   0   0   0   0  12   1   0\n",
      "   0   1   0   1   4   0   0   0 112   1   0   0   0   0   2   0   0   0\n",
      "   7  39   0   0   0   0   2   0   0   0   7   2   6   0   0   0   0   0\n",
      "   0   0   0   0   0  14   0   0   3   0   0   0   6   1   0   0   4   0\n",
      "   0   0   0   0   4   0   0   3   0  26]\n",
      "svc Accuracy:  0.8264984227129337\n",
      "svc F1:  0.7895900667384558\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.58      0.68        36\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       1.00      0.50      0.67        10\n",
      "          3       1.00      0.67      0.80        15\n",
      "          4       0.62      0.98      0.76       117\n",
      "          5       0.85      0.71      0.77        48\n",
      "          6       1.00      0.29      0.45        17\n",
      "          7       0.85      0.79      0.81        14\n",
      "          8       0.00      0.00      0.00        14\n",
      "          9       1.00      0.76      0.86        33\n",
      "\n",
      "avg / total       0.76      0.74      0.72       317\n",
      "\n",
      "[ 21   0   0   0  13   2   0   0   0   0   0   8   0   0   5   0   0   0\n",
      "   0   0   0   0   5   0   5   0   0   0   0   0   0   0   0  10   4   0\n",
      "   0   1   0   0   0   0   0   0 115   2   0   0   0   0   1   0   0   0\n",
      "  13  34   0   0   0   0   2   0   0   0   9   1   5   0   0   0   0   0\n",
      "   0   0   3   0   0  11   0   0   2   0   0   0  11   1   0   0   0   0\n",
      "   0   0   0   0   7   0   0   1   0  25]\n",
      "LR Accuracy:  0.7381703470031545\n",
      "LR F1:  0.6571736694988431\n",
      "For name:  s_chong\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0001-8062-7281': 24, '0000-0002-3095-875X': 12, '0000-0002-8854-9529': 2, '0000-0003-3054-9275': 1, '0000-0002-3627-4025': 1})\n",
      "['0000-0001-8062-7281', '0000-0002-3095-875X']\n",
      "Total sample size after apply threshold:  36\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 157)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        24\n",
      "          1       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.93      0.92      0.91        36\n",
      "\n",
      "[24  0  3  9]\n",
      "MNB Accuracy:  0.9166666666666666\n",
      "MNB F1:  0.8991596638655461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        24\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[24  0  1 11]\n",
      "svc Accuracy:  0.9722222222222222\n",
      "svc F1:  0.9680567879325643\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        24\n",
      "          1       1.00      0.58      0.74        12\n",
      "\n",
      "avg / total       0.89      0.86      0.85        36\n",
      "\n",
      "[24  0  5  7]\n",
      "LR Accuracy:  0.8611111111111112\n",
      "LR F1:  0.8212512413108242\n",
      "For name:  z_wu\n",
      "total sample size before apply threshold:  221\n",
      "Counter({'0000-0003-0807-7195': 52, '0000-0002-9596-9134': 35, '0000-0002-2982-2177': 31, '0000-0002-4468-3240': 25, '0000-0002-0708-6770': 14, '0000-0002-4004-9728': 11, '0000-0002-3719-406X': 9, '0000-0002-6424-6777': 8, '0000-0003-1660-0724': 6, '0000-0002-1824-9563': 5, '0000-0002-2463-242X': 5, '0000-0003-2009-991X': 5, '0000-0002-9383-1270': 4, '0000-0002-4739-1139': 4, '0000-0003-4460-9785': 3, '0000-0002-9774-7770': 2, '0000-0002-7776-563X': 1, '0000-0002-8687-0466': 1})\n",
      "['0000-0002-4004-9728', '0000-0002-0708-6770', '0000-0002-9596-9134', '0000-0003-0807-7195', '0000-0002-4468-3240', '0000-0002-2982-2177']\n",
      "Total sample size after apply threshold:  168\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(168, 318)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "168\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        11\n",
      "          1       1.00      0.93      0.96        14\n",
      "          2       0.96      0.77      0.86        35\n",
      "          3       0.76      1.00      0.87        52\n",
      "          4       0.75      0.48      0.59        25\n",
      "          5       0.74      0.94      0.83        31\n",
      "\n",
      "avg / total       0.84      0.82      0.80       168\n",
      "\n",
      "[ 4  0  0  2  4  1  0 13  0  0  0  1  0  0 27  5  0  3  0  0  0 52  0  0\n",
      "  0  0  1  7 12  5  0  0  0  2  0 29]\n",
      "MNB Accuracy:  0.8154761904761905\n",
      "MNB F1:  0.7723405170559642\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.73      0.80        11\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       0.71      0.97      0.82        35\n",
      "          3       1.00      0.94      0.97        52\n",
      "          4       0.84      0.64      0.73        25\n",
      "          5       0.97      0.90      0.93        31\n",
      "\n",
      "avg / total       0.90      0.89      0.89       168\n",
      "\n",
      "[ 8  0  0  0  3  0  0 14  0  0  0  0  0  0 34  0  0  1  0  0  3 49  0  0\n",
      "  1  0  8  0 16  0  0  0  3  0  0 28]\n",
      "svc Accuracy:  0.8869047619047619\n",
      "svc F1:  0.8750300331237942\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.93      1.00      0.97        14\n",
      "          2       0.78      0.83      0.81        35\n",
      "          3       0.75      1.00      0.86        52\n",
      "          4       0.92      0.48      0.63        25\n",
      "          5       0.92      0.77      0.84        31\n",
      "\n",
      "avg / total       0.85      0.83      0.82       168\n",
      "\n",
      "[ 8  0  0  2  1  0  0 14  0  0  0  0  0  0 29  4  0  2  0  0  0 52  0  0\n",
      "  0  0  5  8 12  0  0  1  3  3  0 24]\n",
      "LR Accuracy:  0.8273809523809523\n",
      "LR F1:  0.8243944004750802\n",
      "For name:  m_swamy\n",
      "total sample size before apply threshold:  134\n",
      "Counter({'0000-0002-3108-3633': 96, '0000-0003-3977-3425': 25, '0000-0002-8084-5534': 9, '0000-0002-7834-7480': 4})\n",
      "['0000-0002-3108-3633', '0000-0003-3977-3425']\n",
      "Total sample size after apply threshold:  121\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(121, 215)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "121\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        96\n",
      "          1       1.00      0.72      0.84        25\n",
      "\n",
      "avg / total       0.95      0.94      0.94       121\n",
      "\n",
      "[96  0  7 18]\n",
      "MNB Accuracy:  0.9421487603305785\n",
      "MNB F1:  0.9010167114642982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        96\n",
      "          1       1.00      0.80      0.89        25\n",
      "\n",
      "avg / total       0.96      0.96      0.96       121\n",
      "\n",
      "[96  0  5 20]\n",
      "svc Accuracy:  0.9586776859504132\n",
      "svc F1:  0.9317540891144952\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        96\n",
      "          1       1.00      0.32      0.48        25\n",
      "\n",
      "avg / total       0.88      0.86      0.83       121\n",
      "\n",
      "[96  0 17  8]\n",
      "LR Accuracy:  0.859504132231405\n",
      "LR F1:  0.7017543859649122\n",
      "For name:  k_nomura\n",
      "total sample size before apply threshold:  38\n",
      "Counter({'0000-0003-3661-6328': 32, '0000-0002-6425-4574': 3, '0000-0003-0625-1778': 1, '0000-0002-5912-074X': 1, '0000-0001-7891-9795': 1})\n",
      "['0000-0003-3661-6328']\n",
      "Total sample size after apply threshold:  32\n",
      "For name:  m_wu\n",
      "total sample size before apply threshold:  658\n",
      "Counter({'0000-0002-1940-6428': 219, '0000-0002-7074-8087': 194, '0000-0002-1674-443X': 56, '0000-0003-3327-828X': 42, '0000-0001-6587-7055': 33, '0000-0002-8811-9203': 29, '0000-0002-7509-1643': 22, '0000-0003-2045-9372': 13, '0000-0002-9161-7940': 11, '0000-0003-3712-1554': 10, '0000-0001-7672-9357': 6, '0000-0003-2113-0245': 5, '0000-0001-6847-7065': 5, '0000-0003-0977-3600': 4, '0000-0003-1372-4764': 2, '0000-0003-1734-7994': 2, '0000-0002-3269-1681': 2, '0000-0002-0183-0490': 1, '0000-0001-6646-050X': 1, '0000-0002-6646-951X': 1})\n",
      "['0000-0002-8811-9203', '0000-0001-6587-7055', '0000-0002-9161-7940', '0000-0003-3712-1554', '0000-0003-3327-828X', '0000-0003-2045-9372', '0000-0002-7509-1643', '0000-0002-1674-443X', '0000-0002-1940-6428', '0000-0002-7074-8087']\n",
      "Total sample size after apply threshold:  629\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(629, 320)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        29\n",
      "          1       0.95      0.55      0.69        33\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.94      0.38      0.54        42\n",
      "          5       1.00      0.08      0.14        13\n",
      "          6       0.00      0.00      0.00        22\n",
      "          7       0.50      0.07      0.12        56\n",
      "          8       0.62      0.91      0.74       219\n",
      "          9       0.63      0.86      0.73       194\n",
      "\n",
      "avg / total       0.59      0.64      0.57       629\n",
      "\n",
      "[  0   0   0   0   0   0   0   0  22   7   0  18   0   0   0   0   0   0\n",
      "  13   2   0   0   0   0   0   0   0   1   2   8   0   0   0   0   0   0\n",
      "   0   0   1   9   0   0   0   0  16   0   0   0  15  11   0   0   0   0\n",
      "   0   1   0   1   4   7   0   0   0   0   0   0   0   0  15   7   0   1\n",
      "   0   0   0   0   0   4  22  29   0   0   0   0   0   0   0   2 199  18\n",
      "   0   0   0   0   1   0   0   0  26 167]\n",
      "MNB Accuracy:  0.643879173290938\n",
      "MNB F1:  0.29699835135095337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.13        29\n",
      "          1       1.00      0.88      0.94        33\n",
      "          2       1.00      0.55      0.71        11\n",
      "          3       1.00      0.90      0.95        10\n",
      "          4       0.81      0.69      0.74        42\n",
      "          5       0.91      0.77      0.83        13\n",
      "          6       0.67      0.18      0.29        22\n",
      "          7       0.83      0.77      0.80        56\n",
      "          8       0.76      0.90      0.82       219\n",
      "          9       0.76      0.85      0.80       194\n",
      "\n",
      "avg / total       0.80      0.79      0.76       629\n",
      "\n",
      "[  2   0   0   0   0   0   0   3  18   6   0  29   0   0   1   0   0   1\n",
      "   1   1   0   0   6   0   0   0   0   0   0   5   0   0   0   9   0   0\n",
      "   0   0   0   1   0   0   0   0  29   0   0   0   4   9   0   0   0   0\n",
      "   0  10   0   0   1   2   0   0   0   0   1   0   4   1  12   4   0   0\n",
      "   0   0   1   1   1  43   5   5   0   0   0   0   1   0   0   1 198  19\n",
      "   0   0   0   0   3   0   1   3  23 164]\n",
      "svc Accuracy:  0.7853736089030207\n",
      "svc F1:  0.6999985385244548\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        29\n",
      "          1       0.97      0.88      0.92        33\n",
      "          2       1.00      0.09      0.17        11\n",
      "          3       1.00      0.30      0.46        10\n",
      "          4       0.85      0.55      0.67        42\n",
      "          5       1.00      0.77      0.87        13\n",
      "          6       0.00      0.00      0.00        22\n",
      "          7       0.90      0.68      0.78        56\n",
      "          8       0.72      0.90      0.80       219\n",
      "          9       0.70      0.87      0.77       194\n",
      "\n",
      "avg / total       0.71      0.75      0.71       629\n",
      "\n",
      "[  0   0   0   0   0   0   0   1  22   6   0  29   0   0   0   0   0   1\n",
      "   2   1   0   0   1   0   0   0   0   0   0  10   0   0   0   3   0   0\n",
      "   0   0   0   7   0   0   0   0  23   0   0   0   8  11   0   0   0   0\n",
      "   0  10   0   0   2   1   0   0   0   0   1   0   0   1  12   8   0   1\n",
      "   0   0   1   0   0  38   8   8   0   0   0   0   0   0   0   1 197  21\n",
      "   0   0   0   0   2   0   1   0  23 168]\n",
      "LR Accuracy:  0.7456279809220986\n",
      "LR F1:  0.5432184571056731\n",
      "For name:  e_lee\n",
      "total sample size before apply threshold:  300\n",
      "Counter({'0000-0003-0232-7704': 81, '0000-0003-0418-1454': 48, '0000-0001-7494-1776': 48, '0000-0003-1255-9808': 40, '0000-0001-7188-3857': 29, '0000-0002-6369-7429': 16, '0000-0001-9670-3242': 10, '0000-0001-8131-6872': 8, '0000-0001-5144-2552': 3, '0000-0003-4725-4959': 3, '0000-0001-6506-4150': 3, '0000-0003-2848-7298': 2, '0000-0001-9580-8974': 2, '0000-0002-3156-2036': 1, '0000-0002-4156-9637': 1, '0000-0002-4513-9888': 1, '0000-0001-5816-2449': 1, '0000-0002-0934-3187': 1, '0000-0002-2674-912X': 1, '0000-0001-7976-5724': 1})\n",
      "['0000-0001-9670-3242', '0000-0003-1255-9808', '0000-0003-0418-1454', '0000-0002-6369-7429', '0000-0001-7494-1776', '0000-0001-7188-3857', '0000-0003-0232-7704']\n",
      "Total sample size after apply threshold:  272\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(272, 452)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "272\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.90      0.95        40\n",
      "          2       1.00      0.71      0.83        48\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.75      0.56      0.64        48\n",
      "          5       0.00      0.00      0.00        29\n",
      "          6       0.48      0.99      0.65        81\n",
      "\n",
      "avg / total       0.60      0.65      0.59       272\n",
      "\n",
      "[ 0  0  0  0  0  0 10  0 36  0  0  1  0  3  0  0 34  0  1  0 13  0  0  0\n",
      "  0  0  0 16  0  0  0  0 27  0 21  0  0  0  0  6  0 23  0  0  0  0  1  0\n",
      " 80]\n",
      "MNB Accuracy:  0.6507352941176471\n",
      "MNB F1:  0.438181019420704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       1.00      0.95      0.97        40\n",
      "          2       0.73      0.92      0.81        48\n",
      "          3       0.82      0.56      0.67        16\n",
      "          4       0.61      0.73      0.67        48\n",
      "          5       0.50      0.24      0.33        29\n",
      "          6       0.81      0.85      0.83        81\n",
      "\n",
      "avg / total       0.76      0.77      0.76       272\n",
      "\n",
      "[ 7  0  3  0  0  0  0  0 38  2  0  0  0  0  0  0 44  0  0  1  3  0  0  0\n",
      "  9  3  0  4  0  0  1  1 35  6  5  0  0  7  1 10  7  4  0  0  3  0  9  0\n",
      " 69]\n",
      "svc Accuracy:  0.7683823529411765\n",
      "svc F1:  0.7289918901179263\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       1.00      0.93      0.96        40\n",
      "          2       0.65      0.92      0.76        48\n",
      "          3       0.86      0.38      0.52        16\n",
      "          4       0.65      0.71      0.68        48\n",
      "          5       0.33      0.07      0.11        29\n",
      "          6       0.73      0.89      0.80        81\n",
      "\n",
      "avg / total       0.72      0.73      0.69       272\n",
      "\n",
      "[ 3  0  7  0  0  0  0  0 37  3  0  0  0  0  0  0 44  0  0  0  4  0  0  0\n",
      "  6  2  1  7  0  0  4  0 34  3  7  0  0  8  1  9  2  9  0  0  2  0  7  0\n",
      " 72]\n",
      "LR Accuracy:  0.7279411764705882\n",
      "LR F1:  0.6138889938504416\n",
      "For name:  j_weber\n",
      "total sample size before apply threshold:  146\n",
      "Counter({'0000-0003-2218-2952': 37, '0000-0002-5493-5886': 34, '0000-0002-2799-7352': 29, '0000-0001-9062-3591': 17, '0000-0002-6835-5065': 16, '0000-0001-5817-0975': 10, '0000-0003-3758-1569': 3})\n",
      "['0000-0002-5493-5886', '0000-0001-9062-3591', '0000-0002-2799-7352', '0000-0001-5817-0975', '0000-0003-2218-2952', '0000-0002-6835-5065']\n",
      "Total sample size after apply threshold:  143\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(143, 434)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92        34\n",
      "          1       1.00      0.41      0.58        17\n",
      "          2       1.00      0.79      0.88        29\n",
      "          3       1.00      0.40      0.57        10\n",
      "          4       0.51      0.95      0.66        37\n",
      "          5       1.00      0.12      0.22        16\n",
      "\n",
      "avg / total       0.84      0.73      0.70       143\n",
      "\n",
      "[33  0  0  0  1  0  0  7  0  0 10  0  0  0 23  0  6  0  0  0  0  4  6  0\n",
      "  2  0  0  0 35  0  3  0  0  0 11  2]\n",
      "MNB Accuracy:  0.7272727272727273\n",
      "MNB F1:  0.6397739227927908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        34\n",
      "          1       1.00      0.65      0.79        17\n",
      "          2       1.00      0.83      0.91        29\n",
      "          3       1.00      0.60      0.75        10\n",
      "          4       0.61      1.00      0.76        37\n",
      "          5       1.00      0.50      0.67        16\n",
      "\n",
      "avg / total       0.90      0.83      0.83       143\n",
      "\n",
      "[33  0  0  0  1  0  0 11  0  0  6  0  0  0 24  0  5  0  0  0  0  6  4  0\n",
      "  0  0  0  0 37  0  0  0  0  0  8  8]\n",
      "svc Accuracy:  0.8321678321678322\n",
      "svc F1:  0.8080363329035736\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        34\n",
      "          1       1.00      0.35      0.52        17\n",
      "          2       1.00      0.79      0.88        29\n",
      "          3       1.00      0.60      0.75        10\n",
      "          4       0.51      1.00      0.68        37\n",
      "          5       1.00      0.19      0.32        16\n",
      "\n",
      "avg / total       0.87      0.76      0.74       143\n",
      "\n",
      "[33  0  0  0  1  0  0  6  0  0 11  0  0  0 23  0  6  0  0  0  0  6  4  0\n",
      "  0  0  0  0 37  0  0  0  0  0 13  3]\n",
      "LR Accuracy:  0.7552447552447552\n",
      "LR F1:  0.6893529496948094\n",
      "For name:  c_fox\n",
      "total sample size before apply threshold:  102\n",
      "Counter({'0000-0001-9480-5704': 54, '0000-0002-4644-2619': 35, '0000-0001-6934-3624': 11, '0000-0002-9278-1777': 2})\n",
      "['0000-0001-9480-5704', '0000-0002-4644-2619', '0000-0001-6934-3624']\n",
      "Total sample size after apply threshold:  100\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 292)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "100\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.89        54\n",
      "          1       1.00      0.86      0.92        35\n",
      "          2       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.89      0.86      0.83       100\n",
      "\n",
      "[54  0  0  5 30  0  9  0  2]\n",
      "MNB Accuracy:  0.86\n",
      "MNB F1:  0.7053383774695249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        54\n",
      "          1       1.00      0.80      0.89        35\n",
      "          2       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.90      0.88      0.87       100\n",
      "\n",
      "[54  0  0  7 28  0  5  0  6]\n",
      "svc Accuracy:  0.88\n",
      "svc F1:  0.8315904139433551\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        54\n",
      "          1       1.00      0.77      0.87        35\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.75      0.81      0.76       100\n",
      "\n",
      "[54  0  0  8 27  0 11  0  0]\n",
      "LR Accuracy:  0.81\n",
      "LR F1:  0.5737871475742952\n",
      "For name:  s_thompson\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0003-0327-7155': 36, '0000-0003-4784-8386': 3, '0000-0001-9689-1490': 2, '0000-0001-9637-2041': 2, '0000-0002-6847-0397': 1, '0000-0002-0457-6926': 1})\n",
      "['0000-0003-0327-7155']\n",
      "Total sample size after apply threshold:  36\n",
      "For name:  b_choi\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-6090-869X': 12, '0000-0002-8657-7497': 4, '0000-0002-1461-9985': 3, '0000-0002-8381-336X': 1, '0000-0002-1412-9951': 1, '0000-0002-4984-5958': 1, '0000-0002-2950-2069': 1, '0000-0002-6561-8851': 1})\n",
      "['0000-0002-6090-869X']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  j_schwartz\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-6472-0184': 34, '0000-0001-8239-8857': 10, '0000-0003-2057-1831': 5, '0000-0001-5487-7260': 1, '0000-0001-9636-8181': 1})\n",
      "['0000-0002-6472-0184', '0000-0001-8239-8857']\n",
      "Total sample size after apply threshold:  44\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 144)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91        34\n",
      "          1       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.87      0.84      0.81        44\n",
      "\n",
      "[34  0  7  3]\n",
      "MNB Accuracy:  0.8409090909090909\n",
      "MNB F1:  0.6841025641025641\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        34\n",
      "          1       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.88      0.86      0.84        44\n",
      "\n",
      "[34  0  6  4]\n",
      "svc Accuracy:  0.8636363636363636\n",
      "svc F1:  0.7451737451737452\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        34\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.60      0.77      0.67        44\n",
      "\n",
      "[34  0 10  0]\n",
      "LR Accuracy:  0.7727272727272727\n",
      "LR F1:  0.4358974358974359\n",
      "For name:  a_brooks\n",
      "total sample size before apply threshold:  185\n",
      "Counter({'0000-0002-4085-9683': 134, '0000-0002-2691-1668': 19, '0000-0003-3551-6982': 14, '0000-0002-8486-4441': 9, '0000-0002-5309-7307': 6, '0000-0003-1334-6230': 3})\n",
      "['0000-0003-3551-6982', '0000-0002-4085-9683', '0000-0002-2691-1668']\n",
      "Total sample size after apply threshold:  167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(167, 539)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "167\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.83      1.00      0.91       134\n",
      "          2       1.00      0.26      0.42        19\n",
      "\n",
      "avg / total       0.78      0.83      0.77       167\n",
      "\n",
      "[  0  14   0   0 134   0   0  14   5]\n",
      "MNB Accuracy:  0.8323353293413174\n",
      "MNB F1:  0.44069069069069067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        14\n",
      "          1       0.89      1.00      0.94       134\n",
      "          2       1.00      0.58      0.73        19\n",
      "\n",
      "avg / total       0.91      0.90      0.88       167\n",
      "\n",
      "[  5   9   0   0 134   0   0   8  11]\n",
      "svc Accuracy:  0.8982035928143712\n",
      "svc F1:  0.7333333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.83      1.00      0.91       134\n",
      "          2       1.00      0.26      0.42        19\n",
      "\n",
      "avg / total       0.78      0.83      0.77       167\n",
      "\n",
      "[  0  14   0   0 134   0   0  14   5]\n",
      "LR Accuracy:  0.8323353293413174\n",
      "LR F1:  0.44069069069069067\n",
      "For name:  l_rocha\n",
      "total sample size before apply threshold:  81\n",
      "Counter({'0000-0001-9402-887X': 24, '0000-0002-4345-6994': 20, '0000-0002-5469-0911': 11, '0000-0001-7832-058X': 8, '0000-0001-8184-8801': 6, '0000-0003-2146-9708': 5, '0000-0002-7219-1518': 5, '0000-0002-5070-9013': 1, '0000-0002-5190-9279': 1})\n",
      "['0000-0002-5469-0911', '0000-0001-9402-887X', '0000-0002-4345-6994']\n",
      "Total sample size after apply threshold:  55\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(55, 169)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.86      1.00      0.92        24\n",
      "          2       0.95      0.90      0.92        20\n",
      "\n",
      "avg / total       0.92      0.91      0.91        55\n",
      "\n",
      "[ 8  2  1  0 24  0  0  2 18]\n",
      "MNB Accuracy:  0.9090909090909091\n",
      "MNB F1:  0.8960863697705803\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.89      1.00      0.94        24\n",
      "          2       1.00      0.90      0.95        20\n",
      "\n",
      "avg / total       0.95      0.95      0.95        55\n",
      "\n",
      "[10  1  0  0 24  0  0  2 18]\n",
      "svc Accuracy:  0.9454545454545454\n",
      "svc F1:  0.9469752813406064\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.83      1.00      0.91        24\n",
      "          2       0.94      0.85      0.89        20\n",
      "\n",
      "avg / total       0.90      0.89      0.89        55\n",
      "\n",
      "[ 8  2  1  0 24  0  0  3 17]\n",
      "LR Accuracy:  0.8909090909090909\n",
      "LR F1:  0.8808341608738829\n",
      "For name:  s_fleming\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0002-4095-9924': 12, '0000-0001-7205-2051': 11, '0000-0003-2223-3975': 6, '0000-0002-6242-8083': 4, '0000-0001-5385-7233': 2})\n",
      "['0000-0001-7205-2051', '0000-0002-4095-9924']\n",
      "Total sample size after apply threshold:  23"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 62)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "23\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.86      1.00      0.92        12\n",
      "\n",
      "avg / total       0.93      0.91      0.91        23\n",
      "\n",
      "[ 9  2  0 12]\n",
      "MNB Accuracy:  0.9130434782608695\n",
      "MNB F1:  0.9115384615384615\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        11\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        23\n",
      "\n",
      "[11  0  1 11]\n",
      "svc Accuracy:  0.9565217391304348\n",
      "svc F1:  0.9565217391304348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.82      0.86        11\n",
      "          1       0.85      0.92      0.88        12\n",
      "\n",
      "avg / total       0.87      0.87      0.87        23\n",
      "\n",
      "[ 9  2  1 11]\n",
      "LR Accuracy:  0.8695652173913043\n",
      "LR F1:  0.8685714285714285\n",
      "For name:  w_tsai\n",
      "total sample size before apply threshold:  113\n",
      "Counter({'0000-0002-2316-5751': 63, '0000-0003-1332-2650': 26, '0000-0002-9437-5131': 22, '0000-0002-4490-3581': 1, '0000-0002-1123-6954': 1})\n",
      "['0000-0003-1332-2650', '0000-0002-9437-5131', '0000-0002-2316-5751']\n",
      "Total sample size after apply threshold:  111\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 95)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82        26\n",
      "          1       1.00      0.77      0.87        22\n",
      "          2       0.83      1.00      0.91        63\n",
      "\n",
      "avg / total       0.90      0.88      0.88       111\n",
      "\n",
      "[18  0  8  0 17  5  0  0 63]\n",
      "MNB Accuracy:  0.8828828828828829\n",
      "MNB F1:  0.8654838367068582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.65      0.79        26\n",
      "          1       1.00      0.91      0.95        22\n",
      "          2       0.85      1.00      0.92        63\n",
      "\n",
      "avg / total       0.92      0.90      0.90       111\n",
      "\n",
      "[17  0  9  0 20  2  0  0 63]\n",
      "svc Accuracy:  0.9009009009009009\n",
      "svc F1:  0.8875955519988791\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.62      0.74        26\n",
      "          1       1.00      0.68      0.81        22\n",
      "          2       0.78      0.98      0.87        63\n",
      "\n",
      "avg / total       0.86      0.84      0.83       111\n",
      "\n",
      "[16  0 10  0 15  7  1  0 62]\n",
      "LR Accuracy:  0.8378378378378378\n",
      "LR F1:  0.809412097980719\n",
      "For name:  m_rodriguez\n",
      "total sample size before apply threshold:  214\n",
      "Counter({'0000-0001-6328-6497': 195, '0000-0001-8926-2987': 8, '0000-0002-9380-6614': 4, '0000-0002-4476-004X': 3, '0000-0001-6778-1663': 2, '0000-0002-4452-7627': 1, '0000-0002-2640-5888': 1})\n",
      "['0000-0001-6328-6497']\n",
      "Total sample size after apply threshold:  195\n",
      "For name:  r_miranda\n",
      "total sample size before apply threshold:  81\n",
      "Counter({'0000-0002-8467-5464': 69, '0000-0003-4798-314X': 7, '0000-0002-6551-9677': 4, '0000-0003-3222-7368': 1})\n",
      "['0000-0002-8467-5464']\n",
      "Total sample size after apply threshold:  69\n",
      "For name:  j_richardson\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0001-6521-610X': 70, '0000-0002-9429-151X': 9, '0000-0003-2733-9736': 3, '0000-0002-8895-8365': 2})\n",
      "['0000-0001-6521-610X']\n",
      "Total sample size after apply threshold:  70\n",
      "For name:  a_chin\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-0417-8653': 50, '0000-0002-0332-0048': 19, '0000-0002-8539-754X': 3, '0000-0003-1813-4042': 1})\n",
      "['0000-0002-0332-0048', '0000-0002-0417-8653']\n",
      "Total sample size after apply threshold:  69\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(69, 140)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        19\n",
      "          1       0.96      1.00      0.98        50\n",
      "\n",
      "avg / total       0.97      0.97      0.97        69\n",
      "\n",
      "[17  2  0 50]\n",
      "MNB Accuracy:  0.9710144927536232\n",
      "MNB F1:  0.9624183006535947\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        19\n",
      "          1       0.96      1.00      0.98        50\n",
      "\n",
      "avg / total       0.97      0.97      0.97        69\n",
      "\n",
      "[17  2  0 50]\n",
      "svc Accuracy:  0.9710144927536232\n",
      "svc F1:  0.9624183006535947\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.73        19\n",
      "          1       0.86      1.00      0.93        50\n",
      "\n",
      "avg / total       0.90      0.88      0.87        69\n",
      "\n",
      "[11  8  0 50]\n",
      "LR Accuracy:  0.8840579710144928\n",
      "LR F1:  0.8296296296296297\n",
      "For name:  h_madsen\n",
      "total sample size before apply threshold:  8\n",
      "Counter({'0000-0002-2498-8709': 3, '0000-0001-7103-5380': 3, '0000-0003-2542-3109': 1, '0000-0002-0612-3437': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_ferguson\n",
      "total sample size before apply threshold:  168\n",
      "Counter({'0000-0003-1321-8714': 157, '0000-0003-0760-757X': 9, '0000-0002-7780-6462': 1, '0000-0002-5463-1874': 1})\n",
      "['0000-0003-1321-8714']\n",
      "Total sample size after apply threshold:  157\n",
      "For name:  s_mitra\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0001-7923-8887': 21, '0000-0001-7620-4809': 11, '0000-0002-0800-4626': 10, '0000-0001-6381-5344': 3, '0000-0003-3526-9942': 1, '0000-0001-5744-3935': 1, '0000-0002-3938-6516': 1})\n",
      "['0000-0001-7620-4809', '0000-0001-7923-8887', '0000-0002-0800-4626']\n",
      "Total sample size after apply threshold:  42\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(42, 1698)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17        11\n",
      "          1       0.66      1.00      0.79        21\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.83      0.74      0.67        42\n",
      "\n",
      "[ 1 10  0  0 21  0  0  1  9]\n",
      "MNB Accuracy:  0.7380952380952381\n",
      "MNB F1:  0.6354959726359926\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82        11\n",
      "          1       0.91      0.95      0.93        21\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.91      0.90      0.90        42\n",
      "\n",
      "[ 9  2  0  1 20  0  1  0  9]\n",
      "svc Accuracy:  0.9047619047619048\n",
      "svc F1:  0.8985942657913283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.43        11\n",
      "          1       0.70      1.00      0.82        21\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.85      0.79      0.75        42\n",
      "\n",
      "[ 3  8  0  0 21  0  0  1  9]\n",
      "LR Accuracy:  0.7857142857142857\n",
      "LR F1:  0.7331564204629221\n",
      "For name:  v_pinto\n",
      "total sample size before apply threshold:  48\n",
      "Counter({'0000-0002-6600-1781': 29, '0000-0002-1152-1667': 11, '0000-0003-3871-9152': 7, '0000-0003-3395-1251': 1})\n",
      "['0000-0002-6600-1781', '0000-0002-1152-1667']\n",
      "Total sample size after apply threshold:  40\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 122)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "40\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        29\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        40\n",
      "\n",
      "[29  0  0 11]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        29\n",
      "          1       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        40\n",
      "\n",
      "[29  0  0 11]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89        29\n",
      "          1       1.00      0.36      0.53        11\n",
      "\n",
      "avg / total       0.86      0.82      0.79        40\n",
      "\n",
      "[29  0  7  4]\n",
      "LR Accuracy:  0.825\n",
      "LR F1:  0.7128205128205128\n",
      "For name:  m_field\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0002-4866-2885': 114, '0000-0003-1310-5074': 6, '0000-0002-8350-417X': 5, '0000-0002-6169-6721': 1})\n",
      "['0000-0002-4866-2885']\n",
      "Total sample size after apply threshold:  114\n",
      "For name:  c_jones\n",
      "total sample size before apply threshold:  354\n",
      "Counter({'0000-0002-0026-9494': 194, '0000-0001-7630-7285': 31, '0000-0001-8594-9554': 28, '0000-0003-0541-0431': 23, '0000-0003-3672-6631': 11, '0000-0002-7249-2580': 11, '0000-0001-9096-9728': 9, '0000-0001-6159-1842': 9, '0000-0003-3430-8110': 7, '0000-0001-6275-0235': 6, '0000-0001-7065-1157': 6, '0000-0003-4680-7080': 4, '0000-0002-1698-0408': 3, '0000-0001-9753-0777': 2, '0000-0002-7196-5825': 2, '0000-0001-6136-7111': 2, '0000-0002-6319-2068': 2, '0000-0002-3708-5859': 1, '0000-0003-1523-2368': 1, '0000-0002-0669-7860': 1, '0000-0002-8765-5178': 1})\n",
      "['0000-0003-0541-0431', '0000-0003-3672-6631', '0000-0001-7630-7285', '0000-0002-7249-2580', '0000-0001-8594-9554', '0000-0002-0026-9494']\n",
      "Total sample size after apply threshold:  298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(298, 558)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "298\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.72        23\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.42      0.59        31\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.71      0.83        28\n",
      "          5       0.77      1.00      0.87       194\n",
      "\n",
      "avg / total       0.78      0.81      0.76       298\n",
      "\n",
      "[ 13   0   0   0   0  10   0   0   0   0   0  11   0   0  13   0   0  18\n",
      "   0   0   0   0   0  11   0   0   0   0  20   8   0   0   0   0   0 194]\n",
      "MNB Accuracy:  0.8053691275167785\n",
      "MNB F1:  0.5027366339025532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        23\n",
      "          1       1.00      0.91      0.95        11\n",
      "          2       1.00      0.74      0.85        31\n",
      "          3       1.00      0.82      0.90        11\n",
      "          4       1.00      0.89      0.94        28\n",
      "          5       0.91      1.00      0.95       194\n",
      "\n",
      "avg / total       0.94      0.94      0.93       298\n",
      "\n",
      "[ 18   0   0   0   0   5   0  10   0   0   0   1   0   0  23   0   0   8\n",
      "   0   0   0   9   0   2   0   0   0   0  25   3   0   0   0   0   0 194]\n",
      "svc Accuracy:  0.9362416107382551\n",
      "svc F1:  0.9131657940754428\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.72        23\n",
      "          1       1.00      0.18      0.31        11\n",
      "          2       1.00      0.29      0.45        31\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.46      0.63        28\n",
      "          5       0.74      1.00      0.85       194\n",
      "\n",
      "avg / total       0.80      0.78      0.73       298\n",
      "\n",
      "[ 13   0   0   0   0  10   0   2   0   0   0   9   0   0   9   0   0  22\n",
      "   0   0   0   0   0  11   0   0   0   0  13  15   0   0   0   0   0 194]\n",
      "LR Accuracy:  0.7751677852348994\n",
      "LR F1:  0.4944680206875329\n",
      "For name:  k_hong\n",
      "total sample size before apply threshold:  127\n",
      "Counter({'0000-0002-4684-6111': 44, '0000-0002-2852-5111': 29, '0000-0001-7325-1036': 20, '0000-0003-3334-817X': 12, '0000-0002-3489-9056': 11, '0000-0002-8308-585X': 6, '0000-0003-1931-0933': 3, '0000-0002-8299-7128': 1, '0000-0001-6213-1848': 1})\n",
      "['0000-0002-3489-9056', '0000-0002-4684-6111', '0000-0002-2852-5111', '0000-0003-3334-817X', '0000-0001-7325-1036']\n",
      "Total sample size after apply threshold:  116\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(116, 245)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.59      1.00      0.74        44\n",
      "          2       1.00      0.79      0.88        29\n",
      "          3       1.00      0.08      0.15        12\n",
      "          4       1.00      0.50      0.67        20\n",
      "\n",
      "avg / total       0.84      0.73      0.71       116\n",
      "\n",
      "[ 7  4  0  0  0  0 44  0  0  0  0  6 23  0  0  0 11  0  1  0  0 10  0  0\n",
      " 10]\n",
      "MNB Accuracy:  0.7327586206896551\n",
      "MNB F1:  0.6444803562450621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.86      0.95      0.90        44\n",
      "          2       0.94      1.00      0.97        29\n",
      "          3       1.00      0.75      0.86        12\n",
      "          4       0.88      0.75      0.81        20\n",
      "\n",
      "avg / total       0.91      0.91      0.90       116\n",
      "\n",
      "[10  0  1  0  0  0 42  1  0  1  0  0 29  0  0  0  2  0  9  1  0  5  0  0\n",
      " 15]\n",
      "svc Accuracy:  0.9051724137931034\n",
      "svc F1:  0.89804541869058\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.78      0.98      0.87        44\n",
      "          2       0.88      1.00      0.94        29\n",
      "          3       1.00      0.50      0.67        12\n",
      "          4       0.93      0.65      0.76        20\n",
      "\n",
      "avg / total       0.87      0.85      0.84       116\n",
      "\n",
      "[ 8  0  3  0  0  0 43  1  0  0  0  0 29  0  0  0  5  0  6  1  0  7  0  0\n",
      " 13]\n",
      "LR Accuracy:  0.853448275862069\n",
      "LR F1:  0.8155297103664226\n",
      "For name:  t_williams\n",
      "total sample size before apply threshold:  190\n",
      "Counter({'0000-0003-3414-3440': 78, '0000-0002-5857-3851': 42, '0000-0003-1072-0223': 25, '0000-0001-6299-3747': 24, '0000-0003-1710-3914': 9, '0000-0002-3866-1344': 6, '0000-0003-0072-3316': 3, '0000-0002-9319-1701': 2, '0000-0003-3463-9200': 1})\n",
      "['0000-0001-6299-3747', '0000-0003-1072-0223', '0000-0003-3414-3440', '0000-0002-5857-3851']\n",
      "Total sample size after apply threshold:  169\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(169, 443)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "169\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        24\n",
      "          1       1.00      0.64      0.78        25\n",
      "          2       0.74      1.00      0.85        78\n",
      "          3       0.93      0.90      0.92        42\n",
      "\n",
      "avg / total       0.86      0.82      0.80       169\n",
      "\n",
      "[ 7  0 14  3  0 16  9  0  0  0 78  0  0  0  4 38]\n",
      "MNB Accuracy:  0.8224852071005917\n",
      "MNB F1:  0.7500555937749268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        24\n",
      "          1       1.00      0.76      0.86        25\n",
      "          2       0.85      1.00      0.92        78\n",
      "          3       0.95      0.90      0.93        42\n",
      "\n",
      "avg / total       0.92      0.91      0.90       169\n",
      "\n",
      "[18  0  4  2  0 19  6  0  0  0 78  0  0  0  4 38]\n",
      "svc Accuracy:  0.9053254437869822\n",
      "svc F1:  0.8913138869738583\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        24\n",
      "          1       1.00      0.60      0.75        25\n",
      "          2       0.70      1.00      0.83        78\n",
      "          3       1.00      0.86      0.92        42\n",
      "\n",
      "avg / total       0.86      0.80      0.79       169\n",
      "\n",
      "[ 7  0 17  0  0 15 10  0  0  0 78  0  0  0  6 36]\n",
      "LR Accuracy:  0.8047337278106509\n",
      "LR F1:  0.7375216629248886\n",
      "For name:  j_xavier\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0002-0702-6700': 12, '0000-0003-1386-4492': 7, '0000-0002-7836-4598': 2, '0000-0002-9669-8532': 1})\n",
      "['0000-0002-0702-6700']\n",
      "Total sample size after apply threshold:  12\n",
      "For name:  b_bhushan\n",
      "total sample size before apply threshold:  187\n",
      "Counter({'0000-0001-7161-6601': 163, '0000-0002-4182-9478': 19, '0000-0002-1716-9764': 3, '0000-0001-5073-0640': 1, '0000-0001-9244-209X': 1})\n",
      "['0000-0001-7161-6601', '0000-0002-4182-9478']\n",
      "Total sample size after apply threshold:  182\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(182, 184)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "182\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       163\n",
      "          1       1.00      0.21      0.35        19\n",
      "\n",
      "avg / total       0.92      0.92      0.89       182\n",
      "\n",
      "[163   0  15   4]\n",
      "MNB Accuracy:  0.9175824175824175\n",
      "MNB F1:  0.6519189085809002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97       163\n",
      "          1       0.92      0.58      0.71        19\n",
      "\n",
      "avg / total       0.95      0.95      0.95       182\n",
      "\n",
      "[162   1   8  11]\n",
      "svc Accuracy:  0.9505494505494505\n",
      "svc F1:  0.8413251961639059\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.94       163\n",
      "          1       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.80      0.90      0.85       182\n",
      "\n",
      "[163   0  19   0]\n",
      "LR Accuracy:  0.8956043956043956\n",
      "LR F1:  0.47246376811594204\n",
      "For name:  r_ellis\n",
      "total sample size before apply threshold:  176\n",
      "Counter({'0000-0003-4931-752X': 158, '0000-0001-7691-5205': 16, '0000-0002-9755-9913': 1, '0000-0003-2355-5407': 1})\n",
      "['0000-0001-7691-5205', '0000-0003-4931-752X']\n",
      "Total sample size after apply threshold:  174\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(174, 499)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "174\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        16\n",
      "          1       0.95      1.00      0.98       158\n",
      "\n",
      "avg / total       0.96      0.95      0.95       174\n",
      "\n",
      "[  8   8   0 158]\n",
      "MNB Accuracy:  0.9540229885057471\n",
      "MNB F1:  0.8209876543209876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.98      1.00      0.99       158\n",
      "\n",
      "avg / total       0.98      0.98      0.98       174\n",
      "\n",
      "[ 13   3   0 158]\n",
      "svc Accuracy:  0.9827586206896551\n",
      "svc F1:  0.9435736677115988\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.91      1.00      0.95       158\n",
      "\n",
      "avg / total       0.82      0.91      0.86       174\n",
      "\n",
      "[  0  16   0 158]\n",
      "LR Accuracy:  0.9080459770114943\n",
      "LR F1:  0.4759036144578313\n",
      "For name:  v_saini\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0002-0258-2871': 11, '0000-0002-9944-0262': 5, '0000-0003-2734-0120': 1, '0000-0002-6796-5881': 1})\n",
      "['0000-0002-0258-2871']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  a_ellis\n",
      "total sample size before apply threshold:  168\n",
      "Counter({'0000-0001-7456-9214': 47, '0000-0002-0725-2353': 41, '0000-0002-0417-0547': 40, '0000-0002-0053-5641': 37, '0000-0002-8164-1146': 3})\n",
      "['0000-0002-0417-0547', '0000-0001-7456-9214', '0000-0002-0725-2353', '0000-0002-0053-5641']\n",
      "Total sample size after apply threshold:  165\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(165, 379)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "165\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        40\n",
      "          1       0.75      0.98      0.85        47\n",
      "          2       0.85      0.71      0.77        41\n",
      "          3       1.00      0.84      0.91        37\n",
      "\n",
      "avg / total       0.89      0.88      0.88       165\n",
      "\n",
      "[39  1  0  0  0 46  1  0  0 12 29  0  0  2  4 31]\n",
      "MNB Accuracy:  0.8787878787878788\n",
      "MNB F1:  0.8810729158048594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        40\n",
      "          1       1.00      0.96      0.98        47\n",
      "          2       0.82      1.00      0.90        41\n",
      "          3       1.00      0.84      0.91        37\n",
      "\n",
      "avg / total       0.96      0.95      0.95       165\n",
      "\n",
      "[39  0  1  0  0 45  2  0  0  0 41  0  0  0  6 31]\n",
      "svc Accuracy:  0.9454545454545454\n",
      "svc F1:  0.9446165621745926\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95        40\n",
      "          1       0.79      0.96      0.87        47\n",
      "          2       0.89      0.78      0.83        41\n",
      "          3       1.00      0.81      0.90        37\n",
      "\n",
      "avg / total       0.90      0.88      0.88       165\n",
      "\n",
      "[39  1  0  0  0 45  2  0  2  7 32  0  1  4  2 30]\n",
      "LR Accuracy:  0.8848484848484849\n",
      "LR F1:  0.8858238367020674\n",
      "For name:  f_reis\n",
      "total sample size before apply threshold:  222\n",
      "Counter({'0000-0002-9258-7472': 111, '0000-0003-3401-9554': 92, '0000-0002-9159-0530': 12, '0000-0003-1546-963X': 4, '0000-0003-2256-4379': 2, '0000-0002-9471-1174': 1})\n",
      "['0000-0002-9159-0530', '0000-0002-9258-7472', '0000-0003-3401-9554']\n",
      "Total sample size after apply threshold:  215\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(215, 395)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "215\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        12\n",
      "          1       0.91      0.94      0.92       111\n",
      "          2       0.93      0.97      0.95        92\n",
      "\n",
      "avg / total       0.92      0.92      0.92       215\n",
      "\n",
      "[  5   7   0   0 104   7   0   3  89]\n",
      "MNB Accuracy:  0.9209302325581395\n",
      "MNB F1:  0.8198294164001297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.94      0.99      0.96       111\n",
      "          2       0.99      0.93      0.96        92\n",
      "\n",
      "avg / total       0.96      0.96      0.96       215\n",
      "\n",
      "[ 11   1   0   0 110   1   0   6  86]\n",
      "svc Accuracy:  0.9627906976744186\n",
      "svc F1:  0.9607759581935976\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       0.86      0.97      0.91       111\n",
      "          2       0.96      0.89      0.93        92\n",
      "\n",
      "avg / total       0.91      0.90      0.89       215\n",
      "\n",
      "[  4   8   0   0 108   3   0  10  82]\n",
      "LR Accuracy:  0.9023255813953488\n",
      "LR F1:  0.7793153591265584\n",
      "For name:  j_gray\n",
      "total sample size before apply threshold:  112\n",
      "Counter({'0000-0001-6380-2324': 55, '0000-0003-4146-7902': 24, '0000-0003-2338-0301': 17, '0000-0002-7287-0748': 8, '0000-0001-5863-6835': 3, '0000-0001-9972-5156': 2, '0000-0001-6668-5899': 1, '0000-0003-3554-0499': 1, '0000-0001-8572-0020': 1})\n",
      "['0000-0003-4146-7902', '0000-0001-6380-2324', '0000-0003-2338-0301']\n",
      "Total sample size after apply threshold:  96\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(96, 437)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "96\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        24\n",
      "          1       0.76      1.00      0.87        55\n",
      "          2       1.00      0.24      0.38        17\n",
      "\n",
      "avg / total       0.86      0.82      0.79        96\n",
      "\n",
      "[20  4  0  0 55  0  0 13  4]\n",
      "MNB Accuracy:  0.8229166666666666\n",
      "MNB F1:  0.7187283407755848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        24\n",
      "          1       0.81      1.00      0.89        55\n",
      "          2       1.00      0.41      0.58        17\n",
      "\n",
      "avg / total       0.89      0.86      0.85        96\n",
      "\n",
      "[21  3  0  0 55  0  0 10  7]\n",
      "svc Accuracy:  0.8645833333333334\n",
      "svc F1:  0.8036585365853659\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        24\n",
      "          1       0.66      1.00      0.80        55\n",
      "          2       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.63      0.71      0.63        96\n",
      "\n",
      "[13 11  0  0 55  0  0 17  0]\n",
      "LR Accuracy:  0.7083333333333334\n",
      "LR F1:  0.4999347173260216\n",
      "For name:  r_hughes\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0001-9910-6566': 30, '0000-0002-4465-4212': 18, '0000-0002-6307-4432': 7, '0000-0002-2875-2103': 2})\n",
      "['0000-0002-4465-4212', '0000-0001-9910-6566']\n",
      "Total sample size after apply threshold:  48\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 171)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        18\n",
      "          1       0.91      1.00      0.95        30\n",
      "\n",
      "avg / total       0.94      0.94      0.94        48\n",
      "\n",
      "[15  3  0 30]\n",
      "MNB Accuracy:  0.9375\n",
      "MNB F1:  0.9307359307359306\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        18\n",
      "          1       0.88      1.00      0.94        30\n",
      "\n",
      "avg / total       0.93      0.92      0.91        48\n",
      "\n",
      "[14  4  0 30]\n",
      "svc Accuracy:  0.9166666666666666\n",
      "svc F1:  0.90625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        18\n",
      "          1       0.71      1.00      0.83        30\n",
      "\n",
      "avg / total       0.82      0.75      0.71        48\n",
      "\n",
      "[ 6 12  0 30]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.6666666666666666\n",
      "For name:  a_green\n",
      "total sample size before apply threshold:  169\n",
      "Counter({'0000-0002-2753-4841': 79, '0000-0002-1268-4951': 39, '0000-0003-2058-1204': 35, '0000-0003-0454-1798': 8, '0000-0002-3674-4242': 4, '0000-0001-7666-5584': 2, '0000-0002-1241-4230': 1, '0000-0003-3404-4995': 1})\n",
      "['0000-0002-1268-4951', '0000-0002-2753-4841', '0000-0003-2058-1204']\n",
      "Total sample size after apply threshold:  153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(153, 338)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "153\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.89        39\n",
      "          1       0.84      1.00      0.91        79\n",
      "          2       1.00      0.80      0.89        35\n",
      "\n",
      "avg / total       0.92      0.90      0.90       153\n",
      "\n",
      "[31  8  0  0 79  0  0  7 28]\n",
      "MNB Accuracy:  0.9019607843137255\n",
      "MNB F1:  0.8959659907636787\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        39\n",
      "          1       0.83      1.00      0.91        79\n",
      "          2       1.00      0.80      0.89        35\n",
      "\n",
      "avg / total       0.91      0.90      0.89       153\n",
      "\n",
      "[30  9  0  0 79  0  0  7 28]\n",
      "svc Accuracy:  0.8954248366013072\n",
      "svc F1:  0.8888333610972293\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        39\n",
      "          1       0.75      1.00      0.85        79\n",
      "          2       1.00      0.66      0.79        35\n",
      "\n",
      "avg / total       0.87      0.82      0.82       153\n",
      "\n",
      "[24 15  0  0 79  0  0 12 23]\n",
      "LR Accuracy:  0.8235294117647058\n",
      "LR F1:  0.8030207547448928\n",
      "For name:  c_reis\n",
      "total sample size before apply threshold:  77\n",
      "Counter({'0000-0002-0286-6639': 54, '0000-0002-1046-4031': 19, '0000-0001-6585-3993': 2, '0000-0002-8193-6964': 2})\n",
      "['0000-0002-0286-6639', '0000-0002-1046-4031']\n",
      "Total sample size after apply threshold:  73\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 264)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "73\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.95        54\n",
      "          1       0.93      0.74      0.82        19\n",
      "\n",
      "avg / total       0.92      0.92      0.91        73\n",
      "\n",
      "[53  1  5 14]\n",
      "MNB Accuracy:  0.9178082191780822\n",
      "MNB F1:  0.8849789915966386\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        54\n",
      "          1       1.00      0.95      0.97        19\n",
      "\n",
      "avg / total       0.99      0.99      0.99        73\n",
      "\n",
      "[54  0  1 18]\n",
      "svc Accuracy:  0.9863013698630136\n",
      "svc F1:  0.9818993305231838\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89        54\n",
      "          1       1.00      0.32      0.48        19\n",
      "\n",
      "avg / total       0.86      0.82      0.79        73\n",
      "\n",
      "[54  0 13  6]\n",
      "LR Accuracy:  0.821917808219178\n",
      "LR F1:  0.6862809917355371\n",
      "For name:  f_scott\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0002-6021-0419': 15, '0000-0003-0229-3698': 8, '0000-0003-2041-4641': 3})\n",
      "['0000-0002-6021-0419']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  l_han\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0003-4180-1288': 8, '0000-0002-0577-9661': 7, '0000-0002-2955-6307': 2, '0000-0003-3436-2811': 2, '0000-0003-3204-6313': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  c_martins\n",
      "total sample size before apply threshold:  121\n",
      "Counter({'0000-0001-8634-6878': 38, '0000-0001-6600-6163': 18, '0000-0002-7901-7600': 17, '0000-0002-8488-5103': 16, '0000-0003-3506-674X': 11, '0000-0001-8710-1856': 4, '0000-0001-8561-5167': 4, '0000-0002-9335-6027': 3, '0000-0003-4341-1005': 3, '0000-0002-8269-9550': 2, '0000-0001-5953-3758': 2, '0000-0002-4886-9261': 1, '0000-0002-7090-6030': 1, '0000-0003-3634-0624': 1})\n",
      "['0000-0001-8634-6878', '0000-0002-8488-5103', '0000-0003-3506-674X', '0000-0001-6600-6163', '0000-0002-7901-7600']\n",
      "Total sample size after apply threshold:  100\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(100, 290)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      1.00      0.79        38\n",
      "          1       1.00      0.88      0.93        16\n",
      "          2       1.00      0.09      0.17        11\n",
      "          3       1.00      0.67      0.80        18\n",
      "          4       0.93      0.82      0.87        17\n",
      "\n",
      "avg / total       0.86      0.79      0.76       100\n",
      "\n",
      "[38  0  0  0  0  2 14  0  0  0  9  0  1  0  1  6  0  0 12  0  3  0  0  0\n",
      " 14]\n",
      "MNB Accuracy:  0.79\n",
      "MNB F1:  0.7133333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        38\n",
      "          1       1.00      1.00      1.00        16\n",
      "          2       1.00      0.73      0.84        11\n",
      "          3       1.00      0.83      0.91        18\n",
      "          4       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.92      0.90      0.90       100\n",
      "\n",
      "[38  0  0  0  0  0 16  0  0  0  3  0  8  0  0  3  0  0 15  0  4  0  0  0\n",
      " 13]\n",
      "svc Accuracy:  0.9\n",
      "svc F1:  0.9003167538296057\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      1.00      0.75        38\n",
      "          1       1.00      0.75      0.86        16\n",
      "          2       1.00      0.27      0.43        11\n",
      "          3       1.00      0.56      0.71        18\n",
      "          4       1.00      0.71      0.83        17\n",
      "\n",
      "avg / total       0.85      0.75      0.74       100\n",
      "\n",
      "[38  0  0  0  0  4 12  0  0  0  8  0  3  0  0  8  0  0 10  0  5  0  0  0\n",
      " 12]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.7160122908842608\n",
      "For name:  r_schneider\n",
      "total sample size before apply threshold:  158\n",
      "Counter({'0000-0002-6870-6902': 43, '0000-0003-2228-1248': 42, '0000-0002-2626-3111': 29, '0000-0003-0012-4962': 25, '0000-0003-3279-5365': 7, '0000-0003-1400-8401': 5, '0000-0001-9317-2888': 2, '0000-0002-0329-5778': 2, '0000-0001-9628-0809': 1, '0000-0001-9501-8489': 1, '0000-0001-5496-7020': 1})\n",
      "['0000-0003-0012-4962', '0000-0003-2228-1248', '0000-0002-6870-6902', '0000-0002-2626-3111']\n",
      "Total sample size after apply threshold:  139\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 359)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        25\n",
      "          1       0.84      0.98      0.90        42\n",
      "          2       0.93      0.98      0.95        43\n",
      "          3       1.00      0.72      0.84        29\n",
      "\n",
      "avg / total       0.93      0.92      0.92       139\n",
      "\n",
      "[24  1  0  0  0 41  1  0  0  1 42  0  0  6  2 21]\n",
      "MNB Accuracy:  0.920863309352518\n",
      "MNB F1:  0.9188090480947624\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        25\n",
      "          1       0.88      0.90      0.89        42\n",
      "          2       0.81      0.98      0.88        43\n",
      "          3       1.00      0.76      0.86        29\n",
      "\n",
      "avg / total       0.91      0.89      0.89       139\n",
      "\n",
      "[22  2  1  0  0 38  4  0  0  1 42  0  0  2  5 22]\n",
      "svc Accuracy:  0.8920863309352518\n",
      "svc F1:  0.8943108710449466\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91        25\n",
      "          1       1.00      0.88      0.94        42\n",
      "          2       0.69      1.00      0.82        43\n",
      "          3       1.00      0.66      0.79        29\n",
      "\n",
      "avg / total       0.91      0.86      0.87       139\n",
      "\n",
      "[21  0  4  0  0 37  5  0  0  0 43  0  0  0 10 19]\n",
      "LR Accuracy:  0.8633093525179856\n",
      "LR F1:  0.8651166561836623\n",
      "For name:  j_regan\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0003-2164-9151': 10, '0000-0001-5816-4516': 9, '0000-0001-9987-7942': 7, '0000-0002-3516-5046': 1})\n",
      "['0000-0003-2164-9151']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  s_brennan\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0003-1789-8809': 12, '0000-0003-3601-9769': 12, '0000-0002-8719-4367': 6, '0000-0002-7634-9546': 1})\n",
      "['0000-0003-1789-8809', '0000-0003-3601-9769']\n",
      "Total sample size after apply threshold:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 78)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "24\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.75      0.82        12\n",
      "          1       0.79      0.92      0.85        12\n",
      "\n",
      "avg / total       0.84      0.83      0.83        24\n",
      "\n",
      "[ 9  3  1 11]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.8321678321678322\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83        12\n",
      "          1       0.83      0.83      0.83        12\n",
      "\n",
      "avg / total       0.83      0.83      0.83        24\n",
      "\n",
      "[10  2  2 10]\n",
      "svc Accuracy:  0.8333333333333334\n",
      "svc F1:  0.8333333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.75      0.75        12\n",
      "          1       0.75      0.75      0.75        12\n",
      "\n",
      "avg / total       0.75      0.75      0.75        24\n",
      "\n",
      "[9 3 3 9]\n",
      "LR Accuracy:  0.75\n",
      "LR F1:  0.75\n",
      "For name:  v_patel\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0003-2875-4659': 20, '0000-0001-6616-3628': 4, '0000-0002-8949-139X': 2, '0000-0003-2844-2698': 1})\n",
      "['0000-0003-2875-4659']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  d_johnston\n",
      "total sample size before apply threshold:  29\n",
      "Counter({'0000-0002-2487-1084': 15, '0000-0003-2424-036X': 7, '0000-0003-0065-1105': 6, '0000-0002-6885-5369': 1})\n",
      "['0000-0002-2487-1084']\n",
      "Total sample size after apply threshold:  15\n",
      "For name:  r_gupta\n",
      "total sample size before apply threshold:  188\n",
      "Counter({'0000-0003-2583-563X': 46, '0000-0002-2984-5010': 36, '0000-0001-6841-6676': 28, '0000-0001-7461-2083': 14, '0000-0002-8328-9780': 9, '0000-0002-5537-8057': 8, '0000-0001-9959-3501': 8, '0000-0001-6819-2748': 6, '0000-0002-6608-9867': 6, '0000-0002-4231-9592': 5, '0000-0001-5755-1143': 5, '0000-0002-6257-1285': 4, '0000-0001-9031-1109': 3, '0000-0002-6585-1725': 3, '0000-0002-1414-2830': 1, '0000-0002-9907-5795': 1, '0000-0002-1334-9186': 1, '0000-0002-8634-7501': 1, '0000-0001-9751-1808': 1, '0000-0003-2958-1526': 1, '0000-0002-3345-7862': 1})\n",
      "['0000-0003-2583-563X', '0000-0001-7461-2083', '0000-0002-2984-5010', '0000-0001-6841-6676']\n",
      "Total sample size after apply threshold:  124\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(124, 521)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "124\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      1.00      0.77        46\n",
      "          1       1.00      0.14      0.25        14\n",
      "          2       1.00      0.86      0.93        36\n",
      "          3       1.00      0.61      0.76        28\n",
      "\n",
      "avg / total       0.86      0.77      0.75       124\n",
      "\n",
      "[46  0  0  0 12  2  0  0  5  0 31  0 11  0  0 17]\n",
      "MNB Accuracy:  0.7741935483870968\n",
      "MNB F1:  0.6743988391376451\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        46\n",
      "          1       1.00      0.64      0.78        14\n",
      "          2       1.00      0.89      0.94        36\n",
      "          3       0.93      1.00      0.97        28\n",
      "\n",
      "avg / total       0.94      0.93      0.92       124\n",
      "\n",
      "[46  0  0  0  5  9  0  0  2  0 32  2  0  0  0 28]\n",
      "svc Accuracy:  0.9274193548387096\n",
      "svc F1:  0.9046488342281622\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        46\n",
      "          1       1.00      0.36      0.53        14\n",
      "          2       1.00      0.86      0.93        36\n",
      "          3       0.96      0.89      0.93        28\n",
      "\n",
      "avg / total       0.90      0.86      0.85       124\n",
      "\n",
      "[46  0  0  0  9  5  0  0  4  0 31  1  3  0  0 25]\n",
      "LR Accuracy:  0.8629032258064516\n",
      "LR F1:  0.8073666753949551\n",
      "For name:  s_reddy\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-9177-0857': 27, '0000-0002-7362-184X': 13, '0000-0002-1458-6853': 7, '0000-0003-2735-9550': 2, '0000-0002-1924-8976': 1, '0000-0002-4726-5714': 1})\n",
      "['0000-0002-9177-0857', '0000-0002-7362-184X']\n",
      "Total sample size after apply threshold:  40\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 144)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "40\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.89        27\n",
      "          1       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.86      0.82      0.80        40\n",
      "\n",
      "[27  0  7  6]\n",
      "MNB Accuracy:  0.825\n",
      "MNB F1:  0.7584124245038826\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92        27\n",
      "          1       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.89      0.88      0.87        40\n",
      "\n",
      "[27  0  5  8]\n",
      "svc Accuracy:  0.875\n",
      "svc F1:  0.8385794995964488\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        27\n",
      "          1       1.00      0.15      0.27        13\n",
      "\n",
      "avg / total       0.80      0.72      0.65        40\n",
      "\n",
      "[27  0 11  2]\n",
      "LR Accuracy:  0.725\n",
      "LR F1:  0.5487179487179488\n",
      "For name:  y_yao\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0001-5827-8716': 19, '0000-0002-4338-2606': 18, '0000-0002-0814-6675': 11, '0000-0002-2943-5994': 3, '0000-0003-4892-052X': 3, '0000-0003-1132-592X': 1, '0000-0001-6502-6226': 1, '0000-0001-9359-2030': 1, '0000-0003-3612-3742': 1})\n",
      "['0000-0002-4338-2606', '0000-0001-5827-8716', '0000-0002-0814-6675']\n",
      "Total sample size after apply threshold:  48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 65)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        18\n",
      "          1       1.00      0.95      0.97        19\n",
      "          2       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.93      0.92      0.92        48\n",
      "\n",
      "[18  0  0  1 18  0  3  0  8]\n",
      "MNB Accuracy:  0.9166666666666666\n",
      "MNB F1:  0.9050260787102893\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        18\n",
      "          1       0.90      1.00      0.95        19\n",
      "          2       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.94      0.94      0.93        48\n",
      "\n",
      "[18  0  0  0 19  0  1  2  8]\n",
      "svc Accuracy:  0.9375\n",
      "svc F1:  0.9216927453769559\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        18\n",
      "          1       1.00      1.00      1.00        19\n",
      "          2       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.95      0.94      0.93        48\n",
      "\n",
      "[18  0  0  0 19  0  3  0  8]\n",
      "LR Accuracy:  0.9375\n",
      "LR F1:  0.9217273954116059\n",
      "For name:  a_huang\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-5701-4521': 38, '0000-0002-5037-6829': 16, '0000-0002-7848-6755': 2, '0000-0003-1939-9149': 1, '0000-0003-1997-1758': 1})\n",
      "['0000-0002-5701-4521', '0000-0002-5037-6829']\n",
      "Total sample size after apply threshold:  54\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(54, 193)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92        38\n",
      "          1       1.00      0.56      0.72        16\n",
      "\n",
      "avg / total       0.89      0.87      0.86        54\n",
      "\n",
      "[38  0  7  9]\n",
      "MNB Accuracy:  0.8703703703703703\n",
      "MNB F1:  0.8178313253012048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        38\n",
      "          1       1.00      0.62      0.77        16\n",
      "\n",
      "avg / total       0.90      0.89      0.88        54\n",
      "\n",
      "[38  0  6 10]\n",
      "svc Accuracy:  0.8888888888888888\n",
      "svc F1:  0.848030018761726\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.84        38\n",
      "          1       1.00      0.12      0.22        16\n",
      "\n",
      "avg / total       0.81      0.74      0.66        54\n",
      "\n",
      "[38  0 14  2]\n",
      "LR Accuracy:  0.7407407407407407\n",
      "LR F1:  0.5333333333333332\n",
      "For name:  d_ghosh\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0002-6571-304X': 9, '0000-0003-0256-1998': 6, '0000-0003-3266-9262': 6, '0000-0001-9691-1498': 1, '0000-0001-8222-5737': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_morgan\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0003-1664-5316': 8, '0000-0003-0194-0304': 4, '0000-0002-3881-7257': 1, '0000-0002-2842-4441': 1, '0000-0002-7060-7735': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  q_li\n",
      "total sample size before apply threshold:  227\n",
      "Counter({'0000-0002-5941-1985': 36, '0000-0001-9565-0855': 33, '0000-0002-5993-0312': 20, '0000-0002-3934-6004': 20, '0000-0002-3876-0617': 15, '0000-0002-8447-9770': 14, '0000-0001-5015-0750': 14, '0000-0002-2450-3628': 11, '0000-0002-7280-5508': 8, '0000-0002-1644-0508': 7, '0000-0002-5143-6678': 6, '0000-0002-2870-4101': 5, '0000-0002-9522-073X': 5, '0000-0003-3370-471X': 5, '0000-0002-8792-0592': 4, '0000-0002-4822-2863': 3, '0000-0002-7724-1289': 3, '0000-0002-1838-3885': 2, '0000-0002-9128-7005': 2, '0000-0001-5699-9843': 2, '0000-0001-9365-3788': 2, '0000-0002-1116-7215': 2, '0000-0002-1990-8233': 2, '0000-0002-0105-4030': 1, '0000-0002-8633-8859': 1, '0000-0003-0463-1590': 1, '0000-0001-7526-2425': 1, '0000-0002-9023-6185': 1, '0000-0003-3752-4716': 1})\n",
      "['0000-0002-2450-3628', '0000-0002-3876-0617', '0000-0002-8447-9770', '0000-0002-5941-1985', '0000-0002-5993-0312', '0000-0001-5015-0750', '0000-0001-9565-0855', '0000-0002-3934-6004']\n",
      "Total sample size after apply threshold:  163\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(163, 448)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "163\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.07      0.12        15\n",
      "          2       1.00      0.21      0.35        14\n",
      "          3       0.71      0.94      0.81        36\n",
      "          4       0.33      0.05      0.09        20\n",
      "          5       1.00      0.57      0.73        14\n",
      "          6       0.36      1.00      0.53        33\n",
      "          7       0.89      0.40      0.55        20\n",
      "\n",
      "avg / total       0.64      0.54      0.47       163\n",
      "\n",
      "[ 0  0  0  0  0  0 10  1  0  1  0  5  0  0  9  0  0  0  3  6  2  0  3  0\n",
      "  0  0  0 34  0  0  2  0  0  0  0  0  1  0 19  0  0  0  0  1  0  8  5  0\n",
      "  0  0  0  0  0  0 33  0  0  0  0  2  0  0 10  8]\n",
      "MNB Accuracy:  0.5398773006134969\n",
      "MNB F1:  0.3982095546816774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82        11\n",
      "          1       1.00      0.53      0.70        15\n",
      "          2       1.00      0.64      0.78        14\n",
      "          3       0.72      0.94      0.82        36\n",
      "          4       0.76      0.95      0.84        20\n",
      "          5       1.00      0.86      0.92        14\n",
      "          6       0.91      0.97      0.94        33\n",
      "          7       0.94      0.75      0.83        20\n",
      "\n",
      "avg / total       0.87      0.85      0.84       163\n",
      "\n",
      "[ 9  0  0  0  1  0  1  0  0  8  0  7  0  0  0  0  0  0  9  3  2  0  0  0\n",
      "  0  0  0 34  2  0  0  0  0  0  0  0 19  0  0  1  0  0  0  0  1 12  1  0\n",
      "  1  0  0  0  0  0 32  0  1  0  0  3  0  0  1 15]\n",
      "svc Accuracy:  0.8466257668711656\n",
      "svc F1:  0.8322188709529633\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.82      0.86        11\n",
      "          1       1.00      0.27      0.42        15\n",
      "          2       1.00      0.29      0.44        14\n",
      "          3       0.57      0.94      0.71        36\n",
      "          4       0.73      0.80      0.76        20\n",
      "          5       1.00      0.79      0.88        14\n",
      "          6       0.87      1.00      0.93        33\n",
      "          7       1.00      0.70      0.82        20\n",
      "\n",
      "avg / total       0.84      0.77      0.75       163\n",
      "\n",
      "[ 9  0  0  1  1  0  0  0  0  4  0 11  0  0  0  0  0  0  4  6  3  0  1  0\n",
      "  0  0  0 34  1  0  1  0  0  0  0  4 16  0  0  0  0  0  0  1  1 11  1  0\n",
      "  0  0  0  0  0  0 33  0  1  0  0  3  0  0  2 14]\n",
      "LR Accuracy:  0.7668711656441718\n",
      "LR F1:  0.7282481131197228\n",
      "For name:  w_wang\n",
      "total sample size before apply threshold:  765\n",
      "Counter({'0000-0001-9033-0158': 194, '0000-0002-1430-1360': 101, '0000-0001-9093-412X': 39, '0000-0003-0509-2605': 30, '0000-0001-5983-3937': 29, '0000-0002-5369-5446': 28, '0000-0003-4287-1704': 27, '0000-0003-4053-5088': 24, '0000-0001-6022-1567': 21, '0000-0002-4309-9077': 19, '0000-0002-9852-1589': 19, '0000-0003-3987-9270': 16, '0000-0002-1935-6301': 15, '0000-0001-9208-7569': 14, '0000-0003-4163-3173': 14, '0000-0002-5257-7675': 13, '0000-0002-6652-5964': 13, '0000-0002-2269-1952': 13, '0000-0002-4628-1755': 12, '0000-0002-5943-4589': 11, '0000-0003-1319-1988': 10, '0000-0003-3007-1750': 9, '0000-0002-3780-5158': 8, '0000-0002-1083-6720': 7, '0000-0002-7762-7560': 6, '0000-0001-6587-8859': 5, '0000-0002-8330-9913': 5, '0000-0001-7496-4548': 5, '0000-0001-9568-3876': 4, '0000-0002-1260-2098': 4, '0000-0001-8947-4867': 4, '0000-0002-6154-7750': 4, '0000-0001-6109-1645': 4, '0000-0003-1567-2371': 4, '0000-0003-1788-2727': 4, '0000-0003-3941-4860': 4, '0000-0002-8814-525X': 3, '0000-0002-9303-516X': 3, '0000-0002-9865-6811': 2, '0000-0002-3245-9049': 2, '0000-0001-9223-6472': 2, '0000-0001-6818-7711': 2, '0000-0002-2468-5222': 2, '0000-0003-1930-4891': 1, '0000-0002-3116-5954': 1, '0000-0002-1225-4011': 1, '0000-0003-4712-3692': 1, '0000-0001-7511-3497': 1, '0000-0002-3709-021X': 1, '0000-0002-2914-1638': 1, '0000-0003-4426-019X': 1, '0000-0002-6983-2548': 1, '0000-0002-5812-6744': 1})\n",
      "['0000-0002-5369-5446', '0000-0002-4309-9077', '0000-0003-1319-1988', '0000-0003-3987-9270', '0000-0002-4628-1755', '0000-0001-5983-3937', '0000-0002-5257-7675', '0000-0001-9033-0158', '0000-0001-9093-412X', '0000-0003-0509-2605', '0000-0001-9208-7569', '0000-0003-4287-1704', '0000-0002-1935-6301', '0000-0002-1430-1360', '0000-0001-6022-1567', '0000-0002-6652-5964', '0000-0002-9852-1589', '0000-0003-4053-5088', '0000-0002-2269-1952', '0000-0002-5943-4589', '0000-0003-4163-3173']\n",
      "Total sample size after apply threshold:  662\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(662, 1007)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "662\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        28\n",
      "          1       0.00      0.00      0.00        19\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.00      0.00      0.00        12\n",
      "          5       1.00      0.52      0.68        29\n",
      "          6       0.00      0.00      0.00        13\n",
      "          7       0.37      0.97      0.54       194\n",
      "          8       1.00      0.03      0.05        39\n",
      "          9       1.00      0.20      0.33        30\n",
      "         10       0.00      0.00      0.00        14\n",
      "         11       1.00      0.33      0.50        27\n",
      "         12       1.00      0.47      0.64        15\n",
      "         13       0.62      0.70      0.66       101\n",
      "         14       0.00      0.00      0.00        21\n",
      "         15       0.00      0.00      0.00        13\n",
      "         16       0.00      0.00      0.00        19\n",
      "         17       0.00      0.00      0.00        24\n",
      "         18       0.00      0.00      0.00        13\n",
      "         19       0.00      0.00      0.00        11\n",
      "         20       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.41      0.45      0.34       662\n",
      "\n",
      "[  0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  16   0   0   0   0   0   3   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0\n",
      "   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   5   0   0   0   0   0   7   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  15   0  10   0   0   0   0   0   4   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  11   0   0   0   0   0   2   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   5   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  36   1   0   0   0\n",
      "   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0\n",
      "   6   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  13   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  18   0   0   0   9   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   8   0   0   0   0   7   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  30   0   0   0   0   0  71   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0\n",
      "   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  10   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  23   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  12   0   0   0   0   0   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  11   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  13   0   0   0   0\n",
      "   0   1   0   0   0   0   0   0   0]\n",
      "MNB Accuracy:  0.4501510574018127\n",
      "MNB F1:  0.1617437213928442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.61      0.76        28\n",
      "          1       0.90      0.47      0.62        19\n",
      "          2       1.00      0.20      0.33        10\n",
      "          3       1.00      0.94      0.97        16\n",
      "          4       1.00      0.83      0.91        12\n",
      "          5       0.83      0.69      0.75        29\n",
      "          6       0.50      0.15      0.24        13\n",
      "          7       0.60      0.94      0.74       194\n",
      "          8       0.89      0.62      0.73        39\n",
      "          9       1.00      0.53      0.70        30\n",
      "         10       1.00      0.57      0.73        14\n",
      "         11       1.00      0.81      0.90        27\n",
      "         12       1.00      0.80      0.89        15\n",
      "         13       0.71      0.78      0.75       101\n",
      "         14       0.85      0.52      0.65        21\n",
      "         15       1.00      0.15      0.27        13\n",
      "         16       1.00      0.79      0.88        19\n",
      "         17       0.68      0.62      0.65        24\n",
      "         18       0.77      0.77      0.77        13\n",
      "         19       1.00      0.64      0.78        11\n",
      "         20       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.79      0.74      0.73       662\n",
      "\n",
      "[ 17   0   0   0   0   0   0  11   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   9   0   0   0   1   0   7   0   0   0   0   0   1   0\n",
      "   0   0   0   1   0   0   0   0   2   0   0   0   0   6   0   0   0   0\n",
      "   0   2   0   0   0   0   0   0   0   0   0   0  15   0   0   0   1   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0\n",
      "   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  20   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   2  10   0   0   0   0   0   1   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   1   2 182   0   0   0   0   0   5   2\n",
      "   0   0   2   0   0   0   0   0   0   0   0   1   0  11  24   0   0   0\n",
      "   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0\n",
      "  16   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "   0   3   0   0   8   0   0   1   0   0   0   1   0   0   0   0   0   0\n",
      "   0   0   0   0   5   0   0   0  22   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   3   0   0   0   0  12   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  19   0   0   0   0   0  79   0\n",
      "   0   0   2   1   0   0   0   0   0   0   0   0   0   8   1   0   0   0\n",
      "   0   0  11   0   0   0   1   0   0   0   0   0   0   0   0   0   3   1\n",
      "   0   0   0   0   5   0   2   0   2   0   0   0   0   0   0   0   0   0\n",
      "   0   2   0   0   0   0   0   2   0   0  15   0   0   0   0   0   0   0\n",
      "   0   0   0   0   6   0   0   0   0   0   3   0   0   0  15   0   0   0\n",
      "   0   1   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0\n",
      "  10   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0\n",
      "   0   0   0   0   7   0   0   0   0   0   0   0   0   2   0   0   0   0\n",
      "   0   1   0   0   0   0   0   0  11]\n",
      "svc Accuracy:  0.7386706948640483\n",
      "svc F1:  0.7080650301943863\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25        28\n",
      "          1       1.00      0.32      0.48        19\n",
      "          2       1.00      0.10      0.18        10\n",
      "          3       1.00      0.06      0.12        16\n",
      "          4       1.00      0.17      0.29        12\n",
      "          5       0.78      0.72      0.75        29\n",
      "          6       0.00      0.00      0.00        13\n",
      "          7       0.45      0.95      0.61       194\n",
      "          8       0.93      0.33      0.49        39\n",
      "          9       0.90      0.30      0.45        30\n",
      "         10       1.00      0.14      0.25        14\n",
      "         11       1.00      0.59      0.74        27\n",
      "         12       1.00      0.47      0.64        15\n",
      "         13       0.61      0.70      0.65       101\n",
      "         14       1.00      0.38      0.55        21\n",
      "         15       0.00      0.00      0.00        13\n",
      "         16       1.00      0.37      0.54        19\n",
      "         17       0.75      0.38      0.50        24\n",
      "         18       0.67      0.31      0.42        13\n",
      "         19       1.00      0.55      0.71        11\n",
      "         20       1.00      0.43      0.60        14\n",
      "\n",
      "avg / total       0.71      0.57      0.53       662\n",
      "\n",
      "[  4   0   0   0   0   0   0  24   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   6   0   0   0   1   0  10   0   0   0   0   0   1   0\n",
      "   0   0   0   1   0   0   0   0   1   0   0   0   0   7   0   0   0   0\n",
      "   0   2   0   0   0   0   0   0   0   0   0   0   1   0   0   0  15   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
      "   0   5   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  21   0   7   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  11   0   0   0   0   0   2   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   1   0 184   0   1   0   0   0   7   0\n",
      "   0   0   1   0   0   0   0   0   0   0   0   3   0  19  13   0   0   0\n",
      "   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15   0\n",
      "   9   0   0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "   0  10   0   0   2   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  11   0   0   0  16   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   8   0   0   0   0   7   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  29   0   0   0   0   0  71   0\n",
      "   0   0   1   0   0   0   0   0   0   0   0   0   0  11   1   0   0   0\n",
      "   0   0   8   0   0   0   1   0   0   0   0   0   0   0   0   0   8   0\n",
      "   0   0   0   0   4   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "   0   5   0   0   0   0   0   7   0   0   7   0   0   0   0   0   0   0\n",
      "   0   0   0   0  12   0   0   0   0   0   3   0   0   0   9   0   0   0\n",
      "   0   0   0   0   0   0   0   7   0   0   0   0   0   2   0   0   0   0\n",
      "   4   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0\n",
      "   0   0   0   0   6   0   0   0   0   0   0   0   0   7   0   0   0   0\n",
      "   0   1   0   0   0   0   0   0   6]\n",
      "LR Accuracy:  0.5694864048338368\n",
      "LR F1:  0.4387649322784573\n",
      "For name:  r_ross\n",
      "total sample size before apply threshold:  374\n",
      "Counter({'0000-0003-4876-8839': 356, '0000-0002-3987-881X': 17, '0000-0002-7825-9974': 1})\n",
      "['0000-0003-4876-8839', '0000-0002-3987-881X']\n",
      "Total sample size after apply threshold:  373\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(373, 428)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "373\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       356\n",
      "          1       0.80      0.24      0.36        17\n",
      "\n",
      "avg / total       0.96      0.96      0.95       373\n",
      "\n",
      "[355   1  13   4]\n",
      "MNB Accuracy:  0.9624664879356568\n",
      "MNB F1:  0.6721496735308891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       356\n",
      "          1       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.99      0.99      0.99       373\n",
      "\n",
      "[356   0   2  15]\n",
      "svc Accuracy:  0.9946380697050938\n",
      "svc F1:  0.9673494397759104\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98       356\n",
      "          1       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.91      0.95      0.93       373\n",
      "\n",
      "[356   0  17   0]\n",
      "LR Accuracy:  0.9544235924932976\n",
      "LR F1:  0.4883401920438957\n",
      "For name:  k_yamamoto\n",
      "total sample size before apply threshold:  106\n",
      "Counter({'0000-0002-7935-7015': 93, '0000-0003-0866-3207': 4, '0000-0002-7590-3568': 4, '0000-0001-6642-7961': 2, '0000-0002-6831-5346': 2, '0000-0002-1619-4407': 1})\n",
      "['0000-0002-7935-7015']\n",
      "Total sample size after apply threshold:  93\n",
      "For name:  j_silva\n",
      "total sample size before apply threshold:  268\n",
      "Counter({'0000-0001-9523-9441': 128, '0000-0003-3977-7418': 28, '0000-0002-3696-3955': 22, '0000-0002-6725-5767': 14, '0000-0003-2583-9518': 13, '0000-0001-9959-4272': 8, '0000-0002-5656-0897': 7, '0000-0001-9487-4259': 6, '0000-0002-6041-1763': 6, '0000-0002-1520-0799': 4, '0000-0001-8055-8925': 3, '0000-0001-9708-1043': 3, '0000-0002-7268-6465': 3, '0000-0003-1224-1699': 2, '0000-0002-7211-1661': 2, '0000-0002-7206-0550': 2, '0000-0003-1244-6483': 2, '0000-0003-4180-565X': 2, '0000-0001-9522-6181': 2, '0000-0001-9554-8797': 2, '0000-0002-6455-9618': 1, '0000-0003-2863-8068': 1, '0000-0003-2318-3893': 1, '0000-0002-9230-7135': 1, '0000-0003-4773-6771': 1, '0000-0002-1134-1252': 1, '0000-0002-1956-5779': 1, '0000-0003-1778-3833': 1, '0000-0001-5722-0213': 1})\n",
      "['0000-0002-6725-5767', '0000-0003-2583-9518', '0000-0003-3977-7418', '0000-0002-3696-3955', '0000-0001-9523-9441']\n",
      "Total sample size after apply threshold:  205\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(205, 355)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "205\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       1.00      0.69      0.82        13\n",
      "          2       1.00      0.89      0.94        28\n",
      "          3       1.00      0.50      0.67        22\n",
      "          4       0.87      1.00      0.93       128\n",
      "\n",
      "avg / total       0.92      0.91      0.90       205\n",
      "\n",
      "[ 13   0   0   0   1   0   9   0   0   4   0   0  25   0   3   0   0   0\n",
      "  11  11   0   0   0   0 128]\n",
      "MNB Accuracy:  0.9073170731707317\n",
      "MNB F1:  0.8644233530271267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        14\n",
      "          1       1.00      0.77      0.87        13\n",
      "          2       1.00      0.96      0.98        28\n",
      "          3       1.00      0.68      0.81        22\n",
      "          4       0.92      1.00      0.96       128\n",
      "\n",
      "avg / total       0.95      0.94      0.94       205\n",
      "\n",
      "[ 13   0   0   0   1   0  10   0   0   3   0   0  27   0   1   1   0   0\n",
      "  15   6   0   0   0   0 128]\n",
      "svc Accuracy:  0.9414634146341463\n",
      "svc F1:  0.9099134273438134\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.79      0.85        14\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       1.00      0.75      0.86        28\n",
      "          3       1.00      0.36      0.53        22\n",
      "          4       0.82      1.00      0.90       128\n",
      "\n",
      "avg / total       0.88      0.86      0.84       205\n",
      "\n",
      "[ 11   0   0   0   3   0   8   0   0   5   0   0  21   0   7   1   0   0\n",
      "   8  13   0   0   0   0 128]\n",
      "LR Accuracy:  0.8585365853658536\n",
      "LR F1:  0.7799886498478048\n",
      "For name:  m_pellegrini\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0003-3817-4412': 31, '0000-0001-8505-9260': 15, '0000-0001-9355-9564': 14, '0000-0003-4878-4505': 3, '0000-0003-3527-9542': 1})\n",
      "['0000-0001-9355-9564', '0000-0003-3817-4412', '0000-0001-8505-9260']\n",
      "Total sample size after apply threshold:  60\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 249)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "60\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.13        14\n",
      "          1       0.57      1.00      0.73        31\n",
      "          2       1.00      0.33      0.50        15\n",
      "\n",
      "avg / total       0.78      0.62      0.53        60\n",
      "\n",
      "[ 1 13  0  0 31  0  0 10  5]\n",
      "MNB Accuracy:  0.6166666666666667\n",
      "MNB F1:  0.4542483660130719\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.57      0.70        14\n",
      "          1       0.72      1.00      0.84        31\n",
      "          2       1.00      0.53      0.70        15\n",
      "\n",
      "avg / total       0.83      0.78      0.77        60\n",
      "\n",
      "[ 8  6  0  0 31  0  1  6  8]\n",
      "svc Accuracy:  0.7833333333333333\n",
      "svc F1:  0.7430473952213082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.13        14\n",
      "          1       0.55      1.00      0.71        31\n",
      "          2       1.00      0.20      0.33        15\n",
      "\n",
      "avg / total       0.77      0.58      0.48        60\n",
      "\n",
      "[ 1 13  0  0 31  0  0 12  3]\n",
      "LR Accuracy:  0.5833333333333334\n",
      "LR F1:  0.393103448275862\n",
      "For name:  s_kwon\n",
      "total sample size before apply threshold:  51\n",
      "Counter({'0000-0002-8490-9101': 17, '0000-0002-0679-1523': 15, '0000-0002-1857-3515': 9, '0000-0002-8215-442X': 5, '0000-0001-5265-862X': 1, '0000-0002-9121-3954': 1, '0000-0003-0249-4190': 1, '0000-0001-9287-4490': 1, '0000-0003-1147-8037': 1})\n",
      "['0000-0002-0679-1523', '0000-0002-8490-9101']\n",
      "Total sample size after apply threshold:  32\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 87)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        15\n",
      "          1       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.94      0.94      0.94        32\n",
      "\n",
      "[15  0  2 15]\n",
      "MNB Accuracy:  0.9375\n",
      "MNB F1:  0.9375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        15\n",
      "          1       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.97      0.97      0.97        32\n",
      "\n",
      "[14  1  0 17]\n",
      "svc Accuracy:  0.96875\n",
      "svc F1:  0.9684729064039409\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        15\n",
      "          1       0.94      0.94      0.94        17\n",
      "\n",
      "avg / total       0.94      0.94      0.94        32\n",
      "\n",
      "[14  1  1 16]\n",
      "LR Accuracy:  0.9375\n",
      "LR F1:  0.9372549019607843\n",
      "For name:  m_correa\n",
      "total sample size before apply threshold:  72\n",
      "Counter({'0000-0002-9868-3131': 63, '0000-0003-4856-7578': 7, '0000-0001-8464-2673': 1, '0000-0003-4985-3330': 1})\n",
      "['0000-0002-9868-3131']\n",
      "Total sample size after apply threshold:  63\n",
      "For name:  a_pal\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0003-3893-1305': 6, '0000-0002-0850-3118': 4, '0000-0001-5425-5218': 3, '0000-0001-7615-7811': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  v_costa\n",
      "total sample size before apply threshold:  141\n",
      "Counter({'0000-0002-0471-2756': 33, '0000-0002-7868-4663': 32, '0000-0002-7294-6933': 27, '0000-0002-2113-7482': 18, '0000-0002-5412-8945': 18, '0000-0001-8188-831X': 7, '0000-0002-1513-0284': 2, '0000-0001-5786-633X': 2, '0000-0003-0122-3567': 1, '0000-0001-8801-5669': 1})\n",
      "['0000-0002-2113-7482', '0000-0002-7294-6933', '0000-0002-5412-8945', '0000-0002-0471-2756', '0000-0002-7868-4663']\n",
      "Total sample size after apply threshold:  128\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(128, 329)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "128\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       1.00      0.93      0.96        27\n",
      "          2       1.00      0.83      0.91        18\n",
      "          3       0.87      1.00      0.93        33\n",
      "          4       0.91      0.91      0.91        32\n",
      "\n",
      "avg / total       0.94      0.94      0.94       128\n",
      "\n",
      "[18  0  0  0  0  0 25  0  1  1  0  0 15  1  2  0  0  0 33  0  0  0  0  3\n",
      " 29]\n",
      "MNB Accuracy:  0.9375\n",
      "MNB F1:  0.9412913670836206\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        18\n",
      "          1       1.00      0.93      0.96        27\n",
      "          2       1.00      0.89      0.94        18\n",
      "          3       1.00      1.00      1.00        33\n",
      "          4       0.86      1.00      0.93        32\n",
      "\n",
      "avg / total       0.97      0.96      0.96       128\n",
      "\n",
      "[17  0  0  0  1  0 25  0  0  2  0  0 16  0  2  0  0  0 33  0  0  0  0  0\n",
      " 32]\n",
      "svc Accuracy:  0.9609375\n",
      "svc F1:  0.9603359470878651\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       1.00      0.93      0.96        27\n",
      "          2       1.00      0.83      0.91        18\n",
      "          3       0.89      1.00      0.94        33\n",
      "          4       0.88      0.91      0.89        32\n",
      "\n",
      "avg / total       0.94      0.94      0.94       128\n",
      "\n",
      "[18  0  0  0  0  0 25  0  1  1  0  0 15  0  3  0  0  0 33  0  0  0  0  3\n",
      " 29]\n",
      "LR Accuracy:  0.9375\n",
      "LR F1:  0.9411588411588412\n",
      "For name:  j_allen\n",
      "total sample size before apply threshold:  111\n",
      "Counter({'0000-0001-5219-4423': 36, '0000-0002-3829-066X': 27, '0000-0001-9974-4226': 12, '0000-0003-3566-3747': 12, '0000-0003-4740-9404': 11, '0000-0002-3894-4854': 5, '0000-0002-6576-2132': 3, '0000-0002-0950-0429': 3, '0000-0002-3084-7785': 1, '0000-0002-6717-8693': 1})\n",
      "['0000-0002-3829-066X', '0000-0003-4740-9404', '0000-0001-9974-4226', '0000-0003-3566-3747', '0000-0001-5219-4423']\n",
      "Total sample size after apply threshold:  98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 377)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        27\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       1.00      0.08      0.15        12\n",
      "          4       0.64      1.00      0.78        36\n",
      "\n",
      "avg / total       0.87      0.80      0.77        98\n",
      "\n",
      "[23  0  0  0  4  0  8  0  0  3  0  0 10  0  2  0  0  0  1 11  0  0  0  0\n",
      " 36]\n",
      "MNB Accuracy:  0.7959183673469388\n",
      "MNB F1:  0.7215302043494263\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.85      0.87        27\n",
      "          1       1.00      0.82      0.90        11\n",
      "          2       1.00      0.92      0.96        12\n",
      "          3       1.00      0.58      0.74        12\n",
      "          4       0.76      0.94      0.84        36\n",
      "\n",
      "avg / total       0.88      0.86      0.86        98\n",
      "\n",
      "[23  0  0  0  4  0  9  0  0  2  0  0 11  0  1  1  0  0  7  4  2  0  0  0\n",
      " 34]\n",
      "svc Accuracy:  0.8571428571428571\n",
      "svc F1:  0.8601589091069972\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.83        27\n",
      "          1       1.00      0.82      0.90        11\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       1.00      0.08      0.15        12\n",
      "          4       0.61      1.00      0.76        36\n",
      "\n",
      "avg / total       0.86      0.77      0.74        98\n",
      "\n",
      "[19  0  0  0  8  0  9  0  0  2  0  0 10  0  2  0  0  0  1 11  0  0  0  0\n",
      " 36]\n",
      "LR Accuracy:  0.7653061224489796\n",
      "LR F1:  0.7093837512601815\n",
      "For name:  y_dong\n",
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0003-0016-9028': 42, '0000-0002-1737-6536': 16, '0000-0003-4550-2322': 9, '0000-0003-1294-4888': 4, '0000-0002-4129-4637': 2, '0000-0001-8595-2868': 2, '0000-0003-1774-1553': 1})\n",
      "['0000-0002-1737-6536', '0000-0003-0016-9028']\n",
      "Total sample size after apply threshold:  58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(58, 192)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.48        16\n",
      "          1       0.79      1.00      0.88        42\n",
      "\n",
      "avg / total       0.85      0.81      0.77        58\n",
      "\n",
      "[ 5 11  0 42]\n",
      "MNB Accuracy:  0.8103448275862069\n",
      "MNB F1:  0.6802005012531329\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        16\n",
      "          1       0.91      1.00      0.95        42\n",
      "\n",
      "avg / total       0.94      0.93      0.93        58\n",
      "\n",
      "[12  4  0 42]\n",
      "svc Accuracy:  0.9310344827586207\n",
      "svc F1:  0.9058441558441558\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.12        16\n",
      "          1       0.74      1.00      0.85        42\n",
      "\n",
      "avg / total       0.81      0.74      0.65        58\n",
      "\n",
      "[ 1 15  0 42]\n",
      "LR Accuracy:  0.7413793103448276\n",
      "LR F1:  0.4830659536541889\n",
      "For name:  m_fitzgerald\n",
      "total sample size before apply threshold:  133\n",
      "Counter({'0000-0003-0183-7761': 81, '0000-0002-4823-8179': 38, '0000-0002-4535-0966': 10, '0000-0002-0176-8973': 4})\n",
      "['0000-0002-4535-0966', '0000-0002-4823-8179', '0000-0003-0183-7761']\n",
      "Total sample size after apply threshold:  129\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(129, 364)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "129\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.97      0.87      0.92        38\n",
      "          2       0.91      1.00      0.95        81\n",
      "\n",
      "avg / total       0.93      0.93      0.93       129\n",
      "\n",
      "[ 6  1  3  0 33  5  0  0 81]\n",
      "MNB Accuracy:  0.9302325581395349\n",
      "MNB F1: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.873202614379085\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       1.00      0.84      0.91        38\n",
      "          2       0.91      1.00      0.95        81\n",
      "\n",
      "avg / total       0.94      0.94      0.94       129\n",
      "\n",
      "[ 8  0  2  0 32  6  0  0 81]\n",
      "svc Accuracy:  0.937984496124031\n",
      "svc F1:  0.9187052598817305\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       1.00      0.61      0.75        38\n",
      "          2       0.80      1.00      0.89        81\n",
      "\n",
      "avg / total       0.88      0.84      0.83       129\n",
      "\n",
      "[ 5  0  5  0 23 15  0  0 81]\n",
      "LR Accuracy:  0.8449612403100775\n",
      "LR F1:  0.7702916391440983\n",
      "For name:  m_ferreira\n",
      "total sample size before apply threshold:  253\n",
      "Counter({'0000-0002-5293-9090': 80, '0000-0002-6814-6773': 33, '0000-0002-9459-8167': 23, '0000-0001-8362-0819': 16, '0000-0003-2098-066X': 15, '0000-0002-0856-9811': 14, '0000-0002-0075-2400': 10, '0000-0002-2071-9851': 10, '0000-0002-8452-2222': 10, '0000-0002-7909-637X': 6, '0000-0001-6789-3796': 5, '0000-0001-8962-7157': 4, '0000-0001-9609-5099': 4, '0000-0003-1137-9776': 4, '0000-0001-6475-9401': 3, '0000-0001-8316-7022': 3, '0000-0002-3740-6069': 3, '0000-0001-5586-6328': 2, '0000-0002-4294-7003': 2, '0000-0002-4741-8661': 2, '0000-0002-0595-620X': 1, '0000-0002-0159-7422': 1, '0000-0002-2437-7780': 1, '0000-0003-0570-6259': 1})\n",
      "['0000-0002-0075-2400', '0000-0003-2098-066X', '0000-0002-2071-9851', '0000-0002-5293-9090', '0000-0002-0856-9811', '0000-0001-8362-0819', '0000-0002-9459-8167', '0000-0002-6814-6773', '0000-0002-8452-2222']\n",
      "Total sample size after apply threshold:  211\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(211, 625)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.87      0.93        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.50      1.00      0.67        80\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       1.00      0.31      0.48        16\n",
      "          6       1.00      0.57      0.72        23\n",
      "          7       1.00      0.58      0.73        33\n",
      "          8       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.65      0.62      0.56       211\n",
      "\n",
      "[ 0  0  0 10  0  0  0  0  0  0 13  0  2  0  0  0  0  0  0  0  0 10  0  0\n",
      "  0  0  0  0  0  0 80  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0\n",
      " 11  0  5  0  0  0  0  0  0 10  0  0 13  0  0  0  0  0 14  0  0  0 19  0\n",
      "  0  0  0  9  0  0  0  0  1]\n",
      "MNB Accuracy:  0.6208530805687204\n",
      "MNB F1:  0.4118042451375785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       1.00      0.93      0.97        15\n",
      "          2       1.00      0.70      0.82        10\n",
      "          3       0.67      1.00      0.80        80\n",
      "          4       1.00      0.21      0.35        14\n",
      "          5       1.00      0.75      0.86        16\n",
      "          6       1.00      0.83      0.90        23\n",
      "          7       0.96      0.76      0.85        33\n",
      "          8       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.87      0.81      0.79       211\n",
      "\n",
      "[ 2  0  0  8  0  0  0  0  0  0 14  0  1  0  0  0  0  0  0  0  7  3  0  0\n",
      "  0  0  0  0  0  0 80  0  0  0  0  0  0  0  0 11  3  0  0  0  0  0  0  0\n",
      "  3  0 12  0  1  0  0  0  0  4  0  0 19  0  0  0  0  0  8  0  0  0 25  0\n",
      "  0  0  0  2  0  0  0  0  8]\n",
      "svc Accuracy:  0.8056872037914692\n",
      "svc F1:  0.7526191600955815\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.87      0.93        15\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.51      1.00      0.68        80\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       1.00      0.62      0.77        16\n",
      "          6       1.00      0.57      0.72        23\n",
      "          7       1.00      0.42      0.60        33\n",
      "          8       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.65      0.64      0.58       211\n",
      "\n",
      "[ 0  0  0 10  0  0  0  0  0  0 13  0  2  0  0  0  0  0  0  0  0 10  0  0\n",
      "  0  0  0  0  0  0 80  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0\n",
      "  6  0 10  0  0  0  0  0  0 10  0  0 13  0  0  0  0  0 19  0  0  0 14  0\n",
      "  0  0  0  6  0  0  0  0  4]\n",
      "LR Accuracy:  0.6350710900473934\n",
      "LR F1:  0.4735892397262359\n",
      "For name:  m_roberts\n",
      "total sample size before apply threshold:  320\n",
      "Counter({'0000-0003-3894-5301': 251, '0000-0002-1441-7363': 26, '0000-0003-0552-7402': 20, '0000-0002-8010-1068': 15, '0000-0002-9396-9720': 3, '0000-0002-0931-9363': 2, '0000-0002-2220-582X': 1, '0000-0003-2693-5093': 1, '0000-0003-2769-7365': 1})\n",
      "['0000-0003-0552-7402', '0000-0002-8010-1068', '0000-0003-3894-5301', '0000-0002-1441-7363']\n",
      "Total sample size after apply threshold:  312\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(312, 564)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        20\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.82      1.00      0.90       251\n",
      "          3       0.00      0.00      0.00        26\n",
      "\n",
      "avg / total       0.72      0.82      0.75       312\n",
      "\n",
      "[  5   0  15   0   0   0  15   0   0   0 250   1   0   0  26   0]\n",
      "MNB Accuracy:  0.8173076923076923\n",
      "MNB F1:  0.32441651705565533\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        20\n",
      "          1       1.00      0.80      0.89        15\n",
      "          2       0.89      1.00      0.94       251\n",
      "          3       1.00      0.31      0.47        26\n",
      "\n",
      "avg / total       0.91      0.90      0.89       312\n",
      "\n",
      "[ 11   0   9   0   0  12   3   0   0   0 251   0   0   0  18   8]\n",
      "svc Accuracy:  0.9038461538461539\n",
      "svc F1:  0.7531908915235591\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.05      0.10        20\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.81      1.00      0.89       251\n",
      "          3       0.00      0.00      0.00        26\n",
      "\n",
      "avg / total       0.71      0.81      0.72       312\n",
      "\n",
      "[  1   0  19   0   0   0  15   0   0   0 251   0   0   0  26   0]\n",
      "LR Accuracy:  0.8076923076923077\n",
      "LR F1:  0.24711913235044908\n",
      "For name:  y_lim\n",
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0002-3484-045X': 21, '0000-0002-8472-289X': 21, '0000-0003-1377-7655': 10, '0000-0002-4181-2916': 8, '0000-0001-5000-5991': 5, '0000-0003-4390-4010': 3, '0000-0003-4050-6332': 2, '0000-0002-3408-8595': 2, '0000-0002-0346-2345': 1, '0000-0002-3279-332X': 1, '0000-0002-4082-3322': 1, '0000-0003-3678-0080': 1})\n",
      "['0000-0002-3484-045X', '0000-0003-1377-7655', '0000-0002-8472-289X']\n",
      "Total sample size after apply threshold:  52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 101)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        21\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       0.88      1.00      0.93        21\n",
      "\n",
      "avg / total       0.95      0.94      0.94        52\n",
      "\n",
      "[21  0  0  0  7  3  0  0 21]\n",
      "MNB Accuracy:  0.9423076923076923\n",
      "MNB F1:  0.918954248366013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        21\n",
      "          1       1.00      0.80      0.89        10\n",
      "          2       0.91      1.00      0.95        21\n",
      "\n",
      "avg / total       0.96      0.96      0.96        52\n",
      "\n",
      "[21  0  0  0  8  2  0  0 21]\n",
      "svc Accuracy:  0.9615384615384616\n",
      "svc F1:  0.9478114478114478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        21\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       0.88      1.00      0.93        21\n",
      "\n",
      "avg / total       0.95      0.94      0.94        52\n",
      "\n",
      "[21  0  0  0  7  3  0  0 21]\n",
      "LR Accuracy:  0.9423076923076923\n",
      "LR F1:  0.918954248366013\n",
      "For name:  g_miller\n",
      "total sample size before apply threshold:  76\n",
      "Counter({'0000-0002-4743-8187': 26, '0000-0001-8984-1284': 23, '0000-0001-6533-3306': 13, '0000-0003-4527-3814': 11, '0000-0002-1108-0654': 3})\n",
      "['0000-0001-6533-3306', '0000-0001-8984-1284', '0000-0003-4527-3814', '0000-0002-4743-8187']\n",
      "Total sample size after apply threshold:  73\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(73, 239)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "73\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.65      0.74      0.69        23\n",
      "          2       1.00      0.18      0.31        11\n",
      "          3       0.65      0.85      0.73        26\n",
      "\n",
      "avg / total       0.77      0.71      0.69        73\n",
      "\n",
      "[11  1  0  1  0 17  0  6  0  4  2  5  0  4  0 22]\n",
      "MNB Accuracy:  0.7123287671232876\n",
      "MNB F1:  0.6628924646781789\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        13\n",
      "          1       0.65      0.96      0.77        23\n",
      "          2       1.00      0.45      0.62        11\n",
      "          3       0.92      0.85      0.88        26\n",
      "\n",
      "avg / total       0.86      0.81      0.81        73\n",
      "\n",
      "[10  2  0  1  0 22  0  1  0  6  5  0  0  4  0 22]\n",
      "svc Accuracy:  0.8082191780821918\n",
      "svc F1:  0.786623760488177\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        13\n",
      "          1       0.57      0.74      0.64        23\n",
      "          2       1.00      0.18      0.31        11\n",
      "          3       0.71      0.85      0.77        26\n",
      "\n",
      "avg / total       0.76      0.70      0.68        73\n",
      "\n",
      "[10  2  0  1  0 17  0  6  0  7  2  2  0  4  0 22]\n",
      "LR Accuracy:  0.6986301369863014\n",
      "LR F1:  0.64767419590182\n",
      "For name:  x_kong\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0003-0676-6923': 34, '0000-0002-4475-2162': 10, '0000-0002-1725-4619': 6, '0000-0003-0659-4084': 6, '0000-0002-8554-0369': 6, '0000-0002-2195-268X': 3, '0000-0003-3290-025X': 2, '0000-0003-1039-494X': 1, '0000-0003-2698-3319': 1})\n",
      "['0000-0002-4475-2162', '0000-0003-0676-6923']\n",
      "Total sample size after apply threshold:  44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(44, 48)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.30      0.43        10\n",
      "          1       0.82      0.97      0.89        34\n",
      "\n",
      "avg / total       0.81      0.82      0.79        44\n",
      "\n",
      "[ 3  7  1 33]\n",
      "MNB Accuracy:  0.8181818181818182\n",
      "MNB F1:  0.6602316602316602\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.70      0.78        10\n",
      "          1       0.92      0.97      0.94        34\n",
      "\n",
      "avg / total       0.91      0.91      0.91        44\n",
      "\n",
      "[ 7  3  1 33]\n",
      "svc Accuracy:  0.9090909090909091\n",
      "svc F1:  0.8603174603174603\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.20      0.31        10\n",
      "          1       0.80      0.97      0.88        34\n",
      "\n",
      "avg / total       0.77      0.80      0.75        44\n",
      "\n",
      "[ 2  8  1 33]\n",
      "LR Accuracy:  0.7954545454545454\n",
      "LR F1:  0.5938461538461539\n",
      "For name:  w_cao\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0002-2447-1486': 91, '0000-0002-8952-9159': 27, '0000-0002-5369-9682': 7, '0000-0001-6209-3482': 1})\n",
      "['0000-0002-8952-9159', '0000-0002-2447-1486']\n",
      "Total sample size after apply threshold:  118\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(118, 166)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "118\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.59      0.74        27\n",
      "          1       0.89      1.00      0.94        91\n",
      "\n",
      "avg / total       0.92      0.91      0.90       118\n",
      "\n",
      "[16 11  0 91]\n",
      "MNB Accuracy:  0.9067796610169492\n",
      "MNB F1:  0.8435956139293892\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        27\n",
      "          1       0.98      1.00      0.99        91\n",
      "\n",
      "avg / total       0.98      0.98      0.98       118\n",
      "\n",
      "[25  2  0 91]\n",
      "svc Accuracy:  0.9830508474576272\n",
      "svc F1:  0.975334448160535\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.26      0.41        27\n",
      "          1       0.82      1.00      0.90        91\n",
      "\n",
      "avg / total       0.86      0.83      0.79       118\n",
      "\n",
      "[ 7 20  0 91]\n",
      "LR Accuracy:  0.8305084745762712\n",
      "LR F1:  0.6563774024461269\n",
      "For name:  c_ma\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0001-8818-6396': 31, '0000-0002-7480-5528': 28, '0000-0001-9245-0356': 18, '0000-0001-7092-7715': 16, '0000-0003-2054-0445': 15, '0000-0001-9612-7898': 9, '0000-0001-6478-5917': 3, '0000-0001-6507-2329': 2, '0000-0002-5936-789X': 2, '0000-0003-1073-4502': 1, '0000-0001-8942-3912': 1})\n",
      "['0000-0001-7092-7715', '0000-0003-2054-0445', '0000-0002-7480-5528', '0000-0001-9245-0356', '0000-0001-8818-6396']\n",
      "Total sample size after apply threshold:  108\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(108, 181)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "108\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88        16\n",
      "          1       0.75      0.20      0.32        15\n",
      "          2       0.67      1.00      0.80        28\n",
      "          3       1.00      0.78      0.88        18\n",
      "          4       0.91      0.94      0.92        31\n",
      "\n",
      "avg / total       0.83      0.81      0.79       108\n",
      "\n",
      "[14  1  0  0  1  2  3  9  0  1  0  0 28  0  0  0  0  3 14  1  0  0  2  0\n",
      " 29]\n",
      "MNB Accuracy:  0.8148148148148148\n",
      "MNB F1:  0.7572848788638262\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.68      0.87      0.76        15\n",
      "          2       0.93      0.96      0.95        28\n",
      "          3       0.89      0.89      0.89        18\n",
      "          4       1.00      0.90      0.95        31\n",
      "\n",
      "avg / total       0.92      0.91      0.91       108\n",
      "\n",
      "[14  2  0  0  0  0 13  2  0  0  0  0 27  1  0  0  2  0 16  0  0  2  0  1\n",
      " 28]\n",
      "svc Accuracy:  0.9074074074074074\n",
      "svc F1:  0.8966898136001353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.86      0.40      0.55        15\n",
      "          2       0.84      0.96      0.90        28\n",
      "          3       0.89      0.89      0.89        18\n",
      "          4       0.78      0.94      0.85        31\n",
      "\n",
      "avg / total       0.86      0.85      0.84       108\n",
      "\n",
      "[14  1  0  0  1  0  6  4  0  5  0  0 27  1  0  0  0  0 16  2  0  0  1  1\n",
      " 29]\n",
      "LR Accuracy:  0.8518518518518519\n",
      "LR F1:  0.8241235888294712\n",
      "For name:  j_chin\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0003-3932-8639': 13, '0000-0002-1840-325X': 9, '0000-0002-2878-8544': 3, '0000-0001-9809-6976': 1, '0000-0001-7626-6778': 1})\n",
      "['0000-0003-3932-8639']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  h_kwon\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0003-4979-8749': 13, '0000-0002-6919-833X': 7, '0000-0002-0960-0198': 5, '0000-0001-6941-4808': 3, '0000-0003-4026-4572': 3, '0000-0002-2936-1358': 1, '0000-0002-8509-3968': 1, '0000-0003-4465-2708': 1, '0000-0001-9772-1354': 1})\n",
      "['0000-0003-4979-8749']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  s_gao\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-7020-037X': 28, '0000-0002-8919-1338': 1, '0000-0002-3574-6393': 1, '0000-0003-3320-8505': 1})\n",
      "['0000-0002-7020-037X']\n",
      "Total sample size after apply threshold:  28\n",
      "For name:  f_tian\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-1247-6896': 9, '0000-0003-3580-022X': 4, '0000-0002-9680-4518': 1, '0000-0003-0534-9749': 1, '0000-0002-9686-2769': 1, '0000-0001-8985-9679': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  f_martins\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0003-0960-4620': 19, '0000-0003-4189-1228': 10, '0000-0003-2668-2401': 9, '0000-0002-1812-2300': 8, '0000-0003-2161-459X': 6, '0000-0002-9863-6255': 5, '0000-0002-3277-1809': 4, '0000-0002-0680-3643': 3, '0000-0003-4997-3973': 1})\n",
      "['0000-0003-4189-1228', '0000-0003-0960-4620']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 46)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       1.00      1.00      1.00        29\n",
      "\n",
      "[10  0  0 19]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       1.00      1.00      1.00        29\n",
      "\n",
      "[10  0  0 19]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.95      1.00      0.97        19\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[ 9  1  0 19]\n",
      "LR Accuracy:  0.9655172413793104\n",
      "LR F1:  0.9608636977058029\n",
      "For name:  s_wolf\n",
      "total sample size before apply threshold:  363\n",
      "Counter({'0000-0003-2972-3440': 173, '0000-0002-7467-7028': 102, '0000-0002-5337-5063': 46, '0000-0003-0832-6315': 15, '0000-0002-3747-8097': 12, '0000-0003-1752-6175': 9, '0000-0003-3921-6629': 3, '0000-0001-7717-6993': 2, '0000-0002-6748-3911': 1})\n",
      "['0000-0002-7467-7028', '0000-0002-5337-5063', '0000-0003-0832-6315', '0000-0003-2972-3440', '0000-0002-3747-8097']\n",
      "Total sample size after apply threshold:  348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(348, 909)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.94      0.95       102\n",
      "          1       1.00      0.39      0.56        46\n",
      "          2       0.00      0.00      0.00        15\n",
      "          3       0.76      1.00      0.86       173\n",
      "          4       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.79      0.82      0.78       348\n",
      "\n",
      "[ 96   0   0   6   0   4  18   0  24   0   0   0   0  15   0   0   0   0\n",
      " 173   0   1   0   0  11   0]\n",
      "MNB Accuracy:  0.8247126436781609\n",
      "MNB F1:  0.47380186505894173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.94      0.96       102\n",
      "          1       1.00      0.70      0.82        46\n",
      "          2       1.00      0.60      0.75        15\n",
      "          3       0.86      1.00      0.93       173\n",
      "          4       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.93      0.92      0.91       348\n",
      "\n",
      "[ 96   0   0   6   0   0  32   0  14   0   0   0   9   6   0   0   0   0\n",
      " 173   0   1   0   0   2   9]\n",
      "svc Accuracy:  0.9166666666666666\n",
      "svc F1:  0.863522697619653\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.84      0.91       102\n",
      "          1       1.00      0.33      0.49        46\n",
      "          2       1.00      0.07      0.12        15\n",
      "          3       0.71      1.00      0.83       173\n",
      "          4       1.00      0.25      0.40        12\n",
      "\n",
      "avg / total       0.85      0.80      0.77       348\n",
      "\n",
      "[ 86   0   0  16   0   1  15   0  30   0   0   0   1  14   0   0   0   0\n",
      " 173   0   0   0   0   9   3]\n",
      "LR Accuracy:  0.7988505747126436\n",
      "LR F1:  0.5521182257000941\n",
      "For name:  m_goldman\n",
      "total sample size before apply threshold:  81\n",
      "Counter({'0000-0002-6786-9320': 74, '0000-0001-6771-169X': 5, '0000-0002-3667-1477': 1, '0000-0001-8908-3356': 1})\n",
      "['0000-0002-6786-9320']\n",
      "Total sample size after apply threshold:  74\n",
      "For name:  d_tang\n",
      "total sample size before apply threshold:  89\n",
      "Counter({'0000-0002-7339-9249': 40, '0000-0001-7136-7481': 39, '0000-0002-4790-9014': 5, '0000-0002-5443-4619': 3, '0000-0002-7615-0246': 2})\n",
      "['0000-0002-7339-9249', '0000-0001-7136-7481']\n",
      "Total sample size after apply threshold:  79\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(79, 197)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.78      0.86        40\n",
      "          1       0.81      0.97      0.88        39\n",
      "\n",
      "avg / total       0.89      0.87      0.87        79\n",
      "\n",
      "[31  9  1 38]\n",
      "MNB Accuracy:  0.8734177215189873\n",
      "MNB F1:  0.8724160206718348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90        40\n",
      "          1       0.92      0.87      0.89        39\n",
      "\n",
      "avg / total       0.90      0.90      0.90        79\n",
      "\n",
      "[37  3  5 34]\n",
      "svc Accuracy:  0.8987341772151899\n",
      "svc F1:  0.8985879332477535\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.90      0.91        40\n",
      "          1       0.90      0.92      0.91        39\n",
      "\n",
      "avg / total       0.91      0.91      0.91        79\n",
      "\n",
      "[36  4  3 36]\n",
      "LR Accuracy:  0.9113924050632911\n",
      "LR F1:  0.9113924050632911\n",
      "For name:  m_adams\n",
      "total sample size before apply threshold:  190\n",
      "Counter({'0000-0003-0435-8651': 59, '0000-0001-8989-508X': 46, '0000-0001-6310-1472': 30, '0000-0002-7743-4515': 29, '0000-0003-2849-9096': 12, '0000-0002-5277-5487': 7, '0000-0002-3878-7684': 5, '0000-0002-3602-6849': 1, '0000-0002-4645-2593': 1})\n",
      "['0000-0002-7743-4515', '0000-0001-6310-1472', '0000-0003-2849-9096', '0000-0003-0435-8651', '0000-0001-8989-508X']\n",
      "Total sample size after apply threshold:  176\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(176, 359)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "176\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        29\n",
      "          1       1.00      0.77      0.87        30\n",
      "          2       1.00      0.08      0.15        12\n",
      "          3       0.64      1.00      0.78        59\n",
      "          4       0.98      0.93      0.96        46\n",
      "\n",
      "avg / total       0.87      0.81      0.79       176\n",
      "\n",
      "[16  0  0 13  0  0 23  0  7  0  0  0  1 10  1  0  0  0 59  0  0  0  0  3\n",
      " 43]\n",
      "MNB Accuracy:  0.8068181818181818\n",
      "MNB F1:  0.6939788604914183\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        29\n",
      "          1       1.00      0.87      0.93        30\n",
      "          2       1.00      0.92      0.96        12\n",
      "          3       0.95      0.92      0.93        59\n",
      "          4       0.78      1.00      0.88        46\n",
      "\n",
      "avg / total       0.92      0.91      0.91       176\n",
      "\n",
      "[23  0  0  2  4  0 26  0  1  3  0  0 11  0  1  0  0  0 54  5  0  0  0  0\n",
      " 46]\n",
      "svc Accuracy:  0.9090909090909091\n",
      "svc F1:  0.915386702253269\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.66      0.79        29\n",
      "          1       1.00      0.87      0.93        30\n",
      "          2       1.00      0.58      0.74        12\n",
      "          3       0.82      0.92      0.86        59\n",
      "          4       0.76      0.96      0.85        46\n",
      "\n",
      "avg / total       0.88      0.85      0.85       176\n",
      "\n",
      "[19  0  0  6  4  0 26  0  2  2  0  0  7  2  3  0  0  0 54  5  0  0  0  2\n",
      " 44]\n",
      "LR Accuracy:  0.8522727272727273\n",
      "LR F1:  0.8334468093310198\n",
      "For name:  t_singh\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-7935-0457': 13, '0000-0001-7420-6739': 11, '0000-0001-7051-6529': 11, '0000-0002-0413-1935': 10, '0000-0003-1007-4540': 2, '0000-0002-5870-6204': 1, '0000-0003-0377-6122': 1, '0000-0002-9740-7776': 1, '0000-0002-7740-4826': 1, '0000-0003-1109-5626': 1})\n",
      "['0000-0002-0413-1935', '0000-0001-7420-6739', '0000-0001-7935-0457', '0000-0001-7051-6529']\n",
      "Total sample size after apply threshold:  45"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(45, 89)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       0.63      0.92      0.75        13\n",
      "          3       0.77      0.91      0.83        11\n",
      "\n",
      "avg / total       0.84      0.78      0.77        45\n",
      "\n",
      "[ 5  0  3  2  0  8  3  0  0  0 12  1  0  0  1 10]\n",
      "MNB Accuracy:  0.7777777777777778\n",
      "MNB F1:  0.7730263157894737\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86        10\n",
      "          1       0.89      0.73      0.80        11\n",
      "          2       0.80      0.92      0.86        13\n",
      "          3       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.87      0.87      0.87        45\n",
      "\n",
      "[ 9  1  0  0  0  8  3  0  1  0 12  0  1  0  0 10]\n",
      "svc Accuracy:  0.8666666666666667\n",
      "svc F1:  0.8666666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.70      0.78        10\n",
      "          1       0.73      0.73      0.73        11\n",
      "          2       0.75      0.92      0.83        13\n",
      "          3       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.83      0.82      0.82        45\n",
      "\n",
      "[ 7  2  1  0  0  8  3  0  0  1 12  0  1  0  0 10]\n",
      "LR Accuracy:  0.8222222222222222\n",
      "LR F1:  0.8212544160820023\n",
      "For name:  m_thompson\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-7764-4096': 80, '0000-0001-8958-0336': 29, '0000-0002-4933-009X': 11, '0000-0002-2865-9558': 10, '0000-0002-5649-1203': 6, '0000-0002-1789-312X': 6, '0000-0002-6910-4938': 4, '0000-0002-1194-1506': 1, '0000-0002-8551-4806': 1, '0000-0002-1358-1962': 1, '0000-0001-7006-3646': 1})\n",
      "['0000-0001-8958-0336', '0000-0002-4933-009X', '0000-0002-2865-9558', '0000-0002-7764-4096']\n",
      "Total sample size after apply threshold:  130\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 377)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "130\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.59      0.74        29\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.10      0.18        10\n",
      "          3       0.71      1.00      0.83        80\n",
      "\n",
      "avg / total       0.74      0.75      0.69       130\n",
      "\n",
      "[17  0  0 12  0  0  0 11  0  0  1  9  0  0  0 80]\n",
      "MNB Accuracy:  0.7538461538461538\n",
      "MNB F1:  0.43857048748353095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.86        29\n",
      "          1       1.00      0.36      0.53        11\n",
      "          2       1.00      0.80      0.89        10\n",
      "          3       0.83      1.00      0.91        80\n",
      "\n",
      "avg / total       0.90      0.88      0.87       130\n",
      "\n",
      "[22  0  0  7  0  4  0  7  0  0  8  2  0  0  0 80]\n",
      "svc Accuracy:  0.8769230769230769\n",
      "svc F1:  0.7985145573380867\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.28      0.43        29\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.66      1.00      0.79        80\n",
      "\n",
      "avg / total       0.63      0.68      0.58       130\n",
      "\n",
      "[ 8  0  0 21  0  0  0 11  0  0  0 10  0  0  0 80]\n",
      "LR Accuracy:  0.676923076923077\n",
      "LR F1:  0.30612791008830614\n",
      "For name:  s_garcia\n",
      "total sample size before apply threshold:  20\n",
      "Counter({'0000-0002-3143-0527': 16, '0000-0003-4190-6055': 2, '0000-0001-5161-0085': 1, '0000-0001-7317-1423': 1})\n",
      "['0000-0002-3143-0527']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  e_wang\n",
      "total sample size before apply threshold:  155\n",
      "Counter({'0000-0002-2243-4964': 64, '0000-0002-1180-5854': 53, '0000-0003-3394-2670': 14, '0000-0002-4942-3771': 10, '0000-0001-9335-5457': 6, '0000-0003-1302-9745': 4, '0000-0002-6653-5791': 2, '0000-0002-5178-3530': 1, '0000-0002-1084-7059': 1})\n",
      "['0000-0002-1180-5854', '0000-0003-3394-2670', '0000-0002-4942-3771', '0000-0002-2243-4964']\n",
      "Total sample size after apply threshold:  141\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(141, 382)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "141\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95        53\n",
      "          1       0.93      0.93      0.93        14\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.90      1.00      0.95        64\n",
      "\n",
      "avg / total       0.85      0.91      0.88       141\n",
      "\n",
      "[52  0  0  1  0 13  0  1  4  1  0  5  0  0  0 64]\n",
      "MNB Accuracy:  0.9148936170212766\n",
      "MNB F1:  0.7077120042716373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        53\n",
      "          1       1.00      0.93      0.96        14\n",
      "          2       1.00      0.50      0.67        10\n",
      "          3       0.88      1.00      0.93        64\n",
      "\n",
      "avg / total       0.94      0.94      0.93       141\n",
      "\n",
      "[50  0  0  3  0 13  0  1  0  0  5  5  0  0  0 64]\n",
      "svc Accuracy:  0.9361702127659575\n",
      "svc F1:  0.8837024963451157\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        53\n",
      "          1       1.00      0.79      0.88        14\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.77      1.00      0.87        64\n",
      "\n",
      "avg / total       0.83      0.87      0.84       141\n",
      "\n",
      "[47  0  0  6  0 11  0  3  0  0  0 10  0  0  0 64]\n",
      "LR Accuracy:  0.8652482269503546\n",
      "LR F1:  0.6726870748299321\n",
      "For name:  c_scott\n",
      "total sample size before apply threshold:  162\n",
      "Counter({'0000-0003-1340-0647': 98, '0000-0001-6110-6982': 39, '0000-0001-9363-1829': 21, '0000-0003-0860-4805': 3, '0000-0003-3254-8647': 1})\n",
      "['0000-0001-9363-1829', '0000-0001-6110-6982', '0000-0003-1340-0647']\n",
      "Total sample size after apply threshold:  158\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(158, 578)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "158\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.17        21\n",
      "          1       0.97      0.90      0.93        39\n",
      "          2       0.82      1.00      0.90        98\n",
      "\n",
      "avg / total       0.88      0.85      0.81       158\n",
      "\n",
      "[ 2  1 18  0 35  4  0  0 98]\n",
      "MNB Accuracy:  0.8544303797468354\n",
      "MNB F1:  0.6687763152063111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        21\n",
      "          1       1.00      0.85      0.92        39\n",
      "          2       0.87      1.00      0.93        98\n",
      "\n",
      "avg / total       0.92      0.91      0.90       158\n",
      "\n",
      "[12  0  9  0 33  6  0  0 98]\n",
      "svc Accuracy:  0.9050632911392406\n",
      "svc F1:  0.8576164488486763\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        21\n",
      "          1       1.00      0.62      0.76        39\n",
      "          2       0.73      1.00      0.84        98\n",
      "\n",
      "avg / total       0.70      0.77      0.71       158\n",
      "\n",
      "[ 0  0 21  0 24 15  0  0 98]\n",
      "LR Accuracy:  0.7721518987341772\n",
      "LR F1:  0.5355774493705528\n",
      "For name:  m_mukherjee\n",
      "total sample size before apply threshold:  16\n",
      "Counter({'0000-0003-3706-406X': 4, '0000-0002-7924-7211': 4, '0000-0002-3083-436X': 3, '0000-0003-0376-8173': 2, '0000-0002-3615-7574': 2, '0000-0001-9653-0556': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  j_schroeder\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-3283-5972': 146, '0000-0002-4136-843X': 2, '0000-0002-3860-8498': 1, '0000-0002-1975-721X': 1})\n",
      "['0000-0002-3283-5972']\n",
      "Total sample size after apply threshold:  146\n",
      "For name:  a_mayer\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-6859-0612': 10, '0000-0003-3278-1182': 4, '0000-0002-6975-7082': 2, '0000-0002-8765-6373': 1})\n",
      "['0000-0002-6859-0612']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  e_wright\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0001-7041-5138': 20, '0000-0002-2390-8017': 3, '0000-0002-2187-7114': 3, '0000-0003-1721-4104': 2})\n",
      "['0000-0001-7041-5138']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  c_moreno\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5582-0028': 37, '0000-0003-0541-4846': 35, '0000-0001-6472-6044': 16, '0000-0003-1839-9673': 16, '0000-0002-1660-7072': 13, '0000-0003-2682-211X': 6, '0000-0002-0876-0341': 6, '0000-0003-4816-8040': 6, '0000-0002-9584-2619': 1})\n",
      "['0000-0001-6472-6044', '0000-0002-1660-7072', '0000-0003-1839-9673', '0000-0003-0541-4846', '0000-0002-5582-0028']\n",
      "Total sample size after apply threshold:  117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(117, 517)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "117\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       1.00      0.62      0.77        16\n",
      "          3       0.90      1.00      0.95        35\n",
      "          4       0.77      0.97      0.86        37\n",
      "\n",
      "avg / total       0.90      0.87      0.87       117\n",
      "\n",
      "[13  0  0  1  2  0  8  0  2  3  0  0 10  0  6  0  0  0 35  0  0  0  0  1\n",
      " 36]\n",
      "MNB Accuracy:  0.8717948717948718\n",
      "MNB F1:  0.846155211672453\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        16\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       1.00      0.81      0.90        16\n",
      "          3       1.00      0.89      0.94        35\n",
      "          4       0.70      1.00      0.82        37\n",
      "\n",
      "avg / total       0.90      0.86      0.87       117\n",
      "\n",
      "[12  0  0  0  4  0  8  0  0  5  0  0 13  0  3  0  0  0 31  4  0  0  0  0\n",
      " 37]\n",
      "svc Accuracy:  0.8632478632478633\n",
      "svc F1:  0.8554431009603423\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        16\n",
      "          1       1.00      0.38      0.56        13\n",
      "          2       1.00      0.25      0.40        16\n",
      "          3       0.97      0.94      0.96        35\n",
      "          4       0.60      1.00      0.75        37\n",
      "\n",
      "avg / total       0.86      0.78      0.76       117\n",
      "\n",
      "[12  0  0  1  3  0  5  0  0  8  0  0  4  0 12  0  0  0 33  2  0  0  0  0\n",
      " 37]\n",
      "LR Accuracy:  0.7777777777777778\n",
      "LR F1:  0.7033389798607189\n",
      "For name:  a_moura\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0003-0339-1230': 15, '0000-0002-2105-7319': 14, '0000-0003-2140-0196': 4, '0000-0002-1513-5448': 3})\n",
      "['0000-0002-2105-7319', '0000-0003-0339-1230']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 68)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[13  1  0 15]\n",
      "MNB Accuracy:  0.9655172413793104\n",
      "MNB F1:  0.965352449223417\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        29\n",
      "\n",
      "[14  0  0 15]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[13  1  0 15]\n",
      "LR Accuracy:  0.9655172413793104\n",
      "LR F1:  0.965352449223417\n",
      "For name:  j_lopez\n",
      "total sample size before apply threshold:  122\n",
      "Counter({'0000-0002-9097-6060': 27, '0000-0003-0842-5348': 23, '0000-0002-5234-1478': 17, '0000-0001-9370-1516': 9, '0000-0001-6884-5577': 6, '0000-0003-3001-1109': 6, '0000-0002-1637-4125': 6, '0000-0003-0821-7530': 4, '0000-0002-5390-6610': 4, '0000-0002-7645-1620': 4, '0000-0002-4104-6262': 3, '0000-0001-5684-4913': 3, '0000-0001-8723-6347': 2, '0000-0003-2213-1186': 2, '0000-0003-0370-4727': 2, '0000-0003-4662-7928': 1, '0000-0003-1028-779X': 1, '0000-0002-4627-2277': 1, '0000-0001-8066-9991': 1})\n",
      "['0000-0003-0842-5348', '0000-0002-9097-6060', '0000-0002-5234-1478']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sample size after apply threshold:  67\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(67, 329)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.87      0.87        23\n",
      "          1       0.89      0.89      0.89        27\n",
      "          2       1.00      1.00      1.00        17\n",
      "\n",
      "avg / total       0.91      0.91      0.91        67\n",
      "\n",
      "[20  3  0  3 24  0  0  0 17]\n",
      "MNB Accuracy:  0.9104477611940298\n",
      "MNB F1:  0.9194847020933977\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.78      0.82        23\n",
      "          1       0.78      0.93      0.85        27\n",
      "          2       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.86      0.85      0.85        67\n",
      "\n",
      "[18  5  0  2 25  0  1  2 14]\n",
      "svc Accuracy:  0.8507462686567164\n",
      "svc F1:  0.8562884172506918\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.57      0.70        23\n",
      "          1       0.69      1.00      0.82        27\n",
      "          2       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.85      0.81      0.80        67\n",
      "\n",
      "[13 10  0  0 27  0  1  2 14]\n",
      "LR Accuracy:  0.8059701492537313\n",
      "LR F1:  0.8080367757787111\n",
      "For name:  a_logan\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0002-1179-5879': 22, '0000-0001-9140-5545': 2, '0000-0002-4403-7329': 1, '0000-0003-3215-5042': 1})\n",
      "['0000-0002-1179-5879']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  l_williams\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-7860-0319': 21, '0000-0002-0021-5613': 9, '0000-0002-8643-4920': 2, '0000-0002-8577-6339': 2, '0000-0001-8439-5270': 2, '0000-0001-6790-1362': 2, '0000-0002-3964-2356': 1, '0000-0003-2404-1985': 1, '0000-0003-2860-1150': 1, '0000-0002-6317-1718': 1})\n",
      "['0000-0002-7860-0319']\n",
      "Total sample size after apply threshold:  21\n",
      "For name:  h_young\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0002-0457-8710': 75, '0000-0003-1538-445X': 28, '0000-0002-4249-9060': 5, '0000-0002-8866-7648': 1})\n",
      "['0000-0003-1538-445X', '0000-0002-0457-8710']\n",
      "Total sample size after apply threshold:  103\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(103, 268)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        28\n",
      "          1       0.85      1.00      0.92        75\n",
      "\n",
      "avg / total       0.89      0.87      0.86       103\n",
      "\n",
      "[15 13  0 75]\n",
      "MNB Accuracy:  0.8737864077669902\n",
      "MNB F1:  0.8089599086888286\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        28\n",
      "          1       0.89      1.00      0.94        75\n",
      "\n",
      "avg / total       0.92      0.91      0.91       103\n",
      "\n",
      "[19  9  0 75]\n",
      "svc Accuracy:  0.912621359223301\n",
      "svc F1:  0.8759534323564835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        28\n",
      "          1       0.78      1.00      0.88        75\n",
      "\n",
      "avg / total       0.84      0.80      0.75       103\n",
      "\n",
      "[ 7 21  0 75]\n",
      "LR Accuracy:  0.7961165048543689\n",
      "LR F1:  0.6385964912280702\n",
      "For name:  a_vincent\n",
      "total sample size before apply threshold:  79\n",
      "Counter({'0000-0002-4185-3267': 39, '0000-0001-6446-3846': 21, '0000-0002-3760-7266': 12, '0000-0002-0360-6644': 7})\n",
      "['0000-0002-4185-3267', '0000-0002-3760-7266', '0000-0001-6446-3846']\n",
      "Total sample size after apply threshold:  72\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(72, 228)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.92        39\n",
      "          1       1.00      0.67      0.80        12\n",
      "          2       0.95      0.90      0.93        21\n",
      "\n",
      "avg / total       0.91      0.90      0.90        72\n",
      "\n",
      "[38  0  1  4  8  0  2  0 19]\n",
      "MNB Accuracy:  0.9027777777777778\n",
      "MNB F1:  0.8808306396316975\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.89        39\n",
      "          1       1.00      0.67      0.80        12\n",
      "          2       0.94      0.81      0.87        21\n",
      "\n",
      "avg / total       0.89      0.88      0.87        72\n",
      "\n",
      "[38  0  1  4  8  0  4  0 17]\n",
      "svc Accuracy:  0.875\n",
      "svc F1:  0.8553041729512317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        39\n",
      "          1       1.00      0.58      0.74        12\n",
      "          2       1.00      0.57      0.73        21\n",
      "\n",
      "avg / total       0.86      0.81      0.79        72\n",
      "\n",
      "[39  0  0  5  7  0  9  0 12]\n",
      "LR Accuracy:  0.8055555555555556\n",
      "LR F1:  0.7706469731641356\n",
      "For name:  a_monteiro\n",
      "total sample size before apply threshold:  132\n",
      "Counter({'0000-0002-8448-4801': 76, '0000-0001-9696-459X': 35, '0000-0001-8182-3380': 7, '0000-0002-2185-0720': 5, '0000-0002-7839-2556': 4, '0000-0002-2322-3624': 2, '0000-0002-3392-2664': 1, '0000-0002-1976-6538': 1, '0000-0003-0499-6522': 1})\n",
      "['0000-0001-9696-459X', '0000-0002-8448-4801']\n",
      "Total sample size after apply threshold:  111\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(111, 942)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        35\n",
      "          1       0.80      1.00      0.89        76\n",
      "\n",
      "avg / total       0.86      0.83      0.81       111\n",
      "\n",
      "[16 19  0 76]\n",
      "MNB Accuracy:  0.8288288288288288\n",
      "MNB F1:  0.7581699346405228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.63      0.77        35\n",
      "          1       0.85      1.00      0.92        76\n",
      "\n",
      "avg / total       0.90      0.88      0.87       111\n",
      "\n",
      "[22 13  0 76]\n",
      "svc Accuracy:  0.8828828828828829\n",
      "svc F1:  0.8465709728867623\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.23      0.37        35\n",
      "          1       0.74      1.00      0.85        76\n",
      "\n",
      "avg / total       0.82      0.76      0.70       111\n",
      "\n",
      "[ 8 27  0 76]\n",
      "LR Accuracy:  0.7567567567567568\n",
      "LR F1:  0.6106275172144991\n",
      "For name:  d_park\n",
      "total sample size before apply threshold:  156\n",
      "Counter({'0000-0003-2307-8575': 95, '0000-0002-6001-4223': 17, '0000-0001-9209-0493': 14, '0000-0003-0147-2424': 13, '0000-0002-7507-1175': 9, '0000-0002-7325-5480': 2, '0000-0001-9675-7179': 2, '0000-0002-5560-873X': 1, '0000-0003-4991-5247': 1, '0000-0002-1007-8595': 1, '0000-0001-9969-3051': 1})\n",
      "['0000-0001-9209-0493', '0000-0002-6001-4223', '0000-0003-0147-2424', '0000-0003-2307-8575']\n",
      "Total sample size after apply threshold:  139\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 128)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.35        14\n",
      "          1       0.80      0.24      0.36        17\n",
      "          2       1.00      0.08      0.14        13\n",
      "          3       0.73      1.00      0.84        95\n",
      "\n",
      "avg / total       0.79      0.74      0.67       139\n",
      "\n",
      "[ 3  1  0 10  0  4  0 13  0  0  1 12  0  0  0 95]\n",
      "MNB Accuracy:  0.7410071942446043\n",
      "MNB F1:  0.42596978185213474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        14\n",
      "          1       0.92      0.65      0.76        17\n",
      "          2       1.00      0.77      0.87        13\n",
      "          3       0.88      1.00      0.94        95\n",
      "\n",
      "avg / total       0.91      0.90      0.89       139\n",
      "\n",
      "[ 9  1  0  4  0 11  0  6  0  0 10  3  0  0  0 95]\n",
      "svc Accuracy:  0.8992805755395683\n",
      "svc F1:  0.836688798457914\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.13        14\n",
      "          1       1.00      0.47      0.64        17\n",
      "          2       1.00      0.31      0.47        13\n",
      "          3       0.75      1.00      0.86        95\n",
      "\n",
      "avg / total       0.83      0.78      0.72       139\n",
      "\n",
      "[ 1  0  0 13  0  8  0  9  0  0  4  9  0  0  0 95]\n",
      "LR Accuracy:  0.7769784172661871\n",
      "LR F1:  0.5259125188536953\n",
      "For name:  d_gao\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0003-1821-2741': 14, '0000-0002-9391-1756': 7, '0000-0001-8725-5740': 1, '0000-0002-2472-7349': 1})\n",
      "['0000-0003-1821-2741']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  d_quinn\n",
      "total sample size before apply threshold:  145\n",
      "Counter({'0000-0002-1411-0417': 139, '0000-0002-6338-5265': 2, '0000-0003-0321-2255': 2, '0000-0001-7790-7768': 2})\n",
      "['0000-0002-1411-0417']\n",
      "Total sample size after apply threshold:  139\n",
      "For name:  n_dias\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-0498-4612': 13, '0000-0002-6907-6148': 2, '0000-0002-4731-0968': 1, '0000-0002-9019-8406': 1})\n",
      "['0000-0002-0498-4612']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  k_fisher\n",
      "total sample size before apply threshold:  24\n",
      "Counter({'0000-0002-2751-156X': 11, '0000-0001-7381-9648': 8, '0000-0002-0828-6395': 3, '0000-0002-1774-4431': 1, '0000-0002-5581-8892': 1})\n",
      "['0000-0002-2751-156X']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  m_schubert\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0003-0278-4091': 22, '0000-0003-2401-9921': 18, '0000-0002-0994-8805': 14, '0000-0001-6238-663X': 12, '0000-0002-8739-4852': 7, '0000-0002-6862-5221': 6, '0000-0002-2911-8075': 5})\n",
      "['0000-0003-2401-9921', '0000-0003-0278-4091', '0000-0001-6238-663X', '0000-0002-0994-8805']\n",
      "Total sample size after apply threshold:  66\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(66, 416)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91        18\n",
      "          1       0.73      1.00      0.85        22\n",
      "          2       1.00      0.67      0.80        12\n",
      "          3       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.91      0.88      0.88        66\n",
      "\n",
      "[15  3  0  0  0 22  0  0  0  4  8  0  0  1  0 13]\n",
      "MNB Accuracy:  0.8787878787878788\n",
      "MNB F1:  0.8795519295519294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        18\n",
      "          1       0.76      1.00      0.86        22\n",
      "          2       1.00      0.67      0.80        12\n",
      "          3       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.92      0.89      0.89        66\n",
      "\n",
      "[16  2  0  0  0 22  0  0  0  4  8  0  0  1  0 13]\n",
      "svc Accuracy:  0.8939393939393939\n",
      "svc F1:  0.8917211328976034\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        18\n",
      "          1       0.69      1.00      0.81        22\n",
      "          2       1.00      0.50      0.67        12\n",
      "          3       1.00      0.86      0.92        14\n",
      "\n",
      "avg / total       0.90      0.85      0.85        66\n",
      "\n",
      "[16  2  0  0  0 22  0  0  0  6  6  0  0  2  0 12]\n",
      "LR Accuracy:  0.8484848484848485\n",
      "LR F1:  0.8364337187866598\n",
      "For name:  j_peters\n",
      "total sample size before apply threshold:  154\n",
      "Counter({'0000-0001-8503-1452': 57, '0000-0002-6725-2814': 36, '0000-0001-8309-3297': 22, '0000-0003-3150-3973': 17, '0000-0003-4592-7275': 13, '0000-0002-5266-8091': 8, '0000-0002-1456-5390': 1})\n",
      "['0000-0001-8309-3297', '0000-0002-6725-2814', '0000-0003-3150-3973', '0000-0001-8503-1452', '0000-0003-4592-7275']\n",
      "Total sample size after apply threshold:  145\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(145, 366)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "145\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        22\n",
      "          1       1.00      0.86      0.93        36\n",
      "          2       1.00      0.76      0.87        17\n",
      "          3       0.68      1.00      0.81        57\n",
      "          4       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.87      0.81      0.81       145\n",
      "\n",
      "[ 9  0  0 13  0  0 31  0  5  0  0  0 13  4  0  0  0  0 57  0  0  0  0  5\n",
      "  8]\n",
      "MNB Accuracy:  0.8137931034482758\n",
      "MNB F1:  0.7886200724975964\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        22\n",
      "          1       0.97      0.83      0.90        36\n",
      "          2       1.00      0.88      0.94        17\n",
      "          3       0.77      1.00      0.87        57\n",
      "          4       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.90      0.88      0.87       145\n",
      "\n",
      "[17  1  0  4  0  0 30  0  6  0  0  0 15  2  0  0  0  0 57  0  0  0  0  5\n",
      "  8]\n",
      "svc Accuracy:  0.8758620689655172\n",
      "svc F1:  0.8673902058785845\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        22\n",
      "          1       1.00      0.75      0.86        36\n",
      "          2       1.00      0.76      0.87        17\n",
      "          3       0.65      1.00      0.79        57\n",
      "          4       1.00      0.54      0.70        13\n",
      "\n",
      "avg / total       0.86      0.79      0.78       145\n",
      "\n",
      "[10  0  0 12  0  0 27  0  9  0  0  0 13  4  0  0  0  0 57  0  0  0  0  6\n",
      "  7]\n",
      "LR Accuracy:  0.7862068965517242\n",
      "LR F1:  0.7670032840722497\n",
      "For name:  e_zimmermann\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0001-9927-3372': 24, '0000-0001-5854-0542': 16, '0000-0002-1964-2711': 15, '0000-0002-4268-9729': 2})\n",
      "['0000-0002-1964-2711', '0000-0001-5854-0542', '0000-0001-9927-3372']\n",
      "Total sample size after apply threshold:  55\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 239)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        15\n",
      "          1       1.00      0.81      0.90        16\n",
      "          2       0.89      1.00      0.94        24\n",
      "\n",
      "avg / total       0.93      0.93      0.93        55\n",
      "\n",
      "[14  0  1  1 13  2  0  0 24]\n",
      "MNB Accuracy:  0.9272727272727272\n",
      "MNB F1:  0.9236871760198332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        15\n",
      "          1       0.88      0.94      0.91        16\n",
      "          2       0.92      0.92      0.92        24\n",
      "\n",
      "avg / total       0.93      0.93      0.93        55\n",
      "\n",
      "[14  0  1  0 15  1  0  2 22]\n",
      "svc Accuracy:  0.9272727272727272\n",
      "svc F1:  0.9304249390456287\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        15\n",
      "          1       1.00      0.75      0.86        16\n",
      "          2       0.83      1.00      0.91        24\n",
      "\n",
      "avg / total       0.92      0.91      0.91        55\n",
      "\n",
      "[14  0  1  0 12  4  0  0 24]\n",
      "LR Accuracy:  0.9090909090909091\n",
      "LR F1:  0.909440158626886\n",
      "For name:  c_zhang\n",
      "total sample size before apply threshold:  321\n",
      "Counter({'0000-0002-7784-1188': 120, '0000-0003-2349-3138': 52, '0000-0002-1581-5806': 25, '0000-0001-9042-4007': 13, '0000-0002-6502-288X': 10, '0000-0002-5957-2287': 9, '0000-0002-3721-8586': 8, '0000-0002-4067-2798': 7, '0000-0003-3435-0247': 7, '0000-0002-7687-0518': 7, '0000-0001-8663-3674': 6, '0000-0001-8222-4566': 5, '0000-0003-0679-7623': 4, '0000-0003-3212-4270': 4, '0000-0001-6885-1678': 4, '0000-0003-1616-4715': 4, '0000-0001-8206-5171': 4, '0000-0001-6685-0137': 3, '0000-0002-7913-4858': 3, '0000-0002-7167-0840': 3, '0000-0002-1207-4264': 3, '0000-0003-0399-1201': 3, '0000-0002-9461-1755': 2, '0000-0003-4968-8793': 2, '0000-0003-2693-6643': 2, '0000-0003-3871-0342': 2, '0000-0001-5249-141X': 2, '0000-0003-1095-9939': 1, '0000-0002-3065-3497': 1, '0000-0002-1607-5563': 1, '0000-0002-7704-9318': 1, '0000-0001-5552-1960': 1, '0000-0002-1458-8170': 1, '0000-0003-2346-6770': 1})\n",
      "['0000-0002-7784-1188', '0000-0002-1581-5806', '0000-0001-9042-4007', '0000-0003-2349-3138', '0000-0002-6502-288X']\n",
      "Total sample size after apply threshold:  220\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(220, 248)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "220\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.99      0.82       120\n",
      "          1       1.00      0.32      0.48        25\n",
      "          2       1.00      0.38      0.56        13\n",
      "          3       0.97      0.65      0.78        52\n",
      "          4       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.78      0.75      0.72       220\n",
      "\n",
      "[119   0   0   1   0  17   8   0   0   0   8   0   5   0   0  18   0   0\n",
      "  34   0  10   0   0   0   0]\n",
      "MNB Accuracy:  0.7545454545454545\n",
      "MNB F1:  0.5274163457914047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       120\n",
      "          1       1.00      0.72      0.84        25\n",
      "          2       1.00      0.46      0.63        13\n",
      "          3       1.00      0.92      0.96        52\n",
      "          4       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.91      0.89      0.88       220\n",
      "\n",
      "[120   0   0   0   0   7  18   0   0   0   7   0   6   0   0   4   0   0\n",
      "  48   0   6   0   0   0   4]\n",
      "svc Accuracy:  0.8909090909090909\n",
      "svc F1:  0.7818615460426966\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83       120\n",
      "          1       1.00      0.40      0.57        25\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       1.00      0.81      0.89        52\n",
      "          4       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.74      0.78      0.73       220\n",
      "\n",
      "[120   0   0   0   0  15  10   0   0   0  13   0   0   0   0  10   0   0\n",
      "  42   0  10   0   0   0   0]\n",
      "LR Accuracy:  0.7818181818181819\n",
      "LR F1:  0.45967578520770014\n",
      "For name:  h_shin\n",
      "total sample size before apply threshold:  114\n",
      "Counter({'0000-0001-7615-9809': 34, '0000-0001-7080-6075': 24, '0000-0003-1226-3206': 20, '0000-0002-3353-0310': 13, '0000-0002-6750-118X': 10, '0000-0001-6504-3413': 9, '0000-0002-3398-1074': 2, '0000-0002-1410-9731': 1, '0000-0002-5161-661X': 1})\n",
      "['0000-0002-6750-118X', '0000-0001-7080-6075', '0000-0001-7615-9809', '0000-0003-1226-3206', '0000-0002-3353-0310']\n",
      "Total sample size after apply threshold:  101\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 88)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        10\n",
      "          1       0.74      0.83      0.78        24\n",
      "          2       0.55      0.97      0.70        34\n",
      "          3       0.83      0.50      0.62        20\n",
      "          4       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.63      0.63      0.56       101\n",
      "\n",
      "[ 1  3  6  0  0  0 20  3  1  0  0  0 33  0  1  0  4  6 10  0  0  0 12  1\n",
      "  0]\n",
      "MNB Accuracy:  0.6336633663366337\n",
      "MNB F1:  0.4586519133765692\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.80      0.84        10\n",
      "          1       0.95      0.83      0.89        24\n",
      "          2       1.00      0.94      0.97        34\n",
      "          3       0.65      0.85      0.74        20\n",
      "          4       0.69      0.69      0.69        13\n",
      "\n",
      "avg / total       0.87      0.85      0.86       101\n",
      "\n",
      "[ 8  0  0  2  0  1 20  0  2  1  0  0 32  1  1  0  1  0 17  2  0  0  0  4\n",
      "  9]\n",
      "svc Accuracy:  0.8514851485148515\n",
      "svc F1:  0.8264258497668109\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       0.84      0.88      0.86        24\n",
      "          2       0.73      0.97      0.84        34\n",
      "          3       0.60      0.60      0.60        20\n",
      "          4       0.67      0.31      0.42        13\n",
      "\n",
      "avg / total       0.75      0.74      0.72       101\n",
      "\n",
      "[ 5  2  3  0  0  0 21  0  2  1  0  0 33  1  0  0  2  5 12  1  0  0  4  5\n",
      "  4]\n",
      "LR Accuracy:  0.7425742574257426\n",
      "LR F1:  0.6760610386726309\n",
      "For name:  r_reis\n",
      "total sample size before apply threshold:  615\n",
      "Counter({'0000-0002-4295-6129': 423, '0000-0002-9639-7940': 113, '0000-0002-9872-9865': 27, '0000-0001-9689-4085': 21, '0000-0002-0681-4721': 10, '0000-0003-0328-1840': 7, '0000-0003-0937-8045': 7, '0000-0003-3746-6894': 4, '0000-0002-6618-2412': 2, '0000-0002-6935-3459': 1})\n",
      "['0000-0002-9639-7940', '0000-0001-9689-4085', '0000-0002-9872-9865', '0000-0002-0681-4721', '0000-0002-4295-6129']\n",
      "Total sample size after apply threshold:  594\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(594, 1136)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.68      0.79       113\n",
      "          1       1.00      0.10      0.17        21\n",
      "          2       1.00      0.11      0.20        27\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.83      1.00      0.91       423\n",
      "\n",
      "avg / total       0.85      0.85      0.81       594\n",
      "\n",
      "[ 77   0   0   0  36   3   2   0   0  16   1   0   3   0  23   0   0   0\n",
      "   0  10   0   0   0   0 423]\n",
      "MNB Accuracy:  0.8501683501683501\n",
      "MNB F1:  0.41528555974042164\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.83      0.89       113\n",
      "          1       1.00      0.57      0.73        21\n",
      "          2       1.00      0.52      0.68        27\n",
      "          3       1.00      0.70      0.82        10\n",
      "          4       0.91      1.00      0.95       423\n",
      "\n",
      "avg / total       0.93      0.93      0.92       594\n",
      "\n",
      "[ 94   0   0   0  19   1  12   0   0   8   1   0  14   0  12   2   0   0\n",
      "   7   1   0   0   0   0 423]\n",
      "svc Accuracy:  0.9259259259259259\n",
      "svc F1:  0.8159155004213859\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.56      0.72       113\n",
      "          1       1.00      0.38      0.55        21\n",
      "          2       1.00      0.19      0.31        27\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.82      1.00      0.90       423\n",
      "\n",
      "avg / total       0.85      0.84      0.81       594\n",
      "\n",
      "[ 63   0   0   0  50   0   8   0   0  13   0   0   5   0  22   0   0   0\n",
      "   0  10   0   0   0   0 423]\n",
      "LR Accuracy:  0.8400673400673401\n",
      "LR F1:  0.4958353599019253\n",
      "For name:  z_ren\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-7606-0331': 25, '0000-0001-7265-065X': 4, '0000-0002-4559-4637': 1, '0000-0003-4208-5076': 1})\n",
      "['0000-0001-7606-0331']\n",
      "Total sample size after apply threshold:  25\n",
      "For name:  m_kumar\n",
      "total sample size before apply threshold:  104\n",
      "Counter({'0000-0003-3769-052X': 22, '0000-0003-1656-1649': 16, '0000-0003-0970-4875': 14, '0000-0001-9173-3872': 10, '0000-0002-0855-3406': 9, '0000-0002-9049-2760': 6, '0000-0002-3554-0563': 4, '0000-0002-4198-5892': 4, '0000-0003-3490-5062': 3, '0000-0002-7630-7389': 2, '0000-0001-6657-1277': 2, '0000-0002-0141-5318': 2, '0000-0001-6745-7425': 2, '0000-0001-5606-401X': 2, '0000-0001-6389-2040': 2, '0000-0002-7936-9892': 1, '0000-0001-5545-3793': 1, '0000-0002-7728-5572': 1, '0000-0001-6578-9741': 1})\n",
      "['0000-0003-1656-1649', '0000-0003-3769-052X', '0000-0003-0970-4875', '0000-0001-9173-3872']\n",
      "Total sample size after apply threshold:  62\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 118)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.76      1.00      0.86        22\n",
      "          2       1.00      1.00      1.00        14\n",
      "          3       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.91      0.89      0.88        62\n",
      "\n",
      "[14  2  0  0  0 22  0  0  0  0 14  0  0  5  0  5]\n",
      "MNB Accuracy:  0.8870967741935484\n",
      "MNB F1:  0.8656862745098038\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.88      1.00      0.94        22\n",
      "          2       1.00      1.00      1.00        14\n",
      "          3       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.96      0.95      0.95        62\n",
      "\n",
      "[13  3  0  0  0 22  0  0  0  0 14  0  0  0  0 10]\n",
      "svc Accuracy:  0.9516129032258065\n",
      "svc F1:  0.9581804842259721\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.90        16\n",
      "          1       0.73      1.00      0.85        22\n",
      "          2       1.00      1.00      1.00        14\n",
      "          3       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.91      0.87      0.86        62\n",
      "\n",
      "[13  3  0  0  0 22  0  0  0  0 14  0  0  5  0  5]\n",
      "LR Accuracy:  0.8709677419354839\n",
      "LR F1:  0.852343059239611\n",
      "For name:  j_wong\n",
      "total sample size before apply threshold:  183\n",
      "Counter({'0000-0003-2953-7728': 59, '0000-0003-2592-3226': 30, '0000-0002-7213-4898': 24, '0000-0001-5572-4143': 21, '0000-0002-8167-540X': 17, '0000-0001-8268-5610': 10, '0000-0001-8080-1294': 8, '0000-0002-9206-3257': 5, '0000-0002-9329-1075': 4, '0000-0003-3897-7725': 4, '0000-0002-6317-2067': 1})\n",
      "['0000-0003-2592-3226', '0000-0001-5572-4143', '0000-0002-8167-540X', '0000-0001-8268-5610', '0000-0003-2953-7728', '0000-0002-7213-4898']\n",
      "Total sample size after apply threshold:  161\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(161, 462)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "161\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        30\n",
      "          1       1.00      0.62      0.76        21\n",
      "          2       1.00      0.71      0.83        17\n",
      "          3       1.00      0.70      0.82        10\n",
      "          4       0.69      1.00      0.82        59\n",
      "          5       1.00      0.88      0.93        24\n",
      "\n",
      "avg / total       0.89      0.84      0.84       161\n",
      "\n",
      "[23  0  0  0  7  0  0 13  0  0  8  0  0  0 12  0  5  0  0  0  0  7  3  0\n",
      "  0  0  0  0 59  0  0  0  0  0  3 21]\n",
      "MNB Accuracy:  0.8385093167701864\n",
      "MNB F1:  0.839420634515644\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        30\n",
      "          1       1.00      0.86      0.92        21\n",
      "          2       1.00      0.88      0.94        17\n",
      "          3       1.00      0.90      0.95        10\n",
      "          4       0.81      1.00      0.89        59\n",
      "          5       1.00      0.92      0.96        24\n",
      "\n",
      "avg / total       0.93      0.91      0.91       161\n",
      "\n",
      "[24  0  0  0  6  0  0 18  0  0  3  0  0  0 15  0  2  0  0  0  0  9  1  0\n",
      "  0  0  0  0 59  0  0  0  0  0  2 22]\n",
      "svc Accuracy:  0.9130434782608695\n",
      "svc F1:  0.9245492276813786\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        30\n",
      "          1       1.00      0.62      0.76        21\n",
      "          2       1.00      0.71      0.83        17\n",
      "          3       1.00      0.80      0.89        10\n",
      "          4       0.66      1.00      0.80        59\n",
      "          5       1.00      0.75      0.86        24\n",
      "\n",
      "avg / total       0.88      0.81      0.82       161\n",
      "\n",
      "[21  0  0  0  9  0  0 13  0  0  8  0  0  0 12  0  5  0  0  0  0  8  2  0\n",
      "  0  0  0  0 59  0  0  0  0  0  6 18]\n",
      "LR Accuracy:  0.8136645962732919\n",
      "LR F1:  0.8265250907238736\n",
      "For name:  s_turner\n",
      "total sample size before apply threshold:  101\n",
      "Counter({'0000-0003-4859-1068': 40, '0000-0002-8439-4507': 32, '0000-0002-1002-0000': 16, '0000-0001-8692-8210': 5, '0000-0003-2308-158X': 4, '0000-0001-5108-7976': 2, '0000-0003-2541-6072': 1, '0000-0003-2735-3220': 1})\n",
      "['0000-0002-1002-0000', '0000-0003-4859-1068', '0000-0002-8439-4507']\n",
      "Total sample size after apply threshold:  88\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 380)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.77        16\n",
      "          1       0.71      1.00      0.83        40\n",
      "          2       1.00      0.69      0.81        32\n",
      "\n",
      "avg / total       0.87      0.82      0.81        88\n",
      "\n",
      "[10  6  0  0 40  0  0 10 22]\n",
      "MNB Accuracy:  0.8181818181818182\n",
      "MNB F1:  0.8057929724596392\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        16\n",
      "          1       0.83      1.00      0.91        40\n",
      "          2       1.00      0.88      0.93        32\n",
      "\n",
      "avg / total       0.92      0.91      0.91        88\n",
      "\n",
      "[12  4  0  0 40  0  0  4 28]\n",
      "svc Accuracy:  0.9090909090909091\n",
      "svc F1:  0.8998556998556998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        16\n",
      "          1       0.69      1.00      0.82        40\n",
      "          2       1.00      0.69      0.81        32\n",
      "\n",
      "avg / total       0.86      0.80      0.79        88\n",
      "\n",
      "[ 8  8  0  0 40  0  0 10 22]\n",
      "LR Accuracy:  0.7954545454545454\n",
      "LR F1:  0.7659360040312421\n",
      "For name:  y_yuan\n",
      "total sample size before apply threshold:  67\n",
      "Counter({'0000-0003-1376-0028': 17, '0000-0001-7094-4419': 11, '0000-0003-4284-3973': 10, '0000-0003-4706-7897': 10, '0000-0002-7577-3257': 9, '0000-0003-3020-0700': 4, '0000-0002-1761-9040': 3, '0000-0002-6719-2567': 1, '0000-0002-1823-3174': 1, '0000-0002-2292-7339': 1})\n",
      "['0000-0003-1376-0028', '0000-0003-4284-3973', '0000-0003-4706-7897', '0000-0001-7094-4419']\n",
      "Total sample size after apply threshold:  48\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 139)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      1.00      0.79        17\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.60      0.75        10\n",
      "          3       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.88      0.81      0.81        48\n",
      "\n",
      "[17  0  0  0  3  7  0  0  4  0  6  0  2  0  0  9]\n",
      "MNB Accuracy:  0.8125\n",
      "MNB F1:  0.8160567715458276\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.94      0.82        17\n",
      "          1       1.00      0.90      0.95        10\n",
      "          2       0.88      0.70      0.78        10\n",
      "          3       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.88      0.85      0.86        48\n",
      "\n",
      "[16  0  1  0  1  9  0  0  3  0  7  0  2  0  0  9]\n",
      "svc Accuracy:  0.8541666666666666\n",
      "svc F1:  0.8614147548358074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      1.00      0.79        17\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      0.60      0.75        10\n",
      "          3       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.88      0.81      0.81        48\n",
      "\n",
      "[17  0  0  0  3  7  0  0  4  0  6  0  2  0  0  9]\n",
      "LR Accuracy:  0.8125\n",
      "LR F1:  0.8160567715458276\n",
      "For name:  l_liu\n",
      "total sample size before apply threshold:  267\n",
      "Counter({'0000-0003-2732-7399': 36, '0000-0003-1844-338X': 35, '0000-0001-6997-8101': 24, '0000-0003-4934-0367': 17, '0000-0002-6944-5417': 15, '0000-0002-8884-4819': 14, '0000-0003-3631-2148': 13, '0000-0001-5868-4482': 11, '0000-0002-5696-3151': 10, '0000-0002-1450-4950': 9, '0000-0002-5054-2372': 9, '0000-0003-3269-8741': 8, '0000-0002-3710-7042': 8, '0000-0002-8396-0554': 7, '0000-0003-2949-6348': 7, '0000-0002-8924-4890': 6, '0000-0002-4604-4629': 6, '0000-0001-5476-0169': 4, '0000-0002-0493-9272': 4, '0000-0002-6159-7475': 4, '0000-0002-7775-5933': 4, '0000-0003-2741-2542': 2, '0000-0001-8689-1788': 2, '0000-0002-4852-1580': 2, '0000-0002-4811-4897': 1, '0000-0003-1506-2370': 1, '0000-0002-4561-1433': 1, '0000-0001-5056-1517': 1, '0000-0003-2230-2934': 1, '0000-0003-0030-3581': 1, '0000-0002-6506-3462': 1, '0000-0002-2213-8057': 1, '0000-0003-0194-1454': 1, '0000-0002-8468-327X': 1})\n",
      "['0000-0002-8884-4819', '0000-0003-3631-2148', '0000-0001-6997-8101', '0000-0003-4934-0367', '0000-0003-1844-338X', '0000-0002-5696-3151', '0000-0002-6944-5417', '0000-0001-5868-4482', '0000-0003-2732-7399']\n",
      "Total sample size after apply threshold:  175\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(175, 439)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.35        14\n",
      "          1       1.00      0.62      0.76        13\n",
      "          2       1.00      0.88      0.93        24\n",
      "          3       1.00      0.35      0.52        17\n",
      "          4       0.57      0.80      0.67        35\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.93      0.87      0.90        15\n",
      "          7       1.00      0.45      0.62        11\n",
      "          8       0.51      0.97      0.67        36\n",
      "\n",
      "avg / total       0.75      0.68      0.65       175\n",
      "\n",
      "[ 3  0  0  0  7  0  0  0  4  0  8  0  0  3  0  0  0  2  0  0 21  0  0  0\n",
      "  0  0  3  0  0  0  6  3  0  0  0  8  0  0  0  0 28  0  1  0  6  0  0  0\n",
      "  0  4  0  0  0  6  0  0  0  0  1  0 13  0  1  0  0  0  0  2  0  0  5  4\n",
      "  0  0  0  0  1  0  0  0 35]\n",
      "MNB Accuracy:  0.68\n",
      "MNB F1:  0.6027559399571922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        14\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       0.91      0.83      0.87        24\n",
      "          3       0.94      1.00      0.97        17\n",
      "          4       0.63      0.97      0.76        35\n",
      "          5       1.00      0.30      0.46        10\n",
      "          6       1.00      0.87      0.93        15\n",
      "          7       1.00      0.73      0.84        11\n",
      "          8       0.82      0.92      0.87        36\n",
      "\n",
      "avg / total       0.87      0.83      0.82       175\n",
      "\n",
      "[ 5  0  0  0  8  0  0  0  1  0 12  0  0  1  0  0  0  0  0  0 20  0  4  0\n",
      "  0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  1 34  0  0  0  0  0  0  1\n",
      "  0  3  3  0  0  3  0  0  0  0  1  0 13  0  1  0  0  1  0  0  0  0  8  2\n",
      "  0  0  0  0  3  0  0  0 33]\n",
      "svc Accuracy:  0.8285714285714286\n",
      "svc F1:  0.7991100808903498\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.35        14\n",
      "          1       1.00      0.69      0.82        13\n",
      "          2       1.00      0.83      0.91        24\n",
      "          3       0.90      0.53      0.67        17\n",
      "          4       0.51      0.91      0.65        35\n",
      "          5       1.00      0.30      0.46        10\n",
      "          6       0.93      0.87      0.90        15\n",
      "          7       1.00      0.45      0.62        11\n",
      "          8       0.69      0.92      0.79        36\n",
      "\n",
      "avg / total       0.82      0.73      0.71       175\n",
      "\n",
      "[ 3  0  0  0  9  0  0  0  2  0  9  0  0  4  0  0  0  0  0  0 20  0  2  0\n",
      "  0  0  2  0  0  0  9  6  0  0  0  2  0  0  0  1 32  0  1  0  1  0  0  0\n",
      "  0  4  3  0  0  3  0  0  0  0  1  0 13  0  1  0  0  0  0  2  0  0  5  4\n",
      "  0  0  0  0  3  0  0  0 33]\n",
      "LR Accuracy:  0.7257142857142858\n",
      "LR F1:  0.6854162518100506\n",
      "For name:  a_fonseca\n",
      "total sample size before apply threshold:  91\n",
      "Counter({'0000-0001-6913-5526': 24, '0000-0001-6237-417X': 13, '0000-0003-1395-1406': 7, '0000-0001-8413-9744': 6, '0000-0003-1118-5525': 6, '0000-0001-9624-7208': 5, '0000-0002-7145-2472': 5, '0000-0001-7505-7878': 4, '0000-0002-6382-6833': 4, '0000-0001-6792-8047': 4, '0000-0002-9087-1306': 4, '0000-0002-1715-5469': 3, '0000-0002-6925-1671': 2, '0000-0002-3207-4819': 2, '0000-0002-6661-5185': 1, '0000-0001-7410-269X': 1})\n",
      "['0000-0001-6237-417X', '0000-0001-6913-5526']\n",
      "Total sample size after apply threshold:  37\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 91)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.96      0.98        24\n",
      "\n",
      "avg / total       0.97      0.97      0.97        37\n",
      "\n",
      "[13  0  1 23]\n",
      "MNB Accuracy:  0.972972972972973\n",
      "MNB F1:  0.9708431836091411\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.96      1.00      0.98        24\n",
      "\n",
      "avg / total       0.97      0.97      0.97        37\n",
      "\n",
      "[12  1  0 24]\n",
      "svc Accuracy:  0.972972972972973\n",
      "svc F1:  0.969795918367347\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82        13\n",
      "          1       0.86      1.00      0.92        24\n",
      "\n",
      "avg / total       0.91      0.89      0.89        37\n",
      "\n",
      "[ 9  4  0 24]\n",
      "LR Accuracy:  0.8918918918918919\n",
      "LR F1:  0.8706293706293706\n",
      "For name:  r_francis\n",
      "total sample size before apply threshold:  13\n",
      "Counter({'0000-0002-3995-7040': 6, '0000-0001-8240-4903': 4, '0000-0002-4598-0861': 2, '0000-0003-1580-7934': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  l_castro\n",
      "total sample size before apply threshold:  74\n",
      "Counter({'0000-0001-7697-386X': 47, '0000-0003-3384-3832': 9, '0000-0002-0852-8235': 7, '0000-0003-3048-933X': 4, '0000-0002-1312-0154': 4, '0000-0002-1359-5272': 3})\n",
      "['0000-0001-7697-386X']\n",
      "Total sample size after apply threshold:  47\n",
      "For name:  k_zhou\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-1898-6379': 5, '0000-0002-0351-8812': 3, '0000-0002-2844-1604': 3, '0000-0001-6645-5102': 2, '0000-0001-6442-0475': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_macdonald\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0001-9851-3610': 38, '0000-0001-7946-0023': 11, '0000-0002-6295-6978': 2, '0000-0001-5421-3536': 1})\n",
      "['0000-0001-7946-0023', '0000-0001-9851-3610']\n",
      "Total sample size after apply threshold:  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(49, 186)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        11\n",
      "          1       0.84      1.00      0.92        38\n",
      "\n",
      "avg / total       0.88      0.86      0.83        49\n",
      "\n",
      "[ 4  7  0 38]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.7244979919678715\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.93      1.00      0.96        38\n",
      "\n",
      "avg / total       0.94      0.94      0.94        49\n",
      "\n",
      "[ 8  3  0 38]\n",
      "svc Accuracy:  0.9387755102040817\n",
      "svc F1:  0.9020652898067956\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.78      1.00      0.87        38\n",
      "\n",
      "avg / total       0.60      0.78      0.68        49\n",
      "\n",
      "[ 0 11  0 38]\n",
      "LR Accuracy:  0.7755102040816326\n",
      "LR F1:  0.43678160919540227\n",
      "For name:  h_guan\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-4683-601X': 17, '0000-0002-4858-3159': 16, '0000-0002-2282-3193': 8, '0000-0001-5425-6974': 3})\n",
      "['0000-0002-4858-3159', '0000-0002-4683-601X']\n",
      "Total sample size after apply threshold:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 82)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.81      0.87        16\n",
      "          1       0.84      0.94      0.89        17\n",
      "\n",
      "avg / total       0.88      0.88      0.88        33\n",
      "\n",
      "[13  3  1 16]\n",
      "MNB Accuracy:  0.8787878787878788\n",
      "MNB F1:  0.8777777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93        16\n",
      "          1       0.89      1.00      0.94        17\n",
      "\n",
      "avg / total       0.95      0.94      0.94        33\n",
      "\n",
      "[14  2  0 17]\n",
      "svc Accuracy:  0.9393939393939394\n",
      "svc F1:  0.9388888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        16\n",
      "          1       0.81      1.00      0.89        17\n",
      "\n",
      "avg / total       0.90      0.88      0.88        33\n",
      "\n",
      "[12  4  0 17]\n",
      "LR Accuracy:  0.8787878787878788\n",
      "LR F1:  0.8759398496240601\n",
      "For name:  t_miller\n",
      "total sample size before apply threshold:  165\n",
      "Counter({'0000-0002-0958-2639': 102, '0000-0003-0731-8006': 42, '0000-0002-1269-1895': 11, '0000-0002-5585-7736': 6, '0000-0002-9749-1656': 3, '0000-0003-4027-7066': 1})\n",
      "['0000-0002-0958-2639', '0000-0002-1269-1895', '0000-0003-0731-8006']\n",
      "Total sample size after apply threshold:  155\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(155, 1391)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "155\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       102\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.79      0.88        42\n",
      "\n",
      "avg / total       0.82      0.87      0.84       155\n",
      "\n",
      "[102   0   0  11   0   0   9   0  33]\n",
      "MNB Accuracy:  0.8709677419354839\n",
      "MNB F1:  0.5969047619047619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       102\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       1.00      0.88      0.94        42\n",
      "\n",
      "avg / total       0.92      0.90      0.88       155\n",
      "\n",
      "[102   0   0  10   1   0   5   0  37]\n",
      "svc Accuracy:  0.9032258064516129\n",
      "svc F1:  0.6782941255804097\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88       102\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.60      0.75        42\n",
      "\n",
      "avg / total       0.79      0.82      0.78       155\n",
      "\n",
      "[102   0   0  11   0   0  17   0  25]\n",
      "LR Accuracy:  0.8193548387096774\n",
      "LR F1:  0.5418596671813347\n",
      "For name:  m_kang\n",
      "total sample size before apply threshold:  131\n",
      "Counter({'0000-0003-1595-1717': 38, '0000-0003-3245-144X': 19, '0000-0002-2039-4866': 18, '0000-0002-4778-8240': 13, '0000-0002-1530-7254': 12, '0000-0003-2140-4234': 10, '0000-0002-8795-2973': 8, '0000-0001-5266-2290': 5, '0000-0002-5054-7587': 4, '0000-0003-4946-8512': 2, '0000-0001-6991-0481': 1, '0000-0001-7600-7469': 1})\n",
      "['0000-0003-1595-1717', '0000-0002-4778-8240', '0000-0002-1530-7254', '0000-0003-2140-4234', '0000-0002-2039-4866', '0000-0003-3245-144X']\n",
      "Total sample size after apply threshold:  110\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(110, 175)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "110\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      1.00      0.73        38\n",
      "          1       1.00      0.77      0.87        13\n",
      "          2       1.00      0.33      0.50        12\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.93      0.72      0.81        18\n",
      "          5       0.94      0.79      0.86        19\n",
      "\n",
      "avg / total       0.74      0.73      0.69       110\n",
      "\n",
      "[38  0  0  0  0  0  2 10  0  0  0  1  7  0  4  0  1  0 10  0  0  0  0  0\n",
      "  5  0  0  0 13  0  4  0  0  0  0 15]\n",
      "MNB Accuracy:  0.7272727272727273\n",
      "MNB F1:  0.6283295508838987\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.92      0.81        38\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        12\n",
      "          3       0.33      0.10      0.15        10\n",
      "          4       1.00      0.83      0.91        18\n",
      "          5       0.95      0.95      0.95        19\n",
      "\n",
      "avg / total       0.84      0.85      0.83       110\n",
      "\n",
      "[35  0  0  2  0  1  0 13  0  0  0  0  0  0 12  0  0  0  9  0  0  1  0  0\n",
      "  3  0  0  0 15  0  1  0  0  0  0 18]\n",
      "svc Accuracy:  0.8545454545454545\n",
      "svc F1:  0.804043162060298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      1.00      0.81        38\n",
      "          1       1.00      0.77      0.87        13\n",
      "          2       1.00      0.83      0.91        12\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.83      0.91        18\n",
      "          5       0.95      0.95      0.95        19\n",
      "\n",
      "avg / total       0.79      0.83      0.79       110\n",
      "\n",
      "[38  0  0  0  0  0  2 10  0  0  0  1  2  0 10  0  0  0 10  0  0  0  0  0\n",
      "  3  0  0  0 15  0  1  0  0  0  0 18]\n",
      "LR Accuracy:  0.8272727272727273\n",
      "LR F1:  0.7406043491539377\n",
      "For name:  z_shi\n",
      "total sample size before apply threshold:  180\n",
      "Counter({'0000-0002-3099-3299': 94, '0000-0002-9624-4960': 25, '0000-0003-2388-6695': 22, '0000-0001-5357-1171': 13, '0000-0002-3928-2960': 12, '0000-0002-3865-0098': 9, '0000-0001-9922-3957': 2, '0000-0002-7798-1121': 1, '0000-0002-8328-0305': 1, '0000-0002-5828-1904': 1})\n",
      "['0000-0002-3099-3299', '0000-0001-5357-1171', '0000-0002-3928-2960', '0000-0002-9624-4960', '0000-0003-2388-6695']\n",
      "Total sample size after apply threshold:  166\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(166, 247)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "166\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92        94\n",
      "          1       1.00      0.54      0.70        13\n",
      "          2       1.00      0.42      0.59        12\n",
      "          3       0.71      0.88      0.79        25\n",
      "          4       1.00      0.68      0.81        22\n",
      "\n",
      "avg / total       0.88      0.86      0.84       166\n",
      "\n",
      "[93  0  0  1  0  3  7  0  3  0  2  0  5  5  0  3  0  0 22  0  7  0  0  0\n",
      " 15]\n",
      "MNB Accuracy:  0.8554216867469879\n",
      "MNB F1:  0.761110493970133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92        94\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       0.95      0.80      0.87        25\n",
      "          4       1.00      0.73      0.84        22\n",
      "\n",
      "avg / total       0.91      0.90      0.90       166\n",
      "\n",
      "[93  0  0  1  0  1 12  0  0  0  3  0  9  0  0  5  0  0 20  0  6  0  0  0\n",
      " 16]\n",
      "svc Accuracy:  0.9036144578313253\n",
      "svc F1:  0.8899210833799953\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.99      0.87        94\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       1.00      0.67      0.80        12\n",
      "          3       0.95      0.76      0.84        25\n",
      "          4       1.00      0.55      0.71        22\n",
      "\n",
      "avg / total       0.87      0.83      0.82       166\n",
      "\n",
      "[93  0  0  1  0  7  6  0  0  0  4  0  8  0  0  6  0  0 19  0 10  0  0  0\n",
      " 12]\n",
      "LR Accuracy:  0.8313253012048193\n",
      "LR F1:  0.770212924651743\n",
      "For name:  t_johnson\n",
      "total sample size before apply threshold:  293\n",
      "Counter({'0000-0001-7147-8237': 174, '0000-0002-5998-3270': 76, '0000-0003-3377-6692': 21, '0000-0002-5372-5457': 17, '0000-0002-9499-3538': 2, '0000-0002-6170-5077': 1, '0000-0002-2724-7017': 1, '0000-0001-6596-6437': 1})\n",
      "['0000-0001-7147-8237', '0000-0003-3377-6692', '0000-0002-5372-5457', '0000-0002-5998-3270']\n",
      "Total sample size after apply threshold:  288\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(288, 2876)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86       174\n",
      "          1       1.00      0.05      0.09        21\n",
      "          2       1.00      0.06      0.11        17\n",
      "          3       1.00      0.71      0.83        76\n",
      "\n",
      "avg / total       0.85      0.80      0.75       288\n",
      "\n",
      "[174   0   0   0  20   1   0   0  16   0   1   0  22   0   0  54]\n",
      "MNB Accuracy:  0.7986111111111112\n",
      "MNB F1:  0.47248307248307253\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.92       174\n",
      "          1       1.00      0.52      0.69        21\n",
      "          2       0.92      0.65      0.76        17\n",
      "          3       0.98      0.79      0.88        76\n",
      "\n",
      "avg / total       0.90      0.89      0.88       288\n",
      "\n",
      "[173   0   1   0   9  11   0   1   6   0  11   0  16   0   0  60]\n",
      "svc Accuracy:  0.8854166666666666\n",
      "svc F1:  0.809344253439553\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86       174\n",
      "          1       0.00      0.00      0.00        21\n",
      "          2       1.00      0.47      0.64        17\n",
      "          3       1.00      0.64      0.78        76\n",
      "\n",
      "avg / total       0.78      0.80      0.76       288\n",
      "\n",
      "[174   0   0   0  21   0   0   0   9   0   8   0  27   0   0  49]\n",
      "LR Accuracy:  0.8020833333333334\n",
      "LR F1:  0.5708148148148148\n",
      "For name:  m_ferretti\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0003-0280-3598': 29, '0000-0003-2961-6362': 8, '0000-0003-0709-3281': 5, '0000-0002-7578-6699': 1})\n",
      "['0000-0003-0280-3598']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  b_peng\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0001-8225-2284': 19, '0000-0003-4183-5939': 4, '0000-0002-5599-6779': 1, '0000-0002-1099-1229': 1})\n",
      "['0000-0001-8225-2284']\n",
      "Total sample size after apply threshold:  19\n",
      "For name:  m_fernandes\n",
      "total sample size before apply threshold:  118\n",
      "Counter({'0000-0001-9391-9574': 60, '0000-0002-1840-616X': 28, '0000-0002-0765-474X': 7, '0000-0001-6533-4309': 6, '0000-0001-7969-2107': 3, '0000-0002-1206-1367': 3, '0000-0001-9239-1202': 3, '0000-0001-7536-2506': 3, '0000-0002-0051-3389': 2, '0000-0002-8009-7513': 2, '0000-0002-9556-7741': 1})\n",
      "['0000-0001-9391-9574', '0000-0002-1840-616X']\n",
      "Total sample size after apply threshold:  88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(88, 170)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        60\n",
      "          1       1.00      0.82      0.90        28\n",
      "\n",
      "avg / total       0.95      0.94      0.94        88\n",
      "\n",
      "[60  0  5 23]\n",
      "MNB Accuracy:  0.9431818181818182\n",
      "MNB F1:  0.9309803921568628\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        60\n",
      "          1       1.00      0.82      0.90        28\n",
      "\n",
      "avg / total       0.95      0.94      0.94        88\n",
      "\n",
      "[60  0  5 23]\n",
      "svc Accuracy:  0.9431818181818182\n",
      "svc F1:  0.9309803921568628\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        60\n",
      "          1       1.00      0.68      0.81        28\n",
      "\n",
      "avg / total       0.91      0.90      0.89        88\n",
      "\n",
      "[60  0  9 19]\n",
      "LR Accuracy:  0.8977272727272727\n",
      "LR F1:  0.8693715982187036\n",
      "For name:  l_cui\n",
      "total sample size before apply threshold:  25\n",
      "Counter({'0000-0001-5549-8780': 18, '0000-0001-5706-9525': 3, '0000-0002-5546-5097': 2, '0000-0002-9818-4543': 1, '0000-0001-5907-0538': 1})\n",
      "['0000-0001-5549-8780']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  s_monteiro\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0002-4026-5965': 19, '0000-0002-7069-0591': 14, '0000-0003-0059-9837': 7, '0000-0002-3037-9635': 4, '0000-0001-5040-6170': 2, '0000-0002-8784-7276': 2, '0000-0002-1389-3851': 1, '0000-0003-3507-9911': 1})\n",
      "['0000-0002-4026-5965', '0000-0002-7069-0591']\n",
      "Total sample size after apply threshold:  33\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 69)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        33\n",
      "\n",
      "[19  0  0 14]\n",
      "MNB Accuracy: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        33\n",
      "\n",
      "[19  0  0 14]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        33\n",
      "\n",
      "[19  0  0 14]\n",
      "LR Accuracy:  1.0\n",
      "LR F1:  1.0\n",
      "For name:  m_hsieh\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0003-3636-6250': 15, '0000-0001-5254-1341': 10, '0000-0002-3396-8427': 5, '0000-0002-7833-847X': 4, '0000-0002-3706-6615': 1})\n",
      "['0000-0003-3636-6250', '0000-0001-5254-1341']\n",
      "Total sample size after apply threshold:  25\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 37)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        15\n",
      "          1       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.83      0.76      0.73        25\n",
      "\n",
      "[15  0  6  4]\n",
      "MNB Accuracy:  0.76\n",
      "MNB F1:  0.7023809523809523\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        15\n",
      "          1       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.87      0.84      0.83        25\n",
      "\n",
      "[15  0  4  6]\n",
      "svc Accuracy:  0.84\n",
      "svc F1:  0.8161764705882353\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        15\n",
      "          1       1.00      0.40      0.57        10\n",
      "\n",
      "avg / total       0.83      0.76      0.73        25\n",
      "\n",
      "[15  0  6  4]\n",
      "LR Accuracy:  0.76\n",
      "LR F1:  0.7023809523809523\n",
      "For name:  c_nelson\n",
      "total sample size before apply threshold:  26\n",
      "Counter({'0000-0003-1034-140X': 16, '0000-0003-0195-5610': 6, '0000-0001-5824-2457': 1, '0000-0003-2525-3496': 1, '0000-0001-6287-1598': 1, '0000-0002-4114-1710': 1})\n",
      "['0000-0003-1034-140X']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  j_barnett\n",
      "total sample size before apply threshold:  23\n",
      "Counter({'0000-0003-0664-4168': 13, '0000-0002-0862-0808': 5, '0000-0001-5381-0064': 4, '0000-0002-4213-4010': 1})\n",
      "['0000-0003-0664-4168']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  j_tian\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0002-4008-0469': 10, '0000-0001-6373-6953': 9, '0000-0001-5313-1600': 1, '0000-0002-5896-2515': 1, '0000-0001-9555-0387': 1})\n",
      "['0000-0002-4008-0469']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  f_costa\n",
      "total sample size before apply threshold:  52\n",
      "Counter({'0000-0002-3097-2834': 22, '0000-0001-5398-3942': 14, '0000-0002-6547-6005': 3, '0000-0001-9368-5640': 3, '0000-0001-8981-7049': 3, '0000-0003-3914-6317': 2, '0000-0001-8729-714X': 2, '0000-0003-0562-2514': 1, '0000-0002-1409-5325': 1, '0000-0001-7572-2014': 1})\n",
      "['0000-0002-3097-2834', '0000-0001-5398-3942']\n",
      "Total sample size after apply threshold:  36\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(36, 151)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        22\n",
      "          1       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[22  0  1 13]\n",
      "MNB Accuracy:  0.9722222222222222\n",
      "MNB F1:  0.9703703703703703\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        22\n",
      "          1       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "[22  0  1 13]\n",
      "svc Accuracy:  0.9722222222222222\n",
      "svc F1:  0.9703703703703703\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        22\n",
      "          1       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.93      0.92      0.91        36\n",
      "\n",
      "[22  0  3 11]\n",
      "LR Accuracy:  0.9166666666666666\n",
      "LR F1:  0.9080851063829787\n",
      "For name:  a_mccarthy\n",
      "total sample size before apply threshold:  88\n",
      "Counter({'0000-0001-7195-6366': 56, '0000-0002-8979-2926': 26, '0000-0001-6896-0225': 4, '0000-0002-3355-9965': 2})\n",
      "['0000-0002-8979-2926', '0000-0001-7195-6366']\n",
      "Total sample size after apply threshold:  82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(82, 335)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.88      0.92        26\n",
      "          1       0.95      0.98      0.96        56\n",
      "\n",
      "avg / total       0.95      0.95      0.95        82\n",
      "\n",
      "[23  3  1 55]\n",
      "MNB Accuracy:  0.9512195121951219\n",
      "MNB F1:  0.9424561403508771\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        26\n",
      "          1       0.89      1.00      0.94        56\n",
      "\n",
      "avg / total       0.92      0.91      0.91        82\n",
      "\n",
      "[19  7  0 56]\n",
      "svc Accuracy:  0.9146341463414634\n",
      "svc F1:  0.8928104575163398\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.56        26\n",
      "          1       0.78      1.00      0.88        56\n",
      "\n",
      "avg / total       0.85      0.80      0.77        82\n",
      "\n",
      "[10 16  0 56]\n",
      "LR Accuracy:  0.8048780487804879\n",
      "LR F1:  0.7152777777777779\n",
      "For name:  y_cheng\n",
      "total sample size before apply threshold:  177\n",
      "Counter({'0000-0001-9150-4690': 38, '0000-0001-7112-8835': 29, '0000-0002-4423-4381': 17, '0000-0003-0125-4267': 16, '0000-0002-2583-228X': 15, '0000-0001-9776-395X': 14, '0000-0002-7529-4408': 11, '0000-0001-6874-8187': 9, '0000-0003-2571-4707': 8, '0000-0002-2077-5335': 5, '0000-0003-4912-9879': 3, '0000-0002-5939-0010': 2, '0000-0002-2431-3197': 2, '0000-0002-1468-6686': 2, '0000-0001-5858-6161': 2, '0000-0002-5906-7694': 1, '0000-0002-2352-8647': 1, '0000-0003-1137-2099': 1, '0000-0003-0822-4458': 1})\n",
      "['0000-0001-9776-395X', '0000-0002-4423-4381', '0000-0003-0125-4267', '0000-0002-2583-228X', '0000-0002-7529-4408', '0000-0001-7112-8835', '0000-0001-9150-4690']\n",
      "Total sample size after apply threshold:  140\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(140, 169)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "140\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       1.00      0.18      0.30        17\n",
      "          2       1.00      0.56      0.72        16\n",
      "          3       0.89      0.53      0.67        15\n",
      "          4       1.00      0.45      0.62        11\n",
      "          5       0.80      0.55      0.65        29\n",
      "          6       0.44      0.95      0.60        38\n",
      "\n",
      "avg / total       0.79      0.64      0.63       140\n",
      "\n",
      "[12  0  0  0  0  0  2  0  3  0  1  0  1 12  0  0  9  0  0  0  7  0  0  0\n",
      "  8  0  0  7  0  0  0  0  5  1  5  0  0  0  0  0 16 13  0  0  0  0  0  2\n",
      " 36]\n",
      "MNB Accuracy:  0.6357142857142857\n",
      "MNB F1:  0.6411149734619122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.25      0.24      0.24        17\n",
      "          2       1.00      0.62      0.77        16\n",
      "          3       0.83      0.67      0.74        15\n",
      "          4       1.00      0.64      0.78        11\n",
      "          5       0.62      0.83      0.71        29\n",
      "          6       0.68      0.79      0.73        38\n",
      "\n",
      "avg / total       0.73      0.69      0.69       140\n",
      "\n",
      "[12  0  0  0  0  2  0  0  4  0  0  0  6  7  0  2 10  0  0  2  2  0  3  0\n",
      " 10  0  0  2  0  0  0  0  7  3  1  0  3  0  0  0 24  2  0  4  0  2  0  2\n",
      " 30]\n",
      "svc Accuracy:  0.6928571428571428\n",
      "svc F1:  0.6986914461806857\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.80      0.24      0.36        17\n",
      "          2       1.00      0.62      0.77        16\n",
      "          3       0.92      0.73      0.81        15\n",
      "          4       1.00      0.55      0.71        11\n",
      "          5       0.58      0.86      0.69        29\n",
      "          6       0.63      0.87      0.73        38\n",
      "\n",
      "avg / total       0.78      0.72      0.71       140\n",
      "\n",
      "[12  0  0  0  0  2  0  0  4  0  0  0  4  9  0  0 10  0  0  4  2  0  0  0\n",
      " 11  0  1  3  0  0  0  0  6  4  1  0  0  0  0  0 25  4  0  1  0  1  0  3\n",
      " 33]\n",
      "LR Accuracy:  0.7214285714285714\n",
      "LR F1:  0.7149170002111179\n",
      "For name:  i_hwang\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0002-6122-4417': 51, '0000-0002-5388-1919': 14, '0000-0002-4973-6823': 7, '0000-0003-2949-3075': 7, '0000-0002-5720-1765': 2, '0000-0002-1291-8973': 1, '0000-0002-4479-9374': 1, '0000-0002-0533-4638': 1})\n",
      "['0000-0002-6122-4417', '0000-0002-5388-1919']\n",
      "Total sample size after apply threshold:  65\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 63)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        51\n",
      "          1       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.96      0.95      0.95        65\n",
      "\n",
      "[51  0  3 11]\n",
      "MNB Accuracy:  0.9538461538461539\n",
      "MNB F1:  0.9257142857142857\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        51\n",
      "          1       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.96      0.95      0.95        65\n",
      "\n",
      "[51  0  3 11]\n",
      "svc Accuracy:  0.9538461538461539\n",
      "svc F1:  0.9257142857142857\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        51\n",
      "          1       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.96      0.95      0.95        65\n",
      "\n",
      "[51  0  3 11]\n",
      "LR Accuracy:  0.9538461538461539\n",
      "LR F1:  0.9257142857142857\n",
      "For name:  y_liu\n",
      "total sample size before apply threshold:  965\n",
      "Counter({'0000-0001-8327-3108': 54, '0000-0002-4423-6045': 50, '0000-0002-1862-3121': 46, '0000-0002-2245-4893': 42, '0000-0002-7078-5937': 41, '0000-0002-5247-1678': 38, '0000-0002-6388-9674': 38, '0000-0002-7968-0162': 37, '0000-0001-6677-7961': 28, '0000-0003-0802-3832': 27, '0000-0002-1282-4897': 26, '0000-0002-8417-2488': 23, '0000-0003-1590-0995': 22, '0000-0002-6535-6169': 21, '0000-0002-5880-8649': 21, '0000-0001-9636-990X': 19, '0000-0002-7135-723X': 18, '0000-0002-2885-1670': 18, '0000-0001-6222-5641': 18, '0000-0002-4638-0788': 17, '0000-0001-5304-3459': 17, '0000-0003-1112-4255': 17, '0000-0002-2253-3698': 16, '0000-0003-0180-4142': 15, '0000-0001-5293-5930': 15, '0000-0002-4300-4349': 15, '0000-0002-8320-8725': 14, '0000-0003-4439-8818': 12, '0000-0001-8404-3806': 11, '0000-0001-8181-1080': 11, '0000-0002-3961-2691': 11, '0000-0003-4150-1111': 10, '0000-0001-5198-3674': 10, '0000-0003-1278-7114': 10, '0000-0002-2491-9439': 9, '0000-0003-1618-8813': 9, '0000-0002-8637-661X': 9, '0000-0001-6076-9733': 8, '0000-0003-3205-8963': 8, '0000-0001-6506-5903': 7, '0000-0002-2144-4474': 7, '0000-0003-1420-0276': 7, '0000-0002-8784-8543': 6, '0000-0002-5867-5065': 6, '0000-0001-5960-8166': 5, '0000-0002-4428-3562': 5, '0000-0002-7232-144X': 5, '0000-0001-8903-9101': 4, '0000-0003-2728-4907': 4, '0000-0001-9954-7214': 4, '0000-0001-8118-7775': 4, '0000-0002-6622-6489': 3, '0000-0001-8518-5734': 3, '0000-0002-2883-8329': 3, '0000-0001-6188-993X': 3, '0000-0003-2165-775X': 3, '0000-0002-2923-0729': 2, '0000-0002-0084-863X': 2, '0000-0002-4345-0138': 2, '0000-0002-3483-5909': 2, '0000-0003-3698-4892': 2, '0000-0002-1109-7704': 2, '0000-0003-3687-1337': 2, '0000-0002-8903-2062': 2, '0000-0003-1630-4052': 2, '0000-0001-8672-6301': 2, '0000-0002-8195-7706': 2, '0000-0001-9319-5940': 1, '0000-0002-9005-9166': 1, '0000-0001-5030-2435': 1, '0000-0002-1899-2082': 1, '0000-0001-8371-9579': 1, '0000-0002-2089-2486': 1, '0000-0002-4715-3800': 1, '0000-0003-4912-1746': 1, '0000-0003-4464-1785': 1, '0000-0003-4897-5299': 1, '0000-0003-2706-383X': 1, '0000-0003-4671-698X': 1, '0000-0001-8473-0024': 1, '0000-0002-7571-3123': 1, '0000-0002-6893-6724': 1, '0000-0002-3426-8780': 1, '0000-0002-2515-4431': 1, '0000-0001-5617-661X': 1, '0000-0001-5562-7757': 1, '0000-0002-9754-6370': 1, '0000-0001-9642-1042': 1, '0000-0001-6504-4598': 1, '0000-0003-4861-6915': 1, '0000-0002-8843-1555': 1, '0000-0001-8922-9976': 1, '0000-0002-6003-9121': 1, '0000-0002-9665-7140': 1, '0000-0002-9465-1220': 1, '0000-0002-8591-2599': 1, '0000-0002-0949-6917': 1, '0000-0001-6624-7549': 1, '0000-0003-3703-2498': 1, '0000-0002-8681-4472': 1})"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['0000-0002-7078-5937', '0000-0001-6677-7961', '0000-0002-8320-8725', '0000-0002-5247-1678', '0000-0002-2245-4893', '0000-0002-4638-0788', '0000-0002-6535-6169', '0000-0002-7968-0162', '0000-0003-4439-8818', '0000-0003-1590-0995', '0000-0002-4423-6045', '0000-0003-0802-3832', '0000-0002-7135-723X', '0000-0002-2253-3698', '0000-0002-2885-1670', '0000-0001-8404-3806', '0000-0003-0180-4142', '0000-0002-1282-4897', '0000-0001-9636-990X', '0000-0001-5293-5930', '0000-0003-4150-1111', '0000-0001-5304-3459', '0000-0002-4300-4349', '0000-0001-6222-5641', '0000-0001-8181-1080', '0000-0002-8417-2488', '0000-0002-6388-9674', '0000-0003-1112-4255', '0000-0001-5198-3674', '0000-0002-1862-3121', '0000-0002-3961-2691', '0000-0001-8327-3108', '0000-0003-1278-7114', '0000-0002-5880-8649']\n",
      "Total sample size after apply threshold:  788\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(788, 2628)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.41      0.35        41\n",
      "          1       0.92      0.79      0.85        28\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.74      0.89      0.81        38\n",
      "          4       0.51      0.86      0.64        42\n",
      "          5       0.00      0.00      0.00        17\n",
      "          6       1.00      0.29      0.44        21\n",
      "          7       0.96      0.73      0.83        37\n",
      "          8       1.00      0.08      0.15        12\n",
      "          9       0.00      0.00      0.00        22\n",
      "         10       0.42      0.68      0.52        50\n",
      "         11       1.00      0.33      0.50        27\n",
      "         12       1.00      0.06      0.11        18\n",
      "         13       1.00      0.25      0.40        16\n",
      "         14       1.00      0.17      0.29        18\n",
      "         15       0.00      0.00      0.00        11\n",
      "         16       1.00      0.13      0.24        15\n",
      "         17       1.00      0.46      0.63        26\n",
      "         18       1.00      0.68      0.81        19\n",
      "         19       0.00      0.00      0.00        15\n",
      "         20       0.00      0.00      0.00        10\n",
      "         21       1.00      0.65      0.79        17\n",
      "         22       1.00      0.07      0.12        15\n",
      "         23       1.00      0.67      0.80        18\n",
      "         24       0.00      0.00      0.00        11\n",
      "         25       1.00      0.57      0.72        23\n",
      "         26       0.95      0.92      0.93        38\n",
      "         27       1.00      0.47      0.64        17\n",
      "         28       0.00      0.00      0.00        10\n",
      "         29       0.44      0.98      0.61        46\n",
      "         30       1.00      0.09      0.17        11\n",
      "         31       0.21      0.91      0.33        54\n",
      "         32       0.00      0.00      0.00        10\n",
      "         33       1.00      0.38      0.55        21\n",
      "\n",
      "avg / total       0.64      0.51      0.48       788\n",
      "\n",
      "[17  0  0 ...  6  0  8]\n",
      "MNB Accuracy:  0.5126903553299492\n",
      "MNB F1:  0.38920847840253225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.56      0.49        41\n",
      "          1       1.00      0.93      0.96        28\n",
      "          2       0.83      0.71      0.77        14\n",
      "          3       0.80      0.97      0.88        38\n",
      "          4       0.85      0.83      0.84        42\n",
      "          5       0.76      0.76      0.76        17\n",
      "          6       1.00      0.57      0.73        21\n",
      "          7       0.86      0.81      0.83        37\n",
      "          8       0.92      0.92      0.92        12\n",
      "          9       0.55      0.55      0.55        22\n",
      "         10       0.54      0.76      0.63        50\n",
      "         11       0.76      0.93      0.83        27\n",
      "         12       1.00      0.78      0.88        18\n",
      "         13       1.00      1.00      1.00        16\n",
      "         14       0.80      0.67      0.73        18\n",
      "         15       0.86      0.55      0.67        11\n",
      "         16       0.94      1.00      0.97        15\n",
      "         17       0.95      0.73      0.83        26\n",
      "         18       1.00      1.00      1.00        19\n",
      "         19       0.53      0.53      0.53        15\n",
      "         20       1.00      1.00      1.00        10\n",
      "         21       1.00      0.82      0.90        17\n",
      "         22       1.00      0.93      0.97        15\n",
      "         23       0.89      0.89      0.89        18\n",
      "         24       1.00      0.64      0.78        11\n",
      "         25       0.91      0.87      0.89        23\n",
      "         26       1.00      0.95      0.97        38\n",
      "         27       1.00      0.71      0.83        17\n",
      "         28       1.00      0.80      0.89        10\n",
      "         29       0.94      0.96      0.95        46\n",
      "         30       1.00      0.91      0.95        11\n",
      "         31       0.65      0.80      0.72        54\n",
      "         32       1.00      0.60      0.75        10\n",
      "         33       1.00      0.81      0.89        21\n",
      "\n",
      "avg / total       0.84      0.81      0.81       788\n",
      "\n",
      "[23  0  0 ...  0  0 17]\n",
      "svc Accuracy:  0.8096446700507615\n",
      "svc F1:  0.8285250130209546\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.54      0.49        41\n",
      "          1       1.00      0.96      0.98        28\n",
      "          2       0.78      0.50      0.61        14\n",
      "          3       0.64      1.00      0.78        38\n",
      "          4       0.70      0.88      0.78        42\n",
      "          5       1.00      0.47      0.64        17\n",
      "          6       0.91      0.48      0.62        21\n",
      "          7       0.75      0.81      0.78        37\n",
      "          8       0.79      0.92      0.85        12\n",
      "          9       0.54      0.32      0.40        22\n",
      "         10       0.51      0.78      0.61        50\n",
      "         11       0.69      0.89      0.77        27\n",
      "         12       1.00      0.61      0.76        18\n",
      "         13       1.00      0.88      0.93        16\n",
      "         14       0.75      0.33      0.46        18\n",
      "         15       0.75      0.27      0.40        11\n",
      "         16       1.00      0.67      0.80        15\n",
      "         17       0.95      0.73      0.83        26\n",
      "         18       1.00      0.95      0.97        19\n",
      "         19       0.67      0.27      0.38        15\n",
      "         20       1.00      0.70      0.82        10\n",
      "         21       1.00      0.76      0.87        17\n",
      "         22       1.00      0.67      0.80        15\n",
      "         23       0.81      0.94      0.87        18\n",
      "         24       1.00      0.09      0.17        11\n",
      "         25       1.00      0.70      0.82        23\n",
      "         26       0.95      0.95      0.95        38\n",
      "         27       0.93      0.82      0.87        17\n",
      "         28       1.00      0.70      0.82        10\n",
      "         29       0.83      0.96      0.89        46\n",
      "         30       1.00      0.91      0.95        11\n",
      "         31       0.49      0.85      0.62        54\n",
      "         32       0.00      0.00      0.00        10\n",
      "         33       1.00      0.81      0.89        21\n",
      "\n",
      "avg / total       0.78      0.74      0.73       788\n",
      "\n",
      "[22  0  0 ...  0  0 17]\n",
      "LR Accuracy:  0.7398477157360406\n",
      "LR F1:  0.7119646475953896\n",
      "For name:  m_engel\n",
      "total sample size before apply threshold:  100\n",
      "Counter({'0000-0003-3067-077X': 75, '0000-0002-7031-3825': 19, '0000-0001-7602-1340': 4, '0000-0002-2271-4229': 1, '0000-0002-1474-4161': 1})\n",
      "['0000-0002-7031-3825', '0000-0003-3067-077X']\n",
      "Total sample size after apply threshold:  94\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(94, 201)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "94\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        19\n",
      "          1       0.95      1.00      0.97        75\n",
      "\n",
      "avg / total       0.96      0.96      0.96        94\n",
      "\n",
      "[15  4  0 75]\n",
      "MNB Accuracy:  0.9574468085106383\n",
      "MNB F1:  0.9281894576012223\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85        19\n",
      "          1       0.94      1.00      0.97        75\n",
      "\n",
      "avg / total       0.95      0.95      0.94        94\n",
      "\n",
      "[14  5  0 75]\n",
      "svc Accuracy:  0.9468085106382979\n",
      "svc F1:  0.9081133919843597\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.37      0.54        19\n",
      "          1       0.86      1.00      0.93        75\n",
      "\n",
      "avg / total       0.89      0.87      0.85        94\n",
      "\n",
      "[ 7 12  0 75]\n",
      "LR Accuracy:  0.8723404255319149\n",
      "LR F1:  0.7321937321937322\n",
      "For name:  w_shi\n",
      "total sample size before apply threshold:  148\n",
      "Counter({'0000-0001-6130-1227': 45, '0000-0002-6336-3912': 40, '0000-0002-9155-613X': 36, '0000-0001-5453-1753': 12, '0000-0002-6458-4776': 6, '0000-0002-1320-2635': 5, '0000-0002-3886-7027': 3, '0000-0001-5683-3800': 1})\n",
      "['0000-0001-5453-1753', '0000-0002-6336-3912', '0000-0002-9155-613X', '0000-0001-6130-1227']\n",
      "Total sample size after apply threshold:  133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 265)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        12\n",
      "          1       1.00      0.90      0.95        40\n",
      "          2       1.00      0.81      0.89        36\n",
      "          3       0.70      1.00      0.83        45\n",
      "\n",
      "avg / total       0.90      0.86      0.85       133\n",
      "\n",
      "[ 4  0  0  8  0 36  0  4  0  0 29  7  0  0  0 45]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.7913410466887049\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.87      0.97      0.92        40\n",
      "          2       0.94      0.94      0.94        36\n",
      "          3       0.98      1.00      0.99        45\n",
      "\n",
      "avg / total       0.94      0.93      0.93       133\n",
      "\n",
      "[ 6  4  1  1  0 39  1  0  0  2 34  0  0  0  0 45]\n",
      "svc Accuracy:  0.9323308270676691\n",
      "svc F1:  0.8794422897364074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        12\n",
      "          1       0.83      0.97      0.90        40\n",
      "          2       1.00      0.86      0.93        36\n",
      "          3       0.92      1.00      0.96        45\n",
      "\n",
      "avg / total       0.92      0.91      0.90       133\n",
      "\n",
      "[ 6  5  0  1  0 39  0  1  0  3 31  2  0  0  0 45]\n",
      "LR Accuracy:  0.9097744360902256\n",
      "LR F1:  0.8615095834108986\n",
      "For name:  d_matthews\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0003-4611-8795': 36, '0000-0002-3579-3608': 11, '0000-0003-3562-9549': 9, '0000-0002-0516-7470': 1})\n",
      "['0000-0002-3579-3608', '0000-0003-4611-8795']\n",
      "Total sample size after apply threshold:  47\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(47, 330)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.76      0.97      0.85        36\n",
      "\n",
      "avg / total       0.58      0.74      0.65        47\n",
      "\n",
      "[ 0 11  1 35]\n",
      "MNB Accuracy:  0.7446808510638298\n",
      "MNB F1:  0.426829268292683\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.18      0.31        11\n",
      "          1       0.80      1.00      0.89        36\n",
      "\n",
      "avg / total       0.85      0.81      0.75        47\n",
      "\n",
      "[ 2  9  0 36]\n",
      "svc Accuracy:  0.8085106382978723\n",
      "svc F1:  0.5982905982905984\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.77      1.00      0.87        36\n",
      "\n",
      "avg / total       0.59      0.77      0.66        47\n",
      "\n",
      "[ 0 11  0 36]\n",
      "LR Accuracy:  0.7659574468085106\n",
      "LR F1:  0.43373493975903615\n",
      "For name:  j_christensen\n",
      "total sample size before apply threshold:  203\n",
      "Counter({'0000-0002-4299-9479': 100, '0000-0003-1414-1886': 53, '0000-0002-7641-8302': 32, '0000-0002-6741-5839': 13, '0000-0002-2689-1169': 1, '0000-0002-9231-8029': 1, '0000-0003-4225-3359': 1, '0000-0003-2370-2702': 1, '0000-0002-2495-8905': 1})\n",
      "['0000-0002-7641-8302', '0000-0002-4299-9479', '0000-0002-6741-5839', '0000-0003-1414-1886']\n",
      "Total sample size after apply threshold:  198\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(198, 373)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.59      0.75        32\n",
      "          1       0.76      0.99      0.86       100\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.80      0.74      0.76        53\n",
      "\n",
      "avg / total       0.76      0.79      0.76       198\n",
      "\n",
      "[19 10  0  3  0 99  0  1  0  7  0  6  0 14  0 39]\n",
      "MNB Accuracy:  0.7929292929292929\n",
      "MNB F1:  0.5926683716965047\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        32\n",
      "          1       1.00      0.96      0.98       100\n",
      "          2       1.00      0.38      0.56        13\n",
      "          3       0.78      1.00      0.88        53\n",
      "\n",
      "avg / total       0.94      0.92      0.92       198\n",
      "\n",
      "[29  0  0  3  0 96  0  4  0  0  5  8  0  0  0 53]\n",
      "svc Accuracy:  0.9242424242424242\n",
      "svc F1:  0.8405000305681591\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        32\n",
      "          1       0.77      0.99      0.87       100\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.80      0.81      0.80        53\n",
      "\n",
      "avg / total       0.77      0.80      0.76       198\n",
      "\n",
      "[16 12  0  4  0 99  0  1  0  7  0  6  0 10  0 43]\n",
      "LR Accuracy:  0.797979797979798\n",
      "LR F1:  0.5847065092638137\n",
      "For name:  j_sampaio\n",
      "total sample size before apply threshold:  117\n",
      "Counter({'0000-0003-2335-9991': 61, '0000-0001-8145-5274': 48, '0000-0003-4359-493X': 5, '0000-0002-0460-3664': 3})\n",
      "['0000-0003-2335-9991', '0000-0001-8145-5274']\n",
      "Total sample size after apply threshold:  109\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 252)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "109\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        61\n",
      "          1       1.00      0.90      0.95        48\n",
      "\n",
      "avg / total       0.96      0.95      0.95       109\n",
      "\n",
      "[61  0  5 43]\n",
      "MNB Accuracy:  0.9541284403669725\n",
      "MNB F1:  0.9528424331573937\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94        61\n",
      "          1       0.98      0.88      0.92        48\n",
      "\n",
      "avg / total       0.94      0.94      0.94       109\n",
      "\n",
      "[60  1  6 42]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "svc Accuracy:  0.9357798165137615\n",
      "svc F1:  0.9339794064203513\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        61\n",
      "          1       1.00      0.83      0.91        48\n",
      "\n",
      "avg / total       0.94      0.93      0.93       109\n",
      "\n",
      "[61  0  8 40]\n",
      "LR Accuracy:  0.926605504587156\n",
      "LR F1:  0.9237762237762238\n",
      "For name:  j_dias\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-7613-6241': 9, '0000-0002-1150-4357': 9, '0000-0003-3732-7122': 5, '0000-0003-2517-7905': 3, '0000-0002-0966-0537': 3, '0000-0003-4732-7230': 1, '0000-0002-6271-6501': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  p_nunes\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0002-4598-685X': 19, '0000-0003-4740-8268': 12, '0000-0002-4641-8846': 4, '0000-0003-1693-1267': 1})\n",
      "['0000-0002-4598-685X', '0000-0003-4740-8268']\n",
      "Total sample size after apply threshold:  31\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(31, 108)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "31\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        31\n",
      "\n",
      "[19  0  0 12]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        19\n",
      "          1       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97        31\n",
      "\n",
      "[19  0  1 11]\n",
      "svc Accuracy:  0.967741935483871\n",
      "svc F1:  0.9654403567447045\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        19\n",
      "          1       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.92      0.90      0.90        31\n",
      "\n",
      "[19  0  3  9]\n",
      "LR Accuracy:  0.9032258064516129\n",
      "LR F1:  0.89198606271777\n",
      "For name:  c_bauer\n",
      "total sample size before apply threshold:  7\n",
      "Counter({'0000-0001-9511-2491': 4, '0000-0003-3466-7076': 1, '0000-0001-8288-8290': 1, '0000-0002-3368-6681': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  r_patel\n",
      "total sample size before apply threshold:  182\n",
      "Counter({'0000-0002-1526-4303': 128, '0000-0002-7444-5550': 16, '0000-0002-4712-1921': 9, '0000-0003-1586-5595': 8, '0000-0002-3851-8257': 8, '0000-0001-6344-4141': 4, '0000-0001-7667-5918': 3, '0000-0002-8442-0349': 2, '0000-0001-5330-1438': 2, '0000-0002-5398-2496': 1, '0000-0002-3418-0260': 1})\n",
      "['0000-0002-7444-5550', '0000-0002-1526-4303']\n",
      "Total sample size after apply threshold:  144\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(144, 526)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "144\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.89      1.00      0.94       128\n",
      "\n",
      "avg / total       0.79      0.89      0.84       144\n",
      "\n",
      "[  0  16   0 128]\n",
      "MNB Accuracy:  0.8888888888888888\n",
      "MNB F1:  0.47058823529411764\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.12      0.22        16\n",
      "          1       0.90      1.00      0.95       128\n",
      "\n",
      "avg / total       0.91      0.90      0.87       144\n",
      "\n",
      "[  2  14   0 128]\n",
      "svc Accuracy:  0.9027777777777778\n",
      "svc F1:  0.5851851851851851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.89      1.00      0.94       128\n",
      "\n",
      "avg / total       0.79      0.89      0.84       144\n",
      "\n",
      "[  0  16   0 128]\n",
      "LR Accuracy:  0.8888888888888888\n",
      "LR F1:  0.47058823529411764\n",
      "For name:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_das\n",
      "total sample size before apply threshold:  74\n",
      "Counter({'0000-0002-0883-1816': 14, '0000-0002-7033-1441': 10, '0000-0003-0740-8140': 8, '0000-0001-5924-4235': 6, '0000-0001-7383-9606': 5, '0000-0002-5196-9589': 5, '0000-0002-7510-1805': 5, '0000-0003-1801-7487': 4, '0000-0002-1733-626X': 3, '0000-0003-0616-9715': 3, '0000-0002-7473-6139': 2, '0000-0003-4305-6007': 2, '0000-0002-2101-9056': 2, '0000-0003-0921-8877': 2, '0000-0001-5884-0852': 1, '0000-0002-0445-0012': 1, '0000-0002-0141-0963': 1})\n",
      "['0000-0002-7033-1441', '0000-0002-0883-1816']\n",
      "Total sample size after apply threshold:  24\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(24, 86)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "24\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.88      1.00      0.93        14\n",
      "\n",
      "avg / total       0.93      0.92      0.91        24\n",
      "\n",
      "[ 8  2  0 14]\n",
      "MNB Accuracy:  0.9166666666666666\n",
      "MNB F1:  0.9111111111111112\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        24\n",
      "\n",
      "[10  0  0 14]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.88      1.00      0.93        14\n",
      "\n",
      "avg / total       0.93      0.92      0.91        24\n",
      "\n",
      "[ 8  2  0 14]\n",
      "LR Accuracy:  0.9166666666666666\n",
      "LR F1:  0.9111111111111112\n",
      "For name:  c_becker\n",
      "total sample size before apply threshold:  110\n",
      "Counter({'0000-0002-1388-1041': 40, '0000-0002-1716-7208': 27, '0000-0002-6369-2185': 17, '0000-0002-7035-6083': 11, '0000-0002-9179-7996': 7, '0000-0003-3406-4670': 6, '0000-0002-8385-0785': 2})\n",
      "['0000-0002-6369-2185', '0000-0002-7035-6083', '0000-0002-1388-1041', '0000-0002-1716-7208']\n",
      "Total sample size after apply threshold:  95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 389)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "95\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        17\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       0.64      0.97      0.77        40\n",
      "          3       0.96      0.93      0.94        27\n",
      "\n",
      "avg / total       0.84      0.76      0.72        95\n",
      "\n",
      "[ 7  0 10  0  0  1 10  0  0  0 39  1  0  0  2 25]\n",
      "MNB Accuracy:  0.7578947368421053\n",
      "MNB F1:  0.6164183635344667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        17\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       0.83      0.97      0.90        40\n",
      "          3       0.96      0.93      0.94        27\n",
      "\n",
      "avg / total       0.92      0.91      0.90        95\n",
      "\n",
      "[14  0  3  0  0  8  3  0  0  0 39  1  0  0  2 25]\n",
      "svc Accuracy:  0.9052631578947369\n",
      "svc F1:  0.8963197550406332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        17\n",
      "          1       1.00      0.27      0.43        11\n",
      "          2       0.62      0.97      0.76        40\n",
      "          3       0.95      0.78      0.86        27\n",
      "\n",
      "avg / total       0.83      0.74      0.72        95\n",
      "\n",
      "[ 7  0 10  0  0  3  8  0  0  0 39  1  0  0  6 21]\n",
      "LR Accuracy:  0.7368421052631579\n",
      "LR F1:  0.6565822931114194\n",
      "For name:  k_zhu\n",
      "total sample size before apply threshold:  6\n",
      "Counter({'0000-0001-7664-7204': 3, '0000-0003-4361-1138': 1, '0000-0003-2784-3190': 1, '0000-0003-2293-3568': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  a_machado\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-8132-5610': 54, '0000-0002-5677-7332': 30, '0000-0003-4380-3711': 25, '0000-0001-6200-3686': 16, '0000-0003-0732-1571': 14, '0000-0003-1999-1206': 4, '0000-0003-1947-8605': 4, '0000-0001-8957-661X': 2, '0000-0001-9341-5827': 1})\n",
      "['0000-0002-8132-5610', '0000-0002-5677-7332', '0000-0003-4380-3711', '0000-0003-0732-1571', '0000-0001-6200-3686']\n",
      "Total sample size after apply threshold:  139\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(139, 362)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.98      0.76        54\n",
      "          1       0.74      0.83      0.78        30\n",
      "          2       0.67      0.32      0.43        25\n",
      "          3       1.00      0.43      0.60        14\n",
      "          4       1.00      0.06      0.12        16\n",
      "\n",
      "avg / total       0.73      0.67      0.61       139\n",
      "\n",
      "[53  1  0  0  0  4 25  1  0  0 14  3  8  0  0  5  1  2  6  0 10  4  1  0\n",
      "  1]\n",
      "MNB Accuracy:  0.6690647482014388\n",
      "MNB F1:  0.5376944696797639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.98      0.81        54\n",
      "          1       0.84      0.87      0.85        30\n",
      "          2       0.69      0.36      0.47        25\n",
      "          3       1.00      0.57      0.73        14\n",
      "          4       0.90      0.56      0.69        16\n",
      "\n",
      "avg / total       0.78      0.76      0.74       139\n",
      "\n",
      "[53  0  1  0  0  4 26  0  0  0 12  3  9  0  1  3  1  2  8  0  5  1  1  0\n",
      "  9]\n",
      "svc Accuracy:  0.7553956834532374\n",
      "svc F1:  0.7109767903687378\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.98      0.67        54\n",
      "          1       0.82      0.60      0.69        30\n",
      "          2       1.00      0.24      0.39        25\n",
      "          3       1.00      0.43      0.60        14\n",
      "          4       1.00      0.06      0.12        16\n",
      "\n",
      "avg / total       0.77      0.60      0.55       139\n",
      "\n",
      "[53  1  0  0  0 12 18  0  0  0 17  2  6  0  0  8  0  0  6  0 14  1  0  0\n",
      "  1]\n",
      "LR Accuracy:  0.60431654676259\n",
      "LR F1:  0.49358752025482744\n",
      "For name:  j_alexander\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0001-6783-4382': 11, '0000-0003-2226-7913': 10, '0000-0002-2258-5738': 5, '0000-0001-9797-6322': 2, '0000-0002-6492-1621': 2, '0000-0001-7734-9428': 1})\n",
      "['0000-0001-6783-4382', '0000-0003-2226-7913']\n",
      "Total sample size after apply threshold:  21\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(21, 123)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "21\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        11\n",
      "          1       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.89      0.86      0.85        21\n",
      "\n",
      "[11  0  3  7]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.851764705882353\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.83      1.00      0.91        10\n",
      "\n",
      "avg / total       0.92      0.90      0.90        21\n",
      "\n",
      "[ 9  2  0 10]\n",
      "svc Accuracy:  0.9047619047619048\n",
      "svc F1:  0.9045454545454545\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.83      1.00      0.91        10\n",
      "\n",
      "avg / total       0.92      0.90      0.90        21\n",
      "\n",
      "[ 9  2  0 10]\n",
      "LR Accuracy:  0.9047619047619048\n",
      "LR F1:  0.9045454545454545\n",
      "For name:  j_schneider\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0001-8016-8687': 13, '0000-0002-6028-9956': 7, '0000-0003-1114-618X': 5, '0000-0001-7169-3973': 5, '0000-0003-1176-8309': 3, '0000-0001-5187-6756': 3, '0000-0002-5863-7747': 1, '0000-0001-6093-5404': 1, '0000-0001-5556-0919': 1, '0000-0001-9610-6501': 1})\n",
      "['0000-0001-8016-8687']\n",
      "Total sample size after apply threshold:  13\n",
      "For name:  g_russo\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-8764-7389': 22, '0000-0002-2716-369X': 11, '0000-0003-1493-1087': 7, '0000-0001-9321-1613': 5, '0000-0003-4687-7353': 5, '0000-0001-5001-3027': 4, '0000-0002-4565-3131': 2, '0000-0003-4215-1926': 1, '0000-0002-7779-6225': 1})\n",
      "['0000-0002-8764-7389', '0000-0002-2716-369X']\n",
      "Total sample size after apply threshold:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 175)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.86      0.84        22\n",
      "          1       0.70      0.64      0.67        11\n",
      "\n",
      "avg / total       0.78      0.79      0.79        33\n",
      "\n",
      "[19  3  4  7]\n",
      "MNB Accuracy:  0.7878787878787878\n",
      "MNB F1:  0.7555555555555555\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        22\n",
      "          1       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.94      0.94      0.94        33\n",
      "\n",
      "[22  0  2  9]\n",
      "svc Accuracy:  0.9393939393939394\n",
      "svc F1:  0.9282608695652175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        22\n",
      "          1       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.81      0.73      0.66        33\n",
      "\n",
      "[22  0  9  2]\n",
      "LR Accuracy:  0.7272727272727273\n",
      "LR F1:  0.5689404934687954\n",
      "For name:  j_carvalho\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-3015-7821': 49, '0000-0001-5256-1422': 33, '0000-0003-4495-057X': 22, '0000-0003-2362-0010': 15, '0000-0001-9743-438X': 9, '0000-0001-8091-5419': 3, '0000-0002-4235-1242': 2, '0000-0002-4027-735X': 2, '0000-0002-6263-344X': 1})\n",
      "['0000-0003-4495-057X', '0000-0001-5256-1422', '0000-0003-2362-0010', '0000-0002-3015-7821']\n",
      "Total sample size after apply threshold:  119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(119, 6019)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "119\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        22\n",
      "          1       0.74      0.97      0.84        33\n",
      "          2       1.00      0.93      0.97        15\n",
      "          3       0.98      0.94      0.96        49\n",
      "\n",
      "avg / total       0.92      0.90      0.90       119\n",
      "\n",
      "[15  7  0  0  0 32  0  1  0  1 14  0  0  3  0 46]\n",
      "MNB Accuracy:  0.8991596638655462\n",
      "MNB F1:  0.8941916621703374\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.86      0.90        22\n",
      "          1       0.86      0.97      0.91        33\n",
      "          2       1.00      1.00      1.00        15\n",
      "          3       1.00      0.96      0.98        49\n",
      "\n",
      "avg / total       0.95      0.95      0.95       119\n",
      "\n",
      "[19  3  0  0  1 32  0  0  0  0 15  0  0  2  0 47]\n",
      "svc Accuracy:  0.9495798319327731\n",
      "svc F1:  0.9495535714285713\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.77      0.85        22\n",
      "          1       0.82      0.97      0.89        33\n",
      "          2       1.00      1.00      1.00        15\n",
      "          3       1.00      0.96      0.98        49\n",
      "\n",
      "avg / total       0.94      0.93      0.93       119\n",
      "\n",
      "[17  5  0  0  1 32  0  0  0  0 15  0  0  2  0 47]\n",
      "LR Accuracy:  0.9327731092436975\n",
      "LR F1:  0.9295138888888889\n",
      "For name:  y_nishikawa\n",
      "total sample size before apply threshold:  21\n",
      "Counter({'0000-0002-0739-8491': 10, '0000-0003-3313-1990': 8, '0000-0002-0088-8447': 2, '0000-0002-1113-6937': 1})\n",
      "['0000-0002-0739-8491']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  j_ward\n",
      "total sample size before apply threshold:  22\n",
      "Counter({'0000-0001-9870-8936': 11, '0000-0002-4108-4330': 5, '0000-0002-4698-8857': 3, '0000-0002-4196-4653': 1, '0000-0003-0289-117X': 1, '0000-0002-4415-5544': 1})\n",
      "['0000-0001-9870-8936']\n",
      "Total sample size after apply threshold:  11\n",
      "For name:  m_singh\n",
      "total sample size before apply threshold:  133\n",
      "Counter({'0000-0002-8072-1769': 52, '0000-0003-3044-1010': 22, '0000-0002-2884-0074': 21, '0000-0002-8396-5451': 21, '0000-0001-8569-8599': 4, '0000-0002-9124-1859': 4, '0000-0001-8526-2955': 3, '0000-0002-9010-0990': 2, '0000-0002-5783-073X': 1, '0000-0003-0051-336X': 1, '0000-0001-9166-626X': 1, '0000-0002-0034-9726': 1})\n",
      "['0000-0003-3044-1010', '0000-0002-8072-1769', '0000-0002-2884-0074', '0000-0002-8396-5451']\n",
      "Total sample size after apply threshold:  116\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(116, 295)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        22\n",
      "          1       0.80      0.98      0.88        52\n",
      "          2       1.00      0.57      0.73        21\n",
      "          3       0.95      1.00      0.98        21\n",
      "\n",
      "avg / total       0.90      0.88      0.87       116\n",
      "\n",
      "[18  4  0  0  0 51  0  1  0  9 12  0  0  0  0 21]\n",
      "MNB Accuracy:  0.8793103448275862\n",
      "MNB F1:  0.8708318145367062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93        22\n",
      "          1       0.88      0.98      0.93        52\n",
      "          2       0.94      0.81      0.87        21\n",
      "          3       1.00      1.00      1.00        21\n",
      "\n",
      "avg / total       0.94      0.93      0.93       116\n",
      "\n",
      "[19  3  0  0  0 51  1  0  0  4 17  0  0  0  0 21]\n",
      "svc Accuracy:  0.9310344827586207\n",
      "svc F1:  0.9314742168400705\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        22\n",
      "          1       0.62      0.98      0.76        52\n",
      "          2       1.00      0.29      0.44        21\n",
      "          3       0.95      0.86      0.90        21\n",
      "\n",
      "avg / total       0.82      0.72      0.69       116\n",
      "\n",
      "[ 9 13  0  0  0 51  0  1  0 15  6  0  0  3  0 18]\n",
      "LR Accuracy:  0.7241379310344828\n",
      "LR F1:  0.6715709088963784\n",
      "For name:  a_bhattacharyya\n",
      "total sample size before apply threshold:  14\n",
      "Counter({'0000-0002-1646-709X': 8, '0000-0002-5948-3364': 3, '0000-0001-7011-2102': 2, '0000-0003-1077-2082': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  e_morris\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0001-7046-3623': 29, '0000-0003-1893-7515': 7, '0000-0002-5011-6744': 3, '0000-0002-9913-6041': 1})\n",
      "['0000-0001-7046-3623']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  m_lewis\n",
      "total sample size before apply threshold:  177\n",
      "Counter({'0000-0002-8430-4479': 63, '0000-0002-5735-5318': 35, '0000-0002-6709-9215': 30, '0000-0001-6042-0865': 13, '0000-0002-2062-6006': 11, '0000-0001-9365-5345': 9, '0000-0002-6241-3690': 8, '0000-0001-5918-3444': 3, '0000-0002-1154-9096': 2, '0000-0002-9703-8456': 1, '0000-0003-4410-5720': 1, '0000-0003-0897-1621': 1})\n",
      "['0000-0002-5735-5318', '0000-0002-8430-4479', '0000-0001-6042-0865', '0000-0002-2062-6006', '0000-0002-6709-9215']\n",
      "Total sample size after apply threshold:  152\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(152, 273)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "152\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.49      0.59        35\n",
      "          1       0.65      0.98      0.78        63\n",
      "          2       1.00      0.38      0.56        13\n",
      "          3       1.00      0.09      0.17        11\n",
      "          4       0.96      0.87      0.91        30\n",
      "\n",
      "avg / total       0.79      0.73      0.70       152\n",
      "\n",
      "[17 18  0  0  0  1 62  0  0  0  3  4  5  0  1  2  8  0  1  0  0  4  0  0\n",
      " 26]\n",
      "MNB Accuracy:  0.7302631578947368\n",
      "MNB F1:  0.6001168068729621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.49      0.64        35\n",
      "          1       0.65      0.98      0.78        63\n",
      "          2       1.00      0.77      0.87        13\n",
      "          3       1.00      0.27      0.43        11\n",
      "          4       1.00      0.83      0.91        30\n",
      "\n",
      "avg / total       0.84      0.77      0.76       152\n",
      "\n",
      "[17 18  0  0  0  1 62  0  0  0  0  3 10  0  0  0  8  0  3  0  0  5  0  0\n",
      " 25]\n",
      "svc Accuracy:  0.7697368421052632\n",
      "svc F1:  0.7257222405704769\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.46      0.63        35\n",
      "          1       0.59      1.00      0.74        63\n",
      "          2       1.00      0.46      0.63        13\n",
      "          3       0.00      0.00      0.00        11\n",
      "          4       1.00      0.77      0.87        30\n",
      "\n",
      "avg / total       0.76      0.71      0.68       152\n",
      "\n",
      "[16 19  0  0  0  0 63  0  0  0  0  7  6  0  0  0 11  0  0  0  0  7  0  0\n",
      " 23]\n",
      "LR Accuracy:  0.7105263157894737\n",
      "LR F1:  0.57362618533014\n",
      "For name:  v_fernandes\n",
      "total sample size before apply threshold:  55\n",
      "Counter({'0000-0001-6060-9035': 17, '0000-0002-3873-2034': 16, '0000-0003-3979-7523': 15, '0000-0002-9671-3923': 6, '0000-0003-0568-2920': 1})\n",
      "['0000-0003-3979-7523', '0000-0002-3873-2034', '0000-0001-6060-9035']\n",
      "Total sample size after apply threshold:  48\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 132)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        15\n",
      "          1       0.94      1.00      0.97        16\n",
      "          2       1.00      1.00      1.00        17\n",
      "\n",
      "avg / total       0.98      0.98      0.98        48\n",
      "\n",
      "[14  1  0  0 16  0  0  0 17]\n",
      "MNB Accuracy:  0.9791666666666666\n",
      "MNB F1:  0.9784047370254267\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        15\n",
      "          1       0.94      1.00      0.97        16\n",
      "          2       1.00      1.00      1.00        17\n",
      "\n",
      "avg / total       0.98      0.98      0.98        48\n",
      "\n",
      "[14  1  0  0 16  0  0  0 17]\n",
      "svc Accuracy:  0.9791666666666666\n",
      "svc F1:  0.9784047370254267\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        15\n",
      "          1       0.94      1.00      0.97        16\n",
      "          2       1.00      1.00      1.00        17\n",
      "\n",
      "avg / total       0.98      0.98      0.98        48\n",
      "\n",
      "[14  1  0  0 16  0  0  0 17]\n",
      "LR Accuracy:  0.9791666666666666\n",
      "LR F1:  0.9784047370254267\n",
      "For name:  m_pinheiro\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0001-8228-3435': 30, '0000-0002-6931-1355': 16, '0000-0002-5500-7408': 2, '0000-0003-0758-5526': 2, '0000-0003-2523-245X': 2, '0000-0001-5963-8947': 1, '0000-0001-8234-6790': 1})\n",
      "['0000-0001-8228-3435', '0000-0002-6931-1355']\n",
      "Total sample size after apply threshold:  46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(46, 234)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95        30\n",
      "          1       0.88      0.94      0.91        16\n",
      "\n",
      "avg / total       0.94      0.93      0.94        46\n",
      "\n",
      "[28  2  1 15]\n",
      "MNB Accuracy:  0.9347826086956522\n",
      "MNB F1:  0.9291217257318953\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        30\n",
      "          1       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.98      0.98      0.98        46\n",
      "\n",
      "[30  0  1 15]\n",
      "svc Accuracy:  0.9782608695652174\n",
      "svc F1:  0.9756742464304601\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        30\n",
      "          1       1.00      0.75      0.86        16\n",
      "\n",
      "avg / total       0.92      0.91      0.91        46\n",
      "\n",
      "[30  0  4 12]\n",
      "LR Accuracy:  0.9130434782608695\n",
      "LR F1:  0.8973214285714286\n",
      "For name:  j_petersen\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0001-9615-1310': 12, '0000-0001-6116-5114': 10, '0000-0001-8612-2508': 5, '0000-0003-0138-0693': 5, '0000-0002-4071-0416': 4, '0000-0002-7715-0088': 2, '0000-0001-6857-982X': 1, '0000-0003-2976-308X': 1, '0000-0003-4939-5149': 1})\n",
      "['0000-0001-6116-5114', '0000-0001-9615-1310']\n",
      "Total sample size after apply threshold:  22\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 51)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "22\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "[ 9  1  0 12]\n",
      "MNB Accuracy:  0.9545454545454546\n",
      "MNB F1:  0.9536842105263159\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "[ 9  1  0 12]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.9536842105263159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       0.80      1.00      0.89        12\n",
      "\n",
      "avg / total       0.89      0.86      0.86        22\n",
      "\n",
      "[ 7  3  0 12]\n",
      "LR Accuracy:  0.8636363636363636\n",
      "LR F1:  0.8562091503267975\n",
      "For name:  k_shimizu\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0002-0229-6541': 44, '0000-0003-2454-1795': 37, '0000-0003-1574-5526': 10, '0000-0001-8261-8098': 8, '0000-0002-2796-8666': 4})\n",
      "['0000-0002-0229-6541', '0000-0003-1574-5526', '0000-0003-2454-1795']\n",
      "Total sample size after apply threshold:  91\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 186)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "91\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        44\n",
      "          1       1.00      0.30      0.46        10\n",
      "          2       1.00      1.00      1.00        37\n",
      "\n",
      "avg / total       0.93      0.92      0.91        91\n",
      "\n",
      "[44  0  0  7  3  0  0  0 37]\n",
      "MNB Accuracy:  0.9230769230769231\n",
      "MNB F1:  0.7959514170040486\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        44\n",
      "          1       1.00      0.70      0.82        10\n",
      "          2       1.00      1.00      1.00        37\n",
      "\n",
      "avg / total       0.97      0.97      0.96        91\n",
      "\n",
      "[44  0  0  3  7  0  0  0 37]\n",
      "svc Accuracy:  0.967032967032967\n",
      "svc F1:  0.9301874595992242\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        44\n",
      "          1       1.00      0.30      0.46        10\n",
      "          2       1.00      1.00      1.00        37\n",
      "\n",
      "avg / total       0.93      0.92      0.91        91\n",
      "\n",
      "[44  0  0  7  3  0  0  0 37]\n",
      "LR Accuracy:  0.9230769230769231\n",
      "LR F1:  0.7959514170040486\n",
      "For name:  p_shaw\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0002-8925-2567': 21, '0000-0003-1076-2669': 18, '0000-0003-3698-1608': 12, '0000-0002-3326-3670': 6})\n",
      "['0000-0002-8925-2567', '0000-0003-1076-2669', '0000-0003-3698-1608']\n",
      "Total sample size after apply threshold:  51\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 187)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.86      0.80        21\n",
      "          1       0.52      0.67      0.59        18\n",
      "          2       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.73      0.67      0.65        51\n",
      "\n",
      "[18  3  0  6 12  0  0  8  4]\n",
      "MNB Accuracy:  0.6666666666666666\n",
      "MNB F1:  0.6284552845528455\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.81      0.87        21\n",
      "          1       0.62      1.00      0.77        18\n",
      "          2       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.84      0.76      0.75        51\n",
      "\n",
      "[17  4  0  0 18  0  1  7  4]\n",
      "svc Accuracy:  0.7647058823529411\n",
      "svc F1:  0.7125841062011276\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.90      0.76        21\n",
      "          1       0.61      0.61      0.61        18\n",
      "          2       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.72      0.67      0.65        51\n",
      "\n",
      "[19  2  0  7 11  0  3  5  4]\n",
      "LR Accuracy:  0.6666666666666666\n",
      "LR F1:  0.6237037037037036\n",
      "For name:  g_coppola\n",
      "total sample size before apply threshold:  142\n",
      "Counter({'0000-0002-9574-0081': 61, '0000-0002-8510-6925': 57, '0000-0003-0147-6142': 16, '0000-0003-2675-783X': 7, '0000-0001-7139-3719': 1})\n",
      "['0000-0002-9574-0081', '0000-0002-8510-6925', '0000-0003-0147-6142']\n",
      "Total sample size after apply threshold:  134\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(134, 482)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "134\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.94        61\n",
      "          1       0.86      1.00      0.93        57\n",
      "          2       1.00      0.38      0.55        16\n",
      "\n",
      "avg / total       0.91      0.90      0.89       134\n",
      "\n",
      "[58  3  0  0 57  0  4  6  6]\n",
      "MNB Accuracy:  0.9029850746268657\n",
      "MNB F1:  0.8051244148805123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        61\n",
      "          1       1.00      0.96      0.98        57\n",
      "          2       1.00      0.69      0.81        16\n",
      "\n",
      "avg / total       0.95      0.95      0.95       134\n",
      "\n",
      "[61  0  0  2 55  0  5  0 11]\n",
      "svc Accuracy:  0.9477611940298507\n",
      "svc F1:  0.914231368688733\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        61\n",
      "          1       1.00      0.93      0.96        57\n",
      "          2       1.00      0.19      0.32        16\n",
      "\n",
      "avg / total       0.90      0.87      0.85       134\n",
      "\n",
      "[61  0  0  4 53  0 13  0  3]\n",
      "LR Accuracy:  0.8731343283582089\n",
      "LR F1:  0.7190412263490643\n",
      "For name:  a_sinclair\n",
      "total sample size before apply threshold:  109\n",
      "Counter({'0000-0003-2741-7992': 64, '0000-0001-8510-8691': 31, '0000-0002-2628-1686': 9, '0000-0002-5602-5958': 5})\n",
      "['0000-0003-2741-7992', '0000-0001-8510-8691']\n",
      "Total sample size after apply threshold:  95\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 276)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "95\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91        64\n",
      "          1       0.91      0.68      0.78        31\n",
      "\n",
      "avg / total       0.88      0.87      0.87        95\n",
      "\n",
      "[62  2 10 21]\n",
      "MNB Accuracy:  0.8736842105263158\n",
      "MNB F1:  0.8447712418300654\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95        64\n",
      "          1       0.93      0.84      0.88        31\n",
      "\n",
      "avg / total       0.93      0.93      0.93        95\n",
      "\n",
      "[62  2  5 26]\n",
      "svc Accuracy:  0.9263157894736842\n",
      "svc F1:  0.9139604088497866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        64\n",
      "          1       1.00      0.45      0.62        31\n",
      "\n",
      "avg / total       0.86      0.82      0.80        95\n",
      "\n",
      "[64  0 17 14]\n",
      "LR Accuracy:  0.8210526315789474\n",
      "LR F1:  0.7524904214559387\n",
      "For name:  y_pan\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0001-7709-0508': 15, '0000-0002-6311-2945': 14, '0000-0002-8587-6065': 7, '0000-0002-5547-0849': 3, '0000-0002-1173-1074': 2, '0000-0001-5133-1342': 1, '0000-0002-3945-6377': 1, '0000-0002-0090-1285': 1, '0000-0002-6894-7271': 1, '0000-0002-9195-3776': 1})\n",
      "['0000-0002-6311-2945', '0000-0001-7709-0508']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 62)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[13  1  0 15]\n",
      "MNB Accuracy:  0.9655172413793104\n",
      "MNB F1:  0.965352449223417\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[13  1  0 15]\n",
      "svc Accuracy:  0.9655172413793104\n",
      "svc F1:  0.965352449223417\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.88      1.00      0.94        15\n",
      "\n",
      "avg / total       0.94      0.93      0.93        29\n",
      "\n",
      "[12  2  0 15]\n",
      "LR Accuracy:  0.9310344827586207\n",
      "LR F1:  0.9302884615384615\n",
      "For name:  m_ramos\n",
      "total sample size before apply threshold:  251\n",
      "Counter({'0000-0002-7554-8324': 187, '0000-0002-8950-2079': 22, '0000-0003-3230-8045': 13, '0000-0002-2157-9774': 8, '0000-0001-6176-5048': 7, '0000-0001-8849-6386': 3, '0000-0001-5224-5665': 3, '0000-0002-2582-7616': 2, '0000-0001-5832-0945': 1, '0000-0001-6594-6591': 1, '0000-0001-6821-3692': 1, '0000-0002-3117-4498': 1, '0000-0003-1133-4164': 1, '0000-0002-9480-782X': 1})\n",
      "['0000-0002-8950-2079', '0000-0003-3230-8045', '0000-0002-7554-8324']\n",
      "Total sample size after apply threshold:  222\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(222, 247)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93        22\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       0.95      1.00      0.97       187\n",
      "\n",
      "avg / total       0.96      0.95      0.95       222\n",
      "\n",
      "[ 19   0   3   0   6   7   0   0 187]\n",
      "MNB Accuracy:  0.954954954954955\n",
      "MNB F1:  0.8441221829981457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93        22\n",
      "          1       1.00      0.77      0.87        13\n",
      "          2       0.97      1.00      0.98       187\n",
      "\n",
      "avg / total       0.97      0.97      0.97       222\n",
      "\n",
      "[ 19   0   3   0  10   3   0   0 187]\n",
      "svc Accuracy:  0.972972972972973\n",
      "svc F1:  0.9268683373332589\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.41      0.58        22\n",
      "          1       1.00      0.23      0.38        13\n",
      "          2       0.89      1.00      0.94       187\n",
      "\n",
      "avg / total       0.91      0.90      0.87       222\n",
      "\n",
      "[  9   0  13   0   3  10   0   0 187]\n",
      "LR Accuracy:  0.8963963963963963\n",
      "LR F1:  0.6325702174914006\n",
      "For name:  j_tsai\n",
      "total sample size before apply threshold:  153\n",
      "Counter({'0000-0003-2723-6841': 83, '0000-0002-8657-3744': 38, '0000-0002-5227-8894': 16, '0000-0001-5202-722X': 7, '0000-0002-8666-2739': 5, '0000-0002-5332-2818': 2, '0000-0003-1693-9437': 1, '0000-0003-4921-3982': 1})\n",
      "['0000-0003-2723-6841', '0000-0002-8657-3744', '0000-0002-5227-8894']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size after apply threshold:  137\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(137, 112)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "137\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.96      0.89        83\n",
      "          1       0.92      0.92      0.92        38\n",
      "          2       1.00      0.12      0.22        16\n",
      "\n",
      "avg / total       0.87      0.85      0.82       137\n",
      "\n",
      "[80  3  0  3 35  0 14  0  2]\n",
      "MNB Accuracy:  0.8540145985401459\n",
      "MNB F1:  0.6773879142300195\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.98        83\n",
      "          1       1.00      0.97      0.99        38\n",
      "          2       0.93      0.88      0.90        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97       137\n",
      "\n",
      "[82  0  1  1 37  0  2  0 14]\n",
      "svc Accuracy:  0.9708029197080292\n",
      "svc F1:  0.9553609831029185\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91        83\n",
      "          1       0.97      0.89      0.93        38\n",
      "          2       0.86      0.38      0.52        16\n",
      "\n",
      "avg / total       0.89      0.88      0.87       137\n",
      "\n",
      "[81  1  1  4 34  0 10  0  6]\n",
      "LR Accuracy:  0.8832116788321168\n",
      "LR F1:  0.7877861131001375\n",
      "For name:  f_dai\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-7651-8549': 18, '0000-0003-0850-6906': 11, '0000-0002-9229-5576': 4, '0000-0002-2983-4880': 1})\n",
      "['0000-0003-0850-6906', '0000-0002-7651-8549']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 41)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.95      1.00      0.97        18\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[10  1  0 18]\n",
      "MNB Accuracy:  0.9655172413793104\n",
      "MNB F1:  0.9626769626769627\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        18\n",
      "\n",
      "avg / total       1.00      1.00      1.00        29\n",
      "\n",
      "[11  0  0 18]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.95      1.00      0.97        18\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[10  1  0 18]\n",
      "LR Accuracy:  0.9655172413793104\n",
      "LR F1:  0.9626769626769627\n",
      "For name:  t_martin\n",
      "total sample size before apply threshold:  83\n",
      "Counter({'0000-0002-4028-4867': 43, '0000-0001-7165-9812': 28, '0000-0002-7872-4194': 7, '0000-0003-2800-5308': 2, '0000-0002-1609-078X': 1, '0000-0002-7302-1190': 1, '0000-0002-6242-6782': 1})\n",
      "['0000-0001-7165-9812', '0000-0002-4028-4867']\n",
      "Total sample size after apply threshold:  71\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 146)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.61      0.76        28\n",
      "          1       0.80      1.00      0.89        43\n",
      "\n",
      "avg / total       0.88      0.85      0.83        71\n",
      "\n",
      "[17 11  0 43]\n",
      "MNB Accuracy:  0.8450704225352113\n",
      "MNB F1:  0.8210767468499427\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81        28\n",
      "          1       0.83      1.00      0.91        43\n",
      "\n",
      "avg / total       0.90      0.87      0.87        71\n",
      "\n",
      "[19  9  0 43]\n",
      "svc Accuracy:  0.8732394366197183\n",
      "svc F1:  0.8568868980963046\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.49        28\n",
      "          1       0.69      1.00      0.82        43\n",
      "\n",
      "avg / total       0.81      0.73      0.69        71\n",
      "\n",
      "[ 9 19  0 43]\n",
      "LR Accuracy:  0.7323943661971831\n",
      "LR F1:  0.6527670527670528\n",
      "For name:  t_o'brien\n",
      "total sample size before apply threshold:  262\n",
      "Counter({'0000-0002-7198-8621': 202, '0000-0002-9161-8070': 39, '0000-0001-9028-5481': 20, '0000-0002-5031-736X': 1})\n",
      "['0000-0002-9161-8070', '0000-0002-7198-8621', '0000-0001-9028-5481']\n",
      "Total sample size after apply threshold:  261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(261, 987)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "261\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.56      0.71        39\n",
      "          1       0.84      1.00      0.91       202\n",
      "          2       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.80      0.85      0.81       261\n",
      "\n",
      "[ 22  17   0   1 201   0   0  20   0]\n",
      "MNB Accuracy:  0.8544061302681992\n",
      "MNB F1:  0.5411045943304008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        39\n",
      "          1       0.89      1.00      0.94       202\n",
      "          2       1.00      0.35      0.52        20\n",
      "\n",
      "avg / total       0.91      0.90      0.89       261\n",
      "\n",
      "[ 26  13   0   0 202   0   0  13   7]\n",
      "svc Accuracy:  0.9003831417624522\n",
      "svc F1:  0.7526844674131495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.23      0.38        39\n",
      "          1       0.80      1.00      0.89       202\n",
      "          2       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.77      0.81      0.74       261\n",
      "\n",
      "[  9  30   0   0 202   0   0  20   0]\n",
      "LR Accuracy:  0.8084291187739464\n",
      "LR F1:  0.4216226138032306\n",
      "For name:  s_may\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0003-1813-7745': 59, '0000-0001-5282-3250': 47, '0000-0002-7228-8440': 7, '0000-0001-6762-7500': 2})\n",
      "['0000-0003-1813-7745', '0000-0001-5282-3250']\n",
      "Total sample size after apply threshold:  106\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(106, 366)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "106\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.83        59\n",
      "          1       1.00      0.47      0.64        47\n",
      "\n",
      "avg / total       0.83      0.76      0.74       106\n",
      "\n",
      "[59  0 25 22]\n",
      "MNB Accuracy:  0.7641509433962265\n",
      "MNB F1:  0.7314279922975575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.83      0.84        59\n",
      "          1       0.80      0.83      0.81        47\n",
      "\n",
      "avg / total       0.83      0.83      0.83       106\n",
      "\n",
      "[49 10  8 39]\n",
      "svc Accuracy:  0.8301886792452831\n",
      "svc F1:  0.8286637931034483\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.98      0.85        59\n",
      "          1       0.97      0.60      0.74        47\n",
      "\n",
      "avg / total       0.85      0.81      0.80       106\n",
      "\n",
      "[58  1 19 28]\n",
      "LR Accuracy:  0.8113207547169812\n",
      "LR F1:  0.7948916408668731\n",
      "For name:  z_cai\n",
      "total sample size before apply threshold:  244\n",
      "Counter({'0000-0002-8724-7684': 200, '0000-0002-8937-4943': 27, '0000-0002-9180-675X': 11, '0000-0003-2884-1429': 6})\n",
      "['0000-0002-9180-675X', '0000-0002-8724-7684', '0000-0002-8937-4943']\n",
      "Total sample size after apply threshold:  238\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(238, 221)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.93      0.99      0.96       200\n",
      "          2       0.96      0.85      0.90        27\n",
      "\n",
      "avg / total       0.89      0.93      0.91       238\n",
      "\n",
      "[  0  11   0   0 199   1   0   4  23]\n",
      "MNB Accuracy:  0.9327731092436975\n",
      "MNB F1:  0.6211044804395188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.97      1.00      0.98       200\n",
      "          2       1.00      0.93      0.96        27\n",
      "\n",
      "avg / total       0.97      0.97      0.97       238\n",
      "\n",
      "[  6   5   0   0 200   0   0   2  25]\n",
      "svc Accuracy:  0.9705882352941176\n",
      "svc F1:  0.8834072657602068\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.89      1.00      0.94       200\n",
      "          2       1.00      0.48      0.65        27\n",
      "\n",
      "avg / total       0.86      0.89      0.86       238\n",
      "\n",
      "[  0  11   0   0 200   0   0  14  13]\n",
      "LR Accuracy:  0.8949579831932774\n",
      "LR F1:  0.5303921568627451\n",
      "For name:  a_pereira\n",
      "total sample size before apply threshold:  205\n",
      "Counter({'0000-0003-1378-4273': 47, '0000-0001-9980-441X': 19, '0000-0002-3478-4718': 15, '0000-0002-1053-8715': 14, '0000-0002-7392-2255': 9, '0000-0001-9430-9399': 7, '0000-0002-8587-262X': 7, '0000-0003-2351-1084': 7, '0000-0003-1587-4264': 7, '0000-0003-1344-2118': 7, '0000-0003-3097-7704': 5, '0000-0001-5062-1241': 5, '0000-0002-3897-2732': 5, '0000-0003-3665-7592': 5, '0000-0001-5206-4063': 4, '0000-0001-7616-4683': 4, '0000-0003-4532-6947': 3, '0000-0002-0131-3354': 3, '0000-0002-8573-7364': 3, '0000-0002-4788-0338': 3, '0000-0003-1698-3374': 3, '0000-0002-7616-0444': 3, '0000-0003-2534-1007': 2, '0000-0001-8335-7694': 2, '0000-0003-0824-1063': 2, '0000-0001-7066-1769': 2, '0000-0001-9479-5550': 2, '0000-0003-2291-1350': 2, '0000-0002-5834-9374': 1, '0000-0003-4203-6311': 1, '0000-0002-5468-0932': 1, '0000-0002-2563-6174': 1, '0000-0002-1068-2880': 1, '0000-0003-0038-2064': 1, '0000-0003-3803-2043': 1, '0000-0002-6733-5425': 1})\n",
      "['0000-0002-1053-8715', '0000-0003-1378-4273', '0000-0001-9980-441X', '0000-0002-3478-4718']\n",
      "Total sample size after apply threshold:  95\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 305)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "95\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        14\n",
      "          1       0.80      1.00      0.89        47\n",
      "          2       1.00      1.00      1.00        19\n",
      "          3       1.00      0.60      0.75        15\n",
      "\n",
      "avg / total       0.90      0.87      0.86        95\n",
      "\n",
      "[ 8  6  0  0  0 47  0  0  0  0 19  0  0  6  0  9]\n",
      "MNB Accuracy:  0.8736842105263158\n",
      "MNB F1:  0.8410162950257289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        14\n",
      "          1       0.89      1.00      0.94        47\n",
      "          2       1.00      0.95      0.97        19\n",
      "          3       0.93      0.87      0.90        15\n",
      "\n",
      "avg / total       0.93      0.93      0.92        95\n",
      "\n",
      "[10  4  0  0  0 47  0  0  0  0 18  1  0  2  0 13]\n",
      "svc Accuracy:  0.9263157894736842\n",
      "svc F1:  0.9107145076110593\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        14\n",
      "          1       0.70      1.00      0.82        47\n",
      "          2       1.00      0.95      0.97        19\n",
      "          3       1.00      0.27      0.42        15\n",
      "\n",
      "avg / total       0.85      0.79      0.76        95\n",
      "\n",
      "[ 6  8  0  0  0 47  0  0  0  1 18  0  0 11  0  4]\n",
      "LR Accuracy:  0.7894736842105263\n",
      "LR F1:  0.704646752015173\n",
      "For name:  d_patel\n",
      "total sample size before apply threshold:  33\n",
      "Counter({'0000-0002-1154-3444': 9, '0000-0002-5744-568X': 8, '0000-0002-2236-7757': 5, '0000-0002-1110-0125': 3, '0000-0002-7198-1163': 2, '0000-0002-3746-8171': 2, '0000-0002-0375-2318': 2, '0000-0002-9592-1990': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  a_james\n",
      "total sample size before apply threshold:  154\n",
      "Counter({'0000-0002-4125-4053': 64, '0000-0002-1411-9307': 37, '0000-0002-0873-3714': 29, '0000-0001-8523-0857': 9, '0000-0002-6174-6696': 4, '0000-0001-8454-6219': 3, '0000-0003-4573-932X': 2, '0000-0001-5655-1213': 2, '0000-0002-0023-4363': 2, '0000-0001-9274-7803': 1, '0000-0002-2002-622X': 1})\n",
      "['0000-0002-4125-4053', '0000-0002-0873-3714', '0000-0002-1411-9307']\n",
      "Total sample size after apply threshold:  130\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(130, 346)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "130\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86        64\n",
      "          1       1.00      0.72      0.84        29\n",
      "          2       1.00      0.68      0.81        37\n",
      "\n",
      "avg / total       0.88      0.85      0.84       130\n",
      "\n",
      "[64  0  0  8 21  0 12  0 25]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.8371054925893636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.96        64\n",
      "          1       1.00      1.00      1.00        29\n",
      "          2       1.00      0.84      0.91        37\n",
      "\n",
      "avg / total       0.96      0.95      0.95       130\n",
      "\n",
      "[64  0  0  0 29  0  6  0 31]\n",
      "svc Accuracy:  0.9538461538461539\n",
      "svc F1:  0.9556628621597895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83        64\n",
      "          1       1.00      0.59      0.74        29\n",
      "          2       1.00      0.62      0.77        37\n",
      "\n",
      "avg / total       0.86      0.80      0.79       130\n",
      "\n",
      "[64  0  0 12 17  0 14  0 23]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.7789886442060355\n",
      "For name:  c_cao\n",
      "total sample size before apply threshold:  74\n",
      "Counter({'0000-0003-2139-1648': 25, '0000-0003-2830-4383': 20, '0000-0001-8621-8403': 19, '0000-0002-0320-1110': 5, '0000-0002-3407-7837': 4, '0000-0001-6909-5739': 1})\n",
      "['0000-0003-2830-4383', '0000-0003-2139-1648', '0000-0001-8621-8403']\n",
      "Total sample size after apply threshold:  64\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(64, 96)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.60      0.73        20\n",
      "          1       0.76      1.00      0.86        25\n",
      "          2       0.94      0.89      0.92        19\n",
      "\n",
      "avg / total       0.86      0.84      0.84        64\n",
      "\n",
      "[12  7  1  0 25  0  1  1 17]\n",
      "MNB Accuracy:  0.84375\n",
      "MNB F1:  0.8360868705696292\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90        20\n",
      "          1       0.96      0.96      0.96        25\n",
      "          2       0.95      0.95      0.95        19\n",
      "\n",
      "avg / total       0.94      0.94      0.94        64\n",
      "\n",
      "[18  1  1  1 24  0  1  0 18]\n",
      "svc Accuracy:  0.9375\n",
      "svc F1:  0.9357894736842104\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.65      0.72        20\n",
      "          1       0.78      1.00      0.88        25\n",
      "          2       0.94      0.79      0.86        19\n",
      "\n",
      "avg / total       0.84      0.83      0.82        64\n",
      "\n",
      "[13  6  1  0 25  0  3  1 15]\n",
      "LR Accuracy:  0.828125\n",
      "LR F1:  0.8188526872737399\n",
      "For name:  c_brown\n",
      "total sample size before apply threshold:  384\n",
      "Counter({'0000-0002-0294-2419': 85, '0000-0002-8959-0101': 60, '0000-0003-2305-846X': 49, '0000-0002-9637-9355': 44, '0000-0003-2506-4871': 33, '0000-0003-0079-7067': 28, '0000-0003-4776-3403': 13, '0000-0002-7271-4091': 12, '0000-0002-0210-1820': 11, '0000-0003-2057-3976': 8, '0000-0002-1559-3238': 8, '0000-0001-6001-2677': 8, '0000-0003-1602-9214': 7, '0000-0003-3060-5652': 6, '0000-0002-7758-6447': 4, '0000-0002-9905-6391': 3, '0000-0003-4780-6485': 2, '0000-0002-9616-2084': 2, '0000-0001-9979-1815': 1})\n",
      "['0000-0002-0294-2419', '0000-0002-0210-1820', '0000-0003-2305-846X', '0000-0002-9637-9355', '0000-0003-0079-7067', '0000-0003-4776-3403', '0000-0003-2506-4871', '0000-0002-8959-0101', '0000-0002-7271-4091']\n",
      "Total sample size after apply threshold:  335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(335, 1160)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "335\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      1.00      0.64        85\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.86      0.92        49\n",
      "          3       0.97      0.68      0.80        44\n",
      "          4       1.00      0.29      0.44        28\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       1.00      0.48      0.65        33\n",
      "          7       0.91      0.83      0.87        60\n",
      "          8       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.77      0.70      0.68       335\n",
      "\n",
      "[85  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  1  0  7  0 42  0  0  0\n",
      "  0  0  0 14  0  0 30  0  0  0  0  0 19  0  0  0  8  0  0  1  0 10  0  0\n",
      "  0  0  0  0  3  0 16  0  0  1  0  0 16  0  0 10  0  0  0  0  0  0 50  0\n",
      "  8  0  0  0  0  0  0  0  4]\n",
      "MNB Accuracy:  0.7014925373134329\n",
      "MNB F1:  0.5371208003713179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.99      0.70        85\n",
      "          1       1.00      0.36      0.53        11\n",
      "          2       1.00      0.90      0.95        49\n",
      "          3       1.00      0.73      0.84        44\n",
      "          4       1.00      0.57      0.73        28\n",
      "          5       1.00      0.23      0.38        13\n",
      "          6       1.00      0.73      0.84        33\n",
      "          7       0.94      0.83      0.88        60\n",
      "          8       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.87      0.78      0.78       335\n",
      "\n",
      "[84  0  0  0  0  0  0  1  0  6  4  0  0  0  0  0  1  0  5  0 44  0  0  0\n",
      "  0  0  0 12  0  0 32  0  0  0  0  0 12  0  0  0 16  0  0  0  0  9  0  0\n",
      "  0  0  3  0  1  0  9  0  0  0  0  0 24  0  0 10  0  0  0  0  0  0 50  0\n",
      "  8  0  0  0  0  0  0  0  4]\n",
      "svc Accuracy:  0.7791044776119403\n",
      "svc F1:  0.7056676553637805\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      1.00      0.64        85\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.82      0.90        49\n",
      "          3       0.97      0.68      0.80        44\n",
      "          4       1.00      0.39      0.56        28\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       1.00      0.45      0.62        33\n",
      "          7       0.94      0.83      0.88        60\n",
      "          8       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.78      0.70      0.68       335\n",
      "\n",
      "[85  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  9  0 40  0  0  0\n",
      "  0  0  0 14  0  0 30  0  0  0  0  0 17  0  0  0 11  0  0  0  0 10  0  0\n",
      "  0  0  0  0  3  0 17  0  0  1  0  0 15  0  0 10  0  0  0  0  0  0 50  0\n",
      "  8  0  0  0  0  0  0  0  4]\n",
      "LR Accuracy:  0.7014925373134329\n",
      "LR F1:  0.5457813850189154\n",
      "For name:  y_liang\n",
      "total sample size before apply threshold:  30\n",
      "Counter({'0000-0002-4798-4882': 18, '0000-0002-7224-9687': 5, '0000-0002-7225-7062': 4, '0000-0002-6440-6144': 2, '0000-0001-7756-1621': 1})\n",
      "['0000-0002-4798-4882']\n",
      "Total sample size after apply threshold:  18\n",
      "For name:  y_fan\n",
      "total sample size before apply threshold:  50\n",
      "Counter({'0000-0001-8477-8458': 18, '0000-0001-9677-3777': 11, '0000-0002-1865-4550': 8, '0000-0002-8897-9836': 3, '0000-0002-7919-4148': 3, '0000-0001-8914-4796': 3, '0000-0003-3743-3988': 2, '0000-0002-6551-9394': 1, '0000-0002-4010-9719': 1})\n",
      "['0000-0001-9677-3777', '0000-0001-8477-8458']\n",
      "Total sample size after apply threshold:  29\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(29, 123)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.82      1.00      0.90        18\n",
      "\n",
      "avg / total       0.89      0.86      0.85        29\n",
      "\n",
      "[ 7  4  0 18]\n",
      "MNB Accuracy:  0.8620689655172413\n",
      "MNB F1:  0.8388888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.95      1.00      0.97        18\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "[10  1  0 18]\n",
      "svc Accuracy:  0.9655172413793104\n",
      "svc F1:  0.9626769626769627\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       0.75      1.00      0.86        18\n",
      "\n",
      "avg / total       0.84      0.79      0.77        29\n",
      "\n",
      "[ 5  6  0 18]\n",
      "LR Accuracy:  0.7931034482758621\n",
      "LR F1:  0.7410714285714286\n",
      "For name:  j_simon\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0003-0214-3745': 54, '0000-0003-0858-0698': 36, '0000-0003-4824-5667': 1, '0000-0001-6081-4127': 1, '0000-0001-7513-9363': 1})\n",
      "['0000-0003-0214-3745', '0000-0003-0858-0698']\n",
      "Total sample size after apply threshold:  90\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(90, 142)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97        54\n",
      "          1       0.97      0.94      0.96        36\n",
      "\n",
      "avg / total       0.97      0.97      0.97        90\n",
      "\n",
      "[53  1  2 34]\n",
      "MNB Accuracy:  0.9666666666666667\n",
      "MNB F1:  0.9651117715467115\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        54\n",
      "          1       1.00      0.92      0.96        36\n",
      "\n",
      "avg / total       0.97      0.97      0.97        90\n",
      "\n",
      "[54  0  3 33]\n",
      "svc Accuracy:  0.9666666666666667\n",
      "svc F1:  0.9647473560517039\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        54\n",
      "          1       1.00      0.83      0.91        36\n",
      "\n",
      "avg / total       0.94      0.93      0.93        90\n",
      "\n",
      "[54  0  6 30]\n",
      "LR Accuracy:  0.9333333333333333\n",
      "LR F1:  0.9282296650717703\n",
      "For name:  m_jeong\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-7019-8089': 34, '0000-0003-0669-1386': 3, '0000-0003-2869-1475': 2, '0000-0003-4850-8121': 2})\n",
      "['0000-0002-7019-8089']\n",
      "Total sample size after apply threshold:  34\n",
      "For name:  j_barrett\n",
      "total sample size before apply threshold:  130\n",
      "Counter({'0000-0002-1720-7724': 116, '0000-0002-2222-0579': 9, '0000-0002-7524-6035': 1, '0000-0002-3316-5894': 1, '0000-0002-5573-0401': 1, '0000-0002-4048-1692': 1, '0000-0002-3736-0662': 1})\n",
      "['0000-0002-1720-7724']\n",
      "Total sample size after apply threshold:  116\n",
      "For name:  d_elliott\n",
      "total sample size before apply threshold:  216\n",
      "Counter({'0000-0001-9959-6841': 129, '0000-0002-6081-5442': 59, '0000-0003-1052-7407': 21, '0000-0001-9837-7890': 7})\n",
      "['0000-0002-6081-5442', '0000-0003-1052-7407', '0000-0001-9959-6841']\n",
      "Total sample size after apply threshold:  209\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(209, 398)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "209\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.66      0.80        59\n",
      "          1       1.00      0.24      0.38        21\n",
      "          2       0.78      1.00      0.88       129\n",
      "\n",
      "avg / total       0.87      0.83      0.80       209\n",
      "\n",
      "[ 39   0  20   0   5  16   0   0 129]\n",
      "MNB Accuracy:  0.8277511961722488\n",
      "MNB F1:  0.6860282574568289\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82        59\n",
      "          1       1.00      0.38      0.55        21\n",
      "          2       0.81      1.00      0.89       129\n",
      "\n",
      "avg / total       0.88      0.85      0.84       209\n",
      "\n",
      "[ 41   0  18   0   8  13   0   0 129]\n",
      "svc Accuracy:  0.8516746411483254\n",
      "svc F1:  0.7548192339816251\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.49      0.66        59\n",
      "          1       0.00      0.00      0.00        21\n",
      "          2       0.72      1.00      0.83       129\n",
      "\n",
      "avg / total       0.72      0.76      0.70       209\n",
      "\n",
      "[ 29   0  30   0   0  21   0   0 129]\n",
      "LR Accuracy:  0.7559808612440191\n",
      "LR F1:  0.49801412180052956\n",
      "For name:  p_antunes\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0002-3553-2678': 25, '0000-0003-3324-4151': 10, '0000-0001-9129-3539': 5, '0000-0003-1969-1860': 1})\n",
      "['0000-0002-3553-2678', '0000-0003-3324-4151']\n",
      "Total sample size after apply threshold:  35\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(35, 58)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        25\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        35\n",
      "\n",
      "[25  0  1  9]\n",
      "MNB Accuracy:  0.9714285714285714\n",
      "MNB F1:  0.9638802889576883\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        25\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        35\n",
      "\n",
      "[25  0  1  9]\n",
      "svc Accuracy:  0.9714285714285714\n",
      "svc F1:  0.9638802889576883\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        25\n",
      "          1       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.95      0.94      0.94        35\n",
      "\n",
      "[25  0  2  8]\n",
      "LR Accuracy:  0.9428571428571428\n",
      "LR F1:  0.9252136752136753\n",
      "For name:  x_yuan\n",
      "total sample size before apply threshold:  71\n",
      "Counter({'0000-0002-1632-8460': 38, '0000-0002-8063-9431': 13, '0000-0001-5395-9109': 11, '0000-0002-2891-1354': 5, '0000-0002-6900-6983': 2, '0000-0001-6983-7368': 1, '0000-0001-7280-7207': 1})\n",
      "['0000-0002-1632-8460', '0000-0001-5395-9109', '0000-0002-8063-9431']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 127)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.87        38\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       1.00      0.54      0.70        13\n",
      "\n",
      "avg / total       0.86      0.82      0.81        62\n",
      "\n",
      "[38  0  0  5  6  0  6  0  7]\n",
      "MNB Accuracy:  0.8225806451612904\n",
      "MNB F1:  0.7598151904439937\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        38\n",
      "          1       1.00      0.55      0.71        11\n",
      "          2       1.00      0.62      0.76        13\n",
      "\n",
      "avg / total       0.87      0.84      0.83        62\n",
      "\n",
      "[38  0  0  5  6  0  5  0  8]\n",
      "svc Accuracy:  0.8387096774193549\n",
      "svc F1:  0.7838360150261655\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      1.00      0.82        38\n",
      "          1       1.00      0.36      0.53        11\n",
      "          2       1.00      0.23      0.38        13\n",
      "\n",
      "avg / total       0.81      0.73      0.67        62\n",
      "\n",
      "[38  0  0  7  4  0 10  0  3]\n",
      "LR Accuracy:  0.7258064516129032\n",
      "LR F1:  0.5751792114695341\n",
      "For name:  t_kim\n",
      "total sample size before apply threshold:  568\n",
      "Counter({'0000-0003-4982-4441': 109, '0000-0001-5193-1428': 95, '0000-0003-4087-8021': 48, '0000-0003-0806-8969': 39, '0000-0001-6568-2469': 34, '0000-0002-9578-5722': 27, '0000-0001-9827-7531': 27, '0000-0003-2920-9038': 23, '0000-0002-7975-2437': 23, '0000-0001-9802-0568': 22, '0000-0003-3950-7557': 22, '0000-0002-4032-1285': 17, '0000-0001-5328-0913': 15, '0000-0002-2116-4579': 14, '0000-0002-4375-8095': 11, '0000-0001-7071-1455': 10, '0000-0002-5239-3833': 9, '0000-0002-5104-6565': 4, '0000-0002-0691-9072': 4, '0000-0002-9355-7574': 3, '0000-0003-4835-0707': 3, '0000-0002-7683-7259': 2, '0000-0002-6944-4385': 2, '0000-0002-2225-1199': 2, '0000-0002-3594-826X': 1, '0000-0002-6494-1868': 1, '0000-0001-5162-5420': 1})\n",
      "['0000-0001-9802-0568', '0000-0002-4032-1285', '0000-0003-3950-7557', '0000-0001-5328-0913', '0000-0001-6568-2469', '0000-0003-2920-9038', '0000-0002-2116-4579', '0000-0002-4375-8095', '0000-0002-9578-5722', '0000-0001-5193-1428', '0000-0003-4982-4441', '0000-0002-7975-2437', '0000-0003-4087-8021', '0000-0001-7071-1455', '0000-0001-9827-7531', '0000-0003-0806-8969']\n",
      "Total sample size after apply threshold:  536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(536, 770)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "536\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        22\n",
      "          1       0.00      0.00      0.00        17\n",
      "          2       1.00      0.32      0.48        22\n",
      "          3       1.00      0.07      0.12        15\n",
      "          4       0.94      0.47      0.63        34\n",
      "          5       1.00      0.09      0.16        23\n",
      "          6       0.00      0.00      0.00        14\n",
      "          7       0.00      0.00      0.00        11\n",
      "          8       1.00      0.41      0.58        27\n",
      "          9       0.55      0.75      0.63        95\n",
      "         10       0.30      0.98      0.46       109\n",
      "         11       0.00      0.00      0.00        23\n",
      "         12       0.73      0.17      0.27        48\n",
      "         13       0.00      0.00      0.00        10\n",
      "         14       1.00      0.11      0.20        27\n",
      "         15       1.00      0.05      0.10        39\n",
      "\n",
      "avg / total       0.57      0.43      0.35       536\n",
      "\n",
      "[  0   0   0   0   0   0   0   0   0   6  16   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   4  13   0   0   0   0   0   0   0   7   0\n",
      "   0   0   0   0   0   6   8   0   1   0   0   0   0   0   0   1   0   0\n",
      "   0   0   0   8   6   0   0   0   0   0   0   0   0   0  16   0   0   0\n",
      "   0   6  12   0   0   0   0   0   0   0   0   0   0   2   0   0   0   4\n",
      "  16   0   1   0   0   0   0   0   0   0   0   0   0   0   0   3  11   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   2   9   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  11   5  11   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  71  24   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   1 107   0   1   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   2  21   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   3  37   0   8   0   0   0   0   0   0   0   1   0   0   0\n",
      "   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5\n",
      "  19   0   0   0   3   0   0   0   0   0   0   0   0   0   0   4  33   0\n",
      "   0   0   0   2]\n",
      "MNB Accuracy:  0.4253731343283582\n",
      "MNB F1:  0.2273889837407379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.45      0.54        22\n",
      "          1       0.71      0.71      0.71        17\n",
      "          2       1.00      0.50      0.67        22\n",
      "          3       0.92      0.73      0.81        15\n",
      "          4       0.81      0.76      0.79        34\n",
      "          5       0.90      0.39      0.55        23\n",
      "          6       0.42      0.36      0.38        14\n",
      "          7       0.80      0.73      0.76        11\n",
      "          8       1.00      0.78      0.88        27\n",
      "          9       0.75      0.82      0.78        95\n",
      "         10       0.91      0.94      0.93       109\n",
      "         11       0.76      0.83      0.79        23\n",
      "         12       0.43      0.92      0.58        48\n",
      "         13       0.67      0.20      0.31        10\n",
      "         14       0.85      0.41      0.55        27\n",
      "         15       0.69      0.62      0.65        39\n",
      "\n",
      "avg / total       0.78      0.74      0.73       536\n",
      "\n",
      "[ 10   1   0   0   0   0   1   0   0   1   2   1   5   0   0   1   1  12\n",
      "   0   0   0   0   0   0   0   1   1   0   1   0   1   0   0   0  11   0\n",
      "   0   0   0   0   0   0   0   0  11   0   0   0   0   0   0  11   0   1\n",
      "   0   0   0   0   0   0   3   0   0   0   2   0   0   0  26   0   1   0\n",
      "   0   3   1   1   0   0   0   0   0   0   0   1   0   9   0   1   0   1\n",
      "   1   0   6   0   0   4   0   0   0   0   1   0   5   0   0   1   2   0\n",
      "   1   0   1   3   0   0   0   0   0   0   0   8   0   2   0   0   0   0\n",
      "   0   1   0   0   0   0   0   0   0   0  21   0   0   0   6   0   0   0\n",
      "   1   1   0   0   1   0   0   0   0  78   0   2  12   0   0   0   0   2\n",
      "   0   0   0   0   0   0   0   1 103   0   3   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   3   1  19   0   0   0   0   0   0   0   0   0   0\n",
      "   1   0   0   1   0   0  44   1   0   1   1   0   0   0   0   0   1   0\n",
      "   0   3   1   0   1   2   0   1   0   0   0   0   1   0   2   1   0   7\n",
      "   0   2   3   0  11   0   0   1   0   0   3   0   1   0   0   2   1   0\n",
      "   7   0   0  24]\n",
      "svc Accuracy:  0.7350746268656716\n",
      "svc F1:  0.6672121537934887\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.18      0.29        22\n",
      "          1       0.78      0.41      0.54        17\n",
      "          2       1.00      0.45      0.62        22\n",
      "          3       0.89      0.53      0.67        15\n",
      "          4       0.86      0.74      0.79        34\n",
      "          5       0.91      0.43      0.59        23\n",
      "          6       0.00      0.00      0.00        14\n",
      "          7       0.80      0.73      0.76        11\n",
      "          8       1.00      0.74      0.85        27\n",
      "          9       0.59      0.93      0.72        95\n",
      "         10       0.79      0.93      0.85       109\n",
      "         11       0.84      0.70      0.76        23\n",
      "         12       0.49      0.90      0.64        48\n",
      "         13       1.00      0.10      0.18        10\n",
      "         14       0.91      0.37      0.53        27\n",
      "         15       0.61      0.56      0.59        39\n",
      "\n",
      "avg / total       0.73      0.70      0.67       536\n",
      "\n",
      "[  4   1   0   0   0   0   0   0   0   6   4   0   3   0   0   4   1   7\n",
      "   0   0   0   0   0   0   0   4   2   0   0   0   1   2   0   0  10   0\n",
      "   0   0   0   0   0   6   0   0   6   0   0   0   0   0   0   8   0   0\n",
      "   0   0   0   2   0   0   5   0   0   0   0   0   0   0  25   0   0   0\n",
      "   0   8   1   0   0   0   0   0   0   0   0   1   1  10   0   1   0   1\n",
      "   3   0   4   0   0   2   0   0   0   0   0   0   0   0   0   6   3   0\n",
      "   3   0   0   2   0   0   0   0   0   0   0   8   0   3   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  20   2   1   0   4   0   0   0\n",
      "   0   0   0   0   1   0   0   0   0  88   0   0   6   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   3 101   1   3   0   0   1   0   0   0   0\n",
      "   1   0   0   0   0   2   3  16   0   0   0   1   0   0   0   0   0   0\n",
      "   0   0   0   4   0   0  43   0   0   1   1   0   0   0   0   0   0   0\n",
      "   0   2   4   0   1   1   0   1   0   0   0   0   0   0   0   1   0   8\n",
      "   2   2   4   0  10   0   0   1   0   0   1   1   1   0   0   4   4   0\n",
      "   5   0   0  22]\n",
      "LR Accuracy:  0.6958955223880597\n",
      "LR F1:  0.5861294848574112\n",
      "For name:  a_cruz\n",
      "total sample size before apply threshold:  80\n",
      "Counter({'0000-0002-0465-4111': 38, '0000-0002-8251-8422': 13, '0000-0002-1662-3072': 10, '0000-0003-0368-9731': 9, '0000-0003-4537-1318': 7, '0000-0002-4591-4362': 3})\n",
      "['0000-0002-8251-8422', '0000-0002-0465-4111', '0000-0002-1662-3072']\n",
      "Total sample size after apply threshold:  61\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 177)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.77      0.83        13\n",
      "          1       0.88      1.00      0.94        38\n",
      "          2       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.91      0.90      0.90        61\n",
      "\n",
      "[10  3  0  0 38  0  1  2  7]\n",
      "MNB Accuracy:  0.9016393442622951\n",
      "MNB F1:  0.865044783345437\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        13\n",
      "          1       1.00      1.00      1.00        38\n",
      "          2       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        61\n",
      "\n",
      "[12  0  1  0 38  0  1  0  9]\n",
      "svc Accuracy:  0.9672131147540983\n",
      "svc F1:  0.9410256410256411\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.73      1.00      0.84        38\n",
      "          2       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.83      0.77      0.72        61\n",
      "\n",
      "[ 8  5  0  0 38  0  0  9  1]\n",
      "LR Accuracy:  0.7704918032786885\n",
      "LR F1:  0.5960557960557961\n",
      "For name:  a_mora\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0002-0785-5795': 54, '0000-0002-6397-4836': 20, '0000-0003-1344-1131': 5, '0000-0003-1354-4739': 3, '0000-0002-9132-5622': 2})\n",
      "['0000-0002-0785-5795', '0000-0002-6397-4836']\n",
      "Total sample size after apply threshold:  74\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(74, 275)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "74\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        54\n",
      "          1       1.00      0.75      0.86        20\n",
      "\n",
      "avg / total       0.94      0.93      0.93        74\n",
      "\n",
      "[54  0  5 15]\n",
      "MNB Accuracy:  0.9324324324324325\n",
      "MNB F1:  0.9064475347661188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        54\n",
      "          1       1.00      0.85      0.92        20\n",
      "\n",
      "avg / total       0.96      0.96      0.96        74\n",
      "\n",
      "[54  0  3 17]\n",
      "svc Accuracy:  0.9594594594594594\n",
      "svc F1:  0.9459459459459459\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92        54\n",
      "          1       1.00      0.50      0.67        20\n",
      "\n",
      "avg / total       0.89      0.86      0.85        74\n",
      "\n",
      "[54  0 10 10]\n",
      "LR Accuracy:  0.8648648648648649\n",
      "LR F1:  0.7909604519774012\n",
      "For name:  j_walker\n",
      "total sample size before apply threshold:  253\n",
      "Counter({'0000-0002-8922-083X': 71, '0000-0002-5349-1689': 70, '0000-0002-2050-1641': 64, '0000-0002-2995-0398': 17, '0000-0002-8683-0026': 15, '0000-0001-6034-7514': 9, '0000-0002-9732-5738': 4, '0000-0001-5151-1693': 1, '0000-0003-1349-2633': 1, '0000-0002-8241-9424': 1})\n",
      "['0000-0002-2995-0398', '0000-0002-2050-1641', '0000-0002-8922-083X', '0000-0002-8683-0026', '0000-0002-5349-1689']\n",
      "Total sample size after apply threshold:  237\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(237, 640)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "237\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.59      0.74        17\n",
      "          1       0.77      0.88      0.82        64\n",
      "          2       0.88      0.82      0.85        71\n",
      "          3       1.00      0.93      0.97        15\n",
      "          4       0.91      0.96      0.93        70\n",
      "\n",
      "avg / total       0.87      0.86      0.86       237\n",
      "\n",
      "[10  6  1  0  0  0 56  6  0  2  0  8 58  0  5  0  1  0 14  0  0  2  1  0\n",
      " 67]\n",
      "MNB Accuracy:  0.8649789029535865\n",
      "MNB F1:  0.8602094228635885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83        17\n",
      "          1       1.00      0.81      0.90        64\n",
      "          2       0.74      1.00      0.85        71\n",
      "          3       1.00      0.87      0.93        15\n",
      "          4       1.00      0.91      0.96        70\n",
      "\n",
      "avg / total       0.92      0.89      0.90       237\n",
      "\n",
      "[12  0  5  0  0  0 52 12  0  0  0  0 71  0  0  0  0  2 13  0  0  0  6  0\n",
      " 64]\n",
      "svc Accuracy:  0.8945147679324894\n",
      "svc F1:  0.8916465282801062\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        17\n",
      "          1       0.96      0.81      0.88        64\n",
      "          2       0.69      0.99      0.81        71\n",
      "          3       1.00      0.67      0.80        15\n",
      "          4       1.00      0.90      0.95        70\n",
      "\n",
      "avg / total       0.90      0.86      0.86       237\n",
      "\n",
      "[ 8  1  8  0  0  0 52 12  0  0  0  1 70  0  0  0  0  5 10  0  0  0  7  0\n",
      " 63]\n",
      "LR Accuracy:  0.8565400843881856\n",
      "LR F1:  0.8155945816338633\n",
      "For name:  j_alves\n",
      "total sample size before apply threshold:  53\n",
      "Counter({'0000-0001-5914-2087': 15, '0000-0001-7221-871X': 13, '0000-0001-7554-2419': 8, '0000-0001-7182-0936': 6, '0000-0002-5736-6519': 4, '0000-0003-3131-9834': 3, '0000-0002-9599-5463': 3, '0000-0002-4355-0921': 1})\n",
      "['0000-0001-5914-2087', '0000-0001-7221-871X']\n",
      "Total sample size after apply threshold:  28\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(28, 120)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.87      0.87        15\n",
      "          1       0.85      0.85      0.85        13\n",
      "\n",
      "avg / total       0.86      0.86      0.86        28\n",
      "\n",
      "[13  2  2 11]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.8564102564102565\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        15\n",
      "          1       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        28\n",
      "\n",
      "[15  0  2 11]\n",
      "svc Accuracy:  0.9285714285714286\n",
      "svc F1:  0.9270833333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        15\n",
      "          1       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        28\n",
      "\n",
      "[15  0  2 11]\n",
      "LR Accuracy:  0.9285714285714286\n",
      "LR F1:  0.9270833333333333\n",
      "For name:  j_seo\n",
      "total sample size before apply threshold:  146\n",
      "Counter({'0000-0002-1927-2618': 56, '0000-0003-0242-1805': 47, '0000-0002-5039-2503': 12, '0000-0001-8881-7952': 10, '0000-0001-5095-4046': 6, '0000-0003-3471-7803': 3, '0000-0001-5844-4585': 3, '0000-0002-6582-8162': 2, '0000-0001-5534-2508': 2, '0000-0002-3329-1540': 2, '0000-0002-2878-4551': 1, '0000-0003-2117-5750': 1, '0000-0001-9338-643X': 1})\n",
      "['0000-0003-0242-1805', '0000-0002-5039-2503', '0000-0001-8881-7952', '0000-0002-1927-2618']\n",
      "Total sample size after apply threshold:  125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(125, 136)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.72      0.72        47\n",
      "          1       1.00      0.67      0.80        12\n",
      "          2       1.00      0.20      0.33        10\n",
      "          3       0.74      0.89      0.81        56\n",
      "\n",
      "avg / total       0.78      0.75      0.74       125\n",
      "\n",
      "[34  0  0 13  3  8  0  1  4  0  2  4  6  0  0 50]\n",
      "MNB Accuracy:  0.752\n",
      "MNB F1:  0.6657973003889271\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.89      0.82        47\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       1.00      0.90      0.95        10\n",
      "          3       0.90      0.84      0.87        56\n",
      "\n",
      "avg / total       0.87      0.86      0.86       125\n",
      "\n",
      "[42  0  0  5  3  9  0  0  1  0  9  0  9  0  0 47]\n",
      "svc Accuracy:  0.856\n",
      "svc F1:  0.8746027650826411\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.89      0.80        47\n",
      "          1       1.00      0.33      0.50        12\n",
      "          2       1.00      0.80      0.89        10\n",
      "          3       0.89      0.88      0.88        56\n",
      "\n",
      "avg / total       0.85      0.82      0.82       125\n",
      "\n",
      "[42  0  0  5  8  4  0  0  1  0  8  1  7  0  0 49]\n",
      "LR Accuracy:  0.824\n",
      "LR F1:  0.7679429429429429\n",
      "For name:  y_tang\n",
      "total sample size before apply threshold:  66\n",
      "Counter({'0000-0003-4888-6771': 34, '0000-0003-2718-544X': 17, '0000-0001-9312-1378': 6, '0000-0002-2649-5270': 5, '0000-0002-8807-9264': 2, '0000-0001-7919-1409': 1, '0000-0003-1096-1764': 1})\n",
      "['0000-0003-4888-6771', '0000-0003-2718-544X']\n",
      "Total sample size after apply threshold:  51\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(51, 173)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        34\n",
      "          1       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.95      0.94      0.94        51\n",
      "\n",
      "[34  0  3 14]\n",
      "MNB Accuracy:  0.9411764705882353\n",
      "MNB F1:  0.9304861426624262\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        34\n",
      "          1       1.00      0.82      0.90        17\n",
      "\n",
      "avg / total       0.95      0.94      0.94        51\n",
      "\n",
      "[34  0  3 14]\n",
      "svc Accuracy:  0.9411764705882353\n",
      "svc F1:  0.9304861426624262\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88        34\n",
      "          1       1.00      0.47      0.64        17\n",
      "\n",
      "avg / total       0.86      0.82      0.80        51\n",
      "\n",
      "[34  0  9  8]\n",
      "LR Accuracy:  0.8235294117647058\n",
      "LR F1:  0.7615584415584415\n",
      "For name:  a_norman\n",
      "total sample size before apply threshold:  28\n",
      "Counter({'0000-0002-1282-394X': 16, '0000-0002-4208-2708': 4, '0000-0002-9499-758X': 4, '0000-0002-4332-6049': 3, '0000-0001-6368-521X': 1})\n",
      "['0000-0002-1282-394X']\n",
      "Total sample size after apply threshold:  16\n",
      "For name:  s_tanaka\n",
      "total sample size before apply threshold:  80\n",
      "Counter({'0000-0002-3468-7694': 38, '0000-0001-5157-3317': 24, '0000-0002-1262-3876': 7, '0000-0003-2002-5582': 6, '0000-0002-7101-0690': 4, '0000-0002-2898-9557': 1})\n",
      "['0000-0001-5157-3317', '0000-0002-3468-7694']\n",
      "Total sample size after apply threshold:  62\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(62, 178)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        24\n",
      "          1       1.00      0.97      0.99        38\n",
      "\n",
      "avg / total       0.98      0.98      0.98        62\n",
      "\n",
      "[24  0  1 37]\n",
      "MNB Accuracy:  0.9838709677419355\n",
      "MNB F1:  0.9831292517006802\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        24\n",
      "          1       1.00      1.00      1.00        38\n",
      "\n",
      "avg / total       1.00      1.00      1.00        62\n",
      "\n",
      "[24  0  0 38]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        24\n",
      "          1       0.86      1.00      0.93        38\n",
      "\n",
      "avg / total       0.92      0.90      0.90        62\n",
      "\n",
      "[18  6  0 38]\n",
      "LR Accuracy:  0.9032258064516129\n",
      "LR F1:  0.89198606271777\n",
      "For name:  c_wen\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0002-5345-0756': 25, '0000-0002-1181-8786': 6, '0000-0002-7684-8820': 2, '0000-0002-5174-1576': 1, '0000-0002-4445-1589': 1, '0000-0002-2538-0439': 1})\n",
      "['0000-0002-5345-0756']\n",
      "Total sample size after apply threshold:  25\n",
      "For name:  c_myers\n",
      "total sample size before apply threshold:  100\n",
      "Counter({'0000-0002-2776-4823': 92, '0000-0003-1492-9008': 6, '0000-0001-7788-8595': 1, '0000-0001-9860-3931': 1})\n",
      "['0000-0002-2776-4823']\n",
      "Total sample size after apply threshold:  92\n",
      "For name:  v_santos\n",
      "total sample size before apply threshold:  30\n",
      "Counter({'0000-0003-0194-7397': 10, '0000-0002-5370-4867': 9, '0000-0001-8693-0759': 4, '0000-0003-3581-5595': 4, '0000-0002-8518-5408': 1, '0000-0003-1283-7388': 1, '0000-0002-9426-6197': 1})\n",
      "['0000-0003-0194-7397']\n",
      "Total sample size after apply threshold:  10\n",
      "For name:  j_brown\n",
      "total sample size before apply threshold:  290\n",
      "Counter({'0000-0002-2797-5428': 66, '0000-0001-5269-7661': 47, '0000-0002-6936-035X': 27, '0000-0001-8155-677X': 25, '0000-0002-6839-5948': 24, '0000-0002-1447-8633': 15, '0000-0002-0653-4615': 14, '0000-0001-8502-4252': 11, '0000-0002-3155-0334': 10, '0000-0002-2002-3010': 10, '0000-0002-7535-2874': 9, '0000-0002-4681-9586': 8, '0000-0002-4128-4359': 5, '0000-0002-9838-7201': 4, '0000-0001-6486-8667': 3, '0000-0003-3705-0290': 2, '0000-0002-1261-4574': 2, '0000-0002-1100-7457': 2, '0000-0001-6738-9653': 2, '0000-0001-5823-3083': 1, '0000-0002-9125-8474': 1, '0000-0002-2973-1021': 1, '0000-0003-2979-779X': 1})\n",
      "['0000-0002-3155-0334', '0000-0002-1447-8633', '0000-0001-5269-7661', '0000-0002-2797-5428', '0000-0001-8502-4252', '0000-0001-8155-677X', '0000-0002-0653-4615', '0000-0002-6936-035X', '0000-0002-2002-3010', '0000-0002-6839-5948']\n",
      "Total sample size after apply threshold:  249\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(249, 569)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "249\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.87      0.87      0.87        47\n",
      "          3       0.41      1.00      0.58        66\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       0.75      0.12      0.21        25\n",
      "          6       1.00      0.21      0.35        14\n",
      "          7       1.00      1.00      1.00        27\n",
      "          8       0.00      0.00      0.00        10\n",
      "          9       1.00      0.29      0.45        24\n",
      "\n",
      "avg / total       0.61      0.59      0.51       249\n",
      "\n",
      "[ 0  0  0 10  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0 41  6\n",
      "  0  0  0  0  0  0  0  0  0 66  0  0  0  0  0  0  0  0  3  8  0  0  0  0\n",
      "  0  0  0  0  2 20  0  3  0  0  0  0  0  0  0 11  0  0  3  0  0  0  0  0\n",
      "  0  0  0  0  0 27  0  0  0  0  0 10  0  0  0  0  0  0  0  0  1 15  0  1\n",
      "  0  0  0  7]\n",
      "MNB Accuracy:  0.5903614457831325\n",
      "MNB F1:  0.3465288854309276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        10\n",
      "          1       1.00      0.47      0.64        15\n",
      "          2       0.58      0.91      0.71        47\n",
      "          3       0.97      0.95      0.96        66\n",
      "          4       1.00      0.45      0.62        11\n",
      "          5       0.68      0.76      0.72        25\n",
      "          6       0.90      0.64      0.75        14\n",
      "          7       1.00      1.00      1.00        27\n",
      "          8       1.00      0.80      0.89        10\n",
      "          9       0.75      0.62      0.68        24\n",
      "\n",
      "avg / total       0.85      0.81      0.81       249\n",
      "\n",
      "[ 5  0  2  0  0  1  1  0  0  1  0  7  7  0  0  0  0  0  0  1  0  0 43  0\n",
      "  0  4  0  0  0  0  0  0  2 63  0  0  0  0  0  1  0  0  6  0  5  0  0  0\n",
      "  0  0  0  0  5  0  0 19  0  0  0  1  0  0  3  1  0  1  9  0  0  0  0  0\n",
      "  0  0  0  0  0 27  0  0  0  0  1  0  0  0  0  0  8  1  0  0  5  1  0  3\n",
      "  0  0  0 15]\n",
      "svc Accuracy:  0.8072289156626506\n",
      "svc F1:  0.7638294368534441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       1.00      0.20      0.33        15\n",
      "          2       0.80      0.91      0.85        47\n",
      "          3       0.54      1.00      0.70        66\n",
      "          4       1.00      0.27      0.43        11\n",
      "          5       0.83      0.40      0.54        25\n",
      "          6       0.89      0.57      0.70        14\n",
      "          7       1.00      1.00      1.00        27\n",
      "          8       1.00      0.50      0.67        10\n",
      "          9       1.00      0.58      0.74        24\n",
      "\n",
      "avg / total       0.78      0.72      0.69       249\n",
      "\n",
      "[ 0  0  0  9  0  0  1  0  0  0  0  3  2 10  0  0  0  0  0  0  0  0 43  3\n",
      "  0  1  0  0  0  0  0  0  0 66  0  0  0  0  0  0  0  0  0  8  3  0  0  0\n",
      "  0  0  0  0  6  9  0 10  0  0  0  0  0  0  0  6  0  0  8  0  0  0  0  0\n",
      "  0  0  0  0  0 27  0  0  0  0  1  4  0  0  0  0  5  0  0  0  2  7  0  1\n",
      "  0  0  0 14]\n",
      "LR Accuracy:  0.7188755020080321\n",
      "LR F1:  0.595521905637749\n",
      "For name:  b_pandey\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0001-6862-4424': 28, '0000-0002-8453-9665': 11, '0000-0001-7870-6060': 2, '0000-0002-3712-5961': 1})\n",
      "['0000-0001-6862-4424', '0000-0002-8453-9665']\n",
      "Total sample size after apply threshold:  39\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(39, 70)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93        28\n",
      "          1       0.89      0.73      0.80        11\n",
      "\n",
      "avg / total       0.90      0.90      0.89        39\n",
      "\n",
      "[27  1  3  8]\n",
      "MNB Accuracy:  0.8974358974358975\n",
      "MNB F1:  0.8655172413793103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        28\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.98      0.97      0.97        39\n",
      "\n",
      "[28  0  1 10]\n",
      "svc Accuracy:  0.9743589743589743\n",
      "svc F1:  0.9674185463659147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        28\n",
      "          1       1.00      0.09      0.17        11\n",
      "\n",
      "avg / total       0.81      0.74      0.66        39\n",
      "\n",
      "[28  0 10  1]\n",
      "LR Accuracy:  0.7435897435897436\n",
      "LR F1:  0.5075757575757576\n",
      "For name:  d_morgan\n",
      "total sample size before apply threshold:  86\n",
      "Counter({'0000-0002-2291-1740': 50, '0000-0002-7410-6591': 27, '0000-0001-8725-9477': 7, '0000-0001-7403-4586': 1, '0000-0002-4911-0046': 1})\n",
      "['0000-0002-2291-1740', '0000-0002-7410-6591']\n",
      "Total sample size after apply threshold:  77\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(77, 219)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.90      0.89        50\n",
      "          1       0.81      0.78      0.79        27\n",
      "\n",
      "avg / total       0.86      0.86      0.86        77\n",
      "\n",
      "[45  5  6 21]\n",
      "MNB Accuracy:  0.8571428571428571\n",
      "MNB F1:  0.8417709695497851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        50\n",
      "          1       1.00      0.78      0.88        27\n",
      "\n",
      "avg / total       0.93      0.92      0.92        77\n",
      "\n",
      "[50  0  6 21]\n",
      "svc Accuracy:  0.922077922077922\n",
      "svc F1:  0.9091981132075473\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93        50\n",
      "          1       1.00      0.74      0.85        27\n",
      "\n",
      "avg / total       0.92      0.91      0.91        77\n",
      "\n",
      "[50  0  7 20]\n",
      "LR Accuracy:  0.9090909090909091\n",
      "LR F1:  0.8928216345197852\n",
      "For name:  r_smith\n",
      "total sample size before apply threshold:  789\n",
      "Counter({'0000-0002-2381-2349': 587, '0000-0002-5252-9649': 43, '0000-0001-5645-8422': 31, '0000-0002-9174-7681': 19, '0000-0001-8483-6777': 19, '0000-0003-1599-9171': 13, '0000-0003-0245-2265': 13, '0000-0001-9746-1230': 10, '0000-0002-8343-794X': 8, '0000-0002-6881-5690': 8, '0000-0003-4000-2919': 6, '0000-0002-3540-1133': 6, '0000-0003-2502-5098': 6, '0000-0001-9634-2918': 4, '0000-0002-6825-888X': 4, '0000-0003-1209-9653': 3, '0000-0002-9044-9199': 3, '0000-0003-2340-0042': 2, '0000-0002-3794-3788': 2, '0000-0002-7413-4189': 1, '0000-0001-7479-7778': 1})\n",
      "['0000-0003-1599-9171', '0000-0002-9174-7681', '0000-0002-2381-2349', '0000-0001-9746-1230', '0000-0002-5252-9649', '0000-0003-0245-2265', '0000-0001-8483-6777', '0000-0001-5645-8422']\n",
      "Total sample size after apply threshold:  735\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(735, 1464)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "735\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       1.00      0.26      0.42        19\n",
      "          2       0.82      1.00      0.90       587\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.91      0.23      0.37        43\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       1.00      0.05      0.10        19\n",
      "          7       1.00      0.03      0.06        31\n",
      "\n",
      "avg / total       0.80      0.82      0.76       735\n",
      "\n",
      "[  0   0  13   0   0   0   0   0   0   5  14   0   0   0   0   0   0   0\n",
      " 586   0   1   0   0   0   0   0  10   0   0   0   0   0   0   0  33   0\n",
      "  10   0   0   0   0   0  13   0   0   0   0   0   0   0  18   0   0   0\n",
      "   1   0   0   0  30   0   0   0   0   1]\n",
      "MNB Accuracy:  0.8204081632653061\n",
      "MNB F1:  0.2310387553965008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47        13\n",
      "          1       1.00      0.84      0.91        19\n",
      "          2       0.91      1.00      0.95       587\n",
      "          3       1.00      0.80      0.89        10\n",
      "          4       1.00      0.58      0.74        43\n",
      "          5       1.00      0.69      0.82        13\n",
      "          6       1.00      0.68      0.81        19\n",
      "          7       1.00      0.39      0.56        31\n",
      "\n",
      "avg / total       0.92      0.92      0.91       735\n",
      "\n",
      "[  4   0   9   0   0   0   0   0   0  16   3   0   0   0   0   0   0   0\n",
      " 587   0   0   0   0   0   0   0   2   8   0   0   0   0   0   0  18   0\n",
      "  25   0   0   0   0   0   4   0   0   9   0   0   0   0   6   0   0   0\n",
      "  13   0   0   0  19   0   0   0   0  12]\n",
      "svc Accuracy:  0.9170068027210885\n",
      "svc F1:  0.768560699578839\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       1.00      0.32      0.48        19\n",
      "          2       0.82      1.00      0.90       587\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.16      0.28        43\n",
      "          5       0.00      0.00      0.00        13\n",
      "          6       1.00      0.32      0.48        19\n",
      "          7       0.00      0.00      0.00        31\n",
      "\n",
      "avg / total       0.76      0.82      0.76       735\n",
      "\n",
      "[  0   0  13   0   0   0   0   0   0   6  13   0   0   0   0   0   0   0\n",
      " 587   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0  36   0\n",
      "   7   0   0   0   0   0  13   0   0   0   0   0   0   0  13   0   0   0\n",
      "   6   0   0   0  31   0   0   0   0   0]\n",
      "LR Accuracy:  0.8244897959183674\n",
      "LR F1:  0.26762471220260936\n",
      "For name:  a_guerrero\n",
      "total sample size before apply threshold:  57\n",
      "Counter({'0000-0001-5474-1451': 28, '0000-0002-4389-5516': 12, '0000-0001-8602-1248': 9, '0000-0001-6050-8699': 6, '0000-0003-2550-6764': 2})\n",
      "['0000-0002-4389-5516', '0000-0001-5474-1451']\n",
      "Total sample size after apply threshold:  40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(40, 80)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "40\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       0.90      1.00      0.95        28\n",
      "\n",
      "avg / total       0.93      0.93      0.92        40\n",
      "\n",
      "[ 9  3  0 28]\n",
      "MNB Accuracy:  0.925\n",
      "MNB F1:  0.9031476997578691\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        28\n",
      "\n",
      "avg / total       1.00      1.00      1.00        40\n",
      "\n",
      "[12  0  0 28]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       0.88      1.00      0.93        28\n",
      "\n",
      "avg / total       0.91      0.90      0.89        40\n",
      "\n",
      "[ 8  4  0 28]\n",
      "LR Accuracy:  0.9\n",
      "LR F1:  0.8666666666666667\n",
      "For name:  a_grant\n",
      "total sample size before apply threshold:  45\n",
      "Counter({'0000-0002-1147-2375': 22, '0000-0001-6146-101X': 9, '0000-0001-7205-5869': 7, '0000-0002-7032-3716': 4, '0000-0001-9746-2989': 2, '0000-0002-1553-596X': 1})\n",
      "['0000-0002-1147-2375']\n",
      "Total sample size after apply threshold:  22\n",
      "For name:  v_kumar\n",
      "total sample size before apply threshold:  98\n",
      "Counter({'0000-0003-3522-1121': 18, '0000-0001-6643-7465': 15, '0000-0002-9795-5967': 15, '0000-0001-6477-8274': 9, '0000-0001-5559-0624': 8, '0000-0003-4937-7442': 7, '0000-0003-0910-233X': 7, '0000-0002-7335-0824': 6, '0000-0003-2121-3964': 4, '0000-0002-1583-7749': 3, '0000-0003-1988-2536': 3, '0000-0002-3834-1906': 1, '0000-0002-1513-5835': 1, '0000-0002-3980-1345': 1})\n",
      "['0000-0001-6643-7465', '0000-0003-3522-1121', '0000-0002-9795-5967']\n",
      "Total sample size after apply threshold:  48\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 116)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        15\n",
      "          1       0.67      1.00      0.80        18\n",
      "          2       1.00      0.60      0.75        15\n",
      "\n",
      "avg / total       0.88      0.81      0.81        48\n",
      "\n",
      "[12  3  0  0 18  0  0  6  9]\n",
      "MNB Accuracy:  0.8125\n",
      "MNB F1:  0.812962962962963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.93      0.87        15\n",
      "          1       1.00      0.89      0.94        18\n",
      "          2       0.93      0.93      0.93        15\n",
      "\n",
      "avg / total       0.92      0.92      0.92        48\n",
      "\n",
      "[14  0  1  2 16  0  1  0 14]\n",
      "svc Accuracy:  0.9166666666666666\n",
      "svc F1:  0.9165032679738561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90        15\n",
      "          1       1.00      0.89      0.94        18\n",
      "          2       0.88      0.93      0.90        15\n",
      "\n",
      "avg / total       0.92      0.92      0.92        48\n",
      "\n",
      "[14  0  1  1 16  1  1  0 14]\n",
      "LR Accuracy:  0.9166666666666666\n",
      "LR F1:  0.915876027830487\n",
      "For name:  p_shah\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0002-9052-4638': 48, '0000-0001-5497-4765': 12, '0000-0002-1255-9325': 11, '0000-0003-4755-1267': 8, '0000-0002-5839-1687': 3, '0000-0003-1929-9754': 2})\n",
      "['0000-0002-9052-4638', '0000-0001-5497-4765', '0000-0002-1255-9325']\n",
      "Total sample size after apply threshold:  71\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(71, 237)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        48\n",
      "          1       1.00      0.50      0.67        12\n",
      "          2       1.00      0.45      0.62        11\n",
      "\n",
      "avg / total       0.86      0.83      0.81        71\n",
      "\n",
      "[48  0  0  6  6  0  6  0  5]\n",
      "MNB Accuracy:  0.8309859154929577\n",
      "MNB F1:  0.7268518518518517\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        48\n",
      "          1       1.00      0.50      0.67        12\n",
      "          2       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.91      0.90      0.89        71\n",
      "\n",
      "[48  0  0  6  6  0  1  0 10]\n",
      "svc Accuracy:  0.9014084507042254\n",
      "svc F1:  0.8503621513330252\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        48\n",
      "          1       1.00      0.50      0.67        12\n",
      "          2       1.00      0.27      0.43        11\n",
      "\n",
      "avg / total       0.85      0.80      0.77        71\n",
      "\n",
      "[48  0  0  6  6  0  8  0  3]\n",
      "LR Accuracy:  0.8028169014084507\n",
      "LR F1:  0.655988455988456\n",
      "For name:  t_yu\n",
      "total sample size before apply threshold:  134\n",
      "Counter({'0000-0002-0113-2895': 59, '0000-0003-2988-7701': 28, '0000-0002-6737-0618': 17, '0000-0001-5012-9353': 17, '0000-0002-6874-989X': 10, '0000-0002-6724-6043': 1, '0000-0002-1029-6699': 1, '0000-0002-0273-9330': 1})\n",
      "['0000-0002-6874-989X', '0000-0002-0113-2895', '0000-0002-6737-0618', '0000-0003-2988-7701', '0000-0001-5012-9353']\n",
      "Total sample size after apply threshold:  131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(131, 599)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       0.66      1.00      0.80        59\n",
      "          2       1.00      0.59      0.74        17\n",
      "          3       1.00      0.50      0.67        28\n",
      "          4       0.91      0.59      0.71        17\n",
      "\n",
      "avg / total       0.84      0.76      0.75       131\n",
      "\n",
      "[ 7  3  0  0  0  0 59  0  0  0  0  7 10  0  0  0 13  0 14  1  0  7  0  0\n",
      " 10]\n",
      "MNB Accuracy:  0.7633587786259542\n",
      "MNB F1:  0.7485039661510249\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.88      1.00      0.94        59\n",
      "          2       1.00      0.82      0.90        17\n",
      "          3       0.90      0.93      0.91        28\n",
      "          4       1.00      0.71      0.83        17\n",
      "\n",
      "avg / total       0.92      0.92      0.91       131\n",
      "\n",
      "[ 9  1  0  0  0  0 59  0  0  0  0  0 14  3  0  0  2  0 26  0  0  5  0  0\n",
      " 12]\n",
      "svc Accuracy:  0.916030534351145\n",
      "svc F1:  0.9053938145326239\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.69      1.00      0.82        59\n",
      "          2       1.00      0.59      0.74        17\n",
      "          3       1.00      0.57      0.73        28\n",
      "          4       1.00      0.71      0.83        17\n",
      "\n",
      "avg / total       0.86      0.80      0.80       131\n",
      "\n",
      "[ 8  2  0  0  0  0 59  0  0  0  0  7 10  0  0  0 12  0 16  0  0  5  0  0\n",
      " 12]\n",
      "LR Accuracy:  0.8015267175572519\n",
      "LR F1:  0.8007866016486707\n",
      "For name:  r_singh\n",
      "total sample size before apply threshold:  197\n",
      "Counter({'0000-0003-4261-7044': 83, '0000-0001-9933-4884': 16, '0000-0001-8094-4703': 15, '0000-0001-6298-8219': 11, '0000-0001-7269-6420': 10, '0000-0001-6358-489X': 8, '0000-0003-3642-0392': 6, '0000-0002-7887-2138': 6, '0000-0002-1195-8738': 6, '0000-0002-2944-2561': 6, '0000-0001-5647-3390': 4, '0000-0001-8068-7428': 4, '0000-0001-7128-5726': 4, '0000-0002-6608-7941': 3, '0000-0002-4842-1336': 3, '0000-0003-0283-3754': 2, '0000-0002-0938-9388': 2, '0000-0001-7049-5473': 2, '0000-0002-1514-5697': 2, '0000-0001-6452-1356': 2, '0000-0003-4022-9945': 1, '0000-0001-8493-4510': 1})\n",
      "['0000-0001-8094-4703', '0000-0001-6298-8219', '0000-0001-7269-6420', '0000-0001-9933-4884', '0000-0003-4261-7044']\n",
      "Total sample size after apply threshold:  135\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(135, 278)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        15\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       1.00      0.38      0.55        16\n",
      "          4       0.67      1.00      0.80        83\n",
      "\n",
      "avg / total       0.64      0.70      0.61       135\n",
      "\n",
      "[ 5  0  0  0 10  0  0  0  0 11  0  0  0  0 10  0  0  0  6 10  0  0  0  0\n",
      " 83]\n",
      "MNB Accuracy:  0.6962962962962963\n",
      "MNB F1:  0.36947738252086076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.73      0.81        15\n",
      "          1       1.00      0.73      0.84        11\n",
      "          2       1.00      0.70      0.82        10\n",
      "          3       1.00      0.94      0.97        16\n",
      "          4       0.89      1.00      0.94        83\n",
      "\n",
      "avg / total       0.92      0.92      0.91       135\n",
      "\n",
      "[11  0  0  0  4  1  8  0  0  2  0  0  7  0  3  0  0  0 15  1  0  0  0  0\n",
      " 83]\n",
      "svc Accuracy:  0.9185185185185185\n",
      "svc F1:  0.8782746486806209\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        15\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.20      0.33        10\n",
      "          3       1.00      0.38      0.55        16\n",
      "          4       0.69      1.00      0.82        83\n",
      "\n",
      "avg / total       0.73      0.73      0.66       135\n",
      "\n",
      "[ 7  0  0  0  8  0  0  0  0 11  0  0  2  0  8  0  0  0  6 10  0  0  0  0\n",
      " 83]\n",
      "LR Accuracy:  0.725925925925926\n",
      "LR F1:  0.4665771010598597\n",
      "For name:  c_baker\n",
      "total sample size before apply threshold:  112\n",
      "Counter({'0000-0001-6861-8964': 49, '0000-0002-4434-3107': 36, '0000-0001-9134-2994': 10, '0000-0002-7622-1251': 6, '0000-0002-9391-2468': 5, '0000-0002-1171-563X': 3, '0000-0002-2675-1078': 2, '0000-0002-6274-0579': 1})\n",
      "['0000-0001-9134-2994', '0000-0001-6861-8964', '0000-0002-4434-3107']\n",
      "Total sample size after apply threshold:  95\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(95, 180)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "95\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        10\n",
      "          1       0.77      1.00      0.87        49\n",
      "          2       1.00      0.81      0.89        36\n",
      "\n",
      "avg / total       0.88      0.84      0.82        95\n",
      "\n",
      "[ 2  8  0  0 49  0  0  7 29]\n",
      "MNB Accuracy:  0.8421052631578947\n",
      "MNB F1:  0.6976325542697225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.87      0.98      0.92        49\n",
      "          2       0.97      0.86      0.91        36\n",
      "\n",
      "avg / total       0.92      0.92      0.92        95\n",
      "\n",
      "[ 8  2  0  0 48  1  0  5 31]\n",
      "svc Accuracy:  0.9157894736842105\n",
      "svc F1:  0.907910172616055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.30      0.46        10\n",
      "          1       0.72      1.00      0.84        49\n",
      "          2       1.00      0.67      0.80        36\n",
      "\n",
      "avg / total       0.86      0.80      0.78        95\n",
      "\n",
      "[ 3  7  0  0 49  0  0 12 24]\n",
      "LR Accuracy:  0.8\n",
      "LR F1:  0.6997150997150996\n",
      "For name:  a_cattaneo\n",
      "total sample size before apply threshold:  196\n",
      "Counter({'0000-0002-6975-8923': 127, '0000-0002-9963-848X': 31, '0000-0002-2962-7259': 18, '0000-0002-4500-6540': 12, '0000-0001-5685-3684': 8})\n",
      "['0000-0002-6975-8923', '0000-0002-2962-7259', '0000-0002-4500-6540', '0000-0002-9963-848X']\n",
      "Total sample size after apply threshold:  188\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(188, 606)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "188\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       127\n",
      "          1       1.00      0.17      0.29        18\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       1.00      0.87      0.93        31\n",
      "\n",
      "avg / total       0.80      0.84      0.78       188\n",
      "\n",
      "[127   0   0   0  15   3   0   0  12   0   0   0   4   0   0  27]\n",
      "MNB Accuracy:  0.8351063829787234\n",
      "MNB F1:  0.5269942096620862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       127\n",
      "          1       1.00      0.78      0.88        18\n",
      "          2       1.00      0.58      0.74        12\n",
      "          3       1.00      0.90      0.95        31\n",
      "\n",
      "avg / total       0.94      0.94      0.93       188\n",
      "\n",
      "[127   0   0   0   4  14   0   0   5   0   7   0   3   0   0  28]\n",
      "svc Accuracy:  0.9361702127659575\n",
      "svc F1:  0.878970466420288\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85       127\n",
      "          1       1.00      0.11      0.20        18\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       1.00      0.48      0.65        31\n",
      "\n",
      "avg / total       0.76      0.77      0.70       188\n",
      "\n",
      "[127   0   0   0  16   2   0   0  12   0   0   0  16   0   0  15]\n",
      "LR Accuracy:  0.7659574468085106\n",
      "LR F1:  0.4261307265830172\n",
      "For name:  a_ferrari\n",
      "total sample size before apply threshold:  114\n",
      "Counter({'0000-0001-9536-3995': 49, '0000-0002-6166-1350': 18, '0000-0003-1465-2774': 17, '0000-0002-7022-9906': 17, '0000-0002-0387-9984': 9, '0000-0002-6265-4419': 3, '0000-0002-5939-8637': 1})\n",
      "['0000-0003-1465-2774', '0000-0002-7022-9906', '0000-0002-6166-1350', '0000-0001-9536-3995']\n",
      "Total sample size after apply threshold:  101\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(101, 319)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "101\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.47      0.64        17\n",
      "          1       1.00      1.00      1.00        17\n",
      "          2       1.00      0.61      0.76        18\n",
      "          3       0.75      1.00      0.86        49\n",
      "\n",
      "avg / total       0.88      0.84      0.83       101\n",
      "\n",
      "[ 8  0  0  9  0 17  0  0  0  0 11  7  0  0  0 49]\n",
      "MNB Accuracy:  0.8415841584158416\n",
      "MNB F1:  0.8145674531155475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        17\n",
      "          1       1.00      1.00      1.00        17\n",
      "          2       1.00      0.67      0.80        18\n",
      "          3       0.86      1.00      0.92        49\n",
      "\n",
      "avg / total       0.93      0.92      0.92       101\n",
      "\n",
      "[15  0  0  2  0 17  0  0  0  0 12  6  0  0  0 49]\n",
      "svc Accuracy:  0.9207920792079208\n",
      "svc F1:  0.9155070754716981\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        17\n",
      "          1       1.00      1.00      1.00        17\n",
      "          2       1.00      0.56      0.71        18\n",
      "          3       0.72      1.00      0.84        49\n",
      "\n",
      "avg / total       0.86      0.81      0.79       101\n",
      "\n",
      "[ 6  0  0 11  0 17  0  0  0  0 10  8  0  0  0 49]\n",
      "LR Accuracy:  0.8118811881188119\n",
      "LR F1:  0.7684079205818337\n",
      "For name:  a_murphy\n",
      "total sample size before apply threshold:  178\n",
      "Counter({'0000-0003-4152-4081': 81, '0000-0002-5222-9902': 61, '0000-0002-2547-4750': 20, '0000-0003-4039-9063': 8, '0000-0002-2820-2304': 4, '0000-0002-9983-8641': 2, '0000-0003-2889-503X': 2})\n",
      "['0000-0003-4152-4081', '0000-0002-2547-4750', '0000-0002-5222-9902']\n",
      "Total sample size after apply threshold:  162\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(162, 805)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "162\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        81\n",
      "          1       1.00      0.60      0.75        20\n",
      "          2       0.98      0.92      0.95        61\n",
      "\n",
      "avg / total       0.93      0.92      0.92       162\n",
      "\n",
      "[81  0  0  7 12  1  5  0 56]\n",
      "MNB Accuracy:  0.9197530864197531\n",
      "MNB F1:  0.8767290083771672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        81\n",
      "          1       1.00      0.65      0.79        20\n",
      "          2       0.87      1.00      0.93        61\n",
      "\n",
      "avg / total       0.95      0.94      0.94       162\n",
      "\n",
      "[79  0  2  0 13  7  0  0 61]\n",
      "svc Accuracy:  0.9444444444444444\n",
      "svc F1:  0.902225499267484\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.99      0.90        81\n",
      "          1       1.00      0.55      0.71        20\n",
      "          2       0.96      0.85      0.90        61\n",
      "\n",
      "avg / total       0.90      0.88      0.88       162\n",
      "\n",
      "[80  0  1  8 11  1  9  0 52]\n",
      "LR Accuracy:  0.8827160493827161\n",
      "LR F1:  0.837633883312059\n",
      "For name:  f_hong\n",
      "total sample size before apply threshold:  41\n",
      "Counter({'0000-0003-1318-2635': 23, '0000-0001-5120-3519': 14, '0000-0003-0060-2063': 2, '0000-0002-4167-6037': 2})\n",
      "['0000-0003-1318-2635', '0000-0001-5120-3519']\n",
      "Total sample size after apply threshold:  37\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(37, 90)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        23\n",
      "          1       0.93      0.93      0.93        14\n",
      "\n",
      "avg / total       0.95      0.95      0.95        37\n",
      "\n",
      "[22  1  1 13]\n",
      "MNB Accuracy:  0.9459459459459459\n",
      "MNB F1:  0.9425465838509317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        23\n",
      "          1       0.93      0.93      0.93        14\n",
      "\n",
      "avg / total       0.95      0.95      0.95        37\n",
      "\n",
      "[22  1  1 13]\n",
      "svc Accuracy:  0.9459459459459459\n",
      "svc F1:  0.9425465838509317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        23\n",
      "          1       1.00      0.50      0.67        14\n",
      "\n",
      "avg / total       0.85      0.81      0.79        37\n",
      "\n",
      "[23  0  7  7]\n",
      "LR Accuracy:  0.8108108108108109\n",
      "LR F1:  0.7672955974842768\n",
      "For name:  m_ferrari\n",
      "total sample size before apply threshold:  150\n",
      "Counter({'0000-0002-3041-2917': 74, '0000-0002-7579-4031': 25, '0000-0002-2986-1272': 22, '0000-0001-6370-605X': 12, '0000-0003-3723-5957': 6, '0000-0001-8535-7348': 5, '0000-0002-7447-6146': 2, '0000-0003-0990-0403': 1, '0000-0003-0283-4263': 1, '0000-0001-7009-6552': 1, '0000-0002-3310-7715': 1})\n",
      "['0000-0002-2986-1272', '0000-0002-3041-2917', '0000-0001-6370-605X', '0000-0002-7579-4031']\n",
      "Total sample size after apply threshold:  133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 389)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        22\n",
      "          1       0.87      1.00      0.93        74\n",
      "          2       1.00      0.58      0.74        12\n",
      "          3       1.00      0.76      0.86        25\n",
      "\n",
      "avg / total       0.93      0.92      0.91       133\n",
      "\n",
      "[22  0  0  0  0 74  0  0  0  5  7  0  0  6  0 19]\n",
      "MNB Accuracy:  0.9172932330827067\n",
      "MNB F1:  0.8828240197406036\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        22\n",
      "          1       0.93      1.00      0.96        74\n",
      "          2       1.00      0.75      0.86        12\n",
      "          3       1.00      0.88      0.94        25\n",
      "\n",
      "avg / total       0.96      0.95      0.95       133\n",
      "\n",
      "[22  0  0  0  0 74  0  0  0  3  9  0  0  3  0 22]\n",
      "svc Accuracy:  0.9548872180451128\n",
      "svc F1:  0.938588007736944\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        22\n",
      "          1       0.80      1.00      0.89        74\n",
      "          2       1.00      0.58      0.74        12\n",
      "          3       1.00      0.68      0.81        25\n",
      "\n",
      "avg / total       0.89      0.86      0.85       133\n",
      "\n",
      "[16  6  0  0  0 74  0  0  0  5  7  0  0  8  0 17]\n",
      "LR Accuracy:  0.8571428571428571\n",
      "LR F1:  0.8186746807137604\n",
      "For name:  j_paredes\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0002-1076-1343': 44, '0000-0002-7788-8939': 9, '0000-0002-0974-8109': 7, '0000-0002-1566-9044': 5, '0000-0002-0620-0770': 3})\n",
      "['0000-0002-1076-1343']\n",
      "Total sample size after apply threshold:  44\n",
      "For name:  z_zhao\n",
      "total sample size before apply threshold:  186\n",
      "Counter({'0000-0003-0654-1193': 79, '0000-0003-2743-9008': 28, '0000-0002-1279-2207': 15, '0000-0002-1876-1284': 15, '0000-0001-6079-1631': 14, '0000-0002-1701-3751': 7, '0000-0002-0862-8471': 6, '0000-0002-2901-5033': 6, '0000-0001-8978-8866': 5, '0000-0002-8679-3130': 4, '0000-0001-8979-844X': 3, '0000-0001-6529-5020': 3, '0000-0002-4577-5470': 1})\n",
      "['0000-0002-1279-2207', '0000-0003-2743-9008', '0000-0001-6079-1631', '0000-0003-0654-1193', '0000-0002-1876-1284']\n",
      "Total sample size after apply threshold:  151\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(151, 194)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "151\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        15\n",
      "          1       1.00      0.82      0.90        28\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.67      1.00      0.80        79\n",
      "          4       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.64      0.74      0.67       151\n",
      "\n",
      "[10  0  0  5  0  0 23  0  5  0  0  0  0 14  0  0  0  0 79  0  0  0  0 15\n",
      "  0]\n",
      "MNB Accuracy:  0.7417218543046358\n",
      "MNB F1:  0.5007982482333035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.85        15\n",
      "          1       0.96      0.93      0.95        28\n",
      "          2       0.83      0.36      0.50        14\n",
      "          3       0.79      0.99      0.88        79\n",
      "          4       0.88      0.47      0.61        15\n",
      "\n",
      "avg / total       0.85      0.84      0.82       151\n",
      "\n",
      "[11  0  0  4  0  0 26  0  2  0  0  1  5  7  1  0  0  1 78  0  0  0  0  8\n",
      "  7]\n",
      "svc Accuracy:  0.8410596026490066\n",
      "svc F1:  0.7553417076328655\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        15\n",
      "          1       1.00      0.86      0.92        28\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.70      1.00      0.82        79\n",
      "          4       1.00      0.27      0.42        15\n",
      "\n",
      "avg / total       0.75      0.77      0.72       151\n",
      "\n",
      "[10  0  0  5  0  0 24  0  4  0  0  0  0 14  0  0  0  0 79  0  0  0  0 11\n",
      "  4]\n",
      "LR Accuracy:  0.7748344370860927\n",
      "LR F1:  0.5934092442645074\n",
      "For name:  j_cao\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-3586-2319': 11, '0000-0002-1544-7441': 10, '0000-0001-5938-6604': 8, '0000-0001-5196-8239': 5, '0000-0001-7414-7660': 4, '0000-0001-6171-1170': 1})\n",
      "['0000-0002-3586-2319', '0000-0002-1544-7441']\n",
      "Total sample size after apply threshold:  21\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(21, 309)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "21\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.55      0.71        11\n",
      "          1       0.67      1.00      0.80        10\n",
      "\n",
      "avg / total       0.84      0.76      0.75        21\n",
      "\n",
      "[ 6  5  0 10]\n",
      "MNB Accuracy:  0.7619047619047619\n",
      "MNB F1:  0.7529411764705882\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.96      0.95      0.95        21\n",
      "\n",
      "[10  1  0 10]\n",
      "svc Accuracy:  0.9523809523809523\n",
      "svc F1:  0.9523809523809523\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.96      0.95      0.95        21\n",
      "\n",
      "[10  1  0 10]\n",
      "LR Accuracy:  0.9523809523809523\n",
      "LR F1:  0.9523809523809523\n",
      "For name:  d_kuo\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-6461-2562': 17, '0000-0002-3505-0169': 7, '0000-0001-9003-9993': 4, '0000-0001-9300-8551': 3, '0000-0002-7162-174X': 3})\n",
      "['0000-0002-6461-2562']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  a_andersen\n",
      "total sample size before apply threshold:  18\n",
      "Counter({'0000-0003-0054-1897': 8, '0000-0002-3831-1707': 6, '0000-0001-8169-7273': 3, '0000-0001-9703-3180': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_longo\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0003-1117-1772': 33, '0000-0001-5062-6245': 5, '0000-0002-6364-8184': 3, '0000-0002-2450-4903': 2, '0000-0001-8325-4003': 1})\n",
      "['0000-0003-1117-1772']\n",
      "Total sample size after apply threshold:  33\n",
      "For name:  h_chiang\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-2979-6108': 18, '0000-0001-8781-5146': 14, '0000-0002-2333-9117': 7, '0000-0001-5041-9705': 5})\n",
      "['0000-0002-2979-6108', '0000-0001-8781-5146']\n",
      "Total sample size after apply threshold:  32"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 48)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        18\n",
      "          1       0.93      1.00      0.97        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97        32\n",
      "\n",
      "[17  1  0 14]\n",
      "MNB Accuracy:  0.96875\n",
      "MNB F1:  0.9684729064039409\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        18\n",
      "          1       0.93      1.00      0.97        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97        32\n",
      "\n",
      "[17  1  0 14]\n",
      "svc Accuracy:  0.96875\n",
      "svc F1:  0.9684729064039409\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        18\n",
      "          1       0.93      1.00      0.97        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97        32\n",
      "\n",
      "[17  1  0 14]\n",
      "LR Accuracy:  0.96875\n",
      "LR F1:  0.9684729064039409\n",
      "For name:  m_o'brien\n",
      "total sample size before apply threshold:  34\n",
      "Counter({'0000-0002-8509-3650': 20, '0000-0002-1721-0464': 9, '0000-0003-1096-1991': 4, '0000-0003-4990-3289': 1})\n",
      "['0000-0002-8509-3650']\n",
      "Total sample size after apply threshold:  20\n",
      "For name:  s_ray\n",
      "total sample size before apply threshold:  123\n",
      "Counter({'0000-0002-1051-7260': 75, '0000-0001-5675-1258': 30, '0000-0001-8034-7706': 9, '0000-0002-2414-2930': 5, '0000-0002-4640-708X': 2, '0000-0003-2566-7146': 2})\n",
      "['0000-0002-1051-7260', '0000-0001-5675-1258']\n",
      "Total sample size after apply threshold:  105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(105, 387)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "105\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        75\n",
      "          1       1.00      0.90      0.95        30\n",
      "\n",
      "avg / total       0.97      0.97      0.97       105\n",
      "\n",
      "[75  0  3 27]\n",
      "MNB Accuracy:  0.9714285714285714\n",
      "MNB F1:  0.9638802889576883\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99        75\n",
      "          1       1.00      0.97      0.98        30\n",
      "\n",
      "avg / total       0.99      0.99      0.99       105\n",
      "\n",
      "[75  0  1 29]\n",
      "svc Accuracy:  0.9904761904761905\n",
      "svc F1:  0.9882141654506678\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.96        75\n",
      "          1       1.00      0.77      0.87        30\n",
      "\n",
      "avg / total       0.94      0.93      0.93       105\n",
      "\n",
      "[75  0  7 23]\n",
      "LR Accuracy:  0.9333333333333333\n",
      "LR F1:  0.9116692705203703\n",
      "For name:  a_cheng\n",
      "total sample size before apply threshold:  636\n",
      "Counter({'0000-0002-9152-6512': 265, '0000-0003-3152-116X': 180, '0000-0003-2345-6951': 71, '0000-0002-1182-7375': 38, '0000-0001-7897-4751': 29, '0000-0003-3862-2967': 25, '0000-0003-2729-606X': 22, '0000-0001-5137-000X': 2, '0000-0002-0977-0381': 2, '0000-0001-5196-3307': 1, '0000-0002-8166-0806': 1})\n",
      "['0000-0003-3862-2967', '0000-0002-1182-7375', '0000-0003-2729-606X', '0000-0003-3152-116X', '0000-0002-9152-6512', '0000-0003-2345-6951', '0000-0001-7897-4751']\n",
      "Total sample size after apply threshold:  630\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(630, 2146)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        25\n",
      "          1       0.50      0.03      0.05        38\n",
      "          2       0.00      0.00      0.00        22\n",
      "          3       0.97      0.90      0.93       180\n",
      "          4       0.65      1.00      0.79       265\n",
      "          5       0.98      0.73      0.84        71\n",
      "          6       0.00      0.00      0.00        29\n",
      "\n",
      "avg / total       0.73      0.77      0.70       630\n",
      "\n",
      "[  2   0   0   2  21   0   0   0   1   0   0  37   0   0   0   0   0   2\n",
      "  19   1   0   0   0   0 162  18   0   0   0   0   0   0 265   0   0   0\n",
      "   0   0   0  19  52   0   0   1   0   1  27   0   0]\n",
      "MNB Accuracy:  0.765079365079365\n",
      "MNB F1:  0.39434875380732975\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.86        25\n",
      "          1       0.94      0.79      0.86        38\n",
      "          2       0.92      0.50      0.65        22\n",
      "          3       0.83      0.99      0.90       180\n",
      "          4       0.95      0.97      0.96       265\n",
      "          5       0.97      0.80      0.88        71\n",
      "          6       0.95      0.69      0.80        29\n",
      "\n",
      "avg / total       0.92      0.91      0.91       630\n",
      "\n",
      "[ 19   0   0   6   0   0   0   0  30   0   0   8   0   0   0   0  11  10\n",
      "   0   1   0   0   1   0 179   0   0   0   0   1   0   5 258   1   0   0\n",
      "   0   1   9   3  57   1   0   0   0   7   2   0  20]\n",
      "svc Accuracy:  0.9111111111111111\n",
      "svc F1:  0.8444982989194704\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.32      0.48        25\n",
      "          1       0.95      0.53      0.68        38\n",
      "          2       1.00      0.23      0.37        22\n",
      "          3       0.72      0.99      0.84       180\n",
      "          4       0.90      0.97      0.94       265\n",
      "          5       1.00      0.76      0.86        71\n",
      "          6       1.00      0.28      0.43        29\n",
      "\n",
      "avg / total       0.88      0.84      0.82       630\n",
      "\n",
      "[  8   0   0  17   0   0   0   0  20   0   0  18   0   0   0   0   5  17\n",
      "   0   0   0   0   0   0 179   1   0   0   0   1   0   6 258   0   0   0\n",
      "   0   0  11   6  54   0   0   0   0  18   3   0   8]\n",
      "LR Accuracy:  0.8444444444444444\n",
      "LR F1:  0.657506445190524\n",
      "For name:  j_savage\n",
      "total sample size before apply threshold:  17\n",
      "Counter({'0000-0002-7756-7166': 6, '0000-0003-0599-0245': 6, '0000-0002-5123-3475': 3, '0000-0002-4737-5673': 2})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  p_matthews\n",
      "total sample size before apply threshold:  329\n",
      "Counter({'0000-0002-1619-8328': 268, '0000-0002-4036-4269': 44, '0000-0002-1362-8003': 10, '0000-0002-2011-9303': 7})\n",
      "['0000-0002-1619-8328', '0000-0002-4036-4269', '0000-0002-1362-8003']\n",
      "Total sample size after apply threshold:  322\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(322, 1264)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "322\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95       268\n",
      "          1       0.93      0.61      0.74        44\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.88      0.91      0.89       322\n",
      "\n",
      "[266   2   0  17  27   0  10   0   0]\n",
      "MNB Accuracy:  0.9099378881987578\n",
      "MNB F1:  0.562677540920893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       268\n",
      "          1       1.00      0.70      0.83        44\n",
      "          2       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.95      0.95      0.94       322\n",
      "\n",
      "[268   0   0  13  31   0   4   0   6]\n",
      "svc Accuracy:  0.9472049689440993\n",
      "svc F1:  0.8486417520594736\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       268\n",
      "          1       1.00      0.34      0.51        44\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.86      0.88      0.85       322\n",
      "\n",
      "[268   0   0  29  15   0  10   0   0]\n",
      "LR Accuracy:  0.8788819875776398\n",
      "LR F1:  0.48021616310488824\n",
      "For name:  i_carvalho\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0002-2028-777X': 24, '0000-0002-7882-3555': 4, '0000-0002-7569-2019': 3, '0000-0001-7981-4442': 3, '0000-0001-5823-1520': 3, '0000-0002-1811-0588': 2})\n",
      "['0000-0002-2028-777X']\n",
      "Total sample size after apply threshold:  24\n",
      "For name:  j_parsons\n",
      "total sample size before apply threshold:  255\n",
      "Counter({'0000-0002-6875-7566': 212, '0000-0003-1785-3627': 36, '0000-0002-4184-343X': 5, '0000-0002-4856-8610': 1, '0000-0003-1022-6364': 1})\n",
      "['0000-0002-6875-7566', '0000-0003-1785-3627']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size after apply threshold:  248\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(248, 342)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "248\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98       212\n",
      "          1       1.00      0.81      0.89        36\n",
      "\n",
      "avg / total       0.97      0.97      0.97       248\n",
      "\n",
      "[212   0   7  29]\n",
      "MNB Accuracy:  0.9717741935483871\n",
      "MNB F1:  0.938033196501874\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       212\n",
      "          1       1.00      0.78      0.88        36\n",
      "\n",
      "avg / total       0.97      0.97      0.97       248\n",
      "\n",
      "[212   0   8  28]\n",
      "svc Accuracy:  0.967741935483871\n",
      "svc F1:  0.9282407407407408\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       212\n",
      "          1       1.00      0.47      0.64        36\n",
      "\n",
      "avg / total       0.93      0.92      0.91       248\n",
      "\n",
      "[212   0  19  17]\n",
      "LR Accuracy:  0.9233870967741935\n",
      "LR F1:  0.7993100217215383\n",
      "For name:  s_oliveira\n",
      "total sample size before apply threshold:  143\n",
      "Counter({'0000-0003-4984-4805': 48, '0000-0002-6011-2122': 25, '0000-0001-7919-4191': 23, '0000-0001-8240-0013': 17, '0000-0002-6914-5529': 8, '0000-0002-7322-1184': 8, '0000-0003-0649-2694': 4, '0000-0002-7654-1909': 4, '0000-0002-3504-5749': 3, '0000-0002-8901-9757': 2, '0000-0002-3840-6781': 1})\n",
      "['0000-0003-4984-4805', '0000-0001-7919-4191', '0000-0002-6011-2122', '0000-0001-8240-0013']\n",
      "Total sample size after apply threshold:  113\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(113, 405)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "113\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        48\n",
      "          1       1.00      0.91      0.95        23\n",
      "          2       1.00      1.00      1.00        25\n",
      "          3       1.00      0.65      0.79        17\n",
      "\n",
      "avg / total       0.94      0.93      0.93       113\n",
      "\n",
      "[48  0  0  0  2 21  0  0  0  0 25  0  6  0  0 11]\n",
      "MNB Accuracy:  0.9292035398230089\n",
      "MNB F1:  0.9158341658341658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        48\n",
      "          1       1.00      0.96      0.98        23\n",
      "          2       1.00      1.00      1.00        25\n",
      "          3       1.00      0.88      0.94        17\n",
      "\n",
      "avg / total       0.98      0.97      0.97       113\n",
      "\n",
      "[48  0  0  0  1 22  0  0  0  0 25  0  2  0  0 15]\n",
      "svc Accuracy:  0.9734513274336283\n",
      "svc F1:  0.9712436868686869\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        48\n",
      "          1       1.00      0.96      0.98        23\n",
      "          2       1.00      0.96      0.98        25\n",
      "          3       1.00      0.65      0.79        17\n",
      "\n",
      "avg / total       0.94      0.93      0.93       113\n",
      "\n",
      "[48  0  0  0  1 22  0  0  1  0 24  0  6  0  0 11]\n",
      "LR Accuracy:  0.9292035398230089\n",
      "LR F1:  0.91654020582592\n",
      "For name:  h_kang\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0003-3431-0827': 25, '0000-0001-9671-0944': 6, '0000-0001-8697-4292': 6, '0000-0003-2844-5880': 2, '0000-0002-4952-5524': 1, '0000-0001-6876-4021': 1, '0000-0001-5550-241X': 1, '0000-0001-9073-5833': 1, '0000-0002-0309-7448': 1, '0000-0002-6771-2112': 1, '0000-0001-5036-5612': 1, '0000-0001-6293-0121': 1})\n",
      "['0000-0003-3431-0827']\n",
      "Total sample size after apply threshold:  25\n",
      "For name:  s_vogt\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-8034-5513': 68, '0000-0003-3466-9995': 9, '0000-0002-9009-5183': 8, '0000-0002-0393-5712': 8})\n",
      "['0000-0002-8034-5513']\n",
      "Total sample size after apply threshold:  68\n",
      "For name:  d_garcia\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0002-8552-1475': 32, '0000-0003-3356-4454': 24, '0000-0002-2820-9151': 2, '0000-0001-6669-9457': 1, '0000-0001-6777-9184': 1})\n",
      "['0000-0003-3356-4454', '0000-0002-8552-1475']\n",
      "Total sample size after apply threshold:  56\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 128)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        24\n",
      "          1       0.97      1.00      0.98        32\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "[23  1  0 32]\n",
      "MNB Accuracy:  0.9821428571428571\n",
      "MNB F1:  0.9816693944353518\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        24\n",
      "          1       0.94      1.00      0.97        32\n",
      "\n",
      "avg / total       0.97      0.96      0.96        56\n",
      "\n",
      "[22  2  0 32]\n",
      "svc Accuracy:  0.9642857142857143\n",
      "svc F1:  0.9631093544137023\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        24\n",
      "          1       0.94      1.00      0.97        32\n",
      "\n",
      "avg / total       0.97      0.96      0.96        56\n",
      "\n",
      "[22  2  0 32]\n",
      "LR Accuracy:  0.9642857142857143\n",
      "LR F1:  0.9631093544137023\n",
      "For name:  w_xie\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0002-2768-3572': 44, '0000-0003-2410-2135': 17, '0000-0003-0493-062X': 15, '0000-0003-4655-6496': 10, '0000-0003-4504-8609': 7, '0000-0003-1762-7224': 6, '0000-0002-5500-8195': 6, '0000-0003-2546-2415': 5, '0000-0003-1501-896X': 2, '0000-0002-4887-3711': 1, '0000-0003-3856-9887': 1, '0000-0002-9983-7948': 1})\n",
      "['0000-0003-2410-2135', '0000-0003-4655-6496', '0000-0002-2768-3572', '0000-0003-0493-062X']\n",
      "Total sample size after apply threshold:  86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 146)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.38        17\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.58      1.00      0.73        44\n",
      "          3       1.00      0.40      0.57        15\n",
      "\n",
      "avg / total       0.67      0.63      0.55        86\n",
      "\n",
      "[ 4  0 13  0  0  0 10  0  0  0 44  0  0  0  9  6]\n",
      "MNB Accuracy:  0.627906976744186\n",
      "MNB F1:  0.4214285714285715\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.59      0.71        17\n",
      "          1       1.00      0.60      0.75        10\n",
      "          2       0.72      0.95      0.82        44\n",
      "          3       0.91      0.67      0.77        15\n",
      "\n",
      "avg / total       0.83      0.79      0.78        86\n",
      "\n",
      "[10  0  7  0  0  6  4  0  1  0 42  1  0  0  5 10]\n",
      "svc Accuracy:  0.7906976744186046\n",
      "svc F1:  0.7642614738202973\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.29      0.45        17\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.58      1.00      0.73        44\n",
      "          3       1.00      0.33      0.50        15\n",
      "\n",
      "avg / total       0.67      0.63      0.55        86\n",
      "\n",
      "[ 5  0 12  0  0  0 10  0  0  0 44  0  0  0 10  5]\n",
      "LR Accuracy:  0.627906976744186\n",
      "LR F1:  0.421969696969697\n",
      "For name:  m_cruz\n",
      "total sample size before apply threshold:  141\n",
      "Counter({'0000-0001-9759-5466': 57, '0000-0001-9846-6754': 46, '0000-0003-1822-0514': 30, '0000-0002-4767-530X': 3, '0000-0001-8152-3054': 3, '0000-0003-3311-7582': 2})\n",
      "['0000-0001-9846-6754', '0000-0001-9759-5466', '0000-0003-1822-0514']\n",
      "Total sample size after apply threshold:  133\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(133, 293)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        46\n",
      "          1       0.98      1.00      0.99        57\n",
      "          2       1.00      0.73      0.85        30\n",
      "\n",
      "avg / total       0.95      0.94      0.94       133\n",
      "\n",
      "[46  0  0  0 57  0  7  1 22]\n",
      "MNB Accuracy:  0.9398496240601504\n",
      "MNB F1:  0.9222503744242875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        46\n",
      "          1       0.97      1.00      0.98        57\n",
      "          2       1.00      0.83      0.91        30\n",
      "\n",
      "avg / total       0.96      0.96      0.96       133\n",
      "\n",
      "[46  0  0  0 57  0  3  2 25]\n",
      "svc Accuracy:  0.9624060150375939\n",
      "svc F1:  0.9534235274707145\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        46\n",
      "          1       0.95      1.00      0.97        57\n",
      "          2       1.00      0.70      0.82        30\n",
      "\n",
      "avg / total       0.94      0.93      0.93       133\n",
      "\n",
      "[46  0  0  0 57  0  6  3 21]\n",
      "LR Accuracy:  0.9323308270676691\n",
      "LR F1:  0.9122212987759205\n",
      "For name:  w_xu\n",
      "total sample size before apply threshold:  126\n",
      "Counter({'0000-0002-2884-3101': 43, '0000-0002-7085-7814': 20, '0000-0003-4019-5140': 19, '0000-0001-8006-2399': 16, '0000-0002-5976-4991': 6, '0000-0002-3014-756X': 6, '0000-0002-2084-2630': 5, '0000-0003-3681-5052': 2, '0000-0003-0164-4652': 2, '0000-0001-7294-8229': 2, '0000-0001-7598-1489': 2, '0000-0002-5442-8569': 1, '0000-0003-0030-8606': 1, '0000-0001-5588-9300': 1})\n",
      "['0000-0002-2884-3101', '0000-0002-7085-7814', '0000-0001-8006-2399', '0000-0003-4019-5140']\n",
      "Total sample size after apply threshold:  98\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(98, 240)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90        43\n",
      "          1       1.00      0.70      0.82        20\n",
      "          2       1.00      0.88      0.93        16\n",
      "          3       1.00      0.89      0.94        19\n",
      "\n",
      "avg / total       0.92      0.90      0.90        98\n",
      "\n",
      "[43  0  0  0  6 14  0  0  2  0 14  0  2  0  0 17]\n",
      "MNB Accuracy:  0.8979591836734694\n",
      "MNB F1:  0.8992851307189542\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        43\n",
      "          1       1.00      0.70      0.82        20\n",
      "          2       1.00      0.88      0.93        16\n",
      "          3       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       0.93      0.92      0.92        98\n",
      "\n",
      "[43  0  0  0  6 14  0  0  2  0 14  0  0  0  0 19]\n",
      "svc Accuracy:  0.9183673469387755\n",
      "svc F1:  0.917939090529829\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      1.00      0.78        43\n",
      "          1       1.00      0.50      0.67        20\n",
      "          2       1.00      0.56      0.72        16\n",
      "          3       1.00      0.63      0.77        19\n",
      "\n",
      "avg / total       0.84      0.76      0.75        98\n",
      "\n",
      "[43  0  0  0 10 10  0  0  7  0  9  0  7  0  0 12]\n",
      "LR Accuracy:  0.7551020408163265\n",
      "LR F1:  0.7356695992179862\n",
      "For name:  k_roy\n",
      "total sample size before apply threshold:  131\n",
      "Counter({'0000-0003-4486-8074': 110, '0000-0001-9623-0617': 17, '0000-0002-3694-3663': 2, '0000-0001-7537-0792': 1, '0000-0001-8799-6207': 1})\n",
      "['0000-0003-4486-8074', '0000-0001-9623-0617']\n",
      "Total sample size after apply threshold:  127\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(127, 107)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       110\n",
      "          1       1.00      0.65      0.79        17\n",
      "\n",
      "avg / total       0.96      0.95      0.95       127\n",
      "\n",
      "[110   0   6  11]\n",
      "MNB Accuracy:  0.952755905511811\n",
      "MNB F1:  0.879582806573957\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       110\n",
      "          1       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.97      0.97      0.97       127\n",
      "\n",
      "[110   0   4  13]\n",
      "svc Accuracy:  0.968503937007874\n",
      "svc F1:  0.924404761904762\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       110\n",
      "          1       1.00      0.24      0.38        17\n",
      "\n",
      "avg / total       0.91      0.90      0.87       127\n",
      "\n",
      "[110   0  13   4]\n",
      "LR Accuracy:  0.8976377952755905\n",
      "LR F1:  0.662579194768036\n",
      "For name:  b_white\n",
      "total sample size before apply threshold:  47\n",
      "Counter({'0000-0002-4293-6128': 29, '0000-0002-0684-5210': 7, '0000-0003-3365-939X': 7, '0000-0002-7477-9956': 3, '0000-0003-4191-3511': 1})\n",
      "['0000-0002-4293-6128']\n",
      "Total sample size after apply threshold:  29\n",
      "For name:  p_graham\n",
      "total sample size before apply threshold:  89\n",
      "Counter({'0000-0002-3745-0940': 33, '0000-0003-2890-2447': 27, '0000-0001-7133-1358': 26, '0000-0002-1600-1601': 3})\n",
      "['0000-0001-7133-1358', '0000-0002-3745-0940', '0000-0003-2890-2447']\n",
      "Total sample size after apply threshold:  86\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(86, 198)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82        26\n",
      "          1       0.75      1.00      0.86        33\n",
      "          2       1.00      0.89      0.94        27\n",
      "\n",
      "avg / total       0.90      0.87      0.87        86\n",
      "\n",
      "[18  8  0  0 33  0  0  3 24]\n",
      "MNB Accuracy:  0.872093023255814\n",
      "MNB F1:  0.8721670486376368\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.92      0.91        26\n",
      "          1       1.00      0.97      0.98        33\n",
      "          2       0.89      0.89      0.89        27\n",
      "\n",
      "avg / total       0.93      0.93      0.93        86\n",
      "\n",
      "[24  0  2  0 32  1  3  0 24]\n",
      "svc Accuracy:  0.9302325581395349\n",
      "svc F1:  0.9263882169542548\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.85      0.86        26\n",
      "          1       1.00      0.97      0.98        33\n",
      "          2       0.83      0.89      0.86        27\n",
      "\n",
      "avg / total       0.91      0.91      0.91        86\n",
      "\n",
      "[22  0  4  0 32  1  3  0 24]\n",
      "LR Accuracy:  0.9069767441860465\n",
      "LR F1:  0.9015011132658192\n",
      "For name:  d_rubin\n",
      "total sample size before apply threshold:  43\n",
      "Counter({'0000-0002-6388-7724': 19, '0000-0002-0483-9458': 13, '0000-0003-1639-6989': 9, '0000-0001-5057-4369': 2})\n",
      "['0000-0002-0483-9458', '0000-0002-6388-7724']\n",
      "Total sample size after apply threshold:  32\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 79)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.95      1.00      0.97        19\n",
      "\n",
      "avg / total       0.97      0.97      0.97        32\n",
      "\n",
      "[12  1  0 19]\n",
      "MNB Accuracy:  0.96875\n",
      "MNB F1:  0.9671794871794872\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.95      1.00      0.97        19\n",
      "\n",
      "avg / total       0.97      0.97      0.97        32\n",
      "\n",
      "[12  1  0 19]\n",
      "svc Accuracy:  0.96875\n",
      "svc F1:  0.9671794871794872\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.90      1.00      0.95        19\n",
      "\n",
      "avg / total       0.94      0.94      0.94        32\n",
      "\n",
      "[11  2  0 19]\n",
      "LR Accuracy:  0.9375\n",
      "LR F1:  0.9333333333333333\n",
      "For name:  b_ryan\n",
      "total sample size before apply threshold:  31\n",
      "Counter({'0000-0002-6703-3718': 15, '0000-0001-7213-3273': 11, '0000-0002-5018-2952': 3, '0000-0003-3881-8556': 2})\n",
      "['0000-0001-7213-3273', '0000-0002-6703-3718']\n",
      "Total sample size after apply threshold:  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(26, 99)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.82      0.86        11\n",
      "          1       0.88      0.93      0.90        15\n",
      "\n",
      "avg / total       0.89      0.88      0.88        26\n",
      "\n",
      "[ 9  2  1 14]\n",
      "MNB Accuracy:  0.8846153846153846\n",
      "MNB F1:  0.8801843317972351\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.88      1.00      0.94        15\n",
      "\n",
      "avg / total       0.93      0.92      0.92        26\n",
      "\n",
      "[ 9  2  0 15]\n",
      "svc Accuracy:  0.9230769230769231\n",
      "svc F1:  0.91875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.88      1.00      0.94        15\n",
      "\n",
      "avg / total       0.93      0.92      0.92        26\n",
      "\n",
      "[ 9  2  0 15]\n",
      "LR Accuracy:  0.9230769230769231\n",
      "LR F1:  0.91875\n",
      "For name:  j_kim\n",
      "total sample size before apply threshold:  2116\n",
      "Counter({'0000-0003-1835-9436': 200, '0000-0003-3477-1172': 146, '0000-0003-1232-5307': 124, '0000-0001-6537-0350': 78, '0000-0003-0934-3344': 73, '0000-0001-7964-106X': 56, '0000-0003-2337-6935': 52, '0000-0003-2068-7287': 51, '0000-0002-3573-638X': 46, '0000-0003-4085-293X': 41, '0000-0002-6349-6950': 41, '0000-0002-6931-8581': 38, '0000-0002-4171-3803': 38, '0000-0003-0373-5080': 36, '0000-0002-1299-4300': 36, '0000-0002-8383-8524': 33, '0000-0002-0087-1151': 32, '0000-0002-3500-7494': 32, '0000-0002-4687-6732': 31, '0000-0001-5979-5774': 30, '0000-0001-9660-6303': 29, '0000-0002-1903-8354': 28, '0000-0002-5390-8763': 27, '0000-0003-0767-1918': 26, '0000-0002-4747-9763': 25, '0000-0003-0103-7457': 24, '0000-0003-4035-0438': 23, '0000-0003-2841-147X': 23, '0000-0003-0693-1415': 23, '0000-0002-3566-3379': 19, '0000-0003-4978-1867': 18, '0000-0002-9570-4216': 18, '0000-0001-5080-7097': 17, '0000-0002-1672-5730': 17, '0000-0002-9159-0733': 16, '0000-0001-8208-8568': 16, '0000-0002-5329-6605': 16, '0000-0003-0578-0635': 16, '0000-0001-5204-3369': 16, '0000-0002-3729-8774': 15, '0000-0002-6152-2924': 15, '0000-0001-6417-864X': 15, '0000-0001-6426-9074': 15, '0000-0002-0195-1460': 14, '0000-0001-5951-8013': 14, '0000-0002-8218-0062': 13, '0000-0003-1519-3274': 12, '0000-0001-9881-2784': 12, '0000-0003-0530-3425': 12, '0000-0002-1376-9498': 12, '0000-0001-5096-4068': 12, '0000-0003-4217-3228': 11, '0000-0003-4438-1872': 11, '0000-0001-9840-4780': 11, '0000-0001-7649-4244': 11, '0000-0001-7842-2172': 10, '0000-0001-9595-2765': 10, '0000-0003-4157-9365': 10, '0000-0003-4802-010X': 9, '0000-0001-6188-7571': 9, '0000-0002-0484-9189': 8, '0000-0003-0448-1684': 8, '0000-0002-8580-8134': 8, '0000-0002-0359-2887': 8, '0000-0002-7040-7397': 8, '0000-0001-6603-6768': 8, '0000-0002-7419-021X': 7, '0000-0002-4490-3610': 7, '0000-0001-7819-2784': 7, '0000-0002-3849-649X': 6, '0000-0001-8984-2914': 6, '0000-0002-6575-452X': 6, '0000-0003-0462-6521': 5, '0000-0002-2713-1006': 5, '0000-0002-1810-5383': 5, '0000-0002-0066-534X': 4, '0000-0002-1076-1095': 4, '0000-0003-0340-4169': 4, '0000-0002-8321-026X': 4, '0000-0001-7340-2770': 4, '0000-0001-5228-4939': 4, '0000-0001-6210-4540': 4, '0000-0003-1222-0054': 3, '0000-0002-7425-1828': 3, '0000-0003-1522-9038': 3, '0000-0001-7409-6306': 3, '0000-0002-5810-1512': 3, '0000-0002-3502-7604': 3, '0000-0001-8087-7977': 3, '0000-0001-9302-0040': 3, '0000-0002-3010-1641': 3, '0000-0001-6201-9602': 3, '0000-0003-3172-3212': 3, '0000-0002-3512-5837': 2, '0000-0003-3889-2289': 2, '0000-0002-2124-0818': 2, '0000-0002-5678-2019': 2, '0000-0001-7353-9259': 2, '0000-0001-5235-2612': 2, '0000-0003-4074-877X': 2, '0000-0002-3984-0686': 2, '0000-0002-2679-8802': 2, '0000-0002-9423-438X': 2, '0000-0002-8908-0902': 2, '0000-0001-6746-7447': 2, '0000-0001-5794-975X': 2, '0000-0001-5402-7725': 1, '0000-0002-1273-6096': 1, '0000-0002-3531-489X': 1, '0000-0002-5886-8545': 1, '0000-0003-1834-4867': 1, '0000-0001-8641-7904': 1, '0000-0002-7918-1072': 1, '0000-0001-8371-2852': 1, '0000-0001-7176-409X': 1, '0000-0002-5409-2743': 1, '0000-0001-8616-1654': 1, '0000-0001-6886-2449': 1, '0000-0002-5201-9841': 1, '0000-0002-4966-1980': 1, '0000-0002-0947-876X': 1, '0000-0001-5104-4634': 1, '0000-0002-8663-798X': 1, '0000-0001-7565-068X': 1, '0000-0003-3530-9342': 1, '0000-0003-4907-4716': 1, '0000-0002-7689-6822': 1, '0000-0001-8986-8436': 1, '0000-0002-6944-473X': 1, '0000-0002-8416-3872': 1, '0000-0001-5086-0277': 1, '0000-0002-1384-6799': 1, '0000-0003-0812-6663': 1, '0000-0002-2156-9875': 1, '0000-0002-1094-3761': 1, '0000-0001-7282-0559': 1, '0000-0003-4677-0513': 1, '0000-0002-1418-3309': 1, '0000-0002-3365-8007': 1, '0000-0002-6143-8810': 1, '0000-0003-2479-0548': 1, '0000-0002-2556-7404': 1, '0000-0001-5494-4582': 1, '0000-0002-1764-1045': 1, '0000-0002-0872-4906': 1, '0000-0002-1368-6684': 1, '0000-0002-8237-3956': 1, '0000-0003-4856-6305': 1, '0000-0002-3423-5401': 1, '0000-0002-6204-5170': 1, '0000-0003-3155-0569': 1, '0000-0002-0341-7085': 1, '0000-0002-2938-3995': 1, '0000-0001-6600-9647': 1, '0000-0003-4184-363X': 1, '0000-0002-9011-4209': 1, '0000-0003-0461-6438': 1, '0000-0002-5065-5916': 1, '0000-0001-9078-6892': 1, '0000-0003-2304-6549': 1, '0000-0003-4491-0308': 1, '0000-0001-5182-0242': 1, '0000-0002-0708-9242': 1, '0000-0002-1690-9396': 1, '0000-0002-0824-8532': 1, '0000-0001-9661-5015': 1, '0000-0001-9061-3350': 1, '0000-0002-6214-3889': 1, '0000-0002-4478-6127': 1})\n",
      "['0000-0003-1519-3274', '0000-0001-9660-6303', '0000-0002-5390-8763', '0000-0002-9159-0733', '0000-0001-7842-2172', '0000-0001-7964-106X', '0000-0002-0195-1460', '0000-0001-9881-2784', '0000-0001-5080-7097', '0000-0003-0103-7457', '0000-0003-1232-5307', '0000-0003-4217-3228', '0000-0002-4687-6732', '0000-0002-0087-1151', '0000-0003-0934-3344', '0000-0002-3500-7494', '0000-0003-4978-1867', '0000-0002-3573-638X', '0000-0003-4438-1872', '0000-0002-3729-8774', '0000-0002-6931-8581', '0000-0002-9570-4216', '0000-0001-5979-5774', '0000-0002-8218-0062', '0000-0003-0767-1918', '0000-0002-1903-8354', '0000-0002-6152-2924', '0000-0001-5951-8013', '0000-0001-8208-8568', '0000-0002-4171-3803', '0000-0001-6417-864X', '0000-0001-9595-2765', '0000-0003-2068-7287', '0000-0002-5329-6605', '0000-0003-4085-293X', '0000-0003-0373-5080', '0000-0003-4035-0438', '0000-0002-4747-9763', '0000-0001-6537-0350', '0000-0003-0530-3425', '0000-0002-1376-9498', '0000-0003-4157-9365', '0000-0002-8383-8524', '0000-0003-2841-147X', '0000-0002-3566-3379', '0000-0003-0693-1415', '0000-0001-9840-4780', '0000-0003-1835-9436', '0000-0001-7649-4244', '0000-0003-2337-6935', '0000-0003-0578-0635', '0000-0002-1672-5730', '0000-0002-6349-6950', '0000-0001-5204-3369', '0000-0002-1299-4300', '0000-0001-6426-9074', '0000-0001-5096-4068', '0000-0003-3477-1172']\n",
      "Total sample size after apply threshold:  1846\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(1846, 1737)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.00      0.00      0.00        29\n",
      "          2       1.00      0.33      0.50        27\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       1.00      0.21      0.35        56\n",
      "          6       0.00      0.00      0.00        14\n",
      "          7       0.00      0.00      0.00        12\n",
      "          8       0.00      0.00      0.00        17\n",
      "          9       1.00      0.25      0.40        24\n",
      "         10       0.45      0.65      0.53       124\n",
      "         11       0.00      0.00      0.00        11\n",
      "         12       1.00      0.06      0.12        31\n",
      "         13       0.00      0.00      0.00        32\n",
      "         14       0.68      0.41      0.51        73\n",
      "         15       0.00      0.00      0.00        32\n",
      "         16       0.00      0.00      0.00        18\n",
      "         17       1.00      0.13      0.23        46\n",
      "         18       0.00      0.00      0.00        11\n",
      "         19       0.00      0.00      0.00        15\n",
      "         20       1.00      0.24      0.38        38\n",
      "         21       0.00      0.00      0.00        18\n",
      "         22       0.00      0.00      0.00        30\n",
      "         23       0.00      0.00      0.00        13\n",
      "         24       0.00      0.00      0.00        26\n",
      "         25       0.00      0.00      0.00        28\n",
      "         26       0.00      0.00      0.00        15\n",
      "         27       0.00      0.00      0.00        14\n",
      "         28       0.00      0.00      0.00        16\n",
      "         29       1.00      0.03      0.05        38\n",
      "         30       0.00      0.00      0.00        15\n",
      "         31       0.00      0.00      0.00        10\n",
      "         32       0.93      0.53      0.67        51\n",
      "         33       0.00      0.00      0.00        16\n",
      "         34       1.00      0.27      0.42        41\n",
      "         35       1.00      0.33      0.50        36\n",
      "         36       1.00      0.22      0.36        23\n",
      "         37       0.00      0.00      0.00        25\n",
      "         38       0.68      0.17      0.27        78\n",
      "         39       0.00      0.00      0.00        12\n",
      "         40       0.00      0.00      0.00        12\n",
      "         41       0.00      0.00      0.00        10\n",
      "         42       1.00      0.12      0.22        33\n",
      "         43       0.00      0.00      0.00        23\n",
      "         44       1.00      0.32      0.48        19\n",
      "         45       0.00      0.00      0.00        23\n",
      "         46       0.00      0.00      0.00        11\n",
      "         47       0.17      0.97      0.29       200\n",
      "         48       0.00      0.00      0.00        11\n",
      "         49       0.00      0.00      0.00        52\n",
      "         50       0.00      0.00      0.00        16\n",
      "         51       0.00      0.00      0.00        17\n",
      "         52       0.90      0.22      0.35        41\n",
      "         53       0.00      0.00      0.00        16\n",
      "         54       1.00      0.50      0.67        36\n",
      "         55       0.00      0.00      0.00        15\n",
      "         56       0.00      0.00      0.00        12\n",
      "         57       0.34      0.70      0.46       146\n",
      "\n",
      "avg / total       0.42      0.30      0.25      1846\n",
      "\n",
      "[  0   0   0 ...   0   0 102]\n",
      "MNB Accuracy:  0.3017334777898158\n",
      "MNB F1:  0.13386088363728044\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.88      0.72      0.79        29\n",
      "          2       0.86      0.93      0.89        27\n",
      "          3       0.89      0.50      0.64        16\n",
      "          4       1.00      0.60      0.75        10\n",
      "          5       0.44      0.61      0.51        56\n",
      "          6       1.00      0.86      0.92        14\n",
      "          7       0.67      1.00      0.80        12\n",
      "          8       1.00      0.65      0.79        17\n",
      "          9       1.00      0.71      0.83        24\n",
      "         10       0.56      0.79      0.65       124\n",
      "         11       0.00      0.00      0.00        11\n",
      "         12       0.93      0.90      0.92        31\n",
      "         13       0.81      0.53      0.64        32\n",
      "         14       0.67      0.77      0.72        73\n",
      "         15       0.45      0.31      0.37        32\n",
      "         16       0.43      0.67      0.52        18\n",
      "         17       0.87      0.85      0.86        46\n",
      "         18       0.00      0.00      0.00        11\n",
      "         19       1.00      0.40      0.57        15\n",
      "         20       0.96      0.71      0.82        38\n",
      "         21       0.81      0.72      0.76        18\n",
      "         22       0.85      0.73      0.79        30\n",
      "         23       0.83      0.38      0.53        13\n",
      "         24       0.80      0.46      0.59        26\n",
      "         25       1.00      0.79      0.88        28\n",
      "         26       0.67      0.27      0.38        15\n",
      "         27       1.00      0.43      0.60        14\n",
      "         28       0.33      0.06      0.11        16\n",
      "         29       0.74      0.66      0.69        38\n",
      "         30       1.00      0.80      0.89        15\n",
      "         31       1.00      0.60      0.75        10\n",
      "         32       0.88      0.69      0.77        51\n",
      "         33       1.00      0.31      0.48        16\n",
      "         34       1.00      0.90      0.95        41\n",
      "         35       0.88      0.81      0.84        36\n",
      "         36       1.00      0.74      0.85        23\n",
      "         37       0.87      0.52      0.65        25\n",
      "         38       0.51      0.50      0.51        78\n",
      "         39       1.00      0.50      0.67        12\n",
      "         40       1.00      0.33      0.50        12\n",
      "         41       1.00      0.70      0.82        10\n",
      "         42       0.79      0.70      0.74        33\n",
      "         43       1.00      0.70      0.82        23\n",
      "         44       1.00      0.84      0.91        19\n",
      "         45       0.76      0.57      0.65        23\n",
      "         46       0.86      0.55      0.67        11\n",
      "         47       0.60      0.86      0.71       200\n",
      "         48       0.42      0.45      0.43        11\n",
      "         49       0.42      0.33      0.37        52\n",
      "         50       0.79      0.69      0.73        16\n",
      "         51       0.30      0.18      0.22        17\n",
      "         52       0.80      0.80      0.80        41\n",
      "         53       0.60      0.19      0.29        16\n",
      "         54       1.00      0.83      0.91        36\n",
      "         55       0.88      0.47      0.61        15\n",
      "         56       1.00      0.67      0.80        12\n",
      "         57       0.44      0.79      0.57       146\n",
      "\n",
      "avg / total       0.72      0.67      0.67      1846\n",
      "\n",
      "[  7   0   0 ...   0   0 116]\n",
      "svc Accuracy:  0.6749729144095341\n",
      "svc F1:  0.6545705215599958\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.42      0.59        12\n",
      "          1       0.79      0.52      0.62        29\n",
      "          2       0.81      0.93      0.86        27\n",
      "          3       1.00      0.31      0.48        16\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       0.57      0.52      0.54        56\n",
      "          6       1.00      0.71      0.83        14\n",
      "          7       0.50      0.25      0.33        12\n",
      "          8       0.91      0.59      0.71        17\n",
      "          9       1.00      0.67      0.80        24\n",
      "         10       0.48      0.77      0.59       124\n",
      "         11       0.00      0.00      0.00        11\n",
      "         12       0.92      0.77      0.84        31\n",
      "         13       1.00      0.28      0.44        32\n",
      "         14       0.58      0.78      0.67        73\n",
      "         15       0.50      0.16      0.24        32\n",
      "         16       0.71      0.56      0.63        18\n",
      "         17       0.78      0.83      0.80        46\n",
      "         18       0.00      0.00      0.00        11\n",
      "         19       1.00      0.27      0.42        15\n",
      "         20       1.00      0.63      0.77        38\n",
      "         21       1.00      0.44      0.62        18\n",
      "         22       0.93      0.43      0.59        30\n",
      "         23       0.00      0.00      0.00        13\n",
      "         24       0.86      0.23      0.36        26\n",
      "         25       1.00      0.82      0.90        28\n",
      "         26       0.67      0.13      0.22        15\n",
      "         27       1.00      0.36      0.53        14\n",
      "         28       0.00      0.00      0.00        16\n",
      "         29       0.67      0.58      0.62        38\n",
      "         30       1.00      0.80      0.89        15\n",
      "         31       1.00      0.30      0.46        10\n",
      "         32       0.85      0.69      0.76        51\n",
      "         33       1.00      0.25      0.40        16\n",
      "         34       1.00      0.85      0.92        41\n",
      "         35       0.92      0.67      0.77        36\n",
      "         36       1.00      0.74      0.85        23\n",
      "         37       0.80      0.48      0.60        25\n",
      "         38       0.45      0.35      0.39        78\n",
      "         39       1.00      0.33      0.50        12\n",
      "         40       0.00      0.00      0.00        12\n",
      "         41       1.00      0.70      0.82        10\n",
      "         42       0.83      0.73      0.77        33\n",
      "         43       1.00      0.39      0.56        23\n",
      "         44       0.81      0.89      0.85        19\n",
      "         45       0.80      0.52      0.63        23\n",
      "         46       0.86      0.55      0.67        11\n",
      "         47       0.52      0.86      0.65       200\n",
      "         48       0.00      0.00      0.00        11\n",
      "         49       0.52      0.25      0.34        52\n",
      "         50       0.82      0.56      0.67        16\n",
      "         51       0.00      0.00      0.00        17\n",
      "         52       0.77      0.83      0.80        41\n",
      "         53       0.00      0.00      0.00        16\n",
      "         54       1.00      0.81      0.89        36\n",
      "         55       0.75      0.20      0.32        15\n",
      "         56       0.75      0.50      0.60        12\n",
      "         57       0.31      0.87      0.46       146\n",
      "\n",
      "avg / total       0.66      0.60      0.58      1846\n",
      "\n",
      "[  5   0   1 ...   0   0 127]\n",
      "LR Accuracy:  0.5985915492957746\n",
      "LR F1:  0.5274551941358625\n",
      "For name:  a_duarte\n",
      "total sample size before apply threshold:  373\n",
      "Counter({'0000-0002-4868-4099': 194, '0000-0002-0616-4650': 36, '0000-0002-9255-3635': 34, '0000-0002-0223-7867': 30, '0000-0003-0800-0112': 19, '0000-0003-2181-0187': 13, '0000-0003-4001-0871': 12, '0000-0003-3333-5977': 10, '0000-0001-9036-0170': 6, '0000-0001-6849-6004': 5, '0000-0001-5578-1586': 4, '0000-0003-0218-1952': 4, '0000-0002-6774-4886': 3, '0000-0002-5911-6521': 2, '0000-0001-8369-368X': 1})\n",
      "['0000-0003-4001-0871', '0000-0003-0800-0112', '0000-0003-2181-0187', '0000-0002-0223-7867', '0000-0002-0616-4650', '0000-0002-4868-4099', '0000-0002-9255-3635', '0000-0003-3333-5977']\n",
      "Total sample size after apply threshold:  348\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(348, 573)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.00      0.00      0.00        19\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       1.00      0.47      0.64        30\n",
      "          4       1.00      0.44      0.62        36\n",
      "          5       0.62      1.00      0.77       194\n",
      "          6       1.00      0.18      0.30        34\n",
      "          7       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.63      0.66      0.58       348\n",
      "\n",
      "[  0   0   0   0   0  12   0   0   0   0   0   0   0  19   0   0   0   0\n",
      "   0   0   0  13   0   0   0   0   0  14   0  16   0   0   0   0   0   0\n",
      "  16  20   0   0   0   0   0   0   0 194   0   0   0   0   0   0   0  28\n",
      "   6   0   0   0   0   0   0  10   0   0]\n",
      "MNB Accuracy:  0.6609195402298851\n",
      "MNB F1:  0.289818333840073\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       1.00      0.47      0.64        19\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       1.00      0.97      0.98        30\n",
      "          4       1.00      0.78      0.88        36\n",
      "          5       0.84      1.00      0.91       194\n",
      "          6       0.97      0.82      0.89        34\n",
      "          7       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.91      0.89      0.88       348\n",
      "\n",
      "[  9   0   0   0   0   3   0   0   0   9   0   0   0   9   1   0   0   0\n",
      "   8   0   0   5   0   0   0   0   0  29   0   1   0   0   0   0   0   0\n",
      "  28   8   0   0   0   0   0   0   0 194   0   0   0   0   0   0   0   6\n",
      "  28   0   0   0   0   0   0   5   0   5]\n",
      "svc Accuracy:  0.8908045977011494\n",
      "svc F1:  0.8235565426735666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       1.00      0.21      0.35        19\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       1.00      0.63      0.78        30\n",
      "          4       1.00      0.39      0.56        36\n",
      "          5       0.65      1.00      0.79       194\n",
      "          6       1.00      0.38      0.55        34\n",
      "          7       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.74      0.70      0.64       348\n",
      "\n",
      "[  1   0   0   0   0  11   0   0   0   4   0   0   0  15   0   0   0   0\n",
      "   0   0   0  13   0   0   0   0   0  19   0  11   0   0   0   0   0   0\n",
      "  14  22   0   0   0   0   0   0   0 194   0   0   0   0   0   0   0  21\n",
      "  13   0   0   0   0   0   0  10   0   0]\n",
      "LR Accuracy:  0.7040229885057471\n",
      "LR F1:  0.3975747458540711\n",
      "For name:  a_correia\n",
      "total sample size before apply threshold:  136\n",
      "Counter({'0000-0002-5115-1429': 81, '0000-0003-0408-6262': 26, '0000-0002-0119-9790': 11, '0000-0002-2831-025X': 7, '0000-0003-2414-0131': 4, '0000-0003-3000-9324': 4, '0000-0002-8946-8579': 2, '0000-0002-2172-6631': 1})\n",
      "['0000-0003-0408-6262', '0000-0002-5115-1429', '0000-0002-0119-9790']\n",
      "Total sample size after apply threshold:  118\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(118, 196)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "118\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        26\n",
      "          1       0.86      1.00      0.93        81\n",
      "          2       1.00      0.09      0.17        11\n",
      "\n",
      "avg / total       0.91      0.89      0.86       118\n",
      "\n",
      "[23  3  0  0 81  0  0 10  1]\n",
      "MNB Accuracy:  0.8898305084745762\n",
      "MNB F1:  0.6770521541950113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        26\n",
      "          1       0.91      1.00      0.95        81\n",
      "          2       1.00      0.27      0.43        11\n",
      "\n",
      "avg / total       0.94      0.93      0.91       118\n",
      "\n",
      "[26  0  0  0 81  0  0  8  3]\n",
      "svc Accuracy:  0.9322033898305084\n",
      "svc F1:  0.7938375350140056\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.65      0.79        26\n",
      "          1       0.80      1.00      0.89        81\n",
      "          2       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.77      0.83      0.79       118\n",
      "\n",
      "[17  9  0  0 81  0  0 11  0]\n",
      "LR Accuracy:  0.8305084745762712\n",
      "LR F1:  0.5602691881761649\n",
      "For name:  a_reynolds\n",
      "total sample size before apply threshold:  40\n",
      "Counter({'0000-0002-0836-746X': 23, '0000-0001-9534-8699': 7, '0000-0002-6768-5716': 5, '0000-0002-9919-4161': 3, '0000-0003-0554-8107': 1, '0000-0002-6364-6250': 1})\n",
      "['0000-0002-0836-746X']\n",
      "Total sample size after apply threshold:  23\n",
      "For name:  g_qin\n",
      "total sample size before apply threshold:  15\n",
      "Counter({'0000-0001-6770-1096': 7, '0000-0002-2212-1597': 6, '0000-0002-3524-2013': 1, '0000-0002-3437-3716': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_tang\n",
      "total sample size before apply threshold:  86\n",
      "Counter({'0000-0001-6460-8136': 36, '0000-0003-2861-682X': 19, '0000-0002-3483-0219': 10, '0000-0002-8756-8445': 6, '0000-0001-5858-5126': 4, '0000-0001-8117-9695': 3, '0000-0003-2876-9199': 3, '0000-0002-2416-4101': 2, '0000-0001-7479-6206': 1, '0000-0001-9726-9943': 1, '0000-0001-7321-6927': 1})\n",
      "['0000-0003-2861-682X', '0000-0001-6460-8136', '0000-0002-3483-0219']\n",
      "Total sample size after apply threshold:  65\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 165)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91        19\n",
      "          1       0.73      1.00      0.85        36\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.70      0.80      0.74        65\n",
      "\n",
      "[16  3  0  0 36  0  0 10  0]\n",
      "MNB Accuracy:  0.8\n",
      "MNB F1:  0.5871148459383754\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        19\n",
      "          1       0.86      1.00      0.92        36\n",
      "          2       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.92      0.91      0.90        65\n",
      "\n",
      "[18  1  0  0 36  0  0  5  5]\n",
      "svc Accuracy:  0.9076923076923077\n",
      "svc F1:  0.8542388542388543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.63      0.77        19\n",
      "          1       0.68      1.00      0.81        36\n",
      "          2       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.67      0.74      0.67        65\n",
      "\n",
      "[12  7  0  0 36  0  0 10  0]\n",
      "LR Accuracy:  0.7384615384615385\n",
      "LR F1:  0.5277274374773469\n",
      "For name:  a_baranov\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0002-9976-8532': 20, '0000-0002-9112-0838': 14, '0000-0003-3987-8112': 7, '0000-0001-8810-9972': 1})\n",
      "['0000-0002-9112-0838', '0000-0002-9976-8532']\n",
      "Total sample size after apply threshold:  34\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(34, 95)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        14\n",
      "          1       0.95      0.95      0.95        20\n",
      "\n",
      "avg / total       0.94      0.94      0.94        34\n",
      "\n",
      "[13  1  1 19]\n",
      "MNB Accuracy:  0.9411764705882353\n",
      "MNB F1:  0.9392857142857143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93        14\n",
      "          1       0.95      0.95      0.95        20\n",
      "\n",
      "avg / total       0.94      0.94      0.94        34\n",
      "\n",
      "[13  1  1 19]\n",
      "svc Accuracy:  0.9411764705882353\n",
      "svc F1:  0.9392857142857143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.71      0.80        14\n",
      "          1       0.83      0.95      0.88        20\n",
      "\n",
      "avg / total       0.86      0.85      0.85        34\n",
      "\n",
      "[10  4  1 19]\n",
      "LR Accuracy:  0.8529411764705882\n",
      "LR F1:  0.8418604651162791\n",
      "For name:  r_gray\n",
      "total sample size before apply threshold:  162\n",
      "Counter({'0000-0001-9694-4206': 83, '0000-0002-9858-0191': 48, '0000-0002-2203-2703': 19, '0000-0001-9668-6497': 6, '0000-0002-5890-1819': 6})\n",
      "['0000-0001-9694-4206', '0000-0002-2203-2703', '0000-0002-9858-0191']\n",
      "Total sample size after apply threshold:  150\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(150, 332)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "150\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91        83\n",
      "          1       1.00      0.37      0.54        19\n",
      "          2       0.96      0.90      0.92        48\n",
      "\n",
      "avg / total       0.90      0.88      0.87       150\n",
      "\n",
      "[82  0  1 11  7  1  5  0 43]\n",
      "MNB Accuracy:  0.88\n",
      "MNB F1:  0.7897566897745119\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        83\n",
      "          1       1.00      0.53      0.69        19\n",
      "          2       1.00      0.88      0.93        48\n",
      "\n",
      "avg / total       0.92      0.90      0.89       150\n",
      "\n",
      "[83  0  0  9 10  0  6  0 42]\n",
      "svc Accuracy:  0.9\n",
      "svc F1:  0.8467051925234438\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        83\n",
      "          1       1.00      0.11      0.19        19\n",
      "          2       1.00      0.83      0.91        48\n",
      "\n",
      "avg / total       0.87      0.83      0.80       150\n",
      "\n",
      "[83  0  0 17  2  0  8  0 40]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.6562256824036928\n",
      "For name:  r_nunes\n",
      "total sample size before apply threshold:  46\n",
      "Counter({'0000-0001-7425-5717': 28, '0000-0002-1377-9899': 13, '0000-0001-8633-4404': 3, '0000-0002-9014-0570': 2})\n",
      "['0000-0002-1377-9899', '0000-0001-7425-5717']\n",
      "Total sample size after apply threshold:  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(41, 117)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "41\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87        13\n",
      "          1       0.90      1.00      0.95        28\n",
      "\n",
      "avg / total       0.93      0.93      0.92        41\n",
      "\n",
      "[10  3  0 28]\n",
      "MNB Accuracy:  0.926829268292683\n",
      "MNB F1:  0.9093588798820929\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82        13\n",
      "          1       0.88      1.00      0.93        28\n",
      "\n",
      "avg / total       0.91      0.90      0.90        41\n",
      "\n",
      "[ 9  4  0 28]\n",
      "svc Accuracy:  0.9024390243902439\n",
      "svc F1:  0.8757575757575757\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.62      0.76        13\n",
      "          1       0.85      1.00      0.92        28\n",
      "\n",
      "avg / total       0.90      0.88      0.87        41\n",
      "\n",
      "[ 8  5  0 28]\n",
      "LR Accuracy:  0.8780487804878049\n",
      "LR F1:  0.839968774395004\n",
      "For name:  s_huang\n",
      "total sample size before apply threshold:  441\n",
      "Counter({'0000-0002-0590-3474': 119, '0000-0002-3239-1072': 85, '0000-0001-5688-3410': 48, '0000-0001-9517-2515': 36, '0000-0001-8261-7079': 28, '0000-0001-6244-1555': 23, '0000-0001-8622-4838': 19, '0000-0003-4815-1863': 17, '0000-0001-7797-3626': 17, '0000-0003-2976-5798': 9, '0000-0002-2030-7574': 8, '0000-0003-1372-0480': 5, '0000-0001-5933-3115': 4, '0000-0002-8436-1991': 4, '0000-0003-1878-9348': 4, '0000-0003-1023-118X': 3, '0000-0001-9751-4523': 2, '0000-0003-4273-9682': 1, '0000-0001-7426-5181': 1, '0000-0002-8547-5309': 1, '0000-0002-1127-8898': 1, '0000-0002-6124-4178': 1, '0000-0002-7906-8467': 1, '0000-0002-8072-4388': 1, '0000-0002-4315-4494': 1, '0000-0003-3200-2206': 1, '0000-0003-3391-539X': 1})\n",
      "['0000-0001-8622-4838', '0000-0002-0590-3474', '0000-0001-5688-3410', '0000-0003-4815-1863', '0000-0001-7797-3626', '0000-0001-6244-1555', '0000-0002-3239-1072', '0000-0001-9517-2515', '0000-0001-8261-7079']\n",
      "Total sample size after apply threshold:  392\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(392, 332)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        19\n",
      "          1       0.62      0.99      0.77       119\n",
      "          2       0.93      0.83      0.88        48\n",
      "          3       1.00      0.12      0.21        17\n",
      "          4       1.00      0.06      0.11        17\n",
      "          5       0.50      0.04      0.08        23\n",
      "          6       0.67      0.86      0.75        85\n",
      "          7       0.90      0.53      0.67        36\n",
      "          8       1.00      0.89      0.94        28\n",
      "\n",
      "avg / total       0.72      0.71      0.65       392\n",
      "\n",
      "[  0  18   1   0   0   0   0   0   0   0 118   1   0   0   0   0   0   0\n",
      "   0   7  40   0   0   1   0   0   0   0   4   0   2   0   0  11   0   0\n",
      "   0   4   0   0   1   0  11   1   0   0  21   1   0   0   1   0   0   0\n",
      "   0  11   0   0   0   0  73   1   0   0   3   0   0   0   0  14  19   0\n",
      "   0   3   0   0   0   0   0   0  25]\n",
      "MNB Accuracy:  0.7117346938775511\n",
      "MNB F1:  0.4899591427694022\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.58      0.71        19\n",
      "          1       0.86      0.97      0.91       119\n",
      "          2       0.93      0.83      0.88        48\n",
      "          3       1.00      0.59      0.74        17\n",
      "          4       1.00      0.71      0.83        17\n",
      "          5       0.84      0.70      0.76        23\n",
      "          6       0.74      0.92      0.82        85\n",
      "          7       0.83      0.67      0.74        36\n",
      "          8       1.00      1.00      1.00        28\n",
      "\n",
      "avg / total       0.86      0.85      0.85       392\n",
      "\n",
      "[ 11   3   2   0   0   0   2   1   0   0 115   1   0   0   1   2   0   0\n",
      "   0   4  40   0   0   2   2   0   0   0   0   0  10   0   0   6   1   0\n",
      "   0   0   0   0  12   0   4   1   0   0   6   0   0   0  16   1   0   0\n",
      "   0   5   0   0   0   0  78   2   0   1   1   0   0   0   0  10  24   0\n",
      "   0   0   0   0   0   0   0   0  28]\n",
      "svc Accuracy:  0.8520408163265306\n",
      "svc F1:  0.8208483430165742\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.16      0.27        19\n",
      "          1       0.79      0.98      0.88       119\n",
      "          2       0.95      0.83      0.89        48\n",
      "          3       1.00      0.53      0.69        17\n",
      "          4       1.00      0.29      0.45        17\n",
      "          5       0.85      0.48      0.61        23\n",
      "          6       0.66      0.94      0.77        85\n",
      "          7       0.88      0.58      0.70        36\n",
      "          8       1.00      0.93      0.96        28\n",
      "\n",
      "avg / total       0.84      0.80      0.77       392\n",
      "\n",
      "[  3  12   1   0   0   0   3   0   0   0 117   0   0   0   1   1   0   0\n",
      "   0   3  40   0   0   1   4   0   0   0   0   0   9   0   0   7   1   0\n",
      "   0   0   0   0   5   0  11   1   0   0   7   1   0   0  11   4   0   0\n",
      "   0   4   0   0   0   0  80   1   0   0   3   0   0   0   0  12  21   0\n",
      "   0   2   0   0   0   0   0   0  26]\n",
      "LR Accuracy:  0.7959183673469388\n",
      "LR F1:  0.6924327485365319\n",
      "For name:  c_reid\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0002-1152-8551': 33, '0000-0003-2739-1585': 13, '0000-0001-8572-1162': 11, '0000-0001-5916-8172': 2, '0000-0001-8117-662X': 1})\n",
      "['0000-0001-8572-1162', '0000-0003-2739-1585', '0000-0002-1152-8551']\n",
      "Total sample size after apply threshold:  57\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(57, 153)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.36      0.53        11\n",
      "          1       1.00      0.54      0.70        13\n",
      "          2       0.72      1.00      0.84        33\n",
      "\n",
      "avg / total       0.84      0.77      0.75        57\n",
      "\n",
      "[ 4  0  7  0  7  6  0  0 33]\n",
      "MNB Accuracy:  0.7719298245614035\n",
      "MNB F1:  0.689592123769339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        11\n",
      "          1       1.00      0.69      0.82        13\n",
      "          2       0.77      1.00      0.87        33\n",
      "\n",
      "avg / total       0.87      0.82      0.81        57\n",
      "\n",
      "[ 5  0  6  0  9  4  0  0 33]\n",
      "svc Accuracy:  0.8245614035087719\n",
      "svc F1:  0.7705342902711324\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17        11\n",
      "          1       1.00      0.15      0.27        13\n",
      "          2       0.61      1.00      0.76        33\n",
      "\n",
      "avg / total       0.77      0.63      0.53        57\n",
      "\n",
      "[ 1  0 10  0  2 11  0  0 33]\n",
      "LR Accuracy:  0.631578947368421\n",
      "LR F1:  0.3973180076628353\n",
      "For name:  h_lu\n",
      "total sample size before apply threshold:  108\n",
      "Counter({'0000-0003-1720-6526': 20, '0000-0002-8340-2739': 19, '0000-0003-2180-3091': 17, '0000-0003-4025-3160': 9, '0000-0001-9732-0833': 6, '0000-0002-1440-9902': 6, '0000-0002-3940-3283': 5, '0000-0002-0017-4276': 5, '0000-0003-3604-7145': 5, '0000-0002-6708-0223': 5, '0000-0002-0349-2181': 4, '0000-0002-9090-258X': 3, '0000-0002-5177-3391': 2, '0000-0002-6881-660X': 1, '0000-0002-9443-4031': 1})\n",
      "['0000-0002-8340-2739', '0000-0003-1720-6526', '0000-0003-2180-3091']\n",
      "Total sample size after apply threshold:  56\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(56, 126)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        19\n",
      "          1       0.95      0.95      0.95        20\n",
      "          2       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.97      0.96      0.96        56\n",
      "\n",
      "[18  1  0  0 19  1  0  0 17]\n",
      "MNB Accuracy:  0.9642857142857143\n",
      "MNB F1:  0.9648005148005149\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        19\n",
      "          1       0.95      0.95      0.95        20\n",
      "          2       0.88      0.88      0.88        17\n",
      "\n",
      "avg / total       0.93      0.93      0.93        56\n",
      "\n",
      "[18  0  1  0 19  1  1  1 15]\n",
      "svc Accuracy:  0.9285714285714286\n",
      "svc F1:  0.9265737874097008\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97        19\n",
      "          1       0.95      0.95      0.95        20\n",
      "          2       0.94      0.88      0.91        17\n",
      "\n",
      "avg / total       0.95      0.95      0.95        56\n",
      "\n",
      "[19  0  0  0 19  1  1  1 15]\n",
      "LR Accuracy:  0.9464285714285714\n",
      "LR F1:  0.9444832944832945\n",
      "For name:  j_cordeiro\n",
      "total sample size before apply threshold:  30\n",
      "Counter({'0000-0003-4656-6045': 14, '0000-0003-4605-1615': 9, '0000-0003-0902-9638': 5, '0000-0001-7876-0219': 1, '0000-0002-2118-1192': 1})\n",
      "['0000-0003-4656-6045']\n",
      "Total sample size after apply threshold:  14\n",
      "For name:  c_yu\n",
      "total sample size before apply threshold:  335\n",
      "Counter({'0000-0001-5664-9392': 252, '0000-0002-2136-2444': 26, '0000-0002-8648-8419': 16, '0000-0002-8453-5023': 11, '0000-0002-1742-2344': 10, '0000-0001-8062-9498': 6, '0000-0003-0084-6746': 5, '0000-0002-2934-2122': 3, '0000-0002-0635-3718': 2, '0000-0003-3712-5491': 2, '0000-0003-1555-8683': 1, '0000-0002-4304-2177': 1})\n",
      "['0000-0002-1742-2344', '0000-0001-5664-9392', '0000-0002-2136-2444', '0000-0002-8648-8419', '0000-0002-8453-5023']\n",
      "Total sample size after apply threshold:  315\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(315, 324)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "315\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.83      0.99      0.90       252\n",
      "          2       0.60      0.12      0.19        26\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.75      0.83      0.77       315\n",
      "\n",
      "[  0  10   0   0   0   0 250   2   0   0   0  23   3   0   0   0  16   0\n",
      "   0   0   0   3   0   0   8]\n",
      "MNB Accuracy:  0.8285714285714286\n",
      "MNB F1:  0.3876361452133887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.94      1.00      0.97       252\n",
      "          2       1.00      0.77      0.87        26\n",
      "          3       1.00      0.50      0.67        16\n",
      "          4       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.95      0.95      0.94       315\n",
      "\n",
      "[  9   1   0   0   0   0 252   0   0   0   0   6  20   0   0   0   8   0\n",
      "   8   0   0   1   0   0  10]\n",
      "svc Accuracy:  0.9492063492063492\n",
      "svc F1:  0.8810424053444648\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        10\n",
      "          1       0.87      1.00      0.93       252\n",
      "          2       1.00      0.62      0.76        26\n",
      "          3       1.00      0.06      0.12        16\n",
      "          4       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.89      0.88      0.84       315\n",
      "\n",
      "[  1   9   0   0   0   0 252   0   0   0   0  10  16   0   0   0  15   0\n",
      "   1   0   0   5   0   0   6]\n",
      "LR Accuracy:  0.8761904761904762\n",
      "LR F1:  0.5390858302135519\n",
      "For name:  d_simpson\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0002-0500-9675': 11, '0000-0002-1189-0833': 11, '0000-0002-8105-2552': 2, '0000-0002-9768-7413': 2, '0000-0001-9538-3208': 1})\n",
      "['0000-0002-0500-9675', '0000-0002-1189-0833']\n",
      "Total sample size after apply threshold:  22\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(22, 52)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "22\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.91      0.87        11\n",
      "          1       0.90      0.82      0.86        11\n",
      "\n",
      "avg / total       0.87      0.86      0.86        22\n",
      "\n",
      "[10  1  2  9]\n",
      "MNB Accuracy:  0.8636363636363636\n",
      "MNB F1:  0.8633540372670807\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "[10  1  0 11]\n",
      "svc Accuracy:  0.9545454545454546\n",
      "svc F1:  0.9544513457556936\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "[10  1  0 11]\n",
      "LR Accuracy:  0.9545454545454546\n",
      "LR F1:  0.9544513457556936\n",
      "For name:  c_pereira\n",
      "total sample size before apply threshold:  258\n",
      "Counter({'0000-0001-7874-1894': 55, '0000-0002-6630-5056': 31, '0000-0002-8392-9581': 29, '0000-0002-9724-1382': 26, '0000-0002-8167-6912': 25, '0000-0002-0804-9197': 14, '0000-0003-3421-8676': 11, '0000-0003-0093-771X': 9, '0000-0002-7133-0600': 8, '0000-0002-2146-1223': 8, '0000-0001-8050-5102': 7, '0000-0001-9224-1917': 7, '0000-0001-8111-1455': 6, '0000-0003-1389-9214': 5, '0000-0001-5514-4544': 4, '0000-0003-1788-4562': 4, '0000-0002-2899-9640': 3, '0000-0003-3406-3985': 3, '0000-0002-1805-7115': 2, '0000-0001-6153-7555': 1})\n",
      "['0000-0002-8167-6912', '0000-0001-7874-1894', '0000-0002-9724-1382', '0000-0002-8392-9581', '0000-0002-0804-9197', '0000-0003-3421-8676', '0000-0002-6630-5056']\n",
      "Total sample size after apply threshold:  191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 459)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        25\n",
      "          1       0.79      1.00      0.88        55\n",
      "          2       1.00      0.77      0.87        26\n",
      "          3       0.87      0.90      0.88        29\n",
      "          4       1.00      0.71      0.83        14\n",
      "          5       1.00      0.09      0.17        11\n",
      "          6       0.89      1.00      0.94        31\n",
      "\n",
      "avg / total       0.89      0.87      0.85       191\n",
      "\n",
      "[24  0  0  0  0  0  1  0 55  0  0  0  0  0  0  3 20  1  0  0  2  0  3  0\n",
      " 26  0  0  0  0  1  0  2 10  0  1  1  8  0  1  0  1  0  0  0  0  0  0  0\n",
      " 31]\n",
      "MNB Accuracy:  0.8743455497382199\n",
      "MNB F1:  0.790045012712662\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        25\n",
      "          1       0.85      1.00      0.92        55\n",
      "          2       1.00      0.88      0.94        26\n",
      "          3       0.90      0.93      0.92        29\n",
      "          4       1.00      0.79      0.88        14\n",
      "          5       1.00      0.73      0.84        11\n",
      "          6       1.00      0.97      0.98        31\n",
      "\n",
      "avg / total       0.94      0.93      0.93       191\n",
      "\n",
      "[24  0  0  1  0  0  0  0 55  0  0  0  0  0  0  2 23  1  0  0  0  0  2  0\n",
      " 27  0  0  0  0  2  0  1 11  0  0  0  3  0  0  0  8  0  0  1  0  0  0  0\n",
      " 30]\n",
      "svc Accuracy:  0.9319371727748691\n",
      "svc F1:  0.9222857244897888\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        25\n",
      "          1       0.72      1.00      0.84        55\n",
      "          2       1.00      0.85      0.92        26\n",
      "          3       0.93      0.90      0.91        29\n",
      "          4       1.00      0.79      0.88        14\n",
      "          5       1.00      0.09      0.17        11\n",
      "          6       1.00      1.00      1.00        31\n",
      "\n",
      "avg / total       0.91      0.88      0.86       191\n",
      "\n",
      "[22  3  0  0  0  0  0  0 55  0  0  0  0  0  0  3 22  1  0  0  0  0  3  0\n",
      " 26  0  0  0  0  2  0  1 11  0  0  0 10  0  0  0  1  0  0  0  0  0  0  0\n",
      " 31]\n",
      "LR Accuracy:  0.8795811518324608\n",
      "LR F1:  0.8073541291917467\n",
      "For name:  h_wang\n",
      "total sample size before apply threshold:  848\n",
      "Counter({'0000-0002-0211-9000': 91, '0000-0003-0477-2908': 62, '0000-0002-5051-4929': 44, '0000-0002-7528-7494': 44, '0000-0002-9887-5555': 39, '0000-0001-5836-4120': 31, '0000-0002-8796-0367': 30, '0000-0002-7752-6217': 30, '0000-0003-1708-8734': 28, '0000-0002-6107-5095': 27, '0000-0001-8238-1641': 27, '0000-0003-4623-1878': 26, '0000-0001-9570-3611': 25, '0000-0001-9199-0721': 25, '0000-0002-7959-7377': 24, '0000-0003-2420-3147': 23, '0000-0002-8066-475X': 19, '0000-0003-1625-3400': 18, '0000-0002-1483-5135': 17, '0000-0001-6590-7736': 15, '0000-0002-9634-8778': 15, '0000-0001-7964-0809': 14, '0000-0001-6507-5503': 13, '0000-0003-4107-2062': 11, '0000-0002-3355-2448': 11, '0000-0002-6567-9144': 10, '0000-0003-4414-3372': 10, '0000-0002-6859-5683': 9, '0000-0002-2565-5543': 8, '0000-0003-0388-510X': 7, '0000-0003-1086-5318': 7, '0000-0002-4858-8195': 5, '0000-0002-2325-0120': 5, '0000-0003-4453-8059': 5, '0000-0001-9243-3935': 5, '0000-0002-9567-8249': 4, '0000-0003-4957-0509': 4, '0000-0002-0769-600X': 4, '0000-0002-1994-4402': 4, '0000-0002-3857-5737': 4, '0000-0001-7988-6120': 3, '0000-0002-0600-2555': 3, '0000-0003-1688-7948': 3, '0000-0001-9530-6587': 3, '0000-0002-9863-0144': 3, '0000-0002-9216-9342': 3, '0000-0002-6938-9507': 3, '0000-0001-9107-6120': 3, '0000-0003-4791-7994': 2, '0000-0001-6529-5629': 2, '0000-0001-5623-1148': 2, '0000-0002-5696-156X': 1, '0000-0002-8415-9793': 1, '0000-0002-3221-2820': 1, '0000-0001-6192-853X': 1, '0000-0002-7167-2483': 1, '0000-0002-0173-0545': 1, '0000-0001-8556-3504': 1, '0000-0001-7815-610X': 1, '0000-0002-7775-3268': 1, '0000-0002-3394-1531': 1, '0000-0002-9100-321X': 1, '0000-0001-9900-8528': 1, '0000-0002-8465-0996': 1, '0000-0001-5228-9270': 1, '0000-0001-9355-1319': 1, '0000-0002-2367-5591': 1, '0000-0001-5388-6691': 1, '0000-0002-2516-6774': 1})\n",
      "['0000-0002-0211-9000', '0000-0001-7964-0809', '0000-0003-2420-3147', '0000-0001-9570-3611', '0000-0001-9199-0721', '0000-0002-8066-475X', '0000-0002-8796-0367', '0000-0003-4107-2062', '0000-0002-3355-2448', '0000-0001-6590-7736', '0000-0002-6567-9144', '0000-0001-5836-4120', '0000-0002-7959-7377', '0000-0003-4623-1878', '0000-0003-1625-3400', '0000-0002-7752-6217', '0000-0003-4414-3372', '0000-0001-6507-5503', '0000-0003-0477-2908', '0000-0002-6107-5095', '0000-0003-1708-8734', '0000-0002-1483-5135', '0000-0002-9887-5555', '0000-0002-5051-4929', '0000-0002-9634-8778', '0000-0002-7528-7494', '0000-0001-8238-1641']\n",
      "Total sample size after apply threshold:  729\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(729, 2302)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "729\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.21      0.99      0.35        91\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       1.00      0.30      0.47        23\n",
      "          3       1.00      0.12      0.21        25\n",
      "          4       0.86      0.24      0.38        25\n",
      "          5       0.00      0.00      0.00        19\n",
      "          6       0.71      0.33      0.45        30\n",
      "          7       0.00      0.00      0.00        11\n",
      "          8       0.00      0.00      0.00        11\n",
      "          9       1.00      0.80      0.89        15\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       1.00      0.58      0.73        31\n",
      "         12       1.00      0.62      0.77        24\n",
      "         13       1.00      0.12      0.21        26\n",
      "         14       1.00      0.33      0.50        18\n",
      "         15       0.93      0.47      0.62        30\n",
      "         16       0.00      0.00      0.00        10\n",
      "         17       0.00      0.00      0.00        13\n",
      "         18       0.95      0.87      0.91        62\n",
      "         19       1.00      0.04      0.07        27\n",
      "         20       0.60      0.11      0.18        28\n",
      "         21       1.00      0.24      0.38        17\n",
      "         22       0.77      0.26      0.38        39\n",
      "         23       0.97      0.84      0.90        44\n",
      "         24       0.00      0.00      0.00        15\n",
      "         25       0.46      0.75      0.57        44\n",
      "         26       1.00      0.56      0.71        27\n",
      "\n",
      "avg / total       0.67      0.47      0.45       729\n",
      "\n",
      "[90  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0\n",
      "  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 15  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  1  0 13  0  0  3  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  1  0  0  0  0  7  0 12  0  0  0  6  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0 19  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0\n",
      " 10  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  5  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0\n",
      "  7  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  1  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  1\n",
      "  0  0  0  0  1  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  1  0 12  0  0  0  0  0  0  0  0  0  0 18  0  0  0\n",
      "  1  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0\n",
      " 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  1  0  8  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  1  0  0  3  0 16  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0\n",
      "  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
      "  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 54  0  0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  1  0  0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  3  0  0  0  0  8  0 13  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0 26  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  3  0  7  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 37  0  0  0\n",
      " 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1\n",
      "  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  1  0  0 33  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 15]\n",
      "MNB Accuracy:  0.46776406035665297\n",
      "MNB F1:  0.3591956548368897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.98      0.67        91\n",
      "          1       0.86      0.43      0.57        14\n",
      "          2       0.92      0.48      0.63        23\n",
      "          3       0.74      0.56      0.64        25\n",
      "          4       0.72      0.72      0.72        25\n",
      "          5       0.65      0.58      0.61        19\n",
      "          6       0.97      0.93      0.95        30\n",
      "          7       0.67      0.18      0.29        11\n",
      "          8       0.91      0.91      0.91        11\n",
      "          9       1.00      0.93      0.97        15\n",
      "         10       1.00      1.00      1.00        10\n",
      "         11       0.96      0.81      0.88        31\n",
      "         12       1.00      0.92      0.96        24\n",
      "         13       1.00      0.77      0.87        26\n",
      "         14       0.86      0.67      0.75        18\n",
      "         15       0.68      0.70      0.69        30\n",
      "         16       1.00      0.80      0.89        10\n",
      "         17       1.00      0.46      0.63        13\n",
      "         18       0.98      0.87      0.92        62\n",
      "         19       0.81      0.48      0.60        27\n",
      "         20       0.63      0.61      0.62        28\n",
      "         21       0.94      0.88      0.91        17\n",
      "         22       0.63      0.74      0.68        39\n",
      "         23       0.95      0.89      0.92        44\n",
      "         24       0.67      0.27      0.38        15\n",
      "         25       0.65      0.73      0.69        44\n",
      "         26       0.96      0.85      0.90        27\n",
      "\n",
      "avg / total       0.80      0.76      0.76       729\n",
      "\n",
      "[89  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  1  6  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1\n",
      "  0  3  1  0  1  0  9  0 11  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0  0  1  0  0  1  0  4  0  0 14  1  0  0  0  0  0  0  0  0  0  0\n",
      "  1  0  0  0  0  2  0  0  0  0  3  0  1  0  0  2 18  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  6  0  0  0  0 11  0  0  0\n",
      "  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      " 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  2  0  0\n",
      "  1  2  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  2  0\n",
      "  1  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0 25  0  0  0\n",
      "  0  0  0  1  0  0  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
      " 22  0  0  0  0  0  0  0  0  0  1  0  0  0  0  4  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  2  0  3  0  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0 12  0  0  0  0  1  0  0  1  0  0  0  0  5  1  1\n",
      "  0  0  1  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  1  0  0  0  0  0\n",
      "  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0\n",
      "  0  0  0  3  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  6  0  0  0\n",
      "  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 54  0  0  0  2  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "  3  0  0  0 13  1  0  1  0  1  0  1  6  0  0  0  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  1 17  0  0  0  0  3  0  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 15  1  0  0  0  0  5  0  0  0  1  0\n",
      "  0  0  1  0  0  0  0  0  0  1  0  0  0  0  0  0 29  0  0  2  0  3  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 39  1  0  0\n",
      "  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  0  0  1  1\n",
      "  4  0  0  3  0  0  2  2  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  3\n",
      "  0  1  0  0 32  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0  0  0  0  0  0 23]\n",
      "svc Accuracy:  0.7585733882030178\n",
      "svc F1:  0.7494252238955292\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.99      0.56        91\n",
      "          1       1.00      0.14      0.25        14\n",
      "          2       1.00      0.48      0.65        23\n",
      "          3       0.88      0.56      0.68        25\n",
      "          4       0.68      0.60      0.64        25\n",
      "          5       1.00      0.32      0.48        19\n",
      "          6       0.77      0.77      0.77        30\n",
      "          7       0.00      0.00      0.00        11\n",
      "          8       1.00      0.91      0.95        11\n",
      "          9       1.00      0.93      0.97        15\n",
      "         10       1.00      1.00      1.00        10\n",
      "         11       1.00      0.74      0.85        31\n",
      "         12       0.95      0.88      0.91        24\n",
      "         13       1.00      0.62      0.76        26\n",
      "         14       0.91      0.56      0.69        18\n",
      "         15       0.66      0.70      0.68        30\n",
      "         16       1.00      0.60      0.75        10\n",
      "         17       1.00      0.08      0.14        13\n",
      "         18       0.96      0.87      0.92        62\n",
      "         19       1.00      0.33      0.50        27\n",
      "         20       0.62      0.46      0.53        28\n",
      "         21       0.93      0.76      0.84        17\n",
      "         22       0.64      0.64      0.64        39\n",
      "         23       0.95      0.91      0.93        44\n",
      "         24       1.00      0.13      0.24        15\n",
      "         25       0.57      0.80      0.67        44\n",
      "         26       0.83      0.74      0.78        27\n",
      "\n",
      "avg / total       0.79      0.69      0.68       729\n",
      "\n",
      "[90  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  4  2  0  0  0  0  2  0  0  0  0  0  0  0  0  1  0  0  0  0  1\n",
      "  0  2  0  0  2  0 10  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  1  0  0  1  0  7  0  0 14  2  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  2  0  2  0  0  1 15  0  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  1  0  1  0  0  4  0 11  0  0  0  0  6  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  5  0  0  0  0  0\n",
      " 23  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  4  0  0\n",
      "  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  4  0\n",
      "  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0 23  0  0  0\n",
      "  1  0  0  1  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0\n",
      " 21  0  0  0  0  0  0  0  0  0  1  0  0  0  0  7  0  0  0  0  0  0  0  0\n",
      "  0  0  0  1 16  0  0  0  0  0  0  0  0  0  0  0  2  0  6  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  1  0  0  1  0  7  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  1  0  0  0  0  1\n",
      "  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  6  0  0  0  0  0  0  0\n",
      "  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      " 54  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "  3  0  0  0  9  1  0  0  1  0  0  1  8  0  0  0  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 13  0  0  0  0  5  1  3  0  0  0  0  0  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  7  0  0  0  1  0\n",
      "  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 25  0  0  3  1  3  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 40  0  0  0\n",
      "  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  2  1\n",
      "  2  1  0  2  0  0  0  2  0  1  0  0  0  0  0  0  0  0  1  0  0  0  0  2\n",
      "  0  1  0  0 35  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "  0  0  1  0  1  0  0  0 20]\n",
      "LR Accuracy:  0.691358024691358\n",
      "LR F1:  0.658303296898768\n",
      "For name:  a_tan\n",
      "total sample size before apply threshold:  200\n",
      "Counter({'0000-0003-2955-8369': 97, '0000-0002-9158-7243': 60, '0000-0001-5313-8650': 18, '0000-0002-9225-0247': 18, '0000-0002-8484-7107': 3, '0000-0003-2902-4025': 3, '0000-0001-6459-6171': 1})\n",
      "['0000-0002-9158-7243', '0000-0001-5313-8650', '0000-0003-2955-8369', '0000-0002-9225-0247']\n",
      "Total sample size after apply threshold:  193\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(193, 644)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "193\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        60\n",
      "          1       1.00      0.11      0.20        18\n",
      "          2       0.81      0.99      0.89        97\n",
      "          3       1.00      0.61      0.76        18\n",
      "\n",
      "avg / total       0.90      0.88      0.84       193\n",
      "\n",
      "[60  0  0  0  1  2 15  0  1  0 96  0  0  0  7 11]\n",
      "MNB Accuracy:  0.8756476683937824\n",
      "MNB F1:  0.7088126257115438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97        60\n",
      "          1       1.00      0.72      0.84        18\n",
      "          2       0.91      1.00      0.95        97\n",
      "          3       1.00      0.94      0.97        18\n",
      "\n",
      "avg / total       0.95      0.95      0.95       193\n",
      "\n",
      "[56  0  4  0  0 13  5  0  0  0 97  0  0  0  1 17]\n",
      "svc Accuracy:  0.9481865284974094\n",
      "svc F1:  0.9316589705960248\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        60\n",
      "          1       0.00      0.00      0.00        18\n",
      "          2       0.76      1.00      0.86        97\n",
      "          3       1.00      0.61      0.76        18\n",
      "\n",
      "avg / total       0.79      0.84      0.80       193\n",
      "\n",
      "[54  0  6  0  0  0 18  0  0  0 97  0  0  0  7 11]\n",
      "LR Accuracy:  0.8393782383419689\n",
      "LR F1:  0.6420528332325066\n",
      "For name:  m_aguilar\n",
      "total sample size before apply threshold:  108\n",
      "Counter({'0000-0002-1935-6619': 59, '0000-0001-7395-5754': 18, '0000-0002-2586-859X': 14, '0000-0002-8084-6991': 8, '0000-0002-5150-1871': 8, '0000-0002-9953-7400': 1})\n",
      "['0000-0002-1935-6619', '0000-0001-7395-5754', '0000-0002-2586-859X']\n",
      "Total sample size after apply threshold:  91\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(91, 171)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "91\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        59\n",
      "          1       1.00      0.78      0.88        18\n",
      "          2       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.95      0.95      0.94        91\n",
      "\n",
      "[59  0  0  4 14  0  1  0 13]\n",
      "MNB Accuracy:  0.945054945054945\n",
      "MNB F1:  0.9324375188196328\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        59\n",
      "          1       1.00      1.00      1.00        18\n",
      "          2       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.99      0.99      0.99        91\n",
      "\n",
      "[59  0  0  0 18  0  1  0 13]\n",
      "svc Accuracy:  0.989010989010989\n",
      "svc F1:  0.984853200539475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91        59\n",
      "          1       1.00      0.50      0.67        18\n",
      "          2       1.00      0.86      0.92        14\n",
      "\n",
      "avg / total       0.90      0.88      0.87        91\n",
      "\n",
      "[59  0  0  9  9  0  2  0 12]\n",
      "LR Accuracy:  0.8791208791208791\n",
      "LR F1:  0.8348240906380441\n",
      "For name:  a_bianchi\n",
      "total sample size before apply threshold:  73\n",
      "Counter({'0000-0002-1082-3911': 38, '0000-0001-6583-1671': 23, '0000-0001-9340-6971': 8, '0000-0002-4571-0511': 2, '0000-0003-4925-5269': 2})\n",
      "['0000-0001-6583-1671', '0000-0002-1082-3911']\n",
      "Total sample size after apply threshold:  61\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 142)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        23\n",
      "          1       0.97      0.97      0.97        38\n",
      "\n",
      "avg / total       0.97      0.97      0.97        61\n",
      "\n",
      "[22  1  1 37]\n",
      "MNB Accuracy:  0.9672131147540983\n",
      "MNB F1:  0.9651029748283753\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        23\n",
      "          1       0.95      1.00      0.97        38\n",
      "\n",
      "avg / total       0.97      0.97      0.97        61\n",
      "\n",
      "[21  2  0 38]\n",
      "svc Accuracy:  0.9672131147540983\n",
      "svc F1:  0.9644522144522144\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.90        23\n",
      "          1       0.90      1.00      0.95        38\n",
      "\n",
      "avg / total       0.94      0.93      0.93        61\n",
      "\n",
      "[19  4  0 38]\n",
      "LR Accuracy:  0.9344262295081968\n",
      "LR F1:  0.9273809523809524\n",
      "For name:  p_rossi\n",
      "total sample size before apply threshold:  200\n",
      "Counter({'0000-0003-2620-7918': 116, '0000-0003-4796-327X': 39, '0000-0002-6316-338X': 36, '0000-0002-3995-8836': 8, '0000-0002-6472-3588': 1})\n",
      "['0000-0002-6316-338X', '0000-0003-2620-7918', '0000-0003-4796-327X']\n",
      "Total sample size after apply threshold:  191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 732)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        36\n",
      "          1       0.93      1.00      0.96       116\n",
      "          2       1.00      0.85      0.92        39\n",
      "\n",
      "avg / total       0.96      0.95      0.95       191\n",
      "\n",
      "[ 33   3   0   0 116   0   0   6  33]\n",
      "MNB Accuracy:  0.9528795811518325\n",
      "MNB F1:  0.9452813358189509\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        36\n",
      "          1       0.95      1.00      0.97       116\n",
      "          2       1.00      0.87      0.93        39\n",
      "\n",
      "avg / total       0.97      0.97      0.97       191\n",
      "\n",
      "[ 35   1   0   0 116   0   0   5  34]\n",
      "svc Accuracy:  0.9685863874345549\n",
      "svc F1:  0.9640707527464004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        36\n",
      "          1       0.82      1.00      0.90       116\n",
      "          2       1.00      0.56      0.72        39\n",
      "\n",
      "avg / total       0.89      0.86      0.85       191\n",
      "\n",
      "[ 27   9   0   0 116   0   0  17  22]\n",
      "LR Accuracy:  0.8638743455497382\n",
      "LR F1:  0.8258930462514145\n",
      "For name:  y_yang\n",
      "total sample size before apply threshold:  665\n",
      "Counter({'0000-0002-8633-0873': 115, '0000-0002-6266-9864': 97, '0000-0003-1391-8040': 73, '0000-0001-8839-8161': 50, '0000-0002-6782-2813': 43, '0000-0001-7896-1184': 39, '0000-0002-3598-7218': 35, '0000-0003-4275-0515': 26, '0000-0002-0007-6481': 16, '0000-0003-3711-2842': 12, '0000-0003-0195-9478': 11, '0000-0001-8572-5155': 10, '0000-0001-8971-4648': 8, '0000-0003-2442-3713': 8, '0000-0002-0491-8295': 8, '0000-0002-7540-3301': 8, '0000-0002-2767-9354': 8, '0000-0002-5982-1706': 8, '0000-0001-7139-1254': 6, '0000-0001-6417-3654': 6, '0000-0001-5769-1795': 6, '0000-0003-0298-8641': 5, '0000-0002-5599-0975': 5, '0000-0002-1707-0633': 5, '0000-0003-1536-343X': 4, '0000-0002-8514-8228': 4, '0000-0001-9306-3227': 3, '0000-0002-5033-6210': 3, '0000-0003-3428-1587': 3, '0000-0002-7856-2009': 3, '0000-0002-5808-0109': 3, '0000-0002-8565-6214': 3, '0000-0002-1837-3628': 3, '0000-0002-6976-7416': 2, '0000-0002-3487-8730': 2, '0000-0001-8274-6196': 2, '0000-0002-2222-0202': 2, '0000-0002-7653-0601': 2, '0000-0003-0576-6032': 2, '0000-0003-1599-635X': 2, '0000-0002-6306-1324': 1, '0000-0001-9436-964X': 1, '0000-0001-5796-7990': 1, '0000-0002-3519-5472': 1, '0000-0002-8404-8305': 1, '0000-0002-7982-7988': 1, '0000-0003-2902-3989': 1, '0000-0001-5726-9420': 1, '0000-0002-0100-1078': 1, '0000-0002-1105-3824': 1, '0000-0002-6891-0655': 1, '0000-0002-1080-5086': 1, '0000-0003-4505-8954': 1, '0000-0002-1416-4925': 1})\n",
      "['0000-0001-8572-5155', '0000-0002-0007-6481', '0000-0002-3598-7218', '0000-0002-6782-2813', '0000-0003-0195-9478', '0000-0002-6266-9864', '0000-0001-7896-1184', '0000-0003-3711-2842', '0000-0002-8633-0873', '0000-0003-1391-8040', '0000-0001-8839-8161', '0000-0003-4275-0515']\n",
      "Total sample size after apply threshold:  527\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(527, 417)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "527\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.00      0.00      0.00        16\n",
      "          2       1.00      0.26      0.41        35\n",
      "          3       0.81      0.79      0.80        43\n",
      "          4       1.00      0.18      0.31        11\n",
      "          5       0.64      0.90      0.75        97\n",
      "          6       0.76      0.41      0.53        39\n",
      "          7       0.00      0.00      0.00        12\n",
      "          8       0.59      0.97      0.73       115\n",
      "          9       0.89      0.74      0.81        73\n",
      "         10       0.72      0.76      0.74        50\n",
      "         11       0.94      0.58      0.71        26\n",
      "\n",
      "avg / total       0.69      0.69      0.65       527\n",
      "\n",
      "[  0   0   0   0   0   0   0   0   9   0   0   1   0   0   0   0   0  11\n",
      "   2   0   3   0   0   0   0   0   9   0   0  14   0   0   7   5   0   0\n",
      "   0   0   0  34   0   2   2   0   0   2   3   0   0   0   0   0   2   3\n",
      "   0   0   4   0   2   0   0   0   0   0   0  87   0   0  10   0   0   0\n",
      "   0   0   0   6   0   4  16   0   6   0   7   0   0   0   0   2   0   1\n",
      "   0   0   8   0   1   0   0   0   0   0   0   4   0   0 111   0   0   0\n",
      "   0   0   0   0   0   7   0   0  12  54   0   0   0   0   0   0   0   1\n",
      "   1   0  10   0  38   0   0   0   0   0   0   1   0   0   8   0   2  15]\n",
      "MNB Accuracy:  0.6944971537001897\n",
      "MNB F1:  0.48257581322105264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.91      0.62      0.74        16\n",
      "          2       0.83      0.71      0.77        35\n",
      "          3       0.77      0.79      0.78        43\n",
      "          4       1.00      0.55      0.71        11\n",
      "          5       0.87      0.88      0.87        97\n",
      "          6       0.69      0.62      0.65        39\n",
      "          7       1.00      0.58      0.74        12\n",
      "          8       0.87      0.94      0.90       115\n",
      "          9       0.91      0.88      0.90        73\n",
      "         10       0.65      0.92      0.76        50\n",
      "         11       0.96      0.92      0.94        26\n",
      "\n",
      "avg / total       0.84      0.83      0.83       527\n",
      "\n",
      "[  6   0   1   0   0   0   1   0   1   0   0   1   0  10   0   1   0   1\n",
      "   2   0   0   0   2   0   0   0  25   1   0   6   0   0   1   2   0   0\n",
      "   0   0   0  34   0   0   2   0   0   0   7   0   0   0   0   0   6   1\n",
      "   1   0   0   0   3   0   0   1   1   0   0  85   0   0   7   2   1   0\n",
      "   0   0   0   6   0   1  24   0   0   0   8   0   0   0   0   1   0   0\n",
      "   1   7   0   0   3   0   0   0   1   0   0   3   1   0 108   2   0   0\n",
      "   0   0   2   0   0   1   0   0   6  64   0   0   0   0   0   1   0   0\n",
      "   3   0   0   0  46   0   0   0   0   0   0   0   0   0   1   0   1  24]\n",
      "svc Accuracy:  0.8330170777988615\n",
      "svc F1:  0.7920938598836466\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.60      0.75        10\n",
      "          1       0.88      0.44      0.58        16\n",
      "          2       0.96      0.69      0.80        35\n",
      "          3       0.78      0.84      0.81        43\n",
      "          4       1.00      0.55      0.71        11\n",
      "          5       0.78      0.90      0.84        97\n",
      "          6       0.70      0.49      0.58        39\n",
      "          7       1.00      0.33      0.50        12\n",
      "          8       0.82      0.92      0.87       115\n",
      "          9       0.88      0.78      0.83        73\n",
      "         10       0.61      0.90      0.73        50\n",
      "         11       0.92      0.92      0.92        26\n",
      "\n",
      "avg / total       0.82      0.80      0.79       527\n",
      "\n",
      "[  6   0   0   0   0   0   1   0   1   1   0   1   0   7   0   0   0   4\n",
      "   3   0   0   0   2   0   0   0  24   0   0   6   0   0   1   3   1   0\n",
      "   0   0   0  36   0   1   1   0   0   0   5   0   0   0   0   0   6   1\n",
      "   0   0   1   0   3   0   0   1   1   0   0  87   0   0   5   2   1   0\n",
      "   0   0   0   7   0   0  19   0   3   0   9   1   0   0   0   2   0   0\n",
      "   0   4   0   0   6   0   0   0   0   0   0   5   1   0 106   2   1   0\n",
      "   0   0   0   0   0   7   0   0   9  57   0   0   0   0   0   1   0   0\n",
      "   2   0   2   0  45   0   0   0   0   0   0   0   0   0   1   0   1  24]\n",
      "LR Accuracy:  0.7988614800759013\n",
      "LR F1:  0.7420269398202874\n",
      "For name:  s_hsieh\n",
      "total sample size before apply threshold:  166\n",
      "Counter({'0000-0002-3188-8482': 88, '0000-0002-1879-4086': 65, '0000-0002-2716-4609': 9, '0000-0002-8475-7486': 3, '0000-0001-7617-8559': 1})\n",
      "['0000-0002-3188-8482', '0000-0002-1879-4086']\n",
      "Total sample size after apply threshold:  153\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(153, 137)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "153\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.94      0.94        88\n",
      "          1       0.92      0.91      0.91        65\n",
      "\n",
      "avg / total       0.93      0.93      0.93       153\n",
      "\n",
      "[83  5  6 59]\n",
      "MNB Accuracy:  0.9281045751633987\n",
      "MNB F1:  0.9262908947575877\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95        88\n",
      "          1       0.95      0.91      0.93        65\n",
      "\n",
      "avg / total       0.94      0.94      0.94       153\n",
      "\n",
      "[85  3  6 59]\n",
      "svc Accuracy:  0.9411764705882353\n",
      "svc F1:  0.9394272643293891\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.94        88\n",
      "          1       0.98      0.83      0.90        65\n",
      "\n",
      "avg / total       0.93      0.92      0.92       153\n",
      "\n",
      "[87  1 11 54]\n",
      "LR Accuracy:  0.9215686274509803\n",
      "LR F1:  0.917741935483871\n",
      "For name:  c_baptista\n",
      "total sample size before apply threshold:  19\n",
      "Counter({'0000-0002-1263-7880': 7, '0000-0002-8158-4743': 7, '0000-0003-4664-6766': 2, '0000-0002-7807-0995': 2, '0000-0002-9966-0708': 1})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  d_kavanagh\n",
      "total sample size before apply threshold:  178\n",
      "Counter({'0000-0001-9072-8828': 113, '0000-0003-4718-0072': 58, '0000-0003-1531-6617': 4, '0000-0003-2854-7270': 3})\n",
      "['0000-0003-4718-0072', '0000-0001-9072-8828']\n",
      "Total sample size after apply threshold:  171\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(171, 448)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "171\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.92        58\n",
      "          1       0.93      1.00      0.96       113\n",
      "\n",
      "avg / total       0.95      0.95      0.95       171\n",
      "\n",
      "[ 49   9   0 113]\n",
      "MNB Accuracy:  0.9473684210526315\n",
      "MNB F1:  0.9387949890634322\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93        58\n",
      "          1       0.93      1.00      0.97       113\n",
      "\n",
      "avg / total       0.96      0.95      0.95       171\n",
      "\n",
      "[ 50   8   0 113]\n",
      "svc Accuracy:  0.9532163742690059\n",
      "svc F1:  0.9458689458689459\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        58\n",
      "          1       0.82      1.00      0.90       113\n",
      "\n",
      "avg / total       0.88      0.85      0.84       171\n",
      "\n",
      "[ 33  25   0 113]\n",
      "LR Accuracy:  0.8538011695906432\n",
      "LR F1:  0.8128365658246136\n",
      "For name:  l_wang\n",
      "total sample size before apply threshold:  828\n",
      "Counter({'0000-0001-9783-4383': 98, '0000-0003-3870-3388': 64, '0000-0002-5947-306X': 63, '0000-0002-5773-1627': 56, '0000-0002-5859-2526': 53, '0000-0002-5126-1046': 48, '0000-0002-4344-8791': 40, '0000-0001-8927-6772': 31, '0000-0001-5813-9505': 31, '0000-0002-1709-9401': 30, '0000-0003-3463-0740': 27, '0000-0003-1382-9195': 25, '0000-0003-3075-6872': 22, '0000-0001-9556-2361': 19, '0000-0002-4809-3109': 17, '0000-0002-1919-9107': 17, '0000-0002-4747-0419': 17, '0000-0002-6156-9028': 16, '0000-0001-7302-4714': 15, '0000-0001-7124-2718': 14, '0000-0001-8412-2985': 9, '0000-0002-8208-7079': 7, '0000-0003-4276-0051': 7, '0000-0002-4165-4022': 6, '0000-0002-7300-9271': 6, '0000-0002-0933-2808': 5, '0000-0001-9355-1167': 5, '0000-0002-4930-8618': 5, '0000-0001-7383-934X': 5, '0000-0001-7324-2682': 5, '0000-0003-1117-1326': 5, '0000-0002-7579-0233': 5, '0000-0002-2753-0947': 4, '0000-0002-1869-9871': 4, '0000-0002-0543-5519': 4, '0000-0002-5371-2138': 4, '0000-0001-5601-7539': 3, '0000-0003-0881-9689': 3, '0000-0001-6223-5962': 3, '0000-0003-0968-1247': 3, '0000-0001-8752-6635': 3, '0000-0001-8905-3456': 2, '0000-0001-6222-7807': 2, '0000-0002-1835-7601': 2, '0000-0001-5038-694X': 2, '0000-0002-2448-8149': 2, '0000-0001-8573-1213': 2, '0000-0003-2746-8992': 1, '0000-0001-7309-4325': 1, '0000-0002-8151-5182': 1, '0000-0002-9062-6183': 1, '0000-0002-5678-2369': 1, '0000-0001-5646-9746': 1, '0000-0001-7587-8924': 1, '0000-0002-0350-8534': 1, '0000-0002-8673-5221': 1, '0000-0003-2766-0845': 1, '0000-0002-5534-5466': 1, '0000-0002-9760-7436': 1})\n",
      "['0000-0002-6156-9028', '0000-0003-3463-0740', '0000-0001-9556-2361', '0000-0001-7302-4714', '0000-0002-4809-3109', '0000-0003-3075-6872', '0000-0002-1919-9107', '0000-0002-4344-8791', '0000-0002-5859-2526', '0000-0003-3870-3388', '0000-0003-1382-9195', '0000-0001-8927-6772', '0000-0002-5773-1627', '0000-0001-9783-4383', '0000-0002-4747-0419', '0000-0001-7124-2718', '0000-0002-1709-9401', '0000-0002-5947-306X', '0000-0001-5813-9505', '0000-0002-5126-1046']\n",
      "Total sample size after apply threshold:  703\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(703, 985)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.48        16\n",
      "          1       0.00      0.00      0.00        27\n",
      "          2       0.00      0.00      0.00        19\n",
      "          3       0.00      0.00      0.00        15\n",
      "          4       1.00      0.71      0.83        17\n",
      "          5       1.00      0.59      0.74        22\n",
      "          6       1.00      0.35      0.52        17\n",
      "          7       0.56      0.12      0.20        40\n",
      "          8       1.00      0.74      0.85        53\n",
      "          9       0.97      0.94      0.95        64\n",
      "         10       1.00      0.20      0.33        25\n",
      "         11       0.96      0.77      0.86        31\n",
      "         12       0.59      0.96      0.73        56\n",
      "         13       0.36      0.95      0.52        98\n",
      "         14       0.00      0.00      0.00        17\n",
      "         15       0.00      0.00      0.00        14\n",
      "         16       1.00      0.23      0.38        30\n",
      "         17       0.59      0.89      0.71        63\n",
      "         18       1.00      0.45      0.62        31\n",
      "         19       0.68      0.90      0.77        48\n",
      "\n",
      "avg / total       0.66      0.62      0.57       703\n",
      "\n",
      "[ 5  0  0  0  0  0  0  0  0  0  0  1  0  6  0  0  0  4  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0 17  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  5  2  0  0  0  3  0  5  0  0  0  0 12  0  0  0  0  0  0  0  0  2  0  0\n",
      "  0  1  0  2  0  0  0  0  0 13  0  0  0  0  0  0  4  1  0  0  0  0  0  4\n",
      "  0  0  0  0  0  0  6  0  0  0  0  0  1 10  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  5  0  2  0  0  3 18  0  0  0 12  0  0  0  0  0  0  0  0  0  0\n",
      " 39  0  0  0  1 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0\n",
      "  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  5  0  0  8  0  0\n",
      "  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0 24  0  6  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 54  0  0  0  0  0  0  2  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  4 93  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0 16  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0 11  0  0  0  1  0  2  0  0  0  0  0  0  0  0  0  0  0  0 12  3  0  0\n",
      "  7  4  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0  0 56  0  0\n",
      "  0  0  0  0  0  0  0  1  0  0  0  0  3 13  0  0  0  0 14  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  4  0  0  0  0  1  0 43]\n",
      "MNB Accuracy:  0.620199146514936\n",
      "MNB F1:  0.4753005746618788\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.44      0.61        16\n",
      "          1       0.67      0.59      0.63        27\n",
      "          2       1.00      0.16      0.27        19\n",
      "          3       0.73      0.53      0.62        15\n",
      "          4       1.00      0.94      0.97        17\n",
      "          5       0.89      0.73      0.80        22\n",
      "          6       1.00      0.82      0.90        17\n",
      "          7       0.46      0.65      0.54        40\n",
      "          8       0.86      0.79      0.82        53\n",
      "          9       0.97      0.94      0.95        64\n",
      "         10       0.84      0.64      0.73        25\n",
      "         11       0.93      0.81      0.86        31\n",
      "         12       0.95      0.95      0.95        56\n",
      "         13       0.54      0.93      0.69        98\n",
      "         14       1.00      0.71      0.83        17\n",
      "         15       1.00      0.07      0.13        14\n",
      "         16       0.59      0.63      0.61        30\n",
      "         17       0.88      0.81      0.84        63\n",
      "         18       0.93      0.81      0.86        31\n",
      "         19       0.93      0.85      0.89        48\n",
      "\n",
      "avg / total       0.82      0.77      0.77       703\n",
      "\n",
      "[ 7  0  0  0  0  0  0  3  0  0  0  0  0  5  0  0  0  1  0  0  0 16  0  0\n",
      "  0  0  0  0  1  0  0  0  0 10  0  0  0  0  0  0  0  1  3  0  0  0  0  4\n",
      "  0  0  1  0  0 10  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0\n",
      "  0  1  0  0  5  1  0  0  0  0  0  1 16  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  1  0  0  4  0  0  1\n",
      "  0  1  0  0  0  0 14  0  0  0  0  0  0  2  0  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0 26  1  2  0  0  0  6  0  0  0  3  1  0  0  2  0  0  0  0  0  0\n",
      " 42  0  0  0  0  8  0  0  1  0  0  0  0  0  0  0  0  0  0  1  1 60  0  0\n",
      "  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0 16  0  0  2  0  0\n",
      "  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0 25  0  4  0  0  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  1 53  1  0  0  1  0  0  0  0  2  0  0\n",
      "  0  0  0  3  1  0  1  0  0 91  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  4 12  0  0  1  0  0  0  0  0  0  0  0  0  4  1  0  0  1\n",
      "  0  7  0  1  0  0  0  0  0  0  0  1  0  1  0  1  1  0  0  0  2  2  0  0\n",
      " 19  1  0  2  0  0  0  0  0  0  0  5  1  0  1  0  0  4  0  0  1 51  0  0\n",
      "  0  0  0  0  0  0  0  1  0  0  0  0  0  5  0  0  0  0 25  0  0  1  0  1\n",
      "  0  1  0  1  0  0  0  0  1  2  0  0  0  0  0 41]\n",
      "svc Accuracy:  0.7709815078236131\n",
      "svc F1:  0.7253746165339414\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        16\n",
      "          1       0.42      0.19      0.26        27\n",
      "          2       0.00      0.00      0.00        19\n",
      "          3       1.00      0.33      0.50        15\n",
      "          4       1.00      0.94      0.97        17\n",
      "          5       0.94      0.73      0.82        22\n",
      "          6       1.00      0.65      0.79        17\n",
      "          7       0.48      0.35      0.41        40\n",
      "          8       0.93      0.74      0.82        53\n",
      "          9       0.98      0.92      0.95        64\n",
      "         10       0.69      0.72      0.71        25\n",
      "         11       0.84      0.84      0.84        31\n",
      "         12       0.83      0.96      0.89        56\n",
      "         13       0.44      0.97      0.61        98\n",
      "         14       1.00      0.35      0.52        17\n",
      "         15       0.00      0.00      0.00        14\n",
      "         16       0.71      0.50      0.59        30\n",
      "         17       0.76      0.81      0.78        63\n",
      "         18       0.92      0.77      0.84        31\n",
      "         19       0.84      0.88      0.86        48\n",
      "\n",
      "avg / total       0.74      0.71      0.69       703\n",
      "\n",
      "[ 4  1  0  0  0  0  0  1  0  0  0  3  0  7  0  0  0  0  0  0  0  5  0  0\n",
      "  0  0  0  0  1  0  0  0  0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  4\n",
      "  0  0  1  0  0 14  0  0  0  0  0  0  0  0  0  5  0  1  0  0  0  0  0  0\n",
      "  0  1  0  0  2  4  0  2  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  1  0  0  0  0  0  0  0 16  0  0  0  0  0  0  2  1  0  0  2  0  0  1\n",
      "  0  1  0  0  0  0 11  0  0  0  0  0  0  4  0  0  0  1  0  0  0  1  0  0\n",
      "  0  0  0 14  0  1  4  0  1 15  0  0  1  2  1  0  0  2  0  0  0  0  0  0\n",
      " 39  0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 59  0  0\n",
      "  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0 18  0  0  2  0  0\n",
      "  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0 26  0  5  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  1 54  0  0  0  1  0  0  0  0  1  0  0\n",
      "  0  0  0  1  0  0  0  0  0 95  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0 10  6  0  0  1  0  0  0  0  0  0  0  0  0  1  1  0  0  1\n",
      "  0 10  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  3  0  0\n",
      " 15  3  0  5  0  0  0  0  0  0  0  3  0  0  3  0  0  6  0  0  0 51  0  0\n",
      "  0  0  0  0  0  0  0  1  0  0  0  0  1  5  0  0  0  0 24  0  0  1  0  0\n",
      "  0  0  0  0  0  0  0  0  2  1  0  0  0  2  0 42]\n",
      "LR Accuracy:  0.7112375533428165\n",
      "LR F1:  0.6274408832941072\n",
      "For name:  m_pinho\n",
      "total sample size before apply threshold:  97\n",
      "Counter({'0000-0002-7132-8842': 42, '0000-0001-8173-0379': 26, '0000-0002-4645-1638': 13, '0000-0002-4298-0014': 6, '0000-0003-4502-667X': 4, '0000-0003-3142-4351': 4, '0000-0002-8045-2546': 1, '0000-0002-7993-5161': 1})\n",
      "['0000-0001-8173-0379', '0000-0002-4645-1638', '0000-0002-7132-8842']\n",
      "Total sample size after apply threshold:  81\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 266)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        26\n",
      "          1       1.00      0.15      0.27        13\n",
      "          2       0.77      0.98      0.86        42\n",
      "\n",
      "avg / total       0.87      0.84      0.80        81\n",
      "\n",
      "[25  0  1  0  2 11  1  0 41]\n",
      "MNB Accuracy:  0.8395061728395061\n",
      "MNB F1:  0.6971210076473234\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        26\n",
      "          1       1.00      0.46      0.63        13\n",
      "          2       0.82      1.00      0.90        42\n",
      "\n",
      "avg / total       0.91      0.89      0.88        81\n",
      "\n",
      "[24  0  2  0  6  7  0  0 42]\n",
      "svc Accuracy:  0.8888888888888888\n",
      "svc F1:  0.8316015846066781\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94        26\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.72      1.00      0.84        42\n",
      "\n",
      "avg / total       0.70      0.80      0.74        81\n",
      "\n",
      "[23  0  3  0  0 13  0  0 42]\n",
      "LR Accuracy:  0.8024691358024691\n",
      "LR F1:  0.5929251700680273\n",
      "For name:  m_bergman\n",
      "total sample size before apply threshold:  36\n",
      "Counter({'0000-0003-2589-2976': 20, '0000-0002-4529-4925': 13, '0000-0002-7033-5362': 2, '0000-0002-7018-1578': 1})\n",
      "['0000-0002-4529-4925', '0000-0003-2589-2976']\n",
      "Total sample size after apply threshold:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(33, 60)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        13\n",
      "          1       0.91      1.00      0.95        20\n",
      "\n",
      "avg / total       0.94      0.94      0.94        33\n",
      "\n",
      "[11  2  0 20]\n",
      "MNB Accuracy:  0.9393939393939394\n",
      "MNB F1:  0.9345238095238095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82        13\n",
      "          1       0.83      1.00      0.91        20\n",
      "\n",
      "avg / total       0.90      0.88      0.87        33\n",
      "\n",
      "[ 9  4  0 20]\n",
      "svc Accuracy:  0.8787878787878788\n",
      "svc F1:  0.8636363636363635\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70        13\n",
      "          1       0.77      1.00      0.87        20\n",
      "\n",
      "avg / total       0.86      0.82      0.80        33\n",
      "\n",
      "[ 7  6  0 20]\n",
      "LR Accuracy:  0.8181818181818182\n",
      "LR F1:  0.7847826086956522\n",
      "For name:  j_castro\n",
      "total sample size before apply threshold:  39\n",
      "Counter({'0000-0001-6169-3822': 15, '0000-0002-0382-553X': 10, '0000-0001-8984-475X': 7, '0000-0003-0794-3178': 3, '0000-0002-1939-7859': 2, '0000-0002-7468-5220': 1, '0000-0003-0868-1894': 1})\n",
      "['0000-0001-6169-3822', '0000-0002-0382-553X']\n",
      "Total sample size after apply threshold:  25\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(25, 53)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        25\n",
      "\n",
      "[15  0  0 10]\n",
      "MNB Accuracy:  1.0\n",
      "MNB F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        25\n",
      "\n",
      "[15  0  0 10]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        15\n",
      "          1       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.96      0.96      0.96        25\n",
      "\n",
      "[15  0  1  9]\n",
      "LR Accuracy:  0.96\n",
      "LR F1:  0.9575551782682513\n",
      "For name:  n_hall\n",
      "total sample size before apply threshold:  115\n",
      "Counter({'0000-0003-2808-0009': 102, '0000-0003-0100-0291': 5, '0000-0003-1503-5989': 4, '0000-0001-7465-5470': 2, '0000-0001-7082-1523': 1, '0000-0002-0216-512X': 1})\n",
      "['0000-0003-2808-0009']\n",
      "Total sample size after apply threshold:  102\n",
      "For name:  d_schneider\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-2124-8385': 40, '0000-0001-9659-6731': 33, '0000-0002-2867-2613': 12, '0000-0002-0163-6137': 5, '0000-0002-5276-3304': 3})\n",
      "['0000-0002-2867-2613', '0000-0001-9659-6731', '0000-0002-2124-8385']\n",
      "Total sample size after apply threshold:  85\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(85, 311)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       0.94      0.94      0.94        33\n",
      "          2       0.88      0.95      0.92        40\n",
      "\n",
      "avg / total       0.92      0.92      0.92        85\n",
      "\n",
      "[ 9  0  3  0 31  2  0  2 38]\n",
      "MNB Accuracy:  0.9176470588235294\n",
      "MNB F1:  0.9040664823797354\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       0.97      0.91      0.94        33\n",
      "          2       0.87      0.97      0.92        40\n",
      "\n",
      "avg / total       0.92      0.92      0.92        85\n",
      "\n",
      "[ 9  0  3  0 30  3  0  1 39]\n",
      "svc Accuracy:  0.9176470588235294\n",
      "svc F1:  0.9040966386554622\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        12\n",
      "          1       1.00      0.85      0.92        33\n",
      "          2       0.82      1.00      0.90        40\n",
      "\n",
      "avg / total       0.91      0.89      0.89        85\n",
      "\n",
      "[ 8  0  4  0 28  5  0  0 40]\n",
      "LR Accuracy:  0.8941176470588236\n",
      "LR F1:  0.8723030637932093\n",
      "For name:  n_kumar\n",
      "total sample size before apply threshold:  156\n",
      "Counter({'0000-0002-9876-2884': 25, '0000-0002-4197-5133': 24, '0000-0003-4665-9401': 22, '0000-0003-0898-908X': 15, '0000-0001-6275-8501': 12, '0000-0003-0170-888X': 11, '0000-0003-4504-4704': 7, '0000-0003-2805-779X': 7, '0000-0002-1546-1921': 5, '0000-0003-4445-877X': 4, '0000-0003-2380-9489': 4, '0000-0001-7364-6601': 4, '0000-0002-1064-1659': 3, '0000-0003-3531-7414': 3, '0000-0002-7123-2111': 2, '0000-0003-3709-0823': 2, '0000-0002-6064-4161': 1, '0000-0002-2009-3158': 1, '0000-0002-3020-3947': 1, '0000-0002-6871-1840': 1, '0000-0001-5932-8500': 1, '0000-0002-2427-647X': 1})\n",
      "['0000-0002-4197-5133', '0000-0003-0898-908X', '0000-0001-6275-8501', '0000-0003-4665-9401', '0000-0003-0170-888X', '0000-0002-9876-2884']\n",
      "Total sample size after apply threshold:  109\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 181)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "109\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        24\n",
      "          1       0.86      0.40      0.55        15\n",
      "          2       0.91      0.83      0.87        12\n",
      "          3       0.88      1.00      0.94        22\n",
      "          4       1.00      0.91      0.95        11\n",
      "          5       0.83      1.00      0.91        25\n",
      "\n",
      "avg / total       0.89      0.89      0.88       109\n",
      "\n",
      "[24  0  0  0  0  0  2  6  1  2  0  4  0  1 10  1  0  0  0  0  0 22  0  0\n",
      "  0  0  0  0 10  1  0  0  0  0  0 25]\n",
      "MNB Accuracy:  0.8899082568807339\n",
      "MNB F1:  0.8621103061806115\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        24\n",
      "          1       0.65      0.87      0.74        15\n",
      "          2       0.92      0.92      0.92        12\n",
      "          3       1.00      0.95      0.98        22\n",
      "          4       1.00      0.91      0.95        11\n",
      "          5       0.92      0.88      0.90        25\n",
      "\n",
      "avg / total       0.92      0.91      0.91       109\n",
      "\n",
      "[22  2  0  0  0  0  0 13  1  0  0  1  0  1 11  0  0  0  0  1  0 21  0  0\n",
      "  0  0  0  0 10  1  0  3  0  0  0 22]\n",
      "svc Accuracy:  0.908256880733945\n",
      "svc F1:  0.9071883117925297\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        24\n",
      "          1       0.89      0.53      0.67        15\n",
      "          2       0.92      0.92      0.92        12\n",
      "          3       0.96      1.00      0.98        22\n",
      "          4       1.00      0.91      0.95        11\n",
      "          5       0.85      0.92      0.88        25\n",
      "\n",
      "avg / total       0.90      0.90      0.89       109\n",
      "\n",
      "[24  0  0  0  0  0  2  8  1  1  0  3  0  1 11  0  0  0  0  0  0 22  0  0\n",
      "  0  0  0  0 10  1  2  0  0  0  0 23]\n",
      "LR Accuracy:  0.8990825688073395\n",
      "LR F1:  0.8868640618640619\n",
      "For name:  i_martins\n",
      "total sample size before apply threshold:  54\n",
      "Counter({'0000-0002-9284-8599': 12, '0000-0002-0136-1671': 11, '0000-0002-8521-2613': 8, '0000-0002-5362-9801': 7, '0000-0001-6797-2558': 7, '0000-0002-3412-9377': 6, '0000-0003-0897-8807': 1, '0000-0003-4328-7286': 1, '0000-0003-3291-0079': 1})\n",
      "['0000-0002-0136-1671', '0000-0002-9284-8599']\n",
      "Total sample size after apply threshold:  23\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(23, 118)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        23\n",
      "\n",
      "[10  1  0 12]\n",
      "MNB Accuracy:  0.9565217391304348\n",
      "MNB F1:  0.9561904761904763\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.86      1.00      0.92        12\n",
      "\n",
      "avg / total       0.93      0.91      0.91        23\n",
      "\n",
      "[ 9  2  0 12]\n",
      "svc Accuracy:  0.9130434782608695\n",
      "svc F1:  0.9115384615384615\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84        11\n",
      "          1       0.80      1.00      0.89        12\n",
      "\n",
      "avg / total       0.90      0.87      0.87        23\n",
      "\n",
      "[ 8  3  0 12]\n",
      "LR Accuracy:  0.8695652173913043\n",
      "LR F1:  0.8654970760233919\n",
      "For name:  j_qiu\n",
      "total sample size before apply threshold:  58\n",
      "Counter({'0000-0002-1541-9627': 41, '0000-0002-7633-6227': 8, '0000-0002-9886-3570': 3, '0000-0001-9220-4219': 2, '0000-0002-1059-627X': 1, '0000-0002-7628-5431': 1, '0000-0002-6155-8548': 1, '0000-0002-1275-4171': 1})\n",
      "['0000-0002-1541-9627']\n",
      "Total sample size after apply threshold:  41\n",
      "For name:  m_antunes\n",
      "total sample size before apply threshold:  27\n",
      "Counter({'0000-0001-5545-2520': 7, '0000-0001-5888-2278': 6, '0000-0002-8913-6136': 6, '0000-0002-1257-2829': 5, '0000-0001-8216-8066': 3})\n",
      "[]\n",
      "Total sample size after apply threshold:  0\n",
      "For name:  m_andersen\n",
      "total sample size before apply threshold:  399\n",
      "Counter({'0000-0002-3894-4811': 222, '0000-0003-4694-486X': 58, '0000-0003-4794-6808': 39, '0000-0001-7029-2860': 21, '0000-0003-1125-1553': 14, '0000-0002-0234-0266': 11, '0000-0001-8275-9472': 11, '0000-0003-4977-3031': 8, '0000-0003-3845-4465': 7, '0000-0002-4833-1867': 3, '0000-0002-4654-3946': 2, '0000-0002-6803-0981': 2, '0000-0002-8164-278X': 1})\n",
      "['0000-0003-1125-1553', '0000-0002-0234-0266', '0000-0003-4794-6808', '0000-0001-7029-2860', '0000-0001-8275-9472', '0000-0003-4694-486X', '0000-0002-3894-4811']\n",
      "Total sample size after apply threshold:  376\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(376, 1019)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.44      0.61        39\n",
      "          3       0.00      0.00      0.00        21\n",
      "          4       0.00      0.00      0.00        11\n",
      "          5       0.90      0.64      0.75        58\n",
      "          6       0.69      1.00      0.82       222\n",
      "\n",
      "avg / total       0.65      0.73      0.66       376\n",
      "\n",
      "[  0   0   0   0   0   0  14   0   0   0   0   0   0  11   0   0  17   0\n",
      "   0   3  19   0   0   0   0   0   0  21   0   0   0   0   0   0  11   0\n",
      "   0   0   0   0  37  21   0   0   0   0   0   1 221]\n",
      "MNB Accuracy:  0.7313829787234043\n",
      "MNB F1:  0.3104480175908747\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88        14\n",
      "          1       1.00      0.45      0.62        11\n",
      "          2       1.00      0.77      0.87        39\n",
      "          3       0.91      0.48      0.62        21\n",
      "          4       0.83      0.45      0.59        11\n",
      "          5       0.98      0.83      0.90        58\n",
      "          6       0.84      1.00      0.91       222\n",
      "\n",
      "avg / total       0.89      0.88      0.87       376\n",
      "\n",
      "[ 11   0   0   0   1   0   2   0   5   0   0   0   0   6   0   0  30   0\n",
      "   0   1   8   0   0   0  10   0   0  11   0   0   0   0   5   0   6   0\n",
      "   0   0   1   0  48   9   0   0   0   0   0   0 222]\n",
      "svc Accuracy:  0.8803191489361702\n",
      "svc F1:  0.7712252885863963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.21      0.35        14\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.36      0.53        39\n",
      "          3       0.00      0.00      0.00        21\n",
      "          4       1.00      0.18      0.31        11\n",
      "          5       1.00      0.57      0.73        58\n",
      "          6       0.69      1.00      0.81       222\n",
      "\n",
      "avg / total       0.73      0.73      0.67       376\n",
      "\n",
      "[  3   0   0   0   0   0  11   0   0   0   0   0   0  11   0   0  14   0\n",
      "   0   0  25   0   0   0   0   0   0  21   0   0   0   0   2   0   9   0\n",
      "   0   0   0   0  33  25   0   0   0   0   0   0 222]\n",
      "LR Accuracy:  0.7287234042553191\n",
      "LR F1:  0.3896281299166982\n",
      "For name:  l_xiao\n",
      "total sample size before apply threshold:  302\n",
      "Counter({'0000-0001-8532-2727': 267, '0000-0002-4631-2443': 24, '0000-0003-0178-9384': 5, '0000-0003-4088-6101': 5, '0000-0002-0391-6909': 1})\n",
      "['0000-0001-8532-2727', '0000-0002-4631-2443']\n",
      "Total sample size after apply threshold:  291\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(291, 712)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96       267\n",
      "          1       1.00      0.17      0.29        24\n",
      "\n",
      "avg / total       0.94      0.93      0.91       291\n",
      "\n",
      "[267   0  20   4]\n",
      "MNB Accuracy:  0.9312714776632303\n",
      "MNB F1:  0.6248066013408973\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       267\n",
      "          1       1.00      0.50      0.67        24\n",
      "\n",
      "avg / total       0.96      0.96      0.95       291\n",
      "\n",
      "[267   0  12  12]\n",
      "svc Accuracy:  0.9587628865979382\n",
      "svc F1:  0.8223443223443223\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       267\n",
      "          1       1.00      0.08      0.15        24\n",
      "\n",
      "avg / total       0.93      0.92      0.89       291\n",
      "\n",
      "[267   0  22   2]\n",
      "LR Accuracy:  0.9243986254295533\n",
      "LR F1:  0.5571389042612065\n",
      "For name:  m_hartmann\n",
      "total sample size before apply threshold:  88\n",
      "Counter({'0000-0001-8069-5284': 28, '0000-0001-6937-5677': 25, '0000-0002-8207-3806': 21, '0000-0001-6046-0365': 10, '0000-0002-4774-2787': 4})\n",
      "['0000-0001-6937-5677', '0000-0001-8069-5284', '0000-0002-8207-3806', '0000-0001-6046-0365']\n",
      "Total sample size after apply threshold:  84\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(84, 304)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "84\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.84      0.89        25\n",
      "          1       0.73      0.96      0.83        28\n",
      "          2       0.89      0.81      0.85        21\n",
      "          3       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.87      0.85      0.84        84\n",
      "\n",
      "[21  3  1  0  1 27  0  0  0  4 17  0  0  3  1  6]\n",
      "MNB Accuracy:  0.8452380952380952\n",
      "MNB F1:  0.8310965630114566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91        25\n",
      "          1       0.76      1.00      0.86        28\n",
      "          2       1.00      0.90      0.95        21\n",
      "          3       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.92      0.89      0.89        84\n",
      "\n",
      "[21  4  0  0  0 28  0  0  0  2 19  0  0  3  0  7]\n",
      "svc Accuracy:  0.8928571428571429\n",
      "svc F1:  0.8870278378910093\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91        25\n",
      "          1       0.67      1.00      0.80        28\n",
      "          2       1.00      0.71      0.83        21\n",
      "          3       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.89      0.83      0.84        84\n",
      "\n",
      "[21  4  0  0  0 28  0  0  0  6 15  0  0  4  0  6]\n",
      "LR Accuracy:  0.8333333333333334\n",
      "LR F1:  0.8240942028985507\n",
      "For name:  k_nielsen\n",
      "total sample size before apply threshold:  194\n",
      "Counter({'0000-0002-5848-0911': 89, '0000-0002-7217-2114': 59, '0000-0001-7956-1748': 20, '0000-0002-9155-2972': 12, '0000-0002-4643-5697': 11, '0000-0002-5510-7767': 2, '0000-0002-4944-9453': 1})\n",
      "['0000-0002-4643-5697', '0000-0002-9155-2972', '0000-0001-7956-1748', '0000-0002-5848-0911', '0000-0002-7217-2114']\n",
      "Total sample size after apply threshold:  191\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(191, 539)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.25      0.40        12\n",
      "          2       1.00      0.40      0.57        20\n",
      "          3       0.68      0.99      0.80        89\n",
      "          4       0.98      0.83      0.90        59\n",
      "\n",
      "avg / total       0.79      0.77      0.74       191\n",
      "\n",
      "[ 0  0  0 11  0  0  3  0  9  0  0  0  8 12  0  0  0  0 88  1  0  0  0 10\n",
      " 49]\n",
      "MNB Accuracy:  0.774869109947644\n",
      "MNB F1:  0.5348328216544881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.45      0.59        11\n",
      "          1       1.00      0.58      0.74        12\n",
      "          2       1.00      0.75      0.86        20\n",
      "          3       0.78      0.99      0.87        89\n",
      "          4       1.00      0.85      0.92        59\n",
      "\n",
      "avg / total       0.89      0.86      0.86       191\n",
      "\n",
      "[ 5  0  0  6  0  0  7  0  5  0  0  0 15  5  0  1  0  0 88  0  0  0  0  9\n",
      " 50]\n",
      "svc Accuracy:  0.8638743455497382\n",
      "svc F1:  0.7941877155794167\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       1.00      0.33      0.50        12\n",
      "          2       1.00      0.35      0.52        20\n",
      "          3       0.65      0.99      0.79        89\n",
      "          4       0.98      0.75      0.85        59\n",
      "\n",
      "avg / total       0.77      0.75      0.71       191\n",
      "\n",
      "[ 0  0  0 11  0  0  4  0  8  0  0  0  7 13  0  0  0  0 88  1  0  0  0 15\n",
      " 44]\n",
      "LR Accuracy:  0.7486910994764397\n",
      "LR F1:  0.53007733007733\n",
      "For name:  m_sousa\n",
      "total sample size before apply threshold:  211\n",
      "Counter({'0000-0002-3009-3290': 117, '0000-0001-9424-4150': 28, '0000-0002-4524-2260': 28, '0000-0003-2305-4813': 9, '0000-0003-4957-7831': 8, '0000-0002-5269-3342': 5, '0000-0002-5397-4672': 4, '0000-0002-9946-4926': 4, '0000-0003-2238-1070': 4, '0000-0003-1687-942X': 2, '0000-0003-2575-3263': 1, '0000-0003-0012-7493': 1})\n",
      "['0000-0002-3009-3290', '0000-0001-9424-4150', '0000-0002-4524-2260']\n",
      "Total sample size after apply threshold:  173\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(173, 317)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "173\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       117\n",
      "          1       1.00      0.57      0.73        28\n",
      "          2       1.00      0.71      0.83        28\n",
      "\n",
      "avg / total       0.90      0.88      0.88       173\n",
      "\n",
      "[117   0   0  12  16   0   8   0  20]\n",
      "MNB Accuracy:  0.884393063583815\n",
      "MNB F1:  0.8272886343752486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.96       117\n",
      "          1       1.00      0.82      0.90        28\n",
      "          2       1.00      0.79      0.88        28\n",
      "\n",
      "avg / total       0.94      0.94      0.93       173\n",
      "\n",
      "[117   0   0   5  23   0   6   0  22]\n",
      "svc Accuracy:  0.9364161849710982\n",
      "svc F1:  0.9123542750433508\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       117\n",
      "          1       1.00      0.54      0.70        28\n",
      "          2       1.00      0.54      0.70        28\n",
      "\n",
      "avg / total       0.88      0.85      0.83       173\n",
      "\n",
      "[117   0   0  13  15   0  13   0  15]\n",
      "LR Accuracy:  0.8497109826589595\n",
      "LR F1:  0.7651162790697675\n",
      "For name:  a_coelho\n",
      "total sample size before apply threshold:  128\n",
      "Counter({'0000-0002-6143-4203': 72, '0000-0003-2780-5821': 15, '0000-0002-7196-4179': 11, '0000-0002-3286-0262': 11, '0000-0003-3077-3859': 6, '0000-0002-7277-2267': 5, '0000-0002-2883-415X': 4, '0000-0003-3527-9091': 2, '0000-0002-9767-8891': 1, '0000-0002-2919-5468': 1})\n",
      "['0000-0003-2780-5821', '0000-0002-7196-4179', '0000-0002-6143-4203', '0000-0002-3286-0262']\n",
      "Total sample size after apply threshold:  109\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(109, 309)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "109\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.12        15\n",
      "          1       1.00      0.27      0.43        11\n",
      "          2       0.71      1.00      0.83        72\n",
      "          3       1.00      0.36      0.53        11\n",
      "\n",
      "avg / total       0.81      0.73      0.66       109\n",
      "\n",
      "[ 1  0 14  0  0  3  8  0  0  0 72  0  0  0  7  4]\n",
      "MNB Accuracy:  0.7339449541284404\n",
      "MNB F1:  0.47981867602532347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.40      0.57        15\n",
      "          1       1.00      0.64      0.78        11\n",
      "          2       0.84      1.00      0.91        72\n",
      "          3       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       0.89      0.87      0.86       109\n",
      "\n",
      "[ 6  0  9  0  0  7  4  0  0  0 72  0  0  0  1 10]\n",
      "svc Accuracy:  0.8715596330275229\n",
      "svc F1:  0.8032449266626482\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.12        15\n",
      "          1       1.00      0.09      0.17        11\n",
      "          2       0.71      1.00      0.83        72\n",
      "          3       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.81      0.73      0.66       109\n",
      "\n",
      "[ 1  0 14  0  0  1 10  0  0  0 72  0  0  0  5  6]\n",
      "LR Accuracy:  0.7339449541284404\n",
      "LR F1:  0.45747974045109374\n",
      "For name:  r_sanz\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0003-2830-0892': 30, '0000-0001-6626-4146': 8, '0000-0002-2381-933X': 3, '0000-0001-8211-7306': 1})\n",
      "['0000-0003-2830-0892']\n",
      "Total sample size after apply threshold:  30\n",
      "For name:  m_ferrara\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0003-2304-7576': 92, '0000-0002-4751-8478': 5, '0000-0001-5291-1373': 4, '0000-0002-1567-4281': 2})\n",
      "['0000-0003-2304-7576']\n",
      "Total sample size after apply threshold:  92\n",
      "For name:  c_hui\n",
      "total sample size before apply threshold:  44\n",
      "Counter({'0000-0002-3660-8160': 34, '0000-0002-3698-5572': 5, '0000-0002-2886-4957': 4, '0000-0002-0260-193X': 1})\n",
      "['0000-0002-3660-8160']\n",
      "Total sample size after apply threshold:  34\n",
      "For name:  l_bruno\n",
      "total sample size before apply threshold:  42\n",
      "Counter({'0000-0001-8260-4729': 22, '0000-0002-6745-0466': 10, '0000-0003-4703-2088': 7, '0000-0002-0875-7716': 2, '0000-0002-3054-2180': 1})\n",
      "['0000-0002-6745-0466', '0000-0001-8260-4729']\n",
      "Total sample size after apply threshold:  32\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(32, 108)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.92      1.00      0.96        22\n",
      "\n",
      "avg / total       0.94      0.94      0.94        32\n",
      "\n",
      "[ 8  2  0 22]\n",
      "MNB Accuracy:  0.9375\n",
      "MNB F1:  0.9227053140096619\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        10\n",
      "          1       0.92      1.00      0.96        22\n",
      "\n",
      "avg / total       0.94      0.94      0.94        32\n",
      "\n",
      "[ 8  2  0 22]\n",
      "svc Accuracy:  0.9375\n",
      "svc F1:  0.9227053140096619\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82        10\n",
      "          1       0.88      1.00      0.94        22\n",
      "\n",
      "avg / total       0.92      0.91      0.90        32\n",
      "\n",
      "[ 7  3  0 22]\n",
      "LR Accuracy:  0.90625\n",
      "LR F1:  0.8798498122653317\n",
      "For name:  s_nielsen\n",
      "total sample size before apply threshold:  290\n",
      "Counter({'0000-0003-2417-0787': 108, '0000-0001-6391-7455': 72, '0000-0001-5341-1055': 44, '0000-0003-4175-3829': 21, '0000-0002-5777-6542': 13, '0000-0002-7780-7131': 11, '0000-0003-4309-5153': 7, '0000-0002-9754-0630': 4, '0000-0002-9214-2932': 4, '0000-0002-0458-3739': 3, '0000-0003-2770-9899': 1, '0000-0002-8449-476X': 1, '0000-0003-2064-8050': 1})\n",
      "['0000-0001-5341-1055', '0000-0003-4175-3829', '0000-0002-5777-6542', '0000-0002-7780-7131', '0000-0001-6391-7455', '0000-0003-2417-0787']\n",
      "Total sample size after apply threshold:  269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(269, 526)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "269\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91        44\n",
      "          1       1.00      0.95      0.98        21\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       1.00      0.27      0.43        11\n",
      "          4       0.91      0.86      0.89        72\n",
      "          5       0.76      0.99      0.86       108\n",
      "\n",
      "avg / total       0.83      0.85      0.83       269\n",
      "\n",
      "[ 37   0   0   0   0   7   0  20   0   0   0   1   0   0   0   0   0  13\n",
      "   0   0   0   3   5   3   0   0   0   0  62  10   0   0   0   0   1 107]\n",
      "MNB Accuracy:  0.8513011152416357\n",
      "MNB F1:  0.6771522447168118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94        44\n",
      "          1       1.00      0.90      0.95        21\n",
      "          2       1.00      0.62      0.76        13\n",
      "          3       1.00      0.73      0.84        11\n",
      "          4       0.97      0.88      0.92        72\n",
      "          5       0.83      1.00      0.91       108\n",
      "\n",
      "avg / total       0.92      0.91      0.91       269\n",
      "\n",
      "[ 39   0   0   0   0   5   0  19   0   0   0   2   0   0   8   0   0   5\n",
      "   0   0   0   8   2   1   0   0   0   0  63   9   0   0   0   0   0 108]\n",
      "svc Accuracy:  0.9107806691449815\n",
      "svc F1:  0.8868400192690666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        44\n",
      "          1       1.00      0.81      0.89        21\n",
      "          2       1.00      0.23      0.38        13\n",
      "          3       1.00      0.36      0.53        11\n",
      "          4       0.98      0.79      0.88        72\n",
      "          5       0.71      0.99      0.83       108\n",
      "\n",
      "avg / total       0.88      0.83      0.82       269\n",
      "\n",
      "[ 36   0   0   0   0   8   0  17   0   0   0   4   0   0   3   0   0  10\n",
      "   0   0   0   4   0   7   0   0   0   0  57  15   0   0   0   0   1 107]\n",
      "LR Accuracy:  0.8327137546468402\n",
      "LR F1:  0.7343746797694166\n",
      "For name:  b_russell\n",
      "total sample size before apply threshold:  84\n",
      "Counter({'0000-0003-2333-4348': 61, '0000-0003-1282-9978': 20, '0000-0002-8740-6040': 1, '0000-0002-3345-8478': 1, '0000-0002-8848-4841': 1})\n",
      "['0000-0003-1282-9978', '0000-0003-2333-4348']\n",
      "Total sample size after apply threshold:  81\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(81, 354)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        20\n",
      "          1       0.98      1.00      0.99        61\n",
      "\n",
      "avg / total       0.99      0.99      0.99        81\n",
      "\n",
      "[19  1  0 61]\n",
      "MNB Accuracy:  0.9876543209876543\n",
      "MNB F1:  0.9831144465290806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        20\n",
      "          1       0.97      1.00      0.98        61\n",
      "\n",
      "avg / total       0.98      0.98      0.97        81\n",
      "\n",
      "[18  2  0 61]\n",
      "svc Accuracy:  0.9753086419753086\n",
      "svc F1:  0.9656196943972835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.35      0.52        20\n",
      "          1       0.82      1.00      0.90        61\n",
      "\n",
      "avg / total       0.87      0.84      0.81        81\n",
      "\n",
      "[ 7 13  0 61]\n",
      "LR Accuracy:  0.8395061728395061\n",
      "LR F1:  0.711111111111111\n",
      "For name:  y_wu\n",
      "total sample size before apply threshold:  612\n",
      "Counter({'0000-0002-3611-0258': 120, '0000-0002-1720-7863': 65, '0000-0003-3456-3373': 43, '0000-0002-2573-8736': 39, '0000-0002-1751-461X': 35, '0000-0001-5579-2197': 33, '0000-0002-2985-219X': 23, '0000-0002-8621-4098': 23, '0000-0003-0365-5590': 23, '0000-0001-9359-1863': 23, '0000-0003-0253-1625': 17, '0000-0001-9142-456X': 14, '0000-0002-0833-1205': 12, '0000-0003-3191-3163': 11, '0000-0002-4459-087X': 10, '0000-0002-7919-1107': 10, '0000-0002-9460-3579': 9, '0000-0002-9289-1271': 9, '0000-0002-3612-7818': 8, '0000-0001-5035-4577': 8, '0000-0002-3805-6515': 7, '0000-0002-5163-0884': 6, '0000-0003-1028-1785': 6, '0000-0003-3511-4270': 5, '0000-0001-7857-0247': 5, '0000-0003-3970-3160': 5, '0000-0001-7247-7404': 5, '0000-0002-1457-3681': 4, '0000-0002-8937-4417': 4, '0000-0003-0878-7605': 4, '0000-0002-8858-1289': 4, '0000-0001-5083-8950': 4, '0000-0003-4542-1741': 3, '0000-0002-1509-1721': 3, '0000-0003-2874-8267': 2, '0000-0002-3269-7143': 2, '0000-0001-7876-261X': 2, '0000-0001-9263-5369': 1, '0000-0003-3357-3051': 1, '0000-0002-8966-1459': 1, '0000-0003-0118-2152': 1, '0000-0001-5480-1741': 1, '0000-0001-5466-2446': 1})\n",
      "['0000-0001-9142-456X', '0000-0001-5579-2197', '0000-0002-3611-0258', '0000-0003-3191-3163', '0000-0002-4459-087X', '0000-0002-2985-219X', '0000-0002-0833-1205', '0000-0002-8621-4098', '0000-0002-7919-1107', '0000-0003-3456-3373', '0000-0002-1751-461X', '0000-0002-1720-7863', '0000-0003-0365-5590', '0000-0001-9359-1863', '0000-0002-2573-8736', '0000-0003-0253-1625']\n",
      "Total sample size after apply threshold:  501\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(501, 748)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67        14\n",
      "          1       0.89      0.24      0.38        33\n",
      "          2       0.38      1.00      0.55       120\n",
      "          3       1.00      0.36      0.53        11\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       1.00      0.09      0.16        23\n",
      "          6       0.00      0.00      0.00        12\n",
      "          7       0.00      0.00      0.00        23\n",
      "          8       0.00      0.00      0.00        10\n",
      "          9       1.00      0.14      0.24        43\n",
      "         10       0.89      0.89      0.89        35\n",
      "         11       0.66      0.85      0.74        65\n",
      "         12       1.00      0.26      0.41        23\n",
      "         13       0.00      0.00      0.00        23\n",
      "         14       1.00      0.64      0.78        39\n",
      "         15       1.00      0.29      0.45        17\n",
      "\n",
      "avg / total       0.64      0.54      0.47       501\n",
      "\n",
      "[  7   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8\n",
      "  12   0   0   0   0   0   0   0   3  10   0   0   0   0   0   0 120   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   4   0   0\n",
      "   0   0   0   0   0   2   0   0   0   0   0   0  10   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  17   0   0   2   0   0   0   0\n",
      "   0   4   0   0   0   0   0   0  11   0   0   0   0   0   0   0   0   1\n",
      "   0   0   0   0   0   0  15   0   0   0   0   0   0   0   1   7   0   0\n",
      "   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  37   0   0   0   0   0   0   6   0   0   0   0   0   0   0   0\n",
      "   2   0   0   0   0   0   0   0  31   2   0   0   0   0   0   1   9   0\n",
      "   0   0   0   0   0   0   0  55   0   0   0   0   0   0  17   0   0   0\n",
      "   0   0   0   0   0   0   6   0   0   0   0   0  23   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0\n",
      "   0   0   0   0  25   0   0   0  10   0   0   0   0   0   0   0   0   2\n",
      "   0   0   0   5]\n",
      "MNB Accuracy:  0.5369261477045908\n",
      "MNB F1:  0.36319334161323047\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.83      0.61      0.70        33\n",
      "          2       0.57      0.95      0.71       120\n",
      "          3       1.00      0.82      0.90        11\n",
      "          4       1.00      0.50      0.67        10\n",
      "          5       0.89      0.74      0.81        23\n",
      "          6       1.00      0.50      0.67        12\n",
      "          7       0.58      0.30      0.40        23\n",
      "          8       0.00      0.00      0.00        10\n",
      "          9       0.64      0.58      0.61        43\n",
      "         10       0.88      0.86      0.87        35\n",
      "         11       0.84      0.88      0.86        65\n",
      "         12       1.00      0.74      0.85        23\n",
      "         13       0.92      0.52      0.67        23\n",
      "         14       1.00      0.77      0.87        39\n",
      "         15       1.00      0.71      0.83        17\n",
      "\n",
      "avg / total       0.78      0.75      0.74       501\n",
      "\n",
      "[ 13   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0  20\n",
      "   7   0   0   0   0   0   0   0   3   3   0   0   0   0   0   1 114   0\n",
      "   0   1   0   0   0   3   0   1   0   0   0   0   0   0   2   9   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   5   0   5   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   3   0   0  17   0   0   0   3\n",
      "   0   0   0   0   0   0   0   0   4   0   0   0   6   0   0   1   0   0\n",
      "   0   1   0   0   0   1  10   0   0   0   0   7   0   0   1   4   0   0\n",
      "   0   0   0   0   9   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "   0   0  17   0   0   1   0   0   0  25   0   0   0   0   0   0   0   1\n",
      "   1   0   0   0   0   2   0   0  30   1   0   0   0   0   0   1   4   0\n",
      "   0   0   0   3   0   0   0  57   0   0   0   0   0   0   6   0   0   0\n",
      "   0   0   0   0   0   0  17   0   0   0   0   0   7   0   0   0   0   0\n",
      "   0   4   0   0   0  12   0   0   0   0   7   0   0   0   0   0   0   2\n",
      "   0   0   0   0  30   0   0   0   3   0   0   0   0   0   0   0   0   2\n",
      "   0   0   0  12]\n",
      "svc Accuracy:  0.7465069860279441\n",
      "svc F1:  0.7106472971771673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.86      0.55      0.67        33\n",
      "          2       0.50      0.97      0.66       120\n",
      "          3       1.00      0.82      0.90        11\n",
      "          4       0.00      0.00      0.00        10\n",
      "          5       1.00      0.52      0.69        23\n",
      "          6       1.00      0.17      0.29        12\n",
      "          7       0.00      0.00      0.00        23\n",
      "          8       0.00      0.00      0.00        10\n",
      "          9       0.54      0.44      0.49        43\n",
      "         10       0.89      0.89      0.89        35\n",
      "         11       0.76      0.86      0.81        65\n",
      "         12       0.88      0.65      0.75        23\n",
      "         13       1.00      0.43      0.61        23\n",
      "         14       1.00      0.74      0.85        39\n",
      "         15       1.00      0.53      0.69        17\n",
      "\n",
      "avg / total       0.70      0.68      0.65       501\n",
      "\n",
      "[ 12   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18\n",
      "   6   0   0   0   0   0   0   1   3   5   0   0   0   0   0   0 117   0\n",
      "   0   0   0   0   0   3   0   0   0   0   0   0   0   0   2   9   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   7   0   0   0   0   0\n",
      "   0   2   0   1   0   0   0   0   0   0   7   0   0  12   0   0   0   4\n",
      "   0   0   0   0   0   0   0   0   7   0   0   0   2   0   0   2   0   1\n",
      "   0   0   0   0   0   1  14   0   0   0   0   0   0   0   1   7   0   0\n",
      "   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  24   0   0   0   0   0   0  19   0   0   0   0   0   0   0   0\n",
      "   2   0   0   0   0   0   0   0  31   2   0   0   0   0   0   2   6   0\n",
      "   0   0   0   0   0   1   0  56   0   0   0   0   0   0   8   0   0   0\n",
      "   0   0   0   0   0   0  15   0   0   0   0   0   9   0   0   0   0   0\n",
      "   0   2   0   0   2  10   0   0   0   0   9   0   0   0   0   0   0   1\n",
      "   0   0   0   0  29   0   0   0   6   0   0   0   0   0   0   0   0   2\n",
      "   0   0   0   9]\n",
      "LR Accuracy:  0.6766467065868264\n",
      "LR F1:  0.5749021359609244\n",
      "For name:  j_soto\n",
      "total sample size before apply threshold:  64\n",
      "Counter({'0000-0003-0234-9188': 39, '0000-0001-6702-2878': 21, '0000-0001-5521-0900': 3, '0000-0001-8961-9106': 1})\n",
      "['0000-0001-6702-2878', '0000-0003-0234-9188']\n",
      "Total sample size after apply threshold:  60\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(60, 255)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "60\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        21\n",
      "          1       1.00      0.97      0.99        39\n",
      "\n",
      "avg / total       0.98      0.98      0.98        60\n",
      "\n",
      "[21  0  1 38]\n",
      "MNB Accuracy:  0.9833333333333333\n",
      "MNB F1:  0.9818785865297492\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        21\n",
      "          1       1.00      1.00      1.00        39\n",
      "\n",
      "avg / total       1.00      1.00      1.00        60\n",
      "\n",
      "[21  0  0 39]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        21\n",
      "          1       0.93      1.00      0.96        39\n",
      "\n",
      "avg / total       0.95      0.95      0.95        60\n",
      "\n",
      "[18  3  0 39]\n",
      "LR Accuracy:  0.95\n",
      "LR F1:  0.9430199430199431\n",
      "For name:  r_mckay\n",
      "total sample size before apply threshold:  53\n",
      "Counter({'0000-0001-7781-1539': 31, '0000-0003-2723-5371': 17, '0000-0002-5602-6985': 4, '0000-0001-8042-2462': 1})\n",
      "['0000-0001-7781-1539', '0000-0003-2723-5371']\n",
      "Total sample size after apply threshold:  48\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 119)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90        31\n",
      "          1       1.00      0.59      0.74        17\n",
      "\n",
      "avg / total       0.88      0.85      0.84        48\n",
      "\n",
      "[31  0  7 10]\n",
      "MNB Accuracy:  0.8541666666666666\n",
      "MNB F1:  0.8196457326892108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        31\n",
      "          1       1.00      0.76      0.87        17\n",
      "\n",
      "avg / total       0.93      0.92      0.91        48\n",
      "\n",
      "[31  0  4 13]\n",
      "svc Accuracy:  0.9166666666666666\n",
      "svc F1:  0.903030303030303\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85        31\n",
      "          1       1.00      0.35      0.52        17\n",
      "\n",
      "avg / total       0.83      0.77      0.73        48\n",
      "\n",
      "[31  0 11  6]\n",
      "LR Accuracy:  0.7708333333333334\n",
      "LR F1:  0.6855270994639666\n",
      "For name:  d_sharma\n",
      "total sample size before apply threshold:  60\n",
      "Counter({'0000-0001-7612-3486': 32, '0000-0002-0082-1285': 16, '0000-0003-4463-1480': 4, '0000-0001-7379-4233': 4, '0000-0001-5818-025X': 2, '0000-0002-2971-5013': 1, '0000-0001-5557-9388': 1})\n",
      "['0000-0001-7612-3486', '0000-0002-0082-1285']\n",
      "Total sample size after apply threshold:  48\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(48, 68)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        32\n",
      "          1       1.00      0.50      0.67        16\n",
      "\n",
      "avg / total       0.87      0.83      0.81        48\n",
      "\n",
      "[32  0  8  8]\n",
      "MNB Accuracy:  0.8333333333333334\n",
      "MNB F1:  0.7777777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94        32\n",
      "          1       0.93      0.81      0.87        16\n",
      "\n",
      "avg / total       0.92      0.92      0.92        48\n",
      "\n",
      "[31  1  3 13]\n",
      "svc Accuracy:  0.9166666666666666\n",
      "svc F1:  0.9030303030303031\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82        32\n",
      "          1       1.00      0.12      0.22        16\n",
      "\n",
      "avg / total       0.80      0.71      0.62        48\n",
      "\n",
      "[32  0 14  2]\n",
      "LR Accuracy:  0.7083333333333334\n",
      "LR F1:  0.5213675213675213\n",
      "For name:  a_wilson\n",
      "total sample size before apply threshold:  252\n",
      "Counter({'0000-0002-5045-2051': 61, '0000-0003-3679-9232': 48, '0000-0002-5016-4164': 36, '0000-0003-1098-8457': 35, '0000-0002-2000-2914': 27, '0000-0002-7696-1671': 10, '0000-0003-1325-8513': 9, '0000-0003-2352-5232': 7, '0000-0001-5865-6537': 7, '0000-0003-3362-7806': 4, '0000-0001-5775-6085': 3, '0000-0002-6473-7234': 2, '0000-0003-1461-6212': 2, '0000-0002-1015-3786': 1})\n",
      "['0000-0003-3679-9232', '0000-0002-5045-2051', '0000-0002-7696-1671', '0000-0002-5016-4164', '0000-0003-1098-8457', '0000-0002-2000-2914']\n",
      "Total sample size after apply threshold:  217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(217, 629)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "217\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.77      0.86        48\n",
      "          1       0.52      0.97      0.67        61\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.94      0.83      0.88        36\n",
      "          4       1.00      0.51      0.68        35\n",
      "          5       1.00      0.56      0.71        27\n",
      "\n",
      "avg / total       0.80      0.73      0.72       217\n",
      "\n",
      "[37 11  0  0  0  0  1 59  0  1  0  0  0 10  0  0  0  0  0  6  0 30  0  0\n",
      "  0 16  0  1 18  0  0 12  0  0  0 15]\n",
      "MNB Accuracy:  0.7327188940092166\n",
      "MNB F1:  0.6351057948409727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.83      0.87        48\n",
      "          1       0.58      0.95      0.72        61\n",
      "          2       1.00      0.40      0.57        10\n",
      "          3       0.97      0.83      0.90        36\n",
      "          4       1.00      0.57      0.73        35\n",
      "          5       1.00      0.67      0.80        27\n",
      "\n",
      "avg / total       0.86      0.78      0.79       217\n",
      "\n",
      "[40  8  0  0  0  0  3 58  0  0  0  0  0  6  4  0  0  0  0  6  0 30  0  0\n",
      "  1 13  0  1 20  0  0  9  0  0  0 18]\n",
      "svc Accuracy:  0.783410138248848\n",
      "svc F1:  0.764047633093707\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.79      0.82        48\n",
      "          1       0.51      0.93      0.66        61\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.97      0.83      0.90        36\n",
      "          4       1.00      0.49      0.65        35\n",
      "          5       1.00      0.48      0.65        27\n",
      "\n",
      "avg / total       0.78      0.71      0.70       217\n",
      "\n",
      "[38 10  0  0  0  0  4 57  0  0  0  0  0 10  0  0  0  0  0  6  0 30  0  0\n",
      "  1 16  0  1 17  0  2 12  0  0  0 13]\n",
      "LR Accuracy:  0.7142857142857143\n",
      "LR F1:  0.6132272567759237\n",
      "For name:  f_marini\n",
      "total sample size before apply threshold:  65\n",
      "Counter({'0000-0001-8266-1117': 37, '0000-0002-9495-2349': 12, '0000-0003-0747-5060': 12, '0000-0003-3252-7758': 4})\n",
      "['0000-0002-9495-2349', '0000-0003-0747-5060', '0000-0001-8266-1117']\n",
      "Total sample size after apply threshold:  61\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(61, 213)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       0.71      1.00      0.83        37\n",
      "\n",
      "avg / total       0.63      0.75      0.67        61\n",
      "\n",
      "[ 0  0 12  0  9  3  0  0 37]\n",
      "MNB Accuracy:  0.7540983606557377\n",
      "MNB F1:  0.5628678437667202\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       1.00      0.75      0.86        12\n",
      "          2       0.82      1.00      0.90        37\n",
      "\n",
      "avg / total       0.89      0.87      0.86        61\n",
      "\n",
      "[ 7  0  5  0  9  3  0  0 37]\n",
      "svc Accuracy:  0.8688524590163934\n",
      "svc F1:  0.8321413289320864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       1.00      0.42      0.59        12\n",
      "          2       0.66      1.00      0.80        37\n",
      "\n",
      "avg / total       0.60      0.69      0.60        61\n",
      "\n",
      "[ 0  0 12  0  5  7  0  0 37]\n",
      "LR Accuracy:  0.6885245901639344\n",
      "LR F1:  0.4613114062829433\n",
      "For name:  h_tsai\n",
      "total sample size before apply threshold:  93\n",
      "Counter({'0000-0002-9393-7155': 36, '0000-0003-1310-9980': 15, '0000-0002-4070-0058': 14, '0000-0002-9661-5848': 8, '0000-0002-7395-1603': 7, '0000-0003-2097-0170': 6, '0000-0003-1174-5473': 1, '0000-0001-8242-4939': 1, '0000-0001-6444-8814': 1, '0000-0002-4480-0240': 1, '0000-0001-8972-7174': 1, '0000-0003-3467-0507': 1, '0000-0003-3840-7853': 1})\n",
      "['0000-0002-4070-0058', '0000-0003-1310-9980', '0000-0002-9393-7155']\n",
      "Total sample size after apply threshold:  65\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(65, 72)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        14\n",
      "          1       1.00      0.53      0.70        15\n",
      "          2       0.71      1.00      0.83        36\n",
      "\n",
      "avg / total       0.84      0.77      0.75        65\n",
      "\n",
      "[ 6  0  8  0  8  7  0  0 36]\n",
      "MNB Accuracy:  0.7692307692307693\n",
      "MNB F1:  0.7077461269365317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.92      0.73      0.81        15\n",
      "          2       0.88      0.97      0.92        36\n",
      "\n",
      "avg / total       0.91      0.91      0.91        65\n",
      "\n",
      "[13  0  1  0 11  4  0  1 35]\n",
      "svc Accuracy:  0.9076923076923077\n",
      "svc F1:  0.8996101364522416\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60        14\n",
      "          1       1.00      0.40      0.57        15\n",
      "          2       0.68      1.00      0.81        36\n",
      "\n",
      "avg / total       0.82      0.74      0.71        65\n",
      "\n",
      "[ 6  0  8  0  6  9  0  0 36]\n",
      "LR Accuracy:  0.7384615384615385\n",
      "LR F1:  0.6601391118245051\n",
      "For name:  s_o'brien\n",
      "total sample size before apply threshold:  32\n",
      "Counter({'0000-0001-7353-8301': 27, '0000-0003-3133-8920': 2, '0000-0001-8965-178X': 2, '0000-0002-2052-0762': 1})\n",
      "['0000-0001-7353-8301']\n",
      "Total sample size after apply threshold:  27\n",
      "For name:  c_webb\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0003-1031-3249': 16, '0000-0002-4094-2524': 15, '0000-0002-2538-6953': 3, '0000-0003-4164-9634': 1})\n",
      "['0000-0002-4094-2524', '0000-0003-1031-3249']\n",
      "Total sample size after apply threshold:  31\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(31, 149)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "31\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.73      0.67        15\n",
      "          1       0.69      0.56      0.62        16\n",
      "\n",
      "avg / total       0.65      0.65      0.64        31\n",
      "\n",
      "[11  4  7  9]\n",
      "MNB Accuracy:  0.6451612903225806\n",
      "MNB F1:  0.6436781609195402\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80        15\n",
      "          1       0.76      1.00      0.86        16\n",
      "\n",
      "avg / total       0.88      0.84      0.83        31\n",
      "\n",
      "[10  5  0 16]\n",
      "svc Accuracy:  0.8387096774193549\n",
      "svc F1:  0.8324324324324324\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.53      0.57        15\n",
      "          1       0.61      0.69      0.65        16\n",
      "\n",
      "avg / total       0.61      0.61      0.61        31\n",
      "\n",
      "[ 8  7  5 11]\n",
      "LR Accuracy:  0.6129032258064516\n",
      "LR F1:  0.6092436974789917\n",
      "For name:  c_adams\n",
      "total sample size before apply threshold:  69\n",
      "Counter({'0000-0003-2100-4417': 43, '0000-0001-5602-2741': 20, '0000-0002-7333-9908': 4, '0000-0003-1628-4020': 1, '0000-0002-0667-8088': 1})\n",
      "['0000-0003-2100-4417', '0000-0001-5602-2741']\n",
      "Total sample size after apply threshold:  63\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(63, 132)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        43\n",
      "          1       1.00      0.65      0.79        20\n",
      "\n",
      "avg / total       0.90      0.89      0.88        63\n",
      "\n",
      "[43  0  7 13]\n",
      "MNB Accuracy:  0.8888888888888888\n",
      "MNB F1:  0.8563049853372435\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93        43\n",
      "          1       0.94      0.75      0.83        20\n",
      "\n",
      "avg / total       0.91      0.90      0.90        63\n",
      "\n",
      "[42  1  5 15]\n",
      "svc Accuracy:  0.9047619047619048\n",
      "svc F1:  0.8833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        43\n",
      "          1       1.00      0.45      0.62        20\n",
      "\n",
      "avg / total       0.86      0.83      0.80        63\n",
      "\n",
      "[43  0 11  9]\n",
      "LR Accuracy:  0.8253968253968254\n",
      "LR F1:  0.7536437966583718\n",
      "For name:  c_peng\n",
      "total sample size before apply threshold:  103\n",
      "Counter({'0000-0003-3666-9833': 79, '0000-0003-3332-184X': 10, '0000-0001-7943-9873': 7, '0000-0001-6090-2944': 5, '0000-0002-0800-1417': 2})\n",
      "['0000-0003-3666-9833', '0000-0003-3332-184X']\n",
      "Total sample size after apply threshold:  89\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(89, 144)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97        79\n",
      "          1       0.86      0.60      0.71        10\n",
      "\n",
      "avg / total       0.94      0.94      0.94        89\n",
      "\n",
      "[78  1  4  6]\n",
      "MNB Accuracy:  0.9438202247191011\n",
      "MNB F1:  0.8374132261600292\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        79\n",
      "          1       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        89\n",
      "\n",
      "[79  0  0 10]\n",
      "svc Accuracy:  1.0\n",
      "svc F1:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        79\n",
      "          1       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.93      0.92      0.90        89\n",
      "\n",
      "[79  0  7  3]\n",
      "LR Accuracy:  0.9213483146067416\n",
      "LR F1:  0.7095571095571096\n",
      "For name:  k_kobayashi\n",
      "total sample size before apply threshold:  35\n",
      "Counter({'0000-0003-2951-1341': 17, '0000-0002-9475-6807': 8, '0000-0002-4642-1690': 7, '0000-0002-4163-9498': 2, '0000-0001-8842-469X': 1})\n",
      "['0000-0003-2951-1341']\n",
      "Total sample size after apply threshold:  17\n",
      "For name:  s_larsen\n",
      "total sample size before apply threshold:  68\n",
      "Counter({'0000-0002-5170-4337': 31, '0000-0002-0838-9378': 11, '0000-0003-4570-9489': 10, '0000-0001-9522-7678': 9, '0000-0002-5134-3332': 4, '0000-0002-9056-6061': 2, '0000-0001-5836-370X': 1})\n",
      "['0000-0002-0838-9378', '0000-0002-5170-4337', '0000-0003-4570-9489']\n",
      "Total sample size after apply threshold:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "(52, 186)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "1\n",
      "52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        11\n",
      "          1       0.79      1.00      0.89        31\n",
      "          2       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.88      0.85      0.82        52\n",
      "\n",
      "[10  1  0  0 31  0  0  7  3]\n",
      "MNB Accuracy:  0.8461538461538461\n",
      "MNB F1:  0.7665445665445666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.84      1.00      0.91        31\n",
      "          2       1.00      0.60      0.75        10\n",
      "\n",
      "avg / total       0.90      0.88      0.88        52\n",
      "\n",
      "[ 9  2  0  0 31  0  0  4  6]\n",
      "svc Accuracy:  0.8846153846153846\n",
      "svc F1:  0.853921568627451\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.64      0.78        11\n",
      "          1       0.72      1.00      0.84        31\n",
      "          2       1.00      0.20      0.33        10\n",
      "\n",
      "avg / total       0.83      0.77      0.73        52\n",
      "\n",
      "[ 7  4  0  0 31  0  0  8  2]\n",
      "LR Accuracy:  0.7692307692307693\n",
      "LR F1:  0.6496496496496497\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# load the file\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "fileDir = \"../Data/\"+Dataset+\"/canopies_labeled/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "# collect statistic to output\n",
    "allname = []\n",
    "num_class = []\n",
    "per_class_count = []\n",
    "average_textual_size = []\n",
    "\n",
    "all_mnb_accuracy = []\n",
    "all_mnb_f1 = []\n",
    "all_svcLinear_accuracy = []\n",
    "all_svcLinear_f1 = []\n",
    "all_LR_accuracy = []\n",
    "all_LR_f1 = []\n",
    "\n",
    "# read all file in labeled group\n",
    "for file in listfiles:\n",
    "    # group name\n",
    "    temp = file.split(\"_\")\n",
    "    name = temp[1]+\"_\"+temp[-1]\n",
    "    print(\"For name: \",name)\n",
    "    allname.append(name)\n",
    "    # read needed content in labeled file\n",
    "    labeled_data = read_labeled_file(fileDir+file)\n",
    "    print(\"total sample size before apply threshold: \",len(labeled_data))\n",
    "    # count number of paper each author write based on author ID\n",
    "    paperCounter = collections.Counter(labeled_data[\"authorID\"])\n",
    "    print(paperCounter)\n",
    "    # collect per class statistic\n",
    "    for k in list(paperCounter):\n",
    "        if paperCounter[k] < threshold:\n",
    "            del paperCounter[k]\n",
    "    temp =list(paperCounter.keys())\n",
    "    print(temp)\n",
    "    per_class_count.append(paperCounter)\n",
    "    num_class.append(len(paperCounter))\n",
    "    # remove samples that are smaller than threshold\n",
    "    labeled_data = labeled_data[labeled_data.authorID.isin(temp)]\n",
    "    print(\"Total sample size after apply threshold: \",len(labeled_data))\n",
    "    # if only have one class or no class pass the threshold, not applicable\n",
    "    if(len(paperCounter)==0) or (len(paperCounter)==1):\n",
    "        average_textual_size.append(\"Not applicable\")\n",
    "        all_mnb_accuracy.append(\"Not applicable\")\n",
    "        all_mnb_f1.append(\"Not applicable\")\n",
    "        all_svcLinear_accuracy.append(\"Not applicable\")\n",
    "        all_svcLinear_f1.append(\"Not applicable\")\n",
    "        all_LR_accuracy.append(\"Not applicable\")\n",
    "        all_LR_f1.append(\"Not applicable\")\n",
    "    else:\n",
    "        # convert author id to label\n",
    "        gather_label = []\n",
    "        for index, record in labeled_data.iterrows():\n",
    "            gather_label.append(temp.index(record[\"authorID\"]))\n",
    "        labeled_data[\"label\"] = gather_label\n",
    "        # shuffle the data\n",
    "        labeled_data = labeled_data.sample(frac=1).reset_index(drop=True)\n",
    "        # extract true label and pid\n",
    "        label = labeled_data[\"label\"]\n",
    "        pid = labeled_data[\"paperID\"]\n",
    "        # list of different data field\n",
    "        part_collection = []\n",
    "        # data part 1, co-author matrix\n",
    "        data_part_co_author = co_author_to_vector(labeled_data[\"co-author\"], emb_type=coauthor_emb_type)\n",
    "        print(data_part_co_author.shape)\n",
    "        part_collection.append(data_part_co_author)\n",
    "        # data part 2.1, venue_id that author attend\n",
    "        data_part_venue = venue_to_vector(labeled_data[\"venue_id\"], emb_type=venue_emb_type)\n",
    "        print(data_part_venue.shape)\n",
    "        part_collection.append(data_part_venue)\n",
    "        # data part 2.2 year that author attend\n",
    "        data_part_year = year_to_vector(labeled_data[\"publish_year\"], emb_type=year_emb_type)\n",
    "        print(data_part_year.shape)\n",
    "        part_collection.append(data_part_year)\n",
    "        # merge different part of data data together by concatenate it all together\n",
    "        # remove empty emb (when emb set off)\n",
    "        part_collection = [part for part in part_collection if len(part)!=0]\n",
    "        print(len(part_collection))\n",
    "        if len(part_collection)>1:\n",
    "            combinedata = np.concatenate(part_collection,axis=1)\n",
    "        elif len(part_collection)==1:\n",
    "            if isinstance(part_collection[0], pd.DataFrame):\n",
    "                combinedata = part_collection[0].values\n",
    "            else:\n",
    "                combinedata = part_collection[0]\n",
    "        else:\n",
    "            print(\"No data available\")\n",
    "            break\n",
    "        print(len(combinedata))\n",
    "        # using converted feature vector to train classifier\n",
    "        # using Multinomial naive bayes\n",
    "        clf = MultinomialNB()\n",
    "        mnbaccuracy, mnbmarcof1 = k_fold_cv(combinedata, label, clf, k=10)\n",
    "        print(\"MNB Accuracy: \",mnbaccuracy)\n",
    "        print(\"MNB F1: \", mnbmarcof1)\n",
    "        all_mnb_accuracy.append(mnbaccuracy)\n",
    "        all_mnb_f1.append(mnbmarcof1)\n",
    "        # using SVM with linear kernal\n",
    "        clf = SVC(decision_function_shape='ovr', kernel='linear')\n",
    "        svcaccuracy, svcmarcof1 = k_fold_cv(combinedata, label, clf, k=10)\n",
    "        print(\"svc Accuracy: \",svcaccuracy)\n",
    "        print(\"svc F1: \", svcmarcof1)\n",
    "        all_svcLinear_accuracy.append(svcaccuracy)\n",
    "        all_svcLinear_f1.append(svcmarcof1)\n",
    "        # using logistic regression\n",
    "        clf = LogisticRegression(multi_class='ovr')\n",
    "        LRaccuracy, LRmarcof1 = k_fold_cv(combinedata, label, clf, k=10)\n",
    "        print(\"LR Accuracy: \",LRaccuracy)\n",
    "        print(\"LR F1: \", LRmarcof1)\n",
    "        all_LR_accuracy.append(LRaccuracy)\n",
    "        all_LR_f1.append(LRmarcof1)\n",
    "# write evaluation result to excel\n",
    "output = pd.DataFrame({'Name Group':allname,\"Class number\":num_class,\"per_class_size\":per_class_count, \n",
    "                       \"svc(linear) accuracy\":all_svcLinear_accuracy, \"svc(linear) macro f1\": all_svcLinear_f1, \n",
    "                       \"mnb accuracy\":all_mnb_accuracy, \"mnb macro f1\": all_mnb_f1,\n",
    "                       \"logistic regression accuracy\":all_LR_accuracy, \"logistic regression macro f1\": all_LR_f1})\n",
    "\n",
    "savePath = \"../result/\"+Dataset+\"/coauthor_only/\"\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "filename = \"2004_coauthor_only_\"+coauthor_emb_type+\"_threshold=\"+str(threshold)+\".csv\"\n",
    "output.to_csv(savePath+filename, encoding='utf-8',index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:36:48.029632Z",
     "start_time": "2018-12-02T02:36:48.005600Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "784\n",
      "784\n",
      "0.8431078927279118\n",
      "0.9095801418648304\n",
      "0.8294931099749167\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "from statistics import mean \n",
    "cleaned_mnb_accuracy = [x for x in all_mnb_accuracy if isinstance(x, float)]\n",
    "cleaned_svcLinear_accuracy = [x for x in all_svcLinear_accuracy if isinstance(x, float)]\n",
    "cleaned_lr_accuracy = [x for x in all_LR_accuracy if isinstance(x, float)]\n",
    "print(len(cleaned_mnb_accuracy))\n",
    "print(len(cleaned_svcLinear_accuracy))\n",
    "print(len(cleaned_lr_accuracy))\n",
    "print(mean(cleaned_mnb_accuracy))\n",
    "print(mean(cleaned_svcLinear_accuracy))\n",
    "print(mean(cleaned_lr_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:36:48.055636Z",
     "start_time": "2018-12-02T02:36:48.031377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "784\n",
      "784\n",
      "0.7449507529794926\n",
      "0.8770878958001022\n",
      "0.7213154764960485\n"
     ]
    }
   ],
   "source": [
    "# f1\n",
    "from statistics import mean \n",
    "# remove string from result\n",
    "cleaned_mnb_f1 = [x for x in all_mnb_f1 if isinstance(x, float)]\n",
    "cleaned_svcLinear_f1 = [x for x in all_svcLinear_f1 if isinstance(x, float)]\n",
    "cleaned_lr_f1 = [x for x in all_LR_f1 if isinstance(x, float)]\n",
    "print(len(cleaned_mnb_f1))\n",
    "print(len(cleaned_svcLinear_f1))\n",
    "print(len(cleaned_lr_f1))\n",
    "print(mean(cleaned_mnb_f1))\n",
    "print(mean(cleaned_svcLinear_f1))\n",
    "print(mean(cleaned_lr_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-29T21:26:31.930Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%who"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
