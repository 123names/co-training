{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vivek gupta0.txt', 'ana castro1.txt', 'amit patel.txt', 'jun chen2.txt', 'carmen torres0.txt', 'robert j young.txt', 'mikael svensson0.txt', 'marco ferrari1.txt', 'wei wang1.txt', 'peng zhang0.txt', 'martin wagner.txt', 'lei wang3.txt', 'michael wagner.txt', 'david g lloyd.txt', 'marco ferrari0.txt', 'carmen moreno.txt', 'jong hee chang.txt', 'chung-may yang1.txt', 'jacob john0.txt', 'jong hee chang0.txt', 'hao song.txt', 'wei lu0.txt', 'qin li0.txt', 'yongsheng liu.txt', 'kevin m. ryan.txt', 'jeremy m brown1.txt', 'alfredo martinez1.txt', 'yu-jun zhao.txt', 'yongsheng liu1.txt', 'jin young kim1.txt', 'yong wang1.txt', 'david g lloyd0.txt', 'jeremy m brown0.txt', 'vineet gupta1.txt', 'xin li.txt', 'vivek kumar1.txt', 'alfredo martinez.txt', 'wei lu.txt', 'yong liu0.txt', 'anna ferrari.txt', 'wei lu1.txt', 'feng liu1.txt', 'wei wang.txt', 'yu zhang1.txt', 'jeong hwan kim.txt', 'hong yang0.txt', 'david g lloyd1.txt', 'kyung su kim0.txt', 'jacob john.txt', 'fang liu.txt', 'jie zhang0.txt', 'qian wang1.txt', 'yong wang.txt', 'cheng luo.txt', 'lei wang2.txt', 'vineet gupta0.txt', 'wei wang3.txt', 'ana castro0.txt', 'yang wang.txt', 'fang liu0.txt', 'jeong hwan kim1.txt', 'qiang wang.txt', 'francisco j blanco.txt', 'wei xu0.txt', 'yu zhang.txt', 'bin liu1.txt', 'yang zhao.txt', 'cheng luo0.txt', 'bin liu0.txt', 'yu-jun zhao1.txt', 'ana castro.txt', 'wei wang4.txt', 'carmen moreno1.txt', 'bin liu.txt', 'yang zhao1.txt', 'vivek gupta.txt', 'ying liu1.txt', 'chung-may yang0.txt', 'marta crespo1.txt', 'jun zhang1.txt', 'wei xu.txt', 'wei xu1.txt', 'richard w morris.txt', 'yongsheng liu0.txt', 'peng zhang2.txt', 'lin yang1.txt', 'carmen moreno0.txt', 'michael wagner0.txt', 'sebastian wolf1.txt', 'chao liu.txt', 'feng xu1.txt', 'giovanni volpe.txt', 'francisco esteves.txt', 'qian wang0.txt', 'vineet gupta.txt', 'feng xu0.txt', 'hong yang1.txt', 'jin young kim.txt', 'jun chen1.txt', 'feng liu.txt', 'francisco j blanco0.txt', 'vivek kumar.txt', 'giovanni volpe0.txt', 'vivek kumar0.txt', 'fang liu1.txt', 'feng liu0.txt', 'sebastian wolf.txt', 'jin young kim0.txt', 'yang wang0.txt', 'yang zhao0.txt', 'john f marshall1.txt', 'jie zhang1.txt', 'pei-ming yang1.txt', 'vivek gupta1.txt', 'jong hee chang1.txt', 'anna ferrari1.txt', 'marta crespo0.txt', 'hao song1.txt', 'pei-ming yang.txt', 'jacob john1.txt', 'qian wang.txt', 'feng xu.txt', 'john f marshall.txt', 'kyung su kim1.txt', 'ying liu.txt', 'hao song0.txt', 'qin li.txt', 'mikael svensson1.txt', 'jun chen.txt', 'chao liu1.txt', 'alfredo martinez0.txt', 'kevin m. ryan0.txt', 'francisco j blanco1.txt', 'robert j young1.txt', 'ying zhang1.txt', 'anna ferrari0.txt', 'yang wang1.txt', 'yu zhang0.txt', 'peng zhang3.txt', 'yong liu.txt', 'jie zhang.txt', 'lu\\udcc3\\udcads alves0.txt', 'ying zhang.txt', 'peng zhang.txt', 'martin wagner0.txt', 'pei-ming yang0.txt', 'sebastian wolf0.txt', 'lin yang.txt', 'jun zhang.txt', 'lu\\udcc3\\udcads alves.txt', 'jun zhang0.txt', 'qiang wang0.txt', 'wei wang0.txt', 'xin li1.txt', 'michael wagner1.txt', 'lei wang0.txt', 'robert j young0.txt', 'john f marshall0.txt', 'yong liu1.txt', 'marta crespo.txt', 'amit patel0.txt', 'richard w morris1.txt', 'cheng luo1.txt', 'chao liu0.txt', 'ying liu2.txt', 'jeong hwan kim0.txt', 'francisco esteves0.txt', 'peng zhang1.txt', 'lin yang0.txt', 'carmen torres.txt', 'lu\\udcc3\\udcads alves1.txt', 'marco ferrari.txt', 'mikael svensson.txt', 'amit patel1.txt', 'martin wagner1.txt', 'michael wagner2.txt', 'yong wang0.txt', 'richard w morris0.txt', 'yu-jun zhao0.txt', 'lei wang.txt', 'xin li0.txt', 'hong yang.txt', 'ana castro2.txt', 'jun chen0.txt', 'wei wang2.txt', 'qin li1.txt', 'carmen torres1.txt', 'qiang wang1.txt', 'giovanni volpe1.txt', 'chung-may yang.txt', 'francisco esteves1.txt', 'lei wang1.txt', 'kevin m. ryan1.txt', 'jeremy m brown.txt', 'kyung su kim.txt', 'ying liu0.txt', 'ying zhang0.txt']\n",
      "['amit patel.txt', 'robert j young.txt', 'martin wagner.txt', 'michael wagner.txt', 'david g lloyd.txt', 'carmen moreno.txt', 'jong hee chang.txt', 'hao song.txt', 'yongsheng liu.txt', 'kevin m. ryan.txt', 'yu-jun zhao.txt', 'xin li.txt', 'alfredo martinez.txt', 'wei lu.txt', 'anna ferrari.txt', 'wei wang.txt', 'jeong hwan kim.txt', 'jacob john.txt', 'fang liu.txt', 'yong wang.txt', 'cheng luo.txt', 'yang wang.txt', 'qiang wang.txt', 'francisco j blanco.txt', 'yu zhang.txt', 'yang zhao.txt', 'ana castro.txt', 'bin liu.txt', 'vivek gupta.txt', 'wei xu.txt', 'richard w morris.txt', 'chao liu.txt', 'giovanni volpe.txt', 'francisco esteves.txt', 'vineet gupta.txt', 'jin young kim.txt', 'feng liu.txt', 'vivek kumar.txt', 'sebastian wolf.txt', 'pei-ming yang.txt', 'qian wang.txt', 'feng xu.txt', 'john f marshall.txt', 'ying liu.txt', 'qin li.txt', 'jun chen.txt', 'yong liu.txt', 'jie zhang.txt', 'ying zhang.txt', 'peng zhang.txt', 'lin yang.txt', 'jun zhang.txt', 'lu\\udcc3\\udcads alves.txt', 'marta crespo.txt', 'carmen torres.txt', 'marco ferrari.txt', 'mikael svensson.txt', 'lei wang.txt', 'hong yang.txt', 'chung-may yang.txt', 'jeremy m brown.txt', 'kyung su kim.txt']\n",
      "['11913376', '0.08125255', '-0.26923013', '0.12350058', '0.21943399', '0.59610617', '0.51254380', '0.22898267', '-0.10301466', '0.30326331', '0.10392465', '-0.53814095', '-0.71505260', '-0.35337681', '-0.32735440', '-0.33889845', '-0.08476824', '-0.00764674', '0.20305537', '-0.09811013', '0.11384773', '0.58976084', '0.55195481', '-0.11707792', '-0.30737293', '0.28930593', '-0.15793842', '0.07968465', '-0.64490777', '0.25303221', '0.13795526', '-0.59605944', '0.10993322', '0.22809988', '0.17154071', '-0.03190814', '0.78956383', '0.16617961', '0.13625665', '0.16641627', '-0.32460654', '0.54845387', '0.15805532', '0.42268327', '-0.47591615', '-0.90558976', '0.21361342', '0.68220812', '-0.50420576', '0.35892728', '-0.48103425', '-0.74120349', '0.26760584', '-0.45437792', '-0.74219644', '0.30243984', '0.64835525', '-0.79712594', '0.24432506', '0.04585288', '-0.47277302', '-0.29017797', '0.05076585', '0.53202695', '0.51363552', '0.47843507', '-0.37980878', '0.01940083', '-0.05815806', '0.22213708', '0.78560197', '-0.44785681', '0.46890551', '-0.20570593', '-0.43913123', '-0.59659898', '0.14616053', '-0.38186955', '-0.88546544', '-0.17453755', '0.01986482', '0.11819258', '-0.04635331', '0.10084460', '0.39913180', '-0.11412212', '-0.02457011', '-0.43758717', '-0.73223943', '-0.61845535', '-0.00799971', '0.74079585', '0.71827167', '-0.16311568', '0.21587248', '0.22008814', '-0.52290118', '0.26979542', '-0.06429942', '0.50549769', '0.67057085']\n",
      "['9495027', '0.46734467', '-0.49478102', '-0.02177235', '-0.00295819', '0.24680787', '0.11355068', '0.77916175', '-0.67775387', '0.16638432', '0.18014170', '-0.08343285', '-0.11152032', '0.61438423', '0.35218149', '-0.22572017', '-0.10624601', '-0.71314585', '0.08520909', '-0.00188732', '0.46030775', '0.33655217', '-0.08700058', '0.52785951', '0.65182328', '-0.17191702', '0.16373043', '0.04264121', '-0.25908113', '0.09841985', '-0.28036603', '0.09219169', '0.33913612', '0.40951988', '-0.02538707', '0.04970863', '0.42290160', '0.72114497', '0.27276611', '-0.27719772', '-0.05005030', '-0.05722509', '0.09947801', '0.45348775', '0.10606055', '-0.70664281', '0.30583522', '0.23149765', '-0.18131909', '-0.03416862', '0.22648448', '0.02437292', '0.03382649', '-0.03163935', '-0.24046949', '-0.68594646', '-0.12041662', '-0.33918905', '-0.16127361', '0.27705750', '0.25891975', '-0.00088351', '-0.39151862', '-0.02331083', '-0.22132848', '0.40771112', '0.00409657', '0.64820319', '0.35636470', '-0.26906487', '-0.11914618', '-0.47875264', '-0.21651788', '-0.28902164', '0.17677231', '-0.48388788', '0.23675539', '0.24094556', '0.26374418', '-0.24995805', '0.11080347', '-0.05691404', '-0.12485087', '0.09261262', '0.37103492', '-0.39172539', '-0.19109701', '-0.70991713', '-0.20962450', '-0.07259109', '0.20274536', '-0.03063696', '0.21069485', '-0.00284787', '0.07928653', '0.13188533', '-0.61890888', '0.14022115', '-0.14196190', '-0.12602659', '-0.10111793']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# collect data\n",
    "# ../Data/DataForClassification/p2v/\n",
    "fileDir = \"../Data/DataForClassification/d2v/\"\n",
    "fileList = os.listdir(fileDir)\n",
    "print(fileList)\n",
    "\n",
    "# loop through files in directory \n",
    "# add name to name list\n",
    "name_list = []\n",
    "for file in fileList:\n",
    "    if not file.startswith('.'):\n",
    "        if not re.match(r'\\D*\\d+.txt$', file):\n",
    "            name_list.append(file)\n",
    "print(name_list)\n",
    "\n",
    "# for name in namelist:\n",
    "#     int counter = 0;\n",
    "#     for file in fileList:\n",
    "#         if not file.startswith('.'):\n",
    "            \n",
    "# hard code to read the file one by one\n",
    "# author as positive sample, other as all samples\n",
    "author_features = []\n",
    "other_features = []\n",
    "with open(fileDir+\"michael wagner0.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        author_features.append(line.strip().split(\" \"))\n",
    "\n",
    "with open(fileDir+\"michael wagner.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        other_features.append(line.strip().split(\" \"))\n",
    "        \n",
    "print(author_features[0])\n",
    "print(other_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "# size of each class\n",
    "print(len(author_features))\n",
    "print(len(other_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "# dimension of each class\n",
    "print(len(author_features[0]))\n",
    "print(len(other_features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative sample size: 239\n",
      "          0            1            2            3            4           5  \\\n",
      "0  11913376   0.08125255  -0.26923013   0.12350058   0.21943399  0.59610617   \n",
      "1  12973727  -0.12425368  -0.61719823  -0.14773583   0.29436713  0.85312623   \n",
      "2  15857247   0.39831164  -0.19049157   0.66954857   1.00282347  1.09913301   \n",
      "3  17081057  -0.65990341  -0.43371347  -0.04118128  -0.02935118  0.15726706   \n",
      "4  18333798  -0.07879562  -0.08480105   0.02117494   0.10787108  0.07532892   \n",
      "\n",
      "             6            7            8           9  ...            92  \\\n",
      "0   0.51254380   0.22898267  -0.10301466  0.30326331  ...    0.71827167   \n",
      "1  -0.61940527   0.45467871   0.21129733  0.66855842  ...    0.79690182   \n",
      "2  -0.13993333  -0.47397777   0.27701509  0.53899837  ...   -0.08898772   \n",
      "3  -0.41299382   0.11691877  -0.04782787  0.46951130  ...    0.32706594   \n",
      "4  -0.08695129   0.08676738  -0.04744303  0.11769948  ...    0.07910561   \n",
      "\n",
      "            93          94          95           96           97           98  \\\n",
      "0  -0.16311568  0.21587248  0.22008814  -0.52290118   0.26979542  -0.06429942   \n",
      "1   0.29094929  0.49219787  0.63869846   0.37419441  -0.09449704  -0.10859369   \n",
      "2   0.40275553  0.52501118  0.06193342   0.03583403   0.40444168  -0.10832498   \n",
      "3   0.26128602  0.87767690  0.42375797   0.17030278   0.09205000   0.12618423   \n",
      "4  -0.06221189  0.11161185  0.03752463  -0.00726667   0.02712237  -0.04490315   \n",
      "\n",
      "            99         100 label  \n",
      "0   0.50549769  0.67057085     0  \n",
      "1   0.21429290  0.56901336     0  \n",
      "2   0.36142290  0.39524740     0  \n",
      "3  -0.05405710  0.37429082     0  \n",
      "4   0.09112431  0.04374575     0  \n",
      "\n",
      "[5 rows x 102 columns]\n",
      "          0            1            2            3           4            5  \\\n",
      "0  26921674   0.05585526  -0.97248983  -0.04392405  0.67226040   0.16188915   \n",
      "1  21546306  -0.06504705  -0.12055077   0.05196844  0.43604615  -0.01156803   \n",
      "2  15632447  -0.28321263  -0.57074463  -0.02944518  0.58251143  -0.16410480   \n",
      "3  21787302  -0.14465332  -0.15866654   0.57298177  1.27661133   1.03167176   \n",
      "4  16872410  -0.04977068  -0.25041869   0.37148300  0.26183793   0.45407793   \n",
      "\n",
      "             6            7            8           9  ...            92  \\\n",
      "0  -0.06074660  -0.13638888  -0.21242382  0.43600142  ...   -0.00748203   \n",
      "1   0.00939985   0.21567065  -0.63395452  0.27833509  ...    0.10073362   \n",
      "2  -0.15531482   0.02657143  -0.77017611  0.17695531  ...   -0.03497310   \n",
      "3   0.35466319  -0.16790181  -0.16323005  0.34691557  ...   -0.35527223   \n",
      "4  -0.46868491   0.22931094  -1.22775614  0.29698139  ...    0.09529300   \n",
      "\n",
      "            93          94           95           96           97  \\\n",
      "0   0.03724948  0.54756647  -0.15713468   0.46984506   0.11222737   \n",
      "1  -0.07779401  0.10192204  -0.08069392  -0.19091374  -0.30695450   \n",
      "2  -0.24164394  0.53895414   0.10982801  -0.46430320  -0.11559630   \n",
      "3   0.82920098  0.25273031   0.42378470  -0.00696326   0.10710710   \n",
      "4  -0.14782690  0.18470450  -0.33937085  -0.18597987  -0.40862331   \n",
      "\n",
      "            98           99          100 label  \n",
      "0   0.35020852  -0.08090507   0.20800859     1  \n",
      "1  -0.27817491  -0.05278816   0.12604131     1  \n",
      "2  -0.54457808   0.10003651   0.33495826     1  \n",
      "3   0.59087652   0.11081164   0.30794311     0  \n",
      "4  -0.73139060  -0.12778245  -0.19971152     1  \n",
      "\n",
      "[5 rows x 102 columns]\n",
      "Total sample size and shape:  (32, 100)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# remove author(positive sample) from other(negative sample)\n",
    "allPaperVectors = [x for x in other_features if x not in author_features]\n",
    "print(\"Negative sample size:\", len(allPaperVectors))\n",
    "\n",
    "# random take sample from all the papers and treat it as class 2\n",
    "# random sample will have same size with author's size\n",
    "if len(author_features)>len(allPaperVectors):\n",
    "    randomSample = allPaperVectors\n",
    "else:\n",
    "    randomSample = random.sample(allPaperVectors, len(author_features))\n",
    "\n",
    "classOne = pd.DataFrame(author_features)\n",
    "classOne[\"label\"] = 0\n",
    "#print(classOne[:2:])\n",
    "\n",
    "classTwo = pd.DataFrame(randomSample)\n",
    "classTwo[\"label\"] = 1\n",
    "#print(classTwo[:2:])\n",
    "\n",
    "# combine data from different class get all data\n",
    "combinedData = pd.concat([classOne, classTwo])\n",
    "print(combinedData[:5])\n",
    "combinedData = combinedData.sample(frac=1).reset_index(drop=True)\n",
    "print(combinedData[:5])\n",
    "# take the paper id out\n",
    "paperID = combinedData[0]\n",
    "# split data and label\n",
    "data = combinedData.drop([0,'label'], axis=1)\n",
    "label = combinedData['label']\n",
    "print(\"Total sample size and shape: \",data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngh0AAkOwA0Bg/h9ia0TK4X+vTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde495bc4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Principal Component Analysis (PCA) applied to this data identifies the combination of attributes\n",
    "# (principal components, or directions in the feature space) that account for the most variance in the data.\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "pca = PCA(n_components=2)\n",
    "pca_transformed = pd.DataFrame(pca.fit_transform(X=data, y=label))\n",
    "pca_transformed[\"label\"] = label\n",
    "#print(pca_transformed)\n",
    "plt.scatter(pca_transformed[label==0][0], pca_transformed[label==0][1], label='Positive sample', c='red')\n",
    "plt.scatter(pca_transformed[label==1][0], pca_transformed[label==1][1], label='Other', c='blue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis (LDA) tries to identify attributes that account for the most variance between classes.\n",
    "# In particular, LDA, in contrast to PCA, is a supervised method, using known class labels.\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis(n_components=2) #2-dimensional LDA\n",
    "lda_transformed = pd.DataFrame(lda.fit(data, label).transform(data))\n",
    "#print(lda_transformed)\n",
    "# plt.scatter(lda_transformed[label==0][0], lda_transformed[label==0][1], label='Class 1', c='red')\n",
    "# plt.scatter(lda_transformed[label==1][0], lda_transformed[label==1][1], label='Class 2', c='blue')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0            1  label\n",
      "0  -1235.446045   361.705780      1\n",
      "1    597.428589  -466.834808      1\n",
      "2    948.410889  -788.553894      1\n",
      "3   2330.454102  2066.631104      0\n",
      "4    189.577927  -749.159546      1\n",
      "5    -61.791752   842.576965      0\n",
      "6  -1092.095337  1037.177979      0\n",
      "7    275.081360   575.682068      1\n",
      "8    226.479767  -281.133148      1\n",
      "9   -123.146088   338.782684      0\n",
      "10   297.486115   146.487076      0\n",
      "11  -189.570190  -549.430420      1\n",
      "12  -912.685547  -138.541443      0\n",
      "13   691.650208    14.423253      0\n",
      "14  1040.896362   908.262756      1\n",
      "15 -1781.895630  -580.532104      0\n",
      "16 -1108.685913  -698.671326      0\n",
      "17  -485.050262  1089.960327      0\n",
      "18  -535.439453   118.137543      1\n",
      "19    50.849743  1319.978516      1\n",
      "20  -836.736084   474.986389      0\n",
      "21 -1381.180420   -97.401192      1\n",
      "22  -453.278595   625.655762      0\n",
      "23  -187.959778 -1151.591431      0\n",
      "24  1170.498413   299.815979      0\n",
      "25   497.207794  1031.871582      0\n",
      "26  -534.999939  -337.040924      1\n",
      "27   709.908203   493.296875      1\n",
      "28  -602.862671  -835.620544      1\n",
      "29   468.886322 -1122.555908      0\n",
      "30  -136.011810   -83.818832      1\n",
      "31  1107.217407  -239.946014      1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njaQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fddc660b1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import Normalizer\n",
    "tsne_transformed = TSNE(n_components=2, init = \"pca\").fit_transform(data)\n",
    "tsne_transformed_normalized = Normalizer(norm='l2').fit_transform(tsne_transformed)\n",
    "tsne_transformed_normalized = pd.DataFrame(tsne_transformed)\n",
    "tsne_transformed_normalized[\"label\"] = label\n",
    "print(tsne_transformed_normalized)\n",
    "plt.scatter(tsne_transformed_normalized[label==0][0], tsne_transformed_normalized[label==0][1], label='Positive sample', c='red')\n",
    "plt.scatter(tsne_transformed_normalized[label==1][0], tsne_transformed_normalized[label==1][1], label='Other', c='blue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "def k_fold_cv(data, label, classifier, clfname):\n",
    "    kf = KFold(n_splits=10, shuffle=False)\n",
    "    roundf1 = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        label_train, test_true_label = label.iloc[train_index], label.iloc[test_index]\n",
    "        # fit data to svm\n",
    "        classifier.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = classifier.predict(data_test)\n",
    "        # find out which sample cause the issue\n",
    "        print(\"Pred: \",label_pred)\n",
    "        print(\"True: \", test_true_label.values.tolist())\n",
    "        print(\"Mislabeled sample: \",end='')\n",
    "        for i in range(len(test_true_label)):\n",
    "            if(label_pred[i]!=test_true_label[test_index[i]]):\n",
    "                print(paperID[test_index[i]]+\",\",end='')\n",
    "        print()\n",
    "        # find round confusion matrix\n",
    "        metrics.confusion_matrix(test_true_label, label_pred).ravel()\n",
    "        roundf1.append(f1_score(test_true_label, label_pred,average='micro'))\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "\n",
    "    print(\"Classifier: {name}\".format(name=clfname))\n",
    "    f1 = np.average(roundf1)\n",
    "    print(\"F1: \", f1)\n",
    "    # return ppv, npv, specificity, sensitivity, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Pred:  [1 0 0 0]\n",
      "True:  [0, 0, 0, 0]\n",
      "Mislabeled sample: 18333798,\n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: 26330430,\n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: 24450576,\n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Classifier: SVM linear\n",
      "F1:  0.9083333333333332\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Pred:  [1 0 0 0]\n",
      "True:  [0, 0, 0, 0]\n",
      "Mislabeled sample: 18333798,\n",
      "Pred:  [1 1 0 1]\n",
      "True:  [1, 1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 1]\n",
      "True:  [0, 1, 1]\n",
      "Mislabeled sample: 26330430,\n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 1]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 1 0]\n",
      "True:  [1, 1, 0]\n",
      "Mislabeled sample: \n",
      "Pred:  [1 0 1]\n",
      "True:  [1, 0, 0]\n",
      "Mislabeled sample: 24450576,\n",
      "Pred:  [0 1 0]\n",
      "True:  [0, 1, 0]\n",
      "Mislabeled sample: \n",
      "Classifier: SVM rbf\n",
      "F1:  0.9083333333333332\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create linear SVM model\n",
    "linear_svc = svm.SVC(kernel='linear', class_weight='balanced', probability=True)\n",
    "print(linear_svc)\n",
    "\n",
    "# fit model and do 10-fold cv\n",
    "k_fold_cv(data, label, linear_svc, \"SVM linear\")\n",
    "\n",
    "\n",
    "'''\n",
    "# compute the distance to decision boundry (Not same as confidence measure)\n",
    "Distance = linear_svc.decision_function(allDatas)\n",
    "\n",
    "# computer the confidence measure (Platt scaling: transforming the outputs of a \n",
    "# classification model into a probability distribution over classes)\n",
    "# P(class/input) = 1 / (1 + exp(A * f(input) + B))\n",
    "# P(class/input) is the probability that “input” belongs to “class” \n",
    "# and f(input) is the signed distance of the input datapoint from the boundary,\n",
    "# which is basically the output of “decision_function”. \n",
    "\n",
    "proba = linear_svc.predict_proba(allDatas)\n",
    "\n",
    "'''\n",
    "\n",
    "# create rbf SVM model with C=10 where (C*Error) is added into minimize function\n",
    "# C big means error matter more\n",
    "rbf_svc = svm.SVC(kernel='rbf', C=100)\n",
    "print(rbf_svc)\n",
    "\n",
    "# fit model and do 10-fold cv\n",
    "k_fold_cv(data, label, rbf_svc, \"SVM rbf\")\n",
    "\n",
    "# # apply the linear svc for all the data in environment\n",
    "# label_pred = rbf_svc.predict(allDatas)\n",
    "# uniqueItems, counts = np.unique(label_pred, return_counts=True)\n",
    "# print(dict(zip(uniqueItems, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
