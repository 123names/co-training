{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First extract all embeddings and get ride of bad formated ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T21:10:21.123765Z",
     "start_time": "2019-01-22T21:03:41.660864Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------- extract all citation embedding ------------ # \n",
    "setting = \"n2v\"\n",
    "Dataset = \"pubmed\"\n",
    "\n",
    "FilesDir = \"vectors/\"+Dataset+\"/\"+setting+\"/data=Meta-alg=N2V-l2=1.0-n2v_p=0.85-iteration=100-no_self_predict=1-idx=0.emb\"\n",
    "# bad formated embedding, need to be cleaned\n",
    "def RepresentsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "n2v_emb = []\n",
    "\n",
    "with open(FilesDir, 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        read_data = line.split(\" \")\n",
    "        if len(read_data)==101 and RepresentsInt(read_data[0]) and len(read_data[0])<=8:\n",
    "            if not read_data[0].startswith('0'):\n",
    "                paper_id = int(read_data[0])\n",
    "                paper_Vectors = [paper_id]+read_data[1:]\n",
    "                n2v_emb.append(paper_Vectors)\n",
    "f.close()\n",
    "n2v_emb = n2v_emb[1:]\n",
    "print(\"Total vector records:\",len(n2v_emb))\n",
    "print(len(n2v_emb[0]))\n",
    "print(n2v_emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T21:21:48.113914Z",
     "start_time": "2019-01-22T21:10:21.126138Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------- sort embedding ------------------- #\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(n2v_emb)\n",
    "print(df[:5])\n",
    "sorted_df = df.sort_values(df.columns[0])\n",
    "sorted_df = sorted_df.reset_index(drop=True)\n",
    "del df\n",
    "print(sorted_df[:5])\n",
    "print(len(sorted_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T21:29:55.177390Z",
     "start_time": "2019-01-22T21:21:48.116715Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------------save sorted n2v to file ------------------------- #\n",
    "import csv\n",
    "sorted_df.to_csv(\"vectors/\"+Dataset+\"/n2v/all_n2v.txt\", header=None, index=None, sep=' ',line_terminator=\"\",\n",
    "                 quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then we extract only n2v embedding we needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T21:35:37.821183Z",
     "start_time": "2019-01-22T21:35:15.418282Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# ------------- extract pid we want ---------------------- #\n",
    "wanted_pids = []\n",
    "fileDir = \"Data/\"+Dataset+\"/canopies/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "for file in listfiles:\n",
    "    with open(fileDir+file, 'r', encoding = 'utf8') as f:\n",
    "        for line in f:\n",
    "            read_data = line.split(\"\\t\")\n",
    "            # some record's doi contain \\r or \\n character in which creating issue, since we do not use those, ignore it\n",
    "            if(len(read_data)==13 or len(read_data)==12):\n",
    "                wanted_pids.append(int(read_data[0]))\n",
    "            else:\n",
    "                print(len(read_data))\n",
    "print(len(wanted_pids))\n",
    "print(wanted_pids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T21:35:46.359661Z",
     "start_time": "2019-01-22T21:35:44.765751Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wanted_pids = list(sorted(set(wanted_pids)))\n",
    "print(len(wanted_pids))\n",
    "print(wanted_pids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T21:55:30.115440Z",
     "start_time": "2019-01-22T21:50:53.260557Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to np array\n",
    "all_embeddings = sorted_df.values\n",
    "del sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T23:12:19.778300Z",
     "start_time": "2019-01-22T21:56:55.371069Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------- select citation contain embedding used in experiment -------- #\n",
    "extracted_embedding = []\n",
    "num_fail_extract = 0\n",
    "for emb in all_embeddings:\n",
    "    if(len(wanted_pids)==0):\n",
    "        break\n",
    "    while (wanted_pids[0]<=int(emb[0])):\n",
    "        if wanted_pids[0]==int(emb[0]):\n",
    "            extracted_embedding.append(emb)\n",
    "            wanted_pids.remove(int(emb[0]))\n",
    "        elif (wanted_pids[0]<int(emb[0])):\n",
    "            # remove paper that not in all dataset\n",
    "            print(wanted_pids[0], \" : \",emb[0])\n",
    "            wanted_pids.remove(wanted_pids[0])\n",
    "            num_fail_extract+=1\n",
    "        if len(wanted_pids)==0:\n",
    "            break\n",
    "print(\"Total paper fail to find: \",num_fail_extract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T23:38:06.127869Z",
     "start_time": "2019-01-22T23:38:06.121181Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(extracted_embedding))\n",
    "print(extracted_embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T23:55:30.868977Z",
     "start_time": "2019-01-22T23:54:41.071303Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------------save selected sorted n2v to file ------------------------- #\n",
    "# export needed embedding to txt file\n",
    "newfileDir = \"vectors/\"+Dataset+\"/n2v/\"\n",
    "if not os.path.exists(newfileDir):\n",
    "    os.makedirs(newfileDir)\n",
    "    \n",
    "np.savetxt(newfileDir+\"n2v.txt\", extracted_embedding, delimiter=' ', fmt=\"%s\", newline='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
