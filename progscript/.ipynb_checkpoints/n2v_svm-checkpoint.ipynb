{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vector records: 8602916\n",
      "['22516865', '0.0109272', '0.126011', '0.186979', '0.0496719', '0.0373553', '0.0458918', '-0.119893', '0.217118', '0.0524591', '0.237477', '0.191269', '-0.0277055', '0.0290957', '-0.0366833', '0.118964', '0.0654807', '-0.0335345', '-0.0900123', '0.128621', '0.0561669', '-0.087823', '-0.0882296', '0.0740289', '0.082104', '0.0269581', '-0.0346502', '0.0153376', '0.104666', '0.0908716', '-0.085694', '-0.111344', '0.0787209', '-0.17003', '-0.103366', '-0.0832094', '-0.210496', '0.153037', '-0.0342884', '0.0698413', '-0.0719641', '-0.0535707', '0.172399', '0.106226', '-0.0593672', '-0.0348048', '-0.0863189', '-0.0801566', '-0.0665761', '0.0673258', '0.0306541', '-0.0896316', '-0.00800971', '-0.174798', '-0.0252528', '0.0098563', '0.0230368', '0.0282268', '-0.0366493', '-0.131323', '0.0318188', '-0.00778704', '-0.0608064', '-0.0860078', '0.215632', '0.0209927', '-0.0953191', '-0.191736', '-0.0741615', '0.151972', '-0.0522046', '-0.11081', '0.134878', '0.090797', '0.0160238', '0.113017', '0.196071', '-0.0598695', '-0.181981', '-0.0217668', '0.165394', '0.0724198', '0.0967185', '-0.115696', '-0.104803', '0.231757', '-0.0871117', '-0.0397107', '0.137358', '-0.083055', '-0.226604', '0.0186784', '-0.0608683', '-0.0177875', '0.082095', '-0.00222851', '-0.137642', '-0.0848053', '0.165064', '-0.022831', '0.240943\\n']\n"
     ]
    }
   ],
   "source": [
    "# extract different view of data\n",
    "# view two, node2vec\n",
    "setting = \"n2v\"\n",
    "\n",
    "viewTwoFilesDir = \"../Data/vectors/\"+setting+\"/data=Meta-alg=N2V-l2=1.0-n2v_p=0.85-iteration=100-no_self_predict=1-idx=0.emb\"\n",
    "viewTwoVectors = []\n",
    "\n",
    "with open(viewTwoFilesDir, 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        read_data = line.split(\" \")\n",
    "        if(len(read_data[0])<=8):\n",
    "            paper_Vectors = read_data\n",
    "            viewTwoVectors.append(paper_Vectors)\n",
    "f.close()\n",
    "viewTwoVectors = viewTwoVectors[1:]\n",
    "print(\"Total vector records:\",len(viewTwoVectors))\n",
    "print(viewTwoVectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chung-may yang.txt', 'chung-may yang0.txt', 'chung-may yang1.txt', 'david g lloyd.txt', 'david g lloyd0.txt', 'david g lloyd1.txt', 'jeong hwan kim.txt', 'jeong hwan kim0.txt', 'jeong hwan kim1.txt', 'kevin m. ryan.txt', 'kevin m. ryan0.txt', 'kevin m. ryan1.txt', 'lei wang.txt', 'lei wang0.txt', 'lei wang1.txt', 'michael wagner.txt', 'michael wagner0.txt', 'michael wagner1.txt']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "# collect data\n",
    "fileDir = \"../Data/filteredSameNameAuthor/filter=30/\"\n",
    "fileList = os.listdir(fileDir)\n",
    "fileList.sort()\n",
    "print(fileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove author(positive sample) from other(negative sample)\n",
    "import random\n",
    "def extractNegativeSample(positiveSample, allSample):\n",
    "    negativeSample = [x for x in allSample if x not in positiveSample]\n",
    "    print(\"Total negative sample size:\", len(negativeSample))\n",
    "    return negativeSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect class vectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extractVectors(author_pids, NegativeSample_pid, allPaperVectors):\n",
    "    # extract class one vectors\n",
    "    author_features = []\n",
    "    for pid in author_pids:\n",
    "         for paper_Vectors in allPaperVectors:\n",
    "            if(paper_Vectors[0] == pid):\n",
    "                author_features.append(paper_Vectors)\n",
    "    print(\"Positive sample size: \", len(author_features))\n",
    "    classOne = pd.DataFrame(author_features)\n",
    "    classOne[\"label\"] = 0\n",
    "    # extract class two vectors\n",
    "    other_features = []\n",
    "    for pid in NegativeSample_pid:\n",
    "        for paper_Vectors in allPaperVectors:\n",
    "            if(paper_Vectors[0] == pid):\n",
    "                other_features.append(paper_Vectors)\n",
    "    print(\"Negative sample size: \", len(other_features))\n",
    "    classTwo = pd.DataFrame(other_features)\n",
    "    classTwo[\"label\"] = 1\n",
    "    return classOne, classTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine data from different class get all data\n",
    "def combineClassesData(classOne,classTwo):\n",
    "    combinedData = pd.concat([classOne, classTwo])\n",
    "    combinedData = combinedData.sample(frac=1).reset_index(drop=True)\n",
    "    combinedData[0] = pd.to_numeric(combinedData[0], errors='coerce')\n",
    "    return combinedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score,accuracy_score)\n",
    "# cross validation\n",
    "def k_fold_cv(data, label, classifier, k=10):\n",
    "    kf = KFold(n_splits=k, shuffle=False)\n",
    "    allTrueLabel = []\n",
    "    allPredLabel = []\n",
    "    for counter,(train_index, test_index) in enumerate(kf.split(data)):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        label_train, test_true_label = label.iloc[train_index], label.iloc[test_index]\n",
    "        # fit data to svm\n",
    "        classifier.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = classifier.predict(data_test)\n",
    "        allTrueLabel.extend(test_true_label)\n",
    "        allPredLabel.extend(label_pred)\n",
    "#         # get predict proba\n",
    "#         proba = classifier.predict_proba(data_test)\n",
    "        # find out which sample cause the issue\n",
    "        print(\"Pred: \",label_pred)\n",
    "        print(\"True: \", test_true_label.values.tolist())\n",
    "        print(\"Mislabeled sample: \",end='')\n",
    "        for i in range(len(test_true_label)):\n",
    "            if(label_pred[i]!=test_true_label[test_index[i]]):\n",
    "                print(paperID[test_index[i]]+\",\",end='')\n",
    "        print()\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "\n",
    "    accuracy = accuracy_score(allTrueLabel, allPredLabel)\n",
    "    f1 = f1_score(allTrueLabel, allPredLabel,average='binary')\n",
    "    precision = precision_score(allTrueLabel, allPredLabel)\n",
    "    recall = recall_score(allTrueLabel, allPredLabel)\n",
    "    tn,fp,fn,tp = metrics.confusion_matrix(allTrueLabel, allPredLabel).ravel()\n",
    "    \n",
    "    print(\"Classifier: \",classifier)\n",
    "    print(metrics.classification_report(allTrueLabel, allPredLabel))\n",
    "    print(metrics.confusion_matrix(allTrueLabel, allPredLabel).ravel())\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print(\"F1: \", f1)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    \n",
    "    return accuracy, f1, precision, recall, tn, fp, fn, tp\n",
    "    # return ppv, npv, specificity, sensitivity, accuracy, f1proba = linear_svc.predict_proba(allDatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['27321135', '27078635', '26996321', '26301538', '25464845', '24615769', '25010185', '24449339', '25044429', '23913257', '24019075', '23322720', '24290358', '24139041', '22554080', '21956564', '22662873', '21805546', '21732687', '21681861', '21751313', '21926996', '21545173', '20872394', '20385807', '19318213', '19764747', '19668857', '19165727', '18426210', '18556466', '17603477', '17406421', '16689635', '16956756', '15840835', '15599909', '15556995', '15378068', '12580587', '12779328', '12518054', '14576413', '12537491', '12515477', '11866580', '12154230', '12148987', '12244330', '12120285', '12203503', '11564556', '11313494']\n",
      "27321135\n"
     ]
    }
   ],
   "source": [
    "# hard code to read the file one by one\n",
    "# store the features for classification\n",
    "author_pids = []\n",
    "other_pids = []\n",
    "# author as positive sample, other as all samples\n",
    "with open(fileDir+\"lei wang0.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        author_pids.extend(line.strip().split(\" \"))\n",
    "\n",
    "with open(fileDir+\"lei wang.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        other_pids.extend(line.strip().split(\" \"))\n",
    "        \n",
    "print(author_pids)\n",
    "print(other_pids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative sample size: 64\n",
      "Choicen negative sample  64\n"
     ]
    }
   ],
   "source": [
    "# extract negative Sample\n",
    "NegativeSample_pid = extractNegativeSample(author_pids, other_pids)\n",
    "print(\"Choicen negative sample \", len(NegativeSample_pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample size:  50\n",
      "Negative sample size:  62\n",
      "(50, 102)\n",
      "(62, 102)\n"
     ]
    }
   ],
   "source": [
    "classOne, classTwo = extractVectors(author_pids,NegativeSample_pid,viewTwoVectors)\n",
    "print(classOne.shape)\n",
    "print(classTwo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-641be93d0ed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaperID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombineClassesData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassOne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassTwo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "paperID, data, label = combineClassesData(classOne, classTwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_svc = svm.SVC(kernel='linear', class_weight='balanced', probability=True,cache_size=4000)\n",
    "accuracy, f1, precision, recall, tn, fp, fn, tp= k_fold_cv(data, label, linear_svc,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
