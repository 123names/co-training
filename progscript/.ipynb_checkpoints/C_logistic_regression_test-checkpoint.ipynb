{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chung-may yang1.txt', 'wei lu0.txt', 'yong wang1.txt', 'david g lloyd0.txt', 'wei lu1.txt', 'feng liu1.txt', 'david g lloyd1.txt', 'jeong hwan kim1.txt', 'chung-may yang0.txt', 'michael wagner0.txt', 'feng liu0.txt', 'hao song1.txt', 'hao song0.txt', 'kevin m. ryan0.txt', 'michael wagner1.txt', 'lei wang0.txt', 'jeong hwan kim0.txt', 'yong wang0.txt', 'lei wang1.txt', 'kevin m. ryan1.txt']\n",
      "['15599909', '-0.232623', '-0.12317', '-0.178615', '-0.120828', '-0.0637316', '0.119655', '-0.136511', '-0.012849', '-0.125184', '0.0461908', '0.0581749', '-0.183963', '-0.0459688', '0.19452', '-0.0170126', '-0.142147', '0.066843', '0.0642291', '0.00959536', '-0.107407', '0.0097539', '0.0416746', '-0.103548', '0.0770354', '0.108264', '0.0566145', '-0.0668466', '0.163799', '0.0729433', '-0.000337214', '-0.161726', '0.046857', '0.0794689', '-0.0573545', '-0.035842', '-0.0549588', '0.0425291', '-0.0653112', '0.0527278', '0.0105899', '-0.15386', '-0.104491', '-0.0575352', '-0.113251', '-0.0697307', '0.0515379', '-0.0936607', '0.0598422', '-0.0820808', '-0.0636461', '0.0354209', '-0.0147456', '0.119361', '-0.0330736', '0.056727', '-0.165324', '-0.0327852', '0.0489133', '0.0677268', '-0.245867', '0.0293898', '-0.0616188', '-0.040249', '-0.205614', '0.0825651', '0.0415449', '0.122681', '-0.231099', '0.108181', '-0.0763333', '0.0119602', '-0.24921', '0.0784226', '-0.0935032', '0.0334085', '-0.0857513', '0.0657114', '0.111908', '0.117492', '0.168683', '0.0201762', '-0.0189834', '0.0308606', '-0.0884006', '-0.0247744', '0.00208677', '0.0574192', '0.104499', '0.00580749', '-0.182603', '0.00696503', '0.037431', '-0.0301263', '-0.128484', '-0.0433902', '0.0996642', '-0.118848', '0.00068486', '-0.0493116', '0.00573114']\n",
      "['20118463', '-0.260863', '-0.0575147', '-0.20865', '-0.06824', '-0.0462675', '0.158533', '-0.103522', '0.0818297', '-0.054455', '0.0763776', '-0.112115', '-0.0312639', '-0.0535294', '0.148288', '-0.0483862', '-0.182657', '0.0290918', '0.113457', '0.0408922', '0.151185', '0.141287', '0.000903907', '0.0310395', '0.154702', '0.0948534', '-0.0197563', '0.0063923', '0.0528762', '0.112095', '-0.0673987', '-0.18505', '0.0861527', '0.0433998', '-0.0521172', '-0.0527875', '0.132237', '-0.119259', '-0.188731', '-0.119535', '0.0908325', '-0.0874132', '-0.0538344', '-0.0218321', '-0.0830512', '-0.151364', '-0.174384', '-0.096629', '-0.0126548', '-0.00266152', '-0.0609014', '0.0111415', '-0.0461712', '0.0617766', '-0.0220772', '0.134287', '-0.125483', '0.0642811', '-0.0330317', '-0.0505816', '-0.000657477', '0.0962274', '-0.0992277', '0.0278588', '-0.142329', '-0.0691681', '-0.0389713', '0.0137012', '-0.0543299', '-0.108635', '-0.0532416', '-0.0513788', '-0.0235441', '0.230458', '-0.0754578', '0.0485878', '-0.0157642', '0.0227683', '-0.19018', '0.0321877', '0.0531086', '-0.0426352', '-0.118388', '0.0774679', '-0.116677', '-0.0588731', '-0.0221933', '-0.06306', '-0.0914483', '0.0717639', '0.0366791', '-0.00220658', '-0.0251809', '-0.0671998', '-0.103334', '-0.148648', '-0.0564627', '-0.206351', '0.0359273', '-0.227927', '0.0661824']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "Dataset = \"pubmed\"\n",
    "# collect data\n",
    "# ../Data/\"+Dataset+\"/DataForClassification/d2v/\n",
    "fileDir = \"../Data/\"+Dataset+\"/DataForClassification/p2v/\"\n",
    "fileList = os.listdir(fileDir)\n",
    "print(fileList)\n",
    "\n",
    "# # auto method that go through all the file in directory\n",
    "# for file in fileList:\n",
    "#     if not file.startswith('.'):\n",
    "#         if file.endswith(\".txt\"):\n",
    "#             file = file[:-4]\n",
    "\n",
    "# hard code to read the file one by one\n",
    "author0 = []\n",
    "author1 = []\n",
    "with open(fileDir+\"lei wang0.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        author0.append(line.strip().split(\" \"))\n",
    "\n",
    "with open(fileDir+\"lei wang1.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        author1.append(line.strip().split(\" \"))\n",
    "print(author0[0])\n",
    "print(author1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# size of each class\n",
    "print(len(author0))\n",
    "print(len(author1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "# number of features (dimension)\n",
    "print(len(author0[0]))\n",
    "print(len(author1[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0          1           2            3           4            5  \\\n",
      "0  15599909  -0.232623    -0.12317    -0.178615   -0.120828   -0.0637316   \n",
      "1  15378068  -0.176372  -0.0831695    -0.153102  -0.0994948  -0.00322887   \n",
      "2  16689635  -0.153682  -0.0443485    -0.107922   -0.139944   -0.0898169   \n",
      "3  12203503  -0.151313  -0.0738476  -0.00177253   -0.232109   -0.0922239   \n",
      "4  23913257  -0.162068   -0.125675    -0.239576   -0.126316   -0.0832195   \n",
      "\n",
      "           6           7           8           9  ...           92  \\\n",
      "0   0.119655   -0.136511   -0.012849   -0.125184  ...     0.037431   \n",
      "1   0.129875   -0.116013  -0.0357381   -0.120952  ...    0.0364562   \n",
      "2   0.055224   -0.193431   -0.130026  -0.0899581  ...   -0.0151897   \n",
      "3  0.0611695  -0.0326336  -0.0115038   -0.214131  ...    0.0369536   \n",
      "4  0.0747052  -0.0250216  -0.0608125  -0.0771873  ...    0.0834163   \n",
      "\n",
      "           93         94           95         96          97          98  \\\n",
      "0  -0.0301263  -0.128484   -0.0433902  0.0996642   -0.118848  0.00068486   \n",
      "1  -0.0249399   -0.10961   -0.0987229  0.0493813   -0.126333  -0.0859457   \n",
      "2  -0.0695683   -0.12338  -0.00300068   0.110622  -0.0888987  -0.0173465   \n",
      "3  -0.0422968   -0.07245   -0.0808708   0.129449   -0.115323  -0.0673075   \n",
      "4   -0.104568   -0.07588    -0.134221   0.120564   -0.137086  -0.0620605   \n",
      "\n",
      "           99         100 label  \n",
      "0  -0.0493116  0.00573114     0  \n",
      "1   -0.257998   -0.144949     0  \n",
      "2   -0.113203   -0.129437     0  \n",
      "3   -0.191113  -0.0546809     0  \n",
      "4    -0.21358   -0.100314     0  \n",
      "\n",
      "[5 rows x 102 columns]\n"
     ]
    }
   ],
   "source": [
    "# reconstract data so that we can feed it to svm\n",
    "import pandas as pd\n",
    "classOne = pd.DataFrame(author0)\n",
    "classOne[\"label\"] = 0\n",
    "#print(classOne[:2:])\n",
    "classTwo = pd.DataFrame(author1)\n",
    "classTwo[\"label\"] = 1\n",
    "#print(classTwo[:2:])\n",
    "# combine data from different class get all data\n",
    "combinedData = pd.concat([classOne, classTwo])\n",
    "print(combinedData[:5])\n",
    "combinedData = combinedData.sample(frac=1).reset_index(drop=True)\n",
    "# take the paper id out\n",
    "paperID = combinedData[0]\n",
    "# split data and label\n",
    "data = combinedData.drop([0,'label'], axis=1)\n",
    "label = combinedData['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "def k_fold_cv(data, label, classifier, clfname):\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    # create lists to collect statistic\n",
    "    tp = []\n",
    "    fp = []\n",
    "    tn = []\n",
    "    fn = []\n",
    "    roundf1 = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        label_train, test_true_label = label.iloc[train_index], label.iloc[test_index]\n",
    "        # fit data to svm\n",
    "        classifier.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = classifier.predict(data_test)\n",
    "         # find out which sample cause the issue\n",
    "        print(\"Pred: \",label_pred)\n",
    "        print(\"True: \", test_true_label.values.tolist())\n",
    "        for i in range(len(test_true_label)):\n",
    "            if(label_pred[i]!=test_true_label[test_index[i]]):\n",
    "                print(\"Mislabeled sample: \",paperID[test_index[i]])\n",
    "        # find round confusion matrix\n",
    "        round_tn, round_fp, round_fn, round_tp = metrics.confusion_matrix(test_true_label, label_pred).ravel()\n",
    "        # add data data to array\n",
    "        tp.append(round_tp)\n",
    "        fp.append(round_fp)\n",
    "        fn.append(round_fn)\n",
    "        tn.append(round_tn)\n",
    "        roundf1.append(f1_score(test_true_label, label_pred,average='micro'))\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "\n",
    "    print(\"Classifier: {name}\\nTrue positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "          .format(name=clfname, tp=np.sum(tp), fp=np.sum(fp), fn=np.sum(fn), tn=np.sum(tn)))\n",
    "    f1 = np.average(roundf1)\n",
    "    ppv, npv, specificity, sensitivity, accuracy = calculate_important_value(np.sum(tp), np.sum(tn),\n",
    "                                                                             np.sum(fp), np.sum(fn), len(data),f1)\n",
    "    return ppv, npv, specificity, sensitivity, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate ppv,npv,specificity,sensitivity, and accuracy\n",
    "def calculate_important_value(tp, tn, fp, fn, sample_length,f1):\n",
    "    # 1. Positive predicted value (PPV) or precision aka hit rate = True positive/ )True positive + False positive)\n",
    "    ppv = (tp / (tp + fp))\n",
    "    # 2. Negative predicted value (NPV) = True negative / (True negative + False negative)\n",
    "    npv = (tn / (tn + fn))\n",
    "    # 3. Specificity = (1 - False positive)\n",
    "    specificity = (tn / (tn + fp))\n",
    "    # 4. Sensitivity = True positive\n",
    "    sensitivity = (tp / (tp + fn))\n",
    "    # 5. Accuracy = (True positive + True negative) / Total number of sample\n",
    "    accuracy = (tp + tn) / sample_length\n",
    "    print('PPV: ', ppv)\n",
    "    print('NPV: ', npv)\n",
    "    print('Specificity: ', specificity)\n",
    "    print('Sensitivity: ', sensitivity)\n",
    "    print('Accuracy: ', accuracy)\n",
    "    print('F1: ', f1)\n",
    "    return ppv, npv, specificity, sensitivity, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "Pred:  [1 1 1 0 0 0 0 1 0 0 1 0]\n",
      "True:  [1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "Pred:  [1 1 0 0 1 1 0 0 1 0 1 1]\n",
      "True:  [1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1]\n",
      "Pred:  [0 0 0 1 1 1 1 0 0 1 0 0]\n",
      "True:  [0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0]\n",
      "Pred:  [0 0 0 0 1 0 1 1 0 0 1 0]\n",
      "True:  [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0]\n",
      "Pred:  [1 1 1 0 1 1 0 1 0 0 1 1]\n",
      "True:  [1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1]\n",
      "Mislabeled sample:  22751827\n",
      "Pred:  [0 1 1 0 1 0 0 1 1 1 0 1]\n",
      "True:  [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1]\n",
      "Pred:  [1 1 1 1 0 1 0 1 1 1 0 0]\n",
      "True:  [1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0]\n",
      "Pred:  [1 1 1 0 0 1 1 0 1 0 1]\n",
      "True:  [1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1]\n",
      "Pred:  [0 1 1 0 0 0 1 1 0 1 0]\n",
      "True:  [0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0]\n",
      "Pred:  [0 0 0 1 1 0 1 1 1 1 1]\n",
      "True:  [0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Classifier: logistic\n",
      "True positive: 63, False positive: 0, False negative: 1, True negative: 53\n",
      "PPV:  1.0\n",
      "NPV:  0.9814814814814815\n",
      "Specificity:  1.0\n",
      "Sensitivity:  0.984375\n",
      "Accuracy:  0.9914529914529915\n",
      "F1:  0.9916666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 0.9814814814814815,\n",
       " 1.0,\n",
       " 0.984375,\n",
       " 0.9914529914529915,\n",
       " 0.9916666666666666)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression\n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "print(logistic)\n",
    "# fit model and do 10-fold cv\n",
    "k_fold_cv(data, label, logistic, \"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
