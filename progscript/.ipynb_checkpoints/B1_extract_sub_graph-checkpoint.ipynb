{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract sub graph of citation\n",
    "\n",
    "Orginal citation graph is too large can't load into memory\n",
    "1. Extract only useful data (3m papers) (Still too large) \n",
    "2. Extract only labeled data (140k papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T01:57:20.483131Z",
     "start_time": "2020-08-18T01:57:18.641726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3151504\n",
      "['27406695', '26876744', '26978780', '26794258', '26628514']\n"
     ]
    }
   ],
   "source": [
    "# ------------------ number of record for all data -------------- #\n",
    "import os\n",
    "\n",
    "Dataset = \"pubmed\"\n",
    "paperIDs = []\n",
    "# read in paper ID\n",
    "with open(\"Data/\"+Dataset+\"/pids.txt\", 'r', encoding = 'utf8') as infile:\n",
    "    for line in infile:\n",
    "        paperIDs.append(line.strip('\\n'))\n",
    "print(len(paperIDs))\n",
    "print(paperIDs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T02:44:05.946519Z",
     "start_time": "2020-08-18T02:29:44.973234Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format wrong:  ['10.1186/1471-2342-13-31']\n",
      "Format wrong:  ['10.1007/s11240-011-9919-5']\n",
      "Format wrong:  ['289/23/3152']\n",
      "Format wrong:  ['1096645']\n",
      "Format wrong:  ['ct0203sattler']\n",
      "Format wrong:  ['jphysiol.2003.044875']\n",
      "Format wrong:  ['s1535610804002077']\n",
      "Format wrong:  ['ajas-25-7-913-2[pii]']\n",
      "Format wrong:  ['2235925100']\n",
      "Format wrong:  ['0904113106']\n",
      "Format wrong:  ['348/26/2599']\n",
      "Format wrong:  ['2003-07-2459']\n",
      "Format wrong:  ['s0006-291x(08)02191-8']\n",
      "Done load all citations, total citation links:  502248885\n",
      "['8587804\\t10.1017/s1742758400012674', '10.1017/s0041977x1100084x\\t10.1364/josa.46.000628', '10.1353/wp.2001.0006\\t7674027', '10.1017/s0041977x1100084x\\t10.1515/zava.1898.13.1.111', '8587804\\t10.1017/s0007485300049415', '10.1017/s1365100505040204\\t10.1093/oxfordjournals.oep.a041948', '10.1017/s0140525x00031769\\t10.1037/0096-1523.7.2.356', '8587804\\t10.1177/0040571x7207500312', '10.1017/s0140525x00031769\\t10.3758/bf03335168', '10.1353/wp.2001.0006\\t10.1111/j.1747-7093.1992.tb00545.x']\n"
     ]
    }
   ],
   "source": [
    "citations = []\n",
    "with open(\"Data/\"+Dataset+\"/allAdditional/16May-citation.txt\", 'r', encoding = 'utf8') as infile:\n",
    "    for line in infile:\n",
    "        source_target = line.strip('\\n').split(\"\\t\")\n",
    "        if(len(source_target)==2):\n",
    "            citations.append(line.strip('\\n'))\n",
    "        else:\n",
    "            print(\"Format wrong: \", source_target)\n",
    "print(\"Done load all citations, total citation links: \",len(citations))\n",
    "print(citations[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:15:29.380872Z",
     "start_time": "2020-08-18T02:59:37.618998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers in citation links:  47527717\n"
     ]
    }
   ],
   "source": [
    "# check number of unique papers in all citation links\n",
    "paperSet = set()\n",
    "for line in citations:\n",
    "    id_list = line.split(\"\\t\")\n",
    "    paperSet.add(id_list[0])\n",
    "    paperSet.add(id_list[1])\n",
    "print(\"Total unique papers in all citation links: \", len(paperSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we extract subgraph for all papers in canopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:04.925884Z",
     "start_time": "2020-08-18T03:21:06.088828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3151504\n",
      "check\n",
      "After: 0:00:00.000472\n",
      "check\n",
      "After: 0:02:31.790500\n",
      "check\n",
      "After: 0:05:06.754192\n",
      "check\n",
      "After: 0:07:42.496000\n",
      "check\n",
      "After: 0:10:17.647858\n",
      "check\n",
      "After: 0:12:54.727110\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "subgraph = []\n",
    "counter = 0\n",
    "paperIDs = set(paperIDs)\n",
    "print(len(paperIDs))\n",
    "\n",
    "t1 = datetime.now()\n",
    "for line in citations:\n",
    "    if counter %100000000 ==0:\n",
    "        print(\"check\")\n",
    "        t2 = datetime.now()\n",
    "        print('After: ' + str(t2 - t1))\n",
    "    id_list = line.split(\"\\t\")\n",
    "    counter+=1\n",
    "    if (id_list[0] in paperIDs) or (id_list[1] in paperIDs):\n",
    "        subgraph.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:04.933020Z",
     "start_time": "2020-08-18T03:34:04.928584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, subgraph size:  78377011\n"
     ]
    }
   ],
   "source": [
    "print(\"Done, subgraph size: \", len(subgraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:45:42.582665Z",
     "start_time": "2020-08-18T03:45:01.182103Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newf = open(\"Data/\"+Dataset+\"/subgraph.txt\",\"w\",encoding='utf8')\n",
    "# for line in subgraph:\n",
    "#     newf.write(line+\"\\n\")\n",
    "# newf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we extract subgraph for only labeled papers in canopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:55:19.741515Z",
     "start_time": "2020-08-18T03:55:15.898740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140266\n",
      "['27406695', '26876744', '26978780', '26794258', '26628514']\n"
     ]
    }
   ],
   "source": [
    "# ---------------- number of record for labeled data ------------------ #\n",
    "import os\n",
    "\n",
    "Dataset = \"pubmed\"\n",
    "\n",
    "fileDir = \"Data/pubmed/canopies_labeled/\"\n",
    "listfiles = os.listdir(fileDir)\n",
    "LabeledRecords_pid = []\n",
    "\n",
    "for file in listfiles:\n",
    "    if not file.startswith('.'):\n",
    "        with open(fileDir+file, 'r', encoding = 'utf8') as f:\n",
    "            for line in f:\n",
    "                read_data = line.split(\"\\t\")\n",
    "                if(len(read_data)==13 or len(read_data)==12):\n",
    "                    LabeledRecords_pid.append(read_data[0])\n",
    "                else:\n",
    "                    print(len(read_data))\n",
    "        f.close()\n",
    "print(len(LabeledRecords_pid))\n",
    "print(LabeledRecords_pid[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:06:32.818190Z",
     "start_time": "2020-08-18T03:56:16.226565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135796\n",
      "check\n",
      "After: 0:00:00.000391\n",
      "check\n",
      "After: 0:02:24.342703\n",
      "check\n",
      "After: 0:04:51.116939\n",
      "check\n",
      "After: 0:06:40.198498\n",
      "check\n",
      "After: 0:08:26.883695\n",
      "check\n",
      "After: 0:10:14.104770\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "labeled_subgraph = []\n",
    "counter = 0\n",
    "labeled_paperIDs = set(LabeledRecords_pid)\n",
    "print(len(labeled_paperIDs))\n",
    "\n",
    "t1 = datetime.now()\n",
    "for line in citations:\n",
    "    if counter %100000000 ==0:\n",
    "        print(\"check\")\n",
    "        t2 = datetime.now()\n",
    "        print('After: ' + str(t2 - t1))\n",
    "    id_list = line.split(\"\\t\")\n",
    "    counter+=1\n",
    "    if (id_list[0] in labeled_paperIDs) or (id_list[1] in labeled_paperIDs):\n",
    "        labeled_subgraph.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:06:32.824359Z",
     "start_time": "2020-08-18T04:06:32.820239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, labeled subgraph size:  6080487\n"
     ]
    }
   ],
   "source": [
    "print(\"Done, labeled subgraph size: \", len(labeled_subgraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:13:25.213156Z",
     "start_time": "2020-08-18T04:13:22.287425Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newf = open(\"Data/\"+Dataset+\"/labeled_subgraph.txt\",\"w\",encoding='utf8')\n",
    "# for line in labeled_subgraph:\n",
    "#     newf.write(line+\"\\n\")\n",
    "# newf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from datetime import datetime\n",
    "# subgraph = []\n",
    "# counter = 0\n",
    "\n",
    "# def binary_search(numbers, target, first, last):\n",
    "#     mid = (first + last) // 2\n",
    "#     if first > last:\n",
    "#         index = -1\n",
    "#     elif target == numbers[mid]:\n",
    "#         index =  mid\n",
    "#     elif target < numbers[mid]:\n",
    "#         index = binary_search(numbers, target, first, mid-1)\n",
    "#     else:\n",
    "#         index = binary_search(numbers, target, mid+1, last)\n",
    "#     return index\n",
    "# t1 = datetime.now()\n",
    "# for line in citations:\n",
    "#     if counter %10000 ==0:\n",
    "#         print(\"check\")\n",
    "#         t2 = datetime.now()\n",
    "#         print('After: ' + str(t2 - t1))\n",
    "#     id_list = line.split(\"\\t\")\n",
    "#     counter+=1\n",
    "#     if (binary_search(paperIDs, id_list[0],0,len(paperIDs)-1)!=-1) or (binary_search(paperIDs,id_list[1],0,len(paperIDs)-1)!=-1):\n",
    "#         subgraph.append(line)\n",
    "#         if id_list[1] in paperIDs:\n",
    "#             print(id_list[1])\n",
    "\n",
    "# newf = open(\"Data/\"+Dataset+\"/subgraph.txt\",w,encoding='utf8')\n",
    "# for line in subgraph:\n",
    "#     newf.write(line)\n",
    "# newf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
