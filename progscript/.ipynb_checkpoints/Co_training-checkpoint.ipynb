{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "# create co training classifier\n",
    "class Co_training_clf(object):\n",
    "    \n",
    "    def __init__(self, clf1, clf2=None, p=-1, n=-1, k=30, u = 75):\n",
    "        self.clf1 = clf1\n",
    "        # assume co_training on one classifier\n",
    "        if clf2 == None:\n",
    "            self.clf2 = copy.copy(clf1)\n",
    "        else:\n",
    "            self.clf2 = clf2\n",
    "        # take p example from most confidently positive labels to example\n",
    "        self.p = p\n",
    "        # take n example from most confidently negative label to example\n",
    "        self.n = n\n",
    "        # number of iteration\n",
    "        self.k = k\n",
    "        # size of pool of unlabeled samples\n",
    "        self.u = u\n",
    "        \n",
    "    def fit(self, dataView1, dataView2, labels):\n",
    "        self.self_labeled_pos = []\n",
    "        self.self_labeled_neg = []\n",
    "        labels = np.asarray(labels)\n",
    "        # get data ratio\n",
    "        pos_count = sum(1 for y_i in y if y_i == 1)\n",
    "        neg_count = sum(1 for y_i in y if y_i == 0)\n",
    "        p_n_ratio = num_pos / float(num_neg)\n",
    "        # if not set number of positive and negative label take from prediction\n",
    "        if self.p == -1 and self.n == -1:\n",
    "            if p_n_ratio > 1:\n",
    "                self.n = 1\n",
    "                self.p = round(self.n*p_n_ratio)\n",
    "            else:\n",
    "                self.p = 1\n",
    "                self.n = round(self.p/p_n_ratio)\n",
    "        # if only set number of positive label take from prediction\n",
    "        if self.p != -1 and self.n == -1:\n",
    "            self.n = round(self.p/p_n_ratio)\n",
    "        # if only set number of negative label take from prediction\n",
    "        if self.p == -1 and self.n != -1:\n",
    "            self.p = round(self.n*p_n_ratio)\n",
    "        assert(self.p > 0 and self.n > 0 and self.k > 0 and self.u > 0)\n",
    "        \n",
    "        # the samples that are initially labeled\n",
    "        L = [i for i, label_i in enumerate(labels) if label_i != -1]\n",
    "        # index of unlabeled samples\n",
    "        U = [i for i, label_i in enumerate(labels) if label_i == -1]\n",
    "        # random drawing sample from U\n",
    "        random.shuffle(U)\n",
    "        U_prime = U[-min(len(U), self.u):]\n",
    "        # remove the samples in U_prime from U\n",
    "        U = U[:-len(U_prime)]\n",
    "        \n",
    "        iterCount = 0\n",
    "        #loop until we have assigned labels to everything in U or we hit our iteration break condition\n",
    "        while iterCount != self.k and U:\n",
    "            iterCount +=1\n",
    "            self.clf1.fit(dataView1[L], labels[L])\n",
    "            self.clf2.fit(dataView2[L], labels[L])\n",
    "            \n",
    "            y1 = self.clf1_.predict(dataView1[U_prime])\n",
    "            y2 = self.clf2_.predict(dataView2[U_prime])\n",
    "            # add to train if prediction match\n",
    "            p,n = [], []\n",
    "            for i, (y1_i, y2_i) in enumerate(zip(y1, y2)):\n",
    "                if len(p) == self.p and len(n) == self.n:\n",
    "                    break\n",
    "                if y1_i == y2_i == 1 and len(p) < self.p:\n",
    "                    p.append(i)\n",
    "                if y2_i == y1_i == 0 and len(n) < self.n:\n",
    "                    n.append(i)\n",
    "            # label the samples and remove thes newly added samples from U_prime\n",
    "            labels[[U_prime[x] for x in p]] = 1\n",
    "            labels[[U_prime[x] for x in n]] = 0\n",
    "            \n",
    "            L.extend([U_prime[x] for x in p])\n",
    "            L.extend([U_prime[x] for x in n])\n",
    "            # add sample to a final list for check\n",
    "            self.self_labeled_pos.extend([U_prime[x] for x in p])\n",
    "            self.self_labeled_neg.extend([U_prime[x] for x in n])\n",
    "            # randomly choice 2p+2n examples from u to replenish u_prime\n",
    "            replenishItem = U[-(2*self.p+2*self.n):]\n",
    "            U_prime.extend(replenishItem)\n",
    "            U = U[:-len(replenishItem)]\n",
    "        # fit the co-trained model\n",
    "        self.clf1_.fit(dataView1[L], labels[L])\n",
    "        self.clf2_.fit(dataView2[L], labels[L])\n",
    "    \n",
    "    def supports_proba(self, clf, x):\n",
    "        try:\n",
    "            clf.predict_proba([x])\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "        \n",
    "    def predict(self, dataView1, dataView2):\n",
    "        y1 = self.clf1.predict(dataView1)\n",
    "        y2 = self.clf2.predict(dataView2)\n",
    "        # Checks if a given classifier supports the 'predict_proba' method\n",
    "        # this allow me to build combined classifiers by multiplying the probabilities output of classifier together\n",
    "        proba_supported = self.supports_proba(self.clf1, dataView1[0]) and self.supports_proba(self.clf2, dataView2[0])\n",
    "        #fill pred with -1 so we can identify the samples in which sample classifiers failed to agree\n",
    "        pred = np.asarray([-1] * dataView1.shape[0])\n",
    "        for i, (y1_i, y2_i) in enumerate(zip(y1, y2)):\n",
    "            # if both agree on label\n",
    "            if y1_i == y2_i:\n",
    "                y_pred[i] = y1_i\n",
    "            # if disagree on label, choice the class have higher probabilities\n",
    "            elif proba_supported:\n",
    "                y1_probas = self.clf1.predict_proba([dataView1[i]])[0]\n",
    "                y2_probas = self.clf2.predict_proba([dataView2[i]])[0]\n",
    "                sum_y_probas = [proba_y1 + proba_y2 for (proba_y1, proba_y2) in zip(y1_probas, y2_probas)]\n",
    "                y_pred[i] = sum_y_probas.index(max(sum_y_probas))\n",
    "            else:\n",
    "                #the classifiers disagree and don't support probability, so we guess\n",
    "                warnings.warn(\"classifiers disagree with label and it don't support probability, result is not accurate\")\n",
    "                y_pred[i] = random.randint(0, 1)\n",
    "        #check if predict works\n",
    "        assert not (-1 in y_pred)\n",
    "        return y_pred\n",
    "    \n",
    "    def predict_proba(self, dataView1, dataView2):\n",
    "        # the predicted probabilities is simply a average of probabilities given from each classifier trained\n",
    "        proba = np.full((dataView1.shape[0], 2), -1)\n",
    "        y1_probas = self.clf1.predict_proba(dataView1)\n",
    "        y2_probas = self.clf2.predict_proba(dataView2)\n",
    "        \n",
    "        for i, (y1_i, y2_i) in enumerate(zip(y1_probas, y2_probas)):\n",
    "            proba[i][0] = (y1_i[0] + y2_i[0]) / 2\n",
    "            proba[i][1] = (y1_i[1] + y2_i[1]) / 2\n",
    "        \n",
    "        return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vector records: 3149075\n",
      "['3', '-0.07245799', '-0.15048164', '-0.04320673', '0.01244448', '0.05051953', '-0.05573996', '0.03158288', '-0.04663554', '-0.00442508', '-0.02417533', '-0.03292065', '0.03798062', '0.08195730', '-0.09100581', '-0.04666801', '-0.06315092', '-0.05957321', '0.09766518', '0.01981102', '0.09956500', '-0.02059892', '-0.02321497', '0.10300557', '0.09654117', '0.02085607', '0.15179265', '0.03320639', '0.04716884', '0.04259005', '-0.01022485', '0.07371941', '0.02970656', '0.18967280', '0.07049462', '-0.07849123', '0.10272161', '0.05396378', '0.04138396', '0.08093689', '-0.04713648', '-0.08277001', '0.06004119', '0.15147503', '-0.10719796', '-0.06268646', '0.15823838', '0.10273122', '0.04453533', '-0.00394740', '-0.01239040', '-0.06826647', '-0.02995823', '0.14925463', '0.12254845', '-0.05894163', '0.11628735', '0.03898517', '0.01221054', '-0.00804257', '-0.06178775', '-0.04752085', '-0.04040224', '0.09192738', '0.01171173', '0.02951661', '-0.02156392', '-0.02458819', '-0.00003645', '-0.06527787', '0.07321506', '0.00926040', '0.04152755', '-0.06273570', '0.00205773', '-0.14158797', '0.01341034', '0.05070017', '-0.06785034', '0.01392612', '0.01312939', '-0.03518058', '-0.04593558', '-0.04542769', '-0.03334041', '0.02727035', '0.03331508', '-0.05495675', '-0.02231646', '-0.01770608', '0.02452897', '0.03648302', '0.02217655', '0.01033537', '0.00610828', '-0.03949452', '0.01911573', '-0.08300079', '-0.04561001', '0.01872506', '0.01281491\\n']\n"
     ]
    }
   ],
   "source": [
    "# extract different view of data\n",
    "# view one, doc2vec\n",
    "\n",
    "# load the vector files\n",
    "import sys\n",
    "import io\n",
    "setting = \"d2v\"\n",
    "\n",
    "viewOneFilesDir = \"../Data/vectors/\"+setting+\"/\"+setting+\".txt\"\n",
    "viewOneVectors = []\n",
    "\n",
    "with open(viewOneFilesDir, 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        read_data = line.split(\" \")\n",
    "        paper_Vectors = read_data\n",
    "        viewOneVectors.append(paper_Vectors)\n",
    "f.close()\n",
    "        \n",
    "print(\"Total vector records:\",len(viewOneVectors))\n",
    "print(viewOneVectors[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vector records: 12140452\n",
      "['22516865', '0.0109272', '0.126011', '0.186979', '0.0496719', '0.0373553', '0.0458918', '-0.119893', '0.217118', '0.0524591', '0.237477', '0.191269', '-0.0277055', '0.0290957', '-0.0366833', '0.118964', '0.0654807', '-0.0335345', '-0.0900123', '0.128621', '0.0561669', '-0.087823', '-0.0882296', '0.0740289', '0.082104', '0.0269581', '-0.0346502', '0.0153376', '0.104666', '0.0908716', '-0.085694', '-0.111344', '0.0787209', '-0.17003', '-0.103366', '-0.0832094', '-0.210496', '0.153037', '-0.0342884', '0.0698413', '-0.0719641', '-0.0535707', '0.172399', '0.106226', '-0.0593672', '-0.0348048', '-0.0863189', '-0.0801566', '-0.0665761', '0.0673258', '0.0306541', '-0.0896316', '-0.00800971', '-0.174798', '-0.0252528', '0.0098563', '0.0230368', '0.0282268', '-0.0366493', '-0.131323', '0.0318188', '-0.00778704', '-0.0608064', '-0.0860078', '0.215632', '0.0209927', '-0.0953191', '-0.191736', '-0.0741615', '0.151972', '-0.0522046', '-0.11081', '0.134878', '0.090797', '0.0160238', '0.113017', '0.196071', '-0.0598695', '-0.181981', '-0.0217668', '0.165394', '0.0724198', '0.0967185', '-0.115696', '-0.104803', '0.231757', '-0.0871117', '-0.0397107', '0.137358', '-0.083055', '-0.226604', '0.0186784', '-0.0608683', '-0.0177875', '0.082095', '-0.00222851', '-0.137642', '-0.0848053', '0.165064', '-0.022831', '0.240943\\n']\n"
     ]
    }
   ],
   "source": [
    "# extract different view of data\n",
    "# view two, node2vec\n",
    "setting = \"n2v\"\n",
    "\n",
    "viewTwoFilesDir = \"../Data/vectors/\"+setting+\"/data=Meta-alg=N2V-l2=1.0-n2v_p=0.85-iteration=100-no_self_predict=1-idx=0.emb\"\n",
    "viewTwoVectors = []\n",
    "\n",
    "with open(viewTwoFilesDir, 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        read_data = line.split(\" \")\n",
    "        paper_Vectors = read_data\n",
    "        viewTwoVectors.append(paper_Vectors)\n",
    "f.close()\n",
    "recordcount, dim = viewTwoVectors[0]\n",
    "viewTwoVectors = viewTwoVectors[1:]\n",
    "print(\"Total vector records:\",len(viewTwoVectors))\n",
    "print(viewTwoVectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chung-may yang.txt', 'chung-may yang0.txt', 'chung-may yang1.txt', 'david g lloyd.txt', 'david g lloyd0.txt', 'david g lloyd1.txt', 'jeong hwan kim.txt', 'jeong hwan kim0.txt', 'jeong hwan kim1.txt', 'kevin m. ryan.txt', 'kevin m. ryan0.txt', 'kevin m. ryan1.txt', 'lei wang.txt', 'lei wang0.txt', 'lei wang1.txt', 'michael wagner.txt', 'michael wagner0.txt', 'michael wagner1.txt']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "# collect data\n",
    "fileDir = \"../Data/filteredSameNameAuthor/filter=30/\"\n",
    "fileList = os.listdir(fileDir)\n",
    "fileList.sort()\n",
    "print(fileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove author(positive sample) from other(negative sample)\n",
    "import random\n",
    "def extractNegativeSample(positiveSample, allSample):\n",
    "    negativeSample = [x for x in allSample if x not in positiveSample]\n",
    "    print(\"Total negative sample size:\", len(negativeSample))\n",
    "    return negativeSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect class vectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extractVectors(author_pids, NegativeSample_pid, allPaperVectors):\n",
    "    # extract class one vectors\n",
    "    author_features = []\n",
    "    for pid in author_pids:\n",
    "         for paper_Vectors in allPaperVectors:\n",
    "            if(paper_Vectors[0] == pid):\n",
    "                author_features.append(paper_Vectors)\n",
    "    print(\"Positive sample size: \", len(author_features))\n",
    "    classOne = pd.DataFrame(author_features)\n",
    "    classOne[\"label\"] = 0\n",
    "    # extract class two vectors\n",
    "    other_features = []\n",
    "    for pid in NegativeSample_pid:\n",
    "        for paper_Vectors in allPaperVectors:\n",
    "            if(paper_Vectors[0] == pid):\n",
    "                other_features.append(paper_Vectors)\n",
    "    print(\"Negative sample size: \", len(other_features))\n",
    "    classTwo = pd.DataFrame(other_features)\n",
    "    classTwo[\"label\"] = 1\n",
    "    return classOne, classTwo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine data from different class get all data\n",
    "def combineClassesData(classOne,classTwo):\n",
    "    combinedData = pd.concat([classOne, classTwo])\n",
    "    combinedData = combinedData.sample(frac=1).reset_index(drop=True)\n",
    "    # take the paper id out\n",
    "    paperID = combinedData[0]\n",
    "    # split data and label\n",
    "    data = combinedData.drop([0,'label'], axis=1)\n",
    "    label = combinedData['label']\n",
    "    print(\"Total sample size and shape: \",data.shape)\n",
    "    return data, label, paperID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['26921674', '27054571', '24612629', '27094404', '27104802', '26976043', '27092400', '26612384', '26601984', '26372590', '25435336', '25808791', '27239504', '26261317', '25471190', '25158072', '26402080', '26332608', '25822830', '26658776', '26619916', '26170016', '26233432', '26402078', '26402085', '25716354', '26484902', '26184561', '26308457', '26200043', '23928294', '24798886', '23521526', '23375567', '23883793', '25685139', '24325976', '24529980', '25062598', '24600411', '23867795', '22913370', '25042114', '25019225', '24571191', '24338591', '24990933', '23759289', '24729411', '24743864', '24089318', '24441882', '22475622', '23137390', '23992793', '22704223', '23990902', '24129642', '23474092', '26151896', '23652383', '22889924', '22889921', '23288874', '21914645', '22339903', '23399382', '24138519', '24204291', '23538093', '23736996', '23219936', '23788523', '23604333', '23680103', '23297009', '23585882', '23564357', '21901269', '22704853', '22437321', '22375927', '22698761', '22238414', '22703453', '22584873', '22914828', '22655589', '21875213', '21402721', '22038536', '22075649', '22451930', '22183013', '22078257', '21892778', '20038948', '21932083']\n",
      "26921674\n"
     ]
    }
   ],
   "source": [
    "# hard code to read the file one by one\n",
    "# store the features for classification\n",
    "author_pids = []\n",
    "other_pids = []\n",
    "# author as positive sample, other as all samples\n",
    "with open(fileDir+\"michael wagner0.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        author_pids.extend(line.strip().split(\" \"))\n",
    "\n",
    "with open(fileDir+\"michael wagner.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        other_pids.extend(line.strip().split(\" \"))\n",
    "        \n",
    "print(author_pids)\n",
    "print(other_pids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative sample size: 141\n",
      "Choicen negative sample  141\n",
      "['26222031', '25148481', '25576608', '25180967', '25303712', '25425419', '25093819', '25170152', '24401855', '24975266', '23263968', '23487774', '23335755', '22582069', '21833037', '23105050', '22701656', '22952791', '22079351', '22572638', '23057602', '23135396', '22141924', '21890669', '22066885', '21514465', '21169452', '21525411', '21709249', '21500343', '21858215', '21930919', '21546306', '21441524', '20535221', '20624973', '20033067', '21966903', '20598889', '19966029', '20675479', '21136591', '20545842', '20600954', '20023027', '20040079', '19120466', '19571892', '18826437', '19514853', '18250313', '18312573', '18177367', '18641160', '18459973', '18606736', '18461076', '18552182', '18647333', '17504498', '17227418', '17367515', '17408790', '17333172', '17635536', '17554047', '17345135', '18043620', '17099228', '16517650', '16572761', '16452171', '16598256', '16898133', '16377170', '16872410', '16517657', '16478447', '16796686', '16704931', '16971007', '16423009', '16166679', '15746340', '15640165', '15811989', '15709360', '16260310', '15743970', '15774634', '16008504', '15869972', '15632447', '15816925', '15577910', '14729693', '15537084', '15184179', '15073324', '15574893', '14742465', '14711691', '13130037', '12955353', '12691889', '12788718', '12957939', '12831908', '12648840', '12662174', '12713462', '12820037', '14602652', '12520066', '12200322', '12180096', '12147510', '11827344', '12200297', '11827353', '12324358', '12450827', '12086193', '12008915', '11553235', '11229931', '11722938', '11357130', '11682181', '11679356', '11311441', '11511864', '11553234', '11404106', '11567003', '11055962', '10831445', '11097916', '11207753', '11207728', '9495027']\n"
     ]
    }
   ],
   "source": [
    "NegativeSample_pid = extractNegativeSample(author_pids, other_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "View1class1, View1class2 = extractVectors(author_pids, NegativeSample_pid, viewOneVectors)\n",
    "View2class1, View2class2 = extractVectors(author_pids, NegativeSample_pid, viewTwoVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataViewone = combineClassesData(View1class1, View1class2)\n",
    "dataViewtwo = combineClassesData(View2class1, View2class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select 50% of sample as test data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
