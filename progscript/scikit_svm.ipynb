{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chung-may yang1.txt', 'wei lu0.txt', 'yong wang1.txt', 'david g lloyd0.txt', 'wei lu1.txt', 'feng liu1.txt', 'david g lloyd1.txt', 'jeong hwan kim1.txt', 'chung-may yang0.txt', 'michael wagner0.txt', 'feng liu0.txt', 'hao song1.txt', 'hao song0.txt', 'kevin m. ryan0.txt', 'michael wagner1.txt', 'lei wang0.txt', 'jeong hwan kim0.txt', 'yong wang0.txt', 'lei wang1.txt', 'kevin m. ryan1.txt']\n",
      "['0.36922291', '-0.19795579', '0.49601007', '0.56937379', '0.23814982', '-0.20741679', '0.02322432', '-0.09128307', '0.10833433', '-0.44993171', '-0.17381026', '0.21698874', '0.15634133', '-0.21289150', '-0.22035176', '-0.66691130', '-0.08266206', '0.52953374', '-0.52283341', '1.01679730', '0.17747700', '0.28360513', '-0.64240116', '0.69723111', '0.36909986', '0.06061623', '-0.27225286', '0.26881346', '0.57831347', '0.45311663', '0.33036721', '0.13136637', '-0.20699488', '0.03498034', '-0.00601116', '0.77119726', '0.53693563', '-0.39640459', '0.45612192', '-0.17980313', '0.05839377', '0.11145472', '0.59343356', '-0.43466347', '-0.90033704', '0.14279611', '0.40302879', '-0.55929625', '-0.16057757', '-0.28040111', '-0.54867595', '0.09380061', '0.42942521', '0.02083231', '0.26515505', '0.19815569', '-0.31907210', '0.22293389', '0.34351552', '0.24123186', '-0.40266612', '-0.39098978', '0.39526391', '-0.14869396', '0.46220195', '-0.24911688', '0.14407194', '-0.31019008', '-0.22382051', '0.47910926', '-0.13816421', '0.41275364', '-0.37393540', '-0.26789114', '-0.12173269', '0.73981011', '-0.36344424', '-0.50586742', '0.14274020', '0.43957645', '-0.40990815', '0.05263811', '0.42403337', '-0.02907073', '0.20193218', '-0.25121129', '-0.38545024', '-0.44561148', '-0.03824271', '0.04786006', '-0.29055598', '0.40918887', '0.12258954', '0.18083471', '0.28799698', '-0.28150690', '-0.22285448', '-0.01726055', '0.27558354', '0.56663853']\n",
      "['0.52925670', '-0.02440211', '0.46244982', '0.25455496', '0.29097646', '-0.49084303', '-0.29846215', '-0.11875289', '0.36637920', '0.52716923', '-0.16882820', '-0.07747390', '-0.24321133', '0.12182794', '-0.53084475', '0.04760885', '-0.14516385', '0.36896935', '-0.27167240', '-0.12398849', '-0.47337487', '0.04626436', '-0.12772705', '-0.52679235', '0.32150948', '0.23685242', '0.39680904', '-0.11311396', '0.60259938', '0.34571129', '0.30368447', '0.20964845', '0.56835812', '0.09647781', '-0.12793781', '0.90811092', '0.76268643', '0.22557400', '-0.55939949', '-0.52558589', '0.27168900', '0.23179965', '0.72889566', '-0.54083997', '-0.60524631', '0.34584150', '0.01599986', '-0.11580328', '0.11896764', '0.11248448', '-0.14225508', '-0.36410978', '0.21276450', '0.27448848', '0.08174735', '0.53830045', '-0.13054605', '0.37568605', '0.30917454', '0.10721625', '-0.37114003', '0.31709844', '0.52754462', '-0.27241397', '-0.00930294', '-0.20201743', '0.02026455', '-0.11423092', '-0.12026037', '0.53341281', '-0.27143639', '0.09190360', '0.05570075', '0.28004658', '-0.42772111', '-0.37804338', '-0.48771355', '-0.65381157', '0.46071026', '0.05214964', '-0.19272241', '-0.33348152', '-0.19886251', '0.11027483', '0.38007542', '-0.28876302', '0.15952943', '-0.31355256', '-0.43861294', '-0.48799017', '-0.10510196', '0.31192565', '0.28950179', '0.04110793', '-0.28755537', '-0.89548236', '-0.31943890', '0.28339240', '-0.06800211', '-0.23878886']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# collect data\n",
    "# ../Data/DataForClassification/d2v/\n",
    "fileDir = \"../Data/DataForClassification/d2v/\"\n",
    "fileList = os.listdir(fileDir)\n",
    "print(fileList)\n",
    "\n",
    "# # auto method that go through all the file in directory\n",
    "# for file in fileList:\n",
    "#     if not file.startswith('.'):\n",
    "#         if file.endswith(\".txt\"):\n",
    "#             file = file[:-4]\n",
    "\n",
    "# hard code to read the file one by one\n",
    "author0 = []\n",
    "author1 = []\n",
    "with open(fileDir+\"david g lloyd0.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        read_data = line.strip().split(\"\\t\")\n",
    "        author0.append(read_data[1].split(\" \"))\n",
    "\n",
    "with open(fileDir+\"david g lloyd1.txt\", 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        read_data = line.strip().split(\"\\t\")\n",
    "        author1.append(read_data[1].split(\" \"))\n",
    "print(author0[0])\n",
    "print(author1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "# size of each class\n",
    "print(len(author0))\n",
    "print(len(author1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# number of features (dimension)\n",
    "print(len(author0[0]))\n",
    "print(len(author1[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0            1            2           3           4            5  \\\n",
      "0   0.36922291  -0.19795579   0.49601007  0.56937379  0.23814982  -0.20741679   \n",
      "1   0.44019809   0.56984979  -0.05801425  0.10724957  0.81136632   0.14514671   \n",
      "2   0.14738785  -0.16762426   0.44191498  0.77328289  0.30972996   0.09072363   \n",
      "3   0.46882892  -0.53388768   0.41525257  0.30116102  0.66694850   0.48965639   \n",
      "4  -0.04815168   0.02721202   0.07970838  0.05371442  0.46587369  -0.13458404   \n",
      "\n",
      "            6            7           8            9  ...            91  \\\n",
      "0  0.02322432  -0.09128307  0.10833433  -0.44993171  ...    0.40918887   \n",
      "1  0.06338627  -0.13445675  0.78733879  -0.02049698  ...    0.34250227   \n",
      "2  0.14121903  -0.15820582  0.04141365  -0.38626724  ...    0.09026022   \n",
      "3  0.23758464   0.15237521  0.54638553   0.25229490  ...   -0.45478535   \n",
      "4  0.23646261   0.04194793  0.12056416  -0.01970780  ...    0.33367929   \n",
      "\n",
      "            92          93          94           95           96           97  \\\n",
      "0   0.12258954  0.18083471  0.28799698  -0.28150690  -0.22285448  -0.01726055   \n",
      "1   0.13470386  0.07506869  0.12009057   0.19346295  -0.33500236  -0.12874065   \n",
      "2   0.15790939  0.65115345  0.22500886   0.13207577  -0.19590142  -0.07299112   \n",
      "3  -0.19973552  0.32123250  0.03010655  -0.45819920  -0.13561103   0.04092679   \n",
      "4   0.11945336  0.52975219  0.28233194   0.20580857  -0.05068877   0.27063113   \n",
      "\n",
      "           98           99 label  \n",
      "0  0.27558354   0.56663853     0  \n",
      "1  0.48684123   0.27083412     0  \n",
      "2  0.17931497   0.60041678     0  \n",
      "3  0.00337549  -0.66781712     0  \n",
      "4  0.35126317   0.39240605     0  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# reconstract data so that we can feed it to svm\n",
    "import pandas as pd\n",
    "classOne = pd.DataFrame(author0)\n",
    "classOne[\"label\"] = 0\n",
    "#print(classOne[:2:])\n",
    "classTwo = pd.DataFrame(author1)\n",
    "classTwo[\"label\"] = 1\n",
    "#print(classTwo[:2:])\n",
    "# combine data from different class get all data\n",
    "combinedData = pd.concat([classOne, classTwo])\n",
    "print(combinedData[:5])\n",
    "combinedData = combinedData.sample(frac=1).reset_index(drop=True)\n",
    "# split data and label\n",
    "data = combinedData.drop('label', axis=1)\n",
    "label = combinedData['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "def k_fold_cv(data, label, classifier, clfname):\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    # create lists to collect statistic\n",
    "    tp = []\n",
    "    fp = []\n",
    "    tn = []\n",
    "    fn = []\n",
    "    roundf1 = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        # print(\"TRAIN:\", train_index, \" \\n TEST:\", test_index)\n",
    "        # split train and test\n",
    "        data_train, data_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        label_train, test_true_label = label.iloc[train_index], label.iloc[test_index]\n",
    "        # fit data to svm\n",
    "        classifier.fit(data_train, label_train)\n",
    "        # get predicted label\n",
    "        label_pred = classifier.predict(data_test)\n",
    "        # find round confusion matrix\n",
    "        round_tn, round_fp, round_fn, round_tp = metrics.confusion_matrix(test_true_label, label_pred).ravel()\n",
    "        # add data data to array\n",
    "        tp.append(round_tp)\n",
    "        fp.append(round_fp)\n",
    "        fn.append(round_fn)\n",
    "        tn.append(round_tn)\n",
    "        roundf1.append(f1_score(test_true_label, label_pred,average='micro'))\n",
    "        # print(\"True positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "        # .format(tp=round_tp, fp=round_fp, fn=round_fn, tn=round_tn))\n",
    "\n",
    "    print(\"Classifier: {name}\\nTrue positive: {tp}, False positive: {fp}, False negative: {fn}, True negative: {tn}\"\n",
    "          .format(name=clfname, tp=np.sum(tp), fp=np.sum(fp), fn=np.sum(fn), tn=np.sum(tn)))\n",
    "    f1 = np.average(roundf1)\n",
    "    ppv, npv, specificity, sensitivity, accuracy = calculate_important_value(np.sum(tp), np.sum(tn),\n",
    "                                                                             np.sum(fp), np.sum(fn), len(data),f1)\n",
    "    return ppv, npv, specificity, sensitivity, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate ppv,npv,specificity,sensitivity, and accuracy\n",
    "def calculate_important_value(tp, tn, fp, fn, sample_length,f1):\n",
    "    # 1. Positive predicted value (PPV) or precision aka hit rate = True positive/ )True positive + False positive)\n",
    "    ppv = (tp / (tp + fp))\n",
    "    # 2. Negative predicted value (NPV) = True negative / (True negative + False negative)\n",
    "    npv = (tn / (tn + fn))\n",
    "    # 3. Specificity = (1 - False positive)\n",
    "    specificity = (tn / (tn + fp))\n",
    "    # 4. Sensitivity = True positive\n",
    "    sensitivity = (tp / (tp + fn))\n",
    "    # 5. Accuracy = (True positive + True negative) / Total number of sample\n",
    "    accuracy = (tp + tn) / sample_length\n",
    "    print('PPV: ', ppv)\n",
    "    print('NPV: ', npv)\n",
    "    print('Specificity: ', specificity)\n",
    "    print('Sensitivity: ', sensitivity)\n",
    "    print('Accuracy: ', accuracy)\n",
    "    print('F1: ', f1)\n",
    "    return ppv, npv, specificity, sensitivity, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Classifier: SVM linear\n",
      "True positive: 102, False positive: 2, False negative: 2, True negative: 48\n",
      "PPV:  0.9807692307692307\n",
      "NPV:  0.96\n",
      "Specificity:  0.96\n",
      "Sensitivity:  0.9807692307692307\n",
      "Accuracy:  0.974025974025974\n",
      "F1:  0.9737500000000001\n",
      "\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Classifier: SVM rbf\n",
      "True positive: 102, False positive: 1, False negative: 2, True negative: 49\n",
      "PPV:  0.9902912621359223\n",
      "NPV:  0.9607843137254902\n",
      "Specificity:  0.98\n",
      "Sensitivity:  0.9807692307692307\n",
      "Accuracy:  0.9805194805194806\n",
      "F1:  0.9808333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9902912621359223,\n",
       " 0.9607843137254902,\n",
       " 0.98,\n",
       " 0.9807692307692307,\n",
       " 0.9805194805194806,\n",
       " 0.9808333333333333)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # create linear SVM model\n",
    "linear_svc = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "print(linear_svc)\n",
    "\n",
    "# fit model and do 10-fold cv\n",
    "k_fold_cv(data, label, linear_svc, \"SVM linear\")\n",
    "\n",
    "print()\n",
    "# create rbf SVM model\n",
    "rbf_svc = svm.SVC(kernel='rbf', C=10)\n",
    "print(rbf_svc)\n",
    "\n",
    "# fit model and do 10-fold cv\n",
    "k_fold_cv(data, label, rbf_svc, \"SVM rbf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
