{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T16:45:36.281310Z",
     "start_time": "2019-09-29T16:45:34.923740Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM hard margin\n",
    "class SupportVectorMachine(object):\n",
    "    \n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import style\n",
    "    \n",
    "    def __init__(self, visualization=True):\n",
    "        self.visualization = visualization\n",
    "        self.colors = {1:'r',-1:'b'}\n",
    "        if self.visualization:\n",
    "            self.fig = self.plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "    \n",
    "    def fit(self,train_data,train_label):\n",
    "        self.train_data = train_data\n",
    "        self.train_label = train_label\n",
    "        \n",
    "        # optimization \n",
    "        # {||w||:[w,b]} save magnitude of w as key and [w,b] will be store as value\n",
    "        opt_dict = {}\n",
    "        # apply to vector w at each step\n",
    "        transforms = [[1,1],\n",
    "                      [-1,1],\n",
    "                      [1,-1],\n",
    "                      [-1,-1]]\n",
    "        # find max feature and min feature\n",
    "        max_value, min_value = None,None\n",
    "        for i in range(len(train_data)):\n",
    "            for feature in train_data[i]:\n",
    "                if(max_value==None) and (min_value==None):\n",
    "                    max_value =feature\n",
    "                    min_value = feature\n",
    "                if(feature > max_value):\n",
    "                    max_value = feature\n",
    "                if(feature < min_value):\n",
    "                    min_value = feature\n",
    "        #alt_max_value = self.np.max(self.np.max(train_data, 0))\n",
    "        #alt_min_value = self.np.min(self.np.min(train_data, 0))\n",
    "        self.max_feature_value = max_value\n",
    "        self.min_feature_value = min_value\n",
    "        \n",
    "        # set step size\n",
    "        step_sizes = [self.max_feature_value*0.1,\n",
    "                     self.max_feature_value*0.01,\n",
    "                     # point of expensive\n",
    "                     self.max_feature_value*0.001]\n",
    "\n",
    "        # extremely expensive\n",
    "        b_range_multiple = 2\n",
    "        # we take large step for bias b \n",
    "        b_multiple = 5\n",
    "        # initial w for all feature column as max_feature_value*10\n",
    "        latest_optimum = self.max_feature_value*10\n",
    "\n",
    "        for step in step_sizes:\n",
    "            w = self.np.array([latest_optimum,latest_optimum])\n",
    "            # we can do this because svm is convex problem, we know when is optimized\n",
    "            optimized = False\n",
    "            while not optimized:\n",
    "                for b in self.np.arange(-1*(self.max_feature_value*b_range_multiple), \n",
    "                                        self.max_feature_value*b_range_multiple, step*b_multiple):\n",
    "                    for transformation in transforms:\n",
    "                        w_t = w*transformation\n",
    "                        fit_constraint = True\n",
    "                        # yi(xi.w+b) >= 1 constraint\n",
    "                        # check update to w will fit constraint or not\n",
    "                        for i in range(len(train_data)):\n",
    "                            xi = train_data[i]\n",
    "                            yi = train_label[i]\n",
    "                            if not yi*(self.np.dot(w_t,xi)+b) >= 1:\n",
    "                                fit_constraint = False\n",
    "                                break\n",
    "                                \n",
    "                        if fit_constraint:\n",
    "                            # np.linalg.norm(w) get magnitude of w\n",
    "                            opt_dict[self.np.linalg.norm(w_t)] = [w_t,b]\n",
    "                        #print(opt_dict)\n",
    "                #print(w)\n",
    "                if w[0] < 0:\n",
    "                    optimized = True\n",
    "                    #print(w)\n",
    "                    print('Optimized a step.')\n",
    "                else:\n",
    "                    w = w - step\n",
    "            # Here we try to find the smallest norm of w (||w||)\n",
    "            # Remember that minimizing ||w|| is maximizing margin m\n",
    "            norms = sorted([n for n in opt_dict])\n",
    "            print(norms)\n",
    "            print(opt_dict[norms[0]])\n",
    "            #||w|| : [w,b]\n",
    "            opt_choice = opt_dict[norms[0]]\n",
    "            self.w = opt_choice[0]\n",
    "            self.b = opt_choice[1]\n",
    "            latest_optimum = opt_choice[0][0]+step*2\n",
    "        for i in range(len(train_data)):\n",
    "            xi = train_data[i]\n",
    "            yi = train_label[i]\n",
    "            print(xi,\" : \",yi*(self.np.dot(self.w,xi)+self.b))\n",
    "        \n",
    "    def predict(self,new_data):\n",
    "        # sign of ((new_data.w+b)=(w^T*new_data +b)) \n",
    "        # np.dot is matrix multiplication here\n",
    "        dist = self.np.dot(new_data,self.w)+self.b\n",
    "        classification = self.np.sign(dist)\n",
    "        print(new_data)\n",
    "        print(\"w: \",self.w)\n",
    "        print(\"b: \", self.b)\n",
    "        print(\"Distance: \",dist)\n",
    "        print(classification)\n",
    "        # if the classification isn't zero, and we have visualization on, we graph\n",
    "        self.visualize()\n",
    "        if self.visualization:\n",
    "            for i in range(len(new_data)):\n",
    "                [self.ax.scatter(new_data[i][0],new_data[i][1],s=100,marker='*',color=self.colors[classification[i]])]\n",
    "            self.plt.show()\n",
    "        return classification\n",
    "    \n",
    "    def hyperplane(self,x,w,b,v):\n",
    "        # v = (w.x+b)\n",
    "        return (-w[0]*x-b+v) / w[1]\n",
    "    \n",
    "    def visualize(self):\n",
    "        #scattering known featuresets.\n",
    "        for i in range(len(self.train_data)):\n",
    "            [self.ax.scatter(self.train_data[i][0],self.train_data[i][1],s=100,color=self.colors[self.train_label[i]])]\n",
    "        datarange = (self.min_feature_value*0.9,self.max_feature_value*1.1)\n",
    "        hyp_x_min = datarange[0]\n",
    "        hyp_x_max = datarange[1]\n",
    "        # w.x + b = 1\n",
    "        # pos sv hyperplane\n",
    "        psv1 = self.hyperplane(hyp_x_min, self.w, self.b, 1)\n",
    "        psv2 = self.hyperplane(hyp_x_max, self.w, self.b, 1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max], [psv1,psv2], \"k\")\n",
    "        # w.x + b = -1\n",
    "        # negative sv hyperplane\n",
    "        nsv1 = self.hyperplane(hyp_x_min, self.w, self.b, -1)\n",
    "        nsv2 = self.hyperplane(hyp_x_max, self.w, self.b, -1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max], [nsv1,nsv2], \"k\")\n",
    "\n",
    "        # w.x + b = 0\n",
    "        # decision\n",
    "        db1 = self.hyperplane(hyp_x_min, self.w, self.b, 0)\n",
    "        db2 = self.hyperplane(hyp_x_max, self.w, self.b, 0)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max], [db1,db2], \"g--\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How to draw a hyperplane? The SVM line (hyperplane) equation: <br>\n",
    "\\begin{equation}\n",
    "y=WX+b = w_{0}+w_{1}x_{1}+w_{2}x_{2}+...+w_{n}x_{n}\n",
    "\\end{equation}\n",
    "where $W$ is initialized weight matrix, $X$ is input data, $b$ is bias. The right most function is the feature wise expansion on $WX+b$ where $w_{0}=b$. \n",
    "__Notice the line equation and hyperplane equation is same, its a different way to express the same thing.__\n",
    "2. How can we find the optimal hyperplane? <br>\n",
    "If we maximize the margin(distance) between two hyperplanes then divide by 2 we get the optimal hyperplane.\n",
    "3. how do we maximize the margin? <br>\n",
    "    1. First use labeled train sample as two hyperplane constraints:\n",
    "    \\begin{equation}\n",
    "    \\vec{x_+}\\cdot\\vec{w}+bias \\geq1 \n",
    "    \\end{equation} where $x_+$ is known sample that are positive and\n",
    "    \\begin{equation}\n",
    "    \\vec {x_-}\\cdot\\vec{w}+bias \\leq-1\n",
    "    \\end{equation}where $x_-$ is known sample that are negative. <br>\n",
    "    We get the decision boundary if \\begin{equation}\\vec{x}\\cdot\\vec{w}+bias = 0 \\end{equation} <br>\n",
    "    We get (+) class hyperplane if \\begin{equation}\\vec{x}\\cdot\\vec{w}+bias = 1 \\end{equation} <br>\n",
    "    We get (-) class hyperplane if \\begin{equation}\\vec{x}\\cdot\\vec{w}+bias = -1 \\end{equation}\n",
    "    2. Second we want to minimum Magnitude of w, below explain how we derived to this simple answer:\n",
    "    first we know hyperplane $H_+$ will be:\n",
    "    \\begin{equation}H_+ = w^T x + b = 1 \\Rightarrow w^T x + b-1 =0 \\end{equation} and hyperplane $H_-$ will be:\n",
    "    \\begin{equation}H_- = w^T x + b = -1 \\Rightarrow w^T x + b+1 =0\\end{equation} and and decision boundary will be\n",
    "    \\begin{equation}w^T x + b = 0 \\end{equation}\n",
    "    At this point, we just need to know one fact: The distance from point $p$ to a line defined implicitly by the equation       $w^T x + b = 0$ is equal to \\begin{equation} \\frac{w^T p + b}{|w|}\\end{equation} Now, we can compute the distance\n",
    "    between two hyperplanes by taking a point on one of hyperplanes and substituting it in equation above. We have defined       $x_+$ is point on hyperplane $H_+ = w^T x+ b = 1$. Hyperplane $H_-$ can be convert to $w^T x + b + 1 = 0$. Then we can       know the distance between $H_+$ and $H_-$ (Other word margin $m$) is \\begin{equation}m = \\frac{w^T x_+ + b + 1}{|w|} =       \\frac{1 + 1}{|w|} = \\frac{2}{|w|}\\end{equation}\n",
    "4. Next step is to form optimization equation which minimizing $||w||$: <br>\n",
    "Minimizing $||w||$ is same as minimize $\\frac{1}{2}||w||^2$. \n",
    "    1. If we are deal with linear separable problem, we can simply use hard margin: \n",
    "    \\begin{equation}\n",
    "    \\begin{aligned}\n",
    "    \\text{minimize} \\quad & \\frac{1}{2}||w||^2 \\\\\n",
    "    \\text{subject to} \\quad & y_i\\cdot(w^T x_i +b)\\geq 1 \\\\\n",
    "    \\end{aligned}\n",
    "    \\end{equation} where $1\\leq i \\leq n$, $n$ is total number of training data-point.\n",
    "    2. If we are deal with no-linear separable problem, we add a slack variables $\\xi_i$:\n",
    "    \\begin{equation}\n",
    "    \\begin{aligned}\n",
    "    \\text{minimize} \\quad & \\frac{1}{2}||w||^2 + C \\sum_{i=1}^{n}\\xi_{i} \\\\\n",
    "    \\text{subject to} \\quad & y_i\\cdot(w^T x_i +b)\\geq 1-\\xi_{i}, \\xi_{i}\\geq 0\\\\\n",
    "    \\end{aligned}\n",
    "    \\end{equation}\n",
    "    Now we have a new term C, where it is the penalty parameter that user can change. (If we have large C, that means          $\\sum_{i=i}^{n}\\xi_{i} $ will be small (allow less error) since we minimizing the whole equation, visa verse)\n",
    "    Notice that the slack variable $\\xi_{i}$ is just hinge loss:\n",
    "    \\begin{equation}\n",
    "    \\xi_{i} = \\max \\left(0,1-y_{i}(w^T x_i +b)\\right)\n",
    "    \\end{equation}\n",
    "5. Choice optimization algorithm to optimize above equation (either hard margin or soft margin) <br>\n",
    "In this program demo, we use hard margin with Sequential minimal optimization (SMO).\n",
    "More details on SMO please check https://en.wikipedia.org/wiki/Sequential_minimal_optimization\n",
    "6. How to make final prediction with test data? <br>\n",
    "Final classification result will be sign of (w.x+b)\n",
    "\\begin{equation}\n",
    "y = sgn(w^T x +b)\n",
    "\\end{equation}\n",
    "Notice that w.x+b is given us the distance to decision boundary and we are taking sign of distance as classification result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T16:45:40.096032Z",
     "start_time": "2019-09-29T16:45:37.750514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized a step.\n",
      "[1.4142135623730951, 2.8284271247461903, 4.242640687119285, 5.656854249492381, 7.0710678118654755, 8.48528137423857, 9.899494936611665, 11.313708498984761, 12.727922061357855, 14.142135623730951, 15.556349186104045, 16.97056274847714, 18.384776310850235, 19.79898987322333, 21.213203435596427, 22.627416997969522, 24.041630560342615, 25.45584412271571, 26.870057685088806, 28.284271247461902, 29.698484809834994, 31.11269837220809, 32.526911934581186, 33.94112549695428, 35.35533905932738, 36.76955262170047, 38.18376618407357, 39.59797974644666, 41.012193308819754, 42.42640687119285, 43.840620433565945, 45.254833995939045, 46.66904755831214, 48.08326112068523, 49.49747468305833, 50.91168824543142, 52.32590180780452, 53.74011537017761, 55.154328932550705, 56.568542494923804, 57.982756057296896, 59.39696961966999, 60.81118318204309, 62.22539674441618, 63.63961030678928, 65.05382386916237, 66.46803743153546, 67.88225099390856, 69.29646455628166, 70.71067811865476, 72.12489168102785, 73.53910524340094, 74.95331880577403, 76.36753236814714, 77.78174593052023, 79.19595949289332, 80.61017305526642, 82.02438661763951, 83.43860018001261, 84.8528137423857, 86.2670273047588, 87.68124086713189, 89.09545442950498, 90.50966799187809, 91.92388155425118, 93.33809511662427, 94.75230867899737, 96.16652224137046, 97.58073580374356, 98.99494936611666, 100.40916292848975, 101.82337649086284, 103.23759005323593, 104.65180361560904, 106.06601717798213, 107.48023074035522, 108.89444430272832, 110.30865786510141, 111.72287142747452, 113.13708498984761, 114.5512985522207, 115.96551211459379, 117.37972567696688, 118.79393923933998, 120.20815280171308, 121.62236636408618, 123.03657992645927, 124.45079348883236, 125.86500705120545, 127.27922061357856, 128.69343417595164, 130.10764773832474, 131.52186130069785, 132.93607486307093, 134.35028842544403, 135.7645019878171, 137.17871555019022, 138.59292911256333, 140.0071426749364, 141.4213562373095]\n",
      "[array([ 1., -1.]), 0.0]\n",
      "Optimized a step.\n",
      "[0.4242640687119264, 0.5656854249492359, 0.7071067811865454, 0.8485281374238548, 0.9899494936611642, 1.1313708498984738, 1.2727922061357833, 1.4142135623730927, 1.4142135623730951, 1.5556349186104022, 1.6970562748477118, 1.8384776310850215, 1.979898987322331, 2.1213203435596406, 2.2627416997969503, 2.40416305603426, 2.5455844122715696, 2.6870057685088793, 2.828427124746189, 2.8284271247461903, 2.9698484809834986, 3.1112698372208083, 3.252691193458118, 3.394112549695427, 3.5355339059327373, 3.6769552621700465, 3.818376618407356, 3.959797974644666, 4.1012193308819755, 4.242640687119285, 5.656854249492381, 7.0710678118654755, 8.48528137423857, 9.899494936611665, 11.313708498984761, 12.727922061357855, 14.142135623730951, 15.556349186104045, 16.97056274847714, 18.384776310850235, 19.79898987322333, 21.213203435596427, 22.627416997969522, 24.041630560342615, 25.45584412271571, 26.870057685088806, 28.284271247461902, 29.698484809834994, 31.11269837220809, 32.526911934581186, 33.94112549695428, 35.35533905932738, 36.76955262170047, 38.18376618407357, 39.59797974644666, 41.012193308819754, 42.42640687119285, 43.840620433565945, 45.254833995939045, 46.66904755831214, 48.08326112068523, 49.49747468305833, 50.91168824543142, 52.32590180780452, 53.74011537017761, 55.154328932550705, 56.568542494923804, 57.982756057296896, 59.39696961966999, 60.81118318204309, 62.22539674441618, 63.63961030678928, 65.05382386916237, 66.46803743153546, 67.88225099390856, 69.29646455628166, 70.71067811865476, 72.12489168102785, 73.53910524340094, 74.95331880577403, 76.36753236814714, 77.78174593052023, 79.19595949289332, 80.61017305526642, 82.02438661763951, 83.43860018001261, 84.8528137423857, 86.2670273047588, 87.68124086713189, 89.09545442950498, 90.50966799187809, 91.92388155425118, 93.33809511662427, 94.75230867899737, 96.16652224137046, 97.58073580374356, 98.99494936611666, 100.40916292848975, 101.82337649086284, 103.23759005323593, 104.65180361560904, 106.06601717798213, 107.48023074035522, 108.89444430272832, 110.30865786510141, 111.72287142747452, 113.13708498984761, 114.5512985522207, 115.96551211459379, 117.37972567696688, 118.79393923933998, 120.20815280171308, 121.62236636408618, 123.03657992645927, 124.45079348883236, 125.86500705120545, 127.27922061357856, 128.69343417595164, 130.10764773832474, 131.52186130069785, 132.93607486307093, 134.35028842544403, 135.7645019878171, 137.17871555019022, 138.59292911256333, 140.0071426749364, 141.4213562373095]\n",
      "[array([ 0.3, -0.3]), 0.0]\n",
      "Optimized a step.\n",
      "[0.3252691193458094, 0.3394112549695404, 0.35355339059327134, 0.3676955262170023, 0.38183766184073326, 0.3959797974644642, 0.41012193308819517, 0.4242640687119262, 0.4242640687119264, 0.4384062043356571, 0.4525483399593881, 0.46669047558311905, 0.48083261120685, 0.49497474683058096, 0.5091168824543119, 0.5232590180780429, 0.5374011537017739, 0.5515432893255048, 0.5656854249492358, 0.5656854249492359, 0.5798275605729667, 0.5939696961966977, 0.6081118318204286, 0.6222539674441596, 0.6363961030678905, 0.6505382386916215, 0.6646803743153525, 0.6788225099390834, 0.6929646455628145, 0.7071067811865454, 0.8485281374238548, 0.9899494936611642, 1.1313708498984738, 1.2727922061357833, 1.4142135623730927, 1.4142135623730951, 1.5556349186104022, 1.6970562748477118, 1.8384776310850215, 1.979898987322331, 2.1213203435596406, 2.2627416997969503, 2.40416305603426, 2.5455844122715696, 2.6870057685088793, 2.828427124746189, 2.8284271247461903, 2.9698484809834986, 3.1112698372208083, 3.252691193458118, 3.394112549695427, 3.5355339059327373, 3.6769552621700465, 3.818376618407356, 3.959797974644666, 4.1012193308819755, 4.242640687119285, 5.656854249492381, 7.0710678118654755, 8.48528137423857, 9.899494936611665, 11.313708498984761, 12.727922061357855, 14.142135623730951, 15.556349186104045, 16.97056274847714, 18.384776310850235, 19.79898987322333, 21.213203435596427, 22.627416997969522, 24.041630560342615, 25.45584412271571, 26.870057685088806, 28.284271247461902, 29.698484809834994, 31.11269837220809, 32.526911934581186, 33.94112549695428, 35.35533905932738, 36.76955262170047, 38.18376618407357, 39.59797974644666, 41.012193308819754, 42.42640687119285, 43.840620433565945, 45.254833995939045, 46.66904755831214, 48.08326112068523, 49.49747468305833, 50.91168824543142, 52.32590180780452, 53.74011537017761, 55.154328932550705, 56.568542494923804, 57.982756057296896, 59.39696961966999, 60.81118318204309, 62.22539674441618, 63.63961030678928, 65.05382386916237, 66.46803743153546, 67.88225099390856, 69.29646455628166, 70.71067811865476, 72.12489168102785, 73.53910524340094, 74.95331880577403, 76.36753236814714, 77.78174593052023, 79.19595949289332, 80.61017305526642, 82.02438661763951, 83.43860018001261, 84.8528137423857, 86.2670273047588, 87.68124086713189, 89.09545442950498, 90.50966799187809, 91.92388155425118, 93.33809511662427, 94.75230867899737, 96.16652224137046, 97.58073580374356, 98.99494936611666, 100.40916292848975, 101.82337649086284, 103.23759005323593, 104.65180361560904, 106.06601717798213, 107.48023074035522, 108.89444430272832, 110.30865786510141, 111.72287142747452, 113.13708498984761, 114.5512985522207, 115.96551211459379, 117.37972567696688, 118.79393923933998, 120.20815280171308, 121.62236636408618, 123.03657992645927, 124.45079348883236, 125.86500705120545, 127.27922061357856, 128.69343417595164, 130.10764773832474, 131.52186130069785, 132.93607486307093, 134.35028842544403, 135.7645019878171, 137.17871555019022, 138.59292911256333, 140.0071426749364, 141.4213562373095]\n",
      "[array([ 0.23, -0.23]), 0.10000000000014353]\n",
      "[1, 7]  :  1.2799999999998461\n",
      "[2, 8]  :  1.2799999999998461\n",
      "[3, 8]  :  1.0499999999998477\n",
      "[5, 1]  :  1.0200000000001366\n",
      "[6, -1]  :  1.7100000000001314\n",
      "[10, 3]  :  1.7100000000001312\n",
      "[[0, 10], [1, 3], [3, 4], [3, 5], [5, 5], [5, 2], [6, -5], [5, -5]]\n",
      "w:  [ 0.23 -0.23]\n",
      "b:  0.10000000000014353\n",
      "Distance:  [-2.2  -0.36 -0.13 -0.36  0.1   0.79  2.63  2.4 ]\n",
      "[-1. -1. -1. -1.  1.  1.  1.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntxkGdH6+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f889fa736a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1,7],[2,8],[3,8],[5,1],[6,-1],[10,3]]\n",
    "label = [-1,-1,-1,1,1,1]\n",
    "test_data = [[0,10],[1,3],[3,4],[3,5],[5,5],[5,2],[6,-5],[5,-5]]\n",
    "\n",
    "svm = SupportVectorMachine()\n",
    "svm.fit(data, label)\n",
    "svm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "label = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(data, label)\n",
    "print(clf.predict(data[-5:]))\n",
    "y_pred = clf.predict(data)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"% (iris.data.shape[0],(iris.target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
