{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T21:21:32.952023Z",
     "start_time": "2019-04-21T21:21:31.491999Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "# binary logistic regression\n",
    "class Logistic_regression(object):\n",
    "    \n",
    "    def __init__(self, n_iter=10, l_rate = 0.3, fit_intercept=True, verbose=True):\n",
    "        self.l_rate = l_rate\n",
    "        self.n_iter=n_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.hstack([intercept, data])\n",
    "    \n",
    "    def get_score(self, newdata):\n",
    "        return np.dot(newdata, self.coef)\n",
    "        \n",
    "    def sigmoid(self,score):\n",
    "        # apply sigmoid function to score get probability\n",
    "        return 1 / (1 + np.exp(-score))\n",
    "    \n",
    "    def predict_prob(self, newdata):\n",
    "        return self.sigmoid(self.get_score(newdata))\n",
    "\n",
    "    def log_likelihood(self, features, target, weights):\n",
    "        scores = np.dot(features, weights)\n",
    "        logli = np.sum( target*scores - np.log(1 + np.exp(scores)))\n",
    "        return logli\n",
    "    \n",
    "    # estimate the coefficient values\n",
    "    def stochastic_gradient_descent(self, data, label, l_rate, n_iter):\n",
    "        # initial 0 weight\n",
    "        self.coef = np.zeros(len(data[0]))\n",
    "        #  run through the training data while updating the coefficients for each iteration\n",
    "        for cycle in range(n_iter):\n",
    "            sum_error = 0\n",
    "            for i in range(len(label)):\n",
    "                iter_result = self.predict_prob(data[i])\n",
    "                print(\"Expect: \", label[i],\" Predict: \", iter_result)\n",
    "                # derivative of loss function is (sigmoid(score)-y)*x\n",
    "                # error = prediction - true\n",
    "                error_signal = iter_result - label[i] \n",
    "                # error * x get gradient\n",
    "                gradient = np.dot(data[i], error_signal)\n",
    "                weight_change = (-self.l_rate)*gradient\n",
    "                print(\"Input sample x: \", data[i])\n",
    "                print(\"weigth before update: \", self.coef)\n",
    "                print(\"w*x: \", self.get_score(data[i]))\n",
    "                print(\"error signal strength: \",error_signal)\n",
    "                print(\"gradient: \", gradient)\n",
    "                print(\"Weight changes: \", weight_change)\n",
    "                self.coef += weight_change\n",
    "                print(\"weigth after update: \", self.coef)\n",
    "                print(\"w*x: \", self.get_score(data[i]))\n",
    "                print(\"\\n\")\n",
    "            if(self.verbose == True):\n",
    "                print('\\n>epoch=%d, lrate=%.3f, error=%.3f \\n' % (cycle, self.l_rate, self.log_likelihood(data, label, self.coef)))\n",
    "        return self.coef\n",
    "    \n",
    "    def fit(self, data, label):\n",
    "        if isinstance(data,np.ndarray):\n",
    "            print(\"pass\")\n",
    "        else:\n",
    "            data = np.asarray(data)\n",
    "        # add x_0 as 1 for bias term\n",
    "        if self.fit_intercept:\n",
    "            data = self.__add_intercept(data)\n",
    "        print(data)\n",
    "        self.trained_coef = self.stochastic_gradient_descent(data, label, self.l_rate, self.n_iter)\n",
    "        self.intercept = self.trained_coef[0]\n",
    "        self.trained_coef = self.trained_coef[1:]\n",
    "        print(\"Intercept: \",self.intercept, \"Final coefficient: \", self.trained_coef)\n",
    "    \n",
    "    def predict(self, newdata):\n",
    "        if isinstance(newdata,np.ndarray):\n",
    "            print(\"pass\")\n",
    "        else:\n",
    "            newdata = np.asarray(newdata)\n",
    "        if self.fit_intercept:\n",
    "            newdata = self.__add_intercept(newdata)\n",
    "        probabilities = self.predict_prob(newdata)\n",
    "        print(probabilities)\n",
    "        result = []\n",
    "        for sample in probabilities:\n",
    "            if(sample>=0.5):\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Linear regression function: \n",
    "\\begin{equation}\n",
    "y=WX+b = w_{0}+w_{1}x_{1}+w_{2}x_{2}+...+w_{n}x_{n}\n",
    "\\end{equation}\n",
    "where $W$ is initialized weight matrix, $X$ is input data, $b$ is bias. The right most function is the feature wise expansion on $WX+b$ where $w_{0}=b$\n",
    "2. Sigmoid activation function:\n",
    "\\begin{equation}\n",
    "Sigmoid(y) = \\frac{1} {1 + e^{-y}}\n",
    "\\end{equation}\n",
    "3. Apply sigmoid function on linear regression function to get probability:\n",
    "\\begin{equation}\n",
    "P = \\frac{1} {1 + e^{-(WX+b)}}\n",
    "\\end{equation}\n",
    "4. Cost function of linear regression, can't used directly for logistic regression:\n",
    "\\begin{equation}\n",
    "J(W) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_w(x^{(i)}) - y^{(i)})^2\n",
    "\\end{equation}\n",
    "rewritten to: \n",
    "\\begin{equation}\n",
    "J(W) = \\frac{1}{m} \\sum_{i=1}^{m} \\frac{1}{2}(h_w(x^{(i)}) - y^{(i)})^2\n",
    "\\end{equation}\n",
    "define a Cost function: \n",
    "\\begin{equation}\n",
    "\\mathrm{Cost}(h_w(x^{(i)}),y^{(i)}) = \\frac{1}{2}(h_w(x^{(i)}) - y^{(i)})^2\n",
    "\\end{equation}\n",
    "takes two parameters for input, $h_w(x^{(i)})$ as hypothesis function (prediction) and $y^{(i)}$ as output (true label). Think it as error algorithm made, if model makes a prediction $h_w(x^{(i)})$ while the actual label was $y^{(i)}$.\n",
    "Now rewrite the cost function for the entrie linear regression as:\n",
    "\\begin{equation}\n",
    "J(W) = \\dfrac{1}{m} \\sum_{i=1}^m \\mathrm{Cost}(h_w(x^{(i)}),y^{(i)})\n",
    "\\end{equation}\n",
    "5. Optimize weight matrix W and bias b (intercept) for logistic regression, form objective (cost) function:\n",
    "\\begin{equation}\n",
    "\\mathrm{Cost}(h_w(x),y) =\n",
    "\\begin{cases}\n",
    "-\\log(h_w(x)) & \\text{if y = 1} \\\\\n",
    "-\\log(1-h_w(x)) & \\text{if y = 0}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "which can be rewrite as \n",
    "\\begin{equation}\n",
    "\\mathrm{Cost}(h_w(x),y) = -y \\log(h_w(x)) - (1 - y) \\log(1-h_w(x))\n",
    "\\end{equation}\n",
    "now final logsitic regression objective function is:\n",
    "\\begin{equation}\n",
    "J(W)= - \\dfrac{1}{m} [\\sum_{i=1}^{m} y^{(i)} \\log(h_w(x^{(i)})) + (1 - y^{(i)}) \\log(1-h_w(x^{(i)}))]\n",
    "\\end{equation}\n",
    "6. Optimize weight matrix W and bias b (intercept) for logistic regression, gradient descent:\n",
    "\\begin{equation}\n",
    "\\Delta W = - \\eta \\nabla J = -\\eta \\frac{\\partial}{\\partial W} J(W)= - \\eta (\\dfrac{1}{m} \\sum_{i=1}^{m} (h_w(x^{(i)}) - y^{(i)}) x^{(i)})\n",
    "\\end{equation}\n",
    "First find the weight changes $\\Delta W$ with above equation, where $\\eta$ is learning rate from user input, $\\nabla J$ means gradient of cost function $J$. Then we update weight $W$: \n",
    "\\begin{equation}\n",
    "W := W + \\Delta W\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: \n",
    "Our goal is to predict whether a student will pass or fail based on number of hours slept and hours spent studying.\n",
    "\n",
    "| Studied | Slept | Passed |\n",
    "|---|---|---|\n",
    "|  4.85\t  |  9.63 |  \t1  |\n",
    "|  8.62\t  |  3.23 |  \t0  |\n",
    "|  5.43\t  |  8.23 |  \t1  |\n",
    "|  9.21\t  |  6.34 |  \t0  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T21:21:40.957229Z",
     "start_time": "2019-04-21T21:21:40.589025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00 4.85 9.63]\n",
      " [1.00 8.62 3.23]\n",
      " [1.00 5.43 8.23]\n",
      " [1.00 9.21 6.34]]\n",
      "Expect:  1  Predict:  0.5\n",
      "Input sample x:  [1.00 4.85 9.63]\n",
      "weigth before update:  [0.00 0.00 0.00]\n",
      "w*x:  0.0\n",
      "error signal strength:  -0.5\n",
      "gradient:  [-0.50 -2.42 -4.82]\n",
      "Weight changes:  [0.10 0.48 0.96]\n",
      "weigth after update:  [0.10 0.48 0.96]\n",
      "w*x:  11.725940000000001\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  0.9993837183479858\n",
      "Input sample x:  [1.00 8.62 3.23]\n",
      "weigth before update:  [0.10 0.48 0.96]\n",
      "w*x:  7.39119\n",
      "error signal strength:  0.9993837183479858\n",
      "gradient:  [1.00 8.61 3.23]\n",
      "Weight changes:  [-0.20 -1.72 -0.65]\n",
      "weigth after update:  [-0.10 -1.24 0.32]\n",
      "w*x:  -9.74570233502335\n",
      "\n",
      "\n",
      "Expect:  1  Predict:  0.014633632790014773\n",
      "Input sample x:  [1.00 5.43 8.23]\n",
      "weigth before update:  [-0.10 -1.24 0.32]\n",
      "w*x:  -4.209691023209496\n",
      "error signal strength:  -0.9853663672099853\n",
      "gradient:  [-0.99 -5.35 -8.11]\n",
      "Weight changes:  [0.20 1.07 1.62]\n",
      "weigth after update:  [0.10 -0.17 1.94]\n",
      "w*x:  15.146412333061884\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  0.9999805319834059\n",
      "Input sample x:  [1.00 9.21 6.34]\n",
      "weigth before update:  [0.10 -0.17 1.94]\n",
      "w*x:  10.846718145407122\n",
      "error signal strength:  0.9999805319834059\n",
      "gradient:  [1.00 9.21 6.34]\n",
      "Weight changes:  [-0.20 -1.84 -1.27]\n",
      "weigth after update:  [-0.10 -2.01 0.67]\n",
      "w*x:  -14.356731183870728\n",
      "\n",
      "\n",
      "\n",
      ">epoch=0, lrate=0.200, error=-8.914 \n",
      "\n",
      "Expect:  1  Predict:  0.03275692927383203\n",
      "Input sample x:  [1.00 4.85 9.63]\n",
      "weigth before update:  [-0.10 -2.01 0.67]\n",
      "w*x:  -3.38533530908214\n",
      "error signal strength:  -0.967243070726168\n",
      "gradient:  [-0.97 -4.69 -9.31]\n",
      "Weight changes:  [0.19 0.94 1.86]\n",
      "weigth after update:  [0.09 -1.07 2.53]\n",
      "w*x:  19.298333116419464\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  0.2767475335092266\n",
      "Input sample x:  [1.00 8.62 3.23]\n",
      "weigth before update:  [0.09 -1.07 2.53]\n",
      "w*x:  -0.9606526949318184\n",
      "error signal strength:  0.2767475335092266\n",
      "gradient:  [0.28 2.39 0.89]\n",
      "Weight changes:  [-0.06 -0.48 -0.18]\n",
      "weigth after update:  [0.04 -1.55 2.36]\n",
      "w*x:  -5.706169955879943\n",
      "\n",
      "\n",
      "Expect:  1  Predict:  0.9999834888335571\n",
      "Input sample x:  [1.00 5.43 8.23]\n",
      "weigth before update:  [0.04 -1.55 2.36]\n",
      "w*x:  11.011457140537127\n",
      "error signal strength:  -1.651116644285633e-05\n",
      "gradient:  [-0.00 -0.00 -0.00]\n",
      "Weight changes:  [0.00 0.00 0.00]\n",
      "weigth after update:  [0.04 -1.55 2.36]\n",
      "w*x:  11.011781478625823\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  0.6695060392693615\n",
      "Input sample x:  [1.00 9.21 6.34]\n",
      "weigth before update:  [0.04 -1.55 2.36]\n",
      "w*x:  0.7059517996620777\n",
      "error signal strength:  0.6695060392693615\n",
      "gradient:  [0.67 6.17 4.24]\n",
      "Weight changes:  [-0.13 -1.23 -0.85]\n",
      "weigth after update:  [-0.10 -2.78 1.51]\n",
      "w*x:  -16.16823824372056\n",
      "\n",
      "\n",
      "\n",
      ">epoch=1, lrate=0.200, error=-3.200 \n",
      "\n",
      "Expect:  1  Predict:  0.7145119321675026\n",
      "Input sample x:  [1.00 4.85 9.63]\n",
      "weigth before update:  [-0.10 -2.78 1.51]\n",
      "w*x:  0.9173994629640081\n",
      "error signal strength:  -0.28548806783249736\n",
      "gradient:  [-0.29 -1.38 -2.75]\n",
      "Weight changes:  [0.06 0.28 0.55]\n",
      "weigth after update:  [-0.04 -2.50 2.06]\n",
      "w*x:  7.612631371203598\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  3.083186216410031e-07\n",
      "Input sample x:  [1.00 8.62 3.23]\n",
      "weigth before update:  [-0.04 -2.50 2.06]\n",
      "w*x:  -14.992131794518503\n",
      "error signal strength:  3.083186216410031e-07\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.04 -2.50 2.06]\n",
      "w*x:  -14.992137081399733\n",
      "\n",
      "\n",
      "Expect:  1  Predict:  0.9637631696071204\n",
      "Input sample x:  [1.00 5.43 8.23]\n",
      "weigth before update:  [-0.04 -2.50 2.06]\n",
      "w*x:  3.2807695739615035\n",
      "error signal strength:  -0.036236830392879615\n",
      "gradient:  [-0.04 -0.20 -0.30]\n",
      "Weight changes:  [0.01 0.04 0.06]\n",
      "weigth after update:  [-0.03 -2.47 2.12]\n",
      "w*x:  3.9925899259938546\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  8.899973645944488e-05\n",
      "Input sample x:  [1.00 9.21 6.34]\n",
      "weigth before update:  [-0.03 -2.47 2.12]\n",
      "w*x:  -9.32678814566918\n",
      "error signal strength:  8.899973645944488e-05\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.03 -2.47 2.12]\n",
      "w*x:  -9.32903128968692\n",
      "\n",
      "\n",
      "\n",
      ">epoch=2, lrate=0.200, error=-0.019 \n",
      "\n",
      "Expect:  1  Predict:  0.9997713814009145\n",
      "Input sample x:  [1.00 4.85 9.63]\n",
      "weigth before update:  [-0.03 -2.47 2.12]\n",
      "w*x:  8.383226804347563\n",
      "error signal strength:  -0.00022861859908551718\n",
      "gradient:  [-0.00 -0.00 -0.00]\n",
      "Weight changes:  [0.00 0.00 0.00]\n",
      "weigth after update:  [-0.03 -2.47 2.12]\n",
      "w*x:  8.388588340299085\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  5.294507983714057e-07\n",
      "Input sample x:  [1.00 8.62 3.23]\n",
      "weigth before update:  [-0.03 -2.47 2.12]\n",
      "w*x:  -14.451425067694174\n",
      "error signal strength:  5.294507983714057e-07\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.03 -2.47 2.12]\n",
      "w*x:  -14.451434146430561\n",
      "\n",
      "\n",
      "Expect:  1  Predict:  0.9819362462488539\n",
      "Input sample x:  [1.00 5.43 8.23]\n",
      "weigth before update:  [-0.03 -2.47 2.12]\n",
      "w*x:  3.995619008601487\n",
      "error signal strength:  -0.018063753751146105\n",
      "gradient:  [-0.02 -0.10 -0.15]\n",
      "Weight changes:  [0.00 0.02 0.03]\n",
      "weigth after update:  [-0.03 -2.45 2.15]\n",
      "w*x:  4.350455439237351\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  0.00012954303279364\n",
      "Input sample x:  [1.00 9.21 6.34]\n",
      "weigth before update:  [-0.03 -2.45 2.15]\n",
      "w*x:  -8.95136788103495\n",
      "error signal strength:  0.00012954303279364\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.03 -2.45 2.15]\n",
      "w*x:  -8.9546328758609\n",
      "\n",
      "\n",
      "\n",
      ">epoch=3, lrate=0.200, error=-0.013 \n",
      "\n",
      "Expect:  1  Predict:  0.9998448402298374\n",
      "Input sample x:  [1.00 4.85 9.63]\n",
      "weigth before update:  [-0.03 -2.45 2.15]\n",
      "w*x:  8.770900024878236\n",
      "error signal strength:  -0.00015515977016256066\n",
      "gradient:  [-0.00 -0.00 -0.00]\n",
      "Weight changes:  [0.00 0.00 0.00]\n",
      "weigth after update:  [-0.03 -2.45 2.15]\n",
      "w*x:  8.774538813188919\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  6.92467974633327e-07\n",
      "Input sample x:  [1.00 8.62 3.23]\n",
      "weigth before update:  [-0.03 -2.45 2.15]\n",
      "w*x:  -14.18300315350294\n",
      "error signal strength:  6.92467974633327e-07\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.03 -2.45 2.15]\n",
      "w*x:  -14.18301502756984\n",
      "\n",
      "\n",
      "Expect:  1  Predict:  0.9872712219139\n",
      "Input sample x:  [1.00 5.43 8.23]\n",
      "weigth before update:  [-0.03 -2.45 2.15]\n",
      "w*x:  4.35107937491329\n",
      "error signal strength:  -0.012728778086099957\n",
      "gradient:  [-0.01 -0.07 -0.10]\n",
      "Weight changes:  [0.00 0.01 0.02]\n",
      "weigth after update:  [-0.03 -2.43 2.17]\n",
      "w*x:  4.601117890974281\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  0.00016846023964905589\n",
      "Input sample x:  [1.00 9.21 6.34]\n",
      "weigth before update:  [-0.03 -2.43 2.17]\n",
      "w*x:  -8.688642328060103\n",
      "error signal strength:  0.00016846023964905589\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.03 -2.43 2.17]\n",
      "w*x:  -8.692888189832603\n",
      "\n",
      "\n",
      "\n",
      ">epoch=4, lrate=0.200, error=-0.010 \n",
      "\n",
      "Expect:  1  Predict:  0.9998817138978011\n",
      "Input sample x:  [1.00 4.85 9.63]\n",
      "weigth before update:  [-0.03 -2.43 2.17]\n",
      "w*x:  9.042285980082303\n",
      "error signal strength:  -0.00011828610219888347\n",
      "gradient:  [-0.00 -0.00 -0.00]\n",
      "Weight changes:  [0.00 0.00 0.00]\n",
      "weigth after update:  [-0.03 -2.43 2.17]\n",
      "w*x:  9.04506001155674\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  8.354558871957727e-07\n",
      "Input sample x:  [1.00 8.62 3.23]\n",
      "weigth before update:  [-0.03 -2.43 2.17]\n",
      "w*x:  -13.995287452938634\n",
      "error signal strength:  8.354558871957727e-07\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.03 -2.43 2.17]\n",
      "w*x:  -13.99530177888504\n",
      "\n",
      "\n",
      "Expect:  1  Predict:  0.9900496804887876\n",
      "Input sample x:  [1.00 5.43 8.23]\n",
      "weigth before update:  [-0.03 -2.43 2.17]\n",
      "w*x:  4.600150461846894\n",
      "error signal strength:  -0.009950319511212391\n",
      "gradient:  [-0.01 -0.05 -0.08]\n",
      "Weight changes:  [0.00 0.01 0.02]\n",
      "weigth after update:  [-0.03 -2.42 2.18]\n",
      "w*x:  4.795610160184566\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  0.00020649484928413623\n",
      "Input sample x:  [1.00 9.21 6.34]\n",
      "weigth before update:  [-0.03 -2.42 2.18]\n",
      "w*x:  -8.485028572635951\n",
      "error signal strength:  0.00020649484928413623\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.03 -2.42 2.18]\n",
      "w*x:  -8.490233056427616\n",
      "\n",
      "\n",
      "\n",
      ">epoch=5, lrate=0.200, error=-0.009 \n",
      "\n",
      "Expect:  1  Predict:  0.9999041626115766\n",
      "Input sample x:  [1.00 4.85 9.63]\n",
      "weigth before update:  [-0.03 -2.42 2.18]\n",
      "w*x:  9.252761831325587\n",
      "error signal strength:  -9.583738842344758e-05\n",
      "gradient:  [-0.00 -0.00 -0.00]\n",
      "Weight changes:  [0.00 0.00 0.00]\n",
      "weigth after update:  [-0.03 -2.42 2.18]\n",
      "w*x:  9.255009398258409\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  9.660870019742695e-07\n",
      "Input sample x:  [1.00 8.62 3.23]\n",
      "weigth before update:  [-0.03 -2.42 2.18]\n",
      "w*x:  -13.850010976546399\n",
      "error signal strength:  9.660870019742695e-07\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.03 -2.42 2.18]\n",
      "w*x:  -13.850027542484625\n",
      "\n",
      "\n",
      "Expect:  1  Predict:  0.9917836366357632\n",
      "Input sample x:  [1.00 5.43 8.23]\n",
      "weigth before update:  [-0.03 -2.42 2.18]\n",
      "w*x:  4.79337727720109\n",
      "error signal strength:  -0.008216363364236812\n",
      "gradient:  [-0.01 -0.04 -0.07]\n",
      "Weight changes:  [0.00 0.01 0.01]\n",
      "weigth after update:  [-0.02 -2.41 2.20]\n",
      "w*x:  4.9547759039282795\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  0.00024386786983957988\n",
      "Input sample x:  [1.00 9.21 6.34]\n",
      "weigth before update:  [-0.02 -2.41 2.20]\n",
      "w*x:  -8.318640098784842\n",
      "error signal strength:  0.00024386786983957988\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.02 -2.41 2.20]\n",
      "w*x:  -8.3247865299442\n",
      "\n",
      "\n",
      "\n",
      ">epoch=6, lrate=0.200, error=-0.007 \n",
      "\n",
      "Expect:  1  Predict:  0.9999193206292164\n",
      "Input sample x:  [1.00 4.85 9.63]\n",
      "weigth before update:  [-0.02 -2.41 2.20]\n",
      "w*x:  9.424946961198597\n",
      "error signal strength:  -8.067937078359844e-05\n",
      "gradient:  [-0.00 -0.00 -0.00]\n",
      "Weight changes:  [0.00 0.00 0.00]\n",
      "weigth after update:  [-0.02 -2.41 2.20]\n",
      "w*x:  9.42683904412069\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  1.0876257191321524e-06\n",
      "Input sample x:  [1.00 8.62 3.23]\n",
      "weigth before update:  [-0.02 -2.41 2.20]\n",
      "w*x:  -13.731512389239185\n",
      "error signal strength:  1.0876257191321524e-06\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.02 -2.41 2.20]\n",
      "w*x:  -13.731531039257698\n",
      "\n",
      "\n",
      "Expect:  1  Predict:  0.992976510118595\n",
      "Input sample x:  [1.00 5.43 8.23]\n",
      "weigth before update:  [-0.02 -2.41 2.20]\n",
      "w*x:  4.95144677968492\n",
      "error signal strength:  -0.007023489881404998\n",
      "gradient:  [-0.01 -0.04 -0.06]\n",
      "Weight changes:  [0.00 0.01 0.01]\n",
      "weigth after update:  [-0.02 -2.41 2.21]\n",
      "w*x:  5.0894131245796945\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  0.0002806454539442798\n",
      "Input sample x:  [1.00 9.21 6.34]\n",
      "weigth before update:  [-0.02 -2.41 2.21]\n",
      "w*x:  -8.178137730175077\n",
      "error signal strength:  0.0002806454539442798\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.02 -2.41 2.21]\n",
      "w*x:  -8.185211101357561\n",
      "\n",
      "\n",
      "\n",
      ">epoch=7, lrate=0.200, error=-0.007 \n",
      "\n",
      "Expect:  1  Predict:  0.999930252556297\n",
      "Input sample x:  [1.00 4.85 9.63]\n",
      "weigth before update:  [-0.02 -2.41 2.21]\n",
      "w*x:  9.570560037477467\n",
      "error signal strength:  -6.974744370302766e-05\n",
      "gradient:  [-0.00 -0.00 -0.00]\n",
      "Weight changes:  [0.00 0.00 0.00]\n",
      "weigth after update:  [-0.02 -2.41 2.21]\n",
      "w*x:  9.572195746157497\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  1.2018264948188077e-06\n",
      "Input sample x:  [1.00 8.62 3.23]\n",
      "weigth before update:  [-0.02 -2.41 2.21]\n",
      "w*x:  -13.631666877515622\n",
      "error signal strength:  1.2018264948188077e-06\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.02 -2.41 2.21]\n",
      "w*x:  -13.631687485787367\n",
      "\n",
      "\n",
      "Expect:  1  Predict:  0.993849731307776\n",
      "Input sample x:  [1.00 5.43 8.23]\n",
      "weigth before update:  [-0.02 -2.41 2.21]\n",
      "w*x:  5.085090248825081\n",
      "error signal strength:  -0.006150268692224015\n",
      "gradient:  [-0.01 -0.03 -0.05]\n",
      "Weight changes:  [0.00 0.01 0.01]\n",
      "weigth after update:  [-0.02 -2.40 2.22]\n",
      "w*x:  5.205903420896906\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  0.00031683288415537485\n",
      "Input sample x:  [1.00 9.21 6.34]\n",
      "weigth before update:  [-0.02 -2.40 2.22]\n",
      "w*x:  -8.056819219329155\n",
      "error signal strength:  0.00031683288415537485\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.02 -2.40 2.22]\n",
      "w*x:  -8.064804656331432\n",
      "\n",
      "\n",
      "\n",
      ">epoch=8, lrate=0.200, error=-0.006 \n",
      "\n",
      "Expect:  1  Predict:  0.9999385070942172\n",
      "Input sample x:  [1.00 4.85 9.63]\n",
      "weigth before update:  [-0.02 -2.40 2.22]\n",
      "w*x:  9.696527248134716\n",
      "error signal strength:  -6.149290578283395e-05\n",
      "gradient:  [-0.00 -0.00 -0.00]\n",
      "Weight changes:  [0.00 0.00 0.00]\n",
      "weigth after update:  [-0.02 -2.40 2.22]\n",
      "w*x:  9.697969372381987\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  1.3097577170308875e-06\n",
      "Input sample x:  [1.00 8.62 3.23]\n",
      "weigth before update:  [-0.02 -2.40 2.22]\n",
      "w*x:  -13.545667076929167\n",
      "error signal strength:  1.3097577170308875e-06\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.02 -2.40 2.22]\n",
      "w*x:  -13.545689535947231\n",
      "\n",
      "\n",
      "Expect:  1  Predict:  0.9945172799869095\n",
      "Input sample x:  [1.00 5.43 8.23]\n",
      "weigth before update:  [-0.02 -2.40 2.22]\n",
      "w*x:  5.200656143124146\n",
      "error signal strength:  -0.00548272001309047\n",
      "gradient:  [-0.01 -0.03 -0.05]\n",
      "Weight changes:  [0.00 0.01 0.01]\n",
      "weigth after update:  [-0.02 -2.39 2.23]\n",
      "w*x:  5.308356282664487\n",
      "\n",
      "\n",
      "Expect:  0  Predict:  0.0003524082403319354\n",
      "Input sample x:  [1.00 9.21 6.34]\n",
      "weigth before update:  [-0.02 -2.39 2.23]\n",
      "w*x:  -7.950367810363138\n",
      "error signal strength:  0.0003524082403319354\n",
      "gradient:  [0.00 0.00 0.00]\n",
      "Weight changes:  [-0.00 -0.00 -0.00]\n",
      "weigth after update:  [-0.02 -2.39 2.23]\n",
      "w*x:  -7.959249886507971\n",
      "\n",
      "\n",
      "\n",
      ">epoch=9, lrate=0.200, error=-0.005 \n",
      "\n",
      "Intercept:  -0.020927128839824855 Final coefficient:  [-2.39 2.23]\n",
      "[1.00 0.00 1.00 0.00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[4.85, 9.63],\n",
    "[8.62, 3.23],\n",
    "[5.43, 8.23],\n",
    "[9.21, 6.34]]\n",
    "\n",
    "label = [1,0,1,0]\n",
    "\n",
    "lrclf = Logistic_regression(fit_intercept=True, n_iter = 10, l_rate = 0.2)\n",
    "lrclf.fit(data, label)\n",
    "lrclf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T23:06:31.762954Z",
     "start_time": "2019-04-20T23:06:30.446164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11420064] [[-3.51068824  3.50466732]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao137/intel/intelpython3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(fit_intercept=True, C = 1e15)\n",
    "clf.fit(data, label)\n",
    "\n",
    "print(clf.intercept_, clf.coef_)\n",
    "clf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
